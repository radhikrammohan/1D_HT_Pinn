{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Three Phase Simulation of Alloys and PINN model development \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the simulation of 1D Phase change of aluminium alloy. There will be three phases (solid,liquid and mushy).   \n",
    "\n",
    "The approach used is finite difference method and the physics involved in heat conduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import csv\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "\n",
    "from pinn_loss import loss_fn_data, l1_regularization, pde_loss, boundary_loss, ic_loss, accuracy\n",
    "from Input_vec_gen import input_gen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the constants and inital geometric domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_l = 3.394878564540885e-05, alpha_s = 3.686205086349929e-05, m_eff = 6.296953764744878e-06\n",
      "dx is 0.0003061224489795918\n",
      "dt is  0.0012711033647622566\n",
      "num_steps is 31469\n",
      "cfl is 0.0012711033647622566\n",
      "stability criteria satisfied\n"
     ]
    }
   ],
   "source": [
    "# Geometry\n",
    "length = 15.0e-3             # Length of the rod\n",
    "\n",
    "# Material properties\n",
    "rho = 2300.0                     # Density of AL380 (kg/m^3)\n",
    "rho_l = 2460.0                   # Density of AL380 (kg/m^3)\n",
    "rho_s = 2710.0                    # Density of AL380 (kg/m^3)\n",
    "rho_m = (rho_l + rho_s )/2       # Desnity in mushy zone is taken as average of liquid and solid density\n",
    "\n",
    "k = 104.0                       # W/m-K\n",
    "k_l = k                       # W/m-K\n",
    "k_s = 96.2                    # W/m-K\n",
    "k_m =  (k_l+k_s)/2                     # W/m-K\n",
    "k_mo = 41.5\n",
    "\n",
    "\n",
    "cp = 1245.3                      # Specific heat of aluminum (J/kg-K)\n",
    "cp_l = cp                      # Specific heat of aluminum (J/kg-K)\n",
    "cp_s = 963.0                 # Specific heat of aluminum (J/kg-K)\n",
    "cp_m =  (cp_l+cp_s)/2                 # Specific heat of mushy zone is taken as average of liquid and solid specific heat\n",
    "# cp_m = cp\n",
    "           # Thermal diffusivity\n",
    "alpha_l = k_l / (rho_l * cp_l) \n",
    "alpha_s = k_s / (rho_s*cp_s)\n",
    "alpha_m = k_m / (rho_m * cp_m)          #`Thermal diffusivity in mushy zone is taken as average of liquid and solid thermal diffusivity`\n",
    "\n",
    "\n",
    "#L_fusion = 3.9e3                 # J/kg\n",
    "L_fusion = 389.0e3               # J/kg  # Latent heat of fusion of aluminum\n",
    "         # Thermal diffusivity\n",
    "\n",
    "\n",
    "T_L = 574.4 +273.0                       #  K -Liquidus Temperature (615 c) AL 380\n",
    "T_S = 497.3 +273.0                     # K- Solidus Temperature (550 C)\n",
    "m_eff =(k_m/(rho_m*(cp_m + (L_fusion/(T_L-T_S)))))\n",
    "print (f\"alpha_l = {alpha_l}, alpha_s = {alpha_s}, m_eff = {m_eff}\")\n",
    "\n",
    "# htc = 10.0                   # W/m^2-K\n",
    "# q = htc*(919.0-723.0)\n",
    "# q = 10000.0\n",
    "\n",
    "\n",
    "num_points = 50                        # Number of spatial points\n",
    "dx = length / (num_points - 1)         # Distance between two spatial points\n",
    "print('dx is',dx)\n",
    "\n",
    "                                                              \n",
    "# Time Discretization  \n",
    "# \n",
    "time_end = 40        # seconds                         \n",
    "\n",
    "maxi = max(alpha_s,alpha_l,alpha_m)\n",
    "dt = abs(0.5*((dx**2) /maxi)) \n",
    "\n",
    "print('dt is ',dt)\n",
    "num_steps = round(time_end/dt)\n",
    "print('num_steps is',num_steps)\n",
    "cfl = 0.5 *(dx**2/max(alpha_l,alpha_s,alpha_m))\n",
    "print('cfl is',cfl)\n",
    "\n",
    "time_steps = np.linspace(0, time_end, num_steps + 1)\n",
    "step_coeff = dt / (dx ** 2)\n",
    "\n",
    "if dt <= cfl:\n",
    "    print('stability criteria satisfied')\n",
    "else:\n",
    "    print('stability criteria not satisfied')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial and Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_init = 919.0\n",
    "# Initial temperature and phase fields\n",
    "temperature = np.full(num_points+2, 919.0)            # Initial temperature of the rod with ghost points at both ends\n",
    "phase = np.zeros(num_points+2)*0.0                    # Initial phase of the rod with ghost points at both ends\n",
    "\n",
    "# Set boundary conditions\n",
    "# temperature[-1] = 919.0 \n",
    "phase[-1] = 1.0\n",
    "\n",
    "# temperature[0] = 919.0 #(40 C)\n",
    "phase[0] = 1.0\n",
    "\n",
    "# Store initial state in history\n",
    "temperature_history = [temperature.copy()]    # List to store temperature at each time step\n",
    "phi_history = [phase.copy()]                    # List to store phase at each time step\n",
    "temp_init = temperature.copy()                 # Initial temperature of the rod\n",
    "# print(temperature_history,phi_history)\n",
    "# Array to store temperature at midpoint over time\n",
    "midpoint_index = num_points // 2                          # Index of the midpoint\n",
    "\n",
    "midpoint_temperature_history = [temperature[midpoint_index]]            # List to store temperature at midpoint over time\n",
    "dm = 60.0e-3                                                            # die thickness in m\n",
    "\n",
    "# r_m =  (k_mo / dm) + (1/htc)\n",
    "\n",
    "t_surr = 500.0                                        # Surrounding temperature in K\n",
    "# t_surr = h()\n",
    "\n",
    "def kramp(temp,v1,v2,T_L,T_s):                                      # Function to calculate thermal conductivity in Mushy Zone\n",
    "        slope = (v1-v2)/(T_L-T_S)\n",
    "        if temp > T_L:\n",
    "            k_m = k_l\n",
    "        elif temp < T_S:\n",
    "            k_m = k_s\n",
    "        else:\n",
    "            k_m = k_s + slope*(temp-T_S)\n",
    "        return k_m\n",
    "\n",
    "def cp_ramp(temp,v1,v2,T_L,T_s):                                    # Function to calculate specific heat capacity in Mushy Zone\n",
    "    slope = (v1-v2)/(T_L-T_S)\n",
    "    if temp > T_L:\n",
    "        cp_m = cp_l\n",
    "    elif temp < T_S:\n",
    "        cp_m = cp_s\n",
    "    else:\n",
    "        cp_m = cp_s + slope*(temp-T_S)\n",
    "    return cp_m\n",
    "\n",
    "def rho_ramp(temp,v1,v2,T_L,T_s):                                       # Function to calculate density in Mushy Zone\n",
    "    slope = (v1-v2)/(T_L-T_S)\n",
    "    if temp > T_L:\n",
    "        rho_m = rho_l\n",
    "    elif temp < T_S:\n",
    "        rho_m = rho_s\n",
    "    else:\n",
    "        rho_m = rho_s + slope*(temp-T_S)\n",
    "    return rho_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the HT equation and phase change numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for m in range(1, num_steps+1):                                                                            # time loop\n",
    "    htc = 10.0                   # htc of Still air in W/m^2-K\n",
    "    q1 = htc*(temp_init[0]-t_surr)   # Heat flux at the left boundary\n",
    "    \n",
    "    # print(f\"q1 is {q1}\")\n",
    "    temperature[0] = temp_init[0] + alpha_l * step_coeff * ((2.0*temp_init[1]) - (2.0 * temp_init[0])-(2.0*dx*(q1)))  # Update boundary condition temperature\n",
    "    \n",
    "    q2 = htc*(temp_init[-1]-t_surr)                   # Heat flux at the right boundary\n",
    "    temperature[-1] = temp_init[-1] + alpha_l * step_coeff * ((2.0*temp_init[-2]) - (2.0 * temp_init[-1])-(2.0*dx*(q2)))  # Update boundary condition temperature\n",
    "    \n",
    "    for n in range(1,num_points+1):              # space loop, adjusted range\n",
    "       \n",
    "        if temperature[n] >= T_L:\n",
    "            temperature[n] += ((alpha_l * step_coeff) * (temp_init[n+1] - (2.0 * temp_init[n]) + temp_init[n-1]))\n",
    "            phase[n] = 0\n",
    "            \n",
    "            # print(f\" Time-Step{m},Spatial point{n},Temperature{temperature[n]}\")\n",
    "        elif T_S < temperature[n] < T_L:\n",
    "            \n",
    "            k_m = kramp(temperature[n],k_l,k_s,T_L,T_S)\n",
    "            cp_m = cp_ramp(temperature[n],cp_l,cp_s,T_L,T_S)\n",
    "            rho_m = rho_ramp(temperature[n],rho_l,rho_s,T_L,T_S)\n",
    "            m_eff =(k_m/(rho_m*(cp_m + (L_fusion/(T_L-T_S)))))\n",
    "            \n",
    "            temperature[n] += ((m_eff * step_coeff)* (temp_init[n+1] - (2.0 * temp_init[n]) + temp_init[n-1]))\n",
    "            \n",
    "            phase[n] = (T_L - temperature[n]) / (T_L - T_S)\n",
    "            # print(m,n,temperature[n],phase[n])\n",
    "         \n",
    "        elif temperature[n]<T_S:\n",
    "            temperature[n] += ((alpha_s * step_coeff) * (temp_init[n+1] - (2.0 * temp_init[n])+ temp_init[n-1]))\n",
    "            phase[n] = 1\n",
    "                     \n",
    "        else:\n",
    "            print(\"ERROR: should not be here\")\n",
    "\n",
    "     \n",
    "          \n",
    "    temperature = temperature.copy()                                                                # Update temperature\n",
    "    phase = phase.copy()                                                                            # Update phase\n",
    "    temp_init = temperature.copy()                                                                  # Update last time step temperature\n",
    "    temperature_history.append(temperature.copy())                                                  # Append the temperature history to add ghost points\n",
    "    phi_history.append(phase.copy())                                                                # Append the phase history to add ghost points\n",
    "    midpoint_temperature_history.append(temperature[midpoint_index])                                # Store midpoint temperature\n",
    "    \n",
    "    \n",
    "    # print(f\"Step {m}, Temperature: {temperature}\")\n",
    "    \n",
    "\n",
    "\n",
    "# print(midpoint_temperature_history)\n",
    "#print(phi_history)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot temperature history for debugging\n",
    "# temperature_history_1 = np.array(temperature_history)\n",
    "# print(temperature_history_1.shape)\n",
    "# time_ss= np.linspace(0, time_end, num_steps+1)\n",
    "# # print(time_ss.shape)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(time_ss, midpoint_temperature_history, label='Midpoint Temperature')\n",
    "# plt.axhline(y=T_L, color='r', linestyle='--', label='Liquidus Temperature')\n",
    "# plt.axhline(y=T_S, color='g', linestyle='--', label='Solidus Temperature')\n",
    "# plt.xlabel('Time(s)')\n",
    "# plt.ylabel('Temperature (K)')\n",
    "# plt.title('Temperature Distribution Over Time at x = 7.5mm') \n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data into Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_history = np.array(temperature_history)\n",
    "\n",
    "phi_history = np.array(phi_history)\n",
    "\n",
    "t_hist = np.array(temperature_history[:,1:-1])\n",
    "p_hist = np.array(phi_history[:,1:-1])\n",
    "\n",
    "t_hist_init = t_hist[0,:]\n",
    "t_hist_bc_l = t_hist[:,0]\n",
    "t_hist_bc_r = t_hist[:,-1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have temperature_history and phi_history as lists of arrays\n",
    "\n",
    "\n",
    "# # Check the new shape after transposing\n",
    "# print(\"Transposed Temperature History Shape:\", temperature_history.shape)\n",
    "# print(\"Transposed Phi History Shape:\", phi_history.shape)\n",
    "\n",
    "# # Create a meshgrid for space and time coordinates\n",
    "# space_coord, time_coord = np.meshgrid(np.arange(temperature_history.shape[1]), np.arange(temperature_history.shape[0]))\n",
    "\n",
    "# time_coord = time_coord * dt \n",
    "# # Create a figure with two subplots\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# # Plot the temperature history on the left subplot\n",
    "# im1 = ax1.pcolormesh(space_coord, time_coord, temperature_history, cmap='viridis')\n",
    "# ax1.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=16)\n",
    "# ax1.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "# ax1.set_title('Temperature Variation Over Time',fontname='Times New Roman', fontsize=20)\n",
    "# fig.colorbar(im1, ax=ax1, label='Temperature')\n",
    "\n",
    "# # Plot the phase history on the right subplot\n",
    "# im2 = ax2.pcolormesh(space_coord, time_coord, phi_history, cmap='viridis')\n",
    "# ax2.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=18)\n",
    "# ax2.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "# ax2.set_title('Phase Variation Over Time',fontname='Times New Roman', fontsize=20)\n",
    "# fig.colorbar(im2, ax=ax2, label='Phase')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# #plot the main\n",
    "# fig, ax = plt.subplots(figsize=(14, 6))\n",
    "# im = ax.pcolormesh(space_coord, time_coord, Dim_ny, cmap='viridis')\n",
    "# ax.set_xlabel('Space Coordinate')\n",
    "# ax.set_ylabel('Time')\n",
    "# ax.set_title('Niyama Variation Over Time')\n",
    "# fig.colorbar(im, ax=ax, label='Main')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU/CPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check for gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (31470,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "space = np.linspace(0, length, num_points) # Spatial points\n",
    "time = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "print(space.shape,time.shape)\n",
    "\n",
    "sp_i = np.linspace(0, length, num_points) # Spatial points\n",
    "time_i = np.zeros(num_points) # Time points\n",
    "\n",
    "sp_b_l = np.zeros(num_steps+1) # Spatial points\n",
    "time_b_l = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "\n",
    "sp_b_r = np.ones(num_steps+1)*length # Spatial points\n",
    "time_b_r = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = input_gen(space,time,'mgrid')\n",
    "inputs_i = input_gen(sp_i,time_i,'scr')\n",
    "inputs_b_l = input_gen(sp_b_l,time_b_l,'scr')\n",
    "inputs_b_r = input_gen(sp_b_r,time_b_r,'scr')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1573500, 2) (50, 2) (31470, 2) (31470, 2)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape,inputs_i.shape,inputs_b_l.shape,inputs_b_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2])\n",
      "torch.Size([1573500, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "inputs = torch.tensor(inputs).float().to(device) # Convert the inputs to a tensor\n",
    "\n",
    "\n",
    "inputs_init = torch.tensor(inputs_i).float().to(device) # Convert the inputs to a tensor\n",
    "inputs_b_l = torch.tensor(inputs_b_l).float().to(device) # Convert the inputs to a tensor\n",
    "inputs_b_r = torch.tensor(inputs_b_r).float().to(device) # Convert the inputs to a tensor\n",
    "\n",
    "print(inputs_init.shape)\n",
    "# label/temp data\n",
    "temp_tr = torch.tensor(t_hist).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp = temp_tr.reshape(-1,1) # Reshape the temperature tensor to a column vector\n",
    "temp_inp_init = torch.tensor(t_hist_init).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp_bc_l = torch.tensor(t_hist_bc_l).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp_bc_r = torch.tensor(t_hist_bc_r).float().to(device) # Convert the temperature history to a tensor\n",
    "print(temp_inp.shape)\n",
    "\n",
    "\n",
    "\n",
    "#Data Splitting\n",
    "\n",
    "# train_inputs, val_test_inputs, train_temp_inp, val_test_temp_inp = train_test_split(inputs, temp_inp, test_size=0.2, random_state=42)\n",
    "# val_inputs, test_inputs, val_temp_inp, test_temp_inp = train_test_split(val_test_inputs, val_test_temp_inp, test_size=0.8, random_state=42)\n",
    "\n",
    "train_inputs, test_inputs, train_temp_inp, test_temp_inp = train_test_split(inputs, temp_inp, test_size=0.2, random_state=42)\n",
    "train_inputs_init, test_inputs_init, train_temp_inp_init, test_temp_inp_init = train_test_split(inputs_init, temp_inp_init, test_size=0.2, random_state=42)\n",
    "train_inputs_bc_l, test_inputs_bc_l, train_temp_inp_bc_l, test_temp_inp_bc_l = train_test_split(inputs_b_l, temp_inp_bc_l, test_size=0.2, random_state=42)\n",
    "train_inputs_bc_r, test_inputs_bc_r, train_temp_inp_bc_r, test_temp_inp_bc_r = train_test_split(inputs_b_r, temp_inp_bc_r, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, temp_inp,transform=None, target_transform =None):\n",
    "        self.inputs = inputs\n",
    "        self.temp_inp = temp_inp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.temp_inp[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "  \n",
    "train_dataset = TensorDataset(train_inputs, train_temp_inp) # Create the training dataset\n",
    "# val_dataset = TensorDataset(val_inputs, val_temp_inp) # Create the validation dataset\n",
    "test_dataset = TensorDataset(test_inputs, test_temp_inp) # Create the test dataset\n",
    "\n",
    "train_dataset_init = TensorDataset(train_inputs_init, train_temp_inp_init) # Create the training dataset\n",
    "test_dataset_init = TensorDataset(test_inputs_init, test_temp_inp_init) # Create the test dataset\n",
    "train_dataset_bc_l = TensorDataset(train_inputs_bc_l, train_temp_inp_bc_l) # Create the training dataset\n",
    "test_dataset_bc_l = TensorDataset(test_inputs_bc_l, test_temp_inp_bc_l) # Create the test dataset\n",
    "train_dataset_bc_r = TensorDataset(train_inputs_bc_r, train_temp_inp_bc_r) # Create the training dataset\n",
    "test_dataset_bc_r = TensorDataset(test_inputs_bc_r, test_temp_inp_bc_r) # Create the test dataset\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "random_sampler_train = RandomSampler(train_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "# random_sampler_val = RandomSampler(val_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the validation dataset\n",
    "random_sampler_test = RandomSampler(test_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "\n",
    "random_sampler_train_init = RandomSampler(train_dataset_init, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_init = RandomSampler(test_dataset_init, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "random_sampler_train_bc_l = RandomSampler(train_dataset_bc_l, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_bc_l = RandomSampler(test_dataset_bc_l, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "random_sampler_train_bc_r = RandomSampler(train_dataset_bc_r, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_bc_r = RandomSampler(test_dataset_bc_r, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=random_sampler_train) # Create the training dataloader\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=random_sampler_val) # Create the validation dataloader\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, sampler=random_sampler_test) # Create the test dataloader\n",
    "\n",
    "train_loader_init = DataLoader(train_dataset_init, batch_size=batch_size, sampler=random_sampler_train_init) # Create the training dataloader\n",
    "test_loader_init = DataLoader(test_dataset_init, batch_size=batch_size, sampler=random_sampler_test_init) # Create the test dataloader\n",
    "train_loader_bc_l = DataLoader(train_dataset_bc_l, batch_size=batch_size, sampler=random_sampler_train_bc_l) # Create the training dataloader\n",
    "test_loader_bc_l = DataLoader(test_dataset_bc_l, batch_size=batch_size, sampler=random_sampler_test_bc_l) # Create the test dataloader\n",
    "train_loader_bc_r = DataLoader(train_dataset_bc_r, batch_size=batch_size, sampler=random_sampler_train_bc_r) # Create the training dataloader\n",
    "test_loader_bc_r = DataLoader(test_dataset_bc_r, batch_size=batch_size, sampler=random_sampler_test_bc_r) # Create the test dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the neural network architecture\n",
    "class Mushydata(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size): # This is the constructor\n",
    "        super(Mushydata, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t):                               # This is the forward pass\n",
    "        input_features = torch.cat([x, t], dim=1)          # Concatenate the input features\n",
    "        m = self.base(input_features)                                 # Pass through the third layer\n",
    "        return m                    # Return the output of the network\n",
    "\n",
    "\n",
    "# features = torch.rand(1, 2)\n",
    "# model = HeatPINN(2, 20, 1)\n",
    "# output = model(features[:, 0:1], features[:, 1:2])\n",
    "# print(output)\n",
    "\n",
    "\n",
    "# Loss function for data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamters Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 40\n",
    "learning_rate = 0.004\n",
    "epochs = 30000\n",
    "# alpha = 0.01  # Adjust this value based on your problem\n",
    "# boundary_value = 313.0\n",
    "# initial_value = init_temp\n",
    "# Initialize the model\n",
    "model = Mushydata(input_size=2, hidden_size=hidden_size,output_size=1).to(device)\n",
    "lambd = 0.1\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss List Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of train_loader is <class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(f\"Datatype of train_loader is {type(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_fn_data(u_pred, u_true):\n",
    "#     return nn.MSELoss()(u_pred, u_true)\n",
    "\n",
    "# def l1_regularization(model, lambd):\n",
    "#     l1_reg = sum(param.abs().sum() for param in model.parameters())\n",
    "#     return l1_reg * lambd\n",
    "\n",
    "# def pde_loss(u_pred,x,t):\n",
    "#     # u_pred.requires_grad = True\n",
    "#     x.requires_grad = True\n",
    "#     t.requires_grad = True\n",
    "    \n",
    "#     u_pred = model(x,t).requires_grad_()\n",
    "#     u_t = torch.autograd.grad(u_pred, t, \n",
    "#                                 torch.ones_like(u_pred).to(device),\n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused=True,\n",
    "#                                 )[0] # Calculate the first time derivative\n",
    "#     if u_t is None:\n",
    "#         raise RuntimeError(\"u_t is None\")\n",
    "\n",
    "#     u_x = torch.autograd.grad(u_pred, \n",
    "#                                 x, \n",
    "#                                 torch.ones_like(u_pred).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused =True)[0] # Calculate the first space derivative\n",
    "            \n",
    "#     u_xx = torch.autograd.grad(u_x, \n",
    "#                                 x, \n",
    "#                                 torch.ones_like(u_x).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused=True)[0] \n",
    "    \n",
    "#     T_S_tensor = torch.tensor(T_S, device=device)\n",
    "#     T_L_tensor = torch.tensor(T_L, device=device)\n",
    "    \n",
    "#     k_m = torch.where((u_pred >= T_S_tensor) * (u_pred <= T_L_tensor),\\\n",
    "#                        kramp(u_pred, k_l,k_s,T_L,T_S),torch.tensor(0.0,device=device))\n",
    "#     cp_m = torch.where(u_pred >= T_S_tensor * u_pred <= T_L_tensor, cp_ramp((u_pred), cp_l,cp_s,T_L,T_S))\n",
    "#     rho_m = torch.where(u_pred >= T_S_tensor * u_pred <= T_L_tensor, rho_ramp((u_pred), rho_l,rho_s,T_L,T_S))\n",
    "#     m_eff = (k_m / (rho_m * (cp_m + (L_fusion / (T_L - T_S)))))\n",
    "\n",
    "#     alpha_T = torch.where(u_pred >= T_L_tensor, alpha_l, torch.where(u_pred<=T_S_tensor,alpha_s ,m_eff))\n",
    "#     alpha_T = 1\n",
    "#     residual = u_t - alpha_T * u_xx\n",
    "\n",
    "#     return nn.MSELoss()(residual,torch.zeros_like(residual))\n",
    "\n",
    "# def boundary_loss(u_pred,x,t,t_surr):\n",
    "    \n",
    "#     u_x = torch.autograd.grad(u_pred,x, \n",
    "#                                 torch.ones_like(u_pred).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused =True)[0] # Calculate the first space derivative\n",
    "#     t_surr_t = torch.tensor(t_surr, device=device)\n",
    "#     res_l = u_x -(htc* (u_pred-t_surr_t))\n",
    "   \n",
    "\n",
    "#     return nn.MSELoss()(res_l,torch.zeros_like(res_l))\n",
    "\n",
    "# def ic_loss(u_pred):\n",
    "#     temp_init_tsr = torch.tensor(temp_init[1:-1],device=device)\n",
    "#     ic = u_pred -temp_init_tsr\n",
    "#     return nn.MSELoss()(ic,torch.zeros_like(ic))\n",
    "\n",
    "def accuracy(u_pred, u_true):\n",
    "    return torch.mean(torch.abs(u_pred - u_true) / u_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation and Testing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, model, loss_fn_data, optimizer, train_dataloader,):\n",
    "    train_losses = []  # Initialize the list to store the training losses\n",
    "    val_losses = []    # Initialize the list to store the validation losses\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()                                                                           # Set the model to training mode\n",
    "        train_loss = 0                                                                              # Initialize the training loss\n",
    "        train_accuracy = 0\n",
    "        for (batch,batch_init,batch_left,batch_right) in \\\n",
    "             zip (train_dataloader,train_loader_init,train_loader_bc_l,train_inputs_bc_r):                                                          # Loop through the training dataloader\n",
    "            inputs, temp_inp= batch                                                             # Get the inputs and the true values\n",
    "            inputs_init, temp_inp_init= batch_init                                                             # Get the inputs and the true values \n",
    "            inputs_left, temp_inp_left= batch_left                                                             # Get the inputs and the true values\n",
    "            inputs_right, temp_inp_right= batch_right                                                             # Get the inputs and the true values\n",
    "\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)                             # Move the inputs and true values to the GPU\n",
    "            inputs_init, temp_inp_init= inputs_init.to(device), temp_inp_init.to(device)                             # Move the initial condition inputs and temperature to the GPU\n",
    "            inputs_left, temp_inp_left= inputs_left.to(device), temp_inp_left.to(device)                             # Move the left boundary condition inputs and temperature values to the GPU\n",
    "            inputs_right, temp_inp_right= inputs_right.to(device), temp_inp_right.to(device)                             # Move the right boundary condition inputs and temperature values to the GPU\n",
    "\n",
    "            optimizer.zero_grad()                                                                    # Zero the gradients\n",
    "            \n",
    "            # Forward pass\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).to(device)                       # Get the predictions\n",
    "            u_initl = model(inputs_init[:,0].unsqueeze(1), inputs_init[:,1].unsqueeze(1)).to(device)                       # Get the predictions\n",
    "            \n",
    "            u_left = model(inputs_b_l[:,0].unsqueeze(1), inputs_b_l[:,1].unsqueeze(1)).to(device)               # Left boundary of the temperature\n",
    "            u_right = model(inputs_b_r[:,0].unsqueeze(1), inputs_b_r[:,1].unsqueeze(1)).to(device)             # Right boundary of the temperature\n",
    "\n",
    "            # Loss calculation\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp)                                              # Calculate the data loss\n",
    "            \n",
    "            pd_loss = pde_loss(model,inputs[:,0].unsqueeze(1),inputs[:,1].unsqueeze(1))             # Calculate the PDE loss\n",
    "            # pd_loss = 0\n",
    "            \n",
    "            initc_loss = ic_loss(u_initl) \n",
    "            # initc_loss =0                                                      # Calculate initial condition loss\n",
    "            \n",
    "            bc_loss_left = boundary_loss(model,inputs_b_l[:,0].unsqueeze(1),inputs_b_l[:,1].unsqueeze(1),t_surr) # Calculate the left boundary condition loss\n",
    "            bc_loss_right = boundary_loss(model,inputs_b_r[:,0].unsqueeze(1),inputs_b_r[:,1].unsqueeze(1),t_surr) # Calculate the right boundary condition loss\n",
    "            bc_loss = bc_loss_left + bc_loss_right\n",
    "            # l1_regularization_loss = l1_regularization(model, lambda_l1)                      # Calculate the L1 regularization loss\n",
    "            # loss = data_loss  + pd_loss + initc_loss + bc_loss                                              # Calculate the total loss\n",
    "            w1 = 0.01\n",
    "            w2 = 0.01\n",
    "            w3 = 0.01\n",
    "            loss = data_loss + w1* pd_loss + w2 *initc_loss + w3* bc_loss\n",
    "            train_accuracy += accuracy(u_pred, temp_inp)                                                              # Calculate the total loss\n",
    "            # Backpropagation\n",
    "            loss.backward(retain_graph=True)                                                        # Backpropagate the gradients\n",
    "            \n",
    "            optimizer.step()                                                                           # Update the weights\n",
    "            \n",
    "            train_loss += loss.item()                                                           # Add the loss to the training set loss                 \n",
    "\n",
    "        \n",
    "\n",
    "        # model.eval()\n",
    "        # test_loss = 0\n",
    "        # test_accuracy = 0\n",
    "        # with torch.no_grad():   \n",
    "        #     for batch in test_dataloader:\n",
    "        #         inputs, temp_inp= batch\n",
    "        #         inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "        #         u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "        #         data_loss = loss_fn_data(u_pred, temp_inp)\n",
    "        #         # l1_regularization_loss = l1_regularization(model, lambd)\n",
    "        #         # loss = data_loss  + l1_regularization_loss\n",
    "        #         loss = data_loss\n",
    "        #         test_accuracy = accuracy(u_pred, temp_inp)\n",
    "        #         test_loss += loss.item()\n",
    "        #     test_losses.append(test_loss)\n",
    "\n",
    "        train_losses.append(train_loss)                                                   # Append the training loss to the list of training losses\n",
    "        \n",
    "        # if epoch % 10 == 0:\n",
    "        #     print(f\"Epoch {epoch}, Training-Loss {train_loss:.4e}\")\n",
    "        \n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Training-Loss {train_loss:.4e}, Data-loss {data_loss:.4e}\\\n",
    "                  , pde-loss {pd_loss:.4e}, initc-loss {initc_loss:.4e}\\\n",
    "                    bc_loss {bc_loss:.4e}\") \n",
    "\n",
    "    return train_losses, val_losses                                                             # Return the training and validation losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(epochs, model, loss_fn_data, optimizer, train_dataloader, test_dataloader):\n",
    "      \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    with torch.no_grad():   \n",
    "        for batch in test_dataloader:\n",
    "            inputs, temp_inp= batch\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp)\n",
    "            # l1_regularization_loss = l1_regularization(model, lambd)\n",
    "            # loss = data_loss  + l1_regularization_loss\n",
    "            loss = data_loss\n",
    "            test_accuracy = accuracy(u_pred, temp_inp)\n",
    "            test_loss += loss.item()\n",
    "        test_losses.append(test_loss)\n",
    "    if epochs % 10 == 0:\n",
    "        print(f\"Epoch {epochs}, Test-Loss {test_loss:.4e}, Test-Accuracy {test_accuracy:.4e}\")      \n",
    "    return test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Button "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training-Loss 1.1530e+06, Data-loss 6.4418e+05                  , pde-loss 6.8376e-04, initc-loss 8.4485e+05                    bc_loss 5.0033e+07\n",
      "Epoch 10, Training-Loss 1.1569e+06, Data-loss 6.5024e+05                  , pde-loss 1.1475e-01, initc-loss 8.4292e+05                    bc_loss 4.9827e+07\n",
      "Epoch 20, Training-Loss 1.1493e+06, Data-loss 6.5129e+05                  , pde-loss 3.6416e+00, initc-loss 8.3536e+05                    bc_loss 4.8961e+07\n",
      "Epoch 30, Training-Loss 1.0856e+06, Data-loss 6.1513e+05                  , pde-loss 5.7624e+01, initc-loss 8.0974e+05                    bc_loss 4.6241e+07\n",
      "Epoch 40, Training-Loss 9.6300e+05, Data-loss 5.6076e+05                  , pde-loss 4.2640e+02, initc-loss 7.4554e+05                    bc_loss 3.9478e+07\n",
      "Epoch 50, Training-Loss 6.7971e+05, Data-loss 4.1115e+05                  , pde-loss 2.4621e+03, initc-loss 6.1294e+05                    bc_loss 2.6241e+07\n",
      "Epoch 60, Training-Loss 2.9964e+05, Data-loss 2.0887e+05                  , pde-loss 1.2325e+04, initc-loss 3.9071e+05                    bc_loss 8.6746e+06\n",
      "Epoch 70, Training-Loss 7.8259e+04, Data-loss 4.2449e+04                  , pde-loss 4.1889e+04, initc-loss 1.4419e+05                    bc_loss 3.3949e+06\n",
      "Epoch 80, Training-Loss 1.0107e+05, Data-loss 2.3388e+04                  , pde-loss 4.5562e+04, initc-loss 8.4535e+04                    bc_loss 7.6381e+06\n",
      "Epoch 90, Training-Loss 6.1183e+04, Data-loss 3.3490e+04                  , pde-loss 2.9725e+04, initc-loss 1.2730e+05                    bc_loss 2.6123e+06\n",
      "Epoch 100, Training-Loss 5.7762e+04, Data-loss 3.9994e+04                  , pde-loss 2.0305e+04, initc-loss 1.3543e+05                    bc_loss 1.6211e+06\n",
      "Epoch 110, Training-Loss 5.3060e+04, Data-loss 3.2141e+04                  , pde-loss 1.7130e+04, initc-loss 1.1155e+05                    bc_loss 1.9632e+06\n",
      "Epoch 120, Training-Loss 4.9042e+04, Data-loss 2.7804e+04                  , pde-loss 1.5189e+04, initc-loss 8.3298e+04                    bc_loss 2.0254e+06\n",
      "Epoch 130, Training-Loss 4.6441e+04, Data-loss 3.0450e+04                  , pde-loss 1.1707e+04, initc-loss 9.5219e+04                    bc_loss 1.4921e+06\n",
      "Epoch 140, Training-Loss 4.6635e+04, Data-loss 3.3551e+04                  , pde-loss 8.9728e+03, initc-loss 9.9257e+04                    bc_loss 1.2002e+06\n",
      "Epoch 150, Training-Loss 4.6344e+04, Data-loss 3.3076e+04                  , pde-loss 8.9314e+03, initc-loss 8.1338e+04                    bc_loss 1.2366e+06\n",
      "Epoch 160, Training-Loss 4.7463e+04, Data-loss 3.4635e+04                  , pde-loss 9.0344e+03, initc-loss 7.5763e+04                    bc_loss 1.1979e+06\n",
      "Epoch 170, Training-Loss 3.5495e+04, Data-loss 2.4573e+04                  , pde-loss 6.3353e+03, initc-loss 8.2825e+04                    bc_loss 1.0030e+06\n",
      "Epoch 180, Training-Loss 3.7885e+04, Data-loss 2.8545e+04                  , pde-loss 8.4117e+03, initc-loss 7.5728e+04                    bc_loss 8.4983e+05\n",
      "Epoch 190, Training-Loss 3.9004e+04, Data-loss 3.0003e+04                  , pde-loss 5.8275e+03, initc-loss 7.5268e+04                    bc_loss 8.1901e+05\n",
      "Epoch 200, Training-Loss 4.0181e+04, Data-loss 3.1525e+04                  , pde-loss 5.8413e+03, initc-loss 7.6035e+04                    bc_loss 7.8372e+05\n",
      "Epoch 210, Training-Loss 3.6703e+04, Data-loss 2.7930e+04                  , pde-loss 5.5230e+03, initc-loss 6.6934e+04                    bc_loss 8.0487e+05\n",
      "Epoch 220, Training-Loss 3.5637e+04, Data-loss 2.7698e+04                  , pde-loss 4.1783e+03, initc-loss 7.2699e+04                    bc_loss 7.1706e+05\n",
      "Epoch 230, Training-Loss 3.0675e+04, Data-loss 2.3748e+04                  , pde-loss 4.2424e+03, initc-loss 7.2434e+04                    bc_loss 6.1603e+05\n",
      "Epoch 240, Training-Loss 3.4831e+04, Data-loss 2.8201e+04                  , pde-loss 3.6610e+03, initc-loss 7.8492e+04                    bc_loss 5.8088e+05\n",
      "Epoch 250, Training-Loss 3.5775e+04, Data-loss 2.8257e+04                  , pde-loss 4.0230e+03, initc-loss 6.7704e+04                    bc_loss 6.8006e+05\n",
      "Epoch 260, Training-Loss 3.7115e+04, Data-loss 3.0365e+04                  , pde-loss 4.4423e+03, initc-loss 7.2943e+04                    bc_loss 5.9764e+05\n",
      "Epoch 270, Training-Loss 3.5356e+04, Data-loss 2.8976e+04                  , pde-loss 3.9041e+03, initc-loss 5.4580e+04                    bc_loss 5.7955e+05\n",
      "Epoch 280, Training-Loss 3.3501e+04, Data-loss 2.7449e+04                  , pde-loss 3.9574e+03, initc-loss 6.6996e+04                    bc_loss 5.3426e+05\n",
      "Epoch 290, Training-Loss 2.9653e+04, Data-loss 2.2650e+04                  , pde-loss 3.1649e+03, initc-loss 5.7475e+04                    bc_loss 6.3971e+05\n",
      "Epoch 300, Training-Loss 2.7587e+04, Data-loss 2.2002e+04                  , pde-loss 3.8434e+03, initc-loss 6.3031e+04                    bc_loss 4.9172e+05\n",
      "Epoch 310, Training-Loss 3.0507e+04, Data-loss 2.4856e+04                  , pde-loss 3.4261e+03, initc-loss 6.0629e+04                    bc_loss 5.0103e+05\n",
      "Epoch 320, Training-Loss 2.8333e+04, Data-loss 2.2910e+04                  , pde-loss 3.2333e+03, initc-loss 5.7066e+04                    bc_loss 4.8197e+05\n",
      "Epoch 330, Training-Loss 3.3848e+04, Data-loss 2.8532e+04                  , pde-loss 3.3113e+03, initc-loss 6.4959e+04                    bc_loss 4.6330e+05\n",
      "Epoch 340, Training-Loss 3.1703e+04, Data-loss 2.6536e+04                  , pde-loss 2.9148e+03, initc-loss 5.0208e+04                    bc_loss 4.6357e+05\n",
      "Epoch 350, Training-Loss 3.3467e+04, Data-loss 2.8477e+04                  , pde-loss 2.2513e+03, initc-loss 5.6806e+04                    bc_loss 4.3988e+05\n",
      "Epoch 360, Training-Loss 2.6602e+04, Data-loss 2.1574e+04                  , pde-loss 2.3961e+03, initc-loss 5.4295e+04                    bc_loss 4.4610e+05\n",
      "Epoch 370, Training-Loss 2.9670e+04, Data-loss 2.5163e+04                  , pde-loss 2.1300e+03, initc-loss 4.3731e+04                    bc_loss 4.0485e+05\n",
      "Epoch 380, Training-Loss 2.5441e+04, Data-loss 2.0896e+04                  , pde-loss 2.3301e+03, initc-loss 5.7966e+04                    bc_loss 3.9417e+05\n",
      "Epoch 390, Training-Loss 3.2235e+04, Data-loss 2.7266e+04                  , pde-loss 1.9488e+03, initc-loss 5.4504e+04                    bc_loss 4.4048e+05\n",
      "Epoch 400, Training-Loss 3.1629e+04, Data-loss 2.6109e+04                  , pde-loss 1.8593e+03, initc-loss 5.1231e+04                    bc_loss 4.9891e+05\n",
      "Epoch 410, Training-Loss 2.4611e+04, Data-loss 2.1239e+04                  , pde-loss 2.0607e+03, initc-loss 5.5057e+04                    bc_loss 2.8003e+05\n",
      "Epoch 420, Training-Loss 2.7742e+04, Data-loss 2.3059e+04                  , pde-loss 2.0792e+03, initc-loss 5.0837e+04                    bc_loss 4.1537e+05\n",
      "Epoch 430, Training-Loss 2.6901e+04, Data-loss 2.2451e+04                  , pde-loss 1.7470e+03, initc-loss 5.7281e+04                    bc_loss 3.8600e+05\n",
      "Epoch 440, Training-Loss 2.8484e+04, Data-loss 2.4812e+04                  , pde-loss 2.1943e+03, initc-loss 4.8939e+04                    bc_loss 3.1608e+05\n",
      "Epoch 450, Training-Loss 3.0512e+04, Data-loss 2.4578e+04                  , pde-loss 1.7569e+03, initc-loss 4.5824e+04                    bc_loss 5.4587e+05\n",
      "Epoch 460, Training-Loss 2.5605e+04, Data-loss 1.9792e+04                  , pde-loss 1.5048e+03, initc-loss 4.5788e+04                    bc_loss 5.3397e+05\n",
      "Epoch 470, Training-Loss 2.7857e+04, Data-loss 2.3574e+04                  , pde-loss 1.0557e+03, initc-loss 4.9549e+04                    bc_loss 3.7765e+05\n",
      "Epoch 480, Training-Loss 2.8448e+04, Data-loss 2.3758e+04                  , pde-loss 1.5589e+03, initc-loss 5.1887e+04                    bc_loss 4.1559e+05\n",
      "Epoch 490, Training-Loss 2.4634e+04, Data-loss 2.0336e+04                  , pde-loss 1.8329e+03, initc-loss 5.2452e+04                    bc_loss 3.7550e+05\n",
      "Epoch 500, Training-Loss 2.5161e+04, Data-loss 2.1482e+04                  , pde-loss 1.3374e+03, initc-loss 4.7942e+04                    bc_loss 3.1857e+05\n",
      "Epoch 510, Training-Loss 2.4891e+04, Data-loss 2.0428e+04                  , pde-loss 1.6407e+03, initc-loss 4.8230e+04                    bc_loss 3.9646e+05\n",
      "Epoch 520, Training-Loss 2.5649e+04, Data-loss 2.2441e+04                  , pde-loss 1.6364e+03, initc-loss 4.7700e+04                    bc_loss 2.7147e+05\n",
      "Epoch 530, Training-Loss 2.5449e+04, Data-loss 2.1189e+04                  , pde-loss 1.4516e+03, initc-loss 3.8818e+04                    bc_loss 3.8579e+05\n",
      "Epoch 540, Training-Loss 2.2371e+04, Data-loss 1.8460e+04                  , pde-loss 1.2369e+03, initc-loss 4.7226e+04                    bc_loss 3.4267e+05\n",
      "Epoch 550, Training-Loss 2.8032e+04, Data-loss 2.4130e+04                  , pde-loss 1.7648e+03, initc-loss 4.4505e+04                    bc_loss 3.4385e+05\n",
      "Epoch 560, Training-Loss 2.0609e+04, Data-loss 1.8635e+04                  , pde-loss 1.4074e+03, initc-loss 4.3819e+04                    bc_loss 1.5222e+05\n",
      "Epoch 570, Training-Loss 2.4578e+04, Data-loss 2.0631e+04                  , pde-loss 8.4265e+02, initc-loss 4.0148e+04                    bc_loss 3.5375e+05\n",
      "Epoch 580, Training-Loss 2.4677e+04, Data-loss 2.1532e+04                  , pde-loss 1.3429e+03, initc-loss 4.7614e+04                    bc_loss 2.6550e+05\n",
      "Epoch 590, Training-Loss 2.0571e+04, Data-loss 1.7346e+04                  , pde-loss 1.1899e+03, initc-loss 4.7600e+04                    bc_loss 2.7371e+05\n",
      "Epoch 600, Training-Loss 2.2043e+04, Data-loss 1.7640e+04                  , pde-loss 1.6200e+03, initc-loss 4.4247e+04                    bc_loss 3.9443e+05\n",
      "Epoch 610, Training-Loss 2.2431e+04, Data-loss 1.9748e+04                  , pde-loss 1.0401e+03, initc-loss 4.6398e+04                    bc_loss 2.2087e+05\n",
      "Epoch 620, Training-Loss 2.4533e+04, Data-loss 1.9364e+04                  , pde-loss 1.3992e+03, initc-loss 3.7014e+04                    bc_loss 4.7856e+05\n",
      "Epoch 630, Training-Loss 2.0162e+04, Data-loss 1.7462e+04                  , pde-loss 1.4769e+03, initc-loss 4.9321e+04                    bc_loss 2.1925e+05\n",
      "Epoch 640, Training-Loss 2.2887e+04, Data-loss 1.8773e+04                  , pde-loss 1.2516e+03, initc-loss 4.0109e+04                    bc_loss 3.7004e+05\n",
      "Epoch 650, Training-Loss 2.6842e+04, Data-loss 2.3132e+04                  , pde-loss 6.7990e+02, initc-loss 3.9669e+04                    bc_loss 3.3065e+05\n",
      "Epoch 660, Training-Loss 2.2305e+04, Data-loss 1.8967e+04                  , pde-loss 1.2317e+03, initc-loss 4.3310e+04                    bc_loss 2.8933e+05\n",
      "Epoch 670, Training-Loss 2.7841e+04, Data-loss 2.5480e+04                  , pde-loss 1.3139e+03, initc-loss 4.4753e+04                    bc_loss 1.9003e+05\n",
      "Epoch 680, Training-Loss 2.0003e+04, Data-loss 1.6721e+04                  , pde-loss 1.4815e+03, initc-loss 3.2928e+04                    bc_loss 2.9380e+05\n",
      "Epoch 690, Training-Loss 2.1595e+04, Data-loss 1.8611e+04                  , pde-loss 1.1813e+03, initc-loss 3.8767e+04                    bc_loss 2.5846e+05\n",
      "Epoch 700, Training-Loss 2.1006e+04, Data-loss 1.6750e+04                  , pde-loss 1.0765e+03, initc-loss 4.1592e+04                    bc_loss 3.8294e+05\n",
      "Epoch 710, Training-Loss 2.2928e+04, Data-loss 1.7156e+04                  , pde-loss 1.2712e+03, initc-loss 4.3036e+04                    bc_loss 5.3296e+05\n",
      "Epoch 720, Training-Loss 2.1203e+04, Data-loss 1.9339e+04                  , pde-loss 1.5117e+03, initc-loss 4.5681e+04                    bc_loss 1.3917e+05\n",
      "Epoch 730, Training-Loss 2.1245e+04, Data-loss 1.6556e+04                  , pde-loss 1.3860e+03, initc-loss 3.0650e+04                    bc_loss 4.3681e+05\n",
      "Epoch 740, Training-Loss 1.9255e+04, Data-loss 1.6701e+04                  , pde-loss 1.2127e+03, initc-loss 3.9085e+04                    bc_loss 2.1511e+05\n",
      "Epoch 750, Training-Loss 1.4293e+04, Data-loss 1.3211e+04                  , pde-loss 1.4093e+03, initc-loss 3.7879e+04                    bc_loss 6.8971e+04\n",
      "Epoch 760, Training-Loss 2.2336e+04, Data-loss 1.8047e+04                  , pde-loss 9.5721e+02, initc-loss 3.4847e+04                    bc_loss 3.9311e+05\n",
      "Epoch 770, Training-Loss 1.9435e+04, Data-loss 1.7217e+04                  , pde-loss 9.6944e+02, initc-loss 4.1568e+04                    bc_loss 1.7926e+05\n",
      "Epoch 780, Training-Loss 2.0146e+04, Data-loss 1.5608e+04                  , pde-loss 1.3203e+03, initc-loss 4.1532e+04                    bc_loss 4.1091e+05\n",
      "Epoch 790, Training-Loss 2.2369e+04, Data-loss 1.9820e+04                  , pde-loss 1.3224e+03, initc-loss 4.1627e+04                    bc_loss 2.1194e+05\n",
      "Epoch 800, Training-Loss 1.8217e+04, Data-loss 1.4316e+04                  , pde-loss 1.6171e+03, initc-loss 3.3291e+04                    bc_loss 3.5523e+05\n",
      "Epoch 810, Training-Loss 2.0320e+04, Data-loss 1.6872e+04                  , pde-loss 1.2741e+03, initc-loss 4.1423e+04                    bc_loss 3.0209e+05\n",
      "Epoch 820, Training-Loss 2.2386e+04, Data-loss 1.9232e+04                  , pde-loss 9.3095e+02, initc-loss 3.5796e+04                    bc_loss 2.7862e+05\n",
      "Epoch 830, Training-Loss 2.2692e+04, Data-loss 2.0347e+04                  , pde-loss 1.3398e+03, initc-loss 4.3264e+04                    bc_loss 1.8996e+05\n",
      "Epoch 840, Training-Loss 1.8556e+04, Data-loss 1.5802e+04                  , pde-loss 1.0496e+03, initc-loss 3.9839e+04                    bc_loss 2.3452e+05\n",
      "Epoch 850, Training-Loss 2.0956e+04, Data-loss 1.8492e+04                  , pde-loss 1.5488e+03, initc-loss 3.4468e+04                    bc_loss 2.1043e+05\n",
      "Epoch 860, Training-Loss 1.5571e+04, Data-loss 1.1645e+04                  , pde-loss 1.3600e+03, initc-loss 2.2056e+04                    bc_loss 3.6916e+05\n",
      "Epoch 870, Training-Loss 1.9540e+04, Data-loss 1.6572e+04                  , pde-loss 1.0061e+03, initc-loss 4.1733e+04                    bc_loss 2.5410e+05\n",
      "Epoch 880, Training-Loss 1.5132e+04, Data-loss 1.2954e+04                  , pde-loss 1.9973e+03, initc-loss 3.9403e+04                    bc_loss 1.7641e+05\n",
      "Epoch 890, Training-Loss 1.7434e+04, Data-loss 1.4439e+04                  , pde-loss 1.2565e+03, initc-loss 3.1664e+04                    bc_loss 2.6665e+05\n",
      "Epoch 900, Training-Loss 1.6417e+04, Data-loss 1.4779e+04                  , pde-loss 1.1485e+03, initc-loss 3.1443e+04                    bc_loss 1.3120e+05\n",
      "Epoch 910, Training-Loss 1.7189e+04, Data-loss 1.5118e+04                  , pde-loss 1.7930e+03, initc-loss 3.6228e+04                    bc_loss 1.6905e+05\n",
      "Epoch 920, Training-Loss 1.6103e+04, Data-loss 1.4247e+04                  , pde-loss 1.8783e+03, initc-loss 3.0954e+04                    bc_loss 1.5278e+05\n",
      "Epoch 930, Training-Loss 1.6306e+04, Data-loss 1.2997e+04                  , pde-loss 1.4009e+03, initc-loss 3.2032e+04                    bc_loss 2.9751e+05\n",
      "Epoch 940, Training-Loss 1.6698e+04, Data-loss 1.5051e+04                  , pde-loss 1.8186e+03, initc-loss 4.3737e+04                    bc_loss 1.1912e+05\n",
      "Epoch 950, Training-Loss 1.6082e+04, Data-loss 1.1629e+04                  , pde-loss 2.2644e+03, initc-loss 2.8232e+04                    bc_loss 4.1478e+05\n",
      "Epoch 960, Training-Loss 1.5592e+04, Data-loss 1.4725e+04                  , pde-loss 7.9694e+02, initc-loss 3.1466e+04                    bc_loss 5.4369e+04\n",
      "Epoch 970, Training-Loss 1.2754e+04, Data-loss 9.0130e+03                  , pde-loss 2.0411e+03, initc-loss 2.6788e+04                    bc_loss 3.4531e+05\n",
      "Epoch 980, Training-Loss 1.5879e+04, Data-loss 1.4282e+04                  , pde-loss 2.6430e+03, initc-loss 3.3325e+04                    bc_loss 1.2375e+05\n",
      "Epoch 990, Training-Loss 1.2525e+04, Data-loss 1.1901e+04                  , pde-loss 1.2288e+03, initc-loss 3.1411e+04                    bc_loss 2.9775e+04\n",
      "Epoch 1000, Training-Loss 9.9107e+03, Data-loss 7.2756e+03                  , pde-loss 1.6398e+03, initc-loss 2.5273e+04                    bc_loss 2.3660e+05\n",
      "Epoch 1010, Training-Loss 1.0540e+04, Data-loss 8.1282e+03                  , pde-loss 1.7567e+03, initc-loss 2.9679e+04                    bc_loss 2.0973e+05\n",
      "Epoch 1020, Training-Loss 2.1973e+04, Data-loss 1.8239e+04                  , pde-loss 1.7015e+03, initc-loss 3.9582e+04                    bc_loss 3.3214e+05\n",
      "Epoch 1030, Training-Loss 1.2635e+04, Data-loss 1.0740e+04                  , pde-loss 3.4070e+03, initc-loss 2.3283e+04                    bc_loss 1.6280e+05\n",
      "Epoch 1040, Training-Loss 1.2285e+04, Data-loss 9.7047e+03                  , pde-loss 1.3946e+03, initc-loss 3.1790e+04                    bc_loss 2.2483e+05\n",
      "Epoch 1050, Training-Loss 1.4375e+04, Data-loss 1.1155e+04                  , pde-loss 1.1221e+03, initc-loss 2.5538e+04                    bc_loss 2.9527e+05\n",
      "Epoch 1060, Training-Loss 9.6538e+03, Data-loss 8.8320e+03                  , pde-loss 3.2528e+03, initc-loss 2.9133e+04                    bc_loss 4.9789e+04\n",
      "Epoch 1070, Training-Loss 9.8728e+03, Data-loss 7.2507e+03                  , pde-loss 2.8117e+03, initc-loss 2.7502e+04                    bc_loss 2.3189e+05\n",
      "Epoch 1080, Training-Loss 1.1616e+04, Data-loss 1.0288e+04                  , pde-loss 1.3791e+03, initc-loss 2.5474e+04                    bc_loss 1.0593e+05\n",
      "Epoch 1090, Training-Loss 1.0550e+04, Data-loss 7.5391e+03                  , pde-loss 3.8153e+03, initc-loss 3.0615e+04                    bc_loss 2.6667e+05\n",
      "Epoch 1100, Training-Loss 1.0658e+04, Data-loss 8.9679e+03                  , pde-loss 3.8685e+03, initc-loss 2.3521e+04                    bc_loss 1.4158e+05\n",
      "Epoch 1110, Training-Loss 1.3129e+04, Data-loss 1.2377e+04                  , pde-loss 1.3201e+03, initc-loss 2.2807e+04                    bc_loss 5.1021e+04\n",
      "Epoch 1120, Training-Loss 8.2809e+03, Data-loss 7.6179e+03                  , pde-loss 2.5369e+03, initc-loss 2.4004e+04                    bc_loss 3.9758e+04\n",
      "Epoch 1130, Training-Loss 1.6569e+04, Data-loss 1.0809e+04                  , pde-loss 3.9241e+03, initc-loss 3.3396e+04                    bc_loss 5.3862e+05\n",
      "Epoch 1140, Training-Loss 1.1246e+04, Data-loss 8.2794e+03                  , pde-loss 2.9202e+03, initc-loss 2.6334e+04                    bc_loss 2.6740e+05\n",
      "Epoch 1150, Training-Loss 8.1847e+03, Data-loss 7.3089e+03                  , pde-loss 2.0763e+03, initc-loss 2.1918e+04                    bc_loss 6.3594e+04\n",
      "Epoch 1160, Training-Loss 8.5184e+03, Data-loss 7.4432e+03                  , pde-loss 3.5779e+03, initc-loss 2.7998e+04                    bc_loss 7.5946e+04\n",
      "Epoch 1170, Training-Loss 1.8833e+04, Data-loss 7.7803e+03                  , pde-loss 3.4229e+03, initc-loss 2.6596e+04                    bc_loss 1.0753e+06\n",
      "Epoch 1180, Training-Loss 1.2626e+04, Data-loss 1.1249e+04                  , pde-loss 2.1095e+03, initc-loss 2.6594e+04                    bc_loss 1.0906e+05\n",
      "Epoch 1190, Training-Loss 1.2743e+04, Data-loss 1.0558e+04                  , pde-loss 2.4935e+03, initc-loss 2.5503e+04                    bc_loss 1.9050e+05\n",
      "Epoch 1200, Training-Loss 1.1473e+04, Data-loss 8.7826e+03                  , pde-loss 3.9750e+03, initc-loss 1.6640e+04                    bc_loss 2.4846e+05\n",
      "Epoch 1210, Training-Loss 5.5347e+03, Data-loss 4.4092e+03                  , pde-loss 1.8835e+03, initc-loss 2.3681e+04                    bc_loss 8.6986e+04\n",
      "Epoch 1220, Training-Loss 1.6169e+04, Data-loss 8.0036e+03                  , pde-loss 2.2806e+03, initc-loss 2.5031e+04                    bc_loss 7.8921e+05\n",
      "Epoch 1230, Training-Loss 1.1831e+04, Data-loss 1.0859e+04                  , pde-loss 2.5063e+03, initc-loss 3.1332e+04                    bc_loss 6.3318e+04\n",
      "Epoch 1240, Training-Loss 1.3346e+04, Data-loss 1.2331e+04                  , pde-loss 2.4787e+03, initc-loss 3.3322e+04                    bc_loss 6.5675e+04\n",
      "Epoch 1250, Training-Loss 7.5006e+03, Data-loss 5.8227e+03                  , pde-loss 3.3884e+03, initc-loss 2.1644e+04                    bc_loss 1.4276e+05\n",
      "Epoch 1260, Training-Loss 1.0506e+04, Data-loss 8.6800e+03                  , pde-loss 1.6485e+03, initc-loss 2.7499e+04                    bc_loss 1.5349e+05\n",
      "Epoch 1270, Training-Loss 1.5262e+04, Data-loss 7.6769e+03                  , pde-loss 2.6039e+03, initc-loss 2.7272e+04                    bc_loss 7.2867e+05\n",
      "Epoch 1280, Training-Loss 1.3874e+04, Data-loss 1.1240e+04                  , pde-loss 4.2913e+03, initc-loss 2.7661e+04                    bc_loss 2.3152e+05\n",
      "Epoch 1290, Training-Loss 5.8585e+03, Data-loss 4.5924e+03                  , pde-loss 2.5067e+03, initc-loss 1.8654e+04                    bc_loss 1.0545e+05\n",
      "Epoch 1300, Training-Loss 6.4702e+03, Data-loss 5.7219e+03                  , pde-loss 3.8060e+03, initc-loss 2.8975e+04                    bc_loss 4.2052e+04\n",
      "Epoch 1310, Training-Loss 1.3915e+04, Data-loss 7.3700e+03                  , pde-loss 3.0939e+03, initc-loss 3.5081e+04                    bc_loss 6.1631e+05\n",
      "Epoch 1320, Training-Loss 1.1008e+04, Data-loss 9.8169e+03                  , pde-loss 2.1872e+03, initc-loss 2.7806e+04                    bc_loss 8.9153e+04\n",
      "Epoch 1330, Training-Loss 8.8238e+03, Data-loss 7.7623e+03                  , pde-loss 2.3361e+03, initc-loss 2.4552e+04                    bc_loss 7.9272e+04\n",
      "Epoch 1340, Training-Loss 4.8491e+03, Data-loss 3.9673e+03                  , pde-loss 2.6636e+03, initc-loss 2.3860e+04                    bc_loss 6.1661e+04\n",
      "Epoch 1350, Training-Loss 7.0569e+03, Data-loss 4.3213e+03                  , pde-loss 3.6150e+03, initc-loss 2.4788e+04                    bc_loss 2.4516e+05\n",
      "Epoch 1360, Training-Loss 9.4096e+03, Data-loss 8.8528e+03                  , pde-loss 1.8708e+03, initc-loss 2.6979e+04                    bc_loss 2.6838e+04\n",
      "Epoch 1370, Training-Loss 9.6371e+03, Data-loss 7.1959e+03                  , pde-loss 2.4970e+03, initc-loss 2.8675e+04                    bc_loss 2.1295e+05\n",
      "Epoch 1380, Training-Loss 8.3280e+03, Data-loss 7.6809e+03                  , pde-loss 2.1431e+03, initc-loss 1.8750e+04                    bc_loss 4.3818e+04\n",
      "Epoch 1390, Training-Loss 5.4122e+03, Data-loss 4.2428e+03                  , pde-loss 3.7025e+03, initc-loss 2.0067e+04                    bc_loss 9.3167e+04\n",
      "Epoch 1400, Training-Loss 5.6493e+03, Data-loss 3.5578e+03                  , pde-loss 1.9660e+03, initc-loss 1.9676e+04                    bc_loss 1.8751e+05\n",
      "Epoch 1410, Training-Loss 1.1747e+04, Data-loss 8.5904e+03                  , pde-loss 1.8852e+03, initc-loss 2.7062e+04                    bc_loss 2.8669e+05\n",
      "Epoch 1420, Training-Loss 7.8525e+03, Data-loss 6.6893e+03                  , pde-loss 2.1199e+03, initc-loss 1.5769e+04                    bc_loss 9.8424e+04\n",
      "Epoch 1430, Training-Loss 6.1537e+03, Data-loss 5.1745e+03                  , pde-loss 5.0006e+03, initc-loss 2.0178e+04                    bc_loss 7.2738e+04\n",
      "Epoch 1440, Training-Loss 6.1822e+03, Data-loss 3.7423e+03                  , pde-loss 1.2157e+03, initc-loss 2.6242e+04                    bc_loss 2.1653e+05\n",
      "Epoch 1450, Training-Loss 1.2657e+04, Data-loss 8.7393e+03                  , pde-loss 1.9957e+03, initc-loss 2.6705e+04                    bc_loss 3.6305e+05\n",
      "Epoch 1460, Training-Loss 1.1016e+04, Data-loss 9.6347e+03                  , pde-loss 8.4314e+03, initc-loss 1.7951e+04                    bc_loss 1.1179e+05\n",
      "Epoch 1470, Training-Loss 5.7945e+03, Data-loss 5.0231e+03                  , pde-loss 1.5339e+03, initc-loss 1.8264e+04                    bc_loss 5.7342e+04\n",
      "Epoch 1480, Training-Loss 9.0250e+03, Data-loss 4.8089e+03                  , pde-loss 1.4333e+03, initc-loss 2.4572e+04                    bc_loss 3.9560e+05\n",
      "Epoch 1490, Training-Loss 5.1444e+03, Data-loss 4.4208e+03                  , pde-loss 2.5593e+03, initc-loss 1.6309e+04                    bc_loss 5.3488e+04\n",
      "Epoch 1500, Training-Loss 7.6472e+03, Data-loss 6.1775e+03                  , pde-loss 4.1063e+03, initc-loss 2.3100e+04                    bc_loss 1.1977e+05\n",
      "Epoch 1510, Training-Loss 1.6203e+04, Data-loss 1.2352e+04                  , pde-loss 9.6651e+02, initc-loss 3.3914e+04                    bc_loss 3.5027e+05\n",
      "Epoch 1520, Training-Loss 8.9475e+03, Data-loss 7.1315e+03                  , pde-loss 1.2574e+03, initc-loss 1.3597e+04                    bc_loss 1.6674e+05\n",
      "Epoch 1530, Training-Loss 6.0059e+03, Data-loss 4.8222e+03                  , pde-loss 5.0552e+03, initc-loss 2.1332e+04                    bc_loss 9.1987e+04\n",
      "Epoch 1540, Training-Loss 6.4519e+03, Data-loss 4.7372e+03                  , pde-loss 1.5473e+03, initc-loss 2.2853e+04                    bc_loss 1.4707e+05\n",
      "Epoch 1550, Training-Loss 9.6646e+03, Data-loss 7.9438e+03                  , pde-loss 6.4495e+02, initc-loss 2.6681e+04                    bc_loss 1.4475e+05\n",
      "Epoch 1560, Training-Loss 1.5129e+04, Data-loss 1.1287e+04                  , pde-loss 2.0542e+03, initc-loss 2.2241e+04                    bc_loss 3.5988e+05\n",
      "Epoch 1570, Training-Loss 1.1153e+04, Data-loss 5.2997e+03                  , pde-loss 5.5679e+03, initc-loss 1.3820e+04                    bc_loss 5.6594e+05\n",
      "Epoch 1580, Training-Loss 4.8511e+03, Data-loss 2.9791e+03                  , pde-loss 2.3603e+03, initc-loss 2.0985e+04                    bc_loss 1.6386e+05\n",
      "Epoch 1590, Training-Loss 3.5758e+03, Data-loss 2.2751e+03                  , pde-loss 2.9190e+03, initc-loss 1.7410e+04                    bc_loss 1.0974e+05\n",
      "Epoch 1600, Training-Loss 7.7409e+03, Data-loss 5.6787e+03                  , pde-loss 1.1966e+03, initc-loss 2.7442e+04                    bc_loss 1.7758e+05\n",
      "Epoch 1610, Training-Loss 1.3487e+04, Data-loss 9.2682e+03                  , pde-loss 1.6739e+03, initc-loss 2.8711e+04                    bc_loss 3.9148e+05\n",
      "Epoch 1620, Training-Loss 6.7864e+03, Data-loss 4.9776e+03                  , pde-loss 2.2160e+03, initc-loss 1.7994e+04                    bc_loss 1.6067e+05\n",
      "Epoch 1630, Training-Loss 6.5690e+03, Data-loss 5.5510e+03                  , pde-loss 4.8143e+03, initc-loss 1.9283e+04                    bc_loss 7.7700e+04\n",
      "Epoch 1640, Training-Loss 2.7274e+03, Data-loss 1.6723e+03                  , pde-loss 2.0447e+03, initc-loss 1.4569e+04                    bc_loss 8.8902e+04\n",
      "Epoch 1650, Training-Loss 5.5637e+03, Data-loss 4.7720e+03                  , pde-loss 3.4838e+03, initc-loss 2.1813e+04                    bc_loss 5.3866e+04\n",
      "Epoch 1660, Training-Loss 1.0820e+04, Data-loss 8.5033e+03                  , pde-loss 3.2097e+03, initc-loss 2.7210e+04                    bc_loss 2.0120e+05\n",
      "Epoch 1670, Training-Loss 7.5846e+03, Data-loss 6.0357e+03                  , pde-loss 2.1656e+03, initc-loss 2.2788e+04                    bc_loss 1.2994e+05\n",
      "Epoch 1680, Training-Loss 7.3343e+03, Data-loss 5.4107e+03                  , pde-loss 3.4030e+03, initc-loss 1.1048e+04                    bc_loss 1.7791e+05\n",
      "Epoch 1690, Training-Loss 5.2291e+03, Data-loss 4.2024e+03                  , pde-loss 8.6235e+02, initc-loss 1.9384e+04                    bc_loss 8.2427e+04\n",
      "Epoch 1700, Training-Loss 3.7952e+03, Data-loss 2.8514e+03                  , pde-loss 1.1817e+03, initc-loss 2.2114e+04                    bc_loss 7.1082e+04\n",
      "Epoch 1710, Training-Loss 6.5586e+03, Data-loss 4.3335e+03                  , pde-loss 1.7847e+03, initc-loss 2.3476e+04                    bc_loss 1.9726e+05\n",
      "Epoch 1720, Training-Loss 7.0907e+03, Data-loss 5.6261e+03                  , pde-loss 8.0381e+02, initc-loss 2.0507e+04                    bc_loss 1.2515e+05\n",
      "Epoch 1730, Training-Loss 8.5367e+03, Data-loss 7.7187e+03                  , pde-loss 3.2185e+03, initc-loss 1.7108e+04                    bc_loss 6.1467e+04\n",
      "Epoch 1740, Training-Loss 6.8963e+03, Data-loss 4.9552e+03                  , pde-loss 2.7907e+03, initc-loss 1.7968e+04                    bc_loss 1.7335e+05\n",
      "Epoch 1750, Training-Loss 7.4890e+03, Data-loss 3.7001e+03                  , pde-loss 1.6180e+03, initc-loss 1.8104e+04                    bc_loss 3.5917e+05\n",
      "Epoch 1760, Training-Loss 1.1353e+04, Data-loss 1.0028e+04                  , pde-loss 8.2827e+03, initc-loss 2.2685e+04                    bc_loss 1.0153e+05\n",
      "Epoch 1770, Training-Loss 7.7054e+03, Data-loss 4.5967e+03                  , pde-loss 1.8052e+03, initc-loss 1.4079e+04                    bc_loss 2.9498e+05\n",
      "Epoch 1780, Training-Loss 7.0923e+03, Data-loss 5.8921e+03                  , pde-loss 1.0436e+03, initc-loss 1.9148e+04                    bc_loss 9.9831e+04\n",
      "Epoch 1790, Training-Loss 3.0145e+03, Data-loss 1.7733e+03                  , pde-loss 3.3932e+03, initc-loss 1.4477e+04                    bc_loss 1.0626e+05\n",
      "Epoch 1800, Training-Loss 3.0367e+03, Data-loss 2.6297e+03                  , pde-loss 2.1491e+03, initc-loss 1.1437e+04                    bc_loss 2.7110e+04\n",
      "Epoch 1810, Training-Loss 8.8889e+03, Data-loss 5.5018e+03                  , pde-loss 8.3405e+02, initc-loss 2.4077e+04                    bc_loss 3.1380e+05\n",
      "Epoch 1820, Training-Loss 5.2492e+03, Data-loss 3.9930e+03                  , pde-loss 2.1020e+03, initc-loss 1.6404e+04                    bc_loss 1.0712e+05\n",
      "Epoch 1830, Training-Loss 8.2963e+03, Data-loss 7.0257e+03                  , pde-loss 4.7890e+03, initc-loss 2.0333e+04                    bc_loss 1.0194e+05\n",
      "Epoch 1840, Training-Loss 5.7093e+03, Data-loss 3.9986e+03                  , pde-loss 2.9313e+03, initc-loss 1.6030e+04                    bc_loss 1.5210e+05\n",
      "Epoch 1850, Training-Loss 1.1016e+04, Data-loss 7.1232e+03                  , pde-loss 1.4121e+03, initc-loss 2.0779e+04                    bc_loss 3.6707e+05\n",
      "Epoch 1860, Training-Loss 4.7348e+03, Data-loss 2.7935e+03                  , pde-loss 1.4845e+03, initc-loss 1.6727e+04                    bc_loss 1.7591e+05\n",
      "Epoch 1870, Training-Loss 4.6363e+03, Data-loss 3.7753e+03                  , pde-loss 5.6247e+03, initc-loss 1.5542e+04                    bc_loss 6.4934e+04\n",
      "Epoch 1880, Training-Loss 2.7398e+03, Data-loss 2.1141e+03                  , pde-loss 1.6756e+03, initc-loss 1.5959e+04                    bc_loss 4.4935e+04\n",
      "Epoch 1890, Training-Loss 8.5780e+03, Data-loss 1.7616e+03                  , pde-loss 2.5812e+03, initc-loss 1.8042e+04                    bc_loss 6.6102e+05\n",
      "Epoch 1900, Training-Loss 1.0768e+04, Data-loss 5.2459e+03                  , pde-loss 3.9414e+03, initc-loss 2.7219e+04                    bc_loss 5.2101e+05\n",
      "Epoch 1910, Training-Loss 1.1823e+04, Data-loss 9.1758e+03                  , pde-loss 1.0021e+03, initc-loss 2.3167e+04                    bc_loss 2.4052e+05\n",
      "Epoch 1920, Training-Loss 6.7096e+03, Data-loss 4.2443e+03                  , pde-loss 1.3808e+03, initc-loss 1.4973e+04                    bc_loss 2.3018e+05\n",
      "Epoch 1930, Training-Loss 4.8083e+03, Data-loss 3.6660e+03                  , pde-loss 3.6792e+03, initc-loss 2.6078e+04                    bc_loss 8.4478e+04\n",
      "Epoch 1940, Training-Loss 6.1330e+03, Data-loss 2.3966e+03                  , pde-loss 1.6107e+03, initc-loss 2.0085e+04                    bc_loss 3.5195e+05\n",
      "Epoch 1950, Training-Loss 8.5331e+03, Data-loss 6.8436e+03                  , pde-loss 1.7017e+03, initc-loss 2.5629e+04                    bc_loss 1.4163e+05\n",
      "Epoch 1960, Training-Loss 8.0256e+03, Data-loss 6.2682e+03                  , pde-loss 1.8406e+03, initc-loss 1.6224e+04                    bc_loss 1.5767e+05\n",
      "Epoch 1970, Training-Loss 8.6353e+03, Data-loss 7.8561e+03                  , pde-loss 2.0752e+03, initc-loss 1.9004e+04                    bc_loss 5.6834e+04\n",
      "Epoch 1980, Training-Loss 7.3730e+03, Data-loss 6.1334e+03                  , pde-loss 3.2942e+03, initc-loss 2.3276e+04                    bc_loss 9.7387e+04\n",
      "Epoch 1990, Training-Loss 9.5114e+03, Data-loss 5.2504e+03                  , pde-loss 1.5672e+03, initc-loss 2.0236e+04                    bc_loss 4.0430e+05\n",
      "Epoch 2000, Training-Loss 4.8475e+03, Data-loss 4.1740e+03                  , pde-loss 9.9692e+02, initc-loss 1.3596e+04                    bc_loss 5.2756e+04\n",
      "Epoch 2010, Training-Loss 1.0637e+04, Data-loss 4.9788e+03                  , pde-loss 4.0567e+03, initc-loss 2.3827e+04                    bc_loss 5.3793e+05\n",
      "Epoch 2020, Training-Loss 5.9606e+03, Data-loss 4.6144e+03                  , pde-loss 4.6441e+03, initc-loss 2.0217e+04                    bc_loss 1.0975e+05\n",
      "Epoch 2030, Training-Loss 1.2124e+04, Data-loss 6.2516e+03                  , pde-loss 1.4615e+03, initc-loss 1.2498e+04                    bc_loss 5.7331e+05\n",
      "Epoch 2040, Training-Loss 4.8625e+03, Data-loss 3.4872e+03                  , pde-loss 5.1628e+03, initc-loss 1.7998e+04                    bc_loss 1.1437e+05\n",
      "Epoch 2050, Training-Loss 6.4115e+03, Data-loss 5.4808e+03                  , pde-loss 4.8578e+03, initc-loss 2.1565e+04                    bc_loss 6.6648e+04\n",
      "Epoch 2060, Training-Loss 3.3037e+03, Data-loss 2.8475e+03                  , pde-loss 1.5451e+03, initc-loss 1.3747e+04                    bc_loss 3.0332e+04\n",
      "Epoch 2070, Training-Loss 3.9215e+03, Data-loss 2.8415e+03                  , pde-loss 2.6309e+03, initc-loss 1.5879e+04                    bc_loss 8.9495e+04\n",
      "Epoch 2080, Training-Loss 3.1762e+03, Data-loss 2.4755e+03                  , pde-loss 1.9944e+03, initc-loss 1.5691e+04                    bc_loss 5.2383e+04\n",
      "Epoch 2090, Training-Loss 4.7753e+03, Data-loss 2.1029e+03                  , pde-loss 2.7927e+03, initc-loss 1.7786e+04                    bc_loss 2.4665e+05\n",
      "Epoch 2100, Training-Loss 2.5054e+03, Data-loss 1.6513e+03                  , pde-loss 3.8867e+03, initc-loss 1.2093e+04                    bc_loss 6.9424e+04\n",
      "Epoch 2110, Training-Loss 5.3278e+03, Data-loss 2.3318e+03                  , pde-loss 4.4959e+03, initc-loss 1.8209e+04                    bc_loss 2.7690e+05\n",
      "Epoch 2120, Training-Loss 3.8882e+03, Data-loss 3.4809e+03                  , pde-loss 2.4270e+03, initc-loss 1.6883e+04                    bc_loss 2.1422e+04\n",
      "Epoch 2130, Training-Loss 1.3088e+04, Data-loss 8.2636e+03                  , pde-loss 7.7628e+02, initc-loss 2.7371e+04                    bc_loss 4.5429e+05\n",
      "Epoch 2140, Training-Loss 9.3587e+03, Data-loss 7.9802e+03                  , pde-loss 8.1900e+02, initc-loss 1.7729e+04                    bc_loss 1.1931e+05\n",
      "Epoch 2150, Training-Loss 4.6248e+03, Data-loss 3.7579e+03                  , pde-loss 3.7766e+03, initc-loss 1.8057e+04                    bc_loss 6.4855e+04\n",
      "Epoch 2160, Training-Loss 4.2859e+03, Data-loss 2.0455e+03                  , pde-loss 1.5463e+03, initc-loss 1.2917e+04                    bc_loss 2.0958e+05\n",
      "Epoch 2170, Training-Loss 7.9855e+03, Data-loss 5.2022e+03                  , pde-loss 1.0456e+03, initc-loss 1.9419e+04                    bc_loss 2.5787e+05\n",
      "Epoch 2180, Training-Loss 5.2062e+03, Data-loss 3.6864e+03                  , pde-loss 1.0359e+03, initc-loss 1.9502e+04                    bc_loss 1.3144e+05\n",
      "Epoch 2190, Training-Loss 4.7716e+03, Data-loss 3.9511e+03                  , pde-loss 5.3398e+03, initc-loss 2.1488e+04                    bc_loss 5.5223e+04\n",
      "Epoch 2200, Training-Loss 2.6667e+03, Data-loss 2.1925e+03                  , pde-loss 2.8749e+03, initc-loss 1.4468e+04                    bc_loss 3.0076e+04\n",
      "Epoch 2210, Training-Loss 1.0924e+04, Data-loss 3.5027e+03                  , pde-loss 2.1558e+03, initc-loss 1.6022e+04                    bc_loss 7.2395e+05\n",
      "Epoch 2220, Training-Loss 6.7827e+03, Data-loss 5.9449e+03                  , pde-loss 4.1808e+03, initc-loss 2.6647e+04                    bc_loss 5.2958e+04\n",
      "Epoch 2230, Training-Loss 6.8273e+03, Data-loss 6.0066e+03                  , pde-loss 3.0717e+03, initc-loss 2.0233e+04                    bc_loss 5.8763e+04\n",
      "Epoch 2240, Training-Loss 4.9782e+03, Data-loss 4.3519e+03                  , pde-loss 1.7235e+03, initc-loss 2.0721e+04                    bc_loss 4.0187e+04\n",
      "Epoch 2250, Training-Loss 8.1047e+03, Data-loss 3.2131e+03                  , pde-loss 1.8530e+03, initc-loss 2.3022e+04                    bc_loss 4.6429e+05\n",
      "Epoch 2260, Training-Loss 1.2381e+04, Data-loss 8.3715e+03                  , pde-loss 2.0234e+03, initc-loss 1.7641e+04                    bc_loss 3.8124e+05\n",
      "Epoch 2270, Training-Loss 7.1521e+03, Data-loss 5.0661e+03                  , pde-loss 2.6469e+03, initc-loss 1.7234e+04                    bc_loss 1.8872e+05\n",
      "Epoch 2280, Training-Loss 7.3649e+03, Data-loss 6.8197e+03                  , pde-loss 2.2538e+03, initc-loss 2.1730e+04                    bc_loss 3.0534e+04\n",
      "Epoch 2290, Training-Loss 4.8273e+03, Data-loss 2.3598e+03                  , pde-loss 2.1067e+03, initc-loss 1.9464e+04                    bc_loss 2.2518e+05\n",
      "Epoch 2300, Training-Loss 7.1128e+03, Data-loss 5.6344e+03                  , pde-loss 2.9026e+03, initc-loss 1.6296e+04                    bc_loss 1.2864e+05\n",
      "Epoch 2310, Training-Loss 7.7431e+03, Data-loss 6.0837e+03                  , pde-loss 4.5645e+03, initc-loss 2.1437e+04                    bc_loss 1.3993e+05\n",
      "Epoch 2320, Training-Loss 1.0601e+04, Data-loss 9.6321e+03                  , pde-loss 8.9780e+02, initc-loss 2.1145e+04                    bc_loss 7.4844e+04\n",
      "Epoch 2330, Training-Loss 3.6610e+03, Data-loss 2.3836e+03                  , pde-loss 2.7717e+03, initc-loss 2.1588e+04                    bc_loss 1.0338e+05\n",
      "Epoch 2340, Training-Loss 4.4452e+03, Data-loss 3.4768e+03                  , pde-loss 4.3585e+03, initc-loss 2.0196e+04                    bc_loss 7.2287e+04\n",
      "Epoch 2350, Training-Loss 8.4170e+03, Data-loss 3.9679e+03                  , pde-loss 1.0094e+03, initc-loss 2.3731e+04                    bc_loss 4.2017e+05\n",
      "Epoch 2360, Training-Loss 1.0681e+04, Data-loss 9.2370e+03                  , pde-loss 1.3934e+03, initc-loss 1.6020e+04                    bc_loss 1.2698e+05\n",
      "Epoch 2370, Training-Loss 5.7834e+03, Data-loss 4.0572e+03                  , pde-loss 4.5168e+03, initc-loss 1.7619e+04                    bc_loss 1.5048e+05\n",
      "Epoch 2380, Training-Loss 3.7103e+03, Data-loss 3.1121e+03                  , pde-loss 2.2212e+03, initc-loss 1.7844e+04                    bc_loss 3.9760e+04\n",
      "Epoch 2390, Training-Loss 3.2798e+03, Data-loss 2.4881e+03                  , pde-loss 2.2500e+03, initc-loss 1.4085e+04                    bc_loss 6.2839e+04\n",
      "Epoch 2400, Training-Loss 8.9657e+03, Data-loss 2.5699e+03                  , pde-loss 2.9511e+03, initc-loss 1.9464e+04                    bc_loss 6.1716e+05\n",
      "Epoch 2410, Training-Loss 6.6155e+03, Data-loss 5.4614e+03                  , pde-loss 3.7529e+03, initc-loss 2.1983e+04                    bc_loss 8.9673e+04\n",
      "Epoch 2420, Training-Loss 8.6149e+03, Data-loss 6.9102e+03                  , pde-loss 1.9774e+03, initc-loss 1.7238e+04                    bc_loss 1.5125e+05\n",
      "Epoch 2430, Training-Loss 7.2214e+03, Data-loss 5.0589e+03                  , pde-loss 6.2067e+03, initc-loss 1.9013e+04                    bc_loss 1.9104e+05\n",
      "Epoch 2440, Training-Loss 3.1391e+03, Data-loss 2.3678e+03                  , pde-loss 2.6699e+03, initc-loss 1.3272e+04                    bc_loss 6.1183e+04\n",
      "Epoch 2450, Training-Loss 5.2873e+03, Data-loss 3.5904e+03                  , pde-loss 9.8299e+02, initc-loss 1.5005e+04                    bc_loss 1.5371e+05\n",
      "Epoch 2460, Training-Loss 2.3006e+03, Data-loss 1.5429e+03                  , pde-loss 1.2571e+03, initc-loss 1.6957e+04                    bc_loss 5.7551e+04\n",
      "Epoch 2470, Training-Loss 2.6342e+03, Data-loss 2.0629e+03                  , pde-loss 2.7705e+03, initc-loss 1.4951e+04                    bc_loss 3.9410e+04\n",
      "Epoch 2480, Training-Loss 7.1526e+03, Data-loss 2.0047e+03                  , pde-loss 9.4739e+02, initc-loss 1.8159e+04                    bc_loss 4.9568e+05\n",
      "Epoch 2490, Training-Loss 3.7121e+03, Data-loss 3.0911e+03                  , pde-loss 3.3794e+03, initc-loss 1.1151e+04                    bc_loss 4.7569e+04\n",
      "Epoch 2500, Training-Loss 3.3572e+03, Data-loss 2.1168e+03                  , pde-loss 3.4454e+03, initc-loss 1.7430e+04                    bc_loss 1.0316e+05\n",
      "Epoch 2510, Training-Loss 4.3939e+03, Data-loss 1.8639e+03                  , pde-loss 2.5006e+03, initc-loss 1.4539e+04                    bc_loss 2.3596e+05\n",
      "Epoch 2520, Training-Loss 3.5261e+03, Data-loss 2.8146e+03                  , pde-loss 1.8924e+03, initc-loss 1.0741e+04                    bc_loss 5.8519e+04\n",
      "Epoch 2530, Training-Loss 1.7309e+03, Data-loss 1.2264e+03                  , pde-loss 1.4163e+03, initc-loss 1.4485e+04                    bc_loss 3.4552e+04\n",
      "Epoch 2540, Training-Loss 8.8164e+03, Data-loss 2.0945e+03                  , pde-loss 6.5587e+02, initc-loss 1.6494e+04                    bc_loss 6.5504e+05\n",
      "Epoch 2550, Training-Loss 4.5063e+03, Data-loss 3.4674e+03                  , pde-loss 1.5729e+03, initc-loss 1.3140e+04                    bc_loss 8.9184e+04\n",
      "Epoch 2560, Training-Loss 3.6618e+03, Data-loss 2.6027e+03                  , pde-loss 2.8077e+03, initc-loss 1.4082e+04                    bc_loss 8.9016e+04\n",
      "Epoch 2570, Training-Loss 4.3703e+03, Data-loss 3.4891e+03                  , pde-loss 1.7464e+03, initc-loss 1.7441e+04                    bc_loss 6.8934e+04\n",
      "Epoch 2580, Training-Loss 2.9576e+03, Data-loss 2.3445e+03                  , pde-loss 2.9950e+03, initc-loss 1.2864e+04                    bc_loss 4.5450e+04\n",
      "Epoch 2590, Training-Loss 2.2606e+03, Data-loss 1.7652e+03                  , pde-loss 3.3819e+03, initc-loss 1.6583e+04                    bc_loss 2.9569e+04\n",
      "Epoch 2600, Training-Loss 1.1586e+04, Data-loss 7.6470e+03                  , pde-loss 4.9815e+03, initc-loss 3.2578e+04                    bc_loss 3.5636e+05\n",
      "Epoch 2610, Training-Loss 8.1061e+03, Data-loss 4.6814e+03                  , pde-loss 3.6682e+03, initc-loss 9.0277e+03                    bc_loss 3.2978e+05\n",
      "Epoch 2620, Training-Loss 8.3976e+03, Data-loss 5.7275e+03                  , pde-loss 7.8573e+02, initc-loss 1.8869e+04                    bc_loss 2.4735e+05\n",
      "Epoch 2630, Training-Loss 4.4441e+03, Data-loss 2.1394e+03                  , pde-loss 4.1693e+03, initc-loss 1.6705e+04                    bc_loss 2.0959e+05\n",
      "Epoch 2640, Training-Loss 4.7756e+03, Data-loss 3.9259e+03                  , pde-loss 3.7336e+03, initc-loss 1.6016e+04                    bc_loss 6.5214e+04\n",
      "Epoch 2650, Training-Loss 6.6815e+03, Data-loss 5.5205e+03                  , pde-loss 2.7880e+03, initc-loss 1.7477e+04                    bc_loss 9.5835e+04\n",
      "Epoch 2660, Training-Loss 4.2769e+03, Data-loss 2.2948e+03                  , pde-loss 3.2934e+03, initc-loss 1.6511e+04                    bc_loss 1.7840e+05\n",
      "Epoch 2670, Training-Loss 3.9399e+03, Data-loss 2.2646e+03                  , pde-loss 9.0881e+02, initc-loss 1.5225e+04                    bc_loss 1.5140e+05\n",
      "Epoch 2680, Training-Loss 8.3027e+03, Data-loss 5.6652e+03                  , pde-loss 6.3715e+02, initc-loss 2.1826e+04                    bc_loss 2.4129e+05\n",
      "Epoch 2690, Training-Loss 6.2914e+03, Data-loss 4.7711e+03                  , pde-loss 2.0720e+03, initc-loss 1.8975e+04                    bc_loss 1.3098e+05\n",
      "Epoch 2700, Training-Loss 3.9093e+03, Data-loss 3.0725e+03                  , pde-loss 3.5100e+03, initc-loss 1.4755e+04                    bc_loss 6.5415e+04\n",
      "Epoch 2710, Training-Loss 3.1147e+03, Data-loss 2.2185e+03                  , pde-loss 7.5671e+02, initc-loss 1.0818e+04                    bc_loss 7.8042e+04\n",
      "Epoch 2720, Training-Loss 6.7787e+03, Data-loss 3.3720e+03                  , pde-loss 7.7228e+02, initc-loss 1.8081e+04                    bc_loss 3.2182e+05\n",
      "Epoch 2730, Training-Loss 3.4280e+03, Data-loss 2.9799e+03                  , pde-loss 1.3246e+03, initc-loss 1.1951e+04                    bc_loss 3.1535e+04\n",
      "Epoch 2740, Training-Loss 4.1007e+03, Data-loss 3.8080e+03                  , pde-loss 2.5613e+03, initc-loss 1.2595e+04                    bc_loss 1.4107e+04\n",
      "Epoch 2750, Training-Loss 3.0324e+03, Data-loss 2.4638e+03                  , pde-loss 2.3370e+03, initc-loss 1.4932e+04                    bc_loss 3.9586e+04\n",
      "Epoch 2760, Training-Loss 5.9136e+03, Data-loss 3.2127e+03                  , pde-loss 1.2402e+03, initc-loss 2.1302e+04                    bc_loss 2.4755e+05\n",
      "Epoch 2770, Training-Loss 4.9378e+03, Data-loss 3.2895e+03                  , pde-loss 1.2679e+03, initc-loss 1.5092e+04                    bc_loss 1.4847e+05\n",
      "Epoch 2780, Training-Loss 7.4961e+03, Data-loss 5.0900e+03                  , pde-loss 6.6795e+03, initc-loss 2.9349e+04                    bc_loss 2.0458e+05\n",
      "Epoch 2790, Training-Loss 5.2304e+03, Data-loss 3.0633e+03                  , pde-loss 1.7276e+03, initc-loss 1.5563e+04                    bc_loss 1.9942e+05\n",
      "Epoch 2800, Training-Loss 1.0270e+04, Data-loss 7.3969e+03                  , pde-loss 1.5028e+03, initc-loss 1.8875e+04                    bc_loss 2.6691e+05\n",
      "Epoch 2810, Training-Loss 2.9781e+03, Data-loss 1.8167e+03                  , pde-loss 2.6783e+03, initc-loss 1.5367e+04                    bc_loss 9.8096e+04\n",
      "Epoch 2820, Training-Loss 3.2162e+03, Data-loss 2.7206e+03                  , pde-loss 2.9853e+03, initc-loss 1.3323e+04                    bc_loss 3.3258e+04\n",
      "Epoch 2830, Training-Loss 1.8541e+03, Data-loss 1.2394e+03                  , pde-loss 2.6248e+03, initc-loss 1.7198e+04                    bc_loss 4.1646e+04\n",
      "Epoch 2840, Training-Loss 5.0807e+03, Data-loss 2.4018e+03                  , pde-loss 1.7618e+03, initc-loss 1.7349e+04                    bc_loss 2.4878e+05\n",
      "Epoch 2850, Training-Loss 3.0268e+03, Data-loss 2.2316e+03                  , pde-loss 2.3735e+03, initc-loss 7.0170e+03                    bc_loss 7.0126e+04\n",
      "Epoch 2860, Training-Loss 3.0390e+03, Data-loss 1.8464e+03                  , pde-loss 2.2151e+03, initc-loss 1.2682e+04                    bc_loss 1.0436e+05\n",
      "Epoch 2870, Training-Loss 2.2101e+03, Data-loss 1.6421e+03                  , pde-loss 1.8716e+03, initc-loss 1.4488e+04                    bc_loss 4.0436e+04\n",
      "Epoch 2880, Training-Loss 1.6212e+04, Data-loss 4.0624e+03                  , pde-loss 2.6094e+03, initc-loss 2.7250e+04                    bc_loss 1.1851e+06\n",
      "Epoch 2890, Training-Loss 1.0364e+04, Data-loss 8.8461e+03                  , pde-loss 5.8298e+03, initc-loss 1.6533e+04                    bc_loss 1.2947e+05\n",
      "Epoch 2900, Training-Loss 4.9303e+03, Data-loss 3.5633e+03                  , pde-loss 9.7094e+02, initc-loss 1.3609e+04                    bc_loss 1.2212e+05\n",
      "Epoch 2910, Training-Loss 5.3614e+03, Data-loss 3.0336e+03                  , pde-loss 1.5469e+03, initc-loss 1.6649e+04                    bc_loss 2.1459e+05\n",
      "Epoch 2920, Training-Loss 5.0331e+03, Data-loss 3.3997e+03                  , pde-loss 5.7681e+03, initc-loss 2.2519e+04                    bc_loss 1.3505e+05\n",
      "Epoch 2930, Training-Loss 6.9986e+03, Data-loss 4.4227e+03                  , pde-loss 5.6924e+03, initc-loss 9.9566e+03                    bc_loss 2.4194e+05\n",
      "Epoch 2940, Training-Loss 6.4975e+03, Data-loss 4.3640e+03                  , pde-loss 8.8229e+02, initc-loss 1.1322e+04                    bc_loss 2.0114e+05\n",
      "Epoch 2950, Training-Loss 1.0711e+04, Data-loss 7.3630e+03                  , pde-loss 9.1070e+02, initc-loss 2.0546e+04                    bc_loss 3.1330e+05\n",
      "Epoch 2960, Training-Loss 4.8640e+03, Data-loss 2.8958e+03                  , pde-loss 1.5421e+03, initc-loss 2.0342e+04                    bc_loss 1.7493e+05\n",
      "Epoch 2970, Training-Loss 3.6393e+03, Data-loss 2.3269e+03                  , pde-loss 1.1933e+03, initc-loss 1.4075e+04                    bc_loss 1.1598e+05\n",
      "Epoch 2980, Training-Loss 2.6427e+03, Data-loss 1.7809e+03                  , pde-loss 2.4768e+03, initc-loss 1.2580e+04                    bc_loss 7.1123e+04\n",
      "Epoch 2990, Training-Loss 8.2059e+03, Data-loss 2.1775e+03                  , pde-loss 1.2427e+03, initc-loss 1.6675e+04                    bc_loss 5.8493e+05\n",
      "Epoch 3000, Training-Loss 1.0995e+04, Data-loss 5.9780e+03                  , pde-loss 8.6405e+02, initc-loss 1.6317e+04                    bc_loss 4.8457e+05\n",
      "Epoch 3010, Training-Loss 4.9104e+03, Data-loss 2.5933e+03                  , pde-loss 4.2888e+03, initc-loss 1.7804e+04                    bc_loss 2.0962e+05\n",
      "Epoch 3020, Training-Loss 5.8222e+03, Data-loss 3.9215e+03                  , pde-loss 3.2474e+03, initc-loss 1.8191e+04                    bc_loss 1.6863e+05\n",
      "Epoch 3030, Training-Loss 4.6853e+03, Data-loss 3.9403e+03                  , pde-loss 9.4008e+02, initc-loss 1.7321e+04                    bc_loss 5.6243e+04\n",
      "Epoch 3040, Training-Loss 2.3789e+03, Data-loss 1.8309e+03                  , pde-loss 1.9216e+03, initc-loss 1.7343e+04                    bc_loss 3.5543e+04\n",
      "Epoch 3050, Training-Loss 3.0516e+03, Data-loss 2.0991e+03                  , pde-loss 2.6382e+03, initc-loss 1.2998e+04                    bc_loss 7.9614e+04\n",
      "Epoch 3060, Training-Loss 4.3309e+03, Data-loss 2.7310e+03                  , pde-loss 4.5678e+03, initc-loss 1.6062e+04                    bc_loss 1.3936e+05\n",
      "Epoch 3070, Training-Loss 1.1002e+04, Data-loss 6.1451e+03                  , pde-loss 4.7992e+03, initc-loss 2.9034e+04                    bc_loss 4.5189e+05\n",
      "Epoch 3080, Training-Loss 1.0985e+04, Data-loss 5.7328e+03                  , pde-loss 3.2305e+03, initc-loss 1.3783e+04                    bc_loss 5.0823e+05\n",
      "Epoch 3090, Training-Loss 9.3816e+03, Data-loss 6.4377e+03                  , pde-loss 7.5253e+02, initc-loss 2.0688e+04                    bc_loss 2.7294e+05\n",
      "Epoch 3100, Training-Loss 4.1923e+03, Data-loss 2.6485e+03                  , pde-loss 2.3721e+03, initc-loss 2.0724e+04                    bc_loss 1.3129e+05\n",
      "Epoch 3110, Training-Loss 5.7243e+03, Data-loss 4.6845e+03                  , pde-loss 2.9808e+03, initc-loss 1.6720e+04                    bc_loss 8.4283e+04\n",
      "Epoch 3120, Training-Loss 5.1851e+03, Data-loss 2.5336e+03                  , pde-loss 3.1689e+03, initc-loss 1.5055e+04                    bc_loss 2.4693e+05\n",
      "Epoch 3130, Training-Loss 5.2889e+03, Data-loss 2.0626e+03                  , pde-loss 1.7309e+03, initc-loss 9.8316e+03                    bc_loss 3.1106e+05\n",
      "Epoch 3140, Training-Loss 7.7933e+03, Data-loss 5.7812e+03                  , pde-loss 8.3400e+02, initc-loss 1.7273e+04                    bc_loss 1.8311e+05\n",
      "Epoch 3150, Training-Loss 6.6272e+03, Data-loss 4.9856e+03                  , pde-loss 3.9162e+02, initc-loss 1.4900e+04                    bc_loss 1.4887e+05\n",
      "Epoch 3160, Training-Loss 2.9640e+03, Data-loss 2.2363e+03                  , pde-loss 2.5851e+03, initc-loss 1.9456e+04                    bc_loss 5.0729e+04\n",
      "Epoch 3170, Training-Loss 4.2395e+03, Data-loss 2.8180e+03                  , pde-loss 1.7878e+03, initc-loss 1.9357e+04                    bc_loss 1.2100e+05\n",
      "Epoch 3180, Training-Loss 4.3949e+03, Data-loss 1.7690e+03                  , pde-loss 6.7015e+02, initc-loss 1.9018e+04                    bc_loss 2.4291e+05\n",
      "Epoch 3190, Training-Loss 5.7887e+03, Data-loss 4.6922e+03                  , pde-loss 1.1271e+03, initc-loss 1.6363e+04                    bc_loss 9.2163e+04\n",
      "Epoch 3200, Training-Loss 5.0729e+03, Data-loss 4.2858e+03                  , pde-loss 3.0546e+03, initc-loss 9.4623e+03                    bc_loss 6.6190e+04\n",
      "Epoch 3210, Training-Loss 4.7611e+03, Data-loss 3.0425e+03                  , pde-loss 3.9853e+03, initc-loss 2.1005e+04                    bc_loss 1.4687e+05\n",
      "Epoch 3220, Training-Loss 1.1422e+04, Data-loss 3.1273e+03                  , pde-loss 8.4232e+02, initc-loss 2.0490e+04                    bc_loss 8.0817e+05\n",
      "Epoch 3230, Training-Loss 8.9370e+03, Data-loss 6.9062e+03                  , pde-loss 1.0646e+03, initc-loss 1.4961e+04                    bc_loss 1.8706e+05\n",
      "Epoch 3240, Training-Loss 4.7827e+03, Data-loss 3.3676e+03                  , pde-loss 5.7069e+03, initc-loss 1.2257e+04                    bc_loss 1.2355e+05\n",
      "Epoch 3250, Training-Loss 3.4921e+03, Data-loss 2.8205e+03                  , pde-loss 4.0607e+03, initc-loss 1.6133e+04                    bc_loss 4.6965e+04\n",
      "Epoch 3260, Training-Loss 1.0257e+04, Data-loss 7.2281e+03                  , pde-loss 2.0954e+03, initc-loss 2.1436e+04                    bc_loss 2.7931e+05\n",
      "Epoch 3270, Training-Loss 7.8557e+03, Data-loss 6.3926e+03                  , pde-loss 2.1727e+03, initc-loss 2.7503e+04                    bc_loss 1.1663e+05\n",
      "Epoch 3280, Training-Loss 6.8387e+03, Data-loss 6.0724e+03                  , pde-loss 1.9138e+03, initc-loss 2.0473e+04                    bc_loss 5.4235e+04\n",
      "Epoch 3290, Training-Loss 6.1265e+03, Data-loss 3.6144e+03                  , pde-loss 1.4185e+03, initc-loss 1.2491e+04                    bc_loss 2.3730e+05\n",
      "Epoch 3300, Training-Loss 6.3262e+03, Data-loss 5.3270e+03                  , pde-loss 9.0986e+02, initc-loss 1.6668e+04                    bc_loss 8.2343e+04\n",
      "Epoch 3310, Training-Loss 1.0729e+04, Data-loss 3.6377e+03                  , pde-loss 2.0729e+03, initc-loss 1.9572e+04                    bc_loss 6.8744e+05\n",
      "Epoch 3320, Training-Loss 6.7259e+03, Data-loss 4.2989e+03                  , pde-loss 6.1958e+03, initc-loss 1.4947e+04                    bc_loss 2.2156e+05\n",
      "Epoch 3330, Training-Loss 1.2945e+04, Data-loss 3.3718e+03                  , pde-loss 6.3777e+02, initc-loss 1.5312e+04                    bc_loss 9.4136e+05\n",
      "Epoch 3340, Training-Loss 1.1489e+04, Data-loss 6.0007e+03                  , pde-loss 9.4819e+02, initc-loss 1.2985e+04                    bc_loss 5.3486e+05\n",
      "Epoch 3350, Training-Loss 6.8513e+03, Data-loss 5.0908e+03                  , pde-loss 7.6311e+03, initc-loss 1.3432e+04                    bc_loss 1.5498e+05\n",
      "Epoch 3360, Training-Loss 3.6341e+03, Data-loss 3.1274e+03                  , pde-loss 3.0827e+03, initc-loss 1.4079e+04                    bc_loss 3.3512e+04\n",
      "Epoch 3370, Training-Loss 3.3580e+03, Data-loss 2.0102e+03                  , pde-loss 2.0947e+03, initc-loss 1.4586e+04                    bc_loss 1.1810e+05\n",
      "Epoch 3380, Training-Loss 5.8251e+03, Data-loss 2.8625e+03                  , pde-loss 3.2053e+03, initc-loss 1.6688e+04                    bc_loss 2.7636e+05\n",
      "Epoch 3390, Training-Loss 4.6848e+03, Data-loss 3.1644e+03                  , pde-loss 3.2334e+03, initc-loss 1.7969e+04                    bc_loss 1.3084e+05\n",
      "Epoch 3400, Training-Loss 2.7326e+03, Data-loss 1.4872e+03                  , pde-loss 2.1289e+03, initc-loss 1.5751e+04                    bc_loss 1.0665e+05\n",
      "Epoch 3410, Training-Loss 4.6657e+03, Data-loss 3.3398e+03                  , pde-loss 4.8318e+02, initc-loss 1.5986e+04                    bc_loss 1.1611e+05\n",
      "Epoch 3420, Training-Loss 6.9274e+03, Data-loss 4.0710e+03                  , pde-loss 6.4509e+02, initc-loss 1.7311e+04                    bc_loss 2.6769e+05\n",
      "Epoch 3430, Training-Loss 5.5026e+03, Data-loss 4.6237e+03                  , pde-loss 7.5947e+02, initc-loss 1.2805e+04                    bc_loss 7.4326e+04\n",
      "Epoch 3440, Training-Loss 4.5945e+03, Data-loss 3.8696e+03                  , pde-loss 3.1277e+03, initc-loss 2.4863e+04                    bc_loss 4.4497e+04\n",
      "Epoch 3450, Training-Loss 8.1073e+03, Data-loss 6.1271e+03                  , pde-loss 3.6080e+03, initc-loss 2.3264e+04                    bc_loss 1.7115e+05\n",
      "Epoch 3460, Training-Loss 1.3323e+04, Data-loss 4.1860e+03                  , pde-loss 2.3083e+03, initc-loss 1.3179e+04                    bc_loss 8.9823e+05\n",
      "Epoch 3470, Training-Loss 1.4399e+04, Data-loss 1.2817e+04                  , pde-loss 9.6516e+02, initc-loss 8.2009e+03                    bc_loss 1.4896e+05\n",
      "Epoch 3480, Training-Loss 5.0927e+03, Data-loss 3.2769e+03                  , pde-loss 3.1249e+03, initc-loss 2.0084e+04                    bc_loss 1.5838e+05\n",
      "Epoch 3490, Training-Loss 5.8002e+03, Data-loss 4.5457e+03                  , pde-loss 5.8339e+03, initc-loss 2.3319e+04                    bc_loss 9.6296e+04\n",
      "Epoch 3500, Training-Loss 3.0512e+03, Data-loss 2.6194e+03                  , pde-loss 8.6855e+02, initc-loss 1.7246e+04                    bc_loss 2.5065e+04\n",
      "Epoch 3510, Training-Loss 2.3086e+03, Data-loss 1.4430e+03                  , pde-loss 1.2538e+03, initc-loss 1.5373e+04                    bc_loss 6.9929e+04\n",
      "Epoch 3520, Training-Loss 3.8722e+03, Data-loss 2.7840e+03                  , pde-loss 7.3611e+02, initc-loss 2.0096e+04                    bc_loss 8.7988e+04\n",
      "Epoch 3530, Training-Loss 3.3332e+03, Data-loss 2.8663e+03                  , pde-loss 1.9098e+03, initc-loss 2.5602e+04                    bc_loss 1.9182e+04\n",
      "Epoch 3540, Training-Loss 6.1629e+03, Data-loss 4.5401e+03                  , pde-loss 2.9432e+03, initc-loss 2.1108e+04                    bc_loss 1.3823e+05\n",
      "Epoch 3550, Training-Loss 8.0152e+03, Data-loss 5.7503e+03                  , pde-loss 2.6009e+03, initc-loss 2.6007e+04                    bc_loss 1.9788e+05\n",
      "Epoch 3560, Training-Loss 5.5678e+03, Data-loss 3.5143e+03                  , pde-loss 1.7252e+03, initc-loss 1.8190e+04                    bc_loss 1.8543e+05\n",
      "Epoch 3570, Training-Loss 3.5263e+03, Data-loss 2.4703e+03                  , pde-loss 2.1249e+03, initc-loss 1.9454e+04                    bc_loss 8.4026e+04\n",
      "Epoch 3580, Training-Loss 3.5210e+03, Data-loss 2.4300e+03                  , pde-loss 2.2648e+03, initc-loss 1.5007e+04                    bc_loss 9.1831e+04\n",
      "Epoch 3590, Training-Loss 7.4770e+03, Data-loss 4.7654e+03                  , pde-loss 2.5707e+03, initc-loss 1.9630e+04                    bc_loss 2.4896e+05\n",
      "Epoch 3600, Training-Loss 9.8541e+03, Data-loss 8.5193e+03                  , pde-loss 1.6040e+03, initc-loss 2.5543e+04                    bc_loss 1.0634e+05\n",
      "Epoch 3610, Training-Loss 4.8347e+03, Data-loss 3.8543e+03                  , pde-loss 1.3974e+03, initc-loss 2.3457e+04                    bc_loss 7.3187e+04\n",
      "Epoch 3620, Training-Loss 3.7978e+03, Data-loss 3.2406e+03                  , pde-loss 1.6044e+03, initc-loss 1.9199e+04                    bc_loss 3.4913e+04\n",
      "Epoch 3630, Training-Loss 5.9848e+03, Data-loss 2.3185e+03                  , pde-loss 2.9229e+03, initc-loss 2.2752e+04                    bc_loss 3.4096e+05\n",
      "Epoch 3640, Training-Loss 6.3047e+03, Data-loss 5.5141e+03                  , pde-loss 2.1201e+03, initc-loss 1.9826e+04                    bc_loss 5.7119e+04\n",
      "Epoch 3650, Training-Loss 5.3072e+03, Data-loss 4.0459e+03                  , pde-loss 2.1412e+03, initc-loss 1.9839e+04                    bc_loss 1.0416e+05\n",
      "Epoch 3660, Training-Loss 6.0784e+03, Data-loss 3.5738e+03                  , pde-loss 1.1624e+03, initc-loss 2.3839e+04                    bc_loss 2.2546e+05\n",
      "Epoch 3670, Training-Loss 7.3830e+03, Data-loss 5.8525e+03                  , pde-loss 9.3094e+02, initc-loss 1.4955e+04                    bc_loss 1.3717e+05\n",
      "Epoch 3680, Training-Loss 5.6169e+03, Data-loss 4.6655e+03                  , pde-loss 3.8383e+03, initc-loss 1.9253e+04                    bc_loss 7.2053e+04\n",
      "Epoch 3690, Training-Loss 6.8723e+03, Data-loss 4.0535e+03                  , pde-loss 3.3181e+03, initc-loss 1.4304e+04                    bc_loss 2.6425e+05\n",
      "Epoch 3700, Training-Loss 4.7737e+03, Data-loss 3.9778e+03                  , pde-loss 8.1066e+02, initc-loss 1.7881e+04                    bc_loss 6.0896e+04\n",
      "Epoch 3710, Training-Loss 4.9750e+03, Data-loss 2.0457e+03                  , pde-loss 1.0425e+03, initc-loss 1.9205e+04                    bc_loss 2.7268e+05\n",
      "Epoch 3720, Training-Loss 2.9202e+03, Data-loss 1.8375e+03                  , pde-loss 2.1234e+03, initc-loss 1.5043e+04                    bc_loss 9.1107e+04\n",
      "Epoch 3730, Training-Loss 7.3932e+03, Data-loss 5.3255e+03                  , pde-loss 5.7830e+03, initc-loss 2.3175e+04                    bc_loss 1.7782e+05\n",
      "Epoch 3740, Training-Loss 4.6302e+03, Data-loss 3.3431e+03                  , pde-loss 1.3144e+03, initc-loss 1.2771e+04                    bc_loss 1.1463e+05\n",
      "Epoch 3750, Training-Loss 1.0198e+04, Data-loss 6.8382e+03                  , pde-loss 7.2753e+02, initc-loss 2.8847e+04                    bc_loss 3.0635e+05\n",
      "Epoch 3760, Training-Loss 3.7056e+03, Data-loss 2.2484e+03                  , pde-loss 3.5609e+03, initc-loss 1.1874e+04                    bc_loss 1.3028e+05\n",
      "Epoch 3770, Training-Loss 5.6769e+03, Data-loss 4.5799e+03                  , pde-loss 4.3771e+03, initc-loss 1.4515e+04                    bc_loss 9.0801e+04\n",
      "Epoch 3780, Training-Loss 2.5424e+03, Data-loss 2.0360e+03                  , pde-loss 1.3373e+03, initc-loss 1.3613e+04                    bc_loss 3.5696e+04\n",
      "Epoch 3790, Training-Loss 1.6542e+03, Data-loss 1.1876e+03                  , pde-loss 1.0274e+03, initc-loss 1.8463e+04                    bc_loss 2.7170e+04\n",
      "Epoch 3800, Training-Loss 2.5002e+03, Data-loss 2.1595e+03                  , pde-loss 1.3699e+03, initc-loss 1.6684e+04                    bc_loss 1.6017e+04\n",
      "Epoch 3810, Training-Loss 2.1353e+03, Data-loss 1.7222e+03                  , pde-loss 1.5464e+03, initc-loss 1.3726e+04                    bc_loss 2.6036e+04\n",
      "Epoch 3820, Training-Loss 8.0925e+03, Data-loss 4.8015e+03                  , pde-loss 3.6604e+03, initc-loss 2.9614e+04                    bc_loss 2.9583e+05\n",
      "Epoch 3830, Training-Loss 1.7365e+04, Data-loss 3.9930e+03                  , pde-loss 3.2189e+03, initc-loss 1.4933e+04                    bc_loss 1.3190e+06\n",
      "Epoch 3840, Training-Loss 9.7452e+03, Data-loss 8.7099e+03                  , pde-loss 6.0016e+02, initc-loss 1.8089e+04                    bc_loss 8.4849e+04\n",
      "Epoch 3850, Training-Loss 5.5790e+03, Data-loss 2.9218e+03                  , pde-loss 2.1295e+03, initc-loss 1.6263e+04                    bc_loss 2.4732e+05\n",
      "Epoch 3860, Training-Loss 7.5004e+03, Data-loss 5.8351e+03                  , pde-loss 5.4725e+03, initc-loss 2.3034e+04                    bc_loss 1.3803e+05\n",
      "Epoch 3870, Training-Loss 3.5969e+03, Data-loss 2.9971e+03                  , pde-loss 1.1412e+03, initc-loss 1.8279e+04                    bc_loss 4.0554e+04\n",
      "Epoch 3880, Training-Loss 4.9577e+03, Data-loss 2.4519e+03                  , pde-loss 5.2881e+02, initc-loss 1.5508e+04                    bc_loss 2.3454e+05\n",
      "Epoch 3890, Training-Loss 4.1493e+03, Data-loss 2.9463e+03                  , pde-loss 6.7843e+02, initc-loss 1.3193e+04                    bc_loss 1.0643e+05\n",
      "Epoch 3900, Training-Loss 3.4877e+03, Data-loss 2.7896e+03                  , pde-loss 2.7731e+03, initc-loss 1.9576e+04                    bc_loss 4.7461e+04\n",
      "Epoch 3910, Training-Loss 4.2729e+03, Data-loss 3.1876e+03                  , pde-loss 2.0435e+03, initc-loss 2.1255e+04                    bc_loss 8.5238e+04\n",
      "Epoch 3920, Training-Loss 6.8526e+03, Data-loss 3.4055e+03                  , pde-loss 9.2206e+02, initc-loss 1.9528e+04                    bc_loss 3.2425e+05\n",
      "Epoch 3930, Training-Loss 7.8976e+03, Data-loss 4.2364e+03                  , pde-loss 1.5699e+03, initc-loss 1.1051e+04                    bc_loss 3.5351e+05\n",
      "Epoch 3940, Training-Loss 8.9128e+03, Data-loss 4.5478e+03                  , pde-loss 6.5821e+03, initc-loss 2.2939e+04                    bc_loss 4.0698e+05\n",
      "Epoch 3950, Training-Loss 6.0269e+03, Data-loss 4.4590e+03                  , pde-loss 4.2719e+03, initc-loss 1.7820e+04                    bc_loss 1.3470e+05\n",
      "Epoch 3960, Training-Loss 3.4244e+03, Data-loss 2.7939e+03                  , pde-loss 7.4220e+02, initc-loss 1.9088e+04                    bc_loss 4.3219e+04\n",
      "Epoch 3970, Training-Loss 3.3083e+03, Data-loss 2.7276e+03                  , pde-loss 6.3600e+02, initc-loss 2.2196e+04                    bc_loss 3.5233e+04\n",
      "Epoch 3980, Training-Loss 4.2196e+03, Data-loss 2.6358e+03                  , pde-loss 1.8601e+03, initc-loss 1.5355e+04                    bc_loss 1.4117e+05\n",
      "Epoch 3990, Training-Loss 4.9409e+03, Data-loss 3.7898e+03                  , pde-loss 1.0368e+03, initc-loss 2.0591e+04                    bc_loss 9.3484e+04\n",
      "Epoch 4000, Training-Loss 3.0391e+03, Data-loss 2.3557e+03                  , pde-loss 1.8176e+03, initc-loss 1.7549e+04                    bc_loss 4.8971e+04\n",
      "Epoch 4010, Training-Loss 9.8945e+03, Data-loss 3.6791e+03                  , pde-loss 3.2088e+03, initc-loss 2.1713e+04                    bc_loss 5.9661e+05\n",
      "Epoch 4020, Training-Loss 8.7006e+03, Data-loss 6.7117e+03                  , pde-loss 5.1556e+03, initc-loss 1.5173e+04                    bc_loss 1.7856e+05\n",
      "Epoch 4030, Training-Loss 1.0578e+04, Data-loss 5.0478e+03                  , pde-loss 1.1934e+03, initc-loss 1.0034e+04                    bc_loss 5.4178e+05\n",
      "Epoch 4040, Training-Loss 9.9587e+03, Data-loss 6.0844e+03                  , pde-loss 7.7573e+02, initc-loss 1.4742e+04                    bc_loss 3.7191e+05\n",
      "Epoch 4050, Training-Loss 3.9305e+03, Data-loss 2.9289e+03                  , pde-loss 3.7143e+03, initc-loss 2.2038e+04                    bc_loss 7.4402e+04\n",
      "Epoch 4060, Training-Loss 3.5140e+03, Data-loss 2.5910e+03                  , pde-loss 3.3718e+03, initc-loss 1.7103e+04                    bc_loss 7.1831e+04\n",
      "Epoch 4070, Training-Loss 2.3958e+03, Data-loss 1.8685e+03                  , pde-loss 1.7928e+03, initc-loss 1.5333e+04                    bc_loss 3.5608e+04\n",
      "Epoch 4080, Training-Loss 3.7178e+03, Data-loss 2.3761e+03                  , pde-loss 1.8513e+03, initc-loss 1.4080e+04                    bc_loss 1.1824e+05\n",
      "Epoch 4090, Training-Loss 3.8661e+03, Data-loss 2.8606e+03                  , pde-loss 1.5477e+03, initc-loss 2.0014e+04                    bc_loss 7.8990e+04\n",
      "Epoch 4100, Training-Loss 1.0500e+04, Data-loss 9.1970e+03                  , pde-loss 1.5051e+03, initc-loss 3.8263e+04                    bc_loss 9.0480e+04\n",
      "Epoch 4110, Training-Loss 9.4454e+03, Data-loss 7.9857e+03                  , pde-loss 3.0030e+03, initc-loss 1.5939e+04                    bc_loss 1.2704e+05\n",
      "Epoch 4120, Training-Loss 4.9081e+03, Data-loss 4.1253e+03                  , pde-loss 8.0491e+02, initc-loss 1.4949e+04                    bc_loss 6.2526e+04\n",
      "Epoch 4130, Training-Loss 5.2531e+03, Data-loss 4.2424e+03                  , pde-loss 1.1890e+03, initc-loss 2.3170e+04                    bc_loss 7.6713e+04\n",
      "Epoch 4140, Training-Loss 3.6064e+03, Data-loss 2.6649e+03                  , pde-loss 2.9152e+03, initc-loss 2.3868e+04                    bc_loss 6.7366e+04\n",
      "Epoch 4150, Training-Loss 1.3494e+04, Data-loss 8.3892e+03                  , pde-loss 2.6501e+03, initc-loss 3.1469e+04                    bc_loss 4.7636e+05\n",
      "Epoch 4160, Training-Loss 9.7249e+03, Data-loss 8.0036e+03                  , pde-loss 1.6193e+03, initc-loss 1.1276e+04                    bc_loss 1.5924e+05\n",
      "Epoch 4170, Training-Loss 8.4388e+03, Data-loss 6.7537e+03                  , pde-loss 7.5719e+02, initc-loss 1.5998e+04                    bc_loss 1.5175e+05\n",
      "Epoch 4180, Training-Loss 5.4339e+03, Data-loss 4.0287e+03                  , pde-loss 1.8027e+03, initc-loss 2.5139e+04                    bc_loss 1.1358e+05\n",
      "Epoch 4190, Training-Loss 4.9909e+03, Data-loss 3.6913e+03                  , pde-loss 3.8093e+03, initc-loss 1.8142e+04                    bc_loss 1.0801e+05\n",
      "Epoch 4200, Training-Loss 4.3291e+03, Data-loss 2.1251e+03                  , pde-loss 2.7286e+03, initc-loss 1.0514e+04                    bc_loss 2.0716e+05\n",
      "Epoch 4210, Training-Loss 1.0039e+04, Data-loss 7.9699e+03                  , pde-loss 3.4868e+02, initc-loss 2.3638e+04                    bc_loss 1.8297e+05\n",
      "Epoch 4220, Training-Loss 4.7781e+03, Data-loss 3.3583e+03                  , pde-loss 7.3981e+02, initc-loss 1.7965e+04                    bc_loss 1.2327e+05\n",
      "Epoch 4230, Training-Loss 5.3772e+03, Data-loss 4.3157e+03                  , pde-loss 3.4154e+03, initc-loss 1.9818e+04                    bc_loss 8.2914e+04\n",
      "Epoch 4240, Training-Loss 2.3037e+03, Data-loss 1.6447e+03                  , pde-loss 2.0290e+03, initc-loss 1.7667e+04                    bc_loss 4.6207e+04\n",
      "Epoch 4250, Training-Loss 2.9278e+03, Data-loss 1.4037e+03                  , pde-loss 1.3449e+03, initc-loss 1.4908e+04                    bc_loss 1.3617e+05\n",
      "Epoch 4260, Training-Loss 4.4222e+03, Data-loss 3.0114e+03                  , pde-loss 7.6815e+02, initc-loss 1.7362e+04                    bc_loss 1.2294e+05\n",
      "Epoch 4270, Training-Loss 4.7508e+03, Data-loss 4.3624e+03                  , pde-loss 1.5361e+03, initc-loss 1.8329e+04                    bc_loss 1.8981e+04\n",
      "Epoch 4280, Training-Loss 3.2884e+03, Data-loss 2.6323e+03                  , pde-loss 3.4579e+03, initc-loss 1.5509e+04                    bc_loss 4.6641e+04\n",
      "Epoch 4290, Training-Loss 7.4074e+03, Data-loss 1.8192e+03                  , pde-loss 3.3806e+03, initc-loss 1.6982e+04                    bc_loss 5.3845e+05\n",
      "Epoch 4300, Training-Loss 6.1314e+03, Data-loss 3.8308e+03                  , pde-loss 4.9935e+03, initc-loss 1.3230e+04                    bc_loss 2.1184e+05\n",
      "Epoch 4310, Training-Loss 1.5160e+04, Data-loss 8.7094e+03                  , pde-loss 6.5467e+02, initc-loss 2.7065e+04                    bc_loss 6.1734e+05\n",
      "Epoch 4320, Training-Loss 7.7668e+03, Data-loss 4.1407e+03                  , pde-loss 3.9949e+02, initc-loss 1.5654e+04                    bc_loss 3.4656e+05\n",
      "Epoch 4330, Training-Loss 4.4116e+03, Data-loss 3.3320e+03                  , pde-loss 5.6040e+03, initc-loss 2.0820e+04                    bc_loss 8.1540e+04\n",
      "Epoch 4340, Training-Loss 3.3815e+03, Data-loss 2.9049e+03                  , pde-loss 2.5438e+03, initc-loss 1.5292e+04                    bc_loss 2.9831e+04\n",
      "Epoch 4350, Training-Loss 4.4806e+03, Data-loss 3.2372e+03                  , pde-loss 1.6308e+03, initc-loss 1.7976e+04                    bc_loss 1.0473e+05\n",
      "Epoch 4360, Training-Loss 7.7830e+03, Data-loss 4.5694e+03                  , pde-loss 2.9629e+03, initc-loss 1.8117e+04                    bc_loss 3.0028e+05\n",
      "Epoch 4370, Training-Loss 2.8359e+03, Data-loss 2.2725e+03                  , pde-loss 1.0822e+03, initc-loss 1.2694e+04                    bc_loss 4.2570e+04\n",
      "Epoch 4380, Training-Loss 6.8450e+03, Data-loss 3.4340e+03                  , pde-loss 3.3307e+02, initc-loss 2.1867e+04                    bc_loss 3.1889e+05\n",
      "Epoch 4390, Training-Loss 2.3932e+03, Data-loss 1.3897e+03                  , pde-loss 1.4355e+03, initc-loss 1.2961e+04                    bc_loss 8.5954e+04\n",
      "Epoch 4400, Training-Loss 2.9404e+03, Data-loss 2.1569e+03                  , pde-loss 2.6199e+03, initc-loss 1.2865e+04                    bc_loss 6.2862e+04\n",
      "Epoch 4410, Training-Loss 6.1099e+03, Data-loss 2.1268e+03                  , pde-loss 1.2492e+03, initc-loss 1.6427e+04                    bc_loss 3.8063e+05\n",
      "Epoch 4420, Training-Loss 6.0505e+03, Data-loss 3.6932e+03                  , pde-loss 3.8653e+02, initc-loss 1.7367e+04                    bc_loss 2.1798e+05\n",
      "Epoch 4430, Training-Loss 4.0648e+03, Data-loss 3.5006e+03                  , pde-loss 3.1939e+03, initc-loss 2.0836e+04                    bc_loss 3.2391e+04\n",
      "Epoch 4440, Training-Loss 3.6285e+03, Data-loss 3.1947e+03                  , pde-loss 2.8905e+03, initc-loss 1.9652e+04                    bc_loss 2.0842e+04\n",
      "Epoch 4450, Training-Loss 2.9092e+03, Data-loss 2.1579e+03                  , pde-loss 1.3193e+03, initc-loss 1.3377e+04                    bc_loss 6.0432e+04\n",
      "Epoch 4460, Training-Loss 1.1535e+04, Data-loss 6.8731e+03                  , pde-loss 2.5475e+03, initc-loss 2.9110e+04                    bc_loss 4.3453e+05\n",
      "Epoch 4470, Training-Loss 6.9642e+03, Data-loss 3.9266e+03                  , pde-loss 4.4701e+03, initc-loss 1.3259e+04                    bc_loss 2.8604e+05\n",
      "Epoch 4480, Training-Loss 9.6821e+03, Data-loss 4.1722e+03                  , pde-loss 4.1141e+02, initc-loss 1.6660e+04                    bc_loss 5.3392e+05\n",
      "Epoch 4490, Training-Loss 8.1720e+03, Data-loss 5.7971e+03                  , pde-loss 5.7193e+02, initc-loss 2.1703e+04                    bc_loss 2.1522e+05\n",
      "Epoch 4500, Training-Loss 5.9583e+03, Data-loss 4.3752e+03                  , pde-loss 4.3191e+03, initc-loss 1.9942e+04                    bc_loss 1.3404e+05\n",
      "Epoch 4510, Training-Loss 4.8372e+03, Data-loss 4.1296e+03                  , pde-loss 5.1308e+03, initc-loss 2.1025e+04                    bc_loss 4.4612e+04\n",
      "Epoch 4520, Training-Loss 3.2047e+03, Data-loss 2.4583e+03                  , pde-loss 1.8020e+03, initc-loss 1.3697e+04                    bc_loss 5.9134e+04\n",
      "Epoch 4530, Training-Loss 3.5744e+03, Data-loss 2.9429e+03                  , pde-loss 4.9873e+02, initc-loss 1.7971e+04                    bc_loss 4.4677e+04\n",
      "Epoch 4540, Training-Loss 4.6567e+03, Data-loss 2.6960e+03                  , pde-loss 1.0511e+03, initc-loss 1.6623e+04                    bc_loss 1.7839e+05\n",
      "Epoch 4550, Training-Loss 6.5429e+03, Data-loss 2.7447e+03                  , pde-loss 2.8310e+03, initc-loss 2.1091e+04                    bc_loss 3.5590e+05\n",
      "Epoch 4560, Training-Loss 3.0647e+03, Data-loss 2.0377e+03                  , pde-loss 3.7540e+03, initc-loss 1.6287e+04                    bc_loss 8.2654e+04\n",
      "Epoch 4570, Training-Loss 9.9506e+03, Data-loss 6.9399e+03                  , pde-loss 4.1965e+02, initc-loss 2.5223e+04                    bc_loss 2.7544e+05\n",
      "Epoch 4580, Training-Loss 7.6235e+03, Data-loss 4.6507e+03                  , pde-loss 5.3351e+02, initc-loss 2.0515e+04                    bc_loss 2.7623e+05\n",
      "Epoch 4590, Training-Loss 5.3870e+03, Data-loss 4.3238e+03                  , pde-loss 4.8227e+03, initc-loss 2.0988e+04                    bc_loss 8.0510e+04\n",
      "Epoch 4600, Training-Loss 5.4759e+03, Data-loss 2.6807e+03                  , pde-loss 3.6746e+03, initc-loss 2.0070e+04                    bc_loss 2.5578e+05\n",
      "Epoch 4610, Training-Loss 3.4972e+03, Data-loss 2.5045e+03                  , pde-loss 2.0422e+03, initc-loss 1.4776e+04                    bc_loss 8.2454e+04\n",
      "Epoch 4620, Training-Loss 7.4346e+03, Data-loss 3.0686e+03                  , pde-loss 8.4823e+02, initc-loss 1.0314e+04                    bc_loss 4.2544e+05\n",
      "Epoch 4630, Training-Loss 6.0196e+03, Data-loss 4.3924e+03                  , pde-loss 7.1622e+02, initc-loss 2.0597e+04                    bc_loss 1.4140e+05\n",
      "Epoch 4640, Training-Loss 2.9127e+03, Data-loss 2.2521e+03                  , pde-loss 2.3475e+03, initc-loss 2.0074e+04                    bc_loss 4.3638e+04\n",
      "Epoch 4650, Training-Loss 2.0290e+03, Data-loss 1.1006e+03                  , pde-loss 2.2270e+03, initc-loss 1.6326e+04                    bc_loss 7.4289e+04\n",
      "Epoch 4660, Training-Loss 8.1167e+03, Data-loss 4.0314e+03                  , pde-loss 9.8452e+02, initc-loss 1.9138e+04                    bc_loss 3.8841e+05\n",
      "Epoch 4670, Training-Loss 7.9825e+03, Data-loss 3.7782e+03                  , pde-loss 1.3199e+03, initc-loss 9.7282e+03                    bc_loss 4.0938e+05\n",
      "Epoch 4680, Training-Loss 3.8173e+03, Data-loss 2.3259e+03                  , pde-loss 6.8589e+03, initc-loss 1.9009e+04                    bc_loss 1.2328e+05\n",
      "Epoch 4690, Training-Loss 3.0170e+03, Data-loss 2.4171e+03                  , pde-loss 3.4026e+03, initc-loss 1.3065e+04                    bc_loss 4.3523e+04\n",
      "Epoch 4700, Training-Loss 3.9990e+03, Data-loss 3.4087e+03                  , pde-loss 9.9232e+02, initc-loss 1.7210e+04                    bc_loss 4.0828e+04\n",
      "Epoch 4710, Training-Loss 4.9014e+03, Data-loss 2.9116e+03                  , pde-loss 7.7149e+02, initc-loss 1.9639e+04                    bc_loss 1.7858e+05\n",
      "Epoch 4720, Training-Loss 1.9142e+03, Data-loss 1.5101e+03                  , pde-loss 1.0109e+03, initc-loss 1.3704e+04                    bc_loss 2.5697e+04\n",
      "Epoch 4730, Training-Loss 2.6637e+03, Data-loss 2.2522e+03                  , pde-loss 2.1815e+03, initc-loss 1.4337e+04                    bc_loss 2.4630e+04\n",
      "Epoch 4740, Training-Loss 2.9733e+03, Data-loss 1.7017e+03                  , pde-loss 1.8616e+03, initc-loss 1.4440e+04                    bc_loss 1.1086e+05\n",
      "Epoch 4750, Training-Loss 7.2124e+03, Data-loss 4.5358e+03                  , pde-loss 1.2761e+03, initc-loss 2.5534e+04                    bc_loss 2.4084e+05\n",
      "Epoch 4760, Training-Loss 3.3322e+03, Data-loss 2.0852e+03                  , pde-loss 1.7970e+03, initc-loss 1.7912e+04                    bc_loss 1.0499e+05\n",
      "Epoch 4770, Training-Loss 9.5325e+03, Data-loss 5.5504e+03                  , pde-loss 6.4378e+03, initc-loss 3.0284e+04                    bc_loss 3.6149e+05\n",
      "Epoch 4780, Training-Loss 5.5487e+03, Data-loss 3.2684e+03                  , pde-loss 4.5804e+03, initc-loss 1.3694e+04                    bc_loss 2.0976e+05\n",
      "Epoch 4790, Training-Loss 7.1293e+03, Data-loss 6.2337e+03                  , pde-loss 4.8784e+02, initc-loss 1.9639e+04                    bc_loss 6.9438e+04\n",
      "Epoch 4800, Training-Loss 5.6213e+03, Data-loss 3.1639e+03                  , pde-loss 7.2011e+02, initc-loss 1.4680e+04                    bc_loss 2.3034e+05\n",
      "Epoch 4810, Training-Loss 5.3245e+03, Data-loss 3.2790e+03                  , pde-loss 2.9399e+03, initc-loss 9.2842e+03                    bc_loss 1.9232e+05\n",
      "Epoch 4820, Training-Loss 3.7510e+03, Data-loss 2.2181e+03                  , pde-loss 4.0925e+03, initc-loss 1.2334e+04                    bc_loss 1.3687e+05\n",
      "Epoch 4830, Training-Loss 2.5085e+03, Data-loss 1.8942e+03                  , pde-loss 6.5285e+02, initc-loss 1.8274e+04                    bc_loss 4.2500e+04\n",
      "Epoch 4840, Training-Loss 5.1959e+03, Data-loss 1.3826e+03                  , pde-loss 7.7892e+02, initc-loss 1.7330e+04                    bc_loss 3.6322e+05\n",
      "Epoch 4850, Training-Loss 2.1319e+03, Data-loss 1.4813e+03                  , pde-loss 1.2533e+03, initc-loss 1.4862e+04                    bc_loss 4.8943e+04\n",
      "Epoch 4860, Training-Loss 1.6782e+03, Data-loss 1.3073e+03                  , pde-loss 2.0567e+03, initc-loss 1.5246e+04                    bc_loss 1.9782e+04\n",
      "Epoch 4870, Training-Loss 2.5329e+03, Data-loss 1.4060e+03                  , pde-loss 2.2729e+03, initc-loss 1.8249e+04                    bc_loss 9.2174e+04\n",
      "Epoch 4880, Training-Loss 1.2799e+04, Data-loss 8.8947e+03                  , pde-loss 4.6245e+03, initc-loss 3.4443e+04                    bc_loss 3.5140e+05\n",
      "Epoch 4890, Training-Loss 6.8082e+03, Data-loss 4.8870e+03                  , pde-loss 3.4731e+03, initc-loss 1.4165e+04                    bc_loss 1.7448e+05\n",
      "Epoch 4900, Training-Loss 8.1039e+03, Data-loss 3.4953e+03                  , pde-loss 4.2756e+02, initc-loss 1.5980e+04                    bc_loss 4.4445e+05\n",
      "Epoch 4910, Training-Loss 5.9486e+03, Data-loss 3.5101e+03                  , pde-loss 1.8393e+02, initc-loss 1.1364e+04                    bc_loss 2.3230e+05\n",
      "Epoch 4920, Training-Loss 2.4734e+03, Data-loss 1.4887e+03                  , pde-loss 2.6780e+03, initc-loss 1.8952e+04                    bc_loss 7.6835e+04\n",
      "Epoch 4930, Training-Loss 4.0931e+03, Data-loss 3.6113e+03                  , pde-loss 3.2393e+03, initc-loss 1.4984e+04                    bc_loss 2.9959e+04\n",
      "Epoch 4940, Training-Loss 2.1143e+03, Data-loss 1.5918e+03                  , pde-loss 1.5167e+03, initc-loss 1.5168e+04                    bc_loss 3.5561e+04\n",
      "Epoch 4950, Training-Loss 2.0581e+03, Data-loss 1.6200e+03                  , pde-loss 1.0881e+03, initc-loss 1.7670e+04                    bc_loss 2.5055e+04\n",
      "Epoch 4960, Training-Loss 8.1842e+03, Data-loss 3.2636e+03                  , pde-loss 5.1259e+02, initc-loss 2.2552e+04                    bc_loss 4.6900e+05\n",
      "Epoch 4970, Training-Loss 4.1577e+03, Data-loss 2.7683e+03                  , pde-loss 1.3752e+03, initc-loss 6.6006e+03                    bc_loss 1.3096e+05\n",
      "Epoch 4980, Training-Loss 7.9667e+03, Data-loss 3.6165e+03                  , pde-loss 6.0128e+03, initc-loss 1.7847e+04                    bc_loss 4.1116e+05\n",
      "Epoch 4990, Training-Loss 5.9888e+03, Data-loss 2.4842e+03                  , pde-loss 3.5088e+03, initc-loss 1.3516e+04                    bc_loss 3.3343e+05\n",
      "Epoch 5000, Training-Loss 4.0605e+03, Data-loss 2.7252e+03                  , pde-loss 6.3811e+02, initc-loss 1.9041e+04                    bc_loss 1.1385e+05\n",
      "Epoch 5010, Training-Loss 2.2341e+03, Data-loss 9.8477e+02                  , pde-loss 1.7974e+03, initc-loss 1.7271e+04                    bc_loss 1.0587e+05\n",
      "Epoch 5020, Training-Loss 2.6269e+03, Data-loss 1.7357e+03                  , pde-loss 1.2490e+03, initc-loss 1.7190e+04                    bc_loss 7.0686e+04\n",
      "Epoch 5030, Training-Loss 1.2055e+04, Data-loss 4.9552e+03                  , pde-loss 3.9235e+02, initc-loss 2.3359e+04                    bc_loss 6.8622e+05\n",
      "Epoch 5040, Training-Loss 5.7141e+03, Data-loss 3.8181e+03                  , pde-loss 8.1819e+02, initc-loss 1.3131e+04                    bc_loss 1.7565e+05\n",
      "Epoch 5050, Training-Loss 3.4232e+03, Data-loss 1.7785e+03                  , pde-loss 4.0130e+03, initc-loss 1.5483e+04                    bc_loss 1.4497e+05\n",
      "Epoch 5060, Training-Loss 2.6582e+03, Data-loss 1.8419e+03                  , pde-loss 1.4974e+03, initc-loss 1.4527e+04                    bc_loss 6.5604e+04\n",
      "Epoch 5070, Training-Loss 2.3633e+03, Data-loss 1.8079e+03                  , pde-loss 1.3559e+03, initc-loss 1.2864e+04                    bc_loss 4.1319e+04\n",
      "Epoch 5080, Training-Loss 1.3462e+04, Data-loss 2.1368e+03                  , pde-loss 2.2553e+03, initc-loss 2.0371e+04                    bc_loss 1.1099e+06\n",
      "Epoch 5090, Training-Loss 9.8229e+03, Data-loss 4.9570e+03                  , pde-loss 5.6725e+03, initc-loss 1.2580e+04                    bc_loss 4.6835e+05\n",
      "Epoch 5100, Training-Loss 5.7582e+03, Data-loss 2.9467e+03                  , pde-loss 7.7183e+02, initc-loss 1.9482e+04                    bc_loss 2.6090e+05\n",
      "Epoch 5110, Training-Loss 8.3035e+03, Data-loss 4.4147e+03                  , pde-loss 3.7240e+02, initc-loss 2.2132e+04                    bc_loss 3.6638e+05\n",
      "Epoch 5120, Training-Loss 5.4700e+03, Data-loss 4.3449e+03                  , pde-loss 2.0388e+03, initc-loss 1.6369e+04                    bc_loss 9.4103e+04\n",
      "Epoch 5130, Training-Loss 3.2237e+03, Data-loss 2.5395e+03                  , pde-loss 2.1534e+03, initc-loss 1.3682e+04                    bc_loss 5.2581e+04\n",
      "Epoch 5140, Training-Loss 2.8557e+03, Data-loss 2.0246e+03                  , pde-loss 1.1910e+03, initc-loss 1.5006e+04                    bc_loss 6.6917e+04\n",
      "Epoch 5150, Training-Loss 2.7343e+03, Data-loss 2.3065e+03                  , pde-loss 2.0638e+03, initc-loss 1.4340e+04                    bc_loss 2.6374e+04\n",
      "Epoch 5160, Training-Loss 1.1295e+04, Data-loss 3.1954e+03                  , pde-loss 1.2438e+03, initc-loss 2.3585e+04                    bc_loss 7.8514e+05\n",
      "Epoch 5170, Training-Loss 8.0817e+03, Data-loss 5.7330e+03                  , pde-loss 4.5912e+02, initc-loss 1.0830e+04                    bc_loss 2.2358e+05\n",
      "Epoch 5180, Training-Loss 3.6292e+03, Data-loss 2.5205e+03                  , pde-loss 1.9546e+03, initc-loss 1.2593e+04                    bc_loss 9.6318e+04\n",
      "Epoch 5190, Training-Loss 3.7822e+03, Data-loss 3.2810e+03                  , pde-loss 3.3867e+03, initc-loss 1.7986e+04                    bc_loss 2.8743e+04\n",
      "Epoch 5200, Training-Loss 1.7725e+03, Data-loss 1.3273e+03                  , pde-loss 1.5198e+03, initc-loss 1.5153e+04                    bc_loss 2.7851e+04\n",
      "Epoch 5210, Training-Loss 2.5173e+03, Data-loss 9.7208e+02                  , pde-loss 1.2227e+03, initc-loss 1.3675e+04                    bc_loss 1.3962e+05\n",
      "Epoch 5220, Training-Loss 2.6400e+04, Data-loss 7.6597e+03                  , pde-loss 9.5190e+02, initc-loss 3.2050e+04                    bc_loss 1.8410e+06\n",
      "Epoch 5230, Training-Loss 1.6379e+04, Data-loss 1.4827e+04                  , pde-loss 1.0453e+03, initc-loss 1.3643e+04                    bc_loss 1.4055e+05\n",
      "Epoch 5240, Training-Loss 9.0231e+03, Data-loss 6.8717e+03                  , pde-loss 2.1606e+03, initc-loss 2.0789e+04                    bc_loss 1.9219e+05\n",
      "Epoch 5250, Training-Loss 5.3371e+03, Data-loss 3.4596e+03                  , pde-loss 1.2107e+03, initc-loss 2.1255e+04                    bc_loss 1.6528e+05\n",
      "Epoch 5260, Training-Loss 3.1787e+03, Data-loss 2.6572e+03                  , pde-loss 8.6603e+02, initc-loss 1.9898e+04                    bc_loss 3.1389e+04\n",
      "Epoch 5270, Training-Loss 3.3410e+03, Data-loss 2.5460e+03                  , pde-loss 2.1073e+03, initc-loss 2.2522e+04                    bc_loss 5.4871e+04\n",
      "Epoch 5280, Training-Loss 2.0088e+04, Data-loss 7.9649e+03                  , pde-loss 1.9654e+03, initc-loss 3.6273e+04                    bc_loss 1.1740e+06\n",
      "Epoch 5290, Training-Loss 1.4278e+04, Data-loss 1.2878e+04                  , pde-loss 2.2710e+03, initc-loss 6.4593e+03                    bc_loss 1.3132e+05\n",
      "Epoch 5300, Training-Loss 7.4694e+03, Data-loss 4.4965e+03                  , pde-loss 1.4193e+03, initc-loss 1.4223e+04                    bc_loss 2.8165e+05\n",
      "Epoch 5310, Training-Loss 4.3893e+03, Data-loss 4.0594e+03                  , pde-loss 1.4682e+03, initc-loss 2.1834e+04                    bc_loss 9.6837e+03\n",
      "Epoch 5320, Training-Loss 6.4244e+03, Data-loss 3.9080e+03                  , pde-loss 1.4637e+03, initc-loss 2.5570e+04                    bc_loss 2.2461e+05\n",
      "Epoch 5330, Training-Loss 5.2482e+03, Data-loss 4.0702e+03                  , pde-loss 7.8624e+02, initc-loss 1.9087e+04                    bc_loss 9.7930e+04\n",
      "Epoch 5340, Training-Loss 6.8769e+03, Data-loss 4.3413e+03                  , pde-loss 2.0451e+03, initc-loss 1.3643e+04                    bc_loss 2.3787e+05\n",
      "Epoch 5350, Training-Loss 6.6334e+03, Data-loss 4.5838e+03                  , pde-loss 5.3982e+03, initc-loss 2.5088e+04                    bc_loss 1.7448e+05\n",
      "Epoch 5360, Training-Loss 4.4265e+03, Data-loss 2.0090e+03                  , pde-loss 2.3791e+03, initc-loss 1.7053e+04                    bc_loss 2.2232e+05\n",
      "Epoch 5370, Training-Loss 6.0502e+03, Data-loss 3.6835e+03                  , pde-loss 5.5133e+02, initc-loss 1.6729e+04                    bc_loss 2.1938e+05\n",
      "Epoch 5380, Training-Loss 6.0407e+03, Data-loss 3.1791e+03                  , pde-loss 9.4760e+02, initc-loss 1.3270e+04                    bc_loss 2.7194e+05\n",
      "Epoch 5390, Training-Loss 4.9781e+03, Data-loss 3.2342e+03                  , pde-loss 4.4140e+03, initc-loss 2.0712e+04                    bc_loss 1.4926e+05\n",
      "Epoch 5400, Training-Loss 1.9337e+03, Data-loss 1.6756e+03                  , pde-loss 1.9314e+03, initc-loss 1.2645e+04                    bc_loss 1.1233e+04\n",
      "Epoch 5410, Training-Loss 2.1147e+03, Data-loss 1.5964e+03                  , pde-loss 1.0421e+03, initc-loss 1.6832e+04                    bc_loss 3.3958e+04\n",
      "Epoch 5420, Training-Loss 2.3067e+03, Data-loss 2.1277e+03                  , pde-loss 1.3906e+03, initc-loss 1.3267e+04                    bc_loss 3.2385e+03\n",
      "Epoch 5430, Training-Loss 2.8039e+03, Data-loss 1.9931e+03                  , pde-loss 1.5832e+03, initc-loss 1.4941e+04                    bc_loss 6.4552e+04\n",
      "Epoch 5440, Training-Loss 9.3676e+03, Data-loss 1.3599e+03                  , pde-loss 8.6354e+02, initc-loss 2.1284e+04                    bc_loss 7.7862e+05\n",
      "Epoch 5450, Training-Loss 6.4433e+03, Data-loss 4.9782e+03                  , pde-loss 5.4813e+02, initc-loss 1.5182e+04                    bc_loss 1.3078e+05\n",
      "Epoch 5460, Training-Loss 5.0135e+03, Data-loss 4.0092e+03                  , pde-loss 2.6290e+03, initc-loss 1.4127e+04                    bc_loss 8.3672e+04\n",
      "Epoch 5470, Training-Loss 9.2748e+03, Data-loss 4.6803e+03                  , pde-loss 3.9208e+03, initc-loss 2.0401e+04                    bc_loss 4.3513e+05\n",
      "Epoch 5480, Training-Loss 3.7527e+03, Data-loss 2.2834e+03                  , pde-loss 1.6105e+03, initc-loss 1.3516e+04                    bc_loss 1.3181e+05\n",
      "Epoch 5490, Training-Loss 8.7980e+03, Data-loss 4.2911e+03                  , pde-loss 4.8800e+02, initc-loss 1.8320e+04                    bc_loss 4.3188e+05\n",
      "Epoch 5500, Training-Loss 7.2586e+03, Data-loss 2.8542e+03                  , pde-loss 8.0293e+02, initc-loss 9.2131e+03                    bc_loss 4.3043e+05\n",
      "Epoch 5510, Training-Loss 4.2875e+03, Data-loss 3.3767e+03                  , pde-loss 4.9779e+03, initc-loss 2.2280e+04                    bc_loss 6.3824e+04\n",
      "Epoch 5520, Training-Loss 2.8280e+03, Data-loss 2.3114e+03                  , pde-loss 2.5041e+03, initc-loss 1.5900e+04                    bc_loss 3.3262e+04\n",
      "Epoch 5530, Training-Loss 2.4352e+03, Data-loss 2.1974e+03                  , pde-loss 1.2849e+03, initc-loss 1.1635e+04                    bc_loss 1.0855e+04\n",
      "Epoch 5540, Training-Loss 2.0880e+03, Data-loss 1.1986e+03                  , pde-loss 1.3561e+03, initc-loss 1.4309e+04                    bc_loss 7.3276e+04\n",
      "Epoch 5550, Training-Loss 5.5760e+03, Data-loss 9.7178e+02                  , pde-loss 9.3361e+02, initc-loss 1.5037e+04                    bc_loss 4.4445e+05\n",
      "Epoch 5560, Training-Loss 1.8813e+04, Data-loss 1.7166e+04                  , pde-loss 6.5810e+02, initc-loss 5.6002e+04                    bc_loss 1.0810e+05\n",
      "Epoch 5570, Training-Loss 9.0232e+03, Data-loss 8.0426e+03                  , pde-loss 1.2984e+03, initc-loss 1.4088e+04                    bc_loss 8.2673e+04\n",
      "Epoch 5580, Training-Loss 3.8478e+03, Data-loss 2.3855e+03                  , pde-loss 1.5629e+03, initc-loss 1.1747e+04                    bc_loss 1.3292e+05\n",
      "Epoch 5590, Training-Loss 3.7018e+03, Data-loss 2.7642e+03                  , pde-loss 2.3178e+03, initc-loss 1.9432e+04                    bc_loss 7.2011e+04\n",
      "Epoch 5600, Training-Loss 2.8873e+03, Data-loss 1.8892e+03                  , pde-loss 2.3743e+03, initc-loss 1.8514e+04                    bc_loss 7.8924e+04\n",
      "Epoch 5610, Training-Loss 8.8379e+03, Data-loss 7.2274e+03                  , pde-loss 1.2669e+03, initc-loss 3.2292e+04                    bc_loss 1.2749e+05\n",
      "Epoch 5620, Training-Loss 1.2723e+04, Data-loss 7.3560e+03                  , pde-loss 1.1579e+03, initc-loss 2.2168e+04                    bc_loss 5.1341e+05\n",
      "Epoch 5630, Training-Loss 1.0679e+04, Data-loss 9.5629e+03                  , pde-loss 2.5531e+03, initc-loss 1.8279e+04                    bc_loss 9.0794e+04\n",
      "Epoch 5640, Training-Loss 6.2795e+03, Data-loss 4.5851e+03                  , pde-loss 1.7018e+03, initc-loss 1.0415e+04                    bc_loss 1.5733e+05\n",
      "Epoch 5650, Training-Loss 7.4324e+03, Data-loss 3.9922e+03                  , pde-loss 3.9824e+02, initc-loss 2.4888e+04                    bc_loss 3.1873e+05\n",
      "Epoch 5660, Training-Loss 4.3665e+03, Data-loss 3.1679e+03                  , pde-loss 1.2106e+03, initc-loss 1.6233e+04                    bc_loss 1.0242e+05\n",
      "Epoch 5670, Training-Loss 3.8062e+03, Data-loss 3.1386e+03                  , pde-loss 4.3132e+03, initc-loss 2.1026e+04                    bc_loss 4.1416e+04\n",
      "Epoch 5680, Training-Loss 3.5715e+03, Data-loss 3.1409e+03                  , pde-loss 2.1999e+03, initc-loss 1.3990e+04                    bc_loss 2.6872e+04\n",
      "Epoch 5690, Training-Loss 7.5322e+03, Data-loss 2.5196e+03                  , pde-loss 7.7948e+02, initc-loss 2.0482e+04                    bc_loss 4.8000e+05\n",
      "Epoch 5700, Training-Loss 9.0975e+03, Data-loss 6.3942e+03                  , pde-loss 5.0640e+02, initc-loss 1.2639e+04                    bc_loss 2.5718e+05\n",
      "Epoch 5710, Training-Loss 5.8823e+03, Data-loss 3.9765e+03                  , pde-loss 3.2162e+03, initc-loss 2.1605e+04                    bc_loss 1.6576e+05\n",
      "Epoch 5720, Training-Loss 8.0353e+03, Data-loss 5.2663e+03                  , pde-loss 5.8550e+03, initc-loss 2.1307e+04                    bc_loss 2.4973e+05\n",
      "Epoch 5730, Training-Loss 5.5676e+03, Data-loss 4.2993e+03                  , pde-loss 1.0838e+03, initc-loss 9.2153e+03                    bc_loss 1.1653e+05\n",
      "Epoch 5740, Training-Loss 5.9691e+03, Data-loss 3.9324e+03                  , pde-loss 4.7470e+02, initc-loss 2.0698e+04                    bc_loss 1.8250e+05\n",
      "Epoch 5750, Training-Loss 2.2011e+03, Data-loss 1.6320e+03                  , pde-loss 1.4324e+03, initc-loss 1.8733e+04                    bc_loss 3.6751e+04\n",
      "Epoch 5760, Training-Loss 2.6816e+03, Data-loss 2.0615e+03                  , pde-loss 2.1884e+03, initc-loss 1.6564e+04                    bc_loss 4.3255e+04\n",
      "Epoch 5770, Training-Loss 6.1249e+03, Data-loss 2.6785e+03                  , pde-loss 7.3448e+02, initc-loss 1.7272e+04                    bc_loss 3.2663e+05\n",
      "Epoch 5780, Training-Loss 4.3569e+03, Data-loss 3.3808e+03                  , pde-loss 8.2542e+02, initc-loss 1.4302e+04                    bc_loss 8.2482e+04\n",
      "Epoch 5790, Training-Loss 3.3507e+03, Data-loss 2.8100e+03                  , pde-loss 2.3978e+03, initc-loss 1.7442e+04                    bc_loss 3.4232e+04\n",
      "Epoch 5800, Training-Loss 2.5152e+03, Data-loss 1.8158e+03                  , pde-loss 2.3624e+03, initc-loss 1.6753e+04                    bc_loss 5.0828e+04\n",
      "Epoch 5810, Training-Loss 7.7093e+03, Data-loss 2.1333e+03                  , pde-loss 1.1150e+03, initc-loss 1.8563e+04                    bc_loss 5.3792e+05\n",
      "Epoch 5820, Training-Loss 9.2344e+03, Data-loss 6.5032e+03                  , pde-loss 5.6866e+02, initc-loss 2.0748e+04                    bc_loss 2.5181e+05\n",
      "Epoch 5830, Training-Loss 6.5277e+03, Data-loss 4.0324e+03                  , pde-loss 3.2353e+03, initc-loss 1.3463e+04                    bc_loss 2.3283e+05\n",
      "Epoch 5840, Training-Loss 1.0081e+04, Data-loss 5.3071e+03                  , pde-loss 5.9837e+03, initc-loss 2.2978e+04                    bc_loss 4.4841e+05\n",
      "Epoch 5850, Training-Loss 3.7258e+03, Data-loss 2.8456e+03                  , pde-loss 9.3815e+02, initc-loss 1.2305e+04                    bc_loss 7.4776e+04\n",
      "Epoch 5860, Training-Loss 1.9844e+03, Data-loss 1.3664e+03                  , pde-loss 1.3296e+03, initc-loss 1.2032e+04                    bc_loss 4.8433e+04\n",
      "Epoch 5870, Training-Loss 1.9823e+03, Data-loss 1.4606e+03                  , pde-loss 1.5394e+03, initc-loss 1.3118e+04                    bc_loss 3.7521e+04\n",
      "Epoch 5880, Training-Loss 2.6952e+03, Data-loss 1.2209e+03                  , pde-loss 9.3024e+02, initc-loss 1.6448e+04                    bc_loss 1.3005e+05\n",
      "Epoch 5890, Training-Loss 2.0968e+03, Data-loss 1.5688e+03                  , pde-loss 1.1902e+03, initc-loss 1.5422e+04                    bc_loss 3.6189e+04\n",
      "Epoch 5900, Training-Loss 2.8933e+03, Data-loss 1.2684e+03                  , pde-loss 1.8319e+03, initc-loss 1.8121e+04                    bc_loss 1.4254e+05\n",
      "Epoch 5910, Training-Loss 2.7863e+03, Data-loss 1.9126e+03                  , pde-loss 1.2296e+03, initc-loss 1.3259e+04                    bc_loss 7.2878e+04\n",
      "Epoch 5920, Training-Loss 2.4920e+03, Data-loss 2.1705e+03                  , pde-loss 2.1391e+03, initc-loss 1.5130e+04                    bc_loss 1.4884e+04\n",
      "Epoch 5930, Training-Loss 6.2744e+03, Data-loss 1.8345e+03                  , pde-loss 1.4762e+03, initc-loss 1.8800e+04                    bc_loss 4.2371e+05\n",
      "Epoch 5940, Training-Loss 6.1632e+03, Data-loss 3.3223e+03                  , pde-loss 6.1831e+02, initc-loss 2.1367e+04                    bc_loss 2.6210e+05\n",
      "Epoch 5950, Training-Loss 3.5325e+03, Data-loss 2.8450e+03                  , pde-loss 1.5402e+03, initc-loss 1.6930e+04                    bc_loss 5.0279e+04\n",
      "Epoch 5960, Training-Loss 4.7518e+03, Data-loss 3.4627e+03                  , pde-loss 2.9981e+03, initc-loss 1.6032e+04                    bc_loss 1.0988e+05\n",
      "Epoch 5970, Training-Loss 2.3959e+03, Data-loss 1.3055e+03                  , pde-loss 1.5163e+03, initc-loss 1.1618e+04                    bc_loss 9.5901e+04\n",
      "Epoch 5980, Training-Loss 1.0093e+04, Data-loss 4.5459e+03                  , pde-loss 6.6365e+02, initc-loss 2.2651e+04                    bc_loss 5.3140e+05\n",
      "Epoch 5990, Training-Loss 5.5700e+03, Data-loss 2.0560e+03                  , pde-loss 1.3546e+03, initc-loss 6.7792e+03                    bc_loss 3.4327e+05\n",
      "Epoch 6000, Training-Loss 5.1365e+03, Data-loss 3.4677e+03                  , pde-loss 6.6458e+03, initc-loss 1.8706e+04                    bc_loss 1.4153e+05\n",
      "Epoch 6010, Training-Loss 3.3127e+03, Data-loss 2.2842e+03                  , pde-loss 3.1089e+03, initc-loss 1.4962e+04                    bc_loss 8.4782e+04\n",
      "Epoch 6020, Training-Loss 3.0295e+03, Data-loss 2.6319e+03                  , pde-loss 1.1784e+03, initc-loss 1.7694e+04                    bc_loss 2.0882e+04\n",
      "Epoch 6030, Training-Loss 2.2143e+03, Data-loss 1.6932e+03                  , pde-loss 1.2997e+03, initc-loss 1.6157e+04                    bc_loss 3.4652e+04\n",
      "Epoch 6040, Training-Loss 1.7371e+03, Data-loss 1.1403e+03                  , pde-loss 1.2803e+03, initc-loss 1.3159e+04                    bc_loss 4.5236e+04\n",
      "Epoch 6050, Training-Loss 1.8285e+03, Data-loss 1.2943e+03                  , pde-loss 1.6505e+03, initc-loss 1.4796e+04                    bc_loss 3.6970e+04\n",
      "Epoch 6060, Training-Loss 2.3480e+03, Data-loss 1.5933e+03                  , pde-loss 2.3469e+03, initc-loss 1.5754e+04                    bc_loss 5.7366e+04\n",
      "Epoch 6070, Training-Loss 1.3127e+04, Data-loss 7.5664e+03                  , pde-loss 1.2661e+03, initc-loss 4.1872e+04                    bc_loss 5.1292e+05\n",
      "Epoch 6080, Training-Loss 1.0459e+04, Data-loss 9.6435e+03                  , pde-loss 1.0004e+03, initc-loss 1.8979e+04                    bc_loss 6.1566e+04\n",
      "Epoch 6090, Training-Loss 9.1968e+03, Data-loss 6.9087e+03                  , pde-loss 1.7415e+03, initc-loss 2.3048e+04                    bc_loss 2.0403e+05\n",
      "Epoch 6100, Training-Loss 3.3521e+03, Data-loss 2.4794e+03                  , pde-loss 2.0065e+03, initc-loss 1.8457e+04                    bc_loss 6.6806e+04\n",
      "Epoch 6110, Training-Loss 4.2881e+03, Data-loss 2.2647e+03                  , pde-loss 1.2210e+03, initc-loss 1.5690e+04                    bc_loss 1.8542e+05\n",
      "Epoch 6120, Training-Loss 1.2765e+04, Data-loss 4.9131e+03                  , pde-loss 1.0756e+03, initc-loss 1.5949e+04                    bc_loss 7.6817e+05\n",
      "Epoch 6130, Training-Loss 6.9690e+03, Data-loss 5.3803e+03                  , pde-loss 7.0201e+02, initc-loss 1.8449e+04                    bc_loss 1.3971e+05\n",
      "Epoch 6140, Training-Loss 4.0965e+03, Data-loss 3.5795e+03                  , pde-loss 3.1334e+03, initc-loss 1.3196e+04                    bc_loss 3.5364e+04\n",
      "Epoch 6150, Training-Loss 5.7505e+03, Data-loss 3.3921e+03                  , pde-loss 4.9354e+03, initc-loss 2.2730e+04                    bc_loss 2.0817e+05\n",
      "Epoch 6160, Training-Loss 2.0620e+03, Data-loss 1.5366e+03                  , pde-loss 9.7769e+02, initc-loss 1.5286e+04                    bc_loss 3.6275e+04\n",
      "Epoch 6170, Training-Loss 3.5280e+03, Data-loss 2.3433e+03                  , pde-loss 8.0453e+02, initc-loss 1.4718e+04                    bc_loss 1.0294e+05\n",
      "Epoch 6180, Training-Loss 3.0816e+03, Data-loss 2.4205e+03                  , pde-loss 1.4037e+03, initc-loss 1.3031e+04                    bc_loss 5.1676e+04\n",
      "Epoch 6190, Training-Loss 1.0264e+04, Data-loss 2.8137e+03                  , pde-loss 7.8981e+02, initc-loss 2.3806e+04                    bc_loss 7.2044e+05\n",
      "Epoch 6200, Training-Loss 6.8277e+03, Data-loss 3.6165e+03                  , pde-loss 8.4957e+02, initc-loss 2.0695e+04                    bc_loss 2.9957e+05\n",
      "Epoch 6210, Training-Loss 6.5076e+03, Data-loss 2.9122e+03                  , pde-loss 3.7909e+03, initc-loss 1.5673e+04                    bc_loss 3.4007e+05\n",
      "Epoch 6220, Training-Loss 6.0698e+03, Data-loss 2.8150e+03                  , pde-loss 3.8901e+03, initc-loss 1.8509e+04                    bc_loss 3.0308e+05\n",
      "Epoch 6230, Training-Loss 4.2028e+03, Data-loss 3.1866e+03                  , pde-loss 8.6819e+02, initc-loss 1.8046e+04                    bc_loss 8.2710e+04\n",
      "Epoch 6240, Training-Loss 5.2813e+03, Data-loss 2.8304e+03                  , pde-loss 6.2144e+02, initc-loss 1.8875e+04                    bc_loss 2.2559e+05\n",
      "Epoch 6250, Training-Loss 5.6177e+03, Data-loss 2.4195e+03                  , pde-loss 9.3735e+02, initc-loss 1.7523e+04                    bc_loss 3.0137e+05\n",
      "Epoch 6260, Training-Loss 3.0098e+03, Data-loss 2.3667e+03                  , pde-loss 3.2504e+03, initc-loss 1.7153e+04                    bc_loss 4.3902e+04\n",
      "Epoch 6270, Training-Loss 2.8233e+03, Data-loss 2.1491e+03                  , pde-loss 3.4489e+03, initc-loss 1.6221e+04                    bc_loss 4.7745e+04\n",
      "Epoch 6280, Training-Loss 1.1666e+03, Data-loss 5.8896e+02                  , pde-loss 1.4858e+03, initc-loss 1.4402e+04                    bc_loss 4.1875e+04\n",
      "Epoch 6290, Training-Loss 2.8058e+03, Data-loss 1.2045e+03                  , pde-loss 1.6493e+03, initc-loss 1.3834e+04                    bc_loss 1.4464e+05\n",
      "Epoch 6300, Training-Loss 2.0127e+03, Data-loss 1.6362e+03                  , pde-loss 1.6810e+03, initc-loss 1.3743e+04                    bc_loss 2.2225e+04\n",
      "Epoch 6310, Training-Loss 1.7513e+03, Data-loss 9.1073e+02                  , pde-loss 1.5209e+03, initc-loss 1.5577e+04                    bc_loss 6.6956e+04\n",
      "Epoch 6320, Training-Loss 1.0882e+04, Data-loss 4.7632e+03                  , pde-loss 7.9173e+02, initc-loss 2.3534e+04                    bc_loss 5.8754e+05\n",
      "Epoch 6330, Training-Loss 2.7587e+03, Data-loss 2.0933e+03                  , pde-loss 1.6283e+03, initc-loss 1.1742e+04                    bc_loss 5.3164e+04\n",
      "Epoch 6340, Training-Loss 8.6344e+03, Data-loss 3.3559e+03                  , pde-loss 4.3372e+03, initc-loss 2.3964e+04                    bc_loss 4.9955e+05\n",
      "Epoch 6350, Training-Loss 5.7838e+03, Data-loss 3.6075e+03                  , pde-loss 4.1285e+03, initc-loss 1.3281e+04                    bc_loss 2.0022e+05\n",
      "Epoch 6360, Training-Loss 2.8947e+03, Data-loss 2.2728e+03                  , pde-loss 1.0693e+03, initc-loss 1.5987e+04                    bc_loss 4.5136e+04\n",
      "Epoch 6370, Training-Loss 1.7357e+03, Data-loss 1.4262e+03                  , pde-loss 1.3067e+03, initc-loss 1.7007e+04                    bc_loss 1.2644e+04\n",
      "Epoch 6380, Training-Loss 3.7130e+03, Data-loss 2.7480e+03                  , pde-loss 1.5733e+03, initc-loss 2.0884e+04                    bc_loss 7.4042e+04\n",
      "Epoch 6390, Training-Loss 9.9459e+03, Data-loss 4.5732e+03                  , pde-loss 7.9015e+02, initc-loss 2.4039e+04                    bc_loss 5.1244e+05\n",
      "Epoch 6400, Training-Loss 7.1299e+03, Data-loss 2.9811e+03                  , pde-loss 7.6010e+02, initc-loss 1.1827e+04                    bc_loss 4.0229e+05\n",
      "Epoch 6410, Training-Loss 4.1105e+03, Data-loss 2.8107e+03                  , pde-loss 3.8552e+03, initc-loss 1.4393e+04                    bc_loss 1.1173e+05\n",
      "Epoch 6420, Training-Loss 1.7656e+03, Data-loss 1.3613e+03                  , pde-loss 2.0662e+03, initc-loss 1.7497e+04                    bc_loss 2.0868e+04\n",
      "Epoch 6430, Training-Loss 3.5366e+03, Data-loss 3.1336e+03                  , pde-loss 1.1657e+03, initc-loss 1.3922e+04                    bc_loss 2.5209e+04\n",
      "Epoch 6440, Training-Loss 3.7636e+03, Data-loss 3.2951e+03                  , pde-loss 1.2896e+03, initc-loss 1.5473e+04                    bc_loss 3.0085e+04\n",
      "Epoch 6450, Training-Loss 3.4321e+03, Data-loss 1.6111e+03                  , pde-loss 2.0225e+03, initc-loss 2.0401e+04                    bc_loss 1.5968e+05\n",
      "Epoch 6460, Training-Loss 1.6399e+04, Data-loss 1.2654e+04                  , pde-loss 2.3903e+03, initc-loss 4.9653e+04                    bc_loss 3.2243e+05\n",
      "Epoch 6470, Training-Loss 5.9333e+03, Data-loss 5.2176e+03                  , pde-loss 1.9558e+03, initc-loss 1.2732e+04                    bc_loss 5.6876e+04\n",
      "Epoch 6480, Training-Loss 6.2547e+03, Data-loss 4.6490e+03                  , pde-loss 1.1715e+03, initc-loss 1.0260e+04                    bc_loss 1.4914e+05\n",
      "Epoch 6490, Training-Loss 2.5637e+03, Data-loss 1.9858e+03                  , pde-loss 2.4380e+03, initc-loss 2.3344e+04                    bc_loss 3.2006e+04\n",
      "Epoch 6500, Training-Loss 2.9641e+03, Data-loss 1.6647e+03                  , pde-loss 1.9318e+03, initc-loss 1.6953e+04                    bc_loss 1.1105e+05\n",
      "Epoch 6510, Training-Loss 5.4050e+03, Data-loss 3.6535e+03                  , pde-loss 4.4758e+02, initc-loss 2.4226e+04                    bc_loss 1.5048e+05\n",
      "Epoch 6520, Training-Loss 3.6097e+03, Data-loss 1.4869e+03                  , pde-loss 1.4625e+03, initc-loss 1.0250e+04                    bc_loss 2.0057e+05\n",
      "Epoch 6530, Training-Loss 9.8767e+03, Data-loss 5.8122e+03                  , pde-loss 6.3906e+03, initc-loss 2.4060e+04                    bc_loss 3.7601e+05\n",
      "Epoch 6540, Training-Loss 6.7939e+03, Data-loss 3.8627e+03                  , pde-loss 4.6129e+03, initc-loss 1.6345e+04                    bc_loss 2.7216e+05\n",
      "Epoch 6550, Training-Loss 4.0777e+03, Data-loss 3.7382e+03                  , pde-loss 6.6684e+02, initc-loss 1.1433e+04                    bc_loss 2.1851e+04\n",
      "Epoch 6560, Training-Loss 3.4817e+03, Data-loss 2.7336e+03                  , pde-loss 6.0648e+02, initc-loss 1.3758e+04                    bc_loss 6.0450e+04\n",
      "Epoch 6570, Training-Loss 2.8057e+03, Data-loss 1.6690e+03                  , pde-loss 2.8092e+03, initc-loss 1.6923e+04                    bc_loss 9.3936e+04\n",
      "Epoch 6580, Training-Loss 4.8627e+03, Data-loss 2.2163e+03                  , pde-loss 1.3796e+03, initc-loss 1.4154e+04                    bc_loss 2.4910e+05\n",
      "Epoch 6590, Training-Loss 6.8281e+03, Data-loss 3.3479e+03                  , pde-loss 4.2420e+02, initc-loss 2.0019e+04                    bc_loss 3.2757e+05\n",
      "Epoch 6600, Training-Loss 3.1332e+03, Data-loss 2.5167e+03                  , pde-loss 1.1241e+03, initc-loss 1.5580e+04                    bc_loss 4.4945e+04\n",
      "Epoch 6610, Training-Loss 4.2935e+03, Data-loss 3.4056e+03                  , pde-loss 2.8301e+03, initc-loss 1.6700e+04                    bc_loss 6.9262e+04\n",
      "Epoch 6620, Training-Loss 3.3746e+03, Data-loss 2.9302e+03                  , pde-loss 1.7258e+03, initc-loss 1.6153e+04                    bc_loss 2.6561e+04\n",
      "Epoch 6630, Training-Loss 4.0245e+03, Data-loss 2.6948e+03                  , pde-loss 1.1415e+03, initc-loss 1.6831e+04                    bc_loss 1.1499e+05\n",
      "Epoch 6640, Training-Loss 6.0522e+03, Data-loss 2.1962e+03                  , pde-loss 9.7808e+02, initc-loss 1.5673e+04                    bc_loss 3.6895e+05\n",
      "Epoch 6650, Training-Loss 4.1198e+03, Data-loss 3.2180e+03                  , pde-loss 3.4090e+03, initc-loss 2.0521e+04                    bc_loss 6.6243e+04\n",
      "Epoch 6660, Training-Loss 7.9199e+03, Data-loss 3.8509e+03                  , pde-loss 5.4198e+03, initc-loss 1.9889e+04                    bc_loss 3.8159e+05\n",
      "Epoch 6670, Training-Loss 2.0511e+03, Data-loss 1.1098e+03                  , pde-loss 1.8870e+03, initc-loss 1.4051e+04                    bc_loss 7.8197e+04\n",
      "Epoch 6680, Training-Loss 4.2463e+03, Data-loss 3.3220e+03                  , pde-loss 6.1566e+02, initc-loss 1.4413e+04                    bc_loss 7.7411e+04\n",
      "Epoch 6690, Training-Loss 2.4936e+03, Data-loss 1.7255e+03                  , pde-loss 1.7078e+03, initc-loss 1.2624e+04                    bc_loss 6.2475e+04\n",
      "Epoch 6700, Training-Loss 1.9604e+03, Data-loss 1.3523e+03                  , pde-loss 1.4362e+03, initc-loss 1.6745e+04                    bc_loss 4.2628e+04\n",
      "Epoch 6710, Training-Loss 1.0772e+04, Data-loss 3.0475e+03                  , pde-loss 7.8400e+02, initc-loss 2.4666e+04                    bc_loss 7.4695e+05\n",
      "Epoch 6720, Training-Loss 7.9836e+03, Data-loss 6.9160e+03                  , pde-loss 3.9848e+02, initc-loss 1.2543e+04                    bc_loss 9.3826e+04\n",
      "Epoch 6730, Training-Loss 3.2358e+03, Data-loss 2.5015e+03                  , pde-loss 1.5703e+03, initc-loss 1.3261e+04                    bc_loss 5.8603e+04\n",
      "Epoch 6740, Training-Loss 4.2226e+03, Data-loss 3.3860e+03                  , pde-loss 3.5898e+03, initc-loss 1.7603e+04                    bc_loss 6.2466e+04\n",
      "Epoch 6750, Training-Loss 3.8320e+03, Data-loss 2.8856e+03                  , pde-loss 1.4767e+03, initc-loss 1.6343e+04                    bc_loss 7.6822e+04\n",
      "Epoch 6760, Training-Loss 1.2189e+04, Data-loss 9.3670e+03                  , pde-loss 7.3245e+02, initc-loss 3.6138e+04                    bc_loss 2.4537e+05\n",
      "Epoch 6770, Training-Loss 7.6613e+03, Data-loss 5.0935e+03                  , pde-loss 1.3464e+03, initc-loss 1.2013e+04                    bc_loss 2.4342e+05\n",
      "Epoch 6780, Training-Loss 1.0214e+04, Data-loss 6.9898e+03                  , pde-loss 7.2291e+03, initc-loss 2.4202e+04                    bc_loss 2.9099e+05\n",
      "Epoch 6790, Training-Loss 9.1338e+03, Data-loss 4.9639e+03                  , pde-loss 4.7846e+03, initc-loss 1.4467e+04                    bc_loss 3.9774e+05\n",
      "Epoch 6800, Training-Loss 6.6682e+03, Data-loss 6.0043e+03                  , pde-loss 5.5164e+02, initc-loss 1.9033e+04                    bc_loss 4.6813e+04\n",
      "Epoch 6810, Training-Loss 3.9856e+03, Data-loss 3.6143e+03                  , pde-loss 3.6853e+02, initc-loss 1.4053e+04                    bc_loss 2.2707e+04\n",
      "Epoch 6820, Training-Loss 3.3614e+03, Data-loss 2.3245e+03                  , pde-loss 2.2237e+03, initc-loss 1.6551e+04                    bc_loss 8.4913e+04\n",
      "Epoch 6830, Training-Loss 7.9767e+03, Data-loss 4.4570e+03                  , pde-loss 1.5784e+03, initc-loss 1.8075e+04                    bc_loss 3.3231e+05\n",
      "Epoch 6840, Training-Loss 5.5691e+03, Data-loss 4.2415e+03                  , pde-loss 5.3082e+02, initc-loss 1.7480e+04                    bc_loss 1.1474e+05\n",
      "Epoch 6850, Training-Loss 3.8250e+03, Data-loss 2.8949e+03                  , pde-loss 1.2763e+03, initc-loss 1.3954e+04                    bc_loss 7.7776e+04\n",
      "Epoch 6860, Training-Loss 6.4456e+03, Data-loss 5.4448e+03                  , pde-loss 3.1980e+03, initc-loss 1.8514e+04                    bc_loss 7.8369e+04\n",
      "Epoch 6870, Training-Loss 3.9658e+03, Data-loss 2.9094e+03                  , pde-loss 1.3688e+03, initc-loss 2.0105e+04                    bc_loss 8.4167e+04\n",
      "Epoch 6880, Training-Loss 1.4911e+04, Data-loss 8.2287e+03                  , pde-loss 7.6243e+02, initc-loss 3.1534e+04                    bc_loss 6.3596e+05\n",
      "Epoch 6890, Training-Loss 8.1261e+03, Data-loss 5.5235e+03                  , pde-loss 9.0135e+02, initc-loss 8.2061e+03                    bc_loss 2.5115e+05\n",
      "Epoch 6900, Training-Loss 3.4807e+03, Data-loss 2.1605e+03                  , pde-loss 3.7257e+03, initc-loss 1.1877e+04                    bc_loss 1.1642e+05\n",
      "Epoch 6910, Training-Loss 5.2229e+03, Data-loss 3.2853e+03                  , pde-loss 2.1540e+03, initc-loss 2.6825e+04                    bc_loss 1.6479e+05\n",
      "Epoch 6920, Training-Loss 3.7920e+03, Data-loss 2.9610e+03                  , pde-loss 9.4403e+02, initc-loss 1.7482e+04                    bc_loss 6.4676e+04\n",
      "Epoch 6930, Training-Loss 4.6289e+03, Data-loss 3.0036e+03                  , pde-loss 1.2256e+03, initc-loss 1.6156e+04                    bc_loss 1.4516e+05\n",
      "Epoch 6940, Training-Loss 2.7625e+03, Data-loss 2.0285e+03                  , pde-loss 1.7108e+03, initc-loss 1.4738e+04                    bc_loss 5.6949e+04\n",
      "Epoch 6950, Training-Loss 7.0723e+03, Data-loss 2.0771e+03                  , pde-loss 3.2106e+03, initc-loss 1.9846e+04                    bc_loss 4.7646e+05\n",
      "Epoch 6960, Training-Loss 5.6767e+03, Data-loss 4.5190e+03                  , pde-loss 5.3178e+03, initc-loss 1.8140e+04                    bc_loss 9.2315e+04\n",
      "Epoch 6970, Training-Loss 4.6238e+03, Data-loss 3.2152e+03                  , pde-loss 1.9264e+03, initc-loss 1.5046e+04                    bc_loss 1.2388e+05\n",
      "Epoch 6980, Training-Loss 6.5470e+03, Data-loss 3.6438e+03                  , pde-loss 5.8512e+02, initc-loss 1.6092e+04                    bc_loss 2.7364e+05\n",
      "Epoch 6990, Training-Loss 7.7976e+03, Data-loss 6.7600e+03                  , pde-loss 3.2292e+02, initc-loss 2.3096e+04                    bc_loss 8.0346e+04\n",
      "Epoch 7000, Training-Loss 8.8233e+03, Data-loss 4.9535e+03                  , pde-loss 2.1075e+03, initc-loss 2.3872e+04                    bc_loss 3.6101e+05\n",
      "Epoch 7010, Training-Loss 5.2109e+03, Data-loss 2.6795e+03                  , pde-loss 6.0272e+03, initc-loss 1.6770e+04                    bc_loss 2.3034e+05\n",
      "Epoch 7020, Training-Loss 5.7153e+03, Data-loss 2.8901e+03                  , pde-loss 1.8546e+03, initc-loss 8.8878e+03                    bc_loss 2.7177e+05\n",
      "Epoch 7030, Training-Loss 6.2651e+03, Data-loss 4.2374e+03                  , pde-loss 5.8086e+02, initc-loss 1.6475e+04                    bc_loss 1.8571e+05\n",
      "Epoch 7040, Training-Loss 5.4389e+03, Data-loss 2.9127e+03                  , pde-loss 4.5190e+02, initc-loss 1.4843e+04                    bc_loss 2.3733e+05\n",
      "Epoch 7050, Training-Loss 4.1185e+03, Data-loss 3.4911e+03                  , pde-loss 2.4467e+03, initc-loss 1.9850e+04                    bc_loss 4.0445e+04\n",
      "Epoch 7060, Training-Loss 2.2278e+03, Data-loss 1.8630e+03                  , pde-loss 1.9859e+03, initc-loss 1.4689e+04                    bc_loss 1.9799e+04\n",
      "Epoch 7070, Training-Loss 1.3433e+03, Data-loss 8.7451e+02                  , pde-loss 1.5474e+03, initc-loss 1.4618e+04                    bc_loss 3.0709e+04\n",
      "Epoch 7080, Training-Loss 8.8454e+03, Data-loss 3.6072e+03                  , pde-loss 1.1858e+03, initc-loss 1.5924e+04                    bc_loss 5.0671e+05\n",
      "Epoch 7090, Training-Loss 4.9557e+03, Data-loss 1.9905e+03                  , pde-loss 1.5120e+03, initc-loss 9.0719e+03                    bc_loss 2.8593e+05\n",
      "Epoch 7100, Training-Loss 4.2945e+03, Data-loss 3.3804e+03                  , pde-loss 3.8356e+03, initc-loss 1.7837e+04                    bc_loss 6.9738e+04\n",
      "Epoch 7110, Training-Loss 3.2876e+03, Data-loss 1.4736e+03                  , pde-loss 2.4063e+03, initc-loss 1.6716e+04                    bc_loss 1.6227e+05\n",
      "Epoch 7120, Training-Loss 2.0526e+03, Data-loss 1.8563e+03                  , pde-loss 1.6319e+03, initc-loss 1.3740e+04                    bc_loss 4.2632e+03\n",
      "Epoch 7130, Training-Loss 1.5317e+03, Data-loss 1.2010e+03                  , pde-loss 1.3287e+03, initc-loss 1.4088e+04                    bc_loss 1.7655e+04\n",
      "Epoch 7140, Training-Loss 2.4128e+03, Data-loss 1.0908e+03                  , pde-loss 1.4117e+03, initc-loss 1.5944e+04                    bc_loss 1.1484e+05\n",
      "Epoch 7150, Training-Loss 7.2927e+03, Data-loss 4.0067e+03                  , pde-loss 2.3444e+03, initc-loss 2.3625e+04                    bc_loss 3.0263e+05\n",
      "Epoch 7160, Training-Loss 2.6581e+03, Data-loss 1.7184e+03                  , pde-loss 2.4535e+03, initc-loss 1.4208e+04                    bc_loss 7.7301e+04\n",
      "Epoch 7170, Training-Loss 6.5659e+03, Data-loss 1.9892e+03                  , pde-loss 8.5921e+02, initc-loss 1.8508e+04                    bc_loss 4.3831e+05\n",
      "Epoch 7180, Training-Loss 4.8855e+03, Data-loss 3.3622e+03                  , pde-loss 5.3000e+02, initc-loss 1.5730e+04                    bc_loss 1.3607e+05\n",
      "Epoch 7190, Training-Loss 3.3163e+03, Data-loss 2.3583e+03                  , pde-loss 2.4683e+03, initc-loss 1.5624e+04                    bc_loss 7.7712e+04\n",
      "Epoch 7200, Training-Loss 2.3102e+03, Data-loss 1.7150e+03                  , pde-loss 2.0091e+03, initc-loss 1.6722e+04                    bc_loss 4.0782e+04\n",
      "Epoch 7210, Training-Loss 2.3455e+03, Data-loss 1.5258e+03                  , pde-loss 1.1537e+03, initc-loss 1.5297e+04                    bc_loss 6.5524e+04\n",
      "Epoch 7220, Training-Loss 1.6740e+04, Data-loss 1.5893e+04                  , pde-loss 1.0808e+03, initc-loss 5.5041e+04                    bc_loss 2.8601e+04\n",
      "Epoch 7230, Training-Loss 9.2150e+03, Data-loss 6.0819e+03                  , pde-loss 1.2494e+03, initc-loss 1.4286e+04                    bc_loss 2.9777e+05\n",
      "Epoch 7240, Training-Loss 6.8905e+03, Data-loss 5.2564e+03                  , pde-loss 2.1752e+03, initc-loss 1.3884e+04                    bc_loss 1.4735e+05\n",
      "Epoch 7250, Training-Loss 5.4302e+03, Data-loss 4.6107e+03                  , pde-loss 1.0619e+03, initc-loss 2.1261e+04                    bc_loss 5.9630e+04\n",
      "Epoch 7260, Training-Loss 8.6124e+03, Data-loss 5.6536e+03                  , pde-loss 5.5097e+02, initc-loss 2.5061e+04                    bc_loss 2.7026e+05\n",
      "Epoch 7270, Training-Loss 4.6856e+03, Data-loss 2.9629e+03                  , pde-loss 9.5304e+02, initc-loss 1.4731e+04                    bc_loss 1.5659e+05\n",
      "Epoch 7280, Training-Loss 3.7679e+03, Data-loss 2.6488e+03                  , pde-loss 2.2715e+03, initc-loss 1.1525e+04                    bc_loss 9.8106e+04\n",
      "Epoch 7290, Training-Loss 2.1107e+03, Data-loss 1.1330e+03                  , pde-loss 3.4588e+03, initc-loss 1.8689e+04                    bc_loss 7.5617e+04\n",
      "Epoch 7300, Training-Loss 2.3476e+03, Data-loss 1.0795e+03                  , pde-loss 1.2297e+03, initc-loss 1.4798e+04                    bc_loss 1.1078e+05\n",
      "Epoch 7310, Training-Loss 1.1766e+04, Data-loss 4.3658e+03                  , pde-loss 4.6654e+02, initc-loss 2.2695e+04                    bc_loss 7.1690e+05\n",
      "Epoch 7320, Training-Loss 6.2931e+03, Data-loss 4.0408e+03                  , pde-loss 6.7735e+02, initc-loss 1.1301e+04                    bc_loss 2.1325e+05\n",
      "Epoch 7330, Training-Loss 3.0927e+03, Data-loss 2.5465e+03                  , pde-loss 3.5334e+03, initc-loss 1.2418e+04                    bc_loss 3.8667e+04\n",
      "Epoch 7340, Training-Loss 3.4402e+03, Data-loss 2.3777e+03                  , pde-loss 3.0505e+03, initc-loss 1.8205e+04                    bc_loss 8.4991e+04\n",
      "Epoch 7350, Training-Loss 2.7503e+03, Data-loss 1.5911e+03                  , pde-loss 7.7757e+02, initc-loss 1.7827e+04                    bc_loss 9.7312e+04\n",
      "Epoch 7360, Training-Loss 3.3296e+03, Data-loss 2.5544e+03                  , pde-loss 9.7290e+02, initc-loss 1.3487e+04                    bc_loss 6.3055e+04\n",
      "Epoch 7370, Training-Loss 3.2603e+03, Data-loss 1.3742e+03                  , pde-loss 1.3280e+03, initc-loss 1.5589e+04                    bc_loss 1.7169e+05\n",
      "Epoch 7380, Training-Loss 2.8904e+03, Data-loss 1.6709e+03                  , pde-loss 3.1068e+03, initc-loss 1.4999e+04                    bc_loss 1.0384e+05\n",
      "Epoch 7390, Training-Loss 8.1467e+03, Data-loss 5.0210e+03                  , pde-loss 4.3868e+03, initc-loss 2.4229e+04                    bc_loss 2.8395e+05\n",
      "Epoch 7400, Training-Loss 5.4925e+03, Data-loss 4.5549e+03                  , pde-loss 3.3071e+03, initc-loss 1.4630e+04                    bc_loss 7.5818e+04\n",
      "Epoch 7410, Training-Loss 6.8872e+03, Data-loss 4.2940e+03                  , pde-loss 8.0618e+02, initc-loss 1.7953e+04                    bc_loss 2.4057e+05\n",
      "Epoch 7420, Training-Loss 4.8214e+03, Data-loss 3.1651e+03                  , pde-loss 3.5055e+02, initc-loss 1.9751e+04                    bc_loss 1.4553e+05\n",
      "Epoch 7430, Training-Loss 5.7007e+03, Data-loss 2.6392e+03                  , pde-loss 1.4811e+03, initc-loss 1.6967e+04                    bc_loss 2.8770e+05\n",
      "Epoch 7440, Training-Loss 1.0294e+04, Data-loss 4.7278e+03                  , pde-loss 5.1481e+03, initc-loss 1.7698e+04                    bc_loss 5.3380e+05\n",
      "Epoch 7450, Training-Loss 1.0096e+04, Data-loss 3.5548e+03                  , pde-loss 3.5823e+03, initc-loss 9.7481e+03                    bc_loss 6.4082e+05\n",
      "Epoch 7460, Training-Loss 1.2566e+04, Data-loss 4.5709e+03                  , pde-loss 7.4123e+02, initc-loss 2.3229e+04                    bc_loss 7.7549e+05\n",
      "Epoch 7470, Training-Loss 1.2145e+04, Data-loss 5.2099e+03                  , pde-loss 4.6895e+02, initc-loss 1.4382e+04                    bc_loss 6.7867e+05\n",
      "Epoch 7480, Training-Loss 5.5033e+03, Data-loss 3.3938e+03                  , pde-loss 4.1503e+03, initc-loss 1.5797e+04                    bc_loss 1.9100e+05\n",
      "Epoch 7490, Training-Loss 2.0052e+03, Data-loss 1.5783e+03                  , pde-loss 1.9109e+03, initc-loss 1.4366e+04                    bc_loss 2.6407e+04\n",
      "Epoch 7500, Training-Loss 2.2766e+03, Data-loss 1.6318e+03                  , pde-loss 9.7891e+02, initc-loss 1.6658e+04                    bc_loss 4.6840e+04\n",
      "Epoch 7510, Training-Loss 2.2403e+03, Data-loss 1.6161e+03                  , pde-loss 1.3415e+03, initc-loss 1.6637e+04                    bc_loss 4.4449e+04\n",
      "Epoch 7520, Training-Loss 2.2330e+03, Data-loss 1.8035e+03                  , pde-loss 1.4014e+03, initc-loss 1.4294e+04                    bc_loss 2.7254e+04\n",
      "Epoch 7530, Training-Loss 4.6924e+03, Data-loss 2.1527e+03                  , pde-loss 1.2774e+03, initc-loss 1.4027e+04                    bc_loss 2.3867e+05\n",
      "Epoch 7540, Training-Loss 1.8797e+03, Data-loss 1.1250e+03                  , pde-loss 1.6916e+03, initc-loss 1.6804e+04                    bc_loss 5.6972e+04\n",
      "Epoch 7550, Training-Loss 2.1966e+03, Data-loss 1.8189e+03                  , pde-loss 2.1579e+03, initc-loss 1.2171e+04                    bc_loss 2.3439e+04\n",
      "Epoch 7560, Training-Loss 1.8794e+03, Data-loss 1.5460e+03                  , pde-loss 2.1367e+03, initc-loss 1.2371e+04                    bc_loss 1.8831e+04\n",
      "Epoch 7570, Training-Loss 1.3677e+03, Data-loss 1.0290e+03                  , pde-loss 1.5684e+03, initc-loss 1.4079e+04                    bc_loss 1.8222e+04\n",
      "Epoch 7580, Training-Loss 1.1738e+04, Data-loss 7.9581e+03                  , pde-loss 4.8234e+02, initc-loss 3.5177e+04                    bc_loss 3.4234e+05\n",
      "Epoch 7590, Training-Loss 4.2608e+03, Data-loss 3.2596e+03                  , pde-loss 7.9410e+02, initc-loss 1.5768e+04                    bc_loss 8.3560e+04\n",
      "Epoch 7600, Training-Loss 4.0663e+03, Data-loss 2.6540e+03                  , pde-loss 2.3234e+03, initc-loss 1.0992e+04                    bc_loss 1.2792e+05\n",
      "Epoch 7610, Training-Loss 5.6020e+03, Data-loss 3.6278e+03                  , pde-loss 3.9932e+03, initc-loss 1.8832e+04                    bc_loss 1.7460e+05\n",
      "Epoch 7620, Training-Loss 3.3648e+03, Data-loss 2.3050e+03                  , pde-loss 1.4715e+03, initc-loss 1.5058e+04                    bc_loss 8.9452e+04\n",
      "Epoch 7630, Training-Loss 4.0009e+03, Data-loss 1.8348e+03                  , pde-loss 5.5223e+02, initc-loss 1.6471e+04                    bc_loss 1.9959e+05\n",
      "Epoch 7640, Training-Loss 9.8137e+03, Data-loss 3.0819e+03                  , pde-loss 5.0033e+02, initc-loss 1.9592e+04                    bc_loss 6.5309e+05\n",
      "Epoch 7650, Training-Loss 4.0495e+03, Data-loss 3.1632e+03                  , pde-loss 2.4698e+03, initc-loss 1.4447e+04                    bc_loss 7.1709e+04\n",
      "Epoch 7660, Training-Loss 4.0203e+03, Data-loss 2.6497e+03                  , pde-loss 4.3456e+03, initc-loss 1.3708e+04                    bc_loss 1.1900e+05\n",
      "Epoch 7670, Training-Loss 2.9938e+03, Data-loss 2.4531e+03                  , pde-loss 1.5246e+03, initc-loss 1.4240e+04                    bc_loss 3.8306e+04\n",
      "Epoch 7680, Training-Loss 1.1131e+03, Data-loss 8.0110e+02                  , pde-loss 1.2714e+03, initc-loss 1.3611e+04                    bc_loss 1.6318e+04\n",
      "Epoch 7690, Training-Loss 2.7792e+03, Data-loss 2.2614e+03                  , pde-loss 1.6603e+03, initc-loss 1.5662e+04                    bc_loss 3.4452e+04\n",
      "Epoch 7700, Training-Loss 2.0785e+03, Data-loss 1.3225e+03                  , pde-loss 1.5408e+03, initc-loss 1.3830e+04                    bc_loss 6.0226e+04\n",
      "Epoch 7710, Training-Loss 7.2952e+03, Data-loss 4.1338e+03                  , pde-loss 7.3071e+02, initc-loss 2.2631e+04                    bc_loss 2.9277e+05\n",
      "Epoch 7720, Training-Loss 6.0423e+03, Data-loss 3.6568e+03                  , pde-loss 1.7026e+03, initc-loss 1.4722e+04                    bc_loss 2.2212e+05\n",
      "Epoch 7730, Training-Loss 9.2857e+03, Data-loss 3.9061e+03                  , pde-loss 5.5818e+03, initc-loss 2.4477e+04                    bc_loss 5.0790e+05\n",
      "Epoch 7740, Training-Loss 6.2162e+03, Data-loss 3.9060e+03                  , pde-loss 4.5328e+03, initc-loss 1.2790e+04                    bc_loss 2.1370e+05\n",
      "Epoch 7750, Training-Loss 2.8375e+03, Data-loss 1.9825e+03                  , pde-loss 1.0359e+03, initc-loss 1.2656e+04                    bc_loss 7.1807e+04\n",
      "Epoch 7760, Training-Loss 1.4447e+03, Data-loss 8.5821e+02                  , pde-loss 1.2005e+03, initc-loss 1.5950e+04                    bc_loss 4.1500e+04\n",
      "Epoch 7770, Training-Loss 3.9624e+03, Data-loss 2.6445e+03                  , pde-loss 1.9036e+03, initc-loss 1.6861e+04                    bc_loss 1.1303e+05\n",
      "Epoch 7780, Training-Loss 3.0477e+03, Data-loss 2.5436e+03                  , pde-loss 1.0816e+03, initc-loss 1.4872e+04                    bc_loss 3.4455e+04\n",
      "Epoch 7790, Training-Loss 2.6934e+03, Data-loss 1.9304e+03                  , pde-loss 8.3083e+02, initc-loss 1.7592e+04                    bc_loss 5.7868e+04\n",
      "Epoch 7800, Training-Loss 4.3233e+03, Data-loss 2.3613e+03                  , pde-loss 7.3679e+02, initc-loss 1.5928e+04                    bc_loss 1.7953e+05\n",
      "Epoch 7810, Training-Loss 2.8161e+03, Data-loss 1.3100e+03                  , pde-loss 1.2505e+03, initc-loss 9.7159e+03                    bc_loss 1.3965e+05\n",
      "Epoch 7820, Training-Loss 1.4371e+03, Data-loss 1.0284e+03                  , pde-loss 3.2050e+03, initc-loss 1.6742e+04                    bc_loss 2.0922e+04\n",
      "Epoch 7830, Training-Loss 2.8007e+03, Data-loss 1.9090e+03                  , pde-loss 1.7714e+03, initc-loss 1.8533e+04                    bc_loss 6.8859e+04\n",
      "Epoch 7840, Training-Loss 2.6456e+03, Data-loss 1.0602e+03                  , pde-loss 1.7923e+03, initc-loss 1.3788e+04                    bc_loss 1.4296e+05\n",
      "Epoch 7850, Training-Loss 6.7669e+03, Data-loss 4.4814e+03                  , pde-loss 4.2990e+03, initc-loss 2.1972e+04                    bc_loss 2.0228e+05\n",
      "Epoch 7860, Training-Loss 4.8575e+03, Data-loss 2.8891e+03                  , pde-loss 2.0659e+03, initc-loss 1.4893e+04                    bc_loss 1.7988e+05\n",
      "Epoch 7870, Training-Loss 1.0392e+04, Data-loss 4.9267e+03                  , pde-loss 2.5948e+02, initc-loss 2.5641e+04                    bc_loss 5.2059e+05\n",
      "Epoch 7880, Training-Loss 5.4123e+03, Data-loss 3.5045e+03                  , pde-loss 7.3308e+02, initc-loss 1.4675e+04                    bc_loss 1.7538e+05\n",
      "Epoch 7890, Training-Loss 4.5393e+03, Data-loss 2.8766e+03                  , pde-loss 3.3200e+03, initc-loss 1.4969e+04                    bc_loss 1.4798e+05\n",
      "Epoch 7900, Training-Loss 1.5793e+03, Data-loss 9.3063e+02                  , pde-loss 1.6804e+03, initc-loss 1.5787e+04                    bc_loss 4.7404e+04\n",
      "Epoch 7910, Training-Loss 2.9239e+03, Data-loss 2.3112e+03                  , pde-loss 1.2078e+03, initc-loss 1.7689e+04                    bc_loss 4.2372e+04\n",
      "Epoch 7920, Training-Loss 1.5501e+03, Data-loss 1.0762e+03                  , pde-loss 1.8849e+03, initc-loss 1.5719e+04                    bc_loss 2.9781e+04\n",
      "Epoch 7930, Training-Loss 1.6694e+03, Data-loss 1.2404e+03                  , pde-loss 1.4943e+03, initc-loss 1.4882e+04                    bc_loss 2.6520e+04\n",
      "Epoch 7940, Training-Loss 1.6123e+04, Data-loss 5.2202e+03                  , pde-loss 6.8466e+02, initc-loss 2.6947e+04                    bc_loss 1.0626e+06\n",
      "Epoch 7950, Training-Loss 8.7188e+03, Data-loss 6.0747e+03                  , pde-loss 3.9235e+02, initc-loss 8.9034e+03                    bc_loss 2.5511e+05\n",
      "Epoch 7960, Training-Loss 3.8481e+03, Data-loss 2.3997e+03                  , pde-loss 2.7402e+03, initc-loss 1.3182e+04                    bc_loss 1.2892e+05\n",
      "Epoch 7970, Training-Loss 1.0603e+04, Data-loss 6.0974e+03                  , pde-loss 5.1921e+03, initc-loss 2.2101e+04                    bc_loss 4.2326e+05\n",
      "Epoch 7980, Training-Loss 4.8900e+03, Data-loss 1.7789e+03                  , pde-loss 3.1380e+03, initc-loss 1.2865e+04                    bc_loss 2.9510e+05\n",
      "Epoch 7990, Training-Loss 4.6620e+03, Data-loss 3.4649e+03                  , pde-loss 4.4392e+02, initc-loss 1.7213e+04                    bc_loss 1.0205e+05\n",
      "Epoch 8000, Training-Loss 3.4854e+03, Data-loss 2.2315e+03                  , pde-loss 4.8817e+02, initc-loss 1.4585e+04                    bc_loss 1.1032e+05\n",
      "Epoch 8010, Training-Loss 1.9161e+03, Data-loss 1.3096e+03                  , pde-loss 2.2050e+03, initc-loss 1.5367e+04                    bc_loss 4.3079e+04\n",
      "Epoch 8020, Training-Loss 6.0315e+03, Data-loss 9.3698e+02                  , pde-loss 1.4726e+03, initc-loss 1.7849e+04                    bc_loss 4.9013e+05\n",
      "Epoch 8030, Training-Loss 7.7333e+03, Data-loss 3.9546e+03                  , pde-loss 4.9748e+02, initc-loss 1.3497e+04                    bc_loss 3.6388e+05\n",
      "Epoch 8040, Training-Loss 2.5917e+03, Data-loss 1.6927e+03                  , pde-loss 2.9196e+03, initc-loss 1.8438e+04                    bc_loss 6.8546e+04\n",
      "Epoch 8050, Training-Loss 1.9639e+03, Data-loss 1.4313e+03                  , pde-loss 1.8662e+03, initc-loss 1.3256e+04                    bc_loss 3.8138e+04\n",
      "Epoch 8060, Training-Loss 2.1633e+03, Data-loss 1.6173e+03                  , pde-loss 1.6052e+03, initc-loss 1.4445e+04                    bc_loss 3.8551e+04\n",
      "Epoch 8070, Training-Loss 3.3081e+03, Data-loss 2.4236e+03                  , pde-loss 1.2735e+03, initc-loss 1.4340e+04                    bc_loss 7.2841e+04\n",
      "Epoch 8080, Training-Loss 1.1307e+04, Data-loss 1.5474e+03                  , pde-loss 1.8037e+03, initc-loss 2.0177e+04                    bc_loss 9.5393e+05\n",
      "Epoch 8090, Training-Loss 6.0408e+03, Data-loss 4.6015e+03                  , pde-loss 5.6370e+03, initc-loss 1.0913e+04                    bc_loss 1.2737e+05\n",
      "Epoch 8100, Training-Loss 4.3910e+03, Data-loss 2.3051e+03                  , pde-loss 2.3373e+03, initc-loss 1.4505e+04                    bc_loss 1.9176e+05\n",
      "Epoch 8110, Training-Loss 6.3226e+03, Data-loss 4.0889e+03                  , pde-loss 2.9186e+02, initc-loss 2.1594e+04                    bc_loss 2.0148e+05\n",
      "Epoch 8120, Training-Loss 5.4186e+03, Data-loss 3.1964e+03                  , pde-loss 2.9182e+02, initc-loss 1.6740e+04                    bc_loss 2.0519e+05\n",
      "Epoch 8130, Training-Loss 3.0356e+03, Data-loss 2.4551e+03                  , pde-loss 1.7131e+03, initc-loss 1.5759e+04                    bc_loss 4.0577e+04\n",
      "Epoch 8140, Training-Loss 2.1561e+03, Data-loss 1.5685e+03                  , pde-loss 1.8305e+03, initc-loss 1.5764e+04                    bc_loss 4.1165e+04\n",
      "Epoch 8150, Training-Loss 3.5854e+03, Data-loss 2.0670e+03                  , pde-loss 1.1770e+03, initc-loss 1.4727e+04                    bc_loss 1.3594e+05\n",
      "Epoch 8160, Training-Loss 5.6702e+03, Data-loss 3.8796e+03                  , pde-loss 4.4164e+02, initc-loss 1.9227e+04                    bc_loss 1.5940e+05\n",
      "Epoch 8170, Training-Loss 3.5222e+03, Data-loss 2.3705e+03                  , pde-loss 1.0833e+03, initc-loss 1.7786e+04                    bc_loss 9.6299e+04\n",
      "Epoch 8180, Training-Loss 3.2502e+03, Data-loss 2.0690e+03                  , pde-loss 3.7141e+03, initc-loss 1.9874e+04                    bc_loss 9.4536e+04\n",
      "Epoch 8190, Training-Loss 6.2139e+03, Data-loss 2.9118e+03                  , pde-loss 3.7785e+03, initc-loss 2.1156e+04                    bc_loss 3.0527e+05\n",
      "Epoch 8200, Training-Loss 5.2310e+03, Data-loss 4.4410e+03                  , pde-loss 2.4562e+03, initc-loss 1.4967e+04                    bc_loss 6.1580e+04\n",
      "Epoch 8210, Training-Loss 5.6897e+03, Data-loss 3.7912e+03                  , pde-loss 7.2807e+02, initc-loss 2.0662e+04                    bc_loss 1.6846e+05\n",
      "Epoch 8220, Training-Loss 4.9012e+03, Data-loss 3.2109e+03                  , pde-loss 2.9396e+02, initc-loss 1.8547e+04                    bc_loss 1.5020e+05\n",
      "Epoch 8230, Training-Loss 4.0614e+03, Data-loss 3.2632e+03                  , pde-loss 2.2328e+03, initc-loss 1.4740e+04                    bc_loss 6.2841e+04\n",
      "Epoch 8240, Training-Loss 3.6237e+03, Data-loss 3.2112e+03                  , pde-loss 3.0519e+03, initc-loss 1.6496e+04                    bc_loss 2.1706e+04\n",
      "Epoch 8250, Training-Loss 2.2840e+03, Data-loss 1.7045e+03                  , pde-loss 1.9427e+03, initc-loss 1.4060e+04                    bc_loss 4.1940e+04\n",
      "Epoch 8260, Training-Loss 1.4975e+04, Data-loss 3.7124e+03                  , pde-loss 2.0417e+03, initc-loss 2.1767e+04                    bc_loss 1.1024e+06\n",
      "Epoch 8270, Training-Loss 1.0132e+04, Data-loss 5.5351e+03                  , pde-loss 5.2415e+03, initc-loss 9.7521e+03                    bc_loss 4.4472e+05\n",
      "Epoch 8280, Training-Loss 7.9505e+03, Data-loss 4.5782e+03                  , pde-loss 1.0042e+03, initc-loss 1.0375e+04                    bc_loss 3.2586e+05\n",
      "Epoch 8290, Training-Loss 1.1206e+04, Data-loss 5.2354e+03                  , pde-loss 4.8265e+02, initc-loss 2.4611e+04                    bc_loss 5.7195e+05\n",
      "Epoch 8300, Training-Loss 4.9166e+03, Data-loss 2.4641e+03                  , pde-loss 3.8989e+02, initc-loss 1.0870e+04                    bc_loss 2.3399e+05\n",
      "Epoch 8310, Training-Loss 4.5445e+03, Data-loss 3.3214e+03                  , pde-loss 3.8211e+03, initc-loss 1.5642e+04                    bc_loss 1.0284e+05\n",
      "Epoch 8320, Training-Loss 2.4003e+03, Data-loss 1.6107e+03                  , pde-loss 1.9889e+03, initc-loss 1.8056e+04                    bc_loss 5.8914e+04\n",
      "Epoch 8330, Training-Loss 1.8083e+03, Data-loss 1.0848e+03                  , pde-loss 1.4723e+03, initc-loss 1.4811e+04                    bc_loss 5.6060e+04\n",
      "Epoch 8340, Training-Loss 2.5947e+03, Data-loss 2.0829e+03                  , pde-loss 9.1150e+02, initc-loss 1.4372e+04                    bc_loss 3.5893e+04\n",
      "Epoch 8350, Training-Loss 2.5549e+03, Data-loss 1.9330e+03                  , pde-loss 1.0209e+03, initc-loss 1.4550e+04                    bc_loss 4.6623e+04\n",
      "Epoch 8360, Training-Loss 4.2866e+03, Data-loss 2.0780e+03                  , pde-loss 7.5333e+02, initc-loss 1.8211e+04                    bc_loss 2.0190e+05\n",
      "Epoch 8370, Training-Loss 4.3390e+03, Data-loss 2.9567e+03                  , pde-loss 8.1447e+02, initc-loss 1.6533e+04                    bc_loss 1.2088e+05\n",
      "Epoch 8380, Training-Loss 2.9432e+03, Data-loss 2.2778e+03                  , pde-loss 2.1904e+03, initc-loss 1.7603e+04                    bc_loss 4.6749e+04\n",
      "Epoch 8390, Training-Loss 3.8795e+03, Data-loss 2.8358e+03                  , pde-loss 2.5677e+03, initc-loss 1.8764e+04                    bc_loss 8.3044e+04\n",
      "Epoch 8400, Training-Loss 2.9870e+03, Data-loss 1.9245e+03                  , pde-loss 1.3483e+03, initc-loss 1.3198e+04                    bc_loss 9.1705e+04\n",
      "Epoch 8410, Training-Loss 1.0025e+04, Data-loss 5.1971e+03                  , pde-loss 3.6747e+02, initc-loss 2.3761e+04                    bc_loss 4.5863e+05\n",
      "Epoch 8420, Training-Loss 4.2457e+03, Data-loss 1.5501e+03                  , pde-loss 1.0970e+03, initc-loss 1.0060e+04                    bc_loss 2.5840e+05\n",
      "Epoch 8430, Training-Loss 4.5281e+03, Data-loss 3.1684e+03                  , pde-loss 5.3247e+03, initc-loss 1.6344e+04                    bc_loss 1.1431e+05\n",
      "Epoch 8440, Training-Loss 1.8666e+03, Data-loss 1.5117e+03                  , pde-loss 2.7253e+03, initc-loss 1.1788e+04                    bc_loss 2.0977e+04\n",
      "Epoch 8450, Training-Loss 2.3640e+03, Data-loss 1.5687e+03                  , pde-loss 1.3058e+03, initc-loss 1.0620e+04                    bc_loss 6.7601e+04\n",
      "Epoch 8460, Training-Loss 2.2254e+03, Data-loss 1.9093e+03                  , pde-loss 9.9120e+02, initc-loss 1.5300e+04                    bc_loss 1.5325e+04\n",
      "Epoch 8470, Training-Loss 3.2377e+03, Data-loss 2.4220e+03                  , pde-loss 1.5174e+03, initc-loss 1.9717e+04                    bc_loss 6.0327e+04\n",
      "Epoch 8480, Training-Loss 9.3885e+03, Data-loss 4.2881e+03                  , pde-loss 3.0785e+03, initc-loss 2.6933e+04                    bc_loss 4.8003e+05\n",
      "Epoch 8490, Training-Loss 5.2382e+03, Data-loss 2.5801e+03                  , pde-loss 3.2856e+03, initc-loss 1.9690e+04                    bc_loss 2.4283e+05\n",
      "Epoch 8500, Training-Loss 5.0854e+03, Data-loss 3.0337e+03                  , pde-loss 7.3806e+02, initc-loss 1.9501e+04                    bc_loss 1.8493e+05\n",
      "Epoch 8510, Training-Loss 4.6133e+03, Data-loss 2.7511e+03                  , pde-loss 5.1861e+02, initc-loss 1.8661e+04                    bc_loss 1.6704e+05\n",
      "Epoch 8520, Training-Loss 1.9261e+03, Data-loss 1.1266e+03                  , pde-loss 2.0683e+03, initc-loss 1.5195e+04                    bc_loss 6.2690e+04\n",
      "Epoch 8530, Training-Loss 2.3855e+03, Data-loss 1.8064e+03                  , pde-loss 1.9737e+03, initc-loss 1.2203e+04                    bc_loss 4.3733e+04\n",
      "Epoch 8540, Training-Loss 1.0019e+04, Data-loss 2.3472e+03                  , pde-loss 7.4310e+02, initc-loss 2.1327e+04                    bc_loss 7.4509e+05\n",
      "Epoch 8550, Training-Loss 5.2113e+03, Data-loss 3.3173e+03                  , pde-loss 2.2481e+02, initc-loss 1.9392e+04                    bc_loss 1.6978e+05\n",
      "Epoch 8560, Training-Loss 6.2675e+03, Data-loss 4.4253e+03                  , pde-loss 1.1486e+03, initc-loss 1.6165e+04                    bc_loss 1.6691e+05\n",
      "Epoch 8570, Training-Loss 4.2885e+03, Data-loss 2.8846e+03                  , pde-loss 4.2786e+03, initc-loss 2.0986e+04                    bc_loss 1.1512e+05\n",
      "Epoch 8580, Training-Loss 2.6978e+03, Data-loss 1.4756e+03                  , pde-loss 3.5779e+03, initc-loss 1.7354e+04                    bc_loss 1.0128e+05\n",
      "Epoch 8590, Training-Loss 7.1487e+03, Data-loss 3.7379e+03                  , pde-loss 7.1006e+02, initc-loss 1.8629e+04                    bc_loss 3.2174e+05\n",
      "Epoch 8600, Training-Loss 8.7326e+03, Data-loss 4.5230e+03                  , pde-loss 2.7778e+02, initc-loss 1.8757e+04                    bc_loss 4.0192e+05\n",
      "Epoch 8610, Training-Loss 3.8753e+03, Data-loss 2.8941e+03                  , pde-loss 1.4919e+03, initc-loss 1.3817e+04                    bc_loss 8.2803e+04\n",
      "Epoch 8620, Training-Loss 4.1666e+03, Data-loss 2.7815e+03                  , pde-loss 3.2356e+03, initc-loss 1.1614e+04                    bc_loss 1.2367e+05\n",
      "Epoch 8630, Training-Loss 1.7928e+03, Data-loss 1.0684e+03                  , pde-loss 1.2362e+03, initc-loss 1.4491e+04                    bc_loss 5.6711e+04\n",
      "Epoch 8640, Training-Loss 4.8563e+03, Data-loss 3.0074e+03                  , pde-loss 7.2758e+02, initc-loss 1.5360e+04                    bc_loss 1.6881e+05\n",
      "Epoch 8650, Training-Loss 3.2071e+03, Data-loss 1.3398e+03                  , pde-loss 6.2013e+02, initc-loss 1.3614e+04                    bc_loss 1.7249e+05\n",
      "Epoch 8660, Training-Loss 1.9985e+03, Data-loss 1.6131e+03                  , pde-loss 2.8925e+03, initc-loss 1.3529e+04                    bc_loss 2.2115e+04\n",
      "Epoch 8670, Training-Loss 3.0934e+03, Data-loss 2.2199e+03                  , pde-loss 3.4952e+03, initc-loss 1.6219e+04                    bc_loss 6.7641e+04\n",
      "Epoch 8680, Training-Loss 2.0844e+03, Data-loss 1.5138e+03                  , pde-loss 1.6322e+03, initc-loss 1.4548e+04                    bc_loss 4.0871e+04\n",
      "Epoch 8690, Training-Loss 1.0022e+04, Data-loss 4.6477e+03                  , pde-loss 2.1864e+03, initc-loss 2.3815e+04                    bc_loss 5.1138e+05\n",
      "Epoch 8700, Training-Loss 3.5708e+03, Data-loss 2.1913e+03                  , pde-loss 2.0759e+03, initc-loss 1.4207e+04                    bc_loss 1.2167e+05\n",
      "Epoch 8710, Training-Loss 3.6910e+03, Data-loss 2.4816e+03                  , pde-loss 5.8555e+02, initc-loss 1.7662e+04                    bc_loss 1.0269e+05\n",
      "Epoch 8720, Training-Loss 4.5696e+03, Data-loss 2.7768e+03                  , pde-loss 3.6714e+02, initc-loss 2.1215e+04                    bc_loss 1.5771e+05\n",
      "Epoch 8730, Training-Loss 3.3506e+03, Data-loss 2.7818e+03                  , pde-loss 2.4613e+03, initc-loss 1.8815e+04                    bc_loss 3.5604e+04\n",
      "Epoch 8740, Training-Loss 2.2967e+03, Data-loss 1.6650e+03                  , pde-loss 2.0558e+03, initc-loss 1.3732e+04                    bc_loss 4.7390e+04\n",
      "Epoch 8750, Training-Loss 4.0525e+03, Data-loss 2.0400e+03                  , pde-loss 9.7328e+02, initc-loss 1.9018e+04                    bc_loss 1.8126e+05\n",
      "Epoch 8760, Training-Loss 8.8100e+03, Data-loss 6.6428e+03                  , pde-loss 3.0790e+02, initc-loss 2.1925e+04                    bc_loss 1.9449e+05\n",
      "Epoch 8770, Training-Loss 6.5014e+03, Data-loss 3.4155e+03                  , pde-loss 1.5987e+03, initc-loss 2.1330e+04                    bc_loss 2.8567e+05\n",
      "Epoch 8780, Training-Loss 6.6304e+03, Data-loss 3.6313e+03                  , pde-loss 4.8893e+03, initc-loss 2.3315e+04                    bc_loss 2.7171e+05\n",
      "Epoch 8790, Training-Loss 2.8312e+03, Data-loss 2.2414e+03                  , pde-loss 2.3056e+03, initc-loss 1.4173e+04                    bc_loss 4.2506e+04\n",
      "Epoch 8800, Training-Loss 4.5455e+03, Data-loss 2.7093e+03                  , pde-loss 7.7418e+02, initc-loss 1.9959e+04                    bc_loss 1.6288e+05\n",
      "Epoch 8810, Training-Loss 3.0347e+03, Data-loss 2.1933e+03                  , pde-loss 5.1562e+02, initc-loss 1.3641e+04                    bc_loss 6.9988e+04\n",
      "Epoch 8820, Training-Loss 5.2829e+03, Data-loss 2.0943e+03                  , pde-loss 2.4565e+03, initc-loss 1.7952e+04                    bc_loss 2.9845e+05\n",
      "Epoch 8830, Training-Loss 8.0715e+03, Data-loss 4.7946e+03                  , pde-loss 5.6162e+03, initc-loss 1.9770e+04                    bc_loss 3.0230e+05\n",
      "Epoch 8840, Training-Loss 4.8167e+03, Data-loss 2.6055e+03                  , pde-loss 1.5241e+03, initc-loss 1.4627e+04                    bc_loss 2.0497e+05\n",
      "Epoch 8850, Training-Loss 1.1605e+04, Data-loss 7.0330e+03                  , pde-loss 4.9927e+02, initc-loss 2.4647e+04                    bc_loss 4.3201e+05\n",
      "Epoch 8860, Training-Loss 6.2345e+03, Data-loss 3.9674e+03                  , pde-loss 6.8616e+02, initc-loss 1.6730e+04                    bc_loss 2.0929e+05\n",
      "Epoch 8870, Training-Loss 3.8526e+03, Data-loss 2.5612e+03                  , pde-loss 3.2208e+03, initc-loss 1.4823e+04                    bc_loss 1.1110e+05\n",
      "Epoch 8880, Training-Loss 1.4884e+03, Data-loss 1.0651e+03                  , pde-loss 1.5074e+03, initc-loss 1.7067e+04                    bc_loss 2.3751e+04\n",
      "Epoch 8890, Training-Loss 4.3264e+03, Data-loss 1.9793e+03                  , pde-loss 9.1651e+02, initc-loss 1.9854e+04                    bc_loss 2.1394e+05\n",
      "Epoch 8900, Training-Loss 6.5804e+03, Data-loss 3.0797e+03                  , pde-loss 8.4674e+02, initc-loss 1.4790e+04                    bc_loss 3.3443e+05\n",
      "Epoch 8910, Training-Loss 2.0715e+03, Data-loss 1.7728e+03                  , pde-loss 2.9053e+03, initc-loss 1.8674e+04                    bc_loss 8.2893e+03\n",
      "Epoch 8920, Training-Loss 1.6107e+03, Data-loss 1.1865e+03                  , pde-loss 2.5615e+03, initc-loss 1.6569e+04                    bc_loss 2.3296e+04\n",
      "Epoch 8930, Training-Loss 2.8216e+03, Data-loss 2.4886e+03                  , pde-loss 1.2316e+03, initc-loss 1.6200e+04                    bc_loss 1.5865e+04\n",
      "Epoch 8940, Training-Loss 2.3031e+03, Data-loss 1.9411e+03                  , pde-loss 9.4050e+02, initc-loss 1.2098e+04                    bc_loss 2.3156e+04\n",
      "Epoch 8950, Training-Loss 2.7478e+03, Data-loss 1.5493e+03                  , pde-loss 1.3738e+03, initc-loss 1.4392e+04                    bc_loss 1.0408e+05\n",
      "Epoch 8960, Training-Loss 5.4502e+03, Data-loss 2.7651e+03                  , pde-loss 3.3538e+03, initc-loss 2.0244e+04                    bc_loss 2.4491e+05\n",
      "Epoch 8970, Training-Loss 5.9420e+03, Data-loss 4.2227e+03                  , pde-loss 3.1208e+03, initc-loss 1.1355e+04                    bc_loss 1.5746e+05\n",
      "Epoch 8980, Training-Loss 6.1279e+03, Data-loss 1.8601e+03                  , pde-loss 1.4947e+03, initc-loss 9.9882e+03                    bc_loss 4.1530e+05\n",
      "Epoch 8990, Training-Loss 4.3567e+03, Data-loss 3.0607e+03                  , pde-loss 2.4984e+02, initc-loss 1.8165e+04                    bc_loss 1.1118e+05\n",
      "Epoch 9000, Training-Loss 3.7141e+03, Data-loss 2.1767e+03                  , pde-loss 1.0985e+03, initc-loss 1.6772e+04                    bc_loss 1.3587e+05\n",
      "Epoch 9010, Training-Loss 2.9171e+03, Data-loss 2.4796e+03                  , pde-loss 2.2661e+03, initc-loss 1.8122e+04                    bc_loss 2.3362e+04\n",
      "Epoch 9020, Training-Loss 1.8083e+03, Data-loss 1.3011e+03                  , pde-loss 1.7603e+03, initc-loss 1.7444e+04                    bc_loss 3.1518e+04\n",
      "Epoch 9030, Training-Loss 2.8780e+03, Data-loss 1.7192e+03                  , pde-loss 1.0256e+03, initc-loss 1.6036e+04                    bc_loss 9.8822e+04\n",
      "Epoch 9040, Training-Loss 1.8262e+04, Data-loss 1.3599e+04                  , pde-loss 1.3971e+03, initc-loss 5.0873e+04                    bc_loss 4.1407e+05\n",
      "Epoch 9050, Training-Loss 8.2955e+03, Data-loss 7.6800e+03                  , pde-loss 1.0153e+03, initc-loss 1.2349e+04                    bc_loss 4.8182e+04\n",
      "Epoch 9060, Training-Loss 5.7349e+03, Data-loss 4.1940e+03                  , pde-loss 5.3845e+02, initc-loss 1.3020e+04                    bc_loss 1.4053e+05\n",
      "Epoch 9070, Training-Loss 3.7073e+03, Data-loss 2.5925e+03                  , pde-loss 2.3570e+03, initc-loss 1.2299e+04                    bc_loss 9.6824e+04\n",
      "Epoch 9080, Training-Loss 2.2981e+03, Data-loss 1.5024e+03                  , pde-loss 2.1495e+03, initc-loss 1.4414e+04                    bc_loss 6.3009e+04\n",
      "Epoch 9090, Training-Loss 3.3205e+03, Data-loss 1.6417e+03                  , pde-loss 1.2810e+03, initc-loss 1.5844e+04                    bc_loss 1.5076e+05\n",
      "Epoch 9100, Training-Loss 3.7861e+03, Data-loss 2.7181e+03                  , pde-loss 2.0815e+03, initc-loss 1.4706e+04                    bc_loss 9.0018e+04\n",
      "Epoch 9110, Training-Loss 7.5678e+03, Data-loss 3.4808e+03                  , pde-loss 3.7254e+03, initc-loss 1.6792e+04                    bc_loss 3.8818e+05\n",
      "Epoch 9120, Training-Loss 6.7700e+03, Data-loss 3.5762e+03                  , pde-loss 1.9158e+03, initc-loss 2.1617e+04                    bc_loss 2.9585e+05\n",
      "Epoch 9130, Training-Loss 1.0220e+04, Data-loss 3.4765e+03                  , pde-loss 3.5738e+02, initc-loss 1.6506e+04                    bc_loss 6.5752e+05\n",
      "Epoch 9140, Training-Loss 1.0895e+04, Data-loss 4.7237e+03                  , pde-loss 3.0746e+02, initc-loss 2.0058e+04                    bc_loss 5.9678e+05\n",
      "Epoch 9150, Training-Loss 7.8644e+03, Data-loss 3.6655e+03                  , pde-loss 6.2781e+02, initc-loss 1.3212e+04                    bc_loss 4.0605e+05\n",
      "Epoch 9160, Training-Loss 5.4639e+03, Data-loss 4.3857e+03                  , pde-loss 5.0195e+03, initc-loss 2.4162e+04                    bc_loss 7.8634e+04\n",
      "Epoch 9170, Training-Loss 2.8545e+03, Data-loss 2.5125e+03                  , pde-loss 3.1929e+03, initc-loss 1.5011e+04                    bc_loss 1.5999e+04\n",
      "Epoch 9180, Training-Loss 3.9970e+03, Data-loss 3.2454e+03                  , pde-loss 1.1690e+03, initc-loss 1.5687e+04                    bc_loss 5.8302e+04\n",
      "Epoch 9190, Training-Loss 3.0312e+03, Data-loss 2.4077e+03                  , pde-loss 9.2159e+02, initc-loss 1.4211e+04                    bc_loss 4.7216e+04\n",
      "Epoch 9200, Training-Loss 2.2015e+03, Data-loss 1.7209e+03                  , pde-loss 7.2289e+02, initc-loss 1.4914e+04                    bc_loss 3.2425e+04\n",
      "Epoch 9210, Training-Loss 1.8086e+03, Data-loss 1.2248e+03                  , pde-loss 1.2532e+03, initc-loss 1.4998e+04                    bc_loss 4.2122e+04\n",
      "Epoch 9220, Training-Loss 5.5519e+03, Data-loss 1.8656e+03                  , pde-loss 1.3735e+03, initc-loss 1.6182e+04                    bc_loss 3.5108e+05\n",
      "Epoch 9230, Training-Loss 4.4974e+03, Data-loss 2.1099e+03                  , pde-loss 6.4687e+02, initc-loss 2.0169e+04                    bc_loss 2.1794e+05\n",
      "Epoch 9240, Training-Loss 3.2322e+03, Data-loss 2.8284e+03                  , pde-loss 1.1662e+03, initc-loss 1.6404e+04                    bc_loss 2.2806e+04\n",
      "Epoch 9250, Training-Loss 2.5896e+03, Data-loss 1.3576e+03                  , pde-loss 2.1000e+03, initc-loss 1.5655e+04                    bc_loss 1.0544e+05\n",
      "Epoch 9260, Training-Loss 1.7176e+03, Data-loss 1.0403e+03                  , pde-loss 2.6312e+03, initc-loss 1.2954e+04                    bc_loss 5.2144e+04\n",
      "Epoch 9270, Training-Loss 2.1889e+03, Data-loss 1.0802e+03                  , pde-loss 2.0265e+03, initc-loss 1.5367e+04                    bc_loss 9.3482e+04\n",
      "Epoch 9280, Training-Loss 9.8881e+03, Data-loss 4.9168e+03                  , pde-loss 3.9500e+02, initc-loss 2.8682e+04                    bc_loss 4.6805e+05\n",
      "Epoch 9290, Training-Loss 8.6668e+03, Data-loss 5.0949e+03                  , pde-loss 5.5473e+02, initc-loss 1.4647e+04                    bc_loss 3.4198e+05\n",
      "Epoch 9300, Training-Loss 4.3561e+03, Data-loss 3.0146e+03                  , pde-loss 3.7916e+03, initc-loss 1.3361e+04                    bc_loss 1.1700e+05\n",
      "Epoch 9310, Training-Loss 2.7380e+03, Data-loss 1.9435e+03                  , pde-loss 2.7480e+03, initc-loss 1.4956e+04                    bc_loss 6.1744e+04\n",
      "Epoch 9320, Training-Loss 3.4198e+03, Data-loss 2.8322e+03                  , pde-loss 8.0353e+02, initc-loss 1.5648e+04                    bc_loss 4.2318e+04\n",
      "Epoch 9330, Training-Loss 3.6335e+03, Data-loss 2.6342e+03                  , pde-loss 8.0573e+02, initc-loss 1.6575e+04                    bc_loss 8.2545e+04\n",
      "Epoch 9340, Training-Loss 3.0605e+03, Data-loss 2.2874e+03                  , pde-loss 1.8713e+03, initc-loss 1.1409e+04                    bc_loss 6.4034e+04\n",
      "Epoch 9350, Training-Loss 1.0955e+04, Data-loss 4.0865e+03                  , pde-loss 4.0503e+03, initc-loss 2.5225e+04                    bc_loss 6.5761e+05\n",
      "Epoch 9360, Training-Loss 2.7304e+03, Data-loss 1.9904e+03                  , pde-loss 3.4759e+03, initc-loss 1.4795e+04                    bc_loss 5.5727e+04\n",
      "Epoch 9370, Training-Loss 2.5114e+03, Data-loss 1.6769e+03                  , pde-loss 1.3756e+03, initc-loss 1.4094e+04                    bc_loss 6.7978e+04\n",
      "Epoch 9380, Training-Loss 2.6561e+03, Data-loss 1.9896e+03                  , pde-loss 1.2395e+03, initc-loss 1.5371e+04                    bc_loss 5.0048e+04\n",
      "Epoch 9390, Training-Loss 2.1592e+03, Data-loss 1.4119e+03                  , pde-loss 2.1001e+03, initc-loss 1.6265e+04                    bc_loss 5.6363e+04\n",
      "Epoch 9400, Training-Loss 1.1677e+04, Data-loss 4.1200e+03                  , pde-loss 2.6903e+03, initc-loss 2.6370e+04                    bc_loss 7.2662e+05\n",
      "Epoch 9410, Training-Loss 9.7275e+03, Data-loss 3.8800e+03                  , pde-loss 2.6356e+03, initc-loss 6.1479e+03                    bc_loss 5.7596e+05\n",
      "Epoch 9420, Training-Loss 1.2857e+04, Data-loss 4.5046e+03                  , pde-loss 5.6529e+02, initc-loss 2.0188e+04                    bc_loss 8.1451e+05\n",
      "Epoch 9430, Training-Loss 5.2730e+03, Data-loss 2.9998e+03                  , pde-loss 1.6877e+02, initc-loss 1.6622e+04                    bc_loss 2.1053e+05\n",
      "Epoch 9440, Training-Loss 4.1130e+03, Data-loss 2.6358e+03                  , pde-loss 2.7062e+03, initc-loss 1.8090e+04                    bc_loss 1.2693e+05\n",
      "Epoch 9450, Training-Loss 2.9277e+03, Data-loss 2.3612e+03                  , pde-loss 1.4453e+03, initc-loss 1.9278e+04                    bc_loss 3.5923e+04\n",
      "Epoch 9460, Training-Loss 4.0242e+03, Data-loss 3.2629e+03                  , pde-loss 6.9485e+02, initc-loss 1.7974e+04                    bc_loss 5.7457e+04\n",
      "Epoch 9470, Training-Loss 4.2413e+03, Data-loss 1.5587e+03                  , pde-loss 1.1638e+03, initc-loss 1.4491e+04                    bc_loss 2.5260e+05\n",
      "Epoch 9480, Training-Loss 1.2152e+03, Data-loss 8.4437e+02                  , pde-loss 1.8339e+03, initc-loss 1.5587e+04                    bc_loss 1.9667e+04\n",
      "Epoch 9490, Training-Loss 1.4522e+03, Data-loss 1.0316e+03                  , pde-loss 2.1548e+03, initc-loss 1.5035e+04                    bc_loss 2.4872e+04\n",
      "Epoch 9500, Training-Loss 2.2131e+03, Data-loss 1.7702e+03                  , pde-loss 1.6988e+03, initc-loss 1.7155e+04                    bc_loss 2.5429e+04\n",
      "Epoch 9510, Training-Loss 8.5026e+03, Data-loss 1.9226e+03                  , pde-loss 1.1116e+03, initc-loss 1.7850e+04                    bc_loss 6.3903e+05\n",
      "Epoch 9520, Training-Loss 2.9644e+03, Data-loss 1.9188e+03                  , pde-loss 8.3064e+02, initc-loss 1.0383e+04                    bc_loss 9.3349e+04\n",
      "Epoch 9530, Training-Loss 2.3537e+03, Data-loss 1.5676e+03                  , pde-loss 1.8622e+03, initc-loss 1.4191e+04                    bc_loss 6.2553e+04\n",
      "Epoch 9540, Training-Loss 1.3527e+03, Data-loss 9.6991e+02                  , pde-loss 1.4002e+03, initc-loss 1.3630e+04                    bc_loss 2.3250e+04\n",
      "Epoch 9550, Training-Loss 6.8322e+02, Data-loss 3.9871e+02                  , pde-loss 1.4040e+03, initc-loss 1.5577e+04                    bc_loss 1.1470e+04\n",
      "Epoch 9560, Training-Loss 1.7425e+03, Data-loss 1.0053e+03                  , pde-loss 1.4913e+03, initc-loss 1.4405e+04                    bc_loss 5.7829e+04\n",
      "Epoch 9570, Training-Loss 9.7647e+02, Data-loss 3.3473e+02                  , pde-loss 1.2419e+03, initc-loss 1.2028e+04                    bc_loss 5.0904e+04\n",
      "Epoch 9580, Training-Loss 1.9283e+03, Data-loss 1.2365e+03                  , pde-loss 2.0218e+03, initc-loss 1.4825e+04                    bc_loss 5.2331e+04\n",
      "Epoch 9590, Training-Loss 2.9234e+03, Data-loss 1.8797e+03                  , pde-loss 2.5117e+03, initc-loss 1.6992e+04                    bc_loss 8.4862e+04\n",
      "Epoch 9600, Training-Loss 3.7281e+03, Data-loss 1.8320e+03                  , pde-loss 2.8398e+03, initc-loss 1.9043e+04                    bc_loss 1.6773e+05\n",
      "Epoch 9610, Training-Loss 2.3943e+03, Data-loss 1.4927e+03                  , pde-loss 1.4440e+03, initc-loss 1.2533e+04                    bc_loss 7.6184e+04\n",
      "Epoch 9620, Training-Loss 7.6423e+03, Data-loss 1.3344e+03                  , pde-loss 7.1053e+02, initc-loss 1.4869e+04                    bc_loss 6.1520e+05\n",
      "Epoch 9630, Training-Loss 2.5201e+03, Data-loss 1.1301e+03                  , pde-loss 4.9839e+02, initc-loss 1.2765e+04                    bc_loss 1.2574e+05\n",
      "Epoch 9640, Training-Loss 1.5289e+03, Data-loss 1.0064e+03                  , pde-loss 1.2702e+03, initc-loss 1.1999e+04                    bc_loss 3.8975e+04\n",
      "Epoch 9650, Training-Loss 2.5883e+03, Data-loss 1.9170e+03                  , pde-loss 1.5257e+03, initc-loss 1.4537e+04                    bc_loss 5.1066e+04\n",
      "Epoch 9660, Training-Loss 4.1614e+03, Data-loss 9.3511e+02                  , pde-loss 1.1220e+03, initc-loss 1.6617e+04                    bc_loss 3.0489e+05\n",
      "Epoch 9670, Training-Loss 5.7642e+03, Data-loss 4.0693e+03                  , pde-loss 4.7776e+02, initc-loss 2.2152e+04                    bc_loss 1.4686e+05\n",
      "Epoch 9680, Training-Loss 3.1577e+03, Data-loss 2.5107e+03                  , pde-loss 1.1731e+03, initc-loss 1.3020e+04                    bc_loss 5.0508e+04\n",
      "Epoch 9690, Training-Loss 2.1375e+03, Data-loss 1.2893e+03                  , pde-loss 1.8514e+03, initc-loss 1.3429e+04                    bc_loss 6.9542e+04\n",
      "Epoch 9700, Training-Loss 3.8161e+03, Data-loss 3.2661e+03                  , pde-loss 1.2321e+03, initc-loss 1.5739e+04                    bc_loss 3.8035e+04\n",
      "Epoch 9710, Training-Loss 2.9168e+03, Data-loss 2.2119e+03                  , pde-loss 1.0286e+03, initc-loss 1.4213e+04                    bc_loss 5.5248e+04\n",
      "Epoch 9720, Training-Loss 8.9294e+03, Data-loss 5.5224e+03                  , pde-loss 7.2870e+02, initc-loss 3.2896e+04                    bc_loss 3.0708e+05\n",
      "Epoch 9730, Training-Loss 6.8172e+03, Data-loss 3.2040e+03                  , pde-loss 1.6996e+03, initc-loss 1.5824e+04                    bc_loss 3.4380e+05\n",
      "Epoch 9740, Training-Loss 1.0350e+04, Data-loss 5.3935e+03                  , pde-loss 7.7703e+03, initc-loss 2.3491e+04                    bc_loss 4.6441e+05\n",
      "Epoch 9750, Training-Loss 6.6057e+03, Data-loss 3.2499e+03                  , pde-loss 3.7586e+03, initc-loss 1.0406e+04                    bc_loss 3.2142e+05\n",
      "Epoch 9760, Training-Loss 4.0419e+03, Data-loss 2.7908e+03                  , pde-loss 5.2887e+02, initc-loss 1.5237e+04                    bc_loss 1.0935e+05\n",
      "Epoch 9770, Training-Loss 1.8950e+03, Data-loss 1.2069e+03                  , pde-loss 1.2057e+03, initc-loss 1.3640e+04                    bc_loss 5.3964e+04\n",
      "Epoch 9780, Training-Loss 2.7246e+03, Data-loss 1.5356e+03                  , pde-loss 1.1003e+03, initc-loss 1.5164e+04                    bc_loss 1.0264e+05\n",
      "Epoch 9790, Training-Loss 1.8559e+03, Data-loss 1.4630e+03                  , pde-loss 1.0159e+03, initc-loss 1.5079e+04                    bc_loss 2.3203e+04\n",
      "Epoch 9800, Training-Loss 1.5205e+03, Data-loss 9.9337e+02                  , pde-loss 1.6136e+03, initc-loss 1.1381e+04                    bc_loss 3.9719e+04\n",
      "Epoch 9810, Training-Loss 2.7125e+03, Data-loss 1.1496e+03                  , pde-loss 1.2704e+03, initc-loss 1.4358e+04                    bc_loss 1.4067e+05\n",
      "Epoch 9820, Training-Loss 4.8325e+03, Data-loss 1.7362e+03                  , pde-loss 1.1329e+03, initc-loss 1.6087e+04                    bc_loss 2.9242e+05\n",
      "Epoch 9830, Training-Loss 2.2237e+03, Data-loss 1.0019e+03                  , pde-loss 1.3395e+03, initc-loss 1.3708e+04                    bc_loss 1.0714e+05\n",
      "Epoch 9840, Training-Loss 2.0746e+03, Data-loss 1.4563e+03                  , pde-loss 2.1440e+03, initc-loss 1.5012e+04                    bc_loss 4.4671e+04\n",
      "Epoch 9850, Training-Loss 1.9946e+03, Data-loss 1.5512e+03                  , pde-loss 2.1254e+03, initc-loss 1.4593e+04                    bc_loss 2.7620e+04\n",
      "Epoch 9860, Training-Loss 2.0251e+03, Data-loss 1.3900e+03                  , pde-loss 1.8089e+03, initc-loss 1.5552e+04                    bc_loss 4.6146e+04\n",
      "Epoch 9870, Training-Loss 1.0679e+03, Data-loss 5.9693e+02                  , pde-loss 1.6671e+03, initc-loss 1.4502e+04                    bc_loss 3.0924e+04\n",
      "Epoch 9880, Training-Loss 1.8341e+03, Data-loss 8.8896e+02                  , pde-loss 1.7800e+03, initc-loss 1.5171e+04                    bc_loss 7.7560e+04\n",
      "Epoch 9890, Training-Loss 3.7856e+03, Data-loss 1.3425e+03                  , pde-loss 2.7395e+03, initc-loss 1.6889e+04                    bc_loss 2.2468e+05\n",
      "Epoch 9900, Training-Loss 2.2650e+03, Data-loss 1.4906e+03                  , pde-loss 1.6317e+03, initc-loss 1.9328e+04                    bc_loss 5.6479e+04\n",
      "Epoch 9910, Training-Loss 1.4075e+03, Data-loss 1.0152e+03                  , pde-loss 1.4050e+03, initc-loss 1.4900e+04                    bc_loss 2.2931e+04\n",
      "Epoch 9920, Training-Loss 1.3679e+03, Data-loss 9.5695e+02                  , pde-loss 1.4939e+03, initc-loss 1.5524e+04                    bc_loss 2.4074e+04\n",
      "Epoch 9930, Training-Loss 8.5497e+03, Data-loss 3.9551e+03                  , pde-loss 4.2399e+02, initc-loss 2.3704e+04                    bc_loss 4.3533e+05\n",
      "Epoch 9940, Training-Loss 3.4781e+03, Data-loss 3.0085e+03                  , pde-loss 5.4576e+02, initc-loss 2.0526e+04                    bc_loss 2.5886e+04\n",
      "Epoch 9950, Training-Loss 1.2374e+03, Data-loss 5.8916e+02                  , pde-loss 1.2561e+03, initc-loss 1.5247e+04                    bc_loss 4.8324e+04\n",
      "Epoch 9960, Training-Loss 3.5286e+03, Data-loss 2.4010e+03                  , pde-loss 8.7337e+02, initc-loss 1.3060e+04                    bc_loss 9.8832e+04\n",
      "Epoch 9970, Training-Loss 2.2824e+03, Data-loss 1.0934e+03                  , pde-loss 1.1570e+03, initc-loss 1.3841e+04                    bc_loss 1.0390e+05\n",
      "Epoch 9980, Training-Loss 2.8877e+03, Data-loss 2.4964e+03                  , pde-loss 2.6312e+03, initc-loss 1.7285e+04                    bc_loss 1.9214e+04\n",
      "Epoch 9990, Training-Loss 2.0127e+03, Data-loss 1.5592e+03                  , pde-loss 2.2034e+03, initc-loss 1.5253e+04                    bc_loss 2.7887e+04\n",
      "Epoch 10000, Training-Loss 1.5005e+03, Data-loss 7.0408e+02                  , pde-loss 1.3755e+03, initc-loss 1.4473e+04                    bc_loss 6.3794e+04\n",
      "Epoch 10010, Training-Loss 8.2421e+03, Data-loss 5.1234e+03                  , pde-loss 2.7486e+03, initc-loss 3.2771e+04                    bc_loss 2.7635e+05\n",
      "Epoch 10020, Training-Loss 5.3201e+03, Data-loss 3.3723e+03                  , pde-loss 2.7880e+03, initc-loss 1.5003e+04                    bc_loss 1.7699e+05\n",
      "Epoch 10030, Training-Loss 5.7861e+03, Data-loss 2.3528e+03                  , pde-loss 6.1091e+02, initc-loss 1.2857e+04                    bc_loss 3.2986e+05\n",
      "Epoch 10040, Training-Loss 4.3405e+03, Data-loss 2.5959e+03                  , pde-loss 8.6096e+02, initc-loss 1.1291e+04                    bc_loss 1.6231e+05\n",
      "Epoch 10050, Training-Loss 3.2009e+03, Data-loss 2.2735e+03                  , pde-loss 2.8566e+03, initc-loss 1.7597e+04                    bc_loss 7.2277e+04\n",
      "Epoch 10060, Training-Loss 4.4537e+03, Data-loss 2.0464e+03                  , pde-loss 2.9704e+03, initc-loss 1.6911e+04                    bc_loss 2.2085e+05\n",
      "Epoch 10070, Training-Loss 7.5685e+03, Data-loss 3.8408e+03                  , pde-loss 3.7937e+03, initc-loss 1.3979e+04                    bc_loss 3.5500e+05\n",
      "Epoch 10080, Training-Loss 4.3145e+03, Data-loss 2.9698e+03                  , pde-loss 6.8283e+02, initc-loss 1.8711e+04                    bc_loss 1.1508e+05\n",
      "Epoch 10090, Training-Loss 1.0732e+04, Data-loss 4.1930e+03                  , pde-loss 2.7977e+02, initc-loss 2.4540e+04                    bc_loss 6.2912e+05\n",
      "Epoch 10100, Training-Loss 2.9961e+03, Data-loss 2.2702e+03                  , pde-loss 7.9390e+02, initc-loss 1.3170e+04                    bc_loss 5.8625e+04\n",
      "Epoch 10110, Training-Loss 3.6046e+03, Data-loss 2.6518e+03                  , pde-loss 2.7780e+03, initc-loss 1.3542e+04                    bc_loss 7.8967e+04\n",
      "Epoch 10120, Training-Loss 2.5132e+03, Data-loss 1.9251e+03                  , pde-loss 1.3897e+03, initc-loss 1.7710e+04                    bc_loss 3.9707e+04\n",
      "Epoch 10130, Training-Loss 2.0481e+03, Data-loss 1.4659e+03                  , pde-loss 1.2353e+03, initc-loss 1.3980e+04                    bc_loss 4.3001e+04\n",
      "Epoch 10140, Training-Loss 2.8319e+03, Data-loss 1.9390e+03                  , pde-loss 1.7183e+03, initc-loss 1.5964e+04                    bc_loss 7.1608e+04\n",
      "Epoch 10150, Training-Loss 2.5662e+03, Data-loss 1.7785e+03                  , pde-loss 2.3541e+03, initc-loss 1.6076e+04                    bc_loss 6.0341e+04\n",
      "Epoch 10160, Training-Loss 1.6269e+04, Data-loss 7.0638e+03                  , pde-loss 1.0211e+03, initc-loss 3.6459e+04                    bc_loss 8.8304e+05\n",
      "Epoch 10170, Training-Loss 5.3490e+03, Data-loss 4.1866e+03                  , pde-loss 1.7659e+02, initc-loss 9.1076e+03                    bc_loss 1.0696e+05\n",
      "Epoch 10180, Training-Loss 6.7217e+03, Data-loss 3.9674e+03                  , pde-loss 6.9805e+02, initc-loss 9.0144e+03                    bc_loss 2.6572e+05\n",
      "Epoch 10190, Training-Loss 4.0930e+03, Data-loss 3.1185e+03                  , pde-loss 4.4459e+03, initc-loss 1.7472e+04                    bc_loss 7.5527e+04\n",
      "Epoch 10200, Training-Loss 3.9727e+03, Data-loss 3.0852e+03                  , pde-loss 4.1712e+03, initc-loss 1.5741e+04                    bc_loss 6.8837e+04\n",
      "Epoch 10210, Training-Loss 1.7100e+03, Data-loss 1.3785e+03                  , pde-loss 1.5403e+03, initc-loss 1.0501e+04                    bc_loss 2.1110e+04\n",
      "Epoch 10220, Training-Loss 2.4115e+03, Data-loss 1.7992e+03                  , pde-loss 1.1744e+03, initc-loss 1.3236e+04                    bc_loss 4.6821e+04\n",
      "Epoch 10230, Training-Loss 1.2194e+03, Data-loss 8.3403e+02                  , pde-loss 1.0622e+03, initc-loss 1.4848e+04                    bc_loss 2.2628e+04\n",
      "Epoch 10240, Training-Loss 6.6840e+03, Data-loss 2.0158e+03                  , pde-loss 8.1115e+02, initc-loss 2.0531e+04                    bc_loss 4.4547e+05\n",
      "Epoch 10250, Training-Loss 5.1924e+03, Data-loss 3.9582e+03                  , pde-loss 4.6075e+02, initc-loss 1.6926e+04                    bc_loss 1.0603e+05\n",
      "Epoch 10260, Training-Loss 3.9659e+03, Data-loss 3.3886e+03                  , pde-loss 9.7161e+02, initc-loss 1.0885e+04                    bc_loss 4.5876e+04\n",
      "Epoch 10270, Training-Loss 2.2554e+03, Data-loss 1.7401e+03                  , pde-loss 2.4186e+03, initc-loss 1.7975e+04                    bc_loss 3.1135e+04\n",
      "Epoch 10280, Training-Loss 1.7397e+03, Data-loss 1.2861e+03                  , pde-loss 2.0570e+03, initc-loss 1.6002e+04                    bc_loss 2.7306e+04\n",
      "Epoch 10290, Training-Loss 1.8263e+04, Data-loss 3.5851e+03                  , pde-loss 9.8476e+02, initc-loss 1.9610e+04                    bc_loss 1.4472e+06\n",
      "Epoch 10300, Training-Loss 1.1622e+04, Data-loss 7.7963e+03                  , pde-loss 7.1201e+02, initc-loss 1.0873e+04                    bc_loss 3.7104e+05\n",
      "Epoch 10310, Training-Loss 4.9241e+03, Data-loss 4.0225e+03                  , pde-loss 3.0139e+03, initc-loss 1.9530e+04                    bc_loss 6.7619e+04\n",
      "Epoch 10320, Training-Loss 1.2735e+04, Data-loss 8.3387e+03                  , pde-loss 4.5242e+03, initc-loss 3.6518e+04                    bc_loss 3.9855e+05\n",
      "Epoch 10330, Training-Loss 6.7166e+03, Data-loss 3.2623e+03                  , pde-loss 3.9597e+03, initc-loss 1.7303e+04                    bc_loss 3.2416e+05\n",
      "Epoch 10340, Training-Loss 3.4000e+03, Data-loss 2.6250e+03                  , pde-loss 7.9998e+02, initc-loss 1.7093e+04                    bc_loss 5.9610e+04\n",
      "Epoch 10350, Training-Loss 2.3600e+03, Data-loss 1.9430e+03                  , pde-loss 7.8773e+02, initc-loss 1.1568e+04                    bc_loss 2.9346e+04\n",
      "Epoch 10360, Training-Loss 2.9252e+03, Data-loss 1.0231e+03                  , pde-loss 1.6066e+03, initc-loss 1.3643e+04                    bc_loss 1.7496e+05\n",
      "Epoch 10370, Training-Loss 3.0860e+03, Data-loss 2.6413e+03                  , pde-loss 1.8217e+03, initc-loss 1.0565e+04                    bc_loss 3.2078e+04\n",
      "Epoch 10380, Training-Loss 1.6213e+03, Data-loss 1.1568e+03                  , pde-loss 1.6063e+03, initc-loss 1.5194e+04                    bc_loss 2.9656e+04\n",
      "Epoch 10390, Training-Loss 3.9381e+03, Data-loss 2.0238e+03                  , pde-loss 9.3019e+02, initc-loss 1.9717e+04                    bc_loss 1.7078e+05\n",
      "Epoch 10400, Training-Loss 5.0299e+03, Data-loss 3.4307e+03                  , pde-loss 5.6616e+02, initc-loss 1.8809e+04                    bc_loss 1.4054e+05\n",
      "Epoch 10410, Training-Loss 3.3269e+03, Data-loss 2.0646e+03                  , pde-loss 1.0375e+03, initc-loss 1.0291e+04                    bc_loss 1.1490e+05\n",
      "Epoch 10420, Training-Loss 3.0488e+03, Data-loss 2.5323e+03                  , pde-loss 2.3098e+03, initc-loss 1.5748e+04                    bc_loss 3.3592e+04\n",
      "Epoch 10430, Training-Loss 1.9436e+03, Data-loss 1.1366e+03                  , pde-loss 2.0427e+03, initc-loss 1.6237e+04                    bc_loss 6.2418e+04\n",
      "Epoch 10440, Training-Loss 1.5869e+04, Data-loss 4.6580e+03                  , pde-loss 1.1546e+03, initc-loss 2.0691e+04                    bc_loss 1.0992e+06\n",
      "Epoch 10450, Training-Loss 8.6723e+03, Data-loss 7.6588e+03                  , pde-loss 3.9922e+02, initc-loss 8.1265e+03                    bc_loss 9.2826e+04\n",
      "Epoch 10460, Training-Loss 3.9553e+03, Data-loss 2.0365e+03                  , pde-loss 8.6677e+02, initc-loss 1.8466e+04                    bc_loss 1.7255e+05\n",
      "Epoch 10470, Training-Loss 3.8647e+03, Data-loss 2.6455e+03                  , pde-loss 3.1511e+03, initc-loss 2.0788e+04                    bc_loss 9.7978e+04\n",
      "Epoch 10480, Training-Loss 3.5906e+03, Data-loss 2.7854e+03                  , pde-loss 2.3101e+03, initc-loss 1.7670e+04                    bc_loss 6.0536e+04\n",
      "Epoch 10490, Training-Loss 6.5307e+03, Data-loss 2.9141e+03                  , pde-loss 9.5004e+02, initc-loss 1.6011e+04                    bc_loss 3.4470e+05\n",
      "Epoch 10500, Training-Loss 1.5109e+04, Data-loss 1.1750e+04                  , pde-loss 6.1632e+02, initc-loss 3.0687e+04                    bc_loss 3.0460e+05\n",
      "Epoch 10510, Training-Loss 7.2395e+03, Data-loss 3.9970e+03                  , pde-loss 1.8711e+03, initc-loss 1.8163e+04                    bc_loss 3.0421e+05\n",
      "Epoch 10520, Training-Loss 7.9449e+03, Data-loss 3.5998e+03                  , pde-loss 5.2547e+03, initc-loss 1.7148e+04                    bc_loss 4.1211e+05\n",
      "Epoch 10530, Training-Loss 3.3990e+03, Data-loss 2.3730e+03                  , pde-loss 1.8022e+03, initc-loss 1.2923e+04                    bc_loss 8.7873e+04\n",
      "Epoch 10540, Training-Loss 2.4313e+03, Data-loss 2.0750e+03                  , pde-loss 4.9227e+02, initc-loss 1.6971e+04                    bc_loss 1.8162e+04\n",
      "Epoch 10550, Training-Loss 3.4717e+03, Data-loss 2.3126e+03                  , pde-loss 7.2692e+02, initc-loss 1.9237e+04                    bc_loss 9.5947e+04\n",
      "Epoch 10560, Training-Loss 1.8839e+03, Data-loss 1.1444e+03                  , pde-loss 1.2920e+03, initc-loss 1.3139e+04                    bc_loss 5.9521e+04\n",
      "Epoch 10570, Training-Loss 1.7046e+03, Data-loss 1.2235e+03                  , pde-loss 1.9607e+03, initc-loss 1.3239e+04                    bc_loss 3.2911e+04\n",
      "Epoch 10580, Training-Loss 2.7838e+03, Data-loss 1.8453e+03                  , pde-loss 1.4639e+03, initc-loss 1.7418e+04                    bc_loss 7.4969e+04\n",
      "Epoch 10590, Training-Loss 5.7772e+03, Data-loss 1.9333e+03                  , pde-loss 1.0459e+03, initc-loss 1.3023e+04                    bc_loss 3.7032e+05\n",
      "Epoch 10600, Training-Loss 1.8828e+03, Data-loss 8.7328e+02                  , pde-loss 1.1958e+03, initc-loss 1.2721e+04                    bc_loss 8.7030e+04\n",
      "Epoch 10610, Training-Loss 2.0673e+03, Data-loss 1.2545e+03                  , pde-loss 1.9072e+03, initc-loss 1.6695e+04                    bc_loss 6.2677e+04\n",
      "Epoch 10620, Training-Loss 5.8438e+03, Data-loss 2.1427e+03                  , pde-loss 2.2724e+03, initc-loss 1.6376e+04                    bc_loss 3.5147e+05\n",
      "Epoch 10630, Training-Loss 4.9284e+03, Data-loss 3.3133e+03                  , pde-loss 3.8943e+03, initc-loss 1.7368e+04                    bc_loss 1.4025e+05\n",
      "Epoch 10640, Training-Loss 4.1010e+03, Data-loss 3.0265e+03                  , pde-loss 2.9093e+03, initc-loss 1.8901e+04                    bc_loss 8.5643e+04\n",
      "Epoch 10650, Training-Loss 4.9105e+03, Data-loss 2.5548e+03                  , pde-loss 8.4459e+02, initc-loss 1.6553e+04                    bc_loss 2.1817e+05\n",
      "Epoch 10660, Training-Loss 9.9107e+03, Data-loss 5.0989e+03                  , pde-loss 2.3883e+02, initc-loss 2.9244e+04                    bc_loss 4.5170e+05\n",
      "Epoch 10670, Training-Loss 7.6428e+03, Data-loss 4.8339e+03                  , pde-loss 2.2327e+02, initc-loss 1.7191e+04                    bc_loss 2.6348e+05\n",
      "Epoch 10680, Training-Loss 4.5355e+03, Data-loss 2.9005e+03                  , pde-loss 2.3937e+03, initc-loss 1.1184e+04                    bc_loss 1.4992e+05\n",
      "Epoch 10690, Training-Loss 7.3441e+03, Data-loss 4.1263e+03                  , pde-loss 4.9665e+03, initc-loss 2.4001e+04                    bc_loss 2.9281e+05\n",
      "Epoch 10700, Training-Loss 4.9695e+03, Data-loss 2.5283e+03                  , pde-loss 2.9947e+03, initc-loss 1.7293e+04                    bc_loss 2.2383e+05\n",
      "Epoch 10710, Training-Loss 4.3661e+03, Data-loss 3.9400e+03                  , pde-loss 5.6033e+02, initc-loss 1.6720e+04                    bc_loss 2.5334e+04\n",
      "Epoch 10720, Training-Loss 3.7090e+03, Data-loss 3.0246e+03                  , pde-loss 5.1187e+02, initc-loss 1.5058e+04                    bc_loss 5.2872e+04\n",
      "Epoch 10730, Training-Loss 3.0537e+03, Data-loss 2.1058e+03                  , pde-loss 1.5926e+03, initc-loss 1.3611e+04                    bc_loss 7.9583e+04\n",
      "Epoch 10740, Training-Loss 2.5057e+03, Data-loss 1.6713e+03                  , pde-loss 1.7369e+03, initc-loss 1.5962e+04                    bc_loss 6.5734e+04\n",
      "Epoch 10750, Training-Loss 3.5796e+03, Data-loss 1.4508e+03                  , pde-loss 1.4759e+03, initc-loss 1.7171e+04                    bc_loss 1.9423e+05\n",
      "Epoch 10760, Training-Loss 7.1004e+03, Data-loss 3.0493e+03                  , pde-loss 4.2757e+02, initc-loss 2.2741e+04                    bc_loss 3.8194e+05\n",
      "Epoch 10770, Training-Loss 4.3107e+03, Data-loss 2.7631e+03                  , pde-loss 3.7695e+02, initc-loss 1.5104e+04                    bc_loss 1.3928e+05\n",
      "Epoch 10780, Training-Loss 4.8897e+03, Data-loss 4.4865e+03                  , pde-loss 2.5907e+03, initc-loss 1.6679e+04                    bc_loss 2.1051e+04\n",
      "Epoch 10790, Training-Loss 3.2290e+03, Data-loss 2.6930e+03                  , pde-loss 2.3501e+03, initc-loss 1.5838e+04                    bc_loss 3.5410e+04\n",
      "Epoch 10800, Training-Loss 3.7439e+03, Data-loss 3.3541e+03                  , pde-loss 1.3505e+03, initc-loss 1.6062e+04                    bc_loss 2.1560e+04\n",
      "Epoch 10810, Training-Loss 1.5489e+04, Data-loss 5.7098e+03                  , pde-loss 1.6260e+03, initc-loss 2.7158e+04                    bc_loss 9.4913e+05\n",
      "Epoch 10820, Training-Loss 9.3122e+03, Data-loss 7.6643e+03                  , pde-loss 4.3842e+03, initc-loss 9.5238e+03                    bc_loss 1.5088e+05\n",
      "Epoch 10830, Training-Loss 6.2522e+03, Data-loss 3.5550e+03                  , pde-loss 1.9547e+03, initc-loss 1.3487e+04                    bc_loss 2.5428e+05\n",
      "Epoch 10840, Training-Loss 6.4186e+03, Data-loss 3.3118e+03                  , pde-loss 3.3798e+02, initc-loss 1.8155e+04                    bc_loss 2.9219e+05\n",
      "Epoch 10850, Training-Loss 8.2258e+03, Data-loss 4.3628e+03                  , pde-loss 2.1457e+02, initc-loss 2.5103e+04                    bc_loss 3.6098e+05\n",
      "Epoch 10860, Training-Loss 5.5826e+03, Data-loss 2.8745e+03                  , pde-loss 1.9266e+03, initc-loss 1.6282e+04                    bc_loss 2.5260e+05\n",
      "Epoch 10870, Training-Loss 4.7193e+03, Data-loss 3.5377e+03                  , pde-loss 4.5350e+03, initc-loss 1.3691e+04                    bc_loss 9.9931e+04\n",
      "Epoch 10880, Training-Loss 4.0118e+03, Data-loss 2.5108e+03                  , pde-loss 2.5843e+03, initc-loss 1.6741e+04                    bc_loss 1.3077e+05\n",
      "Epoch 10890, Training-Loss 2.7103e+03, Data-loss 2.1063e+03                  , pde-loss 4.3299e+02, initc-loss 1.9878e+04                    bc_loss 4.0090e+04\n",
      "Epoch 10900, Training-Loss 1.8741e+03, Data-loss 1.4061e+03                  , pde-loss 8.8396e+02, initc-loss 1.5091e+04                    bc_loss 3.0819e+04\n",
      "Epoch 10910, Training-Loss 3.5251e+03, Data-loss 1.8374e+03                  , pde-loss 1.4462e+03, initc-loss 1.4556e+04                    bc_loss 1.5276e+05\n",
      "Epoch 10920, Training-Loss 1.3526e+04, Data-loss 5.9451e+03                  , pde-loss 3.6744e+02, initc-loss 2.7843e+04                    bc_loss 7.2985e+05\n",
      "Epoch 10930, Training-Loss 1.0292e+04, Data-loss 2.7621e+03                  , pde-loss 8.0462e+02, initc-loss 1.4180e+04                    bc_loss 7.3798e+05\n",
      "Epoch 10940, Training-Loss 5.0962e+03, Data-loss 3.2039e+03                  , pde-loss 5.6546e+03, initc-loss 1.6822e+04                    bc_loss 1.6675e+05\n",
      "Epoch 10950, Training-Loss 5.2200e+03, Data-loss 3.7691e+03                  , pde-loss 3.7812e+03, initc-loss 1.3198e+04                    bc_loss 1.2811e+05\n",
      "Epoch 10960, Training-Loss 2.7779e+03, Data-loss 2.5123e+03                  , pde-loss 1.0606e+03, initc-loss 1.6840e+04                    bc_loss 8.6587e+03\n",
      "Epoch 10970, Training-Loss 2.1588e+03, Data-loss 1.9370e+03                  , pde-loss 1.1360e+03, initc-loss 1.4524e+04                    bc_loss 6.5209e+03\n",
      "Epoch 10980, Training-Loss 1.9289e+03, Data-loss 1.2725e+03                  , pde-loss 1.3091e+03, initc-loss 1.7353e+04                    bc_loss 4.6975e+04\n",
      "Epoch 10990, Training-Loss 2.9223e+03, Data-loss 1.3008e+03                  , pde-loss 1.7338e+03, initc-loss 1.8382e+04                    bc_loss 1.4204e+05\n",
      "Epoch 11000, Training-Loss 6.6726e+03, Data-loss 3.8355e+03                  , pde-loss 2.5798e+03, initc-loss 2.4667e+04                    bc_loss 2.5646e+05\n",
      "Epoch 11010, Training-Loss 5.5108e+03, Data-loss 3.3365e+03                  , pde-loss 2.4468e+03, initc-loss 1.9505e+04                    bc_loss 1.9548e+05\n",
      "Epoch 11020, Training-Loss 4.3808e+03, Data-loss 3.4902e+03                  , pde-loss 5.5000e+02, initc-loss 1.1234e+04                    bc_loss 7.7280e+04\n",
      "Epoch 11030, Training-Loss 5.2599e+03, Data-loss 1.9393e+03                  , pde-loss 3.5900e+02, initc-loss 1.5914e+04                    bc_loss 3.1578e+05\n",
      "Epoch 11040, Training-Loss 2.5909e+03, Data-loss 1.2340e+03                  , pde-loss 2.0083e+03, initc-loss 1.6560e+04                    bc_loss 1.1713e+05\n",
      "Epoch 11050, Training-Loss 2.5042e+03, Data-loss 1.8076e+03                  , pde-loss 3.4831e+03, initc-loss 1.3655e+04                    bc_loss 5.2516e+04\n",
      "Epoch 11060, Training-Loss 2.5870e+03, Data-loss 1.6171e+03                  , pde-loss 2.3986e+03, initc-loss 1.3055e+04                    bc_loss 8.1530e+04\n",
      "Epoch 11070, Training-Loss 3.5688e+03, Data-loss 7.9224e+02                  , pde-loss 2.1465e+03, initc-loss 1.5979e+04                    bc_loss 2.5953e+05\n",
      "Epoch 11080, Training-Loss 2.1690e+03, Data-loss 1.2912e+03                  , pde-loss 7.8341e+02, initc-loss 1.8239e+04                    bc_loss 6.8754e+04\n",
      "Epoch 11090, Training-Loss 1.0923e+04, Data-loss 2.7792e+03                  , pde-loss 1.8905e+02, initc-loss 2.3761e+04                    bc_loss 7.9048e+05\n",
      "Epoch 11100, Training-Loss 3.9647e+03, Data-loss 2.5499e+03                  , pde-loss 3.5199e+02, initc-loss 1.0549e+04                    bc_loss 1.3058e+05\n",
      "Epoch 11110, Training-Loss 3.1495e+03, Data-loss 2.1328e+03                  , pde-loss 2.1785e+03, initc-loss 1.3565e+04                    bc_loss 8.5924e+04\n",
      "Epoch 11120, Training-Loss 1.8928e+03, Data-loss 1.5597e+03                  , pde-loss 1.7504e+03, initc-loss 1.4197e+04                    bc_loss 1.7363e+04\n",
      "Epoch 11130, Training-Loss 1.8941e+03, Data-loss 1.3809e+03                  , pde-loss 1.0447e+03, initc-loss 1.4981e+04                    bc_loss 3.5296e+04\n",
      "Epoch 11140, Training-Loss 1.9531e+03, Data-loss 1.3946e+03                  , pde-loss 1.2946e+03, initc-loss 1.3942e+04                    bc_loss 4.0613e+04\n",
      "Epoch 11150, Training-Loss 1.2517e+03, Data-loss 8.9638e+02                  , pde-loss 1.8135e+03, initc-loss 1.4374e+04                    bc_loss 1.9341e+04\n",
      "Epoch 11160, Training-Loss 2.0548e+03, Data-loss 1.2577e+03                  , pde-loss 2.0532e+03, initc-loss 1.5036e+04                    bc_loss 6.2617e+04\n",
      "Epoch 11170, Training-Loss 3.7258e+03, Data-loss 1.3953e+03                  , pde-loss 1.4879e+03, initc-loss 1.3337e+04                    bc_loss 2.1822e+05\n",
      "Epoch 11180, Training-Loss 8.1060e+03, Data-loss 4.5892e+03                  , pde-loss 4.1126e+02, initc-loss 2.8326e+04                    bc_loss 3.2294e+05\n",
      "Epoch 11190, Training-Loss 2.1011e+03, Data-loss 1.5616e+03                  , pde-loss 7.4181e+02, initc-loss 1.7266e+04                    bc_loss 3.5936e+04\n",
      "Epoch 11200, Training-Loss 1.5165e+03, Data-loss 9.5357e+02                  , pde-loss 1.9022e+03, initc-loss 1.3477e+04                    bc_loss 4.0917e+04\n",
      "Epoch 11210, Training-Loss 3.2527e+03, Data-loss 2.6628e+03                  , pde-loss 1.8389e+03, initc-loss 1.5696e+04                    bc_loss 4.1461e+04\n",
      "Epoch 11220, Training-Loss 3.3097e+03, Data-loss 2.2826e+03                  , pde-loss 8.8135e+02, initc-loss 2.0752e+04                    bc_loss 8.1075e+04\n",
      "Epoch 11230, Training-Loss 5.6431e+03, Data-loss 2.9311e+03                  , pde-loss 4.1836e+02, initc-loss 2.1097e+04                    bc_loss 2.4968e+05\n",
      "Epoch 11240, Training-Loss 4.9254e+03, Data-loss 2.8261e+03                  , pde-loss 1.3446e+03, initc-loss 1.4668e+04                    bc_loss 1.9391e+05\n",
      "Epoch 11250, Training-Loss 1.0464e+04, Data-loss 3.9904e+03                  , pde-loss 5.3435e+03, initc-loss 2.5997e+04                    bc_loss 6.1606e+05\n",
      "Epoch 11260, Training-Loss 4.1071e+03, Data-loss 2.1144e+03                  , pde-loss 3.8666e+03, initc-loss 1.1361e+04                    bc_loss 1.8405e+05\n",
      "Epoch 11270, Training-Loss 3.1482e+03, Data-loss 1.0016e+03                  , pde-loss 9.7416e+02, initc-loss 1.4834e+04                    bc_loss 1.9885e+05\n",
      "Epoch 11280, Training-Loss 2.7408e+03, Data-loss 2.2177e+03                  , pde-loss 9.6213e+02, initc-loss 1.5467e+04                    bc_loss 3.5880e+04\n",
      "Epoch 11290, Training-Loss 1.4322e+03, Data-loss 1.0003e+03                  , pde-loss 1.4970e+03, initc-loss 1.3956e+04                    bc_loss 2.7741e+04\n",
      "Epoch 11300, Training-Loss 2.1123e+03, Data-loss 1.3898e+03                  , pde-loss 1.3758e+03, initc-loss 1.5697e+04                    bc_loss 5.5175e+04\n",
      "Epoch 11310, Training-Loss 5.5048e+03, Data-loss 2.5153e+03                  , pde-loss 8.7253e+02, initc-loss 1.6620e+04                    bc_loss 2.8146e+05\n",
      "Epoch 11320, Training-Loss 4.5674e+03, Data-loss 2.9019e+03                  , pde-loss 5.2004e+02, initc-loss 1.6845e+04                    bc_loss 1.4919e+05\n",
      "Epoch 11330, Training-Loss 2.6571e+03, Data-loss 1.4428e+03                  , pde-loss 1.0483e+03, initc-loss 1.5926e+04                    bc_loss 1.0446e+05\n",
      "Epoch 11340, Training-Loss 1.9015e+03, Data-loss 1.5402e+03                  , pde-loss 2.1479e+03, initc-loss 1.4789e+04                    bc_loss 1.9184e+04\n",
      "Epoch 11350, Training-Loss 2.7508e+03, Data-loss 2.3749e+03                  , pde-loss 2.1350e+03, initc-loss 1.5914e+04                    bc_loss 1.9541e+04\n",
      "Epoch 11360, Training-Loss 1.5332e+03, Data-loss 7.8947e+02                  , pde-loss 1.3620e+03, initc-loss 1.4919e+04                    bc_loss 5.8096e+04\n",
      "Epoch 11370, Training-Loss 1.5931e+04, Data-loss 2.5706e+03                  , pde-loss 7.1749e+02, initc-loss 1.9173e+04                    bc_loss 1.3161e+06\n",
      "Epoch 11380, Training-Loss 8.0605e+03, Data-loss 6.7977e+03                  , pde-loss 3.7169e+02, initc-loss 1.8898e+04                    bc_loss 1.0702e+05\n",
      "Epoch 11390, Training-Loss 6.4454e+03, Data-loss 3.9613e+03                  , pde-loss 1.6040e+03, initc-loss 1.3622e+04                    bc_loss 2.3318e+05\n",
      "Epoch 11400, Training-Loss 1.1581e+04, Data-loss 6.3728e+03                  , pde-loss 5.3803e+03, initc-loss 2.9608e+04                    bc_loss 4.8580e+05\n",
      "Epoch 11410, Training-Loss 6.5426e+03, Data-loss 1.8763e+03                  , pde-loss 3.5918e+03, initc-loss 1.4677e+04                    bc_loss 4.4836e+05\n",
      "Epoch 11420, Training-Loss 4.3188e+03, Data-loss 2.3935e+03                  , pde-loss 6.1124e+02, initc-loss 1.7410e+04                    bc_loss 1.7451e+05\n",
      "Epoch 11430, Training-Loss 8.3407e+03, Data-loss 4.4591e+03                  , pde-loss 4.7714e+02, initc-loss 1.7897e+04                    bc_loss 3.6979e+05\n",
      "Epoch 11440, Training-Loss 3.3724e+03, Data-loss 2.5109e+03                  , pde-loss 1.8355e+03, initc-loss 1.5402e+04                    bc_loss 6.8913e+04\n",
      "Epoch 11450, Training-Loss 2.5528e+03, Data-loss 1.8109e+03                  , pde-loss 2.0494e+03, initc-loss 1.4617e+04                    bc_loss 5.7524e+04\n",
      "Epoch 11460, Training-Loss 1.2423e+03, Data-loss 7.8131e+02                  , pde-loss 1.1205e+03, initc-loss 1.4958e+04                    bc_loss 3.0025e+04\n",
      "Epoch 11470, Training-Loss 8.3435e+03, Data-loss 2.8377e+03                  , pde-loss 1.1960e+03, initc-loss 1.4610e+04                    bc_loss 5.3477e+05\n",
      "Epoch 11480, Training-Loss 2.3490e+03, Data-loss 1.1421e+03                  , pde-loss 6.4292e+02, initc-loss 1.2253e+04                    bc_loss 1.0780e+05\n",
      "Epoch 11490, Training-Loss 2.1949e+03, Data-loss 1.7887e+03                  , pde-loss 1.7524e+03, initc-loss 1.4979e+04                    bc_loss 2.3887e+04\n",
      "Epoch 11500, Training-Loss 1.8509e+03, Data-loss 1.3801e+03                  , pde-loss 2.1986e+03, initc-loss 1.3876e+04                    bc_loss 3.1006e+04\n",
      "Epoch 11510, Training-Loss 1.7877e+03, Data-loss 1.3730e+03                  , pde-loss 1.3452e+03, initc-loss 1.6533e+04                    bc_loss 2.3592e+04\n",
      "Epoch 11520, Training-Loss 3.7422e+03, Data-loss 2.6968e+03                  , pde-loss 1.2720e+03, initc-loss 1.4195e+04                    bc_loss 8.9068e+04\n",
      "Epoch 11530, Training-Loss 9.0338e+03, Data-loss 4.5891e+03                  , pde-loss 4.9786e+02, initc-loss 2.0257e+04                    bc_loss 4.2372e+05\n",
      "Epoch 11540, Training-Loss 7.0540e+03, Data-loss 5.6390e+03                  , pde-loss 2.3428e+03, initc-loss 2.2512e+04                    bc_loss 1.1664e+05\n",
      "Epoch 11550, Training-Loss 1.1409e+04, Data-loss 6.4364e+03                  , pde-loss 5.2164e+03, initc-loss 2.6193e+04                    bc_loss 4.6586e+05\n",
      "Epoch 11560, Training-Loss 4.7550e+03, Data-loss 2.5073e+03                  , pde-loss 2.9954e+03, initc-loss 1.2419e+04                    bc_loss 2.0936e+05\n",
      "Epoch 11570, Training-Loss 3.0671e+03, Data-loss 1.8942e+03                  , pde-loss 6.0170e+02, initc-loss 1.4605e+04                    bc_loss 1.0208e+05\n",
      "Epoch 11580, Training-Loss 2.4356e+03, Data-loss 1.9854e+03                  , pde-loss 1.1754e+03, initc-loss 1.3677e+04                    bc_loss 3.0176e+04\n",
      "Epoch 11590, Training-Loss 3.2749e+03, Data-loss 2.0277e+03                  , pde-loss 1.6741e+03, initc-loss 2.2568e+04                    bc_loss 1.0047e+05\n",
      "Epoch 11600, Training-Loss 1.9980e+03, Data-loss 1.4466e+03                  , pde-loss 1.2714e+03, initc-loss 1.6491e+04                    bc_loss 3.7376e+04\n",
      "Epoch 11610, Training-Loss 2.1939e+03, Data-loss 1.7668e+03                  , pde-loss 1.1908e+03, initc-loss 1.4238e+04                    bc_loss 2.7285e+04\n",
      "Epoch 11620, Training-Loss 1.6861e+03, Data-loss 1.2253e+03                  , pde-loss 1.4687e+03, initc-loss 1.5674e+04                    bc_loss 2.8943e+04\n",
      "Epoch 11630, Training-Loss 2.6495e+03, Data-loss 2.0021e+03                  , pde-loss 1.0359e+03, initc-loss 1.7902e+04                    bc_loss 4.5800e+04\n",
      "Epoch 11640, Training-Loss 3.3562e+03, Data-loss 1.0681e+03                  , pde-loss 6.0485e+02, initc-loss 1.3483e+04                    bc_loss 2.1472e+05\n",
      "Epoch 11650, Training-Loss 2.4446e+03, Data-loss 1.2393e+03                  , pde-loss 7.5081e+02, initc-loss 1.8449e+04                    bc_loss 1.0133e+05\n",
      "Epoch 11660, Training-Loss 1.3716e+03, Data-loss 1.0500e+03                  , pde-loss 2.0109e+03, initc-loss 1.7416e+04                    bc_loss 1.2730e+04\n",
      "Epoch 11670, Training-Loss 1.1656e+03, Data-loss 7.5207e+02                  , pde-loss 2.3083e+03, initc-loss 1.6349e+04                    bc_loss 2.2697e+04\n",
      "Epoch 11680, Training-Loss 1.4514e+03, Data-loss 1.1740e+03                  , pde-loss 1.3785e+03, initc-loss 1.3762e+04                    bc_loss 1.2593e+04\n",
      "Epoch 11690, Training-Loss 2.6706e+03, Data-loss 3.5348e+02                  , pde-loss 1.3960e+03, initc-loss 1.4562e+04                    bc_loss 2.1575e+05\n",
      "Epoch 11700, Training-Loss 6.9736e+03, Data-loss 4.5590e+03                  , pde-loss 3.0342e+03, initc-loss 2.7089e+04                    bc_loss 2.1133e+05\n",
      "Epoch 11710, Training-Loss 7.0809e+03, Data-loss 2.9131e+03                  , pde-loss 3.0968e+03, initc-loss 1.7964e+04                    bc_loss 3.9571e+05\n",
      "Epoch 11720, Training-Loss 9.8003e+03, Data-loss 3.7872e+03                  , pde-loss 3.5691e+02, initc-loss 2.3020e+04                    bc_loss 5.7793e+05\n",
      "Epoch 11730, Training-Loss 9.4493e+03, Data-loss 5.1015e+03                  , pde-loss 1.8677e+02, initc-loss 1.8341e+04                    bc_loss 4.1626e+05\n",
      "Epoch 11740, Training-Loss 2.6824e+03, Data-loss 1.7369e+03                  , pde-loss 2.3017e+03, initc-loss 1.4728e+04                    bc_loss 7.7522e+04\n",
      "Epoch 11750, Training-Loss 3.7843e+03, Data-loss 3.0475e+03                  , pde-loss 2.4513e+03, initc-loss 1.4563e+04                    bc_loss 5.6666e+04\n",
      "Epoch 11760, Training-Loss 2.1142e+03, Data-loss 1.1148e+03                  , pde-loss 1.1431e+03, initc-loss 1.4650e+04                    bc_loss 8.4144e+04\n",
      "Epoch 11770, Training-Loss 1.7380e+03, Data-loss 1.0853e+03                  , pde-loss 1.5611e+03, initc-loss 1.3173e+04                    bc_loss 5.0538e+04\n",
      "Epoch 11780, Training-Loss 2.2551e+03, Data-loss 1.1177e+03                  , pde-loss 1.7031e+03, initc-loss 1.4840e+04                    bc_loss 9.7201e+04\n",
      "Epoch 11790, Training-Loss 9.2570e+03, Data-loss 2.6638e+03                  , pde-loss 2.7702e+03, initc-loss 2.5718e+04                    bc_loss 6.3084e+05\n",
      "Epoch 11800, Training-Loss 1.1950e+04, Data-loss 4.1014e+03                  , pde-loss 3.7796e+03, initc-loss 7.1349e+03                    bc_loss 7.7395e+05\n",
      "Epoch 11810, Training-Loss 6.9544e+03, Data-loss 3.1172e+03                  , pde-loss 6.1834e+02, initc-loss 1.6300e+04                    bc_loss 3.6681e+05\n",
      "Epoch 11820, Training-Loss 7.4574e+03, Data-loss 3.4574e+03                  , pde-loss 2.0205e+02, initc-loss 1.8851e+04                    bc_loss 3.8095e+05\n",
      "Epoch 11830, Training-Loss 3.0674e+03, Data-loss 2.4463e+03                  , pde-loss 1.1450e+03, initc-loss 2.0204e+04                    bc_loss 4.0758e+04\n",
      "Epoch 11840, Training-Loss 3.6071e+03, Data-loss 3.1879e+03                  , pde-loss 2.2091e+03, initc-loss 1.4462e+04                    bc_loss 2.5242e+04\n",
      "Epoch 11850, Training-Loss 2.8181e+03, Data-loss 1.6058e+03                  , pde-loss 1.5595e+03, initc-loss 1.5312e+04                    bc_loss 1.0436e+05\n",
      "Epoch 11860, Training-Loss 7.2663e+03, Data-loss 3.0059e+03                  , pde-loss 6.0743e+02, initc-loss 1.5977e+04                    bc_loss 4.0945e+05\n",
      "Epoch 11870, Training-Loss 2.6856e+03, Data-loss 1.4780e+03                  , pde-loss 1.2191e+03, initc-loss 1.1394e+04                    bc_loss 1.0815e+05\n",
      "Epoch 11880, Training-Loss 3.1745e+03, Data-loss 2.4413e+03                  , pde-loss 3.0263e+03, initc-loss 1.8746e+04                    bc_loss 5.1550e+04\n",
      "Epoch 11890, Training-Loss 2.0657e+03, Data-loss 1.2165e+03                  , pde-loss 2.0877e+03, initc-loss 1.6486e+04                    bc_loss 6.6348e+04\n",
      "Epoch 11900, Training-Loss 1.4884e+03, Data-loss 1.2236e+03                  , pde-loss 1.3550e+03, initc-loss 1.4170e+04                    bc_loss 1.0955e+04\n",
      "Epoch 11910, Training-Loss 2.2659e+03, Data-loss 1.5879e+03                  , pde-loss 1.2283e+03, initc-loss 1.6497e+04                    bc_loss 5.0075e+04\n",
      "Epoch 11920, Training-Loss 2.2136e+03, Data-loss 8.6905e+02                  , pde-loss 1.3883e+03, initc-loss 1.1530e+04                    bc_loss 1.2154e+05\n",
      "Epoch 11930, Training-Loss 1.1480e+03, Data-loss 6.6401e+02                  , pde-loss 1.1475e+03, initc-loss 1.3125e+04                    bc_loss 3.4128e+04\n",
      "Epoch 11940, Training-Loss 3.3713e+03, Data-loss 1.2436e+03                  , pde-loss 1.3825e+03, initc-loss 1.4791e+04                    bc_loss 1.9661e+05\n",
      "Epoch 11950, Training-Loss 3.7612e+03, Data-loss 2.7219e+03                  , pde-loss 3.0216e+03, initc-loss 2.1662e+04                    bc_loss 7.9241e+04\n",
      "Epoch 11960, Training-Loss 4.1332e+03, Data-loss 2.9927e+03                  , pde-loss 1.9924e+03, initc-loss 1.8443e+04                    bc_loss 9.3615e+04\n",
      "Epoch 11970, Training-Loss 4.3405e+03, Data-loss 2.5955e+03                  , pde-loss 1.0170e+03, initc-loss 1.9351e+04                    bc_loss 1.5413e+05\n",
      "Epoch 11980, Training-Loss 8.3660e+03, Data-loss 3.2309e+03                  , pde-loss 4.5249e+02, initc-loss 2.3631e+04                    bc_loss 4.8943e+05\n",
      "Epoch 11990, Training-Loss 4.6589e+03, Data-loss 3.6874e+03                  , pde-loss 8.1221e+02, initc-loss 1.5460e+04                    bc_loss 8.0870e+04\n",
      "Epoch 12000, Training-Loss 3.5523e+03, Data-loss 2.0000e+03                  , pde-loss 2.3417e+03, initc-loss 1.3066e+04                    bc_loss 1.3983e+05\n",
      "Epoch 12010, Training-Loss 2.3831e+03, Data-loss 1.6572e+03                  , pde-loss 1.4146e+03, initc-loss 1.6979e+04                    bc_loss 5.4199e+04\n",
      "Epoch 12020, Training-Loss 1.8855e+03, Data-loss 1.5838e+03                  , pde-loss 8.5196e+02, initc-loss 1.3188e+04                    bc_loss 1.6134e+04\n",
      "Epoch 12030, Training-Loss 7.3053e+03, Data-loss 2.4184e+03                  , pde-loss 4.7463e+02, initc-loss 2.0080e+04                    bc_loss 4.6813e+05\n",
      "Epoch 12040, Training-Loss 3.4194e+03, Data-loss 2.4319e+03                  , pde-loss 7.6981e+02, initc-loss 1.4610e+04                    bc_loss 8.3372e+04\n",
      "Epoch 12050, Training-Loss 3.1222e+03, Data-loss 2.4830e+03                  , pde-loss 1.9260e+03, initc-loss 1.2371e+04                    bc_loss 4.9623e+04\n",
      "Epoch 12060, Training-Loss 1.4926e+03, Data-loss 7.0800e+02                  , pde-loss 1.5988e+03, initc-loss 1.2811e+04                    bc_loss 6.4051e+04\n",
      "Epoch 12070, Training-Loss 8.7106e+03, Data-loss 2.3176e+03                  , pde-loss 9.2127e+02, initc-loss 1.8099e+04                    bc_loss 6.2028e+05\n",
      "Epoch 12080, Training-Loss 5.0645e+03, Data-loss 2.4454e+03                  , pde-loss 7.2136e+02, initc-loss 1.1196e+04                    bc_loss 2.4999e+05\n",
      "Epoch 12090, Training-Loss 2.1293e+03, Data-loss 1.6131e+03                  , pde-loss 2.9553e+03, initc-loss 1.7598e+04                    bc_loss 3.1071e+04\n",
      "Epoch 12100, Training-Loss 7.2217e+03, Data-loss 3.1773e+03                  , pde-loss 3.0650e+03, initc-loss 1.9203e+04                    bc_loss 3.8218e+05\n",
      "Epoch 12110, Training-Loss 2.7795e+03, Data-loss 1.7605e+03                  , pde-loss 1.4432e+03, initc-loss 1.9107e+04                    bc_loss 8.1348e+04\n",
      "Epoch 12120, Training-Loss 1.6296e+03, Data-loss 1.3096e+03                  , pde-loss 1.1555e+03, initc-loss 1.6088e+04                    bc_loss 1.4759e+04\n",
      "Epoch 12130, Training-Loss 1.8837e+03, Data-loss 1.1248e+03                  , pde-loss 1.1025e+03, initc-loss 1.5589e+04                    bc_loss 5.9197e+04\n",
      "Epoch 12140, Training-Loss 2.6693e+03, Data-loss 8.0712e+02                  , pde-loss 1.1713e+03, initc-loss 1.5191e+04                    bc_loss 1.6985e+05\n",
      "Epoch 12150, Training-Loss 7.9321e+03, Data-loss 7.0468e+02                  , pde-loss 1.1664e+03, initc-loss 1.5489e+04                    bc_loss 7.0608e+05\n",
      "Epoch 12160, Training-Loss 6.1502e+03, Data-loss 3.5201e+03                  , pde-loss 5.3424e+02, initc-loss 1.5102e+04                    bc_loss 2.4737e+05\n",
      "Epoch 12170, Training-Loss 4.1339e+03, Data-loss 2.8730e+03                  , pde-loss 1.2336e+03, initc-loss 1.5857e+04                    bc_loss 1.0900e+05\n",
      "Epoch 12180, Training-Loss 1.6636e+03, Data-loss 1.3766e+03                  , pde-loss 2.1708e+03, initc-loss 1.5264e+04                    bc_loss 1.1268e+04\n",
      "Epoch 12190, Training-Loss 1.5251e+03, Data-loss 1.0409e+03                  , pde-loss 1.9491e+03, initc-loss 1.5814e+04                    bc_loss 3.0650e+04\n",
      "Epoch 12200, Training-Loss 2.9091e+03, Data-loss 2.1060e+03                  , pde-loss 1.4002e+03, initc-loss 1.3669e+04                    bc_loss 6.5233e+04\n",
      "Epoch 12210, Training-Loss 1.3214e+04, Data-loss 7.8661e+03                  , pde-loss 3.4867e+02, initc-loss 3.1974e+04                    bc_loss 5.0244e+05\n",
      "Epoch 12220, Training-Loss 9.0727e+03, Data-loss 4.6102e+03                  , pde-loss 6.9015e+02, initc-loss 2.0518e+04                    bc_loss 4.2503e+05\n",
      "Epoch 12230, Training-Loss 8.8981e+03, Data-loss 4.3488e+03                  , pde-loss 4.4243e+03, initc-loss 2.0736e+04                    bc_loss 4.2978e+05\n",
      "Epoch 12240, Training-Loss 5.4143e+03, Data-loss 2.7252e+03                  , pde-loss 3.9917e+03, initc-loss 1.5023e+04                    bc_loss 2.4989e+05\n",
      "Epoch 12250, Training-Loss 2.4126e+03, Data-loss 1.5171e+03                  , pde-loss 1.3407e+03, initc-loss 1.1760e+04                    bc_loss 7.6454e+04\n",
      "Epoch 12260, Training-Loss 3.3601e+03, Data-loss 2.7392e+03                  , pde-loss 6.8091e+02, initc-loss 1.6391e+04                    bc_loss 4.5023e+04\n",
      "Epoch 12270, Training-Loss 2.0387e+03, Data-loss 1.1729e+03                  , pde-loss 8.9767e+02, initc-loss 1.7998e+04                    bc_loss 6.7686e+04\n",
      "Epoch 12280, Training-Loss 2.5624e+03, Data-loss 1.6056e+03                  , pde-loss 1.5813e+03, initc-loss 1.3868e+04                    bc_loss 8.0229e+04\n",
      "Epoch 12290, Training-Loss 6.4099e+03, Data-loss 1.0892e+03                  , pde-loss 6.9177e+02, initc-loss 1.5302e+04                    bc_loss 5.1607e+05\n",
      "Epoch 12300, Training-Loss 2.9917e+03, Data-loss 2.1328e+03                  , pde-loss 9.5610e+02, initc-loss 1.3307e+04                    bc_loss 7.1627e+04\n",
      "Epoch 12310, Training-Loss 2.7532e+03, Data-loss 1.3423e+03                  , pde-loss 2.4486e+03, initc-loss 1.3855e+04                    bc_loss 1.2478e+05\n",
      "Epoch 12320, Training-Loss 1.9670e+03, Data-loss 1.6140e+03                  , pde-loss 1.2630e+03, initc-loss 1.0579e+04                    bc_loss 2.3458e+04\n",
      "Epoch 12330, Training-Loss 2.9442e+03, Data-loss 1.1370e+03                  , pde-loss 9.9923e+02, initc-loss 1.5135e+04                    bc_loss 1.6459e+05\n",
      "Epoch 12340, Training-Loss 9.8456e+02, Data-loss 5.2814e+02                  , pde-loss 1.8162e+03, initc-loss 1.5562e+04                    bc_loss 2.8264e+04\n",
      "Epoch 12350, Training-Loss 1.3127e+03, Data-loss 9.4987e+02                  , pde-loss 2.0578e+03, initc-loss 1.4426e+04                    bc_loss 1.9794e+04\n",
      "Epoch 12360, Training-Loss 1.5028e+03, Data-loss 1.2451e+03                  , pde-loss 1.3865e+03, initc-loss 1.5279e+04                    bc_loss 9.1028e+03\n",
      "Epoch 12370, Training-Loss 1.1615e+04, Data-loss 1.8508e+03                  , pde-loss 1.0135e+03, initc-loss 1.6642e+04                    bc_loss 9.5881e+05\n",
      "Epoch 12380, Training-Loss 6.1977e+03, Data-loss 3.8082e+03                  , pde-loss 4.5429e+02, initc-loss 1.9318e+04                    bc_loss 2.1918e+05\n",
      "Epoch 12390, Training-Loss 2.9757e+03, Data-loss 2.3591e+03                  , pde-loss 1.2990e+03, initc-loss 1.5721e+04                    bc_loss 4.4644e+04\n",
      "Epoch 12400, Training-Loss 2.1212e+03, Data-loss 1.6659e+03                  , pde-loss 2.5962e+03, initc-loss 1.4384e+04                    bc_loss 2.8546e+04\n",
      "Epoch 12410, Training-Loss 1.4391e+03, Data-loss 1.0201e+03                  , pde-loss 1.5542e+03, initc-loss 1.2902e+04                    bc_loss 2.7443e+04\n",
      "Epoch 12420, Training-Loss 1.3592e+03, Data-loss 6.9224e+02                  , pde-loss 1.3326e+03, initc-loss 1.4235e+04                    bc_loss 5.1127e+04\n",
      "Epoch 12430, Training-Loss 1.1593e+04, Data-loss 2.1202e+03                  , pde-loss 2.1406e+03, initc-loss 1.5852e+04                    bc_loss 9.2933e+05\n",
      "Epoch 12440, Training-Loss 6.3372e+03, Data-loss 3.1129e+03                  , pde-loss 4.5781e+03, initc-loss 2.2220e+04                    bc_loss 2.9564e+05\n",
      "Epoch 12450, Training-Loss 5.4404e+03, Data-loss 3.7267e+03                  , pde-loss 1.7708e+03, initc-loss 8.7919e+03                    bc_loss 1.6081e+05\n",
      "Epoch 12460, Training-Loss 3.8579e+03, Data-loss 2.6253e+03                  , pde-loss 6.6060e+02, initc-loss 1.1425e+04                    bc_loss 1.1117e+05\n",
      "Epoch 12470, Training-Loss 2.2919e+03, Data-loss 9.3333e+02                  , pde-loss 1.7985e+03, initc-loss 1.6656e+04                    bc_loss 1.1740e+05\n",
      "Epoch 12480, Training-Loss 2.7969e+03, Data-loss 1.5405e+03                  , pde-loss 2.0723e+03, initc-loss 1.5940e+04                    bc_loss 1.0762e+05\n",
      "Epoch 12490, Training-Loss 1.0346e+04, Data-loss 2.7664e+03                  , pde-loss 5.6238e+02, initc-loss 2.4349e+04                    bc_loss 7.3304e+05\n",
      "Epoch 12500, Training-Loss 5.2101e+03, Data-loss 2.2192e+03                  , pde-loss 5.4527e+02, initc-loss 1.1622e+04                    bc_loss 2.8692e+05\n",
      "Epoch 12510, Training-Loss 2.1741e+03, Data-loss 1.3076e+03                  , pde-loss 3.4487e+03, initc-loss 1.3744e+04                    bc_loss 6.9460e+04\n",
      "Epoch 12520, Training-Loss 2.0296e+03, Data-loss 1.4959e+03                  , pde-loss 2.2571e+03, initc-loss 1.4233e+04                    bc_loss 3.6879e+04\n",
      "Epoch 12530, Training-Loss 1.6006e+03, Data-loss 1.0918e+03                  , pde-loss 1.1585e+03, initc-loss 1.2761e+04                    bc_loss 3.6960e+04\n",
      "Epoch 12540, Training-Loss 3.3325e+03, Data-loss 1.5116e+03                  , pde-loss 1.0306e+03, initc-loss 1.5187e+04                    bc_loss 1.6587e+05\n",
      "Epoch 12550, Training-Loss 4.7829e+03, Data-loss 1.2836e+03                  , pde-loss 2.6730e+03, initc-loss 1.1649e+04                    bc_loss 3.3561e+05\n",
      "Epoch 12560, Training-Loss 2.8225e+03, Data-loss 2.0417e+03                  , pde-loss 6.9796e+02, initc-loss 1.6635e+04                    bc_loss 6.0749e+04\n",
      "Epoch 12570, Training-Loss 7.6070e+03, Data-loss 1.7439e+03                  , pde-loss 3.1512e+02, initc-loss 2.3103e+04                    bc_loss 5.6289e+05\n",
      "Epoch 12580, Training-Loss 3.6932e+03, Data-loss 2.6302e+03                  , pde-loss 8.4335e+02, initc-loss 1.1225e+04                    bc_loss 9.4228e+04\n",
      "Epoch 12590, Training-Loss 2.5433e+03, Data-loss 2.0186e+03                  , pde-loss 2.5124e+03, initc-loss 1.5200e+04                    bc_loss 3.4762e+04\n",
      "Epoch 12600, Training-Loss 1.4621e+03, Data-loss 1.0492e+03                  , pde-loss 1.6547e+03, initc-loss 1.5379e+04                    bc_loss 2.4258e+04\n",
      "Epoch 12610, Training-Loss 2.2977e+03, Data-loss 1.9484e+03                  , pde-loss 1.2014e+03, initc-loss 1.3831e+04                    bc_loss 1.9894e+04\n",
      "Epoch 12620, Training-Loss 2.5806e+03, Data-loss 2.1541e+03                  , pde-loss 1.3468e+03, initc-loss 1.5181e+04                    bc_loss 2.6122e+04\n",
      "Epoch 12630, Training-Loss 1.4725e+03, Data-loss 1.1644e+03                  , pde-loss 1.6705e+03, initc-loss 1.5383e+04                    bc_loss 1.3759e+04\n",
      "Epoch 12640, Training-Loss 1.5291e+03, Data-loss 7.7828e+02                  , pde-loss 1.2173e+03, initc-loss 1.5250e+04                    bc_loss 5.8612e+04\n",
      "Epoch 12650, Training-Loss 5.9886e+03, Data-loss 4.0231e+03                  , pde-loss 5.0190e+02, initc-loss 1.9263e+04                    bc_loss 1.7679e+05\n",
      "Epoch 12660, Training-Loss 2.2794e+03, Data-loss 1.7564e+03                  , pde-loss 1.1916e+03, initc-loss 2.0902e+04                    bc_loss 3.0214e+04\n",
      "Epoch 12670, Training-Loss 1.8408e+03, Data-loss 1.3424e+03                  , pde-loss 1.5629e+03, initc-loss 1.5507e+04                    bc_loss 3.2779e+04\n",
      "Epoch 12680, Training-Loss 1.4493e+03, Data-loss 1.0639e+03                  , pde-loss 1.7086e+03, initc-loss 1.4061e+04                    bc_loss 2.2769e+04\n",
      "Epoch 12690, Training-Loss 1.7432e+03, Data-loss 1.2138e+03                  , pde-loss 1.8831e+03, initc-loss 1.4699e+04                    bc_loss 3.6363e+04\n",
      "Epoch 12700, Training-Loss 4.9180e+03, Data-loss 6.3298e+02                  , pde-loss 1.9654e+03, initc-loss 1.3273e+04                    bc_loss 4.1327e+05\n",
      "Epoch 12710, Training-Loss 5.9149e+03, Data-loss 1.5126e+03                  , pde-loss 2.7368e+03, initc-loss 1.5507e+04                    bc_loss 4.2198e+05\n",
      "Epoch 12720, Training-Loss 3.4387e+03, Data-loss 2.6776e+03                  , pde-loss 1.2627e+03, initc-loss 1.8082e+04                    bc_loss 5.6767e+04\n",
      "Epoch 12730, Training-Loss 2.8874e+03, Data-loss 1.3788e+03                  , pde-loss 8.3517e+02, initc-loss 1.7955e+04                    bc_loss 1.3208e+05\n",
      "Epoch 12740, Training-Loss 1.3293e+03, Data-loss 8.5834e+02                  , pde-loss 1.4438e+03, initc-loss 1.3536e+04                    bc_loss 3.2116e+04\n",
      "Epoch 12750, Training-Loss 1.3306e+03, Data-loss 9.9383e+02                  , pde-loss 1.8052e+03, initc-loss 1.3302e+04                    bc_loss 1.8569e+04\n",
      "Epoch 12760, Training-Loss 1.3226e+04, Data-loss 1.6184e+03                  , pde-loss 7.6119e+02, initc-loss 2.0706e+04                    bc_loss 1.1393e+06\n",
      "Epoch 12770, Training-Loss 3.8233e+03, Data-loss 2.9234e+03                  , pde-loss 3.2547e+02, initc-loss 1.4603e+04                    bc_loss 7.5066e+04\n",
      "Epoch 12780, Training-Loss 4.1073e+03, Data-loss 2.8627e+03                  , pde-loss 1.8477e+03, initc-loss 1.2257e+04                    bc_loss 1.1035e+05\n",
      "Epoch 12790, Training-Loss 1.4790e+03, Data-loss 8.5140e+02                  , pde-loss 1.4923e+03, initc-loss 1.5426e+04                    bc_loss 4.5843e+04\n",
      "Epoch 12800, Training-Loss 2.7743e+03, Data-loss 2.2455e+03                  , pde-loss 7.8866e+02, initc-loss 1.8013e+04                    bc_loss 3.4083e+04\n",
      "Epoch 12810, Training-Loss 9.1767e+03, Data-loss 1.8373e+03                  , pde-loss 7.3190e+02, initc-loss 2.3935e+04                    bc_loss 7.0927e+05\n",
      "Epoch 12820, Training-Loss 2.8375e+03, Data-loss 1.9215e+03                  , pde-loss 2.0412e+03, initc-loss 1.6089e+04                    bc_loss 7.3474e+04\n",
      "Epoch 12830, Training-Loss 3.6855e+03, Data-loss 1.8205e+03                  , pde-loss 3.3883e+03, initc-loss 1.5956e+04                    bc_loss 1.6716e+05\n",
      "Epoch 12840, Training-Loss 2.3013e+03, Data-loss 1.6659e+03                  , pde-loss 1.8252e+03, initc-loss 1.0320e+04                    bc_loss 5.1388e+04\n",
      "Epoch 12850, Training-Loss 1.5325e+03, Data-loss 1.2247e+03                  , pde-loss 8.4119e+02, initc-loss 1.1994e+04                    bc_loss 1.7950e+04\n",
      "Epoch 12860, Training-Loss 1.2693e+03, Data-loss 9.3028e+02                  , pde-loss 1.3520e+03, initc-loss 1.4371e+04                    bc_loss 1.8183e+04\n",
      "Epoch 12870, Training-Loss 7.1107e+02, Data-loss 4.1233e+02                  , pde-loss 1.7354e+03, initc-loss 1.5343e+04                    bc_loss 1.2795e+04\n",
      "Epoch 12880, Training-Loss 6.3348e+03, Data-loss 1.4495e+03                  , pde-loss 2.0352e+03, initc-loss 1.5863e+04                    bc_loss 4.7063e+05\n",
      "Epoch 12890, Training-Loss 3.4196e+03, Data-loss 2.3125e+03                  , pde-loss 2.6721e+03, initc-loss 1.3781e+04                    bc_loss 9.4257e+04\n",
      "Epoch 12900, Training-Loss 3.9822e+03, Data-loss 2.5585e+03                  , pde-loss 9.5356e+02, initc-loss 1.7753e+04                    bc_loss 1.2367e+05\n",
      "Epoch 12910, Training-Loss 8.6816e+03, Data-loss 3.0450e+03                  , pde-loss 2.5602e+02, initc-loss 2.1392e+04                    bc_loss 5.4201e+05\n",
      "Epoch 12920, Training-Loss 2.1065e+03, Data-loss 1.3815e+03                  , pde-loss 1.4677e+03, initc-loss 1.5729e+04                    bc_loss 5.5307e+04\n",
      "Epoch 12930, Training-Loss 3.0996e+03, Data-loss 2.2555e+03                  , pde-loss 2.4321e+03, initc-loss 1.6147e+04                    bc_loss 6.5822e+04\n",
      "Epoch 12940, Training-Loss 1.8044e+03, Data-loss 8.9170e+02                  , pde-loss 1.1316e+03, initc-loss 1.4069e+04                    bc_loss 7.6069e+04\n",
      "Epoch 12950, Training-Loss 2.2343e+03, Data-loss 1.6728e+03                  , pde-loss 1.5773e+03, initc-loss 1.3107e+04                    bc_loss 4.1465e+04\n",
      "Epoch 12960, Training-Loss 1.0920e+04, Data-loss 3.3792e+03                  , pde-loss 2.8625e+03, initc-loss 2.2952e+04                    bc_loss 7.2827e+05\n",
      "Epoch 12970, Training-Loss 4.8063e+03, Data-loss 2.7502e+03                  , pde-loss 3.8512e+03, initc-loss 1.4806e+04                    bc_loss 1.8695e+05\n",
      "Epoch 12980, Training-Loss 3.8365e+03, Data-loss 2.2402e+03                  , pde-loss 5.7959e+02, initc-loss 1.3509e+04                    bc_loss 1.4555e+05\n",
      "Epoch 12990, Training-Loss 1.1013e+04, Data-loss 5.7308e+03                  , pde-loss 1.8836e+02, initc-loss 2.6100e+04                    bc_loss 5.0188e+05\n",
      "Epoch 13000, Training-Loss 7.4641e+03, Data-loss 5.7115e+03                  , pde-loss 6.5667e+02, initc-loss 1.5974e+04                    bc_loss 1.5863e+05\n",
      "Epoch 13010, Training-Loss 2.6552e+03, Data-loss 1.9442e+03                  , pde-loss 2.9887e+03, initc-loss 1.6544e+04                    bc_loss 5.1570e+04\n",
      "Epoch 13020, Training-Loss 1.6564e+03, Data-loss 9.6403e+02                  , pde-loss 1.6774e+03, initc-loss 1.6665e+04                    bc_loss 5.0897e+04\n",
      "Epoch 13030, Training-Loss 4.0502e+03, Data-loss 2.3150e+03                  , pde-loss 7.8848e+02, initc-loss 1.6867e+04                    bc_loss 1.5586e+05\n",
      "Epoch 13040, Training-Loss 1.0897e+04, Data-loss 3.8158e+03                  , pde-loss 2.9183e+02, initc-loss 2.6400e+04                    bc_loss 6.8142e+05\n",
      "Epoch 13050, Training-Loss 8.3172e+03, Data-loss 4.1528e+03                  , pde-loss 8.0675e+02, initc-loss 1.5890e+04                    bc_loss 3.9974e+05\n",
      "Epoch 13060, Training-Loss 5.7902e+03, Data-loss 4.0828e+03                  , pde-loss 5.4265e+03, initc-loss 2.1235e+04                    bc_loss 1.4408e+05\n",
      "Epoch 13070, Training-Loss 6.0835e+03, Data-loss 2.4224e+03                  , pde-loss 3.9241e+03, initc-loss 1.7395e+04                    bc_loss 3.4479e+05\n",
      "Epoch 13080, Training-Loss 4.7778e+03, Data-loss 3.5200e+03                  , pde-loss 9.3142e+02, initc-loss 1.0812e+04                    bc_loss 1.1404e+05\n",
      "Epoch 13090, Training-Loss 4.0083e+03, Data-loss 3.1144e+03                  , pde-loss 6.4850e+02, initc-loss 1.3583e+04                    bc_loss 7.5159e+04\n",
      "Epoch 13100, Training-Loss 4.6642e+03, Data-loss 2.3225e+03                  , pde-loss 9.1360e+02, initc-loss 1.3637e+04                    bc_loss 2.1962e+05\n",
      "Epoch 13110, Training-Loss 4.2788e+03, Data-loss 1.9265e+03                  , pde-loss 1.2916e+03, initc-loss 9.8795e+03                    bc_loss 2.2406e+05\n",
      "Epoch 13120, Training-Loss 2.5491e+03, Data-loss 1.6902e+03                  , pde-loss 1.8274e+03, initc-loss 1.3079e+04                    bc_loss 7.0982e+04\n",
      "Epoch 13130, Training-Loss 1.5201e+03, Data-loss 1.0969e+03                  , pde-loss 2.7834e+03, initc-loss 1.6849e+04                    bc_loss 2.2682e+04\n",
      "Epoch 13140, Training-Loss 1.2774e+03, Data-loss 8.5748e+02                  , pde-loss 1.7537e+03, initc-loss 1.6139e+04                    bc_loss 2.4097e+04\n",
      "Epoch 13150, Training-Loss 1.3579e+03, Data-loss 9.5084e+02                  , pde-loss 1.0972e+03, initc-loss 1.1111e+04                    bc_loss 2.8494e+04\n",
      "Epoch 13160, Training-Loss 1.7035e+03, Data-loss 6.5820e+02                  , pde-loss 9.3049e+02, initc-loss 1.2972e+04                    bc_loss 9.0629e+04\n",
      "Epoch 13170, Training-Loss 1.6559e+03, Data-loss 1.2485e+03                  , pde-loss 1.8066e+03, initc-loss 1.4803e+04                    bc_loss 2.4130e+04\n",
      "Epoch 13180, Training-Loss 1.2310e+03, Data-loss 8.8105e+02                  , pde-loss 2.0179e+03, initc-loss 1.5295e+04                    bc_loss 1.7679e+04\n",
      "Epoch 13190, Training-Loss 1.5026e+03, Data-loss 1.0966e+03                  , pde-loss 1.6195e+03, initc-loss 1.3484e+04                    bc_loss 2.5495e+04\n",
      "Epoch 13200, Training-Loss 9.1744e+02, Data-loss 5.7594e+02                  , pde-loss 1.8118e+03, initc-loss 1.4648e+04                    bc_loss 1.7691e+04\n",
      "Epoch 13210, Training-Loss 1.1990e+03, Data-loss 4.9633e+02                  , pde-loss 1.7610e+03, initc-loss 1.4808e+04                    bc_loss 5.3699e+04\n",
      "Epoch 13220, Training-Loss 3.1430e+03, Data-loss 5.2260e+02                  , pde-loss 1.1662e+03, initc-loss 1.3563e+04                    bc_loss 2.4731e+05\n",
      "Epoch 13230, Training-Loss 1.2426e+04, Data-loss 3.8817e+03                  , pde-loss 2.1757e+02, initc-loss 2.0648e+04                    bc_loss 8.3360e+05\n",
      "Epoch 13240, Training-Loss 5.6171e+03, Data-loss 4.0462e+03                  , pde-loss 6.4943e+02, initc-loss 9.8494e+03                    bc_loss 1.4659e+05\n",
      "Epoch 13250, Training-Loss 3.5241e+03, Data-loss 2.5162e+03                  , pde-loss 2.4238e+03, initc-loss 1.2197e+04                    bc_loss 8.6164e+04\n",
      "Epoch 13260, Training-Loss 2.2361e+03, Data-loss 1.5425e+03                  , pde-loss 1.2454e+03, initc-loss 1.5849e+04                    bc_loss 5.2273e+04\n",
      "Epoch 13270, Training-Loss 1.2259e+03, Data-loss 8.2065e+02                  , pde-loss 1.6215e+03, initc-loss 1.2935e+04                    bc_loss 2.5969e+04\n",
      "Epoch 13280, Training-Loss 1.5564e+03, Data-loss 1.1465e+03                  , pde-loss 1.7617e+03, initc-loss 1.4404e+04                    bc_loss 2.4822e+04\n",
      "Epoch 13290, Training-Loss 1.4385e+04, Data-loss 2.0983e+03                  , pde-loss 1.0026e+03, initc-loss 1.8002e+04                    bc_loss 1.2097e+06\n",
      "Epoch 13300, Training-Loss 6.1710e+03, Data-loss 2.7077e+03                  , pde-loss 5.8036e+02, initc-loss 1.1086e+04                    bc_loss 3.3466e+05\n",
      "Epoch 13310, Training-Loss 8.9639e+03, Data-loss 2.3655e+03                  , pde-loss 4.1804e+03, initc-loss 1.5449e+04                    bc_loss 6.4021e+05\n",
      "Epoch 13320, Training-Loss 6.4674e+03, Data-loss 3.4064e+03                  , pde-loss 4.8149e+03, initc-loss 1.5698e+04                    bc_loss 2.8558e+05\n",
      "Epoch 13330, Training-Loss 2.3263e+03, Data-loss 1.6020e+03                  , pde-loss 1.4950e+03, initc-loss 1.7196e+04                    bc_loss 5.3742e+04\n",
      "Epoch 13340, Training-Loss 1.7879e+03, Data-loss 1.3905e+03                  , pde-loss 1.2106e+03, initc-loss 1.5405e+04                    bc_loss 2.3129e+04\n",
      "Epoch 13350, Training-Loss 1.5890e+03, Data-loss 1.1603e+03                  , pde-loss 1.2758e+03, initc-loss 1.3172e+04                    bc_loss 2.8421e+04\n",
      "Epoch 13360, Training-Loss 1.9014e+03, Data-loss 1.2320e+03                  , pde-loss 1.5604e+03, initc-loss 1.4438e+04                    bc_loss 5.0942e+04\n",
      "Epoch 13370, Training-Loss 1.8307e+03, Data-loss 1.2913e+03                  , pde-loss 1.6162e+03, initc-loss 1.3588e+04                    bc_loss 3.8738e+04\n",
      "Epoch 13380, Training-Loss 1.3650e+03, Data-loss 9.2460e+02                  , pde-loss 1.5857e+03, initc-loss 1.2061e+04                    bc_loss 3.0389e+04\n",
      "Epoch 13390, Training-Loss 9.1286e+02, Data-loss 5.7178e+02                  , pde-loss 1.4850e+03, initc-loss 1.3517e+04                    bc_loss 1.9107e+04\n",
      "Epoch 13400, Training-Loss 2.4831e+03, Data-loss 1.1011e+03                  , pde-loss 1.0887e+03, initc-loss 1.7998e+04                    bc_loss 1.1911e+05\n",
      "Epoch 13410, Training-Loss 3.6793e+03, Data-loss 1.4893e+03                  , pde-loss 8.9136e+02, initc-loss 1.2203e+04                    bc_loss 2.0591e+05\n",
      "Epoch 13420, Training-Loss 3.2868e+03, Data-loss 2.2796e+03                  , pde-loss 3.3740e+02, initc-loss 1.8604e+04                    bc_loss 8.1776e+04\n",
      "Epoch 13430, Training-Loss 4.3403e+03, Data-loss 3.6253e+03                  , pde-loss 9.3395e+02, initc-loss 1.7970e+04                    bc_loss 5.2587e+04\n",
      "Epoch 13440, Training-Loss 2.7563e+03, Data-loss 2.1417e+03                  , pde-loss 1.3742e+03, initc-loss 1.7727e+04                    bc_loss 4.2361e+04\n",
      "Epoch 13450, Training-Loss 1.6994e+03, Data-loss 1.2493e+03                  , pde-loss 2.0434e+03, initc-loss 1.4851e+04                    bc_loss 2.8117e+04\n",
      "Epoch 13460, Training-Loss 1.7606e+03, Data-loss 1.3081e+03                  , pde-loss 1.8783e+03, initc-loss 1.5377e+04                    bc_loss 2.7995e+04\n",
      "Epoch 13470, Training-Loss 1.8602e+04, Data-loss 1.5089e+03                  , pde-loss 1.0155e+03, initc-loss 1.8683e+04                    bc_loss 1.6897e+06\n",
      "Epoch 13480, Training-Loss 9.2433e+03, Data-loss 5.2053e+03                  , pde-loss 3.3994e+02, initc-loss 5.5400e+03                    bc_loss 3.9792e+05\n",
      "Epoch 13490, Training-Loss 8.0038e+03, Data-loss 2.4530e+03                  , pde-loss 3.7198e+03, initc-loss 1.1349e+04                    bc_loss 5.4000e+05\n",
      "Epoch 13500, Training-Loss 9.1837e+03, Data-loss 5.3312e+03                  , pde-loss 5.3639e+03, initc-loss 1.9916e+04                    bc_loss 3.5996e+05\n",
      "Epoch 13510, Training-Loss 4.1490e+03, Data-loss 3.2717e+03                  , pde-loss 1.2328e+03, initc-loss 2.0680e+04                    bc_loss 6.5815e+04\n",
      "Epoch 13520, Training-Loss 4.3522e+03, Data-loss 3.7619e+03                  , pde-loss 6.7852e+02, initc-loss 2.0973e+04                    bc_loss 3.7380e+04\n",
      "Epoch 13530, Training-Loss 3.4877e+03, Data-loss 1.7506e+03                  , pde-loss 1.3012e+03, initc-loss 1.8030e+04                    bc_loss 1.5438e+05\n",
      "Epoch 13540, Training-Loss 3.8559e+03, Data-loss 3.2354e+03                  , pde-loss 1.1342e+03, initc-loss 1.6506e+04                    bc_loss 4.4407e+04\n",
      "Epoch 13550, Training-Loss 2.4468e+03, Data-loss 1.6941e+03                  , pde-loss 9.8802e+02, initc-loss 1.5322e+04                    bc_loss 5.8957e+04\n",
      "Epoch 13560, Training-Loss 1.5937e+03, Data-loss 8.2006e+02                  , pde-loss 1.5291e+03, initc-loss 1.3797e+04                    bc_loss 6.2037e+04\n",
      "Epoch 13570, Training-Loss 7.5522e+03, Data-loss 1.9288e+03                  , pde-loss 8.5423e+02, initc-loss 2.0220e+04                    bc_loss 5.4127e+05\n",
      "Epoch 13580, Training-Loss 2.7651e+03, Data-loss 1.2549e+03                  , pde-loss 5.7355e+02, initc-loss 1.2742e+04                    bc_loss 1.3770e+05\n",
      "Epoch 13590, Training-Loss 2.0724e+03, Data-loss 1.4584e+03                  , pde-loss 2.2967e+03, initc-loss 1.5101e+04                    bc_loss 4.4002e+04\n",
      "Epoch 13600, Training-Loss 2.6447e+03, Data-loss 1.8768e+03                  , pde-loss 1.7132e+03, initc-loss 1.5355e+04                    bc_loss 5.9716e+04\n",
      "Epoch 13610, Training-Loss 2.0511e+03, Data-loss 1.7183e+03                  , pde-loss 1.0678e+03, initc-loss 1.3480e+04                    bc_loss 1.8732e+04\n",
      "Epoch 13620, Training-Loss 4.8732e+03, Data-loss 1.3742e+03                  , pde-loss 1.1329e+03, initc-loss 1.5275e+04                    bc_loss 3.3348e+05\n",
      "Epoch 13630, Training-Loss 1.9332e+03, Data-loss 1.5254e+03                  , pde-loss 1.4069e+03, initc-loss 1.2105e+04                    bc_loss 2.7267e+04\n",
      "Epoch 13640, Training-Loss 1.2418e+04, Data-loss 2.8678e+03                  , pde-loss 2.4921e+03, initc-loss 2.5159e+04                    bc_loss 9.2734e+05\n",
      "Epoch 13650, Training-Loss 6.0957e+03, Data-loss 3.3401e+03                  , pde-loss 4.6036e+03, initc-loss 1.2228e+04                    bc_loss 2.5874e+05\n",
      "Epoch 13660, Training-Loss 2.8443e+03, Data-loss 1.6199e+03                  , pde-loss 8.8987e+02, initc-loss 1.5096e+04                    bc_loss 1.0646e+05\n",
      "Epoch 13670, Training-Loss 1.0610e+04, Data-loss 5.9611e+03                  , pde-loss 2.7379e+02, initc-loss 2.6827e+04                    bc_loss 4.3775e+05\n",
      "Epoch 13680, Training-Loss 4.7532e+03, Data-loss 3.4940e+03                  , pde-loss 7.4526e+02, initc-loss 1.2990e+04                    bc_loss 1.1218e+05\n",
      "Epoch 13690, Training-Loss 3.5905e+03, Data-loss 2.7521e+03                  , pde-loss 3.1069e+03, initc-loss 1.6361e+04                    bc_loss 6.4377e+04\n",
      "Epoch 13700, Training-Loss 2.3685e+03, Data-loss 1.6317e+03                  , pde-loss 1.7633e+03, initc-loss 1.7687e+04                    bc_loss 5.4226e+04\n",
      "Epoch 13710, Training-Loss 2.1465e+03, Data-loss 1.4687e+03                  , pde-loss 1.2731e+03, initc-loss 1.5758e+04                    bc_loss 5.0748e+04\n",
      "Epoch 13720, Training-Loss 1.4508e+03, Data-loss 1.0562e+03                  , pde-loss 1.6642e+03, initc-loss 1.5373e+04                    bc_loss 2.2415e+04\n",
      "Epoch 13730, Training-Loss 2.3786e+03, Data-loss 2.0308e+03                  , pde-loss 1.4999e+03, initc-loss 1.4134e+04                    bc_loss 1.9145e+04\n",
      "Epoch 13740, Training-Loss 1.1703e+04, Data-loss 9.4966e+02                  , pde-loss 1.4058e+03, initc-loss 1.6587e+04                    bc_loss 1.0573e+06\n",
      "Epoch 13750, Training-Loss 1.5179e+04, Data-loss 8.5657e+03                  , pde-loss 2.8168e+02, initc-loss 1.1514e+04                    bc_loss 6.4956e+05\n",
      "Epoch 13760, Training-Loss 9.5144e+03, Data-loss 8.2403e+03                  , pde-loss 1.5224e+03, initc-loss 2.6446e+04                    bc_loss 9.9436e+04\n",
      "Epoch 13770, Training-Loss 8.4769e+03, Data-loss 5.0148e+03                  , pde-loss 4.1872e+03, initc-loss 2.9060e+04                    bc_loss 3.1296e+05\n",
      "Epoch 13780, Training-Loss 3.9022e+03, Data-loss 2.5948e+03                  , pde-loss 2.6686e+03, initc-loss 1.5750e+04                    bc_loss 1.1233e+05\n",
      "Epoch 13790, Training-Loss 2.5267e+03, Data-loss 2.2085e+03                  , pde-loss 9.6675e+02, initc-loss 1.6361e+04                    bc_loss 1.4495e+04\n",
      "Epoch 13800, Training-Loss 2.4503e+03, Data-loss 1.9890e+03                  , pde-loss 7.3868e+02, initc-loss 1.5111e+04                    bc_loss 3.0285e+04\n",
      "Epoch 13810, Training-Loss 2.2658e+03, Data-loss 1.7451e+03                  , pde-loss 1.1959e+03, initc-loss 1.5717e+04                    bc_loss 3.5159e+04\n",
      "Epoch 13820, Training-Loss 2.5516e+03, Data-loss 2.0097e+03                  , pde-loss 1.6933e+03, initc-loss 1.5027e+04                    bc_loss 3.7469e+04\n",
      "Epoch 13830, Training-Loss 1.1013e+03, Data-loss 7.0780e+02                  , pde-loss 1.5485e+03, initc-loss 1.2332e+04                    bc_loss 2.5467e+04\n",
      "Epoch 13840, Training-Loss 3.9778e+03, Data-loss 1.6812e+03                  , pde-loss 1.2003e+03, initc-loss 1.4427e+04                    bc_loss 2.1404e+05\n",
      "Epoch 13850, Training-Loss 1.0575e+04, Data-loss 3.8632e+03                  , pde-loss 5.6211e+02, initc-loss 2.0948e+04                    bc_loss 6.4967e+05\n",
      "Epoch 13860, Training-Loss 6.9710e+03, Data-loss 5.0983e+03                  , pde-loss 4.5967e+02, initc-loss 1.8625e+04                    bc_loss 1.6819e+05\n",
      "Epoch 13870, Training-Loss 3.4517e+03, Data-loss 2.3179e+03                  , pde-loss 1.3529e+03, initc-loss 1.6108e+04                    bc_loss 9.5916e+04\n",
      "Epoch 13880, Training-Loss 2.3890e+03, Data-loss 1.9134e+03                  , pde-loss 2.9420e+03, initc-loss 2.0425e+04                    bc_loss 2.4200e+04\n",
      "Epoch 13890, Training-Loss 2.1382e+03, Data-loss 1.6752e+03                  , pde-loss 1.9601e+03, initc-loss 1.4138e+04                    bc_loss 3.0200e+04\n",
      "Epoch 13900, Training-Loss 9.3636e+03, Data-loss 1.3224e+03                  , pde-loss 1.8165e+03, initc-loss 1.4776e+04                    bc_loss 7.8753e+05\n",
      "Epoch 13910, Training-Loss 6.0842e+03, Data-loss 2.7386e+03                  , pde-loss 3.4106e+03, initc-loss 1.8162e+04                    bc_loss 3.1299e+05\n",
      "Epoch 13920, Training-Loss 2.6067e+03, Data-loss 1.8201e+03                  , pde-loss 1.3824e+03, initc-loss 1.2794e+04                    bc_loss 6.4484e+04\n",
      "Epoch 13930, Training-Loss 4.4196e+03, Data-loss 2.4987e+03                  , pde-loss 6.3105e+02, initc-loss 1.8993e+04                    bc_loss 1.7247e+05\n",
      "Epoch 13940, Training-Loss 2.5973e+03, Data-loss 1.9504e+03                  , pde-loss 1.0800e+03, initc-loss 1.6598e+04                    bc_loss 4.7008e+04\n",
      "Epoch 13950, Training-Loss 2.3294e+03, Data-loss 1.4267e+03                  , pde-loss 1.7191e+03, initc-loss 1.3593e+04                    bc_loss 7.4962e+04\n",
      "Epoch 13960, Training-Loss 1.1193e+04, Data-loss 2.7380e+03                  , pde-loss 7.6574e+02, initc-loss 2.2761e+04                    bc_loss 8.2198e+05\n",
      "Epoch 13970, Training-Loss 4.9283e+03, Data-loss 3.3951e+03                  , pde-loss 1.9899e+02, initc-loss 1.3949e+04                    bc_loss 1.3917e+05\n",
      "Epoch 13980, Training-Loss 3.3840e+03, Data-loss 2.9418e+03                  , pde-loss 1.8724e+03, initc-loss 1.1492e+04                    bc_loss 3.0847e+04\n",
      "Epoch 13990, Training-Loss 2.8305e+03, Data-loss 2.4049e+03                  , pde-loss 2.8097e+03, initc-loss 1.5588e+04                    bc_loss 2.4157e+04\n",
      "Epoch 14000, Training-Loss 3.9195e+03, Data-loss 3.0126e+03                  , pde-loss 1.3077e+03, initc-loss 1.5077e+04                    bc_loss 7.4306e+04\n",
      "Epoch 14010, Training-Loss 2.8022e+03, Data-loss 2.1608e+03                  , pde-loss 5.4331e+02, initc-loss 1.6881e+04                    bc_loss 4.6720e+04\n",
      "Epoch 14020, Training-Loss 9.4498e+03, Data-loss 6.4893e+03                  , pde-loss 3.1963e+02, initc-loss 2.4404e+04                    bc_loss 2.7133e+05\n",
      "Epoch 14030, Training-Loss 7.1664e+03, Data-loss 2.2160e+03                  , pde-loss 2.0540e+03, initc-loss 1.7646e+04                    bc_loss 4.7534e+05\n",
      "Epoch 14040, Training-Loss 1.3782e+04, Data-loss 8.3514e+03                  , pde-loss 7.5413e+03, initc-loss 3.0277e+04                    bc_loss 5.0525e+05\n",
      "Epoch 14050, Training-Loss 6.1079e+03, Data-loss 2.3689e+03                  , pde-loss 2.5749e+03, initc-loss 1.3773e+04                    bc_loss 3.5756e+05\n",
      "Epoch 14060, Training-Loss 5.3310e+03, Data-loss 4.3545e+03                  , pde-loss 6.3388e+02, initc-loss 1.5765e+04                    bc_loss 8.1245e+04\n",
      "Epoch 14070, Training-Loss 2.7492e+03, Data-loss 2.1108e+03                  , pde-loss 9.9017e+02, initc-loss 1.6426e+04                    bc_loss 4.6425e+04\n",
      "Epoch 14080, Training-Loss 2.2445e+03, Data-loss 1.5510e+03                  , pde-loss 1.5079e+03, initc-loss 1.5522e+04                    bc_loss 5.2320e+04\n",
      "Epoch 14090, Training-Loss 2.6202e+03, Data-loss 2.1656e+03                  , pde-loss 1.0417e+03, initc-loss 1.4547e+04                    bc_loss 2.9873e+04\n",
      "Epoch 14100, Training-Loss 2.8183e+03, Data-loss 2.2540e+03                  , pde-loss 1.2137e+03, initc-loss 1.3615e+04                    bc_loss 4.1604e+04\n",
      "Epoch 14110, Training-Loss 1.5826e+03, Data-loss 1.2158e+03                  , pde-loss 1.5517e+03, initc-loss 1.3233e+04                    bc_loss 2.1892e+04\n",
      "Epoch 14120, Training-Loss 7.7435e+02, Data-loss 4.1999e+02                  , pde-loss 1.3592e+03, initc-loss 1.4337e+04                    bc_loss 1.9739e+04\n",
      "Epoch 14130, Training-Loss 3.6252e+03, Data-loss 2.2895e+03                  , pde-loss 1.0441e+03, initc-loss 1.6224e+04                    bc_loss 1.1630e+05\n",
      "Epoch 14140, Training-Loss 2.0922e+03, Data-loss 1.5434e+03                  , pde-loss 9.0073e+02, initc-loss 1.3879e+04                    bc_loss 4.0100e+04\n",
      "Epoch 14150, Training-Loss 1.7735e+03, Data-loss 1.1017e+03                  , pde-loss 1.5830e+03, initc-loss 1.2926e+04                    bc_loss 5.2665e+04\n",
      "Epoch 14160, Training-Loss 3.3063e+03, Data-loss 1.6249e+03                  , pde-loss 1.6224e+03, initc-loss 1.3664e+04                    bc_loss 1.5286e+05\n",
      "Epoch 14170, Training-Loss 9.5090e+03, Data-loss 2.0315e+03                  , pde-loss 8.2757e+02, initc-loss 2.1285e+04                    bc_loss 7.2564e+05\n",
      "Epoch 14180, Training-Loss 4.6756e+03, Data-loss 2.0552e+03                  , pde-loss 4.3982e+02, initc-loss 1.5674e+04                    bc_loss 2.4593e+05\n",
      "Epoch 14190, Training-Loss 3.1752e+03, Data-loss 2.5607e+03                  , pde-loss 1.5132e+03, initc-loss 1.9099e+04                    bc_loss 4.0842e+04\n",
      "Epoch 14200, Training-Loss 1.9704e+03, Data-loss 1.6160e+03                  , pde-loss 1.8444e+03, initc-loss 1.5257e+04                    bc_loss 1.8344e+04\n",
      "Epoch 14210, Training-Loss 1.0827e+03, Data-loss 7.7436e+02                  , pde-loss 1.6516e+03, initc-loss 1.7145e+04                    bc_loss 1.2037e+04\n",
      "Epoch 14220, Training-Loss 1.4552e+03, Data-loss 6.3140e+02                  , pde-loss 1.3785e+03, initc-loss 1.4247e+04                    bc_loss 6.6752e+04\n",
      "Epoch 14230, Training-Loss 5.7993e+03, Data-loss 1.6397e+03                  , pde-loss 2.0705e+03, initc-loss 1.8589e+04                    bc_loss 3.9530e+05\n",
      "Epoch 14240, Training-Loss 1.4454e+03, Data-loss 1.0682e+03                  , pde-loss 2.1530e+03, initc-loss 1.2562e+04                    bc_loss 2.3010e+04\n",
      "Epoch 14250, Training-Loss 1.3872e+03, Data-loss 1.0902e+03                  , pde-loss 1.4718e+03, initc-loss 1.1977e+04                    bc_loss 1.6251e+04\n",
      "Epoch 14260, Training-Loss 1.3612e+03, Data-loss 9.3835e+02                  , pde-loss 1.0224e+03, initc-loss 1.4420e+04                    bc_loss 2.6840e+04\n",
      "Epoch 14270, Training-Loss 3.3045e+03, Data-loss 1.8930e+03                  , pde-loss 1.1736e+03, initc-loss 1.7758e+04                    bc_loss 1.2221e+05\n",
      "Epoch 14280, Training-Loss 1.8695e+04, Data-loss 2.6053e+03                  , pde-loss 1.2233e+03, initc-loss 2.1633e+04                    bc_loss 1.5862e+06\n",
      "Epoch 14290, Training-Loss 1.6454e+04, Data-loss 1.3571e+04                  , pde-loss 2.5403e+02, initc-loss 8.4999e+03                    bc_loss 2.7954e+05\n",
      "Epoch 14300, Training-Loss 7.4726e+03, Data-loss 6.8682e+03                  , pde-loss 1.4859e+03, initc-loss 2.7562e+04                    bc_loss 3.1388e+04\n",
      "Epoch 14310, Training-Loss 6.1929e+03, Data-loss 3.5548e+03                  , pde-loss 2.4132e+03, initc-loss 2.2516e+04                    bc_loss 2.3888e+05\n",
      "Epoch 14320, Training-Loss 3.2295e+03, Data-loss 2.3939e+03                  , pde-loss 9.0276e+02, initc-loss 1.8147e+04                    bc_loss 6.4510e+04\n",
      "Epoch 14330, Training-Loss 1.7882e+03, Data-loss 1.2859e+03                  , pde-loss 8.6645e+02, initc-loss 1.1942e+04                    bc_loss 3.7423e+04\n",
      "Epoch 14340, Training-Loss 2.1701e+03, Data-loss 1.5773e+03                  , pde-loss 1.4905e+03, initc-loss 1.3769e+04                    bc_loss 4.4022e+04\n",
      "Epoch 14350, Training-Loss 4.7912e+03, Data-loss 1.1856e+03                  , pde-loss 1.2771e+03, initc-loss 1.4173e+04                    bc_loss 3.4511e+05\n",
      "Epoch 14360, Training-Loss 9.5896e+03, Data-loss 3.7609e+03                  , pde-loss 3.6187e+02, initc-loss 2.2782e+04                    bc_loss 5.5972e+05\n",
      "Epoch 14370, Training-Loss 5.0822e+03, Data-loss 2.2070e+03                  , pde-loss 5.1439e+02, initc-loss 1.6459e+04                    bc_loss 2.7054e+05\n",
      "Epoch 14380, Training-Loss 3.0622e+03, Data-loss 1.8364e+03                  , pde-loss 3.4020e+03, initc-loss 1.3572e+04                    bc_loss 1.0560e+05\n",
      "Epoch 14390, Training-Loss 6.7551e+03, Data-loss 1.9275e+03                  , pde-loss 3.8805e+03, initc-loss 1.8159e+04                    bc_loss 4.6072e+05\n",
      "Epoch 14400, Training-Loss 4.4725e+03, Data-loss 2.1428e+03                  , pde-loss 2.4664e+03, initc-loss 1.2308e+04                    bc_loss 2.1819e+05\n",
      "Epoch 14410, Training-Loss 2.7009e+03, Data-loss 2.2518e+03                  , pde-loss 6.8462e+02, initc-loss 1.5642e+04                    bc_loss 2.8585e+04\n",
      "Epoch 14420, Training-Loss 4.2258e+03, Data-loss 3.3813e+03                  , pde-loss 5.6679e+02, initc-loss 1.6674e+04                    bc_loss 6.7205e+04\n",
      "Epoch 14430, Training-Loss 1.6364e+03, Data-loss 1.2143e+03                  , pde-loss 1.1998e+03, initc-loss 1.3228e+04                    bc_loss 2.7787e+04\n",
      "Epoch 14440, Training-Loss 1.5626e+03, Data-loss 1.1796e+03                  , pde-loss 1.8095e+03, initc-loss 1.2786e+04                    bc_loss 2.3706e+04\n",
      "Epoch 14450, Training-Loss 2.6050e+03, Data-loss 2.3368e+03                  , pde-loss 2.0086e+03, initc-loss 1.4110e+04                    bc_loss 1.0701e+04\n",
      "Epoch 14460, Training-Loss 1.3111e+03, Data-loss 8.8097e+02                  , pde-loss 1.4476e+03, initc-loss 1.5425e+04                    bc_loss 2.6138e+04\n",
      "Epoch 14470, Training-Loss 5.9109e+03, Data-loss 1.2120e+03                  , pde-loss 1.3547e+03, initc-loss 2.1158e+04                    bc_loss 4.4738e+05\n",
      "Epoch 14480, Training-Loss 1.4274e+04, Data-loss 1.1945e+04                  , pde-loss 9.2702e+02, initc-loss 4.1935e+04                    bc_loss 1.9006e+05\n",
      "Epoch 14490, Training-Loss 1.2806e+04, Data-loss 1.0961e+04                  , pde-loss 8.6545e+02, initc-loss 2.0915e+04                    bc_loss 1.6270e+05\n",
      "Epoch 14500, Training-Loss 1.0076e+04, Data-loss 8.0470e+03                  , pde-loss 1.4183e+03, initc-loss 9.7869e+03                    bc_loss 1.9167e+05\n",
      "Epoch 14510, Training-Loss 2.2968e+03, Data-loss 1.8566e+03                  , pde-loss 1.0569e+03, initc-loss 1.3475e+04                    bc_loss 2.9495e+04\n",
      "Epoch 14520, Training-Loss 5.4033e+03, Data-loss 2.5682e+03                  , pde-loss 9.4512e+02, initc-loss 2.3156e+04                    bc_loss 2.5941e+05\n",
      "Epoch 14530, Training-Loss 4.4538e+03, Data-loss 2.5678e+03                  , pde-loss 1.4448e+03, initc-loss 1.7138e+04                    bc_loss 1.7002e+05\n",
      "Epoch 14540, Training-Loss 1.3261e+04, Data-loss 6.9118e+03                  , pde-loss 1.4436e+03, initc-loss 3.3557e+04                    bc_loss 5.9992e+05\n",
      "Epoch 14550, Training-Loss 7.5563e+03, Data-loss 7.2756e+03                  , pde-loss 1.3075e+03, initc-loss 1.4703e+04                    bc_loss 1.2058e+04\n",
      "Epoch 14560, Training-Loss 4.7581e+03, Data-loss 2.3834e+03                  , pde-loss 8.4998e+02, initc-loss 1.4572e+04                    bc_loss 2.2204e+05\n",
      "Epoch 14570, Training-Loss 3.7966e+03, Data-loss 2.0650e+03                  , pde-loss 2.3933e+03, initc-loss 1.1050e+04                    bc_loss 1.5972e+05\n",
      "Epoch 14580, Training-Loss 5.2235e+03, Data-loss 2.5824e+03                  , pde-loss 2.9631e+03, initc-loss 2.0357e+04                    bc_loss 2.4079e+05\n",
      "Epoch 14590, Training-Loss 2.4398e+03, Data-loss 1.6281e+03                  , pde-loss 4.8263e+02, initc-loss 1.4665e+04                    bc_loss 6.6025e+04\n",
      "Epoch 14600, Training-Loss 2.6207e+03, Data-loss 1.4774e+03                  , pde-loss 3.5862e+02, initc-loss 1.3516e+04                    bc_loss 1.0045e+05\n",
      "Epoch 14610, Training-Loss 3.4442e+03, Data-loss 3.0162e+03                  , pde-loss 1.5723e+03, initc-loss 1.2240e+04                    bc_loss 2.8996e+04\n",
      "Epoch 14620, Training-Loss 1.6517e+03, Data-loss 1.3091e+03                  , pde-loss 2.2605e+03, initc-loss 1.7542e+04                    bc_loss 1.4455e+04\n",
      "Epoch 14630, Training-Loss 9.9990e+03, Data-loss 2.7996e+03                  , pde-loss 8.7687e+02, initc-loss 2.4507e+04                    bc_loss 6.9455e+05\n",
      "Epoch 14640, Training-Loss 6.7008e+03, Data-loss 4.5485e+03                  , pde-loss 2.9441e+02, initc-loss 1.7554e+04                    bc_loss 1.9739e+05\n",
      "Epoch 14650, Training-Loss 5.3818e+03, Data-loss 4.6095e+03                  , pde-loss 1.3381e+03, initc-loss 1.6434e+04                    bc_loss 5.9462e+04\n",
      "Epoch 14660, Training-Loss 4.5028e+03, Data-loss 2.9176e+03                  , pde-loss 3.7964e+03, initc-loss 1.5988e+04                    bc_loss 1.3874e+05\n",
      "Epoch 14670, Training-Loss 3.1706e+03, Data-loss 1.4074e+03                  , pde-loss 3.1269e+03, initc-loss 1.2693e+04                    bc_loss 1.6051e+05\n",
      "Epoch 14680, Training-Loss 7.2644e+03, Data-loss 3.7143e+03                  , pde-loss 6.2805e+02, initc-loss 2.2684e+04                    bc_loss 3.3170e+05\n",
      "Epoch 14690, Training-Loss 7.3327e+03, Data-loss 3.8026e+03                  , pde-loss 2.9785e+02, initc-loss 1.6216e+04                    bc_loss 3.3649e+05\n",
      "Epoch 14700, Training-Loss 8.0330e+03, Data-loss 3.3135e+03                  , pde-loss 1.2491e+03, initc-loss 1.0024e+04                    bc_loss 4.6068e+05\n",
      "Epoch 14710, Training-Loss 5.3207e+03, Data-loss 4.0910e+03                  , pde-loss 5.1141e+03, initc-loss 2.4728e+04                    bc_loss 9.3135e+04\n",
      "Epoch 14720, Training-Loss 6.5731e+03, Data-loss 3.0455e+03                  , pde-loss 3.4312e+03, initc-loss 1.8449e+04                    bc_loss 3.3088e+05\n",
      "Epoch 14730, Training-Loss 3.2861e+03, Data-loss 2.9137e+03                  , pde-loss 8.8276e+02, initc-loss 1.5495e+04                    bc_loss 2.0864e+04\n",
      "Epoch 14740, Training-Loss 3.4727e+03, Data-loss 3.0730e+03                  , pde-loss 6.9041e+02, initc-loss 1.4949e+04                    bc_loss 2.4335e+04\n",
      "Epoch 14750, Training-Loss 1.6130e+03, Data-loss 9.9585e+02                  , pde-loss 1.6027e+03, initc-loss 1.4336e+04                    bc_loss 4.5778e+04\n",
      "Epoch 14760, Training-Loss 8.8206e+03, Data-loss 1.7260e+03                  , pde-loss 1.1433e+03, initc-loss 1.7117e+04                    bc_loss 6.9120e+05\n",
      "Epoch 14770, Training-Loss 6.2616e+03, Data-loss 3.2944e+03                  , pde-loss 2.2208e+02, initc-loss 1.9030e+04                    bc_loss 2.7746e+05\n",
      "Epoch 14780, Training-Loss 3.8750e+03, Data-loss 2.7641e+03                  , pde-loss 1.3255e+03, initc-loss 1.6211e+04                    bc_loss 9.3557e+04\n",
      "Epoch 14790, Training-Loss 4.1045e+03, Data-loss 2.3999e+03                  , pde-loss 3.2867e+03, initc-loss 1.8700e+04                    bc_loss 1.4847e+05\n",
      "Epoch 14800, Training-Loss 4.4814e+03, Data-loss 3.1954e+03                  , pde-loss 1.6135e+03, initc-loss 1.6159e+04                    bc_loss 1.1082e+05\n",
      "Epoch 14810, Training-Loss 2.7940e+03, Data-loss 2.1752e+03                  , pde-loss 8.4397e+02, initc-loss 1.2446e+04                    bc_loss 4.8584e+04\n",
      "Epoch 14820, Training-Loss 3.3947e+03, Data-loss 2.8027e+03                  , pde-loss 1.5066e+03, initc-loss 1.4843e+04                    bc_loss 4.2847e+04\n",
      "Epoch 14830, Training-Loss 6.3683e+03, Data-loss 3.0450e+03                  , pde-loss 3.7434e+03, initc-loss 2.4886e+04                    bc_loss 3.0371e+05\n",
      "Epoch 14840, Training-Loss 6.9629e+03, Data-loss 3.3984e+03                  , pde-loss 3.6126e+03, initc-loss 1.1368e+04                    bc_loss 3.4147e+05\n",
      "Epoch 14850, Training-Loss 4.2230e+03, Data-loss 2.5205e+03                  , pde-loss 7.3253e+02, initc-loss 1.4055e+04                    bc_loss 1.5546e+05\n",
      "Epoch 14860, Training-Loss 1.0111e+04, Data-loss 6.1661e+03                  , pde-loss 2.0679e+02, initc-loss 2.7090e+04                    bc_loss 3.6722e+05\n",
      "Epoch 14870, Training-Loss 6.3391e+03, Data-loss 2.4901e+03                  , pde-loss 7.6108e+02, initc-loss 1.4349e+04                    bc_loss 3.6979e+05\n",
      "Epoch 14880, Training-Loss 4.0597e+03, Data-loss 2.5423e+03                  , pde-loss 3.5830e+03, initc-loss 1.8920e+04                    bc_loss 1.2924e+05\n",
      "Epoch 14890, Training-Loss 1.6867e+03, Data-loss 1.2746e+03                  , pde-loss 1.8847e+03, initc-loss 1.3073e+04                    bc_loss 2.6250e+04\n",
      "Epoch 14900, Training-Loss 2.1492e+03, Data-loss 1.2476e+03                  , pde-loss 1.1332e+03, initc-loss 1.3089e+04                    bc_loss 7.5941e+04\n",
      "Epoch 14910, Training-Loss 2.6518e+03, Data-loss 2.0588e+03                  , pde-loss 7.4150e+02, initc-loss 1.4010e+04                    bc_loss 4.4547e+04\n",
      "Epoch 14920, Training-Loss 1.9796e+03, Data-loss 1.1669e+03                  , pde-loss 9.4555e+02, initc-loss 1.2324e+04                    bc_loss 6.7998e+04\n",
      "Epoch 14930, Training-Loss 2.4257e+03, Data-loss 1.7064e+03                  , pde-loss 1.4160e+03, initc-loss 1.2944e+04                    bc_loss 5.7566e+04\n",
      "Epoch 14940, Training-Loss 1.2236e+04, Data-loss 1.4461e+03                  , pde-loss 9.0399e+02, initc-loss 1.5407e+04                    bc_loss 1.0626e+06\n",
      "Epoch 14950, Training-Loss 6.7222e+03, Data-loss 3.7507e+03                  , pde-loss 4.4324e+02, initc-loss 1.7398e+04                    bc_loss 2.7931e+05\n",
      "Epoch 14960, Training-Loss 1.4593e+03, Data-loss 1.0276e+03                  , pde-loss 1.3008e+03, initc-loss 1.9329e+04                    bc_loss 2.2546e+04\n",
      "Epoch 14970, Training-Loss 1.8931e+03, Data-loss 1.5364e+03                  , pde-loss 1.6382e+03, initc-loss 1.5449e+04                    bc_loss 1.8584e+04\n",
      "Epoch 14980, Training-Loss 2.0658e+03, Data-loss 1.6878e+03                  , pde-loss 1.2667e+03, initc-loss 1.4566e+04                    bc_loss 2.1968e+04\n",
      "Epoch 14990, Training-Loss 1.5585e+03, Data-loss 1.1218e+03                  , pde-loss 1.3944e+03, initc-loss 1.4180e+04                    bc_loss 2.8104e+04\n",
      "Epoch 15000, Training-Loss 2.4121e+03, Data-loss 1.4693e+03                  , pde-loss 1.2040e+03, initc-loss 1.1330e+04                    bc_loss 8.1747e+04\n",
      "Epoch 15010, Training-Loss 1.9392e+03, Data-loss 1.0091e+03                  , pde-loss 2.1881e+03, initc-loss 1.4994e+04                    bc_loss 7.5830e+04\n",
      "Epoch 15020, Training-Loss 6.9229e+03, Data-loss 1.1450e+03                  , pde-loss 3.0957e+03, initc-loss 1.7139e+04                    bc_loss 5.5755e+05\n",
      "Epoch 15030, Training-Loss 3.9480e+03, Data-loss 3.2790e+03                  , pde-loss 2.8154e+03, initc-loss 1.9179e+04                    bc_loss 4.4909e+04\n",
      "Epoch 15040, Training-Loss 3.0394e+03, Data-loss 2.4217e+03                  , pde-loss 1.2357e+03, initc-loss 1.6828e+04                    bc_loss 4.3711e+04\n",
      "Epoch 15050, Training-Loss 1.4212e+03, Data-loss 9.4426e+02                  , pde-loss 1.6176e+03, initc-loss 1.3136e+04                    bc_loss 3.2945e+04\n",
      "Epoch 15060, Training-Loss 2.2850e+03, Data-loss 1.2577e+03                  , pde-loss 1.6025e+03, initc-loss 1.6540e+04                    bc_loss 8.4592e+04\n",
      "Epoch 15070, Training-Loss 2.0334e+03, Data-loss 1.0962e+03                  , pde-loss 2.0122e+03, initc-loss 1.2960e+04                    bc_loss 7.8746e+04\n",
      "Epoch 15080, Training-Loss 1.5640e+04, Data-loss 2.0247e+03                  , pde-loss 7.9061e+02, initc-loss 1.8115e+04                    bc_loss 1.3426e+06\n",
      "Epoch 15090, Training-Loss 7.5607e+03, Data-loss 4.0371e+03                  , pde-loss 2.6142e+02, initc-loss 1.4817e+04                    bc_loss 3.3729e+05\n",
      "Epoch 15100, Training-Loss 4.0922e+03, Data-loss 2.3017e+03                  , pde-loss 6.7404e+02, initc-loss 1.6360e+04                    bc_loss 1.6202e+05\n",
      "Epoch 15110, Training-Loss 3.6146e+03, Data-loss 2.5344e+03                  , pde-loss 3.1659e+03, initc-loss 1.6011e+04                    bc_loss 8.8843e+04\n",
      "Epoch 15120, Training-Loss 2.9701e+03, Data-loss 2.2609e+03                  , pde-loss 1.6754e+03, initc-loss 1.4191e+04                    bc_loss 5.5051e+04\n",
      "Epoch 15130, Training-Loss 2.5929e+03, Data-loss 2.1154e+03                  , pde-loss 1.1243e+03, initc-loss 1.5352e+04                    bc_loss 3.1277e+04\n",
      "Epoch 15140, Training-Loss 1.7064e+03, Data-loss 1.1766e+03                  , pde-loss 1.2262e+03, initc-loss 1.3981e+04                    bc_loss 3.7771e+04\n",
      "Epoch 15150, Training-Loss 6.9965e+03, Data-loss 1.6333e+03                  , pde-loss 1.2246e+03, initc-loss 1.6456e+04                    bc_loss 5.1864e+05\n",
      "Epoch 15160, Training-Loss 6.6293e+03, Data-loss 4.9784e+03                  , pde-loss 6.6362e+02, initc-loss 1.0665e+04                    bc_loss 1.5376e+05\n",
      "Epoch 15170, Training-Loss 2.4828e+03, Data-loss 1.8317e+03                  , pde-loss 2.2516e+03, initc-loss 1.3542e+04                    bc_loss 4.9315e+04\n",
      "Epoch 15180, Training-Loss 2.6932e+03, Data-loss 2.0652e+03                  , pde-loss 3.3414e+03, initc-loss 1.8548e+04                    bc_loss 4.0904e+04\n",
      "Epoch 15190, Training-Loss 9.2745e+03, Data-loss 2.8468e+03                  , pde-loss 2.3955e+03, initc-loss 1.8177e+04                    bc_loss 6.2219e+05\n",
      "Epoch 15200, Training-Loss 4.7154e+03, Data-loss 2.3512e+03                  , pde-loss 1.6342e+03, initc-loss 9.6129e+03                    bc_loss 2.2518e+05\n",
      "Epoch 15210, Training-Loss 2.5146e+03, Data-loss 1.8898e+03                  , pde-loss 5.5528e+02, initc-loss 1.6068e+04                    bc_loss 4.5855e+04\n",
      "Epoch 15220, Training-Loss 1.4525e+03, Data-loss 1.0528e+03                  , pde-loss 1.4103e+03, initc-loss 1.4028e+04                    bc_loss 2.4539e+04\n",
      "Epoch 15230, Training-Loss 1.1135e+03, Data-loss 8.3645e+02                  , pde-loss 1.5456e+03, initc-loss 1.3878e+04                    bc_loss 1.2285e+04\n",
      "Epoch 15240, Training-Loss 2.4517e+03, Data-loss 1.3812e+03                  , pde-loss 1.4942e+03, initc-loss 1.4875e+04                    bc_loss 9.0676e+04\n",
      "Epoch 15250, Training-Loss 1.5466e+03, Data-loss 1.2986e+03                  , pde-loss 1.7332e+03, initc-loss 1.1856e+04                    bc_loss 1.1207e+04\n",
      "Epoch 15260, Training-Loss 2.0103e+03, Data-loss 1.2163e+03                  , pde-loss 1.4589e+03, initc-loss 1.0688e+04                    bc_loss 6.7251e+04\n",
      "Epoch 15270, Training-Loss 1.4174e+04, Data-loss 3.8119e+03                  , pde-loss 3.4336e+02, initc-loss 2.5114e+04                    bc_loss 1.0108e+06\n",
      "Epoch 15280, Training-Loss 5.7806e+03, Data-loss 4.5498e+03                  , pde-loss 2.1184e+02, initc-loss 1.8635e+04                    bc_loss 1.0424e+05\n",
      "Epoch 15290, Training-Loss 3.6690e+03, Data-loss 2.8800e+03                  , pde-loss 1.9390e+03, initc-loss 1.4054e+04                    bc_loss 6.2905e+04\n",
      "Epoch 15300, Training-Loss 1.9799e+03, Data-loss 1.4833e+03                  , pde-loss 1.6817e+03, initc-loss 1.6468e+04                    bc_loss 3.1513e+04\n",
      "Epoch 15310, Training-Loss 2.5911e+03, Data-loss 2.0027e+03                  , pde-loss 1.0923e+03, initc-loss 1.6841e+04                    bc_loss 4.0905e+04\n",
      "Epoch 15320, Training-Loss 3.2638e+03, Data-loss 2.0059e+03                  , pde-loss 1.1764e+03, initc-loss 1.4082e+04                    bc_loss 1.1053e+05\n",
      "Epoch 15330, Training-Loss 6.7706e+03, Data-loss 1.8993e+03                  , pde-loss 7.0109e+02, initc-loss 1.1748e+04                    bc_loss 4.7468e+05\n",
      "Epoch 15340, Training-Loss 2.5058e+03, Data-loss 2.1593e+03                  , pde-loss 2.9583e+03, initc-loss 1.7492e+04                    bc_loss 1.4192e+04\n",
      "Epoch 15350, Training-Loss 6.8952e+03, Data-loss 2.2158e+03                  , pde-loss 3.5408e+03, initc-loss 2.2623e+04                    bc_loss 4.4178e+05\n",
      "Epoch 15360, Training-Loss 2.8625e+03, Data-loss 2.0693e+03                  , pde-loss 1.7204e+03, initc-loss 1.3989e+04                    bc_loss 6.3619e+04\n",
      "Epoch 15370, Training-Loss 2.0153e+03, Data-loss 1.5995e+03                  , pde-loss 1.1242e+03, initc-loss 1.3072e+04                    bc_loss 2.7389e+04\n",
      "Epoch 15380, Training-Loss 1.1035e+03, Data-loss 6.3523e+02                  , pde-loss 1.4229e+03, initc-loss 1.3623e+04                    bc_loss 3.1780e+04\n",
      "Epoch 15390, Training-Loss 2.1795e+03, Data-loss 1.7604e+03                  , pde-loss 1.4417e+03, initc-loss 1.2094e+04                    bc_loss 2.8375e+04\n",
      "Epoch 15400, Training-Loss 1.2042e+03, Data-loss 8.5072e+02                  , pde-loss 1.1420e+03, initc-loss 1.5056e+04                    bc_loss 1.9148e+04\n",
      "Epoch 15410, Training-Loss 1.3556e+03, Data-loss 7.4455e+02                  , pde-loss 1.5105e+03, initc-loss 1.4035e+04                    bc_loss 4.5562e+04\n",
      "Epoch 15420, Training-Loss 1.4363e+03, Data-loss 1.1292e+03                  , pde-loss 1.1387e+03, initc-loss 1.3206e+04                    bc_loss 1.6363e+04\n",
      "Epoch 15430, Training-Loss 1.4590e+03, Data-loss 1.2138e+03                  , pde-loss 1.3503e+03, initc-loss 1.2090e+04                    bc_loss 1.1075e+04\n",
      "Epoch 15440, Training-Loss 5.1441e+03, Data-loss 6.1774e+02                  , pde-loss 1.2946e+03, initc-loss 1.5203e+04                    bc_loss 4.3613e+05\n",
      "Epoch 15450, Training-Loss 1.1375e+04, Data-loss 7.6455e+03                  , pde-loss 2.1496e+02, initc-loss 2.5030e+04                    bc_loss 3.4766e+05\n",
      "Epoch 15460, Training-Loss 8.9939e+03, Data-loss 6.9108e+03                  , pde-loss 4.4112e+02, initc-loss 2.0692e+04                    bc_loss 1.8718e+05\n",
      "Epoch 15470, Training-Loss 4.7312e+03, Data-loss 4.0366e+03                  , pde-loss 2.9390e+03, initc-loss 2.0094e+04                    bc_loss 4.6427e+04\n",
      "Epoch 15480, Training-Loss 2.6271e+03, Data-loss 1.4031e+03                  , pde-loss 2.5634e+03, initc-loss 1.8227e+04                    bc_loss 1.0161e+05\n",
      "Epoch 15490, Training-Loss 3.4068e+03, Data-loss 2.6929e+03                  , pde-loss 9.8522e+02, initc-loss 1.7925e+04                    bc_loss 5.2476e+04\n",
      "Epoch 15500, Training-Loss 1.2771e+04, Data-loss 3.8546e+03                  , pde-loss 6.0454e+02, initc-loss 2.2689e+04                    bc_loss 8.6836e+05\n",
      "Epoch 15510, Training-Loss 1.0387e+04, Data-loss 5.7181e+03                  , pde-loss 8.0771e+02, initc-loss 1.0410e+04                    bc_loss 4.5567e+05\n",
      "Epoch 15520, Training-Loss 4.9623e+03, Data-loss 2.3297e+03                  , pde-loss 4.8446e+03, initc-loss 1.5498e+04                    bc_loss 2.4292e+05\n",
      "Epoch 15530, Training-Loss 7.3266e+03, Data-loss 3.7193e+03                  , pde-loss 5.5909e+03, initc-loss 2.0814e+04                    bc_loss 3.3433e+05\n",
      "Epoch 15540, Training-Loss 4.6761e+03, Data-loss 2.2104e+03                  , pde-loss 1.9109e+03, initc-loss 1.6608e+04                    bc_loss 2.2805e+05\n",
      "Epoch 15550, Training-Loss 3.8634e+03, Data-loss 3.1269e+03                  , pde-loss 6.5817e+02, initc-loss 1.5707e+04                    bc_loss 5.7286e+04\n",
      "Epoch 15560, Training-Loss 2.0963e+03, Data-loss 1.6289e+03                  , pde-loss 6.9517e+02, initc-loss 1.8177e+04                    bc_loss 2.7861e+04\n",
      "Epoch 15570, Training-Loss 2.9775e+03, Data-loss 2.5197e+03                  , pde-loss 1.7251e+03, initc-loss 1.7381e+04                    bc_loss 2.6676e+04\n",
      "Epoch 15580, Training-Loss 7.2254e+03, Data-loss 1.6744e+03                  , pde-loss 1.5380e+03, initc-loss 1.8572e+04                    bc_loss 5.3498e+05\n",
      "Epoch 15590, Training-Loss 4.0068e+03, Data-loss 2.8539e+03                  , pde-loss 7.4708e+02, initc-loss 1.7641e+04                    bc_loss 9.6902e+04\n",
      "Epoch 15600, Training-Loss 4.6950e+03, Data-loss 2.5940e+03                  , pde-loss 7.3734e+02, initc-loss 1.3549e+04                    bc_loss 1.9581e+05\n",
      "Epoch 15610, Training-Loss 2.8173e+03, Data-loss 2.3666e+03                  , pde-loss 2.4233e+03, initc-loss 1.8271e+04                    bc_loss 2.4374e+04\n",
      "Epoch 15620, Training-Loss 1.6164e+03, Data-loss 1.3611e+03                  , pde-loss 2.4936e+03, initc-loss 1.3047e+04                    bc_loss 9.9821e+03\n",
      "Epoch 15630, Training-Loss 2.4056e+03, Data-loss 1.2021e+03                  , pde-loss 1.8928e+03, initc-loss 1.4539e+04                    bc_loss 1.0392e+05\n",
      "Epoch 15640, Training-Loss 2.3655e+03, Data-loss 1.1491e+03                  , pde-loss 1.6610e+03, initc-loss 1.0738e+04                    bc_loss 1.0924e+05\n",
      "Epoch 15650, Training-Loss 1.5125e+03, Data-loss 1.1306e+03                  , pde-loss 9.4454e+02, initc-loss 1.3081e+04                    bc_loss 2.4162e+04\n",
      "Epoch 15660, Training-Loss 1.6009e+03, Data-loss 8.1471e+02                  , pde-loss 8.7888e+02, initc-loss 1.4058e+04                    bc_loss 6.3686e+04\n",
      "Epoch 15670, Training-Loss 1.1217e+04, Data-loss 4.5840e+03                  , pde-loss 5.1856e+02, initc-loss 2.1873e+04                    bc_loss 6.4087e+05\n",
      "Epoch 15680, Training-Loss 4.3895e+03, Data-loss 3.0972e+03                  , pde-loss 4.8234e+02, initc-loss 1.4362e+04                    bc_loss 1.1438e+05\n",
      "Epoch 15690, Training-Loss 3.4803e+03, Data-loss 2.2135e+03                  , pde-loss 9.5915e+02, initc-loss 1.1249e+04                    bc_loss 1.1447e+05\n",
      "Epoch 15700, Training-Loss 2.6625e+03, Data-loss 2.0202e+03                  , pde-loss 2.5180e+03, initc-loss 1.6276e+04                    bc_loss 4.5433e+04\n",
      "Epoch 15710, Training-Loss 1.8665e+03, Data-loss 1.3737e+03                  , pde-loss 1.8378e+03, initc-loss 1.4612e+04                    bc_loss 3.2834e+04\n",
      "Epoch 15720, Training-Loss 1.7169e+04, Data-loss 3.8339e+03                  , pde-loss 8.7011e+02, initc-loss 2.5361e+04                    bc_loss 1.3073e+06\n",
      "Epoch 15730, Training-Loss 6.7933e+03, Data-loss 3.9717e+03                  , pde-loss 3.1188e+02, initc-loss 7.7730e+03                    bc_loss 2.7407e+05\n",
      "Epoch 15740, Training-Loss 5.0371e+03, Data-loss 3.2406e+03                  , pde-loss 2.6169e+03, initc-loss 9.1334e+03                    bc_loss 1.6791e+05\n",
      "Epoch 15750, Training-Loss 1.1294e+04, Data-loss 4.0797e+03                  , pde-loss 6.0172e+03, initc-loss 2.1883e+04                    bc_loss 6.9352e+05\n",
      "Epoch 15760, Training-Loss 4.4498e+03, Data-loss 1.6743e+03                  , pde-loss 3.2559e+03, initc-loss 1.2161e+04                    bc_loss 2.6213e+05\n",
      "Epoch 15770, Training-Loss 4.0126e+03, Data-loss 3.3766e+03                  , pde-loss 8.3264e+02, initc-loss 1.5677e+04                    bc_loss 4.7087e+04\n",
      "Epoch 15780, Training-Loss 3.4106e+03, Data-loss 2.1155e+03                  , pde-loss 8.2831e+02, initc-loss 1.8620e+04                    bc_loss 1.1006e+05\n",
      "Epoch 15790, Training-Loss 1.5466e+03, Data-loss 1.1281e+03                  , pde-loss 1.2391e+03, initc-loss 1.4493e+04                    bc_loss 2.6116e+04\n",
      "Epoch 15800, Training-Loss 2.7938e+03, Data-loss 1.2088e+03                  , pde-loss 1.0785e+03, initc-loss 1.4388e+04                    bc_loss 1.4303e+05\n",
      "Epoch 15810, Training-Loss 2.5812e+03, Data-loss 1.0229e+03                  , pde-loss 7.4867e+02, initc-loss 1.2404e+04                    bc_loss 1.4267e+05\n",
      "Epoch 15820, Training-Loss 1.3137e+03, Data-loss 5.5363e+02                  , pde-loss 1.6007e+03, initc-loss 1.3020e+04                    bc_loss 6.1382e+04\n",
      "Epoch 15830, Training-Loss 2.0183e+03, Data-loss 1.2651e+03                  , pde-loss 2.1772e+03, initc-loss 1.2739e+04                    bc_loss 6.0401e+04\n",
      "Epoch 15840, Training-Loss 8.1442e+02, Data-loss 4.9424e+02                  , pde-loss 1.6964e+03, initc-loss 1.2115e+04                    bc_loss 1.8207e+04\n",
      "Epoch 15850, Training-Loss 1.1965e+03, Data-loss 8.0878e+02                  , pde-loss 1.2680e+03, initc-loss 1.3321e+04                    bc_loss 2.4182e+04\n",
      "Epoch 15860, Training-Loss 1.8057e+03, Data-loss 1.3211e+03                  , pde-loss 1.1025e+03, initc-loss 1.1831e+04                    bc_loss 3.5524e+04\n",
      "Epoch 15870, Training-Loss 9.1607e+02, Data-loss 6.2237e+02                  , pde-loss 1.4637e+03, initc-loss 1.3530e+04                    bc_loss 1.4377e+04\n",
      "Epoch 15880, Training-Loss 3.0909e+03, Data-loss 1.0922e+03                  , pde-loss 1.8970e+03, initc-loss 1.5850e+04                    bc_loss 1.8212e+05\n",
      "Epoch 15890, Training-Loss 4.2098e+03, Data-loss 1.3551e+03                  , pde-loss 2.8682e+03, initc-loss 1.5508e+04                    bc_loss 2.6709e+05\n",
      "Epoch 15900, Training-Loss 6.7845e+03, Data-loss 2.5549e+03                  , pde-loss 3.3712e+03, initc-loss 8.6817e+03                    bc_loss 4.1091e+05\n",
      "Epoch 15910, Training-Loss 2.7499e+03, Data-loss 1.5617e+03                  , pde-loss 9.3612e+02, initc-loss 1.3442e+04                    bc_loss 1.0444e+05\n",
      "Epoch 15920, Training-Loss 2.6405e+03, Data-loss 1.3394e+03                  , pde-loss 7.4693e+02, initc-loss 1.7776e+04                    bc_loss 1.1159e+05\n",
      "Epoch 15930, Training-Loss 1.4559e+03, Data-loss 1.0504e+03                  , pde-loss 1.7502e+03, initc-loss 1.5620e+04                    bc_loss 2.3175e+04\n",
      "Epoch 15940, Training-Loss 1.7756e+03, Data-loss 1.2667e+03                  , pde-loss 1.2577e+03, initc-loss 1.5942e+04                    bc_loss 3.3693e+04\n",
      "Epoch 15950, Training-Loss 1.0806e+04, Data-loss 1.6961e+03                  , pde-loss 4.9411e+02, initc-loss 2.0180e+04                    bc_loss 8.9029e+05\n",
      "Epoch 15960, Training-Loss 3.4170e+03, Data-loss 2.7302e+03                  , pde-loss 3.0949e+02, initc-loss 1.4446e+04                    bc_loss 5.3924e+04\n",
      "Epoch 15970, Training-Loss 2.3853e+03, Data-loss 1.9402e+03                  , pde-loss 1.3982e+03, initc-loss 1.7792e+04                    bc_loss 2.5316e+04\n",
      "Epoch 15980, Training-Loss 1.4859e+03, Data-loss 1.1414e+03                  , pde-loss 1.4337e+03, initc-loss 1.7359e+04                    bc_loss 1.5659e+04\n",
      "Epoch 15990, Training-Loss 1.6357e+03, Data-loss 1.2837e+03                  , pde-loss 1.4617e+03, initc-loss 1.5853e+04                    bc_loss 1.7887e+04\n",
      "Epoch 16000, Training-Loss 1.4572e+03, Data-loss 1.1416e+03                  , pde-loss 1.4029e+03, initc-loss 1.3530e+04                    bc_loss 1.6628e+04\n",
      "Epoch 16010, Training-Loss 9.8782e+02, Data-loss 3.9575e+02                  , pde-loss 1.5694e+03, initc-loss 1.3390e+04                    bc_loss 4.4248e+04\n",
      "Epoch 16020, Training-Loss 1.6247e+03, Data-loss 1.3035e+03                  , pde-loss 1.7641e+03, initc-loss 1.4743e+04                    bc_loss 1.5618e+04\n",
      "Epoch 16030, Training-Loss 1.4236e+03, Data-loss 7.7464e+02                  , pde-loss 1.6006e+03, initc-loss 1.0698e+04                    bc_loss 5.2601e+04\n",
      "Epoch 16040, Training-Loss 1.1664e+03, Data-loss 8.1950e+02                  , pde-loss 1.2439e+03, initc-loss 1.1721e+04                    bc_loss 2.1725e+04\n",
      "Epoch 16050, Training-Loss 9.2341e+02, Data-loss 6.6788e+02                  , pde-loss 1.1308e+03, initc-loss 1.1699e+04                    bc_loss 1.2723e+04\n",
      "Epoch 16060, Training-Loss 1.6567e+04, Data-loss 1.6971e+03                  , pde-loss 1.0617e+03, initc-loss 1.9792e+04                    bc_loss 1.4661e+06\n",
      "Epoch 16070, Training-Loss 5.5897e+03, Data-loss 3.5591e+03                  , pde-loss 3.1045e+02, initc-loss 1.1943e+04                    bc_loss 1.9081e+05\n",
      "Epoch 16080, Training-Loss 4.5069e+03, Data-loss 2.5022e+03                  , pde-loss 1.8117e+03, initc-loss 1.5100e+04                    bc_loss 1.8356e+05\n",
      "Epoch 16090, Training-Loss 4.3115e+03, Data-loss 2.5551e+03                  , pde-loss 2.0057e+03, initc-loss 1.6490e+04                    bc_loss 1.5714e+05\n",
      "Epoch 16100, Training-Loss 2.5013e+03, Data-loss 1.8180e+03                  , pde-loss 8.8601e+02, initc-loss 1.8648e+04                    bc_loss 4.8800e+04\n",
      "Epoch 16110, Training-Loss 3.7851e+03, Data-loss 2.0622e+03                  , pde-loss 1.0525e+03, initc-loss 1.6396e+04                    bc_loss 1.5485e+05\n",
      "Epoch 16120, Training-Loss 6.1899e+03, Data-loss 2.7453e+03                  , pde-loss 6.2321e+02, initc-loss 1.7558e+04                    bc_loss 3.2629e+05\n",
      "Epoch 16130, Training-Loss 3.6948e+03, Data-loss 3.1265e+03                  , pde-loss 2.8491e+03, initc-loss 2.0479e+04                    bc_loss 3.3496e+04\n",
      "Epoch 16140, Training-Loss 7.2676e+03, Data-loss 2.7430e+03                  , pde-loss 3.4789e+03, initc-loss 2.1381e+04                    bc_loss 4.2760e+05\n",
      "Epoch 16150, Training-Loss 2.4581e+03, Data-loss 1.6081e+03                  , pde-loss 1.9283e+03, initc-loss 9.6563e+03                    bc_loss 7.3418e+04\n",
      "Epoch 16160, Training-Loss 1.1364e+03, Data-loss 6.7164e+02                  , pde-loss 7.9093e+02, initc-loss 1.4081e+04                    bc_loss 3.1606e+04\n",
      "Epoch 16170, Training-Loss 1.1797e+03, Data-loss 8.4034e+02                  , pde-loss 1.3012e+03, initc-loss 1.4538e+04                    bc_loss 1.8099e+04\n",
      "Epoch 16180, Training-Loss 1.2161e+03, Data-loss 7.7786e+02                  , pde-loss 1.4091e+03, initc-loss 1.5413e+04                    bc_loss 2.6999e+04\n",
      "Epoch 16190, Training-Loss 1.2702e+03, Data-loss 1.0099e+03                  , pde-loss 1.2170e+03, initc-loss 1.1905e+04                    bc_loss 1.2906e+04\n",
      "Epoch 16200, Training-Loss 1.0161e+03, Data-loss 7.4474e+02                  , pde-loss 1.1567e+03, initc-loss 1.3220e+04                    bc_loss 1.2763e+04\n",
      "Epoch 16210, Training-Loss 1.8555e+03, Data-loss 1.5737e+03                  , pde-loss 1.2936e+03, initc-loss 1.5041e+04                    bc_loss 1.1849e+04\n",
      "Epoch 16220, Training-Loss 1.6224e+03, Data-loss 1.0845e+03                  , pde-loss 1.3558e+03, initc-loss 1.4780e+04                    bc_loss 3.7650e+04\n",
      "Epoch 16230, Training-Loss 2.5283e+04, Data-loss 3.9702e+03                  , pde-loss 6.6025e+02, initc-loss 2.7653e+04                    bc_loss 2.1030e+06\n",
      "Epoch 16240, Training-Loss 5.0866e+03, Data-loss 2.9024e+03                  , pde-loss 3.4848e+02, initc-loss 1.6488e+04                    bc_loss 2.0159e+05\n",
      "Epoch 16250, Training-Loss 4.4267e+03, Data-loss 3.3580e+03                  , pde-loss 2.3757e+03, initc-loss 1.1909e+04                    bc_loss 9.2592e+04\n",
      "Epoch 16260, Training-Loss 2.0739e+03, Data-loss 1.3501e+03                  , pde-loss 1.8880e+03, initc-loss 1.4709e+04                    bc_loss 5.5787e+04\n",
      "Epoch 16270, Training-Loss 2.5503e+03, Data-loss 1.8248e+03                  , pde-loss 9.2970e+02, initc-loss 1.3691e+04                    bc_loss 5.7934e+04\n",
      "Epoch 16280, Training-Loss 1.3887e+03, Data-loss 1.0172e+03                  , pde-loss 1.5964e+03, initc-loss 1.2315e+04                    bc_loss 2.3241e+04\n",
      "Epoch 16290, Training-Loss 1.0466e+04, Data-loss 7.9739e+02                  , pde-loss 1.8632e+03, initc-loss 1.7961e+04                    bc_loss 9.4704e+05\n",
      "Epoch 16300, Training-Loss 3.8869e+03, Data-loss 1.9226e+03                  , pde-loss 2.7102e+03, initc-loss 1.1099e+04                    bc_loss 1.8263e+05\n",
      "Epoch 16310, Training-Loss 1.1546e+04, Data-loss 2.3341e+03                  , pde-loss 8.9239e+02, initc-loss 1.4869e+04                    bc_loss 9.0541e+05\n",
      "Epoch 16320, Training-Loss 1.0054e+04, Data-loss 4.7461e+03                  , pde-loss 2.3479e+02, initc-loss 1.5563e+04                    bc_loss 5.1504e+05\n",
      "Epoch 16330, Training-Loss 4.9072e+03, Data-loss 4.2488e+03                  , pde-loss 2.3248e+03, initc-loss 1.8591e+04                    bc_loss 4.4922e+04\n",
      "Epoch 16340, Training-Loss 3.6976e+03, Data-loss 2.8692e+03                  , pde-loss 3.5851e+03, initc-loss 1.6894e+04                    bc_loss 6.2368e+04\n",
      "Epoch 16350, Training-Loss 1.4411e+03, Data-loss 1.0212e+03                  , pde-loss 1.0570e+03, initc-loss 1.5042e+04                    bc_loss 2.5887e+04\n",
      "Epoch 16360, Training-Loss 1.6146e+03, Data-loss 1.3391e+03                  , pde-loss 9.9831e+02, initc-loss 1.3906e+04                    bc_loss 1.2646e+04\n",
      "Epoch 16370, Training-Loss 1.6401e+03, Data-loss 9.9501e+02                  , pde-loss 1.6313e+03, initc-loss 1.6184e+04                    bc_loss 4.6689e+04\n",
      "Epoch 16380, Training-Loss 2.5933e+03, Data-loss 1.8629e+03                  , pde-loss 1.3844e+03, initc-loss 1.7127e+04                    bc_loss 5.4528e+04\n",
      "Epoch 16390, Training-Loss 2.9770e+03, Data-loss 8.8931e+02                  , pde-loss 1.7490e+03, initc-loss 1.3307e+04                    bc_loss 1.9371e+05\n",
      "Epoch 16400, Training-Loss 1.5393e+03, Data-loss 1.0200e+03                  , pde-loss 1.3324e+03, initc-loss 1.3695e+04                    bc_loss 3.6907e+04\n",
      "Epoch 16410, Training-Loss 1.5542e+03, Data-loss 1.2867e+03                  , pde-loss 1.0954e+03, initc-loss 1.3453e+04                    bc_loss 1.2197e+04\n",
      "Epoch 16420, Training-Loss 1.3152e+03, Data-loss 6.6667e+02                  , pde-loss 1.0814e+03, initc-loss 1.4803e+04                    bc_loss 4.8971e+04\n",
      "Epoch 16430, Training-Loss 1.3938e+04, Data-loss 1.5814e+03                  , pde-loss 5.8597e+02, initc-loss 1.7614e+04                    bc_loss 1.2174e+06\n",
      "Epoch 16440, Training-Loss 7.0197e+03, Data-loss 3.7370e+03                  , pde-loss 3.3464e+02, initc-loss 1.3237e+04                    bc_loss 3.1470e+05\n",
      "Epoch 16450, Training-Loss 2.1449e+03, Data-loss 1.6910e+03                  , pde-loss 1.8833e+03, initc-loss 1.4059e+04                    bc_loss 2.9449e+04\n",
      "Epoch 16460, Training-Loss 1.9036e+03, Data-loss 1.5166e+03                  , pde-loss 2.4214e+03, initc-loss 1.7331e+04                    bc_loss 1.8939e+04\n",
      "Epoch 16470, Training-Loss 3.0567e+03, Data-loss 1.9001e+03                  , pde-loss 1.3954e+03, initc-loss 1.8546e+04                    bc_loss 9.5723e+04\n",
      "Epoch 16480, Training-Loss 2.7536e+03, Data-loss 1.9363e+03                  , pde-loss 1.1888e+03, initc-loss 1.2622e+04                    bc_loss 6.7917e+04\n",
      "Epoch 16490, Training-Loss 7.6258e+03, Data-loss 1.2762e+03                  , pde-loss 2.6201e+03, initc-loss 1.6246e+04                    bc_loss 6.1609e+05\n",
      "Epoch 16500, Training-Loss 7.1030e+03, Data-loss 3.6750e+03                  , pde-loss 4.5699e+03, initc-loss 1.4983e+04                    bc_loss 3.2325e+05\n",
      "Epoch 16510, Training-Loss 3.7215e+03, Data-loss 2.5454e+03                  , pde-loss 1.6482e+03, initc-loss 1.6974e+04                    bc_loss 9.8993e+04\n",
      "Epoch 16520, Training-Loss 2.5244e+03, Data-loss 1.9332e+03                  , pde-loss 8.6264e+02, initc-loss 1.4569e+04                    bc_loss 4.3692e+04\n",
      "Epoch 16530, Training-Loss 1.5418e+03, Data-loss 8.9061e+02                  , pde-loss 1.8521e+03, initc-loss 1.4648e+04                    bc_loss 4.8618e+04\n",
      "Epoch 16540, Training-Loss 1.2402e+03, Data-loss 9.0306e+02                  , pde-loss 1.8773e+03, initc-loss 1.1638e+04                    bc_loss 2.0196e+04\n",
      "Epoch 16550, Training-Loss 1.1242e+03, Data-loss 8.0113e+02                  , pde-loss 1.1622e+03, initc-loss 1.4485e+04                    bc_loss 1.6657e+04\n",
      "Epoch 16560, Training-Loss 5.6088e+03, Data-loss 1.5432e+03                  , pde-loss 7.4009e+02, initc-loss 2.0113e+04                    bc_loss 3.8570e+05\n",
      "Epoch 16570, Training-Loss 9.3662e+03, Data-loss 3.3978e+03                  , pde-loss 2.5933e+02, initc-loss 1.5739e+04                    bc_loss 5.8084e+05\n",
      "Epoch 16580, Training-Loss 6.4766e+03, Data-loss 4.0436e+03                  , pde-loss 4.9489e+02, initc-loss 1.3070e+04                    bc_loss 2.2974e+05\n",
      "Epoch 16590, Training-Loss 4.5576e+03, Data-loss 2.8596e+03                  , pde-loss 2.7022e+03, initc-loss 1.6994e+04                    bc_loss 1.5010e+05\n",
      "Epoch 16600, Training-Loss 3.4037e+03, Data-loss 2.6511e+03                  , pde-loss 1.3428e+03, initc-loss 1.7400e+04                    bc_loss 5.6511e+04\n",
      "Epoch 16610, Training-Loss 1.7633e+03, Data-loss 1.2535e+03                  , pde-loss 8.1130e+02, initc-loss 1.6724e+04                    bc_loss 3.3441e+04\n",
      "Epoch 16620, Training-Loss 2.3136e+03, Data-loss 1.8612e+03                  , pde-loss 1.4557e+03, initc-loss 1.6710e+04                    bc_loss 2.7065e+04\n",
      "Epoch 16630, Training-Loss 3.1698e+03, Data-loss 5.2483e+02                  , pde-loss 1.5905e+03, initc-loss 1.8016e+04                    bc_loss 2.4489e+05\n",
      "Epoch 16640, Training-Loss 9.5831e+03, Data-loss 4.0891e+03                  , pde-loss 4.0264e+02, initc-loss 1.8973e+04                    bc_loss 5.3002e+05\n",
      "Epoch 16650, Training-Loss 8.0977e+03, Data-loss 3.5773e+03                  , pde-loss 1.1562e+03, initc-loss 1.4885e+04                    bc_loss 4.3600e+05\n",
      "Epoch 16660, Training-Loss 5.1321e+03, Data-loss 2.8403e+03                  , pde-loss 5.2849e+03, initc-loss 1.5902e+04                    bc_loss 2.0799e+05\n",
      "Epoch 16670, Training-Loss 4.8437e+03, Data-loss 2.3384e+03                  , pde-loss 3.5529e+03, initc-loss 1.5802e+04                    bc_loss 2.3118e+05\n",
      "Epoch 16680, Training-Loss 1.3714e+03, Data-loss 9.2775e+02                  , pde-loss 9.6285e+02, initc-loss 1.3590e+04                    bc_loss 2.9814e+04\n",
      "Epoch 16690, Training-Loss 2.3177e+03, Data-loss 1.9729e+03                  , pde-loss 7.6004e+02, initc-loss 1.4656e+04                    bc_loss 1.9066e+04\n",
      "Epoch 16700, Training-Loss 2.0347e+03, Data-loss 1.1074e+03                  , pde-loss 1.4248e+03, initc-loss 1.4317e+04                    bc_loss 7.6988e+04\n",
      "Epoch 16710, Training-Loss 1.1558e+03, Data-loss 6.4169e+02                  , pde-loss 1.1448e+03, initc-loss 1.3136e+04                    bc_loss 3.7133e+04\n",
      "Epoch 16720, Training-Loss 1.5070e+03, Data-loss 1.2064e+03                  , pde-loss 1.1045e+03, initc-loss 1.2770e+04                    bc_loss 1.6186e+04\n",
      "Epoch 16730, Training-Loss 4.1319e+03, Data-loss 7.5932e+02                  , pde-loss 1.1708e+03, initc-loss 1.5959e+04                    bc_loss 3.2013e+05\n",
      "Epoch 16740, Training-Loss 6.0865e+03, Data-loss 1.2663e+03                  , pde-loss 8.4321e+02, initc-loss 1.6106e+04                    bc_loss 4.6507e+05\n",
      "Epoch 16750, Training-Loss 2.5532e+03, Data-loss 1.8249e+03                  , pde-loss 8.3013e+02, initc-loss 1.3762e+04                    bc_loss 5.8243e+04\n",
      "Epoch 16760, Training-Loss 2.5137e+03, Data-loss 1.8790e+03                  , pde-loss 1.9149e+03, initc-loss 1.5892e+04                    bc_loss 4.5667e+04\n",
      "Epoch 16770, Training-Loss 1.2999e+03, Data-loss 7.9477e+02                  , pde-loss 2.0232e+03, initc-loss 1.5680e+04                    bc_loss 3.2813e+04\n",
      "Epoch 16780, Training-Loss 2.1873e+03, Data-loss 1.5036e+03                  , pde-loss 1.2650e+03, initc-loss 1.4865e+04                    bc_loss 5.2241e+04\n",
      "Epoch 16790, Training-Loss 7.5094e+03, Data-loss 1.2560e+03                  , pde-loss 7.2933e+02, initc-loss 1.7869e+04                    bc_loss 6.0674e+05\n",
      "Epoch 16800, Training-Loss 4.1082e+03, Data-loss 1.4701e+03                  , pde-loss 1.0236e+03, initc-loss 1.1102e+04                    bc_loss 2.5169e+05\n",
      "Epoch 16810, Training-Loss 9.7719e+03, Data-loss 2.0140e+03                  , pde-loss 3.9937e+03, initc-loss 1.9051e+04                    bc_loss 7.5275e+05\n",
      "Epoch 16820, Training-Loss 5.4294e+03, Data-loss 2.7867e+03                  , pde-loss 5.1317e+03, initc-loss 1.2340e+04                    bc_loss 2.4679e+05\n",
      "Epoch 16830, Training-Loss 2.6691e+03, Data-loss 1.6179e+03                  , pde-loss 1.3814e+03, initc-loss 1.6041e+04                    bc_loss 8.7698e+04\n",
      "Epoch 16840, Training-Loss 2.4099e+03, Data-loss 1.6416e+03                  , pde-loss 6.5083e+02, initc-loss 1.4095e+04                    bc_loss 6.2082e+04\n",
      "Epoch 16850, Training-Loss 2.0679e+03, Data-loss 1.3384e+03                  , pde-loss 1.4215e+03, initc-loss 1.5348e+04                    bc_loss 5.6189e+04\n",
      "Epoch 16860, Training-Loss 1.3807e+03, Data-loss 8.4439e+02                  , pde-loss 1.5255e+03, initc-loss 1.4053e+04                    bc_loss 3.8048e+04\n",
      "Epoch 16870, Training-Loss 1.3554e+03, Data-loss 8.0537e+02                  , pde-loss 1.5778e+03, initc-loss 1.3827e+04                    bc_loss 3.9597e+04\n",
      "Epoch 16880, Training-Loss 2.4898e+03, Data-loss 1.4979e+03                  , pde-loss 1.7062e+03, initc-loss 1.2343e+04                    bc_loss 8.5131e+04\n",
      "Epoch 16890, Training-Loss 2.0382e+03, Data-loss 7.3751e+02                  , pde-loss 6.8020e+02, initc-loss 1.4607e+04                    bc_loss 1.1478e+05\n",
      "Epoch 16900, Training-Loss 1.0180e+04, Data-loss 3.1128e+03                  , pde-loss 1.8577e+02, initc-loss 2.3106e+04                    bc_loss 6.8346e+05\n",
      "Epoch 16910, Training-Loss 4.7035e+03, Data-loss 3.9808e+03                  , pde-loss 3.6757e+02, initc-loss 1.8916e+04                    bc_loss 5.2987e+04\n",
      "Epoch 16920, Training-Loss 3.6662e+03, Data-loss 2.9802e+03                  , pde-loss 2.0461e+03, initc-loss 1.9220e+04                    bc_loss 4.7336e+04\n",
      "Epoch 16930, Training-Loss 2.8469e+03, Data-loss 2.3711e+03                  , pde-loss 1.7995e+03, initc-loss 1.7111e+04                    bc_loss 2.8674e+04\n",
      "Epoch 16940, Training-Loss 1.4786e+03, Data-loss 8.9470e+02                  , pde-loss 1.0443e+03, initc-loss 1.5954e+04                    bc_loss 4.1391e+04\n",
      "Epoch 16950, Training-Loss 7.1092e+03, Data-loss 2.2616e+03                  , pde-loss 9.1390e+02, initc-loss 1.6428e+04                    bc_loss 4.6742e+05\n",
      "Epoch 16960, Training-Loss 2.2535e+03, Data-loss 1.7770e+03                  , pde-loss 2.4697e+03, initc-loss 1.8474e+04                    bc_loss 2.6702e+04\n",
      "Epoch 16970, Training-Loss 4.5938e+03, Data-loss 1.4849e+03                  , pde-loss 3.0370e+03, initc-loss 1.7468e+04                    bc_loss 2.9039e+05\n",
      "Epoch 16980, Training-Loss 1.6557e+03, Data-loss 1.1042e+03                  , pde-loss 1.7685e+03, initc-loss 1.0043e+04                    bc_loss 4.3343e+04\n",
      "Epoch 16990, Training-Loss 1.2056e+03, Data-loss 8.2558e+02                  , pde-loss 8.3262e+02, initc-loss 1.2682e+04                    bc_loss 2.4488e+04\n",
      "Epoch 17000, Training-Loss 1.6919e+03, Data-loss 1.2262e+03                  , pde-loss 1.2126e+03, initc-loss 1.1947e+04                    bc_loss 3.3416e+04\n",
      "Epoch 17010, Training-Loss 1.4780e+03, Data-loss 1.1637e+03                  , pde-loss 1.3443e+03, initc-loss 1.3826e+04                    bc_loss 1.6268e+04\n",
      "Epoch 17020, Training-Loss 1.4484e+03, Data-loss 7.0749e+02                  , pde-loss 1.2718e+03, initc-loss 1.3491e+04                    bc_loss 5.9326e+04\n",
      "Epoch 17030, Training-Loss 1.1311e+03, Data-loss 8.2797e+02                  , pde-loss 1.3621e+03, initc-loss 1.4015e+04                    bc_loss 1.4931e+04\n",
      "Epoch 17040, Training-Loss 1.2312e+03, Data-loss 7.8486e+02                  , pde-loss 1.5107e+03, initc-loss 1.3768e+04                    bc_loss 2.9358e+04\n",
      "Epoch 17050, Training-Loss 4.6569e+03, Data-loss 2.8716e+03                  , pde-loss 2.5195e+03, initc-loss 2.4080e+04                    bc_loss 1.5193e+05\n",
      "Epoch 17060, Training-Loss 2.8159e+03, Data-loss 1.6594e+03                  , pde-loss 1.9113e+03, initc-loss 1.3606e+04                    bc_loss 1.0013e+05\n",
      "Epoch 17070, Training-Loss 8.9207e+03, Data-loss 1.9687e+03                  , pde-loss 7.3143e+02, initc-loss 2.0624e+04                    bc_loss 6.7384e+05\n",
      "Epoch 17080, Training-Loss 2.9577e+03, Data-loss 1.6987e+03                  , pde-loss 1.0183e+03, initc-loss 1.7796e+04                    bc_loss 1.0709e+05\n",
      "Epoch 17090, Training-Loss 2.3575e+03, Data-loss 1.7267e+03                  , pde-loss 2.6585e+03, initc-loss 1.3655e+04                    bc_loss 4.6765e+04\n",
      "Epoch 17100, Training-Loss 1.2443e+03, Data-loss 7.3762e+02                  , pde-loss 1.4765e+03, initc-loss 1.4367e+04                    bc_loss 3.4826e+04\n",
      "Epoch 17110, Training-Loss 2.3149e+03, Data-loss 1.5376e+03                  , pde-loss 9.2994e+02, initc-loss 1.6507e+04                    bc_loss 6.0296e+04\n",
      "Epoch 17120, Training-Loss 1.0491e+04, Data-loss 1.8509e+03                  , pde-loss 7.8729e+02, initc-loss 1.7011e+04                    bc_loss 8.4621e+05\n",
      "Epoch 17130, Training-Loss 6.1368e+03, Data-loss 3.9771e+03                  , pde-loss 5.8071e+02, initc-loss 8.5461e+03                    bc_loss 2.0684e+05\n",
      "Epoch 17140, Training-Loss 3.1688e+03, Data-loss 1.3861e+03                  , pde-loss 1.8804e+03, initc-loss 1.3353e+04                    bc_loss 1.6303e+05\n",
      "Epoch 17150, Training-Loss 2.2540e+03, Data-loss 1.5314e+03                  , pde-loss 1.7186e+03, initc-loss 9.0604e+03                    bc_loss 6.1473e+04\n",
      "Epoch 17160, Training-Loss 1.8664e+03, Data-loss 1.2505e+03                  , pde-loss 1.0409e+03, initc-loss 1.2465e+04                    bc_loss 4.8080e+04\n",
      "Epoch 17170, Training-Loss 2.2520e+03, Data-loss 1.5634e+03                  , pde-loss 1.1612e+03, initc-loss 1.3058e+04                    bc_loss 5.4646e+04\n",
      "Epoch 17180, Training-Loss 1.3907e+03, Data-loss 1.1368e+03                  , pde-loss 1.2336e+03, initc-loss 1.0929e+04                    bc_loss 1.3230e+04\n",
      "Epoch 17190, Training-Loss 1.2689e+03, Data-loss 7.6162e+02                  , pde-loss 1.6338e+03, initc-loss 1.5442e+04                    bc_loss 3.3650e+04\n",
      "Epoch 17200, Training-Loss 1.0870e+04, Data-loss 8.0281e+02                  , pde-loss 1.0478e+03, initc-loss 1.6542e+04                    bc_loss 9.8912e+05\n",
      "Epoch 17210, Training-Loss 8.6689e+03, Data-loss 4.3636e+03                  , pde-loss 4.2630e+02, initc-loss 1.3590e+04                    bc_loss 4.1651e+05\n",
      "Epoch 17220, Training-Loss 2.2774e+03, Data-loss 1.4682e+03                  , pde-loss 1.9285e+03, initc-loss 1.6281e+04                    bc_loss 6.2707e+04\n",
      "Epoch 17230, Training-Loss 2.1015e+03, Data-loss 1.8367e+03                  , pde-loss 1.5303e+03, initc-loss 1.5134e+04                    bc_loss 9.8135e+03\n",
      "Epoch 17240, Training-Loss 1.4422e+03, Data-loss 1.0604e+03                  , pde-loss 1.3996e+03, initc-loss 1.4548e+04                    bc_loss 2.2239e+04\n",
      "Epoch 17250, Training-Loss 1.0552e+03, Data-loss 7.5205e+02                  , pde-loss 1.3651e+03, initc-loss 1.2471e+04                    bc_loss 1.6483e+04\n",
      "Epoch 17260, Training-Loss 2.9918e+03, Data-loss 6.8660e+02                  , pde-loss 1.4887e+03, initc-loss 1.5832e+04                    bc_loss 2.1320e+05\n",
      "Epoch 17270, Training-Loss 2.4336e+03, Data-loss 1.4721e+03                  , pde-loss 2.1516e+03, initc-loss 1.2609e+04                    bc_loss 8.1395e+04\n",
      "Epoch 17280, Training-Loss 1.7253e+03, Data-loss 1.1490e+03                  , pde-loss 1.7389e+03, initc-loss 1.6239e+04                    bc_loss 3.9649e+04\n",
      "Epoch 17290, Training-Loss 1.0769e+03, Data-loss 6.8686e+02                  , pde-loss 1.0634e+03, initc-loss 1.6767e+04                    bc_loss 2.1173e+04\n",
      "Epoch 17300, Training-Loss 7.8351e+02, Data-loss 4.4874e+02                  , pde-loss 1.1146e+03, initc-loss 1.4810e+04                    bc_loss 1.7552e+04\n",
      "Epoch 17310, Training-Loss 9.9096e+03, Data-loss 1.1045e+03                  , pde-loss 1.1416e+03, initc-loss 1.4614e+04                    bc_loss 8.6476e+05\n",
      "Epoch 17320, Training-Loss 4.8847e+03, Data-loss 2.9475e+03                  , pde-loss 4.7184e+02, initc-loss 1.6952e+04                    bc_loss 1.7629e+05\n",
      "Epoch 17330, Training-Loss 3.7940e+03, Data-loss 2.5045e+03                  , pde-loss 6.8690e+02, initc-loss 1.1761e+04                    bc_loss 1.1650e+05\n",
      "Epoch 17340, Training-Loss 2.1689e+03, Data-loss 1.5155e+03                  , pde-loss 2.6448e+03, initc-loss 1.3678e+04                    bc_loss 4.9016e+04\n",
      "Epoch 17350, Training-Loss 1.8266e+03, Data-loss 1.2750e+03                  , pde-loss 1.7015e+03, initc-loss 1.3623e+04                    bc_loss 3.9844e+04\n",
      "Epoch 17360, Training-Loss 1.0132e+03, Data-loss 6.9654e+02                  , pde-loss 1.1932e+03, initc-loss 1.4129e+04                    bc_loss 1.6343e+04\n",
      "Epoch 17370, Training-Loss 2.2499e+03, Data-loss 1.7290e+03                  , pde-loss 9.6060e+02, initc-loss 1.4196e+04                    bc_loss 3.6934e+04\n",
      "Epoch 17380, Training-Loss 1.8215e+03, Data-loss 1.3906e+03                  , pde-loss 1.2857e+03, initc-loss 1.0348e+04                    bc_loss 3.1456e+04\n",
      "Epoch 17390, Training-Loss 1.4301e+04, Data-loss 2.8557e+03                  , pde-loss 2.7898e+03, initc-loss 2.5784e+04                    bc_loss 1.1160e+06\n",
      "Epoch 17400, Training-Loss 2.9233e+03, Data-loss 1.5794e+03                  , pde-loss 2.7093e+03, initc-loss 1.2604e+04                    bc_loss 1.1907e+05\n",
      "Epoch 17410, Training-Loss 1.8179e+03, Data-loss 7.0730e+02                  , pde-loss 9.8708e+02, initc-loss 1.3981e+04                    bc_loss 9.6092e+04\n",
      "Epoch 17420, Training-Loss 2.0112e+03, Data-loss 1.3829e+03                  , pde-loss 1.7909e+03, initc-loss 1.4058e+04                    bc_loss 4.6984e+04\n",
      "Epoch 17430, Training-Loss 1.7994e+03, Data-loss 1.2814e+03                  , pde-loss 1.6465e+03, initc-loss 1.3785e+04                    bc_loss 3.6359e+04\n",
      "Epoch 17440, Training-Loss 5.4922e+03, Data-loss 9.6449e+02                  , pde-loss 1.0258e+03, initc-loss 1.5018e+04                    bc_loss 4.3673e+05\n",
      "Epoch 17450, Training-Loss 3.3688e+03, Data-loss 2.0245e+03                  , pde-loss 3.8668e+02, initc-loss 1.1728e+04                    bc_loss 1.2232e+05\n",
      "Epoch 17460, Training-Loss 2.5646e+03, Data-loss 1.8080e+03                  , pde-loss 1.4661e+03, initc-loss 1.3659e+04                    bc_loss 6.0532e+04\n",
      "Epoch 17470, Training-Loss 2.8674e+03, Data-loss 1.1143e+03                  , pde-loss 2.4909e+03, initc-loss 1.4243e+04                    bc_loss 1.5858e+05\n",
      "Epoch 17480, Training-Loss 1.3591e+03, Data-loss 1.0165e+03                  , pde-loss 1.3360e+03, initc-loss 1.2093e+04                    bc_loss 2.0839e+04\n",
      "Epoch 17490, Training-Loss 1.2271e+03, Data-loss 8.4053e+02                  , pde-loss 1.0031e+03, initc-loss 1.1900e+04                    bc_loss 2.5758e+04\n",
      "Epoch 17500, Training-Loss 2.5891e+03, Data-loss 4.6855e+02                  , pde-loss 9.3886e+02, initc-loss 1.4285e+04                    bc_loss 1.9683e+05\n",
      "Epoch 17510, Training-Loss 6.5347e+03, Data-loss 2.5589e+03                  , pde-loss 3.6354e+02, initc-loss 2.2162e+04                    bc_loss 3.7506e+05\n",
      "Epoch 17520, Training-Loss 3.3969e+03, Data-loss 2.7123e+03                  , pde-loss 1.3399e+03, initc-loss 1.4121e+04                    bc_loss 5.2995e+04\n",
      "Epoch 17530, Training-Loss 1.3270e+03, Data-loss 7.8361e+02                  , pde-loss 1.6339e+03, initc-loss 1.4297e+04                    bc_loss 3.8404e+04\n",
      "Epoch 17540, Training-Loss 1.6344e+03, Data-loss 1.1259e+03                  , pde-loss 1.2603e+03, initc-loss 1.4295e+04                    bc_loss 3.5302e+04\n",
      "Epoch 17550, Training-Loss 2.8437e+03, Data-loss 2.2642e+03                  , pde-loss 1.2795e+03, initc-loss 1.4980e+04                    bc_loss 4.1690e+04\n",
      "Epoch 17560, Training-Loss 6.1165e+03, Data-loss 1.9989e+03                  , pde-loss 9.0232e+02, initc-loss 1.8180e+04                    bc_loss 3.9267e+05\n",
      "Epoch 17570, Training-Loss 2.4978e+03, Data-loss 2.0487e+03                  , pde-loss 2.2795e+03, initc-loss 1.8622e+04                    bc_loss 2.4007e+04\n",
      "Epoch 17580, Training-Loss 9.9554e+03, Data-loss 3.1751e+03                  , pde-loss 3.7630e+03, initc-loss 2.3231e+04                    bc_loss 6.5103e+05\n",
      "Epoch 17590, Training-Loss 3.1787e+03, Data-loss 2.0821e+03                  , pde-loss 1.7993e+03, initc-loss 1.5063e+04                    bc_loss 9.2793e+04\n",
      "Epoch 17600, Training-Loss 2.5088e+03, Data-loss 1.8189e+03                  , pde-loss 6.3180e+02, initc-loss 1.4677e+04                    bc_loss 5.3680e+04\n",
      "Epoch 17610, Training-Loss 2.3892e+03, Data-loss 1.7822e+03                  , pde-loss 1.6864e+03, initc-loss 1.3871e+04                    bc_loss 4.5142e+04\n",
      "Epoch 17620, Training-Loss 1.9584e+03, Data-loss 1.3728e+03                  , pde-loss 1.3785e+03, initc-loss 9.9149e+03                    bc_loss 4.7271e+04\n",
      "Epoch 17630, Training-Loss 2.0759e+03, Data-loss 1.5643e+03                  , pde-loss 1.3073e+03, initc-loss 1.1995e+04                    bc_loss 3.7856e+04\n",
      "Epoch 17640, Training-Loss 1.3222e+03, Data-loss 1.0206e+03                  , pde-loss 1.3703e+03, initc-loss 1.1501e+04                    bc_loss 1.7290e+04\n",
      "Epoch 17650, Training-Loss 1.0556e+04, Data-loss 7.8088e+02                  , pde-loss 1.1719e+03, initc-loss 1.2282e+04                    bc_loss 9.6401e+05\n",
      "Epoch 17660, Training-Loss 2.2827e+03, Data-loss 1.3126e+03                  , pde-loss 5.1794e+02, initc-loss 1.3787e+04                    bc_loss 8.2705e+04\n",
      "Epoch 17670, Training-Loss 1.8392e+03, Data-loss 1.3648e+03                  , pde-loss 9.5799e+02, initc-loss 1.3774e+04                    bc_loss 3.2700e+04\n",
      "Epoch 17680, Training-Loss 1.8963e+03, Data-loss 1.4876e+03                  , pde-loss 1.7109e+03, initc-loss 1.5863e+04                    bc_loss 2.3292e+04\n",
      "Epoch 17690, Training-Loss 2.1782e+03, Data-loss 1.1547e+03                  , pde-loss 1.3659e+03, initc-loss 1.4769e+04                    bc_loss 8.6214e+04\n",
      "Epoch 17700, Training-Loss 2.3308e+03, Data-loss 7.2067e+02                  , pde-loss 8.7412e+02, initc-loss 1.5075e+04                    bc_loss 1.4507e+05\n",
      "Epoch 17710, Training-Loss 1.7431e+03, Data-loss 1.3273e+03                  , pde-loss 1.8548e+03, initc-loss 1.4056e+04                    bc_loss 2.5672e+04\n",
      "Epoch 17720, Training-Loss 3.3107e+03, Data-loss 2.1380e+03                  , pde-loss 2.5917e+03, initc-loss 1.7593e+04                    bc_loss 9.7086e+04\n",
      "Epoch 17730, Training-Loss 2.6620e+03, Data-loss 1.6374e+03                  , pde-loss 1.7428e+03, initc-loss 1.2103e+04                    bc_loss 8.8622e+04\n",
      "Epoch 17740, Training-Loss 2.3385e+03, Data-loss 1.9292e+03                  , pde-loss 9.9561e+02, initc-loss 1.4328e+04                    bc_loss 2.5600e+04\n",
      "Epoch 17750, Training-Loss 1.4244e+03, Data-loss 7.9185e+02                  , pde-loss 9.3621e+02, initc-loss 1.5613e+04                    bc_loss 4.6708e+04\n",
      "Epoch 17760, Training-Loss 1.4282e+03, Data-loss 1.0398e+03                  , pde-loss 1.2762e+03, initc-loss 1.4032e+04                    bc_loss 2.3532e+04\n",
      "Epoch 17770, Training-Loss 7.5871e+02, Data-loss 4.5151e+02                  , pde-loss 1.5077e+03, initc-loss 1.2914e+04                    bc_loss 1.6299e+04\n",
      "Epoch 17780, Training-Loss 5.6677e+03, Data-loss 7.8641e+02                  , pde-loss 1.2018e+03, initc-loss 1.6423e+04                    bc_loss 4.7050e+05\n",
      "Epoch 17790, Training-Loss 5.8672e+03, Data-loss 3.5611e+03                  , pde-loss 2.6470e+02, initc-loss 1.8416e+04                    bc_loss 2.1193e+05\n",
      "Epoch 17800, Training-Loss 3.7093e+03, Data-loss 2.9053e+03                  , pde-loss 1.6170e+03, initc-loss 1.5346e+04                    bc_loss 6.3433e+04\n",
      "Epoch 17810, Training-Loss 1.9284e+03, Data-loss 1.0500e+03                  , pde-loss 1.7494e+03, initc-loss 1.7687e+04                    bc_loss 6.8405e+04\n",
      "Epoch 17820, Training-Loss 2.0796e+03, Data-loss 1.6118e+03                  , pde-loss 9.0880e+02, initc-loss 1.7402e+04                    bc_loss 2.8471e+04\n",
      "Epoch 17830, Training-Loss 1.7856e+03, Data-loss 1.2706e+03                  , pde-loss 1.1919e+03, initc-loss 1.5951e+04                    bc_loss 3.4353e+04\n",
      "Epoch 17840, Training-Loss 1.0908e+04, Data-loss 1.6937e+03                  , pde-loss 1.2617e+03, initc-loss 1.7499e+04                    bc_loss 9.0265e+05\n",
      "Epoch 17850, Training-Loss 4.0480e+03, Data-loss 2.3281e+03                  , pde-loss 1.0686e+03, initc-loss 1.0445e+04                    bc_loss 1.6047e+05\n",
      "Epoch 17860, Training-Loss 1.1758e+04, Data-loss 1.6600e+03                  , pde-loss 3.6250e+03, initc-loss 1.4734e+04                    bc_loss 9.9147e+05\n",
      "Epoch 17870, Training-Loss 9.1306e+03, Data-loss 5.6688e+03                  , pde-loss 5.4941e+03, initc-loss 9.6138e+03                    bc_loss 3.3107e+05\n",
      "Epoch 17880, Training-Loss 4.4458e+03, Data-loss 2.5204e+03                  , pde-loss 1.6588e+03, initc-loss 1.1026e+04                    bc_loss 1.7985e+05\n",
      "Epoch 17890, Training-Loss 3.0751e+03, Data-loss 2.0761e+03                  , pde-loss 7.4279e+02, initc-loss 1.7583e+04                    bc_loss 8.1580e+04\n",
      "Epoch 17900, Training-Loss 2.0065e+03, Data-loss 1.3283e+03                  , pde-loss 1.0636e+03, initc-loss 1.6309e+04                    bc_loss 5.0452e+04\n",
      "Epoch 17910, Training-Loss 1.8085e+03, Data-loss 1.4667e+03                  , pde-loss 1.3360e+03, initc-loss 1.6376e+04                    bc_loss 1.6470e+04\n",
      "Epoch 17920, Training-Loss 1.9710e+03, Data-loss 1.3300e+03                  , pde-loss 1.2963e+03, initc-loss 1.3426e+04                    bc_loss 4.9382e+04\n",
      "Epoch 17930, Training-Loss 7.2207e+03, Data-loss 1.1490e+03                  , pde-loss 1.2329e+03, initc-loss 1.5164e+04                    bc_loss 5.9077e+05\n",
      "Epoch 17940, Training-Loss 2.6809e+03, Data-loss 1.9104e+03                  , pde-loss 1.2203e+03, initc-loss 1.1985e+04                    bc_loss 6.3850e+04\n",
      "Epoch 17950, Training-Loss 1.2203e+03, Data-loss 7.8757e+02                  , pde-loss 1.6871e+03, initc-loss 1.3709e+04                    bc_loss 2.7881e+04\n",
      "Epoch 17960, Training-Loss 2.2350e+03, Data-loss 1.3847e+03                  , pde-loss 1.5890e+03, initc-loss 1.4799e+04                    bc_loss 6.8641e+04\n",
      "Epoch 17970, Training-Loss 1.5085e+03, Data-loss 7.9832e+02                  , pde-loss 1.3476e+03, initc-loss 1.1467e+04                    bc_loss 5.8201e+04\n",
      "Epoch 17980, Training-Loss 1.3238e+03, Data-loss 9.9333e+02                  , pde-loss 1.3117e+03, initc-loss 1.2182e+04                    bc_loss 1.9553e+04\n",
      "Epoch 17990, Training-Loss 1.0554e+03, Data-loss 7.6159e+02                  , pde-loss 1.2428e+03, initc-loss 1.2868e+04                    bc_loss 1.5266e+04\n",
      "Epoch 18000, Training-Loss 1.4615e+03, Data-loss 4.2998e+02                  , pde-loss 1.1441e+03, initc-loss 1.5434e+04                    bc_loss 8.6578e+04\n",
      "Epoch 18010, Training-Loss 1.4197e+04, Data-loss 4.5152e+03                  , pde-loss 4.0355e+02, initc-loss 2.4453e+04                    bc_loss 9.4333e+05\n",
      "Epoch 18020, Training-Loss 3.8896e+03, Data-loss 2.0710e+03                  , pde-loss 4.1953e+02, initc-loss 1.8360e+04                    bc_loss 1.6308e+05\n",
      "Epoch 18030, Training-Loss 2.9969e+03, Data-loss 2.2979e+03                  , pde-loss 2.0801e+03, initc-loss 1.8009e+04                    bc_loss 4.9802e+04\n",
      "Epoch 18040, Training-Loss 2.8271e+03, Data-loss 2.3456e+03                  , pde-loss 1.6278e+03, initc-loss 1.7540e+04                    bc_loss 2.8984e+04\n",
      "Epoch 18050, Training-Loss 2.4042e+03, Data-loss 1.9772e+03                  , pde-loss 1.2211e+03, initc-loss 1.5925e+04                    bc_loss 2.5547e+04\n",
      "Epoch 18060, Training-Loss 2.3835e+03, Data-loss 1.9893e+03                  , pde-loss 1.5568e+03, initc-loss 1.3103e+04                    bc_loss 2.4759e+04\n",
      "Epoch 18070, Training-Loss 8.4564e+03, Data-loss 1.9890e+03                  , pde-loss 1.0266e+03, initc-loss 1.8808e+04                    bc_loss 6.2691e+05\n",
      "Epoch 18080, Training-Loss 8.3757e+03, Data-loss 4.7751e+03                  , pde-loss 4.3848e+02, initc-loss 1.3544e+04                    bc_loss 3.4607e+05\n",
      "Epoch 18090, Training-Loss 4.4165e+03, Data-loss 2.4455e+03                  , pde-loss 2.3572e+03, initc-loss 1.2977e+04                    bc_loss 1.8177e+05\n",
      "Epoch 18100, Training-Loss 1.2135e+04, Data-loss 4.9526e+03                  , pde-loss 6.8079e+03, initc-loss 2.3957e+04                    bc_loss 6.8743e+05\n",
      "Epoch 18110, Training-Loss 4.7987e+03, Data-loss 2.2238e+03                  , pde-loss 3.0736e+03, initc-loss 1.3455e+04                    bc_loss 2.4096e+05\n",
      "Epoch 18120, Training-Loss 2.5706e+03, Data-loss 2.2143e+03                  , pde-loss 7.4151e+02, initc-loss 1.3978e+04                    bc_loss 2.0910e+04\n",
      "Epoch 18130, Training-Loss 3.3723e+03, Data-loss 2.5818e+03                  , pde-loss 6.9017e+02, initc-loss 1.9596e+04                    bc_loss 5.8765e+04\n",
      "Epoch 18140, Training-Loss 2.2027e+03, Data-loss 1.1258e+03                  , pde-loss 1.0712e+03, initc-loss 1.4162e+04                    bc_loss 9.2453e+04\n",
      "Epoch 18150, Training-Loss 2.2579e+03, Data-loss 1.7970e+03                  , pde-loss 1.9422e+03, initc-loss 1.4811e+04                    bc_loss 2.9342e+04\n",
      "Epoch 18160, Training-Loss 1.0452e+03, Data-loss 6.3817e+02                  , pde-loss 1.2845e+03, initc-loss 1.6490e+04                    bc_loss 2.2931e+04\n",
      "Epoch 18170, Training-Loss 1.8728e+03, Data-loss 1.3019e+03                  , pde-loss 1.1106e+03, initc-loss 1.5250e+04                    bc_loss 4.0731e+04\n",
      "Epoch 18180, Training-Loss 9.9542e+02, Data-loss 6.7040e+02                  , pde-loss 1.3748e+03, initc-loss 1.2844e+04                    bc_loss 1.8283e+04\n",
      "Epoch 18190, Training-Loss 1.3309e+03, Data-loss 5.4738e+02                  , pde-loss 1.5737e+03, initc-loss 1.3612e+04                    bc_loss 6.3163e+04\n",
      "Epoch 18200, Training-Loss 2.4329e+03, Data-loss 5.2993e+02                  , pde-loss 1.3151e+03, initc-loss 1.3767e+04                    bc_loss 1.7522e+05\n",
      "Epoch 18210, Training-Loss 5.8615e+03, Data-loss 1.0160e+03                  , pde-loss 6.5671e+02, initc-loss 1.8536e+04                    bc_loss 4.6535e+05\n",
      "Epoch 18220, Training-Loss 4.1417e+03, Data-loss 2.3837e+03                  , pde-loss 5.5359e+02, initc-loss 1.3348e+04                    bc_loss 1.6190e+05\n",
      "Epoch 18230, Training-Loss 1.2416e+03, Data-loss 7.8995e+02                  , pde-loss 1.5212e+03, initc-loss 9.7991e+03                    bc_loss 3.3840e+04\n",
      "Epoch 18240, Training-Loss 1.1209e+03, Data-loss 8.0393e+02                  , pde-loss 2.0011e+03, initc-loss 1.4887e+04                    bc_loss 1.4806e+04\n",
      "Epoch 18250, Training-Loss 2.5371e+03, Data-loss 9.5787e+02                  , pde-loss 1.4845e+03, initc-loss 1.2631e+04                    bc_loss 1.4381e+05\n",
      "Epoch 18260, Training-Loss 1.2841e+03, Data-loss 9.6523e+02                  , pde-loss 1.3229e+03, initc-loss 1.3391e+04                    bc_loss 1.7170e+04\n",
      "Epoch 18270, Training-Loss 1.5070e+03, Data-loss 1.2161e+03                  , pde-loss 1.2796e+03, initc-loss 1.2620e+04                    bc_loss 1.5191e+04\n",
      "Epoch 18280, Training-Loss 1.5304e+04, Data-loss 4.2342e+03                  , pde-loss 9.1008e+02, initc-loss 2.6022e+04                    bc_loss 1.0801e+06\n",
      "Epoch 18290, Training-Loss 4.8460e+03, Data-loss 1.8035e+03                  , pde-loss 5.9627e+02, initc-loss 9.8307e+03                    bc_loss 2.9383e+05\n",
      "Epoch 18300, Training-Loss 2.6617e+03, Data-loss 2.0259e+03                  , pde-loss 2.1104e+03, initc-loss 1.7178e+04                    bc_loss 4.4299e+04\n",
      "Epoch 18310, Training-Loss 1.3027e+03, Data-loss 8.0961e+02                  , pde-loss 1.5529e+03, initc-loss 1.5571e+04                    bc_loss 3.2186e+04\n",
      "Epoch 18320, Training-Loss 1.8484e+03, Data-loss 1.2415e+03                  , pde-loss 1.4959e+03, initc-loss 1.3663e+04                    bc_loss 4.5529e+04\n",
      "Epoch 18330, Training-Loss 6.1008e+03, Data-loss 1.9719e+03                  , pde-loss 2.0862e+03, initc-loss 1.7276e+04                    bc_loss 3.9353e+05\n",
      "Epoch 18340, Training-Loss 1.8150e+03, Data-loss 1.5029e+03                  , pde-loss 2.4937e+03, initc-loss 1.0976e+04                    bc_loss 1.7741e+04\n",
      "Epoch 18350, Training-Loss 2.2591e+03, Data-loss 1.5699e+03                  , pde-loss 2.0131e+03, initc-loss 1.6214e+04                    bc_loss 5.0690e+04\n",
      "Epoch 18360, Training-Loss 1.8044e+03, Data-loss 1.0228e+03                  , pde-loss 1.3241e+03, initc-loss 1.5732e+04                    bc_loss 6.1106e+04\n",
      "Epoch 18370, Training-Loss 2.4087e+03, Data-loss 9.9677e+02                  , pde-loss 1.1234e+03, initc-loss 1.3273e+04                    bc_loss 1.2679e+05\n",
      "Epoch 18380, Training-Loss 2.7818e+03, Data-loss 2.1965e+03                  , pde-loss 4.8475e+02, initc-loss 1.4989e+04                    bc_loss 4.3057e+04\n",
      "Epoch 18390, Training-Loss 9.3423e+03, Data-loss 3.4571e+03                  , pde-loss 3.0015e+02, initc-loss 2.1978e+04                    bc_loss 5.6625e+05\n",
      "Epoch 18400, Training-Loss 2.4771e+03, Data-loss 1.7054e+03                  , pde-loss 9.3598e+02, initc-loss 1.5296e+04                    bc_loss 6.0938e+04\n",
      "Epoch 18410, Training-Loss 2.8870e+03, Data-loss 2.1353e+03                  , pde-loss 1.7692e+03, initc-loss 1.3929e+04                    bc_loss 5.9467e+04\n",
      "Epoch 18420, Training-Loss 3.6514e+03, Data-loss 2.8892e+03                  , pde-loss 1.5946e+03, initc-loss 1.4681e+04                    bc_loss 5.9946e+04\n",
      "Epoch 18430, Training-Loss 3.4719e+03, Data-loss 2.9161e+03                  , pde-loss 1.4974e+03, initc-loss 1.3936e+04                    bc_loss 4.0150e+04\n",
      "Epoch 18440, Training-Loss 1.9133e+03, Data-loss 1.1101e+03                  , pde-loss 1.7481e+03, initc-loss 1.4519e+04                    bc_loss 6.4051e+04\n",
      "Epoch 18450, Training-Loss 4.3563e+03, Data-loss 1.6365e+03                  , pde-loss 1.1150e+03, initc-loss 1.4149e+04                    bc_loss 2.5671e+05\n",
      "Epoch 18460, Training-Loss 8.7580e+03, Data-loss 1.3668e+03                  , pde-loss 2.9181e+03, initc-loss 1.6684e+04                    bc_loss 7.1952e+05\n",
      "Epoch 18470, Training-Loss 5.2594e+03, Data-loss 2.5899e+03                  , pde-loss 3.5519e+03, initc-loss 1.2200e+04                    bc_loss 2.5120e+05\n",
      "Epoch 18480, Training-Loss 2.3841e+03, Data-loss 1.9393e+03                  , pde-loss 1.0937e+03, initc-loss 1.4499e+04                    bc_loss 2.8892e+04\n",
      "Epoch 18490, Training-Loss 1.6136e+03, Data-loss 1.0801e+03                  , pde-loss 1.0245e+03, initc-loss 1.5370e+04                    bc_loss 3.6959e+04\n",
      "Epoch 18500, Training-Loss 2.5973e+03, Data-loss 1.8767e+03                  , pde-loss 2.2454e+03, initc-loss 1.3971e+04                    bc_loss 5.5841e+04\n",
      "Epoch 18510, Training-Loss 1.1982e+03, Data-loss 7.2236e+02                  , pde-loss 1.5293e+03, initc-loss 1.2249e+04                    bc_loss 3.3800e+04\n",
      "Epoch 18520, Training-Loss 1.3430e+03, Data-loss 8.4678e+02                  , pde-loss 1.3938e+03, initc-loss 1.4649e+04                    bc_loss 3.3576e+04\n",
      "Epoch 18530, Training-Loss 2.8180e+03, Data-loss 5.7881e+02                  , pde-loss 1.3439e+03, initc-loss 1.4898e+04                    bc_loss 2.0768e+05\n",
      "Epoch 18540, Training-Loss 1.5839e+03, Data-loss 1.1607e+03                  , pde-loss 1.3322e+03, initc-loss 1.4555e+04                    bc_loss 2.6431e+04\n",
      "Epoch 18550, Training-Loss 1.2821e+03, Data-loss 9.0170e+02                  , pde-loss 1.2283e+03, initc-loss 1.1645e+04                    bc_loss 2.5168e+04\n",
      "Epoch 18560, Training-Loss 9.4220e+03, Data-loss 1.5876e+03                  , pde-loss 1.0019e+03, initc-loss 1.7107e+04                    bc_loss 7.6533e+05\n",
      "Epoch 18570, Training-Loss 2.6532e+03, Data-loss 1.7462e+03                  , pde-loss 8.5780e+02, initc-loss 7.0344e+03                    bc_loss 8.2804e+04\n",
      "Epoch 18580, Training-Loss 2.1632e+03, Data-loss 1.4030e+03                  , pde-loss 1.7156e+03, initc-loss 1.0401e+04                    bc_loss 6.3904e+04\n",
      "Epoch 18590, Training-Loss 1.5721e+03, Data-loss 9.4847e+02                  , pde-loss 1.7576e+03, initc-loss 1.4921e+04                    bc_loss 4.5687e+04\n",
      "Epoch 18600, Training-Loss 7.0498e+02, Data-loss 3.8712e+02                  , pde-loss 1.3101e+03, initc-loss 1.3484e+04                    bc_loss 1.6991e+04\n",
      "Epoch 18610, Training-Loss 1.7989e+03, Data-loss 9.6058e+02                  , pde-loss 1.2723e+03, initc-loss 1.2927e+04                    bc_loss 6.9628e+04\n",
      "Epoch 18620, Training-Loss 5.7413e+02, Data-loss 2.4694e+02                  , pde-loss 1.2735e+03, initc-loss 1.2400e+04                    bc_loss 1.9046e+04\n",
      "Epoch 18630, Training-Loss 7.5530e+03, Data-loss 1.7077e+03                  , pde-loss 1.6428e+03, initc-loss 2.0438e+04                    bc_loss 5.6245e+05\n",
      "Epoch 18640, Training-Loss 1.3277e+03, Data-loss 8.1035e+02                  , pde-loss 1.6883e+03, initc-loss 1.6223e+04                    bc_loss 3.3829e+04\n",
      "Epoch 18650, Training-Loss 1.6672e+03, Data-loss 1.2859e+03                  , pde-loss 1.4439e+03, initc-loss 1.3291e+04                    bc_loss 2.3400e+04\n",
      "Epoch 18660, Training-Loss 1.5390e+03, Data-loss 5.4156e+02                  , pde-loss 1.1839e+03, initc-loss 1.5249e+04                    bc_loss 8.3308e+04\n",
      "Epoch 18670, Training-Loss 6.1798e+03, Data-loss 1.2243e+03                  , pde-loss 4.7048e+02, initc-loss 1.7842e+04                    bc_loss 4.7724e+05\n",
      "Epoch 18680, Training-Loss 3.5147e+03, Data-loss 2.6761e+03                  , pde-loss 5.3616e+02, initc-loss 1.1771e+04                    bc_loss 7.1550e+04\n",
      "Epoch 18690, Training-Loss 2.7088e+03, Data-loss 1.8275e+03                  , pde-loss 1.3333e+03, initc-loss 1.1564e+04                    bc_loss 7.5226e+04\n",
      "Epoch 18700, Training-Loss 1.4257e+03, Data-loss 9.1222e+02                  , pde-loss 9.0624e+02, initc-loss 1.5169e+04                    bc_loss 3.5268e+04\n",
      "Epoch 18710, Training-Loss 6.4140e+03, Data-loss 1.9985e+03                  , pde-loss 8.2642e+02, initc-loss 1.7709e+04                    bc_loss 4.2302e+05\n",
      "Epoch 18720, Training-Loss 3.4894e+03, Data-loss 3.0766e+03                  , pde-loss 2.5283e+03, initc-loss 1.6550e+04                    bc_loss 2.2204e+04\n",
      "Epoch 18730, Training-Loss 1.5508e+03, Data-loss 1.0651e+03                  , pde-loss 2.3104e+03, initc-loss 1.6540e+04                    bc_loss 2.9719e+04\n",
      "Epoch 18740, Training-Loss 1.5679e+03, Data-loss 1.2729e+03                  , pde-loss 1.1285e+03, initc-loss 1.5203e+04                    bc_loss 1.3171e+04\n",
      "Epoch 18750, Training-Loss 1.0858e+03, Data-loss 5.8729e+02                  , pde-loss 1.2319e+03, initc-loss 1.3000e+04                    bc_loss 3.5617e+04\n",
      "Epoch 18760, Training-Loss 6.2487e+03, Data-loss 1.9251e+03                  , pde-loss 1.9925e+03, initc-loss 1.9768e+04                    bc_loss 4.1060e+05\n",
      "Epoch 18770, Training-Loss 1.9784e+03, Data-loss 1.4852e+03                  , pde-loss 1.3319e+03, initc-loss 1.5870e+04                    bc_loss 3.2124e+04\n",
      "Epoch 18780, Training-Loss 1.3305e+03, Data-loss 9.6574e+02                  , pde-loss 1.1730e+03, initc-loss 1.3771e+04                    bc_loss 2.1536e+04\n",
      "Epoch 18790, Training-Loss 9.2629e+02, Data-loss 4.7298e+02                  , pde-loss 1.1938e+03, initc-loss 1.4626e+04                    bc_loss 2.9511e+04\n",
      "Epoch 18800, Training-Loss 6.5358e+03, Data-loss 6.0838e+02                  , pde-loss 1.2063e+03, initc-loss 1.2469e+04                    bc_loss 5.7907e+05\n",
      "Epoch 18810, Training-Loss 2.4195e+03, Data-loss 1.2369e+03                  , pde-loss 6.9509e+02, initc-loss 1.3333e+04                    bc_loss 1.0423e+05\n",
      "Epoch 18820, Training-Loss 1.6538e+03, Data-loss 1.0369e+03                  , pde-loss 1.4762e+03, initc-loss 1.3667e+04                    bc_loss 4.6544e+04\n",
      "Epoch 18830, Training-Loss 1.0928e+03, Data-loss 7.8315e+02                  , pde-loss 1.5915e+03, initc-loss 1.4320e+04                    bc_loss 1.5049e+04\n",
      "Epoch 18840, Training-Loss 7.3397e+02, Data-loss 4.7415e+02                  , pde-loss 1.4435e+03, initc-loss 1.3973e+04                    bc_loss 1.0565e+04\n",
      "Epoch 18850, Training-Loss 2.4809e+03, Data-loss 9.4025e+02                  , pde-loss 1.1498e+03, initc-loss 1.4401e+04                    bc_loss 1.3851e+05\n",
      "Epoch 18860, Training-Loss 5.4742e+03, Data-loss 2.5984e+03                  , pde-loss 6.9263e+02, initc-loss 1.7996e+04                    bc_loss 2.6889e+05\n",
      "Epoch 18870, Training-Loss 1.9480e+03, Data-loss 1.2157e+03                  , pde-loss 1.1071e+03, initc-loss 1.1857e+04                    bc_loss 6.0266e+04\n",
      "Epoch 18880, Training-Loss 1.4198e+03, Data-loss 1.1282e+03                  , pde-loss 2.2722e+03, initc-loss 1.2172e+04                    bc_loss 1.4719e+04\n",
      "Epoch 18890, Training-Loss 2.2526e+03, Data-loss 7.5090e+02                  , pde-loss 1.5162e+03, initc-loss 1.3495e+04                    bc_loss 1.3516e+05\n",
      "Epoch 18900, Training-Loss 1.3196e+03, Data-loss 8.5174e+02                  , pde-loss 1.3365e+03, initc-loss 1.2561e+04                    bc_loss 3.2890e+04\n",
      "Epoch 18910, Training-Loss 1.4598e+04, Data-loss 1.8993e+03                  , pde-loss 2.2479e+03, initc-loss 1.9902e+04                    bc_loss 1.2477e+06\n",
      "Epoch 18920, Training-Loss 2.7336e+03, Data-loss 1.9582e+03                  , pde-loss 1.9127e+03, initc-loss 8.5568e+03                    bc_loss 6.7075e+04\n",
      "Epoch 18930, Training-Loss 1.4313e+03, Data-loss 9.5602e+02                  , pde-loss 1.2129e+03, initc-loss 9.7887e+03                    bc_loss 3.6528e+04\n",
      "Epoch 18940, Training-Loss 1.7671e+03, Data-loss 6.7299e+02                  , pde-loss 9.6577e+02, initc-loss 1.2775e+04                    bc_loss 9.5668e+04\n",
      "Epoch 18950, Training-Loss 9.4997e+03, Data-loss 1.9694e+03                  , pde-loss 7.7507e+02, initc-loss 1.7617e+04                    bc_loss 7.3464e+05\n",
      "Epoch 18960, Training-Loss 4.6170e+03, Data-loss 1.9936e+03                  , pde-loss 5.8807e+02, initc-loss 1.5804e+04                    bc_loss 2.4595e+05\n",
      "Epoch 18970, Training-Loss 1.7993e+03, Data-loss 1.1874e+03                  , pde-loss 1.8306e+03, initc-loss 1.2390e+04                    bc_loss 4.6975e+04\n",
      "Epoch 18980, Training-Loss 1.6779e+03, Data-loss 1.2878e+03                  , pde-loss 2.0541e+03, initc-loss 1.2719e+04                    bc_loss 2.4240e+04\n",
      "Epoch 18990, Training-Loss 2.1913e+03, Data-loss 1.7964e+03                  , pde-loss 1.4471e+03, initc-loss 1.0948e+04                    bc_loss 2.7093e+04\n",
      "Epoch 19000, Training-Loss 1.3999e+03, Data-loss 1.1527e+03                  , pde-loss 1.5024e+03, initc-loss 1.2554e+04                    bc_loss 1.0668e+04\n",
      "Epoch 19010, Training-Loss 1.5652e+03, Data-loss 1.3004e+03                  , pde-loss 1.8105e+03, initc-loss 1.2164e+04                    bc_loss 1.2508e+04\n",
      "Epoch 19020, Training-Loss 8.6010e+02, Data-loss 5.7686e+02                  , pde-loss 1.5119e+03, initc-loss 1.2922e+04                    bc_loss 1.3890e+04\n",
      "Epoch 19030, Training-Loss 7.2009e+02, Data-loss 4.1751e+02                  , pde-loss 1.1778e+03, initc-loss 1.3209e+04                    bc_loss 1.5871e+04\n",
      "Epoch 19040, Training-Loss 9.6268e+03, Data-loss 1.1945e+03                  , pde-loss 1.5998e+03, initc-loss 1.7129e+04                    bc_loss 8.2450e+05\n",
      "Epoch 19050, Training-Loss 5.7850e+03, Data-loss 2.1255e+03                  , pde-loss 2.8062e+03, initc-loss 1.0691e+04                    bc_loss 3.5245e+05\n",
      "Epoch 19060, Training-Loss 2.4317e+03, Data-loss 1.0833e+03                  , pde-loss 9.3661e+02, initc-loss 1.4854e+04                    bc_loss 1.1905e+05\n",
      "Epoch 19070, Training-Loss 3.5135e+03, Data-loss 1.6682e+03                  , pde-loss 7.7928e+02, initc-loss 1.6310e+04                    bc_loss 1.6745e+05\n",
      "Epoch 19080, Training-Loss 2.4227e+03, Data-loss 8.8432e+02                  , pde-loss 1.3038e+03, initc-loss 9.2629e+03                    bc_loss 1.4327e+05\n",
      "Epoch 19090, Training-Loss 8.6129e+03, Data-loss 1.3464e+03                  , pde-loss 6.2128e+02, initc-loss 1.7382e+04                    bc_loss 7.0865e+05\n",
      "Epoch 19100, Training-Loss 2.2444e+03, Data-loss 1.7291e+03                  , pde-loss 9.3568e+02, initc-loss 1.3963e+04                    bc_loss 3.6628e+04\n",
      "Epoch 19110, Training-Loss 1.6737e+03, Data-loss 1.2760e+03                  , pde-loss 1.9631e+03, initc-loss 1.1874e+04                    bc_loss 2.5928e+04\n",
      "Epoch 19120, Training-Loss 1.3833e+03, Data-loss 6.1072e+02                  , pde-loss 1.4479e+03, initc-loss 1.2617e+04                    bc_loss 6.3196e+04\n",
      "Epoch 19130, Training-Loss 1.3926e+03, Data-loss 9.0618e+02                  , pde-loss 1.3430e+03, initc-loss 1.1482e+04                    bc_loss 3.5815e+04\n",
      "Epoch 19140, Training-Loss 1.4548e+03, Data-loss 9.6493e+02                  , pde-loss 1.6536e+03, initc-loss 1.3341e+04                    bc_loss 3.3991e+04\n",
      "Epoch 19150, Training-Loss 1.0712e+03, Data-loss 7.4959e+02                  , pde-loss 1.5163e+03, initc-loss 1.4097e+04                    bc_loss 1.6549e+04\n",
      "Epoch 19160, Training-Loss 1.6129e+03, Data-loss 1.1659e+03                  , pde-loss 1.2475e+03, initc-loss 1.5508e+04                    bc_loss 2.7940e+04\n",
      "Epoch 19170, Training-Loss 9.3439e+02, Data-loss 4.0528e+02                  , pde-loss 1.3431e+03, initc-loss 1.6666e+04                    bc_loss 3.4902e+04\n",
      "Epoch 19180, Training-Loss 1.2071e+03, Data-loss 9.0944e+02                  , pde-loss 1.4633e+03, initc-loss 1.4109e+04                    bc_loss 1.4191e+04\n",
      "Epoch 19190, Training-Loss 1.1416e+03, Data-loss 7.0377e+02                  , pde-loss 1.1733e+03, initc-loss 1.4387e+04                    bc_loss 2.8222e+04\n",
      "Epoch 19200, Training-Loss 4.1101e+03, Data-loss 1.8719e+03                  , pde-loss 3.4175e+02, initc-loss 1.5985e+04                    bc_loss 2.0749e+05\n",
      "Epoch 19210, Training-Loss 1.9587e+03, Data-loss 1.4185e+03                  , pde-loss 9.9456e+02, initc-loss 1.6017e+04                    bc_loss 3.7001e+04\n",
      "Epoch 19220, Training-Loss 2.2940e+03, Data-loss 1.9411e+03                  , pde-loss 1.4584e+03, initc-loss 1.5757e+04                    bc_loss 1.8073e+04\n",
      "Epoch 19230, Training-Loss 1.6089e+03, Data-loss 1.1798e+03                  , pde-loss 1.5361e+03, initc-loss 1.5164e+04                    bc_loss 2.6209e+04\n",
      "Epoch 19240, Training-Loss 1.3622e+03, Data-loss 9.8303e+02                  , pde-loss 1.7616e+03, initc-loss 1.4434e+04                    bc_loss 2.1719e+04\n",
      "Epoch 19250, Training-Loss 6.8597e+03, Data-loss 1.4835e+03                  , pde-loss 2.0376e+03, initc-loss 1.7942e+04                    bc_loss 5.1764e+05\n",
      "Epoch 19260, Training-Loss 3.3887e+03, Data-loss 2.0155e+03                  , pde-loss 2.3608e+03, initc-loss 1.0558e+04                    bc_loss 1.2440e+05\n",
      "Epoch 19270, Training-Loss 2.8331e+03, Data-loss 1.4929e+03                  , pde-loss 1.4859e+03, initc-loss 7.7412e+03                    bc_loss 1.2479e+05\n",
      "Epoch 19280, Training-Loss 2.0002e+03, Data-loss 1.5005e+03                  , pde-loss 6.4492e+02, initc-loss 1.3111e+04                    bc_loss 3.6206e+04\n",
      "Epoch 19290, Training-Loss 5.5469e+03, Data-loss 4.4615e+02                  , pde-loss 1.2959e+03, initc-loss 1.2720e+04                    bc_loss 4.9606e+05\n",
      "Epoch 19300, Training-Loss 1.8645e+03, Data-loss 6.4422e+02                  , pde-loss 1.3897e+03, initc-loss 1.3017e+04                    bc_loss 1.0762e+05\n",
      "Epoch 19310, Training-Loss 6.7991e+03, Data-loss 2.1318e+03                  , pde-loss 4.0052e+02, initc-loss 1.8242e+04                    bc_loss 4.4809e+05\n",
      "Epoch 19320, Training-Loss 2.0135e+03, Data-loss 1.0678e+03                  , pde-loss 1.0548e+03, initc-loss 1.3107e+04                    bc_loss 8.0408e+04\n",
      "Epoch 19330, Training-Loss 1.3693e+03, Data-loss 1.0158e+03                  , pde-loss 1.7584e+03, initc-loss 1.2211e+04                    bc_loss 2.1380e+04\n",
      "Epoch 19340, Training-Loss 1.4489e+03, Data-loss 9.6142e+02                  , pde-loss 1.4582e+03, initc-loss 1.3289e+04                    bc_loss 3.3998e+04\n",
      "Epoch 19350, Training-Loss 1.0498e+03, Data-loss 6.9587e+02                  , pde-loss 1.7285e+03, initc-loss 1.1866e+04                    bc_loss 2.1795e+04\n",
      "Epoch 19360, Training-Loss 1.2862e+03, Data-loss 9.7319e+02                  , pde-loss 1.7163e+03, initc-loss 1.2067e+04                    bc_loss 1.7517e+04\n",
      "Epoch 19370, Training-Loss 8.6018e+02, Data-loss 4.9843e+02                  , pde-loss 1.1316e+03, initc-loss 1.2998e+04                    bc_loss 2.2046e+04\n",
      "Epoch 19380, Training-Loss 1.1340e+03, Data-loss 8.9788e+02                  , pde-loss 1.2173e+03, initc-loss 1.2677e+04                    bc_loss 9.7147e+03\n",
      "Epoch 19390, Training-Loss 5.2062e+02, Data-loss 3.3243e+02                  , pde-loss 1.1279e+03, initc-loss 1.2580e+04                    bc_loss 5.1103e+03\n",
      "Epoch 19400, Training-Loss 9.8248e+03, Data-loss 4.3883e+02                  , pde-loss 1.0124e+03, initc-loss 1.4972e+04                    bc_loss 9.2261e+05\n",
      "Epoch 19410, Training-Loss 2.9782e+03, Data-loss 1.8032e+03                  , pde-loss 6.8606e+02, initc-loss 9.5361e+03                    bc_loss 1.0728e+05\n",
      "Epoch 19420, Training-Loss 1.9621e+03, Data-loss 1.3051e+03                  , pde-loss 1.5942e+03, initc-loss 1.1553e+04                    bc_loss 5.2553e+04\n",
      "Epoch 19430, Training-Loss 1.4978e+03, Data-loss 1.0198e+03                  , pde-loss 1.3482e+03, initc-loss 1.3374e+04                    bc_loss 3.3074e+04\n",
      "Epoch 19440, Training-Loss 1.5405e+03, Data-loss 1.1996e+03                  , pde-loss 1.3944e+03, initc-loss 1.2976e+04                    bc_loss 1.9713e+04\n",
      "Epoch 19450, Training-Loss 1.3678e+03, Data-loss 1.0375e+03                  , pde-loss 1.6239e+03, initc-loss 1.3020e+04                    bc_loss 1.8380e+04\n",
      "Epoch 19460, Training-Loss 1.2726e+03, Data-loss 8.8149e+02                  , pde-loss 1.5272e+03, initc-loss 1.2974e+04                    bc_loss 2.4606e+04\n",
      "Epoch 19470, Training-Loss 1.6233e+04, Data-loss 4.9098e+03                  , pde-loss 2.8386e+03, initc-loss 3.0985e+04                    bc_loss 1.0985e+06\n",
      "Epoch 19480, Training-Loss 3.7328e+03, Data-loss 2.4473e+03                  , pde-loss 3.4095e+03, initc-loss 1.3797e+04                    bc_loss 1.1134e+05\n",
      "Epoch 19490, Training-Loss 2.3599e+03, Data-loss 1.7322e+03                  , pde-loss 1.1344e+03, initc-loss 1.4480e+04                    bc_loss 4.7160e+04\n",
      "Epoch 19500, Training-Loss 1.9765e+03, Data-loss 1.1032e+03                  , pde-loss 1.1130e+03, initc-loss 1.4750e+04                    bc_loss 7.1465e+04\n",
      "Epoch 19510, Training-Loss 1.4520e+03, Data-loss 9.0264e+02                  , pde-loss 1.5156e+03, initc-loss 1.2335e+04                    bc_loss 4.1081e+04\n",
      "Epoch 19520, Training-Loss 1.3183e+03, Data-loss 8.0146e+02                  , pde-loss 1.7434e+03, initc-loss 1.2517e+04                    bc_loss 3.7425e+04\n",
      "Epoch 19530, Training-Loss 1.5551e+03, Data-loss 6.5777e+02                  , pde-loss 1.2854e+03, initc-loss 1.3097e+04                    bc_loss 7.5353e+04\n",
      "Epoch 19540, Training-Loss 1.2410e+04, Data-loss 3.0074e+03                  , pde-loss 5.3534e+02, initc-loss 2.3068e+04                    bc_loss 9.1664e+05\n",
      "Epoch 19550, Training-Loss 3.4193e+03, Data-loss 2.0926e+03                  , pde-loss 6.2789e+02, initc-loss 1.4709e+04                    bc_loss 1.1734e+05\n",
      "Epoch 19560, Training-Loss 1.9574e+03, Data-loss 1.4041e+03                  , pde-loss 2.0272e+03, initc-loss 1.4926e+04                    bc_loss 3.8382e+04\n",
      "Epoch 19570, Training-Loss 1.4283e+03, Data-loss 1.0226e+03                  , pde-loss 1.0742e+03, initc-loss 1.4330e+04                    bc_loss 2.5174e+04\n",
      "Epoch 19580, Training-Loss 1.4204e+03, Data-loss 1.0830e+03                  , pde-loss 1.2771e+03, initc-loss 1.3434e+04                    bc_loss 1.9029e+04\n",
      "Epoch 19590, Training-Loss 5.5852e+03, Data-loss 1.2203e+03                  , pde-loss 1.2292e+03, initc-loss 1.5854e+04                    bc_loss 4.1941e+05\n",
      "Epoch 19600, Training-Loss 6.5644e+03, Data-loss 2.9789e+03                  , pde-loss 2.9978e+02, initc-loss 1.7699e+04                    bc_loss 3.4055e+05\n",
      "Epoch 19610, Training-Loss 5.6439e+03, Data-loss 3.2278e+03                  , pde-loss 1.1182e+03, initc-loss 1.1330e+04                    bc_loss 2.2916e+05\n",
      "Epoch 19620, Training-Loss 6.9235e+03, Data-loss 1.7382e+03                  , pde-loss 3.9899e+03, initc-loss 1.4770e+04                    bc_loss 4.9977e+05\n",
      "Epoch 19630, Training-Loss 5.4658e+03, Data-loss 2.7832e+03                  , pde-loss 2.6440e+03, initc-loss 1.3373e+04                    bc_loss 2.5224e+05\n",
      "Epoch 19640, Training-Loss 5.1344e+03, Data-loss 3.7489e+03                  , pde-loss 6.3322e+02, initc-loss 1.7909e+04                    bc_loss 1.2000e+05\n",
      "Epoch 19650, Training-Loss 8.1876e+03, Data-loss 2.8116e+03                  , pde-loss 2.7479e+02, initc-loss 1.7767e+04                    bc_loss 5.1955e+05\n",
      "Epoch 19660, Training-Loss 3.4034e+03, Data-loss 2.0945e+03                  , pde-loss 3.5687e+03, initc-loss 1.1289e+04                    bc_loss 1.1603e+05\n",
      "Epoch 19670, Training-Loss 3.0201e+03, Data-loss 2.6348e+03                  , pde-loss 4.7036e+03, initc-loss 1.5727e+04                    bc_loss 1.8100e+04\n",
      "Epoch 19680, Training-Loss 3.4547e+03, Data-loss 2.2876e+03                  , pde-loss 1.4330e+03, initc-loss 1.4322e+04                    bc_loss 1.0096e+05\n",
      "Epoch 19690, Training-Loss 1.4597e+03, Data-loss 1.0956e+03                  , pde-loss 7.5690e+02, initc-loss 8.7681e+03                    bc_loss 2.6889e+04\n",
      "Epoch 19700, Training-Loss 1.4938e+03, Data-loss 1.1585e+03                  , pde-loss 1.2920e+03, initc-loss 1.3148e+04                    bc_loss 1.9090e+04\n",
      "Epoch 19710, Training-Loss 1.8136e+03, Data-loss 6.9887e+02                  , pde-loss 2.0143e+03, initc-loss 1.2530e+04                    bc_loss 9.6928e+04\n",
      "Epoch 19720, Training-Loss 1.4518e+03, Data-loss 9.6020e+02                  , pde-loss 1.3218e+03, initc-loss 1.4595e+04                    bc_loss 3.3242e+04\n",
      "Epoch 19730, Training-Loss 2.3762e+03, Data-loss 1.9777e+03                  , pde-loss 9.8145e+02, initc-loss 1.5061e+04                    bc_loss 2.3812e+04\n",
      "Epoch 19740, Training-Loss 9.1077e+02, Data-loss 4.7580e+02                  , pde-loss 1.0954e+03, initc-loss 1.4160e+04                    bc_loss 2.8241e+04\n",
      "Epoch 19750, Training-Loss 3.9129e+03, Data-loss 1.0118e+03                  , pde-loss 7.9283e+02, initc-loss 1.8051e+04                    bc_loss 2.7127e+05\n",
      "Epoch 19760, Training-Loss 3.0595e+03, Data-loss 1.2557e+03                  , pde-loss 5.3992e+02, initc-loss 1.3619e+04                    bc_loss 1.6622e+05\n",
      "Epoch 19770, Training-Loss 2.2948e+03, Data-loss 9.2398e+02                  , pde-loss 1.6454e+03, initc-loss 1.4476e+04                    bc_loss 1.2096e+05\n",
      "Epoch 19780, Training-Loss 1.4886e+03, Data-loss 1.0160e+03                  , pde-loss 3.0162e+03, initc-loss 1.6448e+04                    bc_loss 2.7790e+04\n",
      "Epoch 19790, Training-Loss 3.6169e+03, Data-loss 8.1742e+02                  , pde-loss 1.6380e+03, initc-loss 1.5182e+04                    bc_loss 2.6313e+05\n",
      "Epoch 19800, Training-Loss 2.5657e+03, Data-loss 5.5826e+02                  , pde-loss 1.4049e+03, initc-loss 1.4457e+04                    bc_loss 1.8488e+05\n",
      "Epoch 19810, Training-Loss 5.7471e+03, Data-loss 2.1267e+03                  , pde-loss 2.4709e+03, initc-loss 1.8780e+04                    bc_loss 3.4079e+05\n",
      "Epoch 19820, Training-Loss 2.4315e+03, Data-loss 1.4665e+03                  , pde-loss 2.2742e+03, initc-loss 1.2991e+04                    bc_loss 8.1229e+04\n",
      "Epoch 19830, Training-Loss 1.7315e+03, Data-loss 1.2505e+03                  , pde-loss 8.5803e+02, initc-loss 1.2895e+04                    bc_loss 3.4345e+04\n",
      "Epoch 19840, Training-Loss 2.0992e+03, Data-loss 1.3262e+03                  , pde-loss 7.1401e+02, initc-loss 1.6345e+04                    bc_loss 6.0241e+04\n",
      "Epoch 19850, Training-Loss 5.6358e+03, Data-loss 1.0870e+03                  , pde-loss 1.2121e+03, initc-loss 1.4301e+04                    bc_loss 4.3937e+05\n",
      "Epoch 19860, Training-Loss 3.7762e+03, Data-loss 1.2400e+03                  , pde-loss 6.9181e+02, initc-loss 1.1981e+04                    bc_loss 2.4094e+05\n",
      "Epoch 19870, Training-Loss 1.7799e+03, Data-loss 1.1610e+03                  , pde-loss 1.3006e+03, initc-loss 1.4665e+04                    bc_loss 4.5918e+04\n",
      "Epoch 19880, Training-Loss 2.2612e+03, Data-loss 1.8550e+03                  , pde-loss 1.2400e+03, initc-loss 1.3899e+04                    bc_loss 2.5480e+04\n",
      "Epoch 19890, Training-Loss 5.9059e+03, Data-loss 9.7583e+02                  , pde-loss 1.2450e+03, initc-loss 1.4596e+04                    bc_loss 4.7717e+05\n",
      "Epoch 19900, Training-Loss 1.9025e+03, Data-loss 1.1786e+03                  , pde-loss 1.7689e+03, initc-loss 1.2398e+04                    bc_loss 5.8223e+04\n",
      "Epoch 19910, Training-Loss 2.0520e+03, Data-loss 1.5354e+03                  , pde-loss 2.3201e+03, initc-loss 1.2795e+04                    bc_loss 3.6544e+04\n",
      "Epoch 19920, Training-Loss 1.2537e+03, Data-loss 6.8887e+02                  , pde-loss 1.2148e+03, initc-loss 1.5799e+04                    bc_loss 3.9468e+04\n",
      "Epoch 19930, Training-Loss 1.6186e+03, Data-loss 1.2948e+03                  , pde-loss 9.4072e+02, initc-loss 1.2962e+04                    bc_loss 1.8478e+04\n",
      "Epoch 19940, Training-Loss 8.1757e+02, Data-loss 4.8539e+02                  , pde-loss 1.5201e+03, initc-loss 1.3821e+04                    bc_loss 1.7877e+04\n",
      "Epoch 19950, Training-Loss 2.0937e+03, Data-loss 3.9947e+02                  , pde-loss 1.1629e+03, initc-loss 1.2323e+04                    bc_loss 1.5593e+05\n",
      "Epoch 19960, Training-Loss 1.0357e+04, Data-loss 5.1865e+03                  , pde-loss 4.5254e+02, initc-loss 2.5464e+04                    bc_loss 4.9110e+05\n",
      "Epoch 19970, Training-Loss 5.3752e+03, Data-loss 3.6268e+03                  , pde-loss 4.9390e+02, initc-loss 1.2379e+04                    bc_loss 1.6197e+05\n",
      "Epoch 19980, Training-Loss 2.3903e+03, Data-loss 1.2323e+03                  , pde-loss 2.5720e+03, initc-loss 1.1593e+04                    bc_loss 1.0163e+05\n",
      "Epoch 19990, Training-Loss 2.5136e+03, Data-loss 1.5720e+03                  , pde-loss 1.3704e+03, initc-loss 1.5255e+04                    bc_loss 7.7529e+04\n",
      "Epoch 20000, Training-Loss 4.5789e+03, Data-loss 2.4572e+03                  , pde-loss 7.6053e+02, initc-loss 1.6888e+04                    bc_loss 1.9452e+05\n",
      "Epoch 20010, Training-Loss 6.3645e+03, Data-loss 3.1609e+03                  , pde-loss 7.1973e+02, initc-loss 1.4563e+04                    bc_loss 3.0508e+05\n",
      "Epoch 20020, Training-Loss 3.5169e+03, Data-loss 1.5990e+03                  , pde-loss 3.6385e+03, initc-loss 1.4796e+04                    bc_loss 1.7336e+05\n",
      "Epoch 20030, Training-Loss 1.1198e+04, Data-loss 5.1003e+03                  , pde-loss 5.4778e+03, initc-loss 2.6255e+04                    bc_loss 5.7801e+05\n",
      "Epoch 20040, Training-Loss 4.3345e+03, Data-loss 2.7973e+03                  , pde-loss 2.0585e+03, initc-loss 1.2444e+04                    bc_loss 1.3922e+05\n",
      "Epoch 20050, Training-Loss 3.2361e+03, Data-loss 2.4510e+03                  , pde-loss 9.4347e+02, initc-loss 1.7149e+04                    bc_loss 6.0418e+04\n",
      "Epoch 20060, Training-Loss 2.4508e+03, Data-loss 1.8353e+03                  , pde-loss 1.5507e+03, initc-loss 1.5109e+04                    bc_loss 4.4886e+04\n",
      "Epoch 20070, Training-Loss 3.3106e+03, Data-loss 2.6524e+03                  , pde-loss 1.3582e+03, initc-loss 8.6060e+03                    bc_loss 5.5854e+04\n",
      "Epoch 20080, Training-Loss 3.5503e+03, Data-loss 1.3417e+03                  , pde-loss 1.0006e+03, initc-loss 1.1070e+04                    bc_loss 2.0879e+05\n",
      "Epoch 20090, Training-Loss 1.4605e+03, Data-loss 1.1142e+03                  , pde-loss 1.3143e+03, initc-loss 1.2491e+04                    bc_loss 2.0827e+04\n",
      "Epoch 20100, Training-Loss 2.2607e+03, Data-loss 6.6937e+02                  , pde-loss 1.4273e+03, initc-loss 1.1975e+04                    bc_loss 1.4573e+05\n",
      "Epoch 20110, Training-Loss 2.3521e+03, Data-loss 1.3591e+03                  , pde-loss 1.2503e+03, initc-loss 1.5090e+04                    bc_loss 8.2958e+04\n",
      "Epoch 20120, Training-Loss 6.8463e+03, Data-loss 2.2964e+03                  , pde-loss 6.0861e+02, initc-loss 1.6298e+04                    bc_loss 4.3808e+05\n",
      "Epoch 20130, Training-Loss 2.3067e+03, Data-loss 1.4537e+03                  , pde-loss 6.0599e+02, initc-loss 1.0883e+04                    bc_loss 7.3811e+04\n",
      "Epoch 20140, Training-Loss 1.5505e+03, Data-loss 9.1317e+02                  , pde-loss 1.8309e+03, initc-loss 1.2469e+04                    bc_loss 4.9430e+04\n",
      "Epoch 20150, Training-Loss 1.1900e+03, Data-loss 9.3329e+02                  , pde-loss 2.1442e+03, initc-loss 1.3192e+04                    bc_loss 1.0331e+04\n",
      "Epoch 20160, Training-Loss 1.3998e+03, Data-loss 1.1429e+03                  , pde-loss 1.3599e+03, initc-loss 1.2455e+04                    bc_loss 1.1883e+04\n",
      "Epoch 20170, Training-Loss 1.1569e+03, Data-loss 8.7108e+02                  , pde-loss 1.1979e+03, initc-loss 1.1640e+04                    bc_loss 1.5745e+04\n",
      "Epoch 20180, Training-Loss 2.1820e+03, Data-loss 1.1943e+03                  , pde-loss 1.4306e+03, initc-loss 1.4399e+04                    bc_loss 8.2934e+04\n",
      "Epoch 20190, Training-Loss 1.4340e+04, Data-loss 3.2349e+03                  , pde-loss 8.0383e+02, initc-loss 2.2395e+04                    bc_loss 1.0873e+06\n",
      "Epoch 20200, Training-Loss 4.7177e+03, Data-loss 2.7743e+03                  , pde-loss 4.1515e+02, initc-loss 1.6765e+04                    bc_loss 1.7716e+05\n",
      "Epoch 20210, Training-Loss 3.6137e+03, Data-loss 2.5995e+03                  , pde-loss 2.3658e+03, initc-loss 1.5363e+04                    bc_loss 8.3690e+04\n",
      "Epoch 20220, Training-Loss 2.0864e+03, Data-loss 1.4868e+03                  , pde-loss 1.6234e+03, initc-loss 1.7485e+04                    bc_loss 4.0854e+04\n",
      "Epoch 20230, Training-Loss 2.4492e+03, Data-loss 1.8945e+03                  , pde-loss 1.1897e+03, initc-loss 1.5991e+04                    bc_loss 3.8286e+04\n",
      "Epoch 20240, Training-Loss 1.7046e+03, Data-loss 1.1302e+03                  , pde-loss 1.1873e+03, initc-loss 1.3058e+04                    bc_loss 4.3188e+04\n",
      "Epoch 20250, Training-Loss 3.2559e+03, Data-loss 2.4079e+03                  , pde-loss 1.3658e+03, initc-loss 1.3905e+04                    bc_loss 6.9524e+04\n",
      "Epoch 20260, Training-Loss 7.5455e+03, Data-loss 9.5558e+02                  , pde-loss 1.3098e+03, initc-loss 1.6196e+04                    bc_loss 6.4149e+05\n",
      "Epoch 20270, Training-Loss 4.9934e+03, Data-loss 1.9757e+03                  , pde-loss 2.0519e+03, initc-loss 1.3260e+04                    bc_loss 2.8646e+05\n",
      "Epoch 20280, Training-Loss 1.0754e+04, Data-loss 4.4269e+03                  , pde-loss 4.8794e+03, initc-loss 2.1704e+04                    bc_loss 6.0608e+05\n",
      "Epoch 20290, Training-Loss 6.1492e+03, Data-loss 2.4641e+03                  , pde-loss 2.5728e+03, initc-loss 1.2540e+04                    bc_loss 3.5339e+05\n",
      "Epoch 20300, Training-Loss 2.5695e+03, Data-loss 2.0224e+03                  , pde-loss 6.5493e+02, initc-loss 1.5060e+04                    bc_loss 3.8995e+04\n",
      "Epoch 20310, Training-Loss 4.2210e+03, Data-loss 2.2377e+03                  , pde-loss 7.8339e+02, initc-loss 1.9021e+04                    bc_loss 1.7852e+05\n",
      "Epoch 20320, Training-Loss 3.2417e+03, Data-loss 2.8448e+03                  , pde-loss 1.3332e+03, initc-loss 1.3376e+04                    bc_loss 2.4980e+04\n",
      "Epoch 20330, Training-Loss 1.2136e+03, Data-loss 6.7722e+02                  , pde-loss 1.5077e+03, initc-loss 1.3448e+04                    bc_loss 3.8684e+04\n",
      "Epoch 20340, Training-Loss 1.6670e+03, Data-loss 1.2945e+03                  , pde-loss 1.3107e+03, initc-loss 1.2887e+04                    bc_loss 2.3057e+04\n",
      "Epoch 20350, Training-Loss 1.4880e+03, Data-loss 1.1511e+03                  , pde-loss 1.4015e+03, initc-loss 1.1980e+04                    bc_loss 2.0308e+04\n",
      "Epoch 20360, Training-Loss 1.2569e+03, Data-loss 7.0902e+02                  , pde-loss 1.4568e+03, initc-loss 1.5391e+04                    bc_loss 3.7944e+04\n",
      "Epoch 20370, Training-Loss 1.0285e+03, Data-loss 6.7152e+02                  , pde-loss 1.5526e+03, initc-loss 1.5149e+04                    bc_loss 1.8996e+04\n",
      "Epoch 20380, Training-Loss 6.1865e+03, Data-loss 1.2110e+03                  , pde-loss 9.7875e+02, initc-loss 1.7891e+04                    bc_loss 4.7867e+05\n",
      "Epoch 20390, Training-Loss 6.0296e+03, Data-loss 1.5773e+03                  , pde-loss 3.8733e+02, initc-loss 1.7722e+04                    bc_loss 4.2712e+05\n",
      "Epoch 20400, Training-Loss 3.7537e+03, Data-loss 3.1318e+03                  , pde-loss 7.3668e+02, initc-loss 1.8163e+04                    bc_loss 4.3298e+04\n",
      "Epoch 20410, Training-Loss 2.1117e+03, Data-loss 1.6443e+03                  , pde-loss 1.8589e+03, initc-loss 1.3426e+04                    bc_loss 3.1457e+04\n",
      "Epoch 20420, Training-Loss 8.2345e+02, Data-loss 4.2264e+02                  , pde-loss 2.2605e+03, initc-loss 1.5089e+04                    bc_loss 2.2732e+04\n",
      "Epoch 20430, Training-Loss 1.3742e+03, Data-loss 9.9939e+02                  , pde-loss 1.6649e+03, initc-loss 1.3882e+04                    bc_loss 2.1930e+04\n",
      "Epoch 20440, Training-Loss 2.4447e+03, Data-loss 1.2740e+03                  , pde-loss 1.5388e+03, initc-loss 1.2367e+04                    bc_loss 1.0316e+05\n",
      "Epoch 20450, Training-Loss 5.8960e+03, Data-loss 7.3954e+02                  , pde-loss 2.1077e+03, initc-loss 1.3949e+04                    bc_loss 4.9959e+05\n",
      "Epoch 20460, Training-Loss 1.5594e+03, Data-loss 9.7370e+02                  , pde-loss 1.5458e+03, initc-loss 1.1031e+04                    bc_loss 4.5994e+04\n",
      "Epoch 20470, Training-Loss 1.6216e+03, Data-loss 1.1047e+03                  , pde-loss 1.0250e+03, initc-loss 1.0137e+04                    bc_loss 4.0535e+04\n",
      "Epoch 20480, Training-Loss 1.0992e+03, Data-loss 6.2896e+02                  , pde-loss 7.9388e+02, initc-loss 1.3583e+04                    bc_loss 3.2646e+04\n",
      "Epoch 20490, Training-Loss 1.2089e+04, Data-loss 4.3988e+03                  , pde-loss 4.4684e+02, initc-loss 2.7021e+04                    bc_loss 7.4157e+05\n",
      "Epoch 20500, Training-Loss 2.4154e+03, Data-loss 1.8620e+03                  , pde-loss 8.4143e+02, initc-loss 1.4442e+04                    bc_loss 4.0058e+04\n",
      "Epoch 20510, Training-Loss 2.4663e+03, Data-loss 2.0838e+03                  , pde-loss 1.3496e+03, initc-loss 1.3325e+04                    bc_loss 2.3575e+04\n",
      "Epoch 20520, Training-Loss 1.6413e+03, Data-loss 1.1445e+03                  , pde-loss 1.4940e+03, initc-loss 1.5371e+04                    bc_loss 3.2819e+04\n",
      "Epoch 20530, Training-Loss 2.4717e+03, Data-loss 1.2545e+03                  , pde-loss 1.3808e+03, initc-loss 1.3131e+04                    bc_loss 1.0721e+05\n",
      "Epoch 20540, Training-Loss 3.5296e+03, Data-loss 2.2415e+03                  , pde-loss 8.7508e+02, initc-loss 1.0940e+04                    bc_loss 1.1699e+05\n",
      "Epoch 20550, Training-Loss 1.3146e+03, Data-loss 8.8236e+02                  , pde-loss 2.3613e+03, initc-loss 1.3350e+04                    bc_loss 2.7517e+04\n",
      "Epoch 20560, Training-Loss 2.0129e+03, Data-loss 1.4562e+03                  , pde-loss 2.6320e+03, initc-loss 1.5256e+04                    bc_loss 3.7785e+04\n",
      "Epoch 20570, Training-Loss 1.9139e+03, Data-loss 7.3902e+02                  , pde-loss 1.4494e+03, initc-loss 1.5209e+04                    bc_loss 1.0083e+05\n",
      "Epoch 20580, Training-Loss 2.2479e+03, Data-loss 1.8403e+03                  , pde-loss 1.0090e+03, initc-loss 1.5271e+04                    bc_loss 2.4480e+04\n",
      "Epoch 20590, Training-Loss 1.0837e+03, Data-loss 6.7171e+02                  , pde-loss 9.4113e+02, initc-loss 1.3607e+04                    bc_loss 2.6653e+04\n",
      "Epoch 20600, Training-Loss 1.0090e+03, Data-loss 6.7542e+02                  , pde-loss 1.2840e+03, initc-loss 1.3668e+04                    bc_loss 1.8406e+04\n",
      "Epoch 20610, Training-Loss 1.7337e+03, Data-loss 1.3483e+03                  , pde-loss 1.3676e+03, initc-loss 1.2287e+04                    bc_loss 2.4882e+04\n",
      "Epoch 20620, Training-Loss 2.0971e+03, Data-loss 9.0530e+02                  , pde-loss 1.1255e+03, initc-loss 1.1984e+04                    bc_loss 1.0607e+05\n",
      "Epoch 20630, Training-Loss 7.6138e+03, Data-loss 2.3918e+03                  , pde-loss 3.7207e+02, initc-loss 1.9969e+04                    bc_loss 5.0185e+05\n",
      "Epoch 20640, Training-Loss 2.8208e+03, Data-loss 2.1791e+03                  , pde-loss 7.8907e+02, initc-loss 1.8759e+04                    bc_loss 4.4618e+04\n",
      "Epoch 20650, Training-Loss 2.0509e+03, Data-loss 1.5073e+03                  , pde-loss 1.7468e+03, initc-loss 1.5002e+04                    bc_loss 3.7613e+04\n",
      "Epoch 20660, Training-Loss 1.0294e+03, Data-loss 5.6356e+02                  , pde-loss 1.5712e+03, initc-loss 1.5832e+04                    bc_loss 2.9184e+04\n",
      "Epoch 20670, Training-Loss 2.0231e+03, Data-loss 7.5674e+02                  , pde-loss 1.3043e+03, initc-loss 1.4633e+04                    bc_loss 1.1070e+05\n",
      "Epoch 20680, Training-Loss 2.4101e+03, Data-loss 1.2513e+03                  , pde-loss 1.6749e+03, initc-loss 8.9982e+03                    bc_loss 1.0520e+05\n",
      "Epoch 20690, Training-Loss 1.4242e+04, Data-loss 3.2575e+03                  , pde-loss 4.1183e+03, initc-loss 2.5984e+04                    bc_loss 1.0683e+06\n",
      "Epoch 20700, Training-Loss 6.8171e+03, Data-loss 2.4680e+03                  , pde-loss 4.0098e+03, initc-loss 1.1830e+04                    bc_loss 4.1907e+05\n",
      "Epoch 20710, Training-Loss 3.4055e+03, Data-loss 2.4110e+03                  , pde-loss 8.2954e+02, initc-loss 1.9171e+04                    bc_loss 7.9450e+04\n",
      "Epoch 20720, Training-Loss 2.0371e+03, Data-loss 1.5596e+03                  , pde-loss 1.1033e+03, initc-loss 1.4826e+04                    bc_loss 3.1823e+04\n",
      "Epoch 20730, Training-Loss 2.1358e+03, Data-loss 1.4420e+03                  , pde-loss 1.7457e+03, initc-loss 1.3450e+04                    bc_loss 5.4188e+04\n",
      "Epoch 20740, Training-Loss 1.9157e+03, Data-loss 1.0231e+03                  , pde-loss 1.2008e+03, initc-loss 1.4697e+04                    bc_loss 7.3361e+04\n",
      "Epoch 20750, Training-Loss 1.2204e+03, Data-loss 8.3233e+02                  , pde-loss 1.5164e+03, initc-loss 1.2699e+04                    bc_loss 2.4597e+04\n",
      "Epoch 20760, Training-Loss 1.1896e+03, Data-loss 8.0883e+02                  , pde-loss 1.3857e+03, initc-loss 1.3286e+04                    bc_loss 2.3407e+04\n",
      "Epoch 20770, Training-Loss 9.8843e+03, Data-loss 1.6292e+03                  , pde-loss 5.9351e+02, initc-loss 1.8467e+04                    bc_loss 8.0645e+05\n",
      "Epoch 20780, Training-Loss 4.3902e+03, Data-loss 2.4785e+03                  , pde-loss 1.8138e+02, initc-loss 1.7472e+04                    bc_loss 1.7351e+05\n",
      "Epoch 20790, Training-Loss 3.2146e+03, Data-loss 2.5603e+03                  , pde-loss 8.1200e+02, initc-loss 1.2309e+04                    bc_loss 5.2315e+04\n",
      "Epoch 20800, Training-Loss 1.2490e+03, Data-loss 7.1669e+02                  , pde-loss 1.3198e+03, initc-loss 1.2445e+04                    bc_loss 3.9468e+04\n",
      "Epoch 20810, Training-Loss 2.9329e+03, Data-loss 1.4808e+03                  , pde-loss 1.4173e+03, initc-loss 1.6020e+04                    bc_loss 1.2778e+05\n",
      "Epoch 20820, Training-Loss 4.2392e+03, Data-loss 2.2558e+03                  , pde-loss 1.6981e+03, initc-loss 9.8050e+03                    bc_loss 1.8683e+05\n",
      "Epoch 20830, Training-Loss 1.6621e+03, Data-loss 1.1846e+03                  , pde-loss 2.8078e+03, initc-loss 1.2111e+04                    bc_loss 3.2832e+04\n",
      "Epoch 20840, Training-Loss 1.6773e+03, Data-loss 1.2705e+03                  , pde-loss 1.5914e+03, initc-loss 1.3989e+04                    bc_loss 2.5095e+04\n",
      "Epoch 20850, Training-Loss 1.1109e+03, Data-loss 7.9598e+02                  , pde-loss 1.1315e+03, initc-loss 1.2856e+04                    bc_loss 1.7507e+04\n",
      "Epoch 20860, Training-Loss 3.1636e+03, Data-loss 1.3561e+03                  , pde-loss 1.3115e+03, initc-loss 1.3002e+04                    bc_loss 1.6643e+05\n",
      "Epoch 20870, Training-Loss 1.3782e+03, Data-loss 8.2787e+02                  , pde-loss 1.5954e+03, initc-loss 1.1323e+04                    bc_loss 4.2114e+04\n",
      "Epoch 20880, Training-Loss 9.2570e+02, Data-loss 5.8749e+02                  , pde-loss 1.1786e+03, initc-loss 1.2273e+04                    bc_loss 2.0369e+04\n",
      "Epoch 20890, Training-Loss 1.0010e+03, Data-loss 5.5914e+02                  , pde-loss 1.0011e+03, initc-loss 1.5133e+04                    bc_loss 2.8047e+04\n",
      "Epoch 20900, Training-Loss 8.8841e+02, Data-loss 5.7163e+02                  , pde-loss 1.3043e+03, initc-loss 1.3292e+04                    bc_loss 1.7082e+04\n",
      "Epoch 20910, Training-Loss 1.3330e+03, Data-loss 6.8667e+02                  , pde-loss 1.4312e+03, initc-loss 1.3623e+04                    bc_loss 4.9579e+04\n",
      "Epoch 20920, Training-Loss 1.3030e+04, Data-loss 6.1204e+03                  , pde-loss 4.7254e+02, initc-loss 2.9616e+04                    bc_loss 6.6086e+05\n",
      "Epoch 20930, Training-Loss 4.3410e+03, Data-loss 3.1606e+03                  , pde-loss 7.8489e+02, initc-loss 1.6393e+04                    bc_loss 1.0085e+05\n",
      "Epoch 20940, Training-Loss 2.2030e+03, Data-loss 1.6595e+03                  , pde-loss 1.1906e+03, initc-loss 1.6586e+04                    bc_loss 3.6572e+04\n",
      "Epoch 20950, Training-Loss 2.0790e+03, Data-loss 1.5497e+03                  , pde-loss 1.7159e+03, initc-loss 1.6349e+04                    bc_loss 3.4871e+04\n",
      "Epoch 20960, Training-Loss 1.4280e+03, Data-loss 1.0676e+03                  , pde-loss 1.6143e+03, initc-loss 1.3602e+04                    bc_loss 2.0829e+04\n",
      "Epoch 20970, Training-Loss 2.0873e+03, Data-loss 1.6672e+03                  , pde-loss 1.7723e+03, initc-loss 1.3226e+04                    bc_loss 2.7011e+04\n",
      "Epoch 20980, Training-Loss 1.0980e+04, Data-loss 2.0316e+03                  , pde-loss 2.4132e+03, initc-loss 2.0645e+04                    bc_loss 8.7180e+05\n",
      "Epoch 20990, Training-Loss 3.6081e+03, Data-loss 1.6449e+03                  , pde-loss 2.4770e+03, initc-loss 1.1312e+04                    bc_loss 1.8254e+05\n",
      "Epoch 21000, Training-Loss 1.7430e+03, Data-loss 1.4194e+03                  , pde-loss 1.0479e+03, initc-loss 1.2165e+04                    bc_loss 1.9140e+04\n",
      "Epoch 21010, Training-Loss 3.1331e+03, Data-loss 7.5668e+02                  , pde-loss 1.0168e+03, initc-loss 1.5552e+04                    bc_loss 2.2107e+05\n",
      "Epoch 21020, Training-Loss 2.3409e+03, Data-loss 7.0061e+02                  , pde-loss 1.0639e+03, initc-loss 1.3392e+04                    bc_loss 1.4958e+05\n",
      "Epoch 21030, Training-Loss 1.5569e+03, Data-loss 6.9476e+02                  , pde-loss 1.2439e+03, initc-loss 1.2547e+04                    bc_loss 7.2421e+04\n",
      "Epoch 21040, Training-Loss 3.9485e+03, Data-loss 8.6844e+02                  , pde-loss 8.5858e+02, initc-loss 1.6320e+04                    bc_loss 2.9083e+05\n",
      "Epoch 21050, Training-Loss 1.4720e+03, Data-loss 1.0513e+03                  , pde-loss 1.0637e+03, initc-loss 1.3894e+04                    bc_loss 2.7113e+04\n",
      "Epoch 21060, Training-Loss 1.1006e+03, Data-loss 7.5477e+02                  , pde-loss 1.4555e+03, initc-loss 1.4026e+04                    bc_loss 1.9100e+04\n",
      "Epoch 21070, Training-Loss 1.3187e+03, Data-loss 7.8101e+02                  , pde-loss 1.6621e+03, initc-loss 1.2758e+04                    bc_loss 3.9347e+04\n",
      "Epoch 21080, Training-Loss 1.1359e+03, Data-loss 7.3901e+02                  , pde-loss 1.9445e+03, initc-loss 1.4137e+04                    bc_loss 2.3611e+04\n",
      "Epoch 21090, Training-Loss 1.1329e+03, Data-loss 7.9724e+02                  , pde-loss 1.4495e+03, initc-loss 1.3430e+04                    bc_loss 1.8689e+04\n",
      "Epoch 21100, Training-Loss 1.1586e+03, Data-loss 8.2782e+02                  , pde-loss 1.2215e+03, initc-loss 1.0617e+04                    bc_loss 2.1240e+04\n",
      "Epoch 21110, Training-Loss 1.1610e+03, Data-loss 7.2645e+02                  , pde-loss 1.0415e+03, initc-loss 1.2161e+04                    bc_loss 3.0248e+04\n",
      "Epoch 21120, Training-Loss 1.1560e+04, Data-loss 4.0737e+03                  , pde-loss 3.6582e+02, initc-loss 2.6320e+04                    bc_loss 7.2197e+05\n",
      "Epoch 21130, Training-Loss 4.9453e+03, Data-loss 3.4443e+03                  , pde-loss 4.0143e+02, initc-loss 1.8262e+04                    bc_loss 1.3143e+05\n",
      "Epoch 21140, Training-Loss 3.3468e+03, Data-loss 2.4867e+03                  , pde-loss 1.9793e+03, initc-loss 1.4273e+04                    bc_loss 6.9753e+04\n",
      "Epoch 21150, Training-Loss 3.3831e+03, Data-loss 2.3912e+03                  , pde-loss 1.3525e+03, initc-loss 1.6648e+04                    bc_loss 8.1196e+04\n",
      "Epoch 21160, Training-Loss 4.5332e+03, Data-loss 2.6034e+03                  , pde-loss 9.1618e+02, initc-loss 1.6818e+04                    bc_loss 1.7524e+05\n",
      "Epoch 21170, Training-Loss 5.9154e+03, Data-loss 1.9994e+03                  , pde-loss 6.0605e+02, initc-loss 1.5659e+04                    bc_loss 3.7533e+05\n",
      "Epoch 21180, Training-Loss 5.4895e+03, Data-loss 4.2875e+03                  , pde-loss 2.6838e+03, initc-loss 1.6131e+04                    bc_loss 1.0138e+05\n",
      "Epoch 21190, Training-Loss 1.2869e+04, Data-loss 5.6780e+03                  , pde-loss 4.7653e+03, initc-loss 2.5210e+04                    bc_loss 6.8909e+05\n",
      "Epoch 21200, Training-Loss 3.7064e+03, Data-loss 1.6519e+03                  , pde-loss 2.5371e+03, initc-loss 1.2358e+04                    bc_loss 1.9056e+05\n",
      "Epoch 21210, Training-Loss 2.0384e+03, Data-loss 1.6443e+03                  , pde-loss 8.2543e+02, initc-loss 1.4406e+04                    bc_loss 2.4177e+04\n",
      "Epoch 21220, Training-Loss 4.6428e+03, Data-loss 1.3107e+03                  , pde-loss 1.1662e+03, initc-loss 1.6367e+04                    bc_loss 3.1568e+05\n",
      "Epoch 21230, Training-Loss 2.1361e+03, Data-loss 1.7736e+03                  , pde-loss 1.2570e+03, initc-loss 1.2713e+04                    bc_loss 2.2275e+04\n",
      "Epoch 21240, Training-Loss 1.2161e+03, Data-loss 8.4377e+02                  , pde-loss 1.4071e+03, initc-loss 1.3254e+04                    bc_loss 2.2570e+04\n",
      "Epoch 21250, Training-Loss 1.9127e+03, Data-loss 4.7438e+02                  , pde-loss 1.6340e+03, initc-loss 1.3350e+04                    bc_loss 1.2885e+05\n",
      "Epoch 21260, Training-Loss 1.8217e+03, Data-loss 1.5268e+03                  , pde-loss 1.4675e+03, initc-loss 1.2138e+04                    bc_loss 1.5885e+04\n",
      "Epoch 21270, Training-Loss 9.7902e+02, Data-loss 6.2300e+02                  , pde-loss 1.2591e+03, initc-loss 1.2476e+04                    bc_loss 2.1867e+04\n",
      "Epoch 21280, Training-Loss 1.0099e+03, Data-loss 6.3157e+02                  , pde-loss 1.3844e+03, initc-loss 1.5359e+04                    bc_loss 2.1089e+04\n",
      "Epoch 21290, Training-Loss 1.9533e+03, Data-loss 8.2080e+02                  , pde-loss 1.2030e+03, initc-loss 1.3609e+04                    bc_loss 9.8443e+04\n",
      "Epoch 21300, Training-Loss 1.0448e+03, Data-loss 2.2774e+02                  , pde-loss 1.0239e+03, initc-loss 1.4010e+04                    bc_loss 6.6673e+04\n",
      "Epoch 21310, Training-Loss 2.7448e+03, Data-loss 8.5157e+02                  , pde-loss 8.5918e+02, initc-loss 1.2223e+04                    bc_loss 1.7624e+05\n",
      "Epoch 21320, Training-Loss 9.8826e+02, Data-loss 7.0519e+02                  , pde-loss 1.4092e+03, initc-loss 1.1581e+04                    bc_loss 1.5317e+04\n",
      "Epoch 21330, Training-Loss 7.0303e+02, Data-loss 3.4818e+02                  , pde-loss 1.6634e+03, initc-loss 1.1304e+04                    bc_loss 2.2518e+04\n",
      "Epoch 21340, Training-Loss 9.3306e+02, Data-loss 6.4947e+02                  , pde-loss 1.5219e+03, initc-loss 1.2449e+04                    bc_loss 1.4388e+04\n",
      "Epoch 21350, Training-Loss 7.5433e+02, Data-loss 4.8549e+02                  , pde-loss 1.4819e+03, initc-loss 1.2338e+04                    bc_loss 1.3064e+04\n",
      "Epoch 21360, Training-Loss 1.2238e+03, Data-loss 8.1942e+02                  , pde-loss 1.4019e+03, initc-loss 1.3500e+04                    bc_loss 2.5531e+04\n",
      "Epoch 21370, Training-Loss 1.9870e+03, Data-loss 8.5827e+02                  , pde-loss 1.1211e+03, initc-loss 1.3704e+04                    bc_loss 9.8053e+04\n",
      "Epoch 21380, Training-Loss 9.2881e+03, Data-loss 6.7378e+03                  , pde-loss 1.9945e+02, initc-loss 3.0190e+04                    bc_loss 2.2464e+05\n",
      "Epoch 21390, Training-Loss 6.6130e+03, Data-loss 5.7039e+03                  , pde-loss 5.3388e+02, initc-loss 2.4080e+04                    bc_loss 6.6293e+04\n",
      "Epoch 21400, Training-Loss 4.3403e+03, Data-loss 2.7344e+03                  , pde-loss 2.6932e+03, initc-loss 1.8100e+04                    bc_loss 1.3980e+05\n",
      "Epoch 21410, Training-Loss 2.2494e+03, Data-loss 1.5453e+03                  , pde-loss 1.7181e+03, initc-loss 1.9037e+04                    bc_loss 4.9651e+04\n",
      "Epoch 21420, Training-Loss 4.5996e+03, Data-loss 1.6291e+03                  , pde-loss 7.4519e+02, initc-loss 2.0087e+04                    bc_loss 2.7621e+05\n",
      "Epoch 21430, Training-Loss 6.8812e+03, Data-loss 3.4243e+03                  , pde-loss 4.7890e+02, initc-loss 1.3481e+04                    bc_loss 3.3173e+05\n",
      "Epoch 21440, Training-Loss 3.6464e+03, Data-loss 2.6126e+03                  , pde-loss 3.1843e+03, initc-loss 1.5611e+04                    bc_loss 8.4586e+04\n",
      "Epoch 21450, Training-Loss 1.0574e+04, Data-loss 4.2630e+03                  , pde-loss 4.6357e+03, initc-loss 2.4862e+04                    bc_loss 6.0158e+05\n",
      "Epoch 21460, Training-Loss 2.4712e+03, Data-loss 1.5923e+03                  , pde-loss 2.0901e+03, initc-loss 1.4181e+04                    bc_loss 7.1617e+04\n",
      "Epoch 21470, Training-Loss 2.2848e+03, Data-loss 1.8638e+03                  , pde-loss 7.7275e+02, initc-loss 1.4005e+04                    bc_loss 2.7318e+04\n",
      "Epoch 21480, Training-Loss 1.9621e+03, Data-loss 1.5497e+03                  , pde-loss 1.3061e+03, initc-loss 1.5037e+04                    bc_loss 2.4894e+04\n",
      "Epoch 21490, Training-Loss 2.2187e+03, Data-loss 1.4622e+03                  , pde-loss 1.3072e+03, initc-loss 1.1148e+04                    bc_loss 6.3199e+04\n",
      "Epoch 21500, Training-Loss 1.2864e+03, Data-loss 8.9404e+02                  , pde-loss 1.2040e+03, initc-loss 1.5768e+04                    bc_loss 2.2265e+04\n",
      "Epoch 21510, Training-Loss 1.6831e+03, Data-loss 1.3493e+03                  , pde-loss 1.2206e+03, initc-loss 1.5993e+04                    bc_loss 1.6171e+04\n",
      "Epoch 21520, Training-Loss 8.4412e+02, Data-loss 5.7530e+02                  , pde-loss 1.2945e+03, initc-loss 1.2846e+04                    bc_loss 1.2741e+04\n",
      "Epoch 21530, Training-Loss 1.6404e+03, Data-loss 1.2590e+03                  , pde-loss 1.3209e+03, initc-loss 1.3190e+04                    bc_loss 2.3628e+04\n",
      "Epoch 21540, Training-Loss 3.0218e+03, Data-loss 1.2640e+03                  , pde-loss 7.9463e+02, initc-loss 1.8173e+04                    bc_loss 1.5680e+05\n",
      "Epoch 21550, Training-Loss 2.2857e+03, Data-loss 1.4674e+03                  , pde-loss 8.8059e+02, initc-loss 1.8141e+04                    bc_loss 6.2809e+04\n",
      "Epoch 21560, Training-Loss 1.7662e+03, Data-loss 1.3212e+03                  , pde-loss 1.9661e+03, initc-loss 1.6898e+04                    bc_loss 2.5636e+04\n",
      "Epoch 21570, Training-Loss 2.3344e+03, Data-loss 1.1394e+03                  , pde-loss 2.0394e+03, initc-loss 1.4705e+04                    bc_loss 1.0276e+05\n",
      "Epoch 21580, Training-Loss 7.4842e+02, Data-loss 4.2924e+02                  , pde-loss 1.5825e+03, initc-loss 1.2475e+04                    bc_loss 1.7860e+04\n",
      "Epoch 21590, Training-Loss 1.3420e+03, Data-loss 1.0743e+03                  , pde-loss 9.9038e+02, initc-loss 1.2866e+04                    bc_loss 1.2921e+04\n",
      "Epoch 21600, Training-Loss 4.8647e+03, Data-loss 1.3521e+03                  , pde-loss 7.3488e+02, initc-loss 1.5597e+04                    bc_loss 3.3493e+05\n",
      "Epoch 21610, Training-Loss 7.1467e+03, Data-loss 3.4112e+03                  , pde-loss 2.2757e+02, initc-loss 1.8110e+04                    bc_loss 3.5521e+05\n",
      "Epoch 21620, Training-Loss 6.0434e+03, Data-loss 2.1266e+03                  , pde-loss 4.1190e+02, initc-loss 1.1322e+04                    bc_loss 3.7994e+05\n",
      "Epoch 21630, Training-Loss 2.5966e+03, Data-loss 2.1796e+03                  , pde-loss 3.3041e+03, initc-loss 1.8664e+04                    bc_loss 1.9729e+04\n",
      "Epoch 21640, Training-Loss 3.7304e+03, Data-loss 2.5599e+03                  , pde-loss 3.7355e+03, initc-loss 2.2238e+04                    bc_loss 9.1083e+04\n",
      "Epoch 21650, Training-Loss 1.6091e+03, Data-loss 1.3199e+03                  , pde-loss 1.0560e+03, initc-loss 1.3585e+04                    bc_loss 1.4285e+04\n",
      "Epoch 21660, Training-Loss 9.9482e+02, Data-loss 7.3046e+02                  , pde-loss 1.0380e+03, initc-loss 1.2360e+04                    bc_loss 1.3039e+04\n",
      "Epoch 21670, Training-Loss 4.7534e+03, Data-loss 8.0272e+02                  , pde-loss 1.8185e+03, initc-loss 1.4513e+04                    bc_loss 3.7873e+05\n",
      "Epoch 21680, Training-Loss 1.5383e+03, Data-loss 9.2848e+02                  , pde-loss 1.7466e+03, initc-loss 1.1786e+04                    bc_loss 4.7446e+04\n",
      "Epoch 21690, Training-Loss 1.1649e+03, Data-loss 8.7678e+02                  , pde-loss 1.0804e+03, initc-loss 1.1878e+04                    bc_loss 1.5856e+04\n",
      "Epoch 21700, Training-Loss 1.3017e+03, Data-loss 8.9573e+02                  , pde-loss 1.0984e+03, initc-loss 1.7684e+04                    bc_loss 2.1810e+04\n",
      "Epoch 21710, Training-Loss 1.2968e+03, Data-loss 9.0150e+02                  , pde-loss 1.3883e+03, initc-loss 1.4422e+04                    bc_loss 2.3722e+04\n",
      "Epoch 21720, Training-Loss 1.3958e+03, Data-loss 1.0435e+03                  , pde-loss 1.3054e+03, initc-loss 1.3459e+04                    bc_loss 2.0470e+04\n",
      "Epoch 21730, Training-Loss 3.1712e+03, Data-loss 5.1490e+02                  , pde-loss 1.0628e+03, initc-loss 1.4142e+04                    bc_loss 2.5043e+05\n",
      "Epoch 21740, Training-Loss 5.9052e+03, Data-loss 2.3465e+03                  , pde-loss 5.7464e+02, initc-loss 1.7413e+04                    bc_loss 3.3788e+05\n",
      "Epoch 21750, Training-Loss 3.0990e+03, Data-loss 1.5755e+03                  , pde-loss 7.2975e+02, initc-loss 1.2895e+04                    bc_loss 1.3873e+05\n",
      "Epoch 21760, Training-Loss 2.2662e+03, Data-loss 1.7465e+03                  , pde-loss 2.2567e+03, initc-loss 1.1813e+04                    bc_loss 3.7900e+04\n",
      "Epoch 21770, Training-Loss 1.9710e+03, Data-loss 1.5571e+03                  , pde-loss 2.1370e+03, initc-loss 1.2620e+04                    bc_loss 2.6634e+04\n",
      "Epoch 21780, Training-Loss 9.2580e+02, Data-loss 5.3247e+02                  , pde-loss 1.6564e+03, initc-loss 1.2897e+04                    bc_loss 2.4779e+04\n",
      "Epoch 21790, Training-Loss 5.1250e+03, Data-loss 1.4599e+03                  , pde-loss 1.6284e+03, initc-loss 1.5371e+04                    bc_loss 3.4951e+05\n",
      "Epoch 21800, Training-Loss 4.5907e+03, Data-loss 2.1358e+03                  , pde-loss 2.5840e+03, initc-loss 1.9431e+04                    bc_loss 2.2347e+05\n",
      "Epoch 21810, Training-Loss 3.7387e+03, Data-loss 2.2836e+03                  , pde-loss 1.7139e+03, initc-loss 1.7175e+04                    bc_loss 1.2663e+05\n",
      "Epoch 21820, Training-Loss 2.0657e+03, Data-loss 1.5675e+03                  , pde-loss 6.3382e+02, initc-loss 1.6199e+04                    bc_loss 3.2984e+04\n",
      "Epoch 21830, Training-Loss 1.4975e+03, Data-loss 1.1395e+03                  , pde-loss 8.5496e+02, initc-loss 1.1162e+04                    bc_loss 2.3781e+04\n",
      "Epoch 21840, Training-Loss 1.2853e+04, Data-loss 7.1684e+02                  , pde-loss 1.1830e+03, initc-loss 1.3141e+04                    bc_loss 1.1992e+06\n",
      "Epoch 21850, Training-Loss 5.1438e+03, Data-loss 2.2960e+03                  , pde-loss 6.3460e+02, initc-loss 1.2316e+04                    bc_loss 2.7182e+05\n",
      "Epoch 21860, Training-Loss 1.7871e+03, Data-loss 1.1585e+03                  , pde-loss 1.0056e+03, initc-loss 1.4801e+04                    bc_loss 4.7056e+04\n",
      "Epoch 21870, Training-Loss 9.4883e+02, Data-loss 6.0538e+02                  , pde-loss 1.3494e+03, initc-loss 1.4359e+04                    bc_loss 1.8636e+04\n",
      "Epoch 21880, Training-Loss 1.2977e+03, Data-loss 9.2512e+02                  , pde-loss 1.2877e+03, initc-loss 1.6375e+04                    bc_loss 1.9600e+04\n",
      "Epoch 21890, Training-Loss 8.4378e+03, Data-loss 8.6733e+02                  , pde-loss 1.3134e+03, initc-loss 1.5553e+04                    bc_loss 7.4018e+05\n",
      "Epoch 21900, Training-Loss 3.6549e+03, Data-loss 2.1185e+03                  , pde-loss 9.8368e+02, initc-loss 9.4405e+03                    bc_loss 1.4321e+05\n",
      "Epoch 21910, Training-Loss 2.0814e+03, Data-loss 1.2382e+03                  , pde-loss 2.5715e+03, initc-loss 1.3281e+04                    bc_loss 6.8463e+04\n",
      "Epoch 21920, Training-Loss 8.5726e+03, Data-loss 2.5493e+03                  , pde-loss 2.6540e+03, initc-loss 1.7005e+04                    bc_loss 5.8267e+05\n",
      "Epoch 21930, Training-Loss 3.1894e+03, Data-loss 1.2791e+03                  , pde-loss 1.7373e+03, initc-loss 1.3300e+04                    bc_loss 1.7599e+05\n",
      "Epoch 21940, Training-Loss 1.8655e+03, Data-loss 1.3901e+03                  , pde-loss 7.1390e+02, initc-loss 1.2138e+04                    bc_loss 3.4692e+04\n",
      "Epoch 21950, Training-Loss 1.6694e+03, Data-loss 1.0780e+03                  , pde-loss 1.0739e+03, initc-loss 1.4671e+04                    bc_loss 4.3391e+04\n",
      "Epoch 21960, Training-Loss 1.3121e+03, Data-loss 9.0132e+02                  , pde-loss 1.3004e+03, initc-loss 1.1507e+04                    bc_loss 2.8272e+04\n",
      "Epoch 21970, Training-Loss 1.5627e+03, Data-loss 1.0858e+03                  , pde-loss 1.1943e+03, initc-loss 1.3421e+04                    bc_loss 3.3076e+04\n",
      "Epoch 21980, Training-Loss 7.6684e+03, Data-loss 7.3139e+02                  , pde-loss 1.1171e+03, initc-loss 1.4240e+04                    bc_loss 6.7834e+05\n",
      "Epoch 21990, Training-Loss 3.2411e+03, Data-loss 1.7576e+03                  , pde-loss 8.6948e+02, initc-loss 7.6629e+03                    bc_loss 1.3982e+05\n",
      "Epoch 22000, Training-Loss 2.2266e+03, Data-loss 1.4918e+03                  , pde-loss 1.4730e+03, initc-loss 1.1556e+04                    bc_loss 6.0446e+04\n",
      "Epoch 22010, Training-Loss 1.1851e+03, Data-loss 5.9489e+02                  , pde-loss 1.7208e+03, initc-loss 1.2274e+04                    bc_loss 4.5023e+04\n",
      "Epoch 22020, Training-Loss 1.1528e+03, Data-loss 6.8003e+02                  , pde-loss 1.7836e+03, initc-loss 1.0616e+04                    bc_loss 3.4876e+04\n",
      "Epoch 22030, Training-Loss 1.4090e+03, Data-loss 1.0939e+03                  , pde-loss 1.4718e+03, initc-loss 1.1952e+04                    bc_loss 1.8092e+04\n",
      "Epoch 22040, Training-Loss 9.9344e+02, Data-loss 7.0269e+02                  , pde-loss 1.3730e+03, initc-loss 1.1792e+04                    bc_loss 1.5910e+04\n",
      "Epoch 22050, Training-Loss 1.6319e+03, Data-loss 6.0733e+02                  , pde-loss 1.2505e+03, initc-loss 1.3551e+04                    bc_loss 8.7653e+04\n",
      "Epoch 22060, Training-Loss 7.0530e+02, Data-loss 3.6814e+02                  , pde-loss 1.2642e+03, initc-loss 1.3583e+04                    bc_loss 1.8869e+04\n",
      "Epoch 22070, Training-Loss 8.5110e+02, Data-loss 5.8168e+02                  , pde-loss 1.5071e+03, initc-loss 1.3679e+04                    bc_loss 1.1755e+04\n",
      "Epoch 22080, Training-Loss 9.7603e+02, Data-loss 6.2563e+02                  , pde-loss 1.2696e+03, initc-loss 1.3540e+04                    bc_loss 2.0231e+04\n",
      "Epoch 22090, Training-Loss 2.0463e+04, Data-loss 3.2984e+03                  , pde-loss 6.0412e+02, initc-loss 2.6690e+04                    bc_loss 1.6892e+06\n",
      "Epoch 22100, Training-Loss 4.8730e+03, Data-loss 2.9034e+03                  , pde-loss 4.6051e+02, initc-loss 1.1973e+04                    bc_loss 1.8453e+05\n",
      "Epoch 22110, Training-Loss 2.7181e+03, Data-loss 1.8011e+03                  , pde-loss 1.4829e+03, initc-loss 9.4608e+03                    bc_loss 8.0754e+04\n",
      "Epoch 22120, Training-Loss 2.2302e+03, Data-loss 9.9255e+02                  , pde-loss 1.6124e+03, initc-loss 1.0702e+04                    bc_loss 1.1145e+05\n",
      "Epoch 22130, Training-Loss 3.1391e+03, Data-loss 1.3465e+03                  , pde-loss 2.4043e+03, initc-loss 1.3560e+04                    bc_loss 1.6329e+05\n",
      "Epoch 22140, Training-Loss 4.4068e+03, Data-loss 9.9996e+02                  , pde-loss 2.7364e+03, initc-loss 1.6596e+04                    bc_loss 3.2135e+05\n",
      "Epoch 22150, Training-Loss 1.8209e+03, Data-loss 1.1364e+03                  , pde-loss 1.4285e+03, initc-loss 1.2781e+04                    bc_loss 5.4236e+04\n",
      "Epoch 22160, Training-Loss 1.6333e+03, Data-loss 1.2963e+03                  , pde-loss 7.0654e+02, initc-loss 1.3074e+04                    bc_loss 1.9923e+04\n",
      "Epoch 22170, Training-Loss 2.7309e+03, Data-loss 1.9871e+03                  , pde-loss 1.3206e+03, initc-loss 1.8869e+04                    bc_loss 5.4185e+04\n",
      "Epoch 22180, Training-Loss 1.9661e+03, Data-loss 1.1732e+03                  , pde-loss 1.3660e+03, initc-loss 1.4518e+04                    bc_loss 6.3408e+04\n",
      "Epoch 22190, Training-Loss 6.7332e+03, Data-loss 2.0511e+03                  , pde-loss 7.9928e+02, initc-loss 1.5799e+04                    bc_loss 4.5161e+05\n",
      "Epoch 22200, Training-Loss 4.6748e+03, Data-loss 2.9860e+03                  , pde-loss 6.4322e+02, initc-loss 1.2704e+04                    bc_loss 1.5553e+05\n",
      "Epoch 22210, Training-Loss 1.6787e+03, Data-loss 1.2972e+03                  , pde-loss 1.5262e+03, initc-loss 1.6340e+04                    bc_loss 2.0287e+04\n",
      "Epoch 22220, Training-Loss 9.2177e+02, Data-loss 5.2695e+02                  , pde-loss 1.8260e+03, initc-loss 1.4581e+04                    bc_loss 2.3075e+04\n",
      "Epoch 22230, Training-Loss 8.2301e+02, Data-loss 4.3880e+02                  , pde-loss 1.6383e+03, initc-loss 1.2267e+04                    bc_loss 2.4516e+04\n",
      "Epoch 22240, Training-Loss 1.2941e+03, Data-loss 6.0497e+02                  , pde-loss 1.6536e+03, initc-loss 1.4693e+04                    bc_loss 5.2570e+04\n",
      "Epoch 22250, Training-Loss 1.1535e+03, Data-loss 9.3055e+02                  , pde-loss 1.5641e+03, initc-loss 1.3775e+04                    bc_loss 6.9563e+03\n",
      "Epoch 22260, Training-Loss 4.0758e+03, Data-loss 1.7842e+03                  , pde-loss 1.3263e+03, initc-loss 1.5219e+04                    bc_loss 2.1262e+05\n",
      "Epoch 22270, Training-Loss 1.0604e+03, Data-loss 7.4855e+02                  , pde-loss 1.4976e+03, initc-loss 1.0240e+04                    bc_loss 1.9448e+04\n",
      "Epoch 22280, Training-Loss 8.3100e+02, Data-loss 5.9536e+02                  , pde-loss 1.3527e+03, initc-loss 1.1791e+04                    bc_loss 1.0420e+04\n",
      "Epoch 22290, Training-Loss 1.5703e+03, Data-loss 1.0858e+03                  , pde-loss 1.2990e+03, initc-loss 1.6289e+04                    bc_loss 3.0856e+04\n",
      "Epoch 22300, Training-Loss 9.6059e+02, Data-loss 5.9045e+02                  , pde-loss 1.5488e+03, initc-loss 1.3638e+04                    bc_loss 2.1827e+04\n",
      "Epoch 22310, Training-Loss 1.0099e+03, Data-loss 6.7261e+02                  , pde-loss 1.5257e+03, initc-loss 1.2913e+04                    bc_loss 1.9294e+04\n",
      "Epoch 22320, Training-Loss 3.3875e+03, Data-loss 9.3786e+02                  , pde-loss 1.2198e+03, initc-loss 1.7231e+04                    bc_loss 2.2652e+05\n",
      "Epoch 22330, Training-Loss 9.9661e+03, Data-loss 5.5114e+03                  , pde-loss 1.3314e+02, initc-loss 2.1379e+04                    bc_loss 4.2395e+05\n",
      "Epoch 22340, Training-Loss 7.9811e+03, Data-loss 3.7155e+03                  , pde-loss 1.9011e+02, initc-loss 1.7928e+04                    bc_loss 4.0843e+05\n",
      "Epoch 22350, Training-Loss 4.2114e+03, Data-loss 2.8811e+03                  , pde-loss 2.6704e+03, initc-loss 1.8352e+04                    bc_loss 1.1201e+05\n",
      "Epoch 22360, Training-Loss 3.9371e+03, Data-loss 3.2915e+03                  , pde-loss 1.4841e+03, initc-loss 1.9592e+04                    bc_loss 4.3490e+04\n",
      "Epoch 22370, Training-Loss 2.9895e+03, Data-loss 2.4420e+03                  , pde-loss 1.0611e+03, initc-loss 1.6186e+04                    bc_loss 3.7498e+04\n",
      "Epoch 22380, Training-Loss 2.1539e+03, Data-loss 1.6478e+03                  , pde-loss 1.4684e+03, initc-loss 1.4328e+04                    bc_loss 3.4817e+04\n",
      "Epoch 22390, Training-Loss 3.3008e+03, Data-loss 2.8050e+03                  , pde-loss 1.3781e+03, initc-loss 1.5149e+04                    bc_loss 3.3052e+04\n",
      "Epoch 22400, Training-Loss 1.4454e+03, Data-loss 9.3498e+02                  , pde-loss 1.2676e+03, initc-loss 1.4800e+04                    bc_loss 3.4977e+04\n",
      "Epoch 22410, Training-Loss 2.3113e+03, Data-loss 4.7300e+02                  , pde-loss 1.3154e+03, initc-loss 1.5269e+04                    bc_loss 1.6725e+05\n",
      "Epoch 22420, Training-Loss 1.0582e+04, Data-loss 2.8321e+03                  , pde-loss 4.9800e+02, initc-loss 2.1252e+04                    bc_loss 7.5321e+05\n",
      "Epoch 22430, Training-Loss 5.8638e+03, Data-loss 3.4465e+03                  , pde-loss 1.5170e+03, initc-loss 1.6947e+04                    bc_loss 2.2326e+05\n",
      "Epoch 22440, Training-Loss 1.3080e+04, Data-loss 4.8087e+03                  , pde-loss 5.0363e+03, initc-loss 2.2941e+04                    bc_loss 7.9919e+05\n",
      "Epoch 22450, Training-Loss 6.1602e+03, Data-loss 3.0425e+03                  , pde-loss 3.7761e+03, initc-loss 1.1918e+04                    bc_loss 2.9608e+05\n",
      "Epoch 22460, Training-Loss 3.8097e+03, Data-loss 3.3935e+03                  , pde-loss 9.1944e+02, initc-loss 1.7197e+04                    bc_loss 2.3504e+04\n",
      "Epoch 22470, Training-Loss 3.0471e+03, Data-loss 2.6233e+03                  , pde-loss 8.0458e+02, initc-loss 1.7939e+04                    bc_loss 2.3634e+04\n",
      "Epoch 22480, Training-Loss 2.7198e+03, Data-loss 1.9907e+03                  , pde-loss 1.4865e+03, initc-loss 1.8514e+04                    bc_loss 5.2907e+04\n",
      "Epoch 22490, Training-Loss 3.1922e+03, Data-loss 2.3234e+03                  , pde-loss 1.3862e+03, initc-loss 1.9903e+04                    bc_loss 6.5592e+04\n",
      "Epoch 22500, Training-Loss 1.0133e+03, Data-loss 7.0926e+02                  , pde-loss 1.1200e+03, initc-loss 1.3257e+04                    bc_loss 1.6032e+04\n",
      "Epoch 22510, Training-Loss 1.9701e+03, Data-loss 1.5485e+03                  , pde-loss 1.0295e+03, initc-loss 1.4146e+04                    bc_loss 2.6983e+04\n",
      "Epoch 22520, Training-Loss 6.0038e+03, Data-loss 6.8090e+02                  , pde-loss 1.4417e+03, initc-loss 1.1798e+04                    bc_loss 5.1905e+05\n",
      "Epoch 22530, Training-Loss 1.5900e+03, Data-loss 1.1075e+03                  , pde-loss 1.8814e+03, initc-loss 1.1081e+04                    bc_loss 3.5291e+04\n",
      "Epoch 22540, Training-Loss 1.3218e+03, Data-loss 9.2639e+02                  , pde-loss 1.4730e+03, initc-loss 1.1884e+04                    bc_loss 2.6182e+04\n",
      "Epoch 22550, Training-Loss 7.2295e+02, Data-loss 4.2044e+02                  , pde-loss 1.0098e+03, initc-loss 1.1768e+04                    bc_loss 1.7473e+04\n",
      "Epoch 22560, Training-Loss 1.0095e+03, Data-loss 7.4517e+02                  , pde-loss 1.1490e+03, initc-loss 1.2572e+04                    bc_loss 1.2715e+04\n",
      "Epoch 22570, Training-Loss 1.2245e+03, Data-loss 4.1803e+02                  , pde-loss 1.5162e+03, initc-loss 1.7047e+04                    bc_loss 6.2086e+04\n",
      "Epoch 22580, Training-Loss 9.4114e+03, Data-loss 1.8754e+03                  , pde-loss 1.3642e+03, initc-loss 2.1120e+04                    bc_loss 7.3112e+05\n",
      "Epoch 22590, Training-Loss 1.1667e+04, Data-loss 1.0005e+04                  , pde-loss 2.4818e+02, initc-loss 1.4758e+04                    bc_loss 1.5126e+05\n",
      "Epoch 22600, Training-Loss 4.6521e+03, Data-loss 3.5043e+03                  , pde-loss 2.7538e+02, initc-loss 1.9064e+04                    bc_loss 9.5440e+04\n",
      "Epoch 22610, Training-Loss 4.3311e+03, Data-loss 3.5757e+03                  , pde-loss 1.8842e+03, initc-loss 2.0614e+04                    bc_loss 5.3048e+04\n",
      "Epoch 22620, Training-Loss 2.7343e+03, Data-loss 2.2536e+03                  , pde-loss 2.1639e+03, initc-loss 2.1119e+04                    bc_loss 2.4789e+04\n",
      "Epoch 22630, Training-Loss 1.1928e+03, Data-loss 8.2899e+02                  , pde-loss 1.5587e+03, initc-loss 1.6061e+04                    bc_loss 1.8765e+04\n",
      "Epoch 22640, Training-Loss 2.5909e+03, Data-loss 2.2223e+03                  , pde-loss 1.6484e+03, initc-loss 1.3208e+04                    bc_loss 2.1999e+04\n",
      "Epoch 22650, Training-Loss 1.0646e+04, Data-loss 3.5374e+03                  , pde-loss 2.1059e+03, initc-loss 2.6266e+04                    bc_loss 6.8246e+05\n",
      "Epoch 22660, Training-Loss 6.4383e+03, Data-loss 2.4868e+03                  , pde-loss 2.6899e+03, initc-loss 1.0322e+04                    bc_loss 3.8214e+05\n",
      "Epoch 22670, Training-Loss 9.3767e+03, Data-loss 1.8899e+03                  , pde-loss 7.6790e+02, initc-loss 1.5994e+04                    bc_loss 7.3192e+05\n",
      "Epoch 22680, Training-Loss 1.1142e+04, Data-loss 5.6299e+03                  , pde-loss 1.6733e+02, initc-loss 2.9901e+04                    bc_loss 5.2116e+05\n",
      "Epoch 22690, Training-Loss 6.9419e+03, Data-loss 1.8681e+03                  , pde-loss 1.4983e+03, initc-loss 1.3943e+04                    bc_loss 4.9193e+05\n",
      "Epoch 22700, Training-Loss 4.6404e+03, Data-loss 3.5549e+03                  , pde-loss 4.1383e+03, initc-loss 1.0579e+04                    bc_loss 9.3842e+04\n",
      "Epoch 22710, Training-Loss 2.3365e+03, Data-loss 1.2565e+03                  , pde-loss 1.2400e+03, initc-loss 1.5716e+04                    bc_loss 9.1051e+04\n",
      "Epoch 22720, Training-Loss 2.4963e+03, Data-loss 1.9978e+03                  , pde-loss 4.9830e+02, initc-loss 1.6324e+04                    bc_loss 3.3022e+04\n",
      "Epoch 22730, Training-Loss 2.0370e+03, Data-loss 1.5282e+03                  , pde-loss 8.6303e+02, initc-loss 1.6113e+04                    bc_loss 3.3900e+04\n",
      "Epoch 22740, Training-Loss 3.0987e+03, Data-loss 2.6365e+03                  , pde-loss 1.1806e+03, initc-loss 1.4905e+04                    bc_loss 3.0131e+04\n",
      "Epoch 22750, Training-Loss 1.2974e+03, Data-loss 8.9346e+02                  , pde-loss 1.5510e+03, initc-loss 1.4332e+04                    bc_loss 2.4514e+04\n",
      "Epoch 22760, Training-Loss 1.0751e+03, Data-loss 6.9980e+02                  , pde-loss 1.5506e+03, initc-loss 1.3214e+04                    bc_loss 2.2765e+04\n",
      "Epoch 22770, Training-Loss 1.7015e+03, Data-loss 1.3361e+03                  , pde-loss 1.2984e+03, initc-loss 1.3637e+04                    bc_loss 2.1603e+04\n",
      "Epoch 22780, Training-Loss 1.6944e+03, Data-loss 1.1276e+03                  , pde-loss 1.3856e+03, initc-loss 1.2458e+04                    bc_loss 4.2845e+04\n",
      "Epoch 22790, Training-Loss 3.7112e+03, Data-loss 1.2621e+03                  , pde-loss 1.1536e+03, initc-loss 1.4566e+04                    bc_loss 2.2919e+05\n",
      "Epoch 22800, Training-Loss 1.1038e+04, Data-loss 2.5980e+03                  , pde-loss 5.1800e+02, initc-loss 1.9758e+04                    bc_loss 8.2372e+05\n",
      "Epoch 22810, Training-Loss 1.8965e+03, Data-loss 1.1904e+03                  , pde-loss 9.0497e+02, initc-loss 1.3064e+04                    bc_loss 5.6640e+04\n",
      "Epoch 22820, Training-Loss 1.5431e+03, Data-loss 1.0406e+03                  , pde-loss 1.8089e+03, initc-loss 1.3185e+04                    bc_loss 3.5259e+04\n",
      "Epoch 22830, Training-Loss 2.1751e+03, Data-loss 1.6806e+03                  , pde-loss 1.5758e+03, initc-loss 1.3202e+04                    bc_loss 3.4670e+04\n",
      "Epoch 22840, Training-Loss 1.4040e+03, Data-loss 9.7994e+02                  , pde-loss 1.3680e+03, initc-loss 1.5151e+04                    bc_loss 2.5884e+04\n",
      "Epoch 22850, Training-Loss 1.2445e+03, Data-loss 8.4477e+02                  , pde-loss 1.5567e+03, initc-loss 1.3941e+04                    bc_loss 2.4474e+04\n",
      "Epoch 22860, Training-Loss 1.7506e+03, Data-loss 1.2960e+03                  , pde-loss 1.6628e+03, initc-loss 1.2732e+04                    bc_loss 3.1063e+04\n",
      "Epoch 22870, Training-Loss 1.2215e+04, Data-loss 1.7168e+03                  , pde-loss 2.3112e+03, initc-loss 1.9415e+04                    bc_loss 1.0281e+06\n",
      "Epoch 22880, Training-Loss 3.8933e+03, Data-loss 2.1080e+03                  , pde-loss 2.8058e+03, initc-loss 1.0499e+04                    bc_loss 1.6522e+05\n",
      "Epoch 22890, Training-Loss 1.8821e+03, Data-loss 1.2228e+03                  , pde-loss 1.2009e+03, initc-loss 1.3188e+04                    bc_loss 5.1540e+04\n",
      "Epoch 22900, Training-Loss 1.2285e+03, Data-loss 8.2076e+02                  , pde-loss 1.2308e+03, initc-loss 1.4205e+04                    bc_loss 2.5336e+04\n",
      "Epoch 22910, Training-Loss 1.1710e+03, Data-loss 7.8317e+02                  , pde-loss 1.5201e+03, initc-loss 1.5058e+04                    bc_loss 2.2204e+04\n",
      "Epoch 22920, Training-Loss 1.2042e+03, Data-loss 8.9317e+02                  , pde-loss 1.2083e+03, initc-loss 1.4388e+04                    bc_loss 1.5504e+04\n",
      "Epoch 22930, Training-Loss 1.4206e+03, Data-loss 4.7494e+02                  , pde-loss 1.0400e+03, initc-loss 1.2264e+04                    bc_loss 8.1263e+04\n",
      "Epoch 22940, Training-Loss 1.9382e+04, Data-loss 1.2111e+03                  , pde-loss 5.5773e+02, initc-loss 1.6777e+04                    bc_loss 1.7997e+06\n",
      "Epoch 22950, Training-Loss 3.8376e+03, Data-loss 2.4384e+03                  , pde-loss 4.2255e+02, initc-loss 1.0567e+04                    bc_loss 1.2893e+05\n",
      "Epoch 22960, Training-Loss 2.4300e+03, Data-loss 1.8405e+03                  , pde-loss 1.3289e+03, initc-loss 1.5078e+04                    bc_loss 4.2546e+04\n",
      "Epoch 22970, Training-Loss 1.4649e+03, Data-loss 1.1101e+03                  , pde-loss 1.5160e+03, initc-loss 1.3786e+04                    bc_loss 2.0179e+04\n",
      "Epoch 22980, Training-Loss 1.6705e+03, Data-loss 1.1579e+03                  , pde-loss 1.4832e+03, initc-loss 1.5208e+04                    bc_loss 3.4578e+04\n",
      "Epoch 22990, Training-Loss 1.9813e+03, Data-loss 1.0118e+03                  , pde-loss 1.4228e+03, initc-loss 1.4353e+04                    bc_loss 8.1166e+04\n",
      "Epoch 23000, Training-Loss 1.5453e+03, Data-loss 1.2092e+03                  , pde-loss 1.9624e+03, initc-loss 1.3561e+04                    bc_loss 1.8095e+04\n",
      "Epoch 23010, Training-Loss 9.5071e+02, Data-loss 6.0987e+02                  , pde-loss 1.8834e+03, initc-loss 1.3979e+04                    bc_loss 1.8221e+04\n",
      "Epoch 23020, Training-Loss 9.6140e+02, Data-loss 6.8178e+02                  , pde-loss 1.1214e+03, initc-loss 1.2697e+04                    bc_loss 1.4143e+04\n",
      "Epoch 23030, Training-Loss 1.0241e+03, Data-loss 7.4887e+02                  , pde-loss 1.0712e+03, initc-loss 1.1619e+04                    bc_loss 1.4829e+04\n",
      "Epoch 23040, Training-Loss 1.0717e+03, Data-loss 7.9425e+02                  , pde-loss 1.3345e+03, initc-loss 1.3866e+04                    bc_loss 1.2543e+04\n",
      "Epoch 23050, Training-Loss 1.3038e+03, Data-loss 9.8599e+02                  , pde-loss 1.3142e+03, initc-loss 1.3479e+04                    bc_loss 1.6986e+04\n",
      "Epoch 23060, Training-Loss 1.3430e+03, Data-loss 8.7605e+02                  , pde-loss 1.2913e+03, initc-loss 1.4020e+04                    bc_loss 3.1386e+04\n",
      "Epoch 23070, Training-Loss 1.4535e+04, Data-loss 4.2071e+03                  , pde-loss 2.3820e+03, initc-loss 2.8003e+04                    bc_loss 1.0024e+06\n",
      "Epoch 23080, Training-Loss 9.1258e+03, Data-loss 3.1026e+03                  , pde-loss 2.7561e+03, initc-loss 1.0346e+04                    bc_loss 5.8922e+05\n",
      "Epoch 23090, Training-Loss 1.1558e+04, Data-loss 3.1914e+03                  , pde-loss 5.3176e+02, initc-loss 1.8272e+04                    bc_loss 8.1785e+05\n",
      "Epoch 23100, Training-Loss 3.4334e+03, Data-loss 2.5737e+03                  , pde-loss 3.3640e+02, initc-loss 1.3245e+04                    bc_loss 7.2394e+04\n",
      "Epoch 23110, Training-Loss 2.1006e+03, Data-loss 1.3692e+03                  , pde-loss 2.1226e+03, initc-loss 1.4847e+04                    bc_loss 5.6176e+04\n",
      "Epoch 23120, Training-Loss 2.9195e+03, Data-loss 1.7292e+03                  , pde-loss 1.4912e+03, initc-loss 1.6405e+04                    bc_loss 1.0114e+05\n",
      "Epoch 23130, Training-Loss 1.6019e+03, Data-loss 1.2267e+03                  , pde-loss 1.0848e+03, initc-loss 1.4562e+04                    bc_loss 2.1870e+04\n",
      "Epoch 23140, Training-Loss 7.1110e+02, Data-loss 4.0373e+02                  , pde-loss 1.3884e+03, initc-loss 1.5535e+04                    bc_loss 1.3814e+04\n",
      "Epoch 23150, Training-Loss 9.2795e+02, Data-loss 6.5480e+02                  , pde-loss 1.4410e+03, initc-loss 1.1787e+04                    bc_loss 1.4087e+04\n",
      "Epoch 23160, Training-Loss 7.0817e+03, Data-loss 9.8943e+02                  , pde-loss 9.2776e+02, initc-loss 1.8020e+04                    bc_loss 5.9028e+05\n",
      "Epoch 23170, Training-Loss 5.1278e+03, Data-loss 1.5702e+03                  , pde-loss 4.6763e+02, initc-loss 1.4016e+04                    bc_loss 3.4127e+05\n",
      "Epoch 23180, Training-Loss 2.0745e+03, Data-loss 1.6732e+03                  , pde-loss 1.2632e+03, initc-loss 1.6141e+04                    bc_loss 2.2729e+04\n",
      "Epoch 23190, Training-Loss 2.5333e+03, Data-loss 2.0791e+03                  , pde-loss 1.5116e+03, initc-loss 1.5569e+04                    bc_loss 2.8344e+04\n",
      "Epoch 23200, Training-Loss 1.7655e+03, Data-loss 1.3781e+03                  , pde-loss 1.3873e+03, initc-loss 1.4591e+04                    bc_loss 2.2753e+04\n",
      "Epoch 23210, Training-Loss 1.5237e+03, Data-loss 1.1693e+03                  , pde-loss 1.5313e+03, initc-loss 1.3315e+04                    bc_loss 2.0600e+04\n",
      "Epoch 23220, Training-Loss 7.1067e+03, Data-loss 1.3848e+03                  , pde-loss 1.6858e+03, initc-loss 1.2432e+04                    bc_loss 5.5807e+05\n",
      "Epoch 23230, Training-Loss 1.6633e+03, Data-loss 1.1418e+03                  , pde-loss 1.7747e+03, initc-loss 1.2184e+04                    bc_loss 3.8195e+04\n",
      "Epoch 23240, Training-Loss 4.1756e+03, Data-loss 1.1604e+03                  , pde-loss 1.7779e+03, initc-loss 1.5045e+04                    bc_loss 2.8470e+05\n",
      "Epoch 23250, Training-Loss 1.4302e+03, Data-loss 9.2897e+02                  , pde-loss 8.5018e+02, initc-loss 1.3156e+04                    bc_loss 3.6115e+04\n",
      "Epoch 23260, Training-Loss 7.0965e+03, Data-loss 1.8499e+03                  , pde-loss 4.8251e+02, initc-loss 1.5285e+04                    bc_loss 5.0889e+05\n",
      "Epoch 23270, Training-Loss 1.9877e+03, Data-loss 1.3600e+03                  , pde-loss 8.4611e+02, initc-loss 1.1255e+04                    bc_loss 5.0662e+04\n",
      "Epoch 23280, Training-Loss 1.7495e+03, Data-loss 1.2326e+03                  , pde-loss 1.5750e+03, initc-loss 1.0406e+04                    bc_loss 3.9706e+04\n",
      "Epoch 23290, Training-Loss 1.7086e+03, Data-loss 1.1824e+03                  , pde-loss 1.6760e+03, initc-loss 1.5058e+04                    bc_loss 3.5893e+04\n",
      "Epoch 23300, Training-Loss 1.0899e+03, Data-loss 6.0104e+02                  , pde-loss 1.4399e+03, initc-loss 1.2634e+04                    bc_loss 3.4814e+04\n",
      "Epoch 23310, Training-Loss 8.8958e+02, Data-loss 5.4829e+02                  , pde-loss 1.4689e+03, initc-loss 1.3714e+04                    bc_loss 1.8946e+04\n",
      "Epoch 23320, Training-Loss 9.7634e+02, Data-loss 6.3494e+02                  , pde-loss 1.3648e+03, initc-loss 1.1708e+04                    bc_loss 2.1067e+04\n",
      "Epoch 23330, Training-Loss 3.8200e+03, Data-loss 1.1106e+03                  , pde-loss 1.0723e+03, initc-loss 1.3744e+04                    bc_loss 2.5613e+05\n",
      "Epoch 23340, Training-Loss 2.5275e+03, Data-loss 5.2512e+02                  , pde-loss 7.8625e+02, initc-loss 1.6560e+04                    bc_loss 1.8290e+05\n",
      "Epoch 23350, Training-Loss 1.2954e+03, Data-loss 9.4685e+02                  , pde-loss 1.0247e+03, initc-loss 1.3448e+04                    bc_loss 2.0383e+04\n",
      "Epoch 23360, Training-Loss 1.2321e+03, Data-loss 8.8901e+02                  , pde-loss 1.8969e+03, initc-loss 1.3258e+04                    bc_loss 1.9155e+04\n",
      "Epoch 23370, Training-Loss 9.9671e+02, Data-loss 7.0931e+02                  , pde-loss 1.5244e+03, initc-loss 1.3274e+04                    bc_loss 1.3941e+04\n",
      "Epoch 23380, Training-Loss 1.6790e+03, Data-loss 5.3186e+02                  , pde-loss 1.2678e+03, initc-loss 1.1943e+04                    bc_loss 1.0151e+05\n",
      "Epoch 23390, Training-Loss 4.0871e+03, Data-loss 8.7333e+02                  , pde-loss 1.5564e+03, initc-loss 1.2369e+04                    bc_loss 3.0745e+05\n",
      "Epoch 23400, Training-Loss 7.2770e+03, Data-loss 4.5381e+03                  , pde-loss 3.1006e+03, initc-loss 2.4432e+04                    bc_loss 2.4636e+05\n",
      "Epoch 23410, Training-Loss 4.9062e+03, Data-loss 2.4387e+03                  , pde-loss 2.2284e+03, initc-loss 1.2521e+04                    bc_loss 2.3200e+05\n",
      "Epoch 23420, Training-Loss 1.2114e+04, Data-loss 3.2174e+03                  , pde-loss 3.9634e+02, initc-loss 2.2174e+04                    bc_loss 8.6712e+05\n",
      "Epoch 23430, Training-Loss 5.4445e+03, Data-loss 2.9115e+03                  , pde-loss 2.8900e+02, initc-loss 1.5593e+04                    bc_loss 2.3742e+05\n",
      "Epoch 23440, Training-Loss 3.7112e+03, Data-loss 2.4344e+03                  , pde-loss 2.8249e+03, initc-loss 1.5798e+04                    bc_loss 1.0906e+05\n",
      "Epoch 23450, Training-Loss 2.1957e+03, Data-loss 1.0995e+03                  , pde-loss 2.2651e+03, initc-loss 1.5298e+04                    bc_loss 9.2053e+04\n",
      "Epoch 23460, Training-Loss 2.2419e+03, Data-loss 1.3173e+03                  , pde-loss 1.2468e+03, initc-loss 1.5545e+04                    bc_loss 7.5674e+04\n",
      "Epoch 23470, Training-Loss 2.7035e+03, Data-loss 9.9696e+02                  , pde-loss 1.3974e+03, initc-loss 1.3270e+04                    bc_loss 1.5598e+05\n",
      "Epoch 23480, Training-Loss 8.2712e+03, Data-loss 2.1742e+03                  , pde-loss 2.9213e+03, initc-loss 1.6643e+04                    bc_loss 5.9014e+05\n",
      "Epoch 23490, Training-Loss 4.1957e+03, Data-loss 1.5170e+03                  , pde-loss 1.6412e+03, initc-loss 1.4842e+04                    bc_loss 2.5139e+05\n",
      "Epoch 23500, Training-Loss 6.5328e+03, Data-loss 2.4377e+03                  , pde-loss 4.9966e+02, initc-loss 1.8989e+04                    bc_loss 3.9002e+05\n",
      "Epoch 23510, Training-Loss 6.3059e+03, Data-loss 2.3533e+03                  , pde-loss 4.7939e+02, initc-loss 1.6738e+04                    bc_loss 3.7805e+05\n",
      "Epoch 23520, Training-Loss 1.9274e+03, Data-loss 1.5237e+03                  , pde-loss 1.9909e+03, initc-loss 1.3164e+04                    bc_loss 2.5214e+04\n",
      "Epoch 23530, Training-Loss 2.2052e+03, Data-loss 1.8093e+03                  , pde-loss 2.0721e+03, initc-loss 1.5450e+04                    bc_loss 2.2067e+04\n",
      "Epoch 23540, Training-Loss 1.0978e+03, Data-loss 6.4906e+02                  , pde-loss 1.1979e+03, initc-loss 1.4288e+04                    bc_loss 2.9387e+04\n",
      "Epoch 23550, Training-Loss 1.2750e+03, Data-loss 9.0285e+02                  , pde-loss 1.2260e+03, initc-loss 1.4983e+04                    bc_loss 2.1006e+04\n",
      "Epoch 23560, Training-Loss 1.1999e+03, Data-loss 8.9615e+02                  , pde-loss 1.3684e+03, initc-loss 1.3152e+04                    bc_loss 1.5850e+04\n",
      "Epoch 23570, Training-Loss 8.7408e+02, Data-loss 3.2853e+02                  , pde-loss 1.5477e+03, initc-loss 1.4595e+04                    bc_loss 3.8413e+04\n",
      "Epoch 23580, Training-Loss 1.2438e+03, Data-loss 9.5694e+02                  , pde-loss 1.6197e+03, initc-loss 1.1794e+04                    bc_loss 1.5277e+04\n",
      "Epoch 23590, Training-Loss 1.4219e+03, Data-loss 1.0884e+03                  , pde-loss 1.2792e+03, initc-loss 1.3656e+04                    bc_loss 1.8422e+04\n",
      "Epoch 23600, Training-Loss 1.0952e+04, Data-loss 1.4249e+03                  , pde-loss 6.5628e+02, initc-loss 1.9769e+04                    bc_loss 9.3229e+05\n",
      "Epoch 23610, Training-Loss 6.2970e+03, Data-loss 2.8865e+03                  , pde-loss 2.3924e+02, initc-loss 1.2223e+04                    bc_loss 3.2859e+05\n",
      "Epoch 23620, Training-Loss 2.0409e+03, Data-loss 1.5032e+03                  , pde-loss 1.2601e+03, initc-loss 1.5092e+04                    bc_loss 3.7419e+04\n",
      "Epoch 23630, Training-Loss 2.3853e+03, Data-loss 1.9262e+03                  , pde-loss 1.3089e+03, initc-loss 1.4498e+04                    bc_loss 3.0100e+04\n",
      "Epoch 23640, Training-Loss 1.7322e+03, Data-loss 1.2033e+03                  , pde-loss 1.7897e+03, initc-loss 1.5683e+04                    bc_loss 3.5414e+04\n",
      "Epoch 23650, Training-Loss 8.5153e+02, Data-loss 5.4756e+02                  , pde-loss 1.3397e+03, initc-loss 1.2399e+04                    bc_loss 1.6659e+04\n",
      "Epoch 23660, Training-Loss 9.6555e+02, Data-loss 6.4033e+02                  , pde-loss 1.3717e+03, initc-loss 1.3943e+04                    bc_loss 1.7207e+04\n",
      "Epoch 23670, Training-Loss 2.5241e+03, Data-loss 1.3720e+03                  , pde-loss 1.7249e+03, initc-loss 1.5835e+04                    bc_loss 9.7656e+04\n",
      "Epoch 23680, Training-Loss 1.6435e+03, Data-loss 7.3296e+02                  , pde-loss 1.6988e+03, initc-loss 1.4643e+04                    bc_loss 7.4713e+04\n",
      "Epoch 23690, Training-Loss 1.1453e+03, Data-loss 8.8076e+02                  , pde-loss 8.2819e+02, initc-loss 1.4822e+04                    bc_loss 1.0808e+04\n",
      "Epoch 23700, Training-Loss 1.1093e+03, Data-loss 8.4823e+02                  , pde-loss 9.3665e+02, initc-loss 1.5630e+04                    bc_loss 9.5380e+03\n",
      "Epoch 23710, Training-Loss 1.1229e+03, Data-loss 5.1982e+02                  , pde-loss 1.2440e+03, initc-loss 1.3567e+04                    bc_loss 4.5495e+04\n",
      "Epoch 23720, Training-Loss 7.5226e+03, Data-loss 8.4648e+02                  , pde-loss 1.1486e+03, initc-loss 1.4595e+04                    bc_loss 6.5187e+05\n",
      "Epoch 23730, Training-Loss 8.3095e+03, Data-loss 1.4809e+03                  , pde-loss 4.2013e+02, initc-loss 1.0590e+04                    bc_loss 6.7185e+05\n",
      "Epoch 23740, Training-Loss 1.9390e+03, Data-loss 1.3358e+03                  , pde-loss 1.4044e+03, initc-loss 1.2334e+04                    bc_loss 4.6584e+04\n",
      "Epoch 23750, Training-Loss 1.7753e+03, Data-loss 1.4418e+03                  , pde-loss 1.5541e+03, initc-loss 1.1197e+04                    bc_loss 2.0597e+04\n",
      "Epoch 23760, Training-Loss 1.3358e+03, Data-loss 1.0675e+03                  , pde-loss 1.4951e+03, initc-loss 1.3064e+04                    bc_loss 1.2274e+04\n",
      "Epoch 23770, Training-Loss 1.3781e+03, Data-loss 9.3053e+02                  , pde-loss 1.3217e+03, initc-loss 1.4222e+04                    bc_loss 2.9212e+04\n",
      "Epoch 23780, Training-Loss 1.0403e+03, Data-loss 7.5967e+02                  , pde-loss 1.2309e+03, initc-loss 1.3241e+04                    bc_loss 1.3594e+04\n",
      "Epoch 23790, Training-Loss 8.2608e+03, Data-loss 1.6636e+03                  , pde-loss 1.8402e+03, initc-loss 2.2006e+04                    bc_loss 6.3587e+05\n",
      "Epoch 23800, Training-Loss 1.4257e+03, Data-loss 1.0545e+03                  , pde-loss 1.3558e+03, initc-loss 1.0393e+04                    bc_loss 2.5374e+04\n",
      "Epoch 23810, Training-Loss 1.8726e+03, Data-loss 1.0012e+03                  , pde-loss 8.5058e+02, initc-loss 1.2788e+04                    bc_loss 7.3500e+04\n",
      "Epoch 23820, Training-Loss 9.4192e+02, Data-loss 6.1285e+02                  , pde-loss 1.4849e+03, initc-loss 1.2703e+04                    bc_loss 1.8720e+04\n",
      "Epoch 23830, Training-Loss 9.2305e+03, Data-loss 9.8831e+02                  , pde-loss 1.2544e+03, initc-loss 1.2538e+04                    bc_loss 8.1042e+05\n",
      "Epoch 23840, Training-Loss 6.2692e+03, Data-loss 2.9076e+03                  , pde-loss 4.0826e+02, initc-loss 1.4778e+04                    bc_loss 3.2097e+05\n",
      "Epoch 23850, Training-Loss 3.1741e+03, Data-loss 2.7341e+03                  , pde-loss 1.1966e+03, initc-loss 1.9472e+04                    bc_loss 2.3339e+04\n",
      "Epoch 23860, Training-Loss 2.8028e+03, Data-loss 2.3486e+03                  , pde-loss 1.3874e+03, initc-loss 1.6374e+04                    bc_loss 2.7664e+04\n",
      "Epoch 23870, Training-Loss 1.6588e+03, Data-loss 1.3236e+03                  , pde-loss 1.4308e+03, initc-loss 1.6129e+04                    bc_loss 1.5966e+04\n",
      "Epoch 23880, Training-Loss 1.0817e+03, Data-loss 6.9591e+02                  , pde-loss 1.2529e+03, initc-loss 1.5107e+04                    bc_loss 2.2223e+04\n",
      "Epoch 23890, Training-Loss 2.5308e+03, Data-loss 8.1584e+02                  , pde-loss 1.4444e+03, initc-loss 1.4596e+04                    bc_loss 1.5545e+05\n",
      "Epoch 23900, Training-Loss 1.0010e+03, Data-loss 7.5659e+02                  , pde-loss 1.4217e+03, initc-loss 1.3113e+04                    bc_loss 9.9024e+03\n",
      "Epoch 23910, Training-Loss 1.2191e+03, Data-loss 9.2030e+02                  , pde-loss 1.2597e+03, initc-loss 1.3439e+04                    bc_loss 1.5184e+04\n",
      "Epoch 23920, Training-Loss 9.5510e+02, Data-loss 6.3274e+02                  , pde-loss 1.2545e+03, initc-loss 1.2462e+04                    bc_loss 1.8520e+04\n",
      "Epoch 23930, Training-Loss 5.9106e+02, Data-loss 3.6535e+02                  , pde-loss 1.4691e+03, initc-loss 1.2901e+04                    bc_loss 8.2005e+03\n",
      "Epoch 23940, Training-Loss 7.0626e+02, Data-loss 3.9758e+02                  , pde-loss 1.3680e+03, initc-loss 1.2955e+04                    bc_loss 1.6545e+04\n",
      "Epoch 23950, Training-Loss 3.5888e+03, Data-loss 7.0581e+02                  , pde-loss 1.4333e+03, initc-loss 1.4769e+04                    bc_loss 2.7210e+05\n",
      "Epoch 23960, Training-Loss 1.2047e+04, Data-loss 8.3794e+03                  , pde-loss 3.4292e+03, initc-loss 1.5453e+04                    bc_loss 3.4791e+05\n",
      "Epoch 23970, Training-Loss 7.8541e+03, Data-loss 5.5796e+03                  , pde-loss 8.9196e+02, initc-loss 2.6584e+04                    bc_loss 1.9998e+05\n",
      "Epoch 23980, Training-Loss 1.2097e+04, Data-loss 7.2372e+03                  , pde-loss 2.2623e+02, initc-loss 3.2223e+04                    bc_loss 4.5353e+05\n",
      "Epoch 23990, Training-Loss 2.7984e+03, Data-loss 2.2428e+03                  , pde-loss 1.2364e+03, initc-loss 1.4340e+04                    bc_loss 3.9988e+04\n",
      "Epoch 24000, Training-Loss 3.6178e+03, Data-loss 2.9297e+03                  , pde-loss 2.2672e+03, initc-loss 1.4995e+04                    bc_loss 5.1546e+04\n",
      "Epoch 24010, Training-Loss 3.9603e+03, Data-loss 2.1180e+03                  , pde-loss 1.2786e+03, initc-loss 1.5945e+04                    bc_loss 1.6701e+05\n",
      "Epoch 24020, Training-Loss 1.5261e+03, Data-loss 1.2702e+03                  , pde-loss 1.3880e+03, initc-loss 1.3555e+04                    bc_loss 1.0650e+04\n",
      "Epoch 24030, Training-Loss 1.8639e+03, Data-loss 1.5560e+03                  , pde-loss 1.4169e+03, initc-loss 1.5511e+04                    bc_loss 1.3858e+04\n",
      "Epoch 24040, Training-Loss 1.0824e+04, Data-loss 2.1148e+03                  , pde-loss 9.1184e+02, initc-loss 1.6504e+04                    bc_loss 8.5354e+05\n",
      "Epoch 24050, Training-Loss 4.9283e+03, Data-loss 2.1605e+03                  , pde-loss 3.9263e+02, initc-loss 1.4799e+04                    bc_loss 2.6159e+05\n",
      "Epoch 24060, Training-Loss 2.2617e+03, Data-loss 1.2271e+03                  , pde-loss 1.6472e+03, initc-loss 1.4041e+04                    bc_loss 8.7769e+04\n",
      "Epoch 24070, Training-Loss 2.8840e+03, Data-loss 2.4619e+03                  , pde-loss 9.3875e+02, initc-loss 1.5096e+04                    bc_loss 2.6172e+04\n",
      "Epoch 24080, Training-Loss 1.6328e+03, Data-loss 1.1643e+03                  , pde-loss 1.2775e+03, initc-loss 1.4178e+04                    bc_loss 3.1398e+04\n",
      "Epoch 24090, Training-Loss 9.5519e+02, Data-loss 5.6516e+02                  , pde-loss 1.6711e+03, initc-loss 1.4135e+04                    bc_loss 2.3196e+04\n",
      "Epoch 24100, Training-Loss 8.9452e+02, Data-loss 4.1505e+02                  , pde-loss 1.4935e+03, initc-loss 1.2192e+04                    bc_loss 3.4261e+04\n",
      "Epoch 24110, Training-Loss 2.1629e+03, Data-loss 1.4630e+03                  , pde-loss 1.4996e+03, initc-loss 1.1579e+04                    bc_loss 5.6910e+04\n",
      "Epoch 24120, Training-Loss 2.6120e+03, Data-loss 1.0940e+03                  , pde-loss 2.4573e+03, initc-loss 1.6447e+04                    bc_loss 1.3289e+05\n",
      "Epoch 24130, Training-Loss 6.2498e+03, Data-loss 2.2564e+03                  , pde-loss 3.0237e+03, initc-loss 2.0552e+04                    bc_loss 3.7576e+05\n",
      "Epoch 24140, Training-Loss 2.3153e+03, Data-loss 1.5084e+03                  , pde-loss 1.1004e+03, initc-loss 1.0528e+04                    bc_loss 6.9064e+04\n",
      "Epoch 24150, Training-Loss 2.2912e+03, Data-loss 1.8229e+03                  , pde-loss 7.1759e+02, initc-loss 1.0294e+04                    bc_loss 3.5817e+04\n",
      "Epoch 24160, Training-Loss 2.0409e+03, Data-loss 1.4788e+03                  , pde-loss 6.8069e+02, initc-loss 1.5280e+04                    bc_loss 4.0243e+04\n",
      "Epoch 24170, Training-Loss 5.4822e+03, Data-loss 7.9901e+02                  , pde-loss 1.2773e+03, initc-loss 1.5812e+04                    bc_loss 4.5123e+05\n",
      "Epoch 24180, Training-Loss 3.7605e+03, Data-loss 1.8866e+03                  , pde-loss 7.0723e+02, initc-loss 1.3800e+04                    bc_loss 1.7288e+05\n",
      "Epoch 24190, Training-Loss 1.4316e+03, Data-loss 7.4431e+02                  , pde-loss 1.0888e+03, initc-loss 1.2483e+04                    bc_loss 5.5154e+04\n",
      "Epoch 24200, Training-Loss 1.9537e+03, Data-loss 1.5459e+03                  , pde-loss 1.7508e+03, initc-loss 1.3481e+04                    bc_loss 2.5545e+04\n",
      "Epoch 24210, Training-Loss 9.1296e+02, Data-loss 5.7511e+02                  , pde-loss 1.5914e+03, initc-loss 1.2400e+04                    bc_loss 1.9794e+04\n",
      "Epoch 24220, Training-Loss 1.3496e+03, Data-loss 1.0747e+03                  , pde-loss 1.5641e+03, initc-loss 1.1519e+04                    bc_loss 1.4403e+04\n",
      "Epoch 24230, Training-Loss 9.9339e+02, Data-loss 6.2138e+02                  , pde-loss 1.3397e+03, initc-loss 1.2785e+04                    bc_loss 2.3077e+04\n",
      "Epoch 24240, Training-Loss 5.7629e+03, Data-loss 9.1734e+02                  , pde-loss 1.1269e+03, initc-loss 1.3115e+04                    bc_loss 4.7031e+05\n",
      "Epoch 24250, Training-Loss 1.2733e+04, Data-loss 2.9738e+03                  , pde-loss 6.4150e+02, initc-loss 2.0719e+04                    bc_loss 9.5452e+05\n",
      "Epoch 24260, Training-Loss 2.5925e+03, Data-loss 1.8351e+03                  , pde-loss 2.8457e+02, initc-loss 1.2620e+04                    bc_loss 6.2838e+04\n",
      "Epoch 24270, Training-Loss 3.3015e+03, Data-loss 2.7012e+03                  , pde-loss 1.4283e+03, initc-loss 2.0029e+04                    bc_loss 3.8577e+04\n",
      "Epoch 24280, Training-Loss 2.0967e+03, Data-loss 1.5982e+03                  , pde-loss 1.5037e+03, initc-loss 1.7057e+04                    bc_loss 3.1284e+04\n",
      "Epoch 24290, Training-Loss 1.3554e+03, Data-loss 9.1610e+02                  , pde-loss 1.3338e+03, initc-loss 1.5759e+04                    bc_loss 2.6841e+04\n",
      "Epoch 24300, Training-Loss 1.8685e+03, Data-loss 1.4860e+03                  , pde-loss 1.4816e+03, initc-loss 1.3336e+04                    bc_loss 2.3434e+04\n",
      "Epoch 24310, Training-Loss 2.0910e+03, Data-loss 1.4902e+03                  , pde-loss 1.6856e+03, initc-loss 1.4675e+04                    bc_loss 4.3719e+04\n",
      "Epoch 24320, Training-Loss 1.0265e+03, Data-loss 6.1241e+02                  , pde-loss 1.8282e+03, initc-loss 1.2802e+04                    bc_loss 2.6780e+04\n",
      "Epoch 24330, Training-Loss 1.0142e+03, Data-loss 5.8114e+02                  , pde-loss 1.5016e+03, initc-loss 1.2268e+04                    bc_loss 2.9537e+04\n",
      "Epoch 24340, Training-Loss 5.7432e+03, Data-loss 6.0331e+02                  , pde-loss 1.8919e+03, initc-loss 1.4556e+04                    bc_loss 4.9754e+05\n",
      "Epoch 24350, Training-Loss 5.2756e+03, Data-loss 2.3898e+03                  , pde-loss 3.0788e+03, initc-loss 1.5137e+04                    bc_loss 2.7037e+05\n",
      "Epoch 24360, Training-Loss 2.5512e+03, Data-loss 1.4994e+03                  , pde-loss 1.2318e+03, initc-loss 1.3768e+04                    bc_loss 9.0179e+04\n",
      "Epoch 24370, Training-Loss 1.8228e+03, Data-loss 1.2736e+03                  , pde-loss 9.4319e+02, initc-loss 1.0285e+04                    bc_loss 4.3684e+04\n",
      "Epoch 24380, Training-Loss 3.7676e+03, Data-loss 8.8612e+02                  , pde-loss 8.3475e+02, initc-loss 1.2169e+04                    bc_loss 2.7514e+05\n",
      "Epoch 24390, Training-Loss 7.4552e+03, Data-loss 2.0462e+03                  , pde-loss 7.8089e+02, initc-loss 2.2165e+04                    bc_loss 5.1796e+05\n",
      "Epoch 24400, Training-Loss 2.9607e+03, Data-loss 2.5387e+03                  , pde-loss 8.2048e+02, initc-loss 1.0225e+04                    bc_loss 3.1153e+04\n",
      "Epoch 24410, Training-Loss 1.6089e+03, Data-loss 1.1136e+03                  , pde-loss 1.6217e+03, initc-loss 1.4054e+04                    bc_loss 3.3854e+04\n",
      "Epoch 24420, Training-Loss 2.0007e+03, Data-loss 1.4978e+03                  , pde-loss 1.7030e+03, initc-loss 1.4624e+04                    bc_loss 3.3958e+04\n",
      "Epoch 24430, Training-Loss 1.3181e+03, Data-loss 8.3466e+02                  , pde-loss 1.3848e+03, initc-loss 1.1688e+04                    bc_loss 3.5275e+04\n",
      "Epoch 24440, Training-Loss 7.7499e+02, Data-loss 4.1585e+02                  , pde-loss 1.6290e+03, initc-loss 1.2919e+04                    bc_loss 2.1367e+04\n",
      "Epoch 24450, Training-Loss 1.3630e+03, Data-loss 7.0347e+02                  , pde-loss 1.5660e+03, initc-loss 1.6740e+04                    bc_loss 4.7649e+04\n",
      "Epoch 24460, Training-Loss 2.1689e+03, Data-loss 1.4233e+03                  , pde-loss 1.7130e+03, initc-loss 1.4192e+04                    bc_loss 5.8653e+04\n",
      "Epoch 24470, Training-Loss 1.1868e+03, Data-loss 6.0040e+02                  , pde-loss 1.2125e+03, initc-loss 1.2531e+04                    bc_loss 4.4901e+04\n",
      "Epoch 24480, Training-Loss 1.7832e+03, Data-loss 1.4056e+03                  , pde-loss 5.3830e+02, initc-loss 1.6713e+04                    bc_loss 2.0515e+04\n",
      "Epoch 24490, Training-Loss 6.8188e+03, Data-loss 2.2215e+03                  , pde-loss 4.9429e+02, initc-loss 2.0695e+04                    bc_loss 4.3854e+05\n",
      "Epoch 24500, Training-Loss 3.4128e+03, Data-loss 2.3976e+03                  , pde-loss 1.4734e+03, initc-loss 1.7979e+04                    bc_loss 8.2067e+04\n",
      "Epoch 24510, Training-Loss 1.1475e+03, Data-loss 6.8399e+02                  , pde-loss 2.1283e+03, initc-loss 1.6254e+04                    bc_loss 2.7969e+04\n",
      "Epoch 24520, Training-Loss 1.4566e+03, Data-loss 1.1013e+03                  , pde-loss 1.1757e+03, initc-loss 1.4311e+04                    bc_loss 2.0047e+04\n",
      "Epoch 24530, Training-Loss 1.1103e+03, Data-loss 6.4937e+02                  , pde-loss 1.3520e+03, initc-loss 1.3282e+04                    bc_loss 3.1456e+04\n",
      "Epoch 24540, Training-Loss 1.4288e+03, Data-loss 1.1274e+03                  , pde-loss 1.4780e+03, initc-loss 1.4215e+04                    bc_loss 1.4450e+04\n",
      "Epoch 24550, Training-Loss 9.4753e+02, Data-loss 6.7141e+02                  , pde-loss 1.3491e+03, initc-loss 1.3532e+04                    bc_loss 1.2731e+04\n",
      "Epoch 24560, Training-Loss 1.1348e+03, Data-loss 7.1172e+02                  , pde-loss 1.1364e+03, initc-loss 1.1802e+04                    bc_loss 2.9373e+04\n",
      "Epoch 24570, Training-Loss 1.0170e+03, Data-loss 6.8820e+02                  , pde-loss 1.2480e+03, initc-loss 1.3777e+04                    bc_loss 1.7854e+04\n",
      "Epoch 24580, Training-Loss 1.0366e+03, Data-loss 8.0395e+02                  , pde-loss 1.3607e+03, initc-loss 1.0692e+04                    bc_loss 1.1211e+04\n",
      "Epoch 24590, Training-Loss 8.3872e+02, Data-loss 5.9994e+02                  , pde-loss 1.3133e+03, initc-loss 1.2803e+04                    bc_loss 9.7624e+03\n",
      "Epoch 24600, Training-Loss 6.9146e+02, Data-loss 4.6296e+02                  , pde-loss 1.1237e+03, initc-loss 1.2274e+04                    bc_loss 9.4517e+03\n",
      "Epoch 24610, Training-Loss 1.6960e+03, Data-loss 4.3583e+02                  , pde-loss 1.1525e+03, initc-loss 1.3514e+04                    bc_loss 1.1135e+05\n",
      "Epoch 24620, Training-Loss 1.5053e+04, Data-loss 7.1972e+03                  , pde-loss 4.2948e+02, initc-loss 2.9183e+04                    bc_loss 7.5597e+05\n",
      "Epoch 24630, Training-Loss 3.5825e+03, Data-loss 2.5031e+03                  , pde-loss 1.9516e+03, initc-loss 1.6835e+04                    bc_loss 8.9147e+04\n",
      "Epoch 24640, Training-Loss 2.1238e+03, Data-loss 1.9070e+03                  , pde-loss 1.8398e+03, initc-loss 1.3370e+04                    bc_loss 6.4691e+03\n",
      "Epoch 24650, Training-Loss 2.0778e+03, Data-loss 1.1530e+03                  , pde-loss 1.1886e+03, initc-loss 1.5062e+04                    bc_loss 7.6230e+04\n",
      "Epoch 24660, Training-Loss 7.4116e+02, Data-loss 4.6824e+02                  , pde-loss 1.2283e+03, initc-loss 1.2194e+04                    bc_loss 1.3869e+04\n",
      "Epoch 24670, Training-Loss 6.2864e+03, Data-loss 1.0002e+03                  , pde-loss 1.7443e+03, initc-loss 1.6098e+04                    bc_loss 5.1077e+05\n",
      "Epoch 24680, Training-Loss 2.2391e+03, Data-loss 1.1605e+03                  , pde-loss 1.9741e+03, initc-loss 1.2216e+04                    bc_loss 9.3667e+04\n",
      "Epoch 24690, Training-Loss 2.7256e+03, Data-loss 2.3888e+03                  , pde-loss 9.4441e+02, initc-loss 1.4144e+04                    bc_loss 1.8593e+04\n",
      "Epoch 24700, Training-Loss 1.8125e+03, Data-loss 1.4228e+03                  , pde-loss 1.2682e+03, initc-loss 1.3430e+04                    bc_loss 2.4279e+04\n",
      "Epoch 24710, Training-Loss 8.5728e+02, Data-loss 6.0619e+02                  , pde-loss 1.4533e+03, initc-loss 1.2965e+04                    bc_loss 1.0691e+04\n",
      "Epoch 24720, Training-Loss 1.8227e+03, Data-loss 1.1317e+03                  , pde-loss 1.2548e+03, initc-loss 1.5181e+04                    bc_loss 5.2670e+04\n",
      "Epoch 24730, Training-Loss 8.1351e+02, Data-loss 5.5813e+02                  , pde-loss 1.3143e+03, initc-loss 1.3795e+04                    bc_loss 1.0428e+04\n",
      "Epoch 24740, Training-Loss 8.9431e+02, Data-loss 6.6264e+02                  , pde-loss 1.2711e+03, initc-loss 1.2550e+04                    bc_loss 9.3447e+03\n",
      "Epoch 24750, Training-Loss 1.1753e+03, Data-loss 8.3850e+02                  , pde-loss 1.2790e+03, initc-loss 1.3836e+04                    bc_loss 1.8562e+04\n",
      "Epoch 24760, Training-Loss 9.8873e+03, Data-loss 2.3752e+03                  , pde-loss 8.1483e+02, initc-loss 2.3877e+04                    bc_loss 7.2652e+05\n",
      "Epoch 24770, Training-Loss 1.5074e+03, Data-loss 7.5402e+02                  , pde-loss 6.7242e+02, initc-loss 1.3739e+04                    bc_loss 6.0931e+04\n",
      "Epoch 24780, Training-Loss 9.4825e+02, Data-loss 6.4773e+02                  , pde-loss 1.4033e+03, initc-loss 1.1820e+04                    bc_loss 1.6828e+04\n",
      "Epoch 24790, Training-Loss 1.2416e+03, Data-loss 9.3744e+02                  , pde-loss 1.6911e+03, initc-loss 1.2104e+04                    bc_loss 1.6621e+04\n",
      "Epoch 24800, Training-Loss 7.7724e+02, Data-loss 3.4324e+02                  , pde-loss 1.2569e+03, initc-loss 1.2791e+04                    bc_loss 2.9352e+04\n",
      "Epoch 24810, Training-Loss 6.5375e+02, Data-loss 4.6273e+02                  , pde-loss 1.4569e+03, initc-loss 1.1125e+04                    bc_loss 6.5194e+03\n",
      "Epoch 24820, Training-Loss 9.5345e+02, Data-loss 6.4796e+02                  , pde-loss 1.5235e+03, initc-loss 1.2528e+04                    bc_loss 1.6498e+04\n",
      "Epoch 24830, Training-Loss 1.2805e+04, Data-loss 5.7748e+03                  , pde-loss 2.8563e+03, initc-loss 3.1973e+04                    bc_loss 6.6815e+05\n",
      "Epoch 24840, Training-Loss 4.2948e+03, Data-loss 1.7899e+03                  , pde-loss 1.9070e+03, initc-loss 1.1177e+04                    bc_loss 2.3741e+05\n",
      "Epoch 24850, Training-Loss 5.9270e+03, Data-loss 1.7816e+03                  , pde-loss 5.5426e+02, initc-loss 1.5438e+04                    bc_loss 3.9854e+05\n",
      "Epoch 24860, Training-Loss 1.8566e+03, Data-loss 1.2792e+03                  , pde-loss 9.7977e+02, initc-loss 1.1701e+04                    bc_loss 4.5064e+04\n",
      "Epoch 24870, Training-Loss 1.4233e+03, Data-loss 6.7348e+02                  , pde-loss 1.2289e+03, initc-loss 1.2742e+04                    bc_loss 6.1010e+04\n",
      "Epoch 24880, Training-Loss 1.4400e+04, Data-loss 1.4121e+03                  , pde-loss 8.2258e+02, initc-loss 2.1821e+04                    bc_loss 1.2761e+06\n",
      "Epoch 24890, Training-Loss 6.1582e+03, Data-loss 3.9383e+03                  , pde-loss 5.4887e+02, initc-loss 1.1623e+04                    bc_loss 2.0982e+05\n",
      "Epoch 24900, Training-Loss 1.8895e+03, Data-loss 1.3255e+03                  , pde-loss 1.8118e+03, initc-loss 1.7610e+04                    bc_loss 3.6979e+04\n",
      "Epoch 24910, Training-Loss 1.9679e+03, Data-loss 1.5566e+03                  , pde-loss 1.6803e+03, initc-loss 1.5447e+04                    bc_loss 2.4002e+04\n",
      "Epoch 24920, Training-Loss 3.4096e+03, Data-loss 1.0638e+03                  , pde-loss 1.3285e+03, initc-loss 1.1945e+04                    bc_loss 2.2131e+05\n",
      "Epoch 24930, Training-Loss 1.3141e+03, Data-loss 1.0780e+03                  , pde-loss 1.6496e+03, initc-loss 1.2511e+04                    bc_loss 9.4454e+03\n",
      "Epoch 24940, Training-Loss 1.6263e+03, Data-loss 1.1846e+03                  , pde-loss 1.5855e+03, initc-loss 1.6523e+04                    bc_loss 2.6067e+04\n",
      "Epoch 24950, Training-Loss 2.0889e+03, Data-loss 1.3329e+03                  , pde-loss 1.4554e+03, initc-loss 1.5565e+04                    bc_loss 5.8578e+04\n",
      "Epoch 24960, Training-Loss 1.2227e+03, Data-loss 8.0508e+02                  , pde-loss 9.6469e+02, initc-loss 1.2225e+04                    bc_loss 2.8569e+04\n",
      "Epoch 24970, Training-Loss 1.8221e+03, Data-loss 1.0398e+03                  , pde-loss 6.9278e+02, initc-loss 1.3292e+04                    bc_loss 6.4246e+04\n",
      "Epoch 24980, Training-Loss 7.9251e+03, Data-loss 1.0930e+03                  , pde-loss 9.2165e+02, initc-loss 1.4027e+04                    bc_loss 6.6827e+05\n",
      "Epoch 24990, Training-Loss 4.1101e+03, Data-loss 2.3931e+03                  , pde-loss 9.8464e+02, initc-loss 9.3099e+03                    bc_loss 1.6141e+05\n",
      "Epoch 25000, Training-Loss 1.7244e+03, Data-loss 1.2998e+03                  , pde-loss 1.8034e+03, initc-loss 1.6104e+04                    bc_loss 2.4546e+04\n",
      "Epoch 25010, Training-Loss 1.5422e+03, Data-loss 9.5359e+02                  , pde-loss 1.5778e+03, initc-loss 1.6680e+04                    bc_loss 4.0601e+04\n",
      "Epoch 25020, Training-Loss 1.2965e+03, Data-loss 9.4731e+02                  , pde-loss 1.5900e+03, initc-loss 1.6083e+04                    bc_loss 1.7249e+04\n",
      "Epoch 25030, Training-Loss 1.9237e+03, Data-loss 1.5276e+03                  , pde-loss 1.3141e+03, initc-loss 1.5044e+04                    bc_loss 2.3244e+04\n",
      "Epoch 25040, Training-Loss 7.6981e+02, Data-loss 5.0239e+02                  , pde-loss 1.3544e+03, initc-loss 1.2390e+04                    bc_loss 1.2998e+04\n",
      "Epoch 25050, Training-Loss 4.7638e+03, Data-loss 9.8042e+02                  , pde-loss 1.7439e+03, initc-loss 1.4503e+04                    bc_loss 3.6209e+05\n",
      "Epoch 25060, Training-Loss 1.8730e+03, Data-loss 1.1667e+03                  , pde-loss 1.9022e+03, initc-loss 1.3725e+04                    bc_loss 5.4999e+04\n",
      "Epoch 25070, Training-Loss 1.7365e+03, Data-loss 1.2139e+03                  , pde-loss 9.4272e+02, initc-loss 1.3260e+04                    bc_loss 3.8057e+04\n",
      "Epoch 25080, Training-Loss 1.1601e+03, Data-loss 7.1732e+02                  , pde-loss 9.7281e+02, initc-loss 1.4966e+04                    bc_loss 2.8337e+04\n",
      "Epoch 25090, Training-Loss 1.0527e+03, Data-loss 6.3199e+02                  , pde-loss 1.5227e+03, initc-loss 1.3791e+04                    bc_loss 2.6757e+04\n",
      "Epoch 25100, Training-Loss 8.5084e+03, Data-loss 1.2007e+03                  , pde-loss 9.0997e+02, initc-loss 1.7189e+04                    bc_loss 7.1267e+05\n",
      "Epoch 25110, Training-Loss 4.4168e+03, Data-loss 2.1171e+03                  , pde-loss 3.5985e+02, initc-loss 1.6295e+04                    bc_loss 2.1332e+05\n",
      "Epoch 25120, Training-Loss 3.3352e+03, Data-loss 2.3879e+03                  , pde-loss 1.5617e+03, initc-loss 2.0662e+04                    bc_loss 7.2508e+04\n",
      "Epoch 25130, Training-Loss 1.7129e+03, Data-loss 1.3063e+03                  , pde-loss 2.3911e+03, initc-loss 1.5090e+04                    bc_loss 2.3176e+04\n",
      "Epoch 25140, Training-Loss 1.1301e+03, Data-loss 7.7548e+02                  , pde-loss 1.3995e+03, initc-loss 1.3573e+04                    bc_loss 2.0488e+04\n",
      "Epoch 25150, Training-Loss 2.4140e+03, Data-loss 1.4232e+03                  , pde-loss 1.2513e+03, initc-loss 1.2162e+04                    bc_loss 8.5671e+04\n",
      "Epoch 25160, Training-Loss 1.3078e+03, Data-loss 9.0312e+02                  , pde-loss 1.4341e+03, initc-loss 1.0668e+04                    bc_loss 2.8367e+04\n",
      "Epoch 25170, Training-Loss 9.5017e+03, Data-loss 1.8661e+03                  , pde-loss 1.8925e+03, initc-loss 1.9907e+04                    bc_loss 7.4176e+05\n",
      "Epoch 25180, Training-Loss 2.0027e+03, Data-loss 1.2385e+03                  , pde-loss 1.4606e+03, initc-loss 9.2839e+03                    bc_loss 6.5678e+04\n",
      "Epoch 25190, Training-Loss 1.7109e+03, Data-loss 1.2807e+03                  , pde-loss 6.2973e+02, initc-loss 1.3263e+04                    bc_loss 2.9122e+04\n",
      "Epoch 25200, Training-Loss 4.3356e+03, Data-loss 1.5974e+03                  , pde-loss 1.1783e+03, initc-loss 1.9316e+04                    bc_loss 2.5332e+05\n",
      "Epoch 25210, Training-Loss 7.5484e+03, Data-loss 1.8487e+03                  , pde-loss 9.0662e+02, initc-loss 1.6895e+04                    bc_loss 5.5216e+05\n",
      "Epoch 25220, Training-Loss 2.7169e+03, Data-loss 1.9400e+03                  , pde-loss 1.2584e+03, initc-loss 1.0968e+04                    bc_loss 6.5464e+04\n",
      "Epoch 25230, Training-Loss 1.9632e+03, Data-loss 1.2977e+03                  , pde-loss 1.8776e+03, initc-loss 1.2262e+04                    bc_loss 5.2418e+04\n",
      "Epoch 25240, Training-Loss 1.3390e+03, Data-loss 8.1179e+02                  , pde-loss 1.5385e+03, initc-loss 1.3853e+04                    bc_loss 3.7333e+04\n",
      "Epoch 25250, Training-Loss 1.3507e+03, Data-loss 9.8739e+02                  , pde-loss 1.5594e+03, initc-loss 1.4334e+04                    bc_loss 2.0440e+04\n",
      "Epoch 25260, Training-Loss 2.4421e+03, Data-loss 1.3328e+03                  , pde-loss 1.2577e+03, initc-loss 1.1778e+04                    bc_loss 9.7897e+04\n",
      "Epoch 25270, Training-Loss 1.1488e+03, Data-loss 8.4601e+02                  , pde-loss 1.1481e+03, initc-loss 1.3294e+04                    bc_loss 1.5842e+04\n",
      "Epoch 25280, Training-Loss 6.1158e+02, Data-loss 3.0662e+02                  , pde-loss 1.4141e+03, initc-loss 1.4810e+04                    bc_loss 1.4271e+04\n",
      "Epoch 25290, Training-Loss 1.3573e+03, Data-loss 8.5368e+02                  , pde-loss 1.2067e+03, initc-loss 1.3784e+04                    bc_loss 3.5372e+04\n",
      "Epoch 25300, Training-Loss 4.5457e+03, Data-loss 1.0768e+03                  , pde-loss 8.3046e+02, initc-loss 1.1539e+04                    bc_loss 3.3452e+05\n",
      "Epoch 25310, Training-Loss 1.6894e+03, Data-loss 9.5347e+02                  , pde-loss 1.3160e+03, initc-loss 9.2443e+03                    bc_loss 6.3030e+04\n",
      "Epoch 25320, Training-Loss 1.5114e+03, Data-loss 1.1694e+03                  , pde-loss 1.9796e+03, initc-loss 1.2660e+04                    bc_loss 1.9566e+04\n",
      "Epoch 25330, Training-Loss 1.1824e+03, Data-loss 9.0171e+02                  , pde-loss 1.5860e+03, initc-loss 1.3100e+04                    bc_loss 1.3385e+04\n",
      "Epoch 25340, Training-Loss 9.5287e+03, Data-loss 1.4138e+03                  , pde-loss 1.7393e+03, initc-loss 1.8802e+04                    bc_loss 7.9095e+05\n",
      "Epoch 25350, Training-Loss 4.4123e+03, Data-loss 1.6949e+03                  , pde-loss 2.1887e+03, initc-loss 1.1689e+04                    bc_loss 2.5786e+05\n",
      "Epoch 25360, Training-Loss 2.0028e+03, Data-loss 1.2318e+03                  , pde-loss 8.1562e+02, initc-loss 1.5068e+04                    bc_loss 6.1215e+04\n",
      "Epoch 25370, Training-Loss 9.7852e+03, Data-loss 1.2414e+03                  , pde-loss 4.3021e+02, initc-loss 1.8654e+04                    bc_loss 8.3530e+05\n",
      "Epoch 25380, Training-Loss 4.6843e+03, Data-loss 3.7322e+03                  , pde-loss 1.1768e+03, initc-loss 5.9253e+03                    bc_loss 8.8105e+04\n",
      "Epoch 25390, Training-Loss 1.3836e+03, Data-loss 7.0642e+02                  , pde-loss 1.9032e+03, initc-loss 1.2673e+04                    bc_loss 5.3141e+04\n",
      "Epoch 25400, Training-Loss 1.7998e+03, Data-loss 1.2704e+03                  , pde-loss 1.4529e+03, initc-loss 1.4641e+04                    bc_loss 3.6849e+04\n",
      "Epoch 25410, Training-Loss 1.3032e+03, Data-loss 9.5086e+02                  , pde-loss 1.3061e+03, initc-loss 1.1980e+04                    bc_loss 2.1947e+04\n",
      "Epoch 25420, Training-Loss 1.1065e+03, Data-loss 7.2508e+02                  , pde-loss 1.5384e+03, initc-loss 1.3353e+04                    bc_loss 2.3250e+04\n",
      "Epoch 25430, Training-Loss 1.1436e+03, Data-loss 8.2221e+02                  , pde-loss 1.3412e+03, initc-loss 1.4125e+04                    bc_loss 1.6669e+04\n",
      "Epoch 25440, Training-Loss 1.2694e+03, Data-loss 8.2777e+02                  , pde-loss 8.7213e+02, initc-loss 1.5782e+04                    bc_loss 2.7504e+04\n",
      "Epoch 25450, Training-Loss 1.1708e+04, Data-loss 1.8287e+03                  , pde-loss 8.8484e+02, initc-loss 2.0451e+04                    bc_loss 9.6658e+05\n",
      "Epoch 25460, Training-Loss 2.2749e+03, Data-loss 1.3268e+03                  , pde-loss 6.6922e+02, initc-loss 8.6392e+03                    bc_loss 8.5501e+04\n",
      "Epoch 25470, Training-Loss 2.0097e+03, Data-loss 1.0751e+03                  , pde-loss 1.5244e+03, initc-loss 1.1853e+04                    bc_loss 8.0075e+04\n",
      "Epoch 25480, Training-Loss 1.2862e+03, Data-loss 8.4307e+02                  , pde-loss 1.4559e+03, initc-loss 1.3718e+04                    bc_loss 2.9144e+04\n",
      "Epoch 25490, Training-Loss 1.6405e+03, Data-loss 1.2588e+03                  , pde-loss 1.3128e+03, initc-loss 1.2862e+04                    bc_loss 2.3998e+04\n",
      "Epoch 25500, Training-Loss 1.3816e+03, Data-loss 9.2500e+02                  , pde-loss 1.8642e+03, initc-loss 1.3774e+04                    bc_loss 3.0018e+04\n",
      "Epoch 25510, Training-Loss 1.5262e+03, Data-loss 4.2730e+02                  , pde-loss 1.8104e+03, initc-loss 1.3889e+04                    bc_loss 9.4188e+04\n",
      "Epoch 25520, Training-Loss 9.8636e+03, Data-loss 3.4198e+03                  , pde-loss 2.4700e+03, initc-loss 2.2224e+04                    bc_loss 6.1969e+05\n",
      "Epoch 25530, Training-Loss 3.0536e+03, Data-loss 1.5556e+03                  , pde-loss 2.0527e+03, initc-loss 1.3355e+04                    bc_loss 1.3439e+05\n",
      "Epoch 25540, Training-Loss 2.5364e+03, Data-loss 1.6072e+03                  , pde-loss 8.9209e+02, initc-loss 1.2165e+04                    bc_loss 7.9867e+04\n",
      "Epoch 25550, Training-Loss 2.0012e+03, Data-loss 1.2896e+03                  , pde-loss 1.1885e+03, initc-loss 1.4103e+04                    bc_loss 5.5861e+04\n",
      "Epoch 25560, Training-Loss 2.0904e+03, Data-loss 1.4774e+03                  , pde-loss 1.5919e+03, initc-loss 1.5449e+04                    bc_loss 4.4254e+04\n",
      "Epoch 25570, Training-Loss 1.3302e+03, Data-loss 8.0866e+02                  , pde-loss 1.2953e+03, initc-loss 1.3578e+04                    bc_loss 3.7285e+04\n",
      "Epoch 25580, Training-Loss 1.1557e+03, Data-loss 6.7853e+02                  , pde-loss 1.3064e+03, initc-loss 1.4301e+04                    bc_loss 3.2115e+04\n",
      "Epoch 25590, Training-Loss 1.6777e+03, Data-loss 7.9261e+02                  , pde-loss 1.3199e+03, initc-loss 1.2913e+04                    bc_loss 7.4271e+04\n",
      "Epoch 25600, Training-Loss 1.3603e+04, Data-loss 4.6454e+03                  , pde-loss 2.6266e+02, initc-loss 2.5982e+04                    bc_loss 8.6947e+05\n",
      "Epoch 25610, Training-Loss 5.5446e+03, Data-loss 2.3837e+03                  , pde-loss 6.3836e+02, initc-loss 1.4722e+04                    bc_loss 3.0074e+05\n",
      "Epoch 25620, Training-Loss 4.9022e+03, Data-loss 2.2693e+03                  , pde-loss 3.5967e+03, initc-loss 1.8507e+04                    bc_loss 2.4119e+05\n",
      "Epoch 25630, Training-Loss 1.7356e+03, Data-loss 1.0608e+03                  , pde-loss 1.1147e+03, initc-loss 1.2871e+04                    bc_loss 5.3501e+04\n",
      "Epoch 25640, Training-Loss 1.8699e+03, Data-loss 1.4259e+03                  , pde-loss 5.4570e+02, initc-loss 1.5220e+04                    bc_loss 2.8639e+04\n",
      "Epoch 25650, Training-Loss 1.5215e+03, Data-loss 9.4034e+02                  , pde-loss 1.3044e+03, initc-loss 1.2497e+04                    bc_loss 4.4320e+04\n",
      "Epoch 25660, Training-Loss 1.0101e+03, Data-loss 7.4388e+02                  , pde-loss 1.3838e+03, initc-loss 1.2369e+04                    bc_loss 1.2866e+04\n",
      "Epoch 25670, Training-Loss 1.5513e+03, Data-loss 1.0155e+03                  , pde-loss 1.3035e+03, initc-loss 1.3005e+04                    bc_loss 3.9269e+04\n",
      "Epoch 25680, Training-Loss 2.4320e+03, Data-loss 1.8949e+03                  , pde-loss 1.2225e+03, initc-loss 1.2518e+04                    bc_loss 3.9971e+04\n",
      "Epoch 25690, Training-Loss 1.4140e+03, Data-loss 1.0665e+03                  , pde-loss 1.2135e+03, initc-loss 1.1061e+04                    bc_loss 2.2475e+04\n",
      "Epoch 25700, Training-Loss 1.0538e+03, Data-loss 8.1674e+02                  , pde-loss 1.4994e+03, initc-loss 1.2663e+04                    bc_loss 9.5457e+03\n",
      "Epoch 25710, Training-Loss 2.7981e+03, Data-loss 1.1074e+03                  , pde-loss 1.6205e+03, initc-loss 1.3853e+04                    bc_loss 1.5359e+05\n",
      "Epoch 25720, Training-Loss 3.6679e+03, Data-loss 7.6141e+02                  , pde-loss 1.9502e+03, initc-loss 1.3145e+04                    bc_loss 2.7555e+05\n",
      "Epoch 25730, Training-Loss 5.1039e+03, Data-loss 2.2621e+03                  , pde-loss 2.1300e+03, initc-loss 7.4119e+03                    bc_loss 2.7464e+05\n",
      "Epoch 25740, Training-Loss 1.0744e+04, Data-loss 2.6106e+03                  , pde-loss 6.5590e+02, initc-loss 2.0887e+04                    bc_loss 7.9182e+05\n",
      "Epoch 25750, Training-Loss 8.7694e+03, Data-loss 3.7917e+03                  , pde-loss 3.7523e+02, initc-loss 2.4358e+04                    bc_loss 4.7303e+05\n",
      "Epoch 25760, Training-Loss 3.6331e+03, Data-loss 2.9900e+03                  , pde-loss 1.2619e+03, initc-loss 1.3793e+04                    bc_loss 4.9252e+04\n",
      "Epoch 25770, Training-Loss 1.4674e+03, Data-loss 9.6832e+02                  , pde-loss 1.1658e+03, initc-loss 1.4362e+04                    bc_loss 3.4382e+04\n",
      "Epoch 25780, Training-Loss 1.6449e+03, Data-loss 1.0788e+03                  , pde-loss 1.5408e+03, initc-loss 1.6660e+04                    bc_loss 3.8410e+04\n",
      "Epoch 25790, Training-Loss 1.2800e+03, Data-loss 8.5148e+02                  , pde-loss 1.5854e+03, initc-loss 1.1732e+04                    bc_loss 2.9533e+04\n",
      "Epoch 25800, Training-Loss 1.1103e+03, Data-loss 7.9714e+02                  , pde-loss 1.7460e+03, initc-loss 1.2732e+04                    bc_loss 1.6837e+04\n",
      "Epoch 25810, Training-Loss 1.7262e+03, Data-loss 5.5212e+02                  , pde-loss 1.3239e+03, initc-loss 1.4746e+04                    bc_loss 1.0134e+05\n",
      "Epoch 25820, Training-Loss 7.8795e+02, Data-loss 4.6561e+02                  , pde-loss 1.1448e+03, initc-loss 1.1172e+04                    bc_loss 1.9917e+04\n",
      "Epoch 25830, Training-Loss 2.7457e+03, Data-loss 9.6313e+02                  , pde-loss 1.0556e+03, initc-loss 1.2806e+04                    bc_loss 1.6439e+05\n",
      "Epoch 25840, Training-Loss 1.2789e+03, Data-loss 8.9897e+02                  , pde-loss 8.4844e+02, initc-loss 1.1504e+04                    bc_loss 2.5639e+04\n",
      "Epoch 25850, Training-Loss 1.2573e+03, Data-loss 9.2578e+02                  , pde-loss 1.4003e+03, initc-loss 1.1802e+04                    bc_loss 1.9952e+04\n",
      "Epoch 25860, Training-Loss 1.3215e+03, Data-loss 9.5140e+02                  , pde-loss 1.5461e+03, initc-loss 1.6065e+04                    bc_loss 1.9395e+04\n",
      "Epoch 25870, Training-Loss 1.2098e+03, Data-loss 8.3548e+02                  , pde-loss 1.1520e+03, initc-loss 1.5478e+04                    bc_loss 2.0797e+04\n",
      "Epoch 25880, Training-Loss 1.1278e+03, Data-loss 8.4044e+02                  , pde-loss 1.3533e+03, initc-loss 1.3984e+04                    bc_loss 1.3398e+04\n",
      "Epoch 25890, Training-Loss 1.2701e+03, Data-loss 6.1477e+02                  , pde-loss 1.1819e+03, initc-loss 1.4034e+04                    bc_loss 5.0314e+04\n",
      "Epoch 25900, Training-Loss 1.1478e+04, Data-loss 3.5800e+03                  , pde-loss 4.2585e+02, initc-loss 2.6601e+04                    bc_loss 7.6282e+05\n",
      "Epoch 25910, Training-Loss 2.4835e+03, Data-loss 1.8459e+03                  , pde-loss 1.1536e+03, initc-loss 1.5436e+04                    bc_loss 4.7164e+04\n",
      "Epoch 25920, Training-Loss 2.0871e+03, Data-loss 1.6084e+03                  , pde-loss 1.3746e+03, initc-loss 1.2765e+04                    bc_loss 3.3726e+04\n",
      "Epoch 25930, Training-Loss 1.7494e+03, Data-loss 1.0820e+03                  , pde-loss 1.7392e+03, initc-loss 1.3139e+04                    bc_loss 5.1858e+04\n",
      "Epoch 25940, Training-Loss 1.7471e+03, Data-loss 1.0051e+03                  , pde-loss 1.7172e+03, initc-loss 1.1685e+04                    bc_loss 6.0798e+04\n",
      "Epoch 25950, Training-Loss 1.9260e+03, Data-loss 1.2768e+03                  , pde-loss 1.5380e+03, initc-loss 1.1897e+04                    bc_loss 5.1490e+04\n",
      "Epoch 25960, Training-Loss 1.6762e+03, Data-loss 8.6153e+02                  , pde-loss 1.4205e+03, initc-loss 1.3500e+04                    bc_loss 6.6542e+04\n",
      "Epoch 25970, Training-Loss 1.4030e+03, Data-loss 1.0223e+03                  , pde-loss 9.7827e+02, initc-loss 1.5003e+04                    bc_loss 2.2088e+04\n",
      "Epoch 25980, Training-Loss 1.3089e+03, Data-loss 7.8349e+02                  , pde-loss 1.2001e+03, initc-loss 1.5322e+04                    bc_loss 3.6024e+04\n",
      "Epoch 25990, Training-Loss 1.6095e+03, Data-loss 1.3517e+03                  , pde-loss 1.2496e+03, initc-loss 1.2262e+04                    bc_loss 1.2277e+04\n",
      "Epoch 26000, Training-Loss 6.8337e+02, Data-loss 4.4958e+02                  , pde-loss 1.3915e+03, initc-loss 1.3668e+04                    bc_loss 8.3194e+03\n",
      "Epoch 26010, Training-Loss 1.6115e+04, Data-loss 2.3455e+03                  , pde-loss 7.5607e+02, initc-loss 2.4145e+04                    bc_loss 1.3521e+06\n",
      "Epoch 26020, Training-Loss 5.4063e+03, Data-loss 4.0475e+03                  , pde-loss 3.8813e+02, initc-loss 1.3103e+04                    bc_loss 1.2239e+05\n",
      "Epoch 26030, Training-Loss 3.0493e+03, Data-loss 2.0535e+03                  , pde-loss 1.5709e+03, initc-loss 1.3539e+04                    bc_loss 8.4467e+04\n",
      "Epoch 26040, Training-Loss 2.0822e+03, Data-loss 1.5544e+03                  , pde-loss 1.1452e+03, initc-loss 1.5415e+04                    bc_loss 3.6229e+04\n",
      "Epoch 26050, Training-Loss 2.1215e+03, Data-loss 1.5072e+03                  , pde-loss 1.3434e+03, initc-loss 1.4114e+04                    bc_loss 4.5971e+04\n",
      "Epoch 26060, Training-Loss 2.0105e+03, Data-loss 1.5297e+03                  , pde-loss 1.4046e+03, initc-loss 1.3795e+04                    bc_loss 3.2881e+04\n",
      "Epoch 26070, Training-Loss 2.1572e+03, Data-loss 6.2799e+02                  , pde-loss 1.3967e+03, initc-loss 1.4192e+04                    bc_loss 1.3733e+05\n",
      "Epoch 26080, Training-Loss 4.8710e+03, Data-loss 9.9768e+02                  , pde-loss 8.5643e+02, initc-loss 1.7304e+04                    bc_loss 3.6917e+05\n",
      "Epoch 26090, Training-Loss 1.3818e+04, Data-loss 1.6369e+03                  , pde-loss 2.3766e+03, initc-loss 1.5204e+04                    bc_loss 1.2005e+06\n",
      "Epoch 26100, Training-Loss 9.3330e+03, Data-loss 3.9581e+03                  , pde-loss 4.4501e+03, initc-loss 1.4808e+04                    bc_loss 5.1823e+05\n",
      "Epoch 26110, Training-Loss 3.6670e+03, Data-loss 2.3877e+03                  , pde-loss 1.1483e+03, initc-loss 1.5685e+04                    bc_loss 1.1110e+05\n",
      "Epoch 26120, Training-Loss 3.8714e+03, Data-loss 3.4197e+03                  , pde-loss 7.1332e+02, initc-loss 1.5763e+04                    bc_loss 2.8702e+04\n",
      "Epoch 26130, Training-Loss 7.0687e+03, Data-loss 1.2995e+03                  , pde-loss 1.5932e+03, initc-loss 1.6851e+04                    bc_loss 5.5848e+05\n",
      "Epoch 26140, Training-Loss 2.5211e+03, Data-loss 2.1943e+03                  , pde-loss 1.5219e+03, initc-loss 1.0394e+04                    bc_loss 2.0760e+04\n",
      "Epoch 26150, Training-Loss 1.6595e+03, Data-loss 1.2085e+03                  , pde-loss 1.0099e+03, initc-loss 1.3610e+04                    bc_loss 3.0487e+04\n",
      "Epoch 26160, Training-Loss 1.5128e+03, Data-loss 8.6003e+02                  , pde-loss 1.5643e+03, initc-loss 1.3173e+04                    bc_loss 5.0542e+04\n",
      "Epoch 26170, Training-Loss 1.1668e+03, Data-loss 8.7795e+02                  , pde-loss 1.4859e+03, initc-loss 1.2857e+04                    bc_loss 1.4540e+04\n",
      "Epoch 26180, Training-Loss 1.1351e+03, Data-loss 5.6500e+02                  , pde-loss 1.3298e+03, initc-loss 1.4360e+04                    bc_loss 4.1322e+04\n",
      "Epoch 26190, Training-Loss 4.1984e+03, Data-loss 1.0629e+03                  , pde-loss 9.1608e+02, initc-loss 1.2204e+04                    bc_loss 3.0043e+05\n",
      "Epoch 26200, Training-Loss 5.9773e+03, Data-loss 1.7685e+03                  , pde-loss 6.5825e+02, initc-loss 1.3668e+04                    bc_loss 4.0655e+05\n",
      "Epoch 26210, Training-Loss 1.5856e+03, Data-loss 9.1327e+02                  , pde-loss 1.4084e+03, initc-loss 1.1120e+04                    bc_loss 5.4708e+04\n",
      "Epoch 26220, Training-Loss 1.0643e+03, Data-loss 7.4107e+02                  , pde-loss 1.9544e+03, initc-loss 1.3061e+04                    bc_loss 1.7310e+04\n",
      "Epoch 26230, Training-Loss 5.0408e+03, Data-loss 7.5257e+02                  , pde-loss 1.2459e+03, initc-loss 1.4869e+04                    bc_loss 4.1271e+05\n",
      "Epoch 26240, Training-Loss 2.1142e+03, Data-loss 1.8444e+03                  , pde-loss 1.0997e+03, initc-loss 1.2765e+04                    bc_loss 1.3116e+04\n",
      "Epoch 26250, Training-Loss 1.2029e+03, Data-loss 9.0796e+02                  , pde-loss 1.4173e+03, initc-loss 1.2935e+04                    bc_loss 1.5142e+04\n",
      "Epoch 26260, Training-Loss 8.3786e+02, Data-loss 5.3839e+02                  , pde-loss 1.1356e+03, initc-loss 1.4004e+04                    bc_loss 1.4807e+04\n",
      "Epoch 26270, Training-Loss 6.6630e+02, Data-loss 4.3030e+02                  , pde-loss 1.2301e+03, initc-loss 1.2843e+04                    bc_loss 9.5270e+03\n",
      "Epoch 26280, Training-Loss 5.8180e+02, Data-loss 3.4453e+02                  , pde-loss 1.2237e+03, initc-loss 1.3150e+04                    bc_loss 9.3539e+03\n",
      "Epoch 26290, Training-Loss 5.0170e+03, Data-loss 1.2552e+03                  , pde-loss 7.5041e+02, initc-loss 1.9498e+04                    bc_loss 3.5593e+05\n",
      "Epoch 26300, Training-Loss 2.8952e+03, Data-loss 1.1994e+03                  , pde-loss 7.0118e+02, initc-loss 1.3436e+04                    bc_loss 1.5545e+05\n",
      "Epoch 26310, Training-Loss 1.4680e+03, Data-loss 1.0442e+03                  , pde-loss 1.4496e+03, initc-loss 1.1728e+04                    bc_loss 2.9199e+04\n",
      "Epoch 26320, Training-Loss 2.2821e+03, Data-loss 1.9303e+03                  , pde-loss 1.8525e+03, initc-loss 1.2745e+04                    bc_loss 2.0590e+04\n",
      "Epoch 26330, Training-Loss 8.3156e+02, Data-loss 5.6264e+02                  , pde-loss 1.6255e+03, initc-loss 1.2005e+04                    bc_loss 1.3262e+04\n",
      "Epoch 26340, Training-Loss 3.7690e+03, Data-loss 1.0157e+03                  , pde-loss 1.5110e+03, initc-loss 1.3838e+04                    bc_loss 2.5999e+05\n",
      "Epoch 26350, Training-Loss 5.5130e+03, Data-loss 2.3802e+03                  , pde-loss 2.6048e+03, initc-loss 1.9481e+04                    bc_loss 2.9119e+05\n",
      "Epoch 26360, Training-Loss 2.3743e+03, Data-loss 1.8529e+03                  , pde-loss 1.0858e+03, initc-loss 1.5772e+04                    bc_loss 3.5286e+04\n",
      "Epoch 26370, Training-Loss 1.5950e+03, Data-loss 1.2519e+03                  , pde-loss 1.0301e+03, initc-loss 1.6073e+04                    bc_loss 1.7203e+04\n",
      "Epoch 26380, Training-Loss 2.9488e+03, Data-loss 1.0686e+03                  , pde-loss 1.5843e+03, initc-loss 1.4296e+04                    bc_loss 1.7214e+05\n",
      "Epoch 26390, Training-Loss 6.7512e+03, Data-loss 1.4399e+03                  , pde-loss 1.0478e+03, initc-loss 1.4271e+04                    bc_loss 5.1580e+05\n",
      "Epoch 26400, Training-Loss 6.1331e+03, Data-loss 2.1709e+03                  , pde-loss 3.0424e+02, initc-loss 1.6496e+04                    bc_loss 3.7942e+05\n",
      "Epoch 26410, Training-Loss 1.9966e+03, Data-loss 1.0839e+03                  , pde-loss 1.1693e+03, initc-loss 1.6488e+04                    bc_loss 7.3617e+04\n",
      "Epoch 26420, Training-Loss 3.6285e+03, Data-loss 7.9217e+02                  , pde-loss 1.9863e+03, initc-loss 1.4718e+04                    bc_loss 2.6692e+05\n",
      "Epoch 26430, Training-Loss 9.2864e+02, Data-loss 6.2079e+02                  , pde-loss 1.5081e+03, initc-loss 1.2949e+04                    bc_loss 1.6328e+04\n",
      "Epoch 26440, Training-Loss 1.5148e+03, Data-loss 1.1219e+03                  , pde-loss 1.2880e+03, initc-loss 1.3623e+04                    bc_loss 2.4377e+04\n",
      "Epoch 26450, Training-Loss 1.6216e+03, Data-loss 1.0365e+03                  , pde-loss 1.5190e+03, initc-loss 1.5165e+04                    bc_loss 4.1828e+04\n",
      "Epoch 26460, Training-Loss 1.9905e+03, Data-loss 1.4712e+03                  , pde-loss 1.2661e+03, initc-loss 1.2315e+04                    bc_loss 3.8350e+04\n",
      "Epoch 26470, Training-Loss 5.3621e+03, Data-loss 1.5063e+03                  , pde-loss 1.2440e+03, initc-loss 1.4383e+04                    bc_loss 3.6996e+05\n",
      "Epoch 26480, Training-Loss 3.6135e+03, Data-loss 1.7701e+03                  , pde-loss 8.4089e+02, initc-loss 1.6684e+04                    bc_loss 1.6682e+05\n",
      "Epoch 26490, Training-Loss 1.6428e+03, Data-loss 1.0857e+03                  , pde-loss 1.7216e+03, initc-loss 1.4583e+04                    bc_loss 3.9407e+04\n",
      "Epoch 26500, Training-Loss 1.7384e+03, Data-loss 1.3030e+03                  , pde-loss 2.0063e+03, initc-loss 1.3428e+04                    bc_loss 2.8109e+04\n",
      "Epoch 26510, Training-Loss 1.6322e+03, Data-loss 1.1719e+03                  , pde-loss 1.2705e+03, initc-loss 1.4787e+04                    bc_loss 2.9971e+04\n",
      "Epoch 26520, Training-Loss 8.0081e+02, Data-loss 4.3925e+02                  , pde-loss 1.2411e+03, initc-loss 1.4870e+04                    bc_loss 2.0045e+04\n",
      "Epoch 26530, Training-Loss 9.0904e+02, Data-loss 5.5033e+02                  , pde-loss 1.1679e+03, initc-loss 1.5204e+04                    bc_loss 1.9499e+04\n",
      "Epoch 26540, Training-Loss 6.2521e+02, Data-loss 3.1248e+02                  , pde-loss 1.2861e+03, initc-loss 1.2643e+04                    bc_loss 1.7344e+04\n",
      "Epoch 26550, Training-Loss 9.6205e+02, Data-loss 6.7857e+02                  , pde-loss 1.2863e+03, initc-loss 1.3285e+04                    bc_loss 1.3777e+04\n",
      "Epoch 26560, Training-Loss 1.8322e+03, Data-loss 7.2993e+02                  , pde-loss 1.0813e+03, initc-loss 1.4754e+04                    bc_loss 9.4397e+04\n",
      "Epoch 26570, Training-Loss 1.3633e+04, Data-loss 6.1847e+03                  , pde-loss 3.3985e+02, initc-loss 2.9976e+04                    bc_loss 7.1455e+05\n",
      "Epoch 26580, Training-Loss 3.9178e+03, Data-loss 2.8978e+03                  , pde-loss 9.0555e+02, initc-loss 1.5619e+04                    bc_loss 8.5476e+04\n",
      "Epoch 26590, Training-Loss 1.5475e+03, Data-loss 8.8776e+02                  , pde-loss 1.8444e+03, initc-loss 1.6965e+04                    bc_loss 4.7161e+04\n",
      "Epoch 26600, Training-Loss 2.1836e+03, Data-loss 1.5865e+03                  , pde-loss 1.3097e+03, initc-loss 1.7222e+04                    bc_loss 4.1174e+04\n",
      "Epoch 26610, Training-Loss 1.0144e+03, Data-loss 5.7630e+02                  , pde-loss 1.5497e+03, initc-loss 1.1629e+04                    bc_loss 3.0634e+04\n",
      "Epoch 26620, Training-Loss 1.4476e+03, Data-loss 9.9761e+02                  , pde-loss 1.4591e+03, initc-loss 1.3358e+04                    bc_loss 3.0177e+04\n",
      "Epoch 26630, Training-Loss 2.2487e+03, Data-loss 1.2548e+03                  , pde-loss 1.1844e+03, initc-loss 1.3095e+04                    bc_loss 8.5113e+04\n",
      "Epoch 26640, Training-Loss 3.4021e+03, Data-loss 1.2752e+03                  , pde-loss 1.6391e+03, initc-loss 1.3000e+04                    bc_loss 1.9805e+05\n",
      "Epoch 26650, Training-Loss 1.0581e+04, Data-loss 4.6547e+03                  , pde-loss 3.8715e+03, initc-loss 2.1189e+04                    bc_loss 5.6760e+05\n",
      "Epoch 26660, Training-Loss 3.7315e+03, Data-loss 1.9391e+03                  , pde-loss 1.8251e+03, initc-loss 1.3666e+04                    bc_loss 1.6375e+05\n",
      "Epoch 26670, Training-Loss 2.9442e+03, Data-loss 2.3864e+03                  , pde-loss 4.7988e+02, initc-loss 1.6220e+04                    bc_loss 3.9083e+04\n",
      "Epoch 26680, Training-Loss 1.7059e+03, Data-loss 1.2285e+03                  , pde-loss 1.4952e+03, initc-loss 1.6576e+04                    bc_loss 2.9672e+04\n",
      "Epoch 26690, Training-Loss 1.2909e+03, Data-loss 7.5712e+02                  , pde-loss 1.9535e+03, initc-loss 1.2184e+04                    bc_loss 3.9243e+04\n",
      "Epoch 26700, Training-Loss 2.1227e+03, Data-loss 9.7534e+02                  , pde-loss 8.2148e+02, initc-loss 1.3445e+04                    bc_loss 1.0047e+05\n",
      "Epoch 26710, Training-Loss 4.7009e+03, Data-loss 1.6755e+03                  , pde-loss 7.0138e+02, initc-loss 1.4565e+04                    bc_loss 2.8728e+05\n",
      "Epoch 26720, Training-Loss 1.2165e+03, Data-loss 6.5081e+02                  , pde-loss 1.4509e+03, initc-loss 1.1333e+04                    bc_loss 4.3787e+04\n",
      "Epoch 26730, Training-Loss 1.1907e+03, Data-loss 8.3751e+02                  , pde-loss 1.8349e+03, initc-loss 1.4612e+04                    bc_loss 1.8877e+04\n",
      "Epoch 26740, Training-Loss 1.4062e+03, Data-loss 1.0755e+03                  , pde-loss 1.2859e+03, initc-loss 1.3475e+04                    bc_loss 1.8315e+04\n",
      "Epoch 26750, Training-Loss 1.4816e+03, Data-loss 1.0405e+03                  , pde-loss 1.2388e+03, initc-loss 1.5532e+04                    bc_loss 2.7334e+04\n",
      "Epoch 26760, Training-Loss 7.0643e+02, Data-loss 3.7922e+02                  , pde-loss 1.4622e+03, initc-loss 1.4327e+04                    bc_loss 1.6931e+04\n",
      "Epoch 26770, Training-Loss 8.0729e+02, Data-loss 4.4331e+02                  , pde-loss 1.1926e+03, initc-loss 1.5735e+04                    bc_loss 1.9470e+04\n",
      "Epoch 26780, Training-Loss 6.4664e+02, Data-loss 3.6468e+02                  , pde-loss 1.3237e+03, initc-loss 1.3801e+04                    bc_loss 1.3071e+04\n",
      "Epoch 26790, Training-Loss 1.0383e+03, Data-loss 5.0611e+02                  , pde-loss 1.6635e+03, initc-loss 1.5532e+04                    bc_loss 3.6021e+04\n",
      "Epoch 26800, Training-Loss 1.6386e+03, Data-loss 9.1123e+02                  , pde-loss 1.3624e+03, initc-loss 1.2752e+04                    bc_loss 5.8622e+04\n",
      "Epoch 26810, Training-Loss 1.8620e+04, Data-loss 3.0165e+03                  , pde-loss 4.2766e+02, initc-loss 2.5084e+04                    bc_loss 1.5349e+06\n",
      "Epoch 26820, Training-Loss 4.7456e+03, Data-loss 3.1063e+03                  , pde-loss 2.0599e+02, initc-loss 1.8366e+04                    bc_loss 1.4536e+05\n",
      "Epoch 26830, Training-Loss 4.2775e+03, Data-loss 3.4612e+03                  , pde-loss 1.4118e+03, initc-loss 1.8050e+04                    bc_loss 6.2173e+04\n",
      "Epoch 26840, Training-Loss 3.3340e+03, Data-loss 2.7944e+03                  , pde-loss 1.3107e+03, initc-loss 1.7108e+04                    bc_loss 3.5540e+04\n",
      "Epoch 26850, Training-Loss 3.4867e+03, Data-loss 2.8933e+03                  , pde-loss 1.2000e+03, initc-loss 1.6668e+04                    bc_loss 4.1469e+04\n",
      "Epoch 26860, Training-Loss 1.3613e+03, Data-loss 8.8805e+02                  , pde-loss 1.6349e+03, initc-loss 1.3958e+04                    bc_loss 3.1731e+04\n",
      "Epoch 26870, Training-Loss 2.0398e+03, Data-loss 1.1019e+03                  , pde-loss 1.3347e+03, initc-loss 1.2773e+04                    bc_loss 7.9681e+04\n",
      "Epoch 26880, Training-Loss 2.4107e+03, Data-loss 1.7027e+03                  , pde-loss 1.0696e+03, initc-loss 1.3125e+04                    bc_loss 5.6604e+04\n",
      "Epoch 26890, Training-Loss 1.2687e+03, Data-loss 8.4694e+02                  , pde-loss 1.6825e+03, initc-loss 1.2458e+04                    bc_loss 2.8033e+04\n",
      "Epoch 26900, Training-Loss 2.1433e+03, Data-loss 9.3050e+02                  , pde-loss 1.7563e+03, initc-loss 1.4078e+04                    bc_loss 1.0545e+05\n",
      "Epoch 26910, Training-Loss 9.0396e+03, Data-loss 2.6278e+03                  , pde-loss 2.7589e+03, initc-loss 2.3317e+04                    bc_loss 6.1510e+05\n",
      "Epoch 26920, Training-Loss 3.9181e+03, Data-loss 1.4542e+03                  , pde-loss 2.0094e+03, initc-loss 1.1493e+04                    bc_loss 2.3288e+05\n",
      "Epoch 26930, Training-Loss 2.2229e+03, Data-loss 1.7322e+03                  , pde-loss 5.5361e+02, initc-loss 1.2892e+04                    bc_loss 3.5625e+04\n",
      "Epoch 26940, Training-Loss 1.9290e+03, Data-loss 8.4845e+02                  , pde-loss 1.1551e+03, initc-loss 1.4739e+04                    bc_loss 9.2166e+04\n",
      "Epoch 26950, Training-Loss 1.7448e+03, Data-loss 1.1959e+03                  , pde-loss 1.6468e+03, initc-loss 1.0724e+04                    bc_loss 4.2517e+04\n",
      "Epoch 26960, Training-Loss 4.8788e+03, Data-loss 6.7103e+02                  , pde-loss 9.3925e+02, initc-loss 1.3949e+04                    bc_loss 4.0589e+05\n",
      "Epoch 26970, Training-Loss 2.3780e+03, Data-loss 1.2172e+03                  , pde-loss 6.7569e+02, initc-loss 1.5981e+04                    bc_loss 9.9423e+04\n",
      "Epoch 26980, Training-Loss 1.6230e+03, Data-loss 9.9632e+02                  , pde-loss 1.2492e+03, initc-loss 1.4189e+04                    bc_loss 4.7229e+04\n",
      "Epoch 26990, Training-Loss 1.5828e+03, Data-loss 1.1335e+03                  , pde-loss 1.8068e+03, initc-loss 1.5875e+04                    bc_loss 2.7243e+04\n",
      "Epoch 27000, Training-Loss 1.4422e+03, Data-loss 9.6978e+02                  , pde-loss 1.3986e+03, initc-loss 1.6013e+04                    bc_loss 2.9829e+04\n",
      "Epoch 27010, Training-Loss 1.0698e+03, Data-loss 7.6068e+02                  , pde-loss 1.3722e+03, initc-loss 1.1645e+04                    bc_loss 1.7894e+04\n",
      "Epoch 27020, Training-Loss 1.1225e+03, Data-loss 7.7288e+02                  , pde-loss 1.3563e+03, initc-loss 1.2482e+04                    bc_loss 2.1122e+04\n",
      "Epoch 27030, Training-Loss 1.2159e+03, Data-loss 8.6826e+02                  , pde-loss 1.0782e+03, initc-loss 1.3995e+04                    bc_loss 1.9691e+04\n",
      "Epoch 27040, Training-Loss 7.6820e+02, Data-loss 3.5076e+02                  , pde-loss 1.1292e+03, initc-loss 1.5047e+04                    bc_loss 2.5566e+04\n",
      "Epoch 27050, Training-Loss 2.9344e+03, Data-loss 6.5213e+02                  , pde-loss 1.1876e+03, initc-loss 1.5797e+04                    bc_loss 2.1125e+05\n",
      "Epoch 27060, Training-Loss 1.6869e+03, Data-loss 6.6044e+02                  , pde-loss 9.9781e+02, initc-loss 1.3796e+04                    bc_loss 8.7852e+04\n",
      "Epoch 27070, Training-Loss 1.4375e+03, Data-loss 1.1010e+03                  , pde-loss 1.5195e+03, initc-loss 1.4447e+04                    bc_loss 1.7681e+04\n",
      "Epoch 27080, Training-Loss 9.2538e+02, Data-loss 6.5574e+02                  , pde-loss 1.5102e+03, initc-loss 1.2846e+04                    bc_loss 1.2608e+04\n",
      "Epoch 27090, Training-Loss 7.2197e+02, Data-loss 4.5647e+02                  , pde-loss 1.3202e+03, initc-loss 1.1427e+04                    bc_loss 1.3803e+04\n",
      "Epoch 27100, Training-Loss 1.0761e+03, Data-loss 5.9646e+02                  , pde-loss 1.1096e+03, initc-loss 1.0741e+04                    bc_loss 3.6113e+04\n",
      "Epoch 27110, Training-Loss 3.8060e+03, Data-loss 7.9864e+02                  , pde-loss 1.8456e+03, initc-loss 1.5150e+04                    bc_loss 2.8374e+05\n",
      "Epoch 27120, Training-Loss 6.3740e+03, Data-loss 1.8639e+03                  , pde-loss 3.5180e+03, initc-loss 1.6242e+04                    bc_loss 4.3125e+05\n",
      "Epoch 27130, Training-Loss 2.7498e+03, Data-loss 1.5026e+03                  , pde-loss 1.6721e+03, initc-loss 1.5529e+04                    bc_loss 1.0752e+05\n",
      "Epoch 27140, Training-Loss 2.1664e+03, Data-loss 1.4707e+03                  , pde-loss 8.3713e+02, initc-loss 1.5938e+04                    bc_loss 5.2794e+04\n",
      "Epoch 27150, Training-Loss 1.7228e+03, Data-loss 1.0583e+03                  , pde-loss 1.5216e+03, initc-loss 1.4360e+04                    bc_loss 5.0565e+04\n",
      "Epoch 27160, Training-Loss 1.7630e+03, Data-loss 5.4291e+02                  , pde-loss 1.4420e+03, initc-loss 1.4805e+04                    bc_loss 1.0576e+05\n",
      "Epoch 27170, Training-Loss 1.1156e+04, Data-loss 2.9498e+03                  , pde-loss 5.1999e+02, initc-loss 2.4741e+04                    bc_loss 7.9532e+05\n",
      "Epoch 27180, Training-Loss 4.3222e+03, Data-loss 2.1949e+03                  , pde-loss 5.9596e+02, initc-loss 1.3476e+04                    bc_loss 1.9866e+05\n",
      "Epoch 27190, Training-Loss 2.6058e+03, Data-loss 1.6894e+03                  , pde-loss 2.5634e+03, initc-loss 1.6819e+04                    bc_loss 7.2261e+04\n",
      "Epoch 27200, Training-Loss 2.1234e+03, Data-loss 1.4972e+03                  , pde-loss 1.4860e+03, initc-loss 1.5762e+04                    bc_loss 4.5369e+04\n",
      "Epoch 27210, Training-Loss 1.5921e+03, Data-loss 1.1385e+03                  , pde-loss 1.1433e+03, initc-loss 1.3714e+04                    bc_loss 3.0496e+04\n",
      "Epoch 27220, Training-Loss 1.0491e+03, Data-loss 5.5312e+02                  , pde-loss 1.2658e+03, initc-loss 1.3132e+04                    bc_loss 3.5197e+04\n",
      "Epoch 27230, Training-Loss 1.2186e+03, Data-loss 6.9462e+02                  , pde-loss 9.3283e+02, initc-loss 1.2784e+04                    bc_loss 3.8685e+04\n",
      "Epoch 27240, Training-Loss 1.2872e+03, Data-loss 1.0521e+03                  , pde-loss 6.5352e+02, initc-loss 1.3436e+04                    bc_loss 9.4160e+03\n",
      "Epoch 27250, Training-Loss 8.2352e+03, Data-loss 1.0481e+03                  , pde-loss 8.3393e+02, initc-loss 1.4680e+04                    bc_loss 7.0319e+05\n",
      "Epoch 27260, Training-Loss 7.1237e+03, Data-loss 6.3868e+02                  , pde-loss 5.7038e+02, initc-loss 1.4323e+04                    bc_loss 6.3361e+05\n",
      "Epoch 27270, Training-Loss 1.3761e+03, Data-loss 8.8210e+02                  , pde-loss 1.1987e+03, initc-loss 1.4188e+04                    bc_loss 3.4008e+04\n",
      "Epoch 27280, Training-Loss 1.2366e+03, Data-loss 7.9596e+02                  , pde-loss 1.6026e+03, initc-loss 1.3153e+04                    bc_loss 2.9308e+04\n",
      "Epoch 27290, Training-Loss 1.2995e+03, Data-loss 9.5894e+02                  , pde-loss 1.7110e+03, initc-loss 1.1430e+04                    bc_loss 2.0915e+04\n",
      "Epoch 27300, Training-Loss 1.3032e+03, Data-loss 1.0708e+03                  , pde-loss 1.5154e+03, initc-loss 1.2116e+04                    bc_loss 9.6036e+03\n",
      "Epoch 27310, Training-Loss 9.9689e+02, Data-loss 7.5315e+02                  , pde-loss 1.2660e+03, initc-loss 1.1922e+04                    bc_loss 1.1186e+04\n",
      "Epoch 27320, Training-Loss 6.7729e+02, Data-loss 4.3717e+02                  , pde-loss 1.3679e+03, initc-loss 1.3662e+04                    bc_loss 8.9826e+03\n",
      "Epoch 27330, Training-Loss 9.3376e+02, Data-loss 7.0112e+02                  , pde-loss 1.1394e+03, initc-loss 1.4502e+04                    bc_loss 7.6223e+03\n",
      "Epoch 27340, Training-Loss 8.3201e+02, Data-loss 4.5838e+02                  , pde-loss 1.2914e+03, initc-loss 1.2580e+04                    bc_loss 2.3492e+04\n",
      "Epoch 27350, Training-Loss 9.7228e+02, Data-loss 7.5340e+02                  , pde-loss 1.2842e+03, initc-loss 1.2948e+04                    bc_loss 7.6566e+03\n",
      "Epoch 27360, Training-Loss 4.8332e+03, Data-loss 4.1918e+02                  , pde-loss 1.1573e+03, initc-loss 1.3648e+04                    bc_loss 4.2660e+05\n",
      "Epoch 27370, Training-Loss 8.9494e+03, Data-loss 4.7743e+03                  , pde-loss 2.6862e+02, initc-loss 3.0164e+04                    bc_loss 3.8707e+05\n",
      "Epoch 27380, Training-Loss 8.6526e+03, Data-loss 6.0355e+03                  , pde-loss 3.1207e+02, initc-loss 1.9458e+04                    bc_loss 2.4194e+05\n",
      "Epoch 27390, Training-Loss 4.5253e+03, Data-loss 3.6752e+03                  , pde-loss 2.6044e+03, initc-loss 1.5201e+04                    bc_loss 6.7203e+04\n",
      "Epoch 27400, Training-Loss 3.6965e+03, Data-loss 2.3595e+03                  , pde-loss 2.1750e+03, initc-loss 1.7814e+04                    bc_loss 1.1371e+05\n",
      "Epoch 27410, Training-Loss 2.5450e+03, Data-loss 1.9119e+03                  , pde-loss 9.2256e+02, initc-loss 1.5986e+04                    bc_loss 4.6402e+04\n",
      "Epoch 27420, Training-Loss 1.6343e+03, Data-loss 1.1037e+03                  , pde-loss 1.3547e+03, initc-loss 1.0517e+04                    bc_loss 4.1186e+04\n",
      "Epoch 27430, Training-Loss 2.1290e+03, Data-loss 1.5635e+03                  , pde-loss 1.6043e+03, initc-loss 1.2698e+04                    bc_loss 4.2248e+04\n",
      "Epoch 27440, Training-Loss 6.7423e+03, Data-loss 1.2743e+03                  , pde-loss 1.0941e+03, initc-loss 1.6254e+04                    bc_loss 5.2946e+05\n",
      "Epoch 27450, Training-Loss 6.6426e+03, Data-loss 4.6608e+03                  , pde-loss 3.7842e+02, initc-loss 1.1767e+04                    bc_loss 1.8604e+05\n",
      "Epoch 27460, Training-Loss 1.0964e+04, Data-loss 2.7166e+03                  , pde-loss 2.1775e+03, initc-loss 1.4019e+04                    bc_loss 8.0853e+05\n",
      "Epoch 27470, Training-Loss 3.9447e+04, Data-loss 2.5592e+04                  , pde-loss 1.7312e+04, initc-loss 4.7363e+04                    bc_loss 1.3209e+06\n",
      "Epoch 27480, Training-Loss 2.2320e+04, Data-loss 1.5799e+04                  , pde-loss 2.0411e+04, initc-loss 2.9455e+04                    bc_loss 6.0224e+05\n",
      "Epoch 27490, Training-Loss 1.5446e+04, Data-loss 8.6463e+03                  , pde-loss 3.3316e+03, initc-loss 2.8305e+04                    bc_loss 6.4830e+05\n",
      "Epoch 27500, Training-Loss 1.7552e+04, Data-loss 9.4744e+03                  , pde-loss 2.0246e+03, initc-loss 2.9581e+04                    bc_loss 7.7613e+05\n",
      "Epoch 27510, Training-Loss 1.8526e+04, Data-loss 1.1395e+04                  , pde-loss 1.1954e+03, initc-loss 3.1673e+04                    bc_loss 6.8020e+05\n",
      "Epoch 27520, Training-Loss 1.8585e+04, Data-loss 1.4044e+04                  , pde-loss 3.5214e+02, initc-loss 3.2892e+04                    bc_loss 4.2078e+05\n",
      "Epoch 27530, Training-Loss 2.5058e+04, Data-loss 2.1188e+04                  , pde-loss 1.1103e+03, initc-loss 2.7731e+04                    bc_loss 3.5817e+05\n",
      "Epoch 27540, Training-Loss 1.2195e+04, Data-loss 1.0083e+04                  , pde-loss 5.3456e+02, initc-loss 3.0258e+04                    bc_loss 1.8041e+05\n",
      "Epoch 27550, Training-Loss 1.6322e+04, Data-loss 1.3264e+04                  , pde-loss 8.1263e+02, initc-loss 2.6331e+04                    bc_loss 2.7866e+05\n",
      "Epoch 27560, Training-Loss 1.5691e+04, Data-loss 1.3188e+04                  , pde-loss 7.6560e+02, initc-loss 2.3067e+04                    bc_loss 2.2648e+05\n",
      "Epoch 27570, Training-Loss 1.1564e+04, Data-loss 1.0181e+04                  , pde-loss 5.9580e+02, initc-loss 2.2782e+04                    bc_loss 1.1496e+05\n",
      "Epoch 27580, Training-Loss 1.6438e+04, Data-loss 1.5167e+04                  , pde-loss 8.6374e+02, initc-loss 3.1713e+04                    bc_loss 9.4494e+04\n",
      "Epoch 27590, Training-Loss 1.1022e+04, Data-loss 9.8085e+03                  , pde-loss 1.0879e+03, initc-loss 2.3756e+04                    bc_loss 9.6507e+04\n",
      "Epoch 27600, Training-Loss 1.5572e+04, Data-loss 1.1018e+04                  , pde-loss 5.8965e+02, initc-loss 3.0815e+04                    bc_loss 4.2396e+05\n",
      "Epoch 27610, Training-Loss 1.5579e+04, Data-loss 1.4858e+04                  , pde-loss 4.6312e+02, initc-loss 2.9605e+04                    bc_loss 4.2037e+04\n",
      "Epoch 27620, Training-Loss 1.1721e+04, Data-loss 9.7194e+03                  , pde-loss 8.2144e+02, initc-loss 2.3816e+04                    bc_loss 1.7549e+05\n",
      "Epoch 27630, Training-Loss 1.6020e+04, Data-loss 1.1280e+04                  , pde-loss 2.0715e+03, initc-loss 2.7812e+04                    bc_loss 4.4409e+05\n",
      "Epoch 27640, Training-Loss 1.0565e+04, Data-loss 9.4754e+03                  , pde-loss 1.5592e+03, initc-loss 2.6578e+04                    bc_loss 8.0817e+04\n",
      "Epoch 27650, Training-Loss 1.2894e+04, Data-loss 1.0960e+04                  , pde-loss 6.8107e+02, initc-loss 2.2371e+04                    bc_loss 1.7035e+05\n",
      "Epoch 27660, Training-Loss 2.0797e+04, Data-loss 1.4372e+04                  , pde-loss 4.3150e+02, initc-loss 3.3523e+04                    bc_loss 6.0859e+05\n",
      "Epoch 27670, Training-Loss 1.4149e+04, Data-loss 1.2891e+04                  , pde-loss 6.4117e+02, initc-loss 2.6936e+04                    bc_loss 9.8301e+04\n",
      "Epoch 27680, Training-Loss 1.3229e+04, Data-loss 1.0583e+04                  , pde-loss 1.1921e+03, initc-loss 2.0035e+04                    bc_loss 2.4343e+05\n",
      "Epoch 27690, Training-Loss 1.4137e+04, Data-loss 1.2591e+04                  , pde-loss 7.0192e+02, initc-loss 2.1868e+04                    bc_loss 1.3203e+05\n",
      "Epoch 27700, Training-Loss 1.1376e+04, Data-loss 1.0705e+04                  , pde-loss 7.5359e+02, initc-loss 2.6749e+04                    bc_loss 3.9616e+04\n",
      "Epoch 27710, Training-Loss 1.0767e+04, Data-loss 9.2416e+03                  , pde-loss 9.5722e+02, initc-loss 2.2882e+04                    bc_loss 1.2871e+05\n",
      "Epoch 27720, Training-Loss 1.3426e+04, Data-loss 1.1930e+04                  , pde-loss 7.9223e+02, initc-loss 2.7700e+04                    bc_loss 1.2112e+05\n",
      "Epoch 27730, Training-Loss 1.2882e+04, Data-loss 1.1516e+04                  , pde-loss 6.8210e+02, initc-loss 3.0407e+04                    bc_loss 1.0549e+05\n",
      "Epoch 27740, Training-Loss 2.1836e+04, Data-loss 1.7195e+04                  , pde-loss 5.2642e+02, initc-loss 4.0243e+04                    bc_loss 4.2331e+05\n",
      "Epoch 27750, Training-Loss 2.3887e+04, Data-loss 1.0858e+04                  , pde-loss 8.0951e+02, initc-loss 2.4794e+04                    bc_loss 1.2772e+06\n",
      "Epoch 27760, Training-Loss 1.8442e+04, Data-loss 1.2021e+04                  , pde-loss 4.4908e+03, initc-loss 2.1514e+04                    bc_loss 6.1611e+05\n",
      "Epoch 27770, Training-Loss 1.2114e+04, Data-loss 8.7722e+03                  , pde-loss 9.1145e+02, initc-loss 2.3523e+04                    bc_loss 3.0972e+05\n",
      "Epoch 27780, Training-Loss 1.0999e+04, Data-loss 9.9284e+03                  , pde-loss 9.7478e+02, initc-loss 2.0275e+04                    bc_loss 8.5805e+04\n",
      "Epoch 27790, Training-Loss 9.2669e+03, Data-loss 7.8646e+03                  , pde-loss 9.3567e+02, initc-loss 3.0294e+04                    bc_loss 1.0900e+05\n",
      "Epoch 27800, Training-Loss 1.1420e+04, Data-loss 9.4617e+03                  , pde-loss 5.9420e+02, initc-loss 2.6218e+04                    bc_loss 1.6904e+05\n",
      "Epoch 27810, Training-Loss 6.8449e+03, Data-loss 6.0160e+03                  , pde-loss 8.3772e+02, initc-loss 2.0461e+04                    bc_loss 6.1594e+04\n",
      "Epoch 27820, Training-Loss 8.3422e+03, Data-loss 7.2840e+03                  , pde-loss 1.1146e+03, initc-loss 2.0273e+04                    bc_loss 8.4425e+04\n",
      "Epoch 27830, Training-Loss 8.8712e+03, Data-loss 7.6250e+03                  , pde-loss 9.2591e+02, initc-loss 1.9110e+04                    bc_loss 1.0458e+05\n",
      "Epoch 27840, Training-Loss 1.2185e+04, Data-loss 1.0315e+04                  , pde-loss 5.0224e+02, initc-loss 3.2942e+04                    bc_loss 1.5360e+05\n",
      "Epoch 27850, Training-Loss 7.2565e+03, Data-loss 6.5890e+03                  , pde-loss 9.0607e+02, initc-loss 2.6125e+04                    bc_loss 3.9718e+04\n",
      "Epoch 27860, Training-Loss 1.1992e+04, Data-loss 8.8206e+03                  , pde-loss 1.8078e+03, initc-loss 2.2724e+04                    bc_loss 2.9263e+05\n",
      "Epoch 27870, Training-Loss 9.6081e+03, Data-loss 7.6708e+03                  , pde-loss 2.0474e+03, initc-loss 1.4755e+04                    bc_loss 1.7692e+05\n",
      "Epoch 27880, Training-Loss 1.1883e+04, Data-loss 8.2374e+03                  , pde-loss 6.8564e+02, initc-loss 1.8585e+04                    bc_loss 3.4532e+05\n",
      "Epoch 27890, Training-Loss 1.1881e+04, Data-loss 9.7834e+03                  , pde-loss 6.2158e+02, initc-loss 2.0387e+04                    bc_loss 1.8873e+05\n",
      "Epoch 27900, Training-Loss 6.2076e+03, Data-loss 5.3791e+03                  , pde-loss 9.3929e+02, initc-loss 2.1157e+04                    bc_loss 6.0760e+04\n",
      "Epoch 27910, Training-Loss 6.8147e+03, Data-loss 5.6714e+03                  , pde-loss 1.6198e+03, initc-loss 2.0152e+04                    bc_loss 9.2555e+04\n",
      "Epoch 27920, Training-Loss 7.2040e+03, Data-loss 6.2205e+03                  , pde-loss 1.3115e+03, initc-loss 1.8462e+04                    bc_loss 7.8578e+04\n",
      "Epoch 27930, Training-Loss 7.8759e+03, Data-loss 6.9643e+03                  , pde-loss 1.1528e+03, initc-loss 1.9576e+04                    bc_loss 7.0436e+04\n",
      "Epoch 27940, Training-Loss 8.6773e+03, Data-loss 7.2809e+03                  , pde-loss 1.9210e+03, initc-loss 2.1805e+04                    bc_loss 1.1592e+05\n",
      "Epoch 27950, Training-Loss 6.8389e+03, Data-loss 5.8865e+03                  , pde-loss 1.9608e+03, initc-loss 1.9475e+04                    bc_loss 7.3803e+04\n",
      "Epoch 27960, Training-Loss 1.5252e+04, Data-loss 1.0465e+04                  , pde-loss 4.3817e+02, initc-loss 3.1305e+04                    bc_loss 4.4701e+05\n",
      "Epoch 27970, Training-Loss 1.0288e+04, Data-loss 8.5547e+03                  , pde-loss 5.5244e+02, initc-loss 1.6276e+04                    bc_loss 1.5648e+05\n",
      "Epoch 27980, Training-Loss 1.3949e+04, Data-loss 8.9268e+03                  , pde-loss 2.3138e+03, initc-loss 2.7358e+04                    bc_loss 4.7253e+05\n",
      "Epoch 27990, Training-Loss 7.2772e+03, Data-loss 6.1504e+03                  , pde-loss 1.6697e+03, initc-loss 1.4356e+04                    bc_loss 9.6658e+04\n",
      "Epoch 28000, Training-Loss 6.1505e+03, Data-loss 4.4668e+03                  , pde-loss 1.0564e+03, initc-loss 1.8159e+04                    bc_loss 1.4916e+05\n",
      "Epoch 28010, Training-Loss 5.1937e+03, Data-loss 3.9386e+03                  , pde-loss 2.0264e+03, initc-loss 1.6178e+04                    bc_loss 1.0730e+05\n",
      "Epoch 28020, Training-Loss 4.8395e+03, Data-loss 4.1237e+03                  , pde-loss 1.2387e+03, initc-loss 1.5687e+04                    bc_loss 5.4657e+04\n",
      "Epoch 28030, Training-Loss 4.0750e+03, Data-loss 3.2358e+03                  , pde-loss 1.2248e+03, initc-loss 1.7391e+04                    bc_loss 6.5308e+04\n",
      "Epoch 28040, Training-Loss 6.8110e+03, Data-loss 4.2950e+03                  , pde-loss 1.2656e+03, initc-loss 1.9185e+04                    bc_loss 2.3115e+05\n",
      "Epoch 28050, Training-Loss 5.8363e+03, Data-loss 4.9876e+03                  , pde-loss 9.3692e+02, initc-loss 1.6090e+04                    bc_loss 6.7847e+04\n",
      "Epoch 28060, Training-Loss 3.7459e+03, Data-loss 2.9020e+03                  , pde-loss 1.4311e+03, initc-loss 1.5056e+04                    bc_loss 6.7903e+04\n",
      "Epoch 28070, Training-Loss 4.1171e+03, Data-loss 3.6915e+03                  , pde-loss 1.5822e+03, initc-loss 1.5280e+04                    bc_loss 2.5697e+04\n",
      "Epoch 28080, Training-Loss 4.7654e+03, Data-loss 4.0655e+03                  , pde-loss 1.3645e+03, initc-loss 1.6747e+04                    bc_loss 5.1884e+04\n",
      "Epoch 28090, Training-Loss 1.1946e+04, Data-loss 8.0025e+03                  , pde-loss 5.1775e+02, initc-loss 2.2264e+04                    bc_loss 3.7156e+05\n",
      "Epoch 28100, Training-Loss 3.7381e+03, Data-loss 2.8525e+03                  , pde-loss 6.6666e+02, initc-loss 1.5638e+04                    bc_loss 7.2259e+04\n",
      "Epoch 28110, Training-Loss 1.0106e+04, Data-loss 5.9276e+03                  , pde-loss 2.1270e+03, initc-loss 1.6013e+04                    bc_loss 3.9970e+05\n",
      "Epoch 28120, Training-Loss 4.6168e+03, Data-loss 3.8607e+03                  , pde-loss 1.4950e+03, initc-loss 1.9026e+04                    bc_loss 5.5091e+04\n",
      "Epoch 28130, Training-Loss 3.7827e+03, Data-loss 3.1518e+03                  , pde-loss 1.4414e+03, initc-loss 1.4658e+04                    bc_loss 4.6994e+04\n",
      "Epoch 28140, Training-Loss 3.8011e+03, Data-loss 3.2053e+03                  , pde-loss 1.4982e+03, initc-loss 1.3951e+04                    bc_loss 4.4124e+04\n",
      "Epoch 28150, Training-Loss 3.2468e+03, Data-loss 2.4300e+03                  , pde-loss 1.2252e+03, initc-loss 1.4214e+04                    bc_loss 6.6238e+04\n",
      "Epoch 28160, Training-Loss 2.2895e+03, Data-loss 1.7522e+03                  , pde-loss 1.2516e+03, initc-loss 1.2725e+04                    bc_loss 3.9762e+04\n",
      "Epoch 28170, Training-Loss 3.8863e+03, Data-loss 2.5252e+03                  , pde-loss 1.0205e+03, initc-loss 1.5586e+04                    bc_loss 1.1951e+05\n",
      "Epoch 28180, Training-Loss 6.6447e+03, Data-loss 2.8210e+03                  , pde-loss 3.8910e+02, initc-loss 1.6042e+04                    bc_loss 3.6594e+05\n",
      "Epoch 28190, Training-Loss 8.8362e+03, Data-loss 4.5037e+03                  , pde-loss 2.5237e+03, initc-loss 2.2372e+04                    bc_loss 4.0835e+05\n",
      "Epoch 28200, Training-Loss 4.4911e+03, Data-loss 3.5664e+03                  , pde-loss 2.7096e+03, initc-loss 1.6436e+04                    bc_loss 7.3320e+04\n",
      "Epoch 28210, Training-Loss 4.6915e+03, Data-loss 3.5492e+03                  , pde-loss 1.6796e+03, initc-loss 1.2248e+04                    bc_loss 1.0030e+05\n",
      "Epoch 28220, Training-Loss 2.4715e+03, Data-loss 1.6495e+03                  , pde-loss 9.7929e+02, initc-loss 1.7457e+04                    bc_loss 6.3762e+04\n",
      "Epoch 28230, Training-Loss 2.4305e+03, Data-loss 1.6343e+03                  , pde-loss 1.3402e+03, initc-loss 1.3940e+04                    bc_loss 6.4333e+04\n",
      "Epoch 28240, Training-Loss 5.8407e+03, Data-loss 2.4486e+03                  , pde-loss 7.9382e+02, initc-loss 1.5049e+04                    bc_loss 3.2337e+05\n",
      "Epoch 28250, Training-Loss 3.9902e+03, Data-loss 3.1810e+03                  , pde-loss 6.6511e+02, initc-loss 1.2692e+04                    bc_loss 6.7571e+04\n",
      "Epoch 28260, Training-Loss 3.7681e+03, Data-loss 2.9837e+03                  , pde-loss 1.5604e+03, initc-loss 1.4961e+04                    bc_loss 6.1913e+04\n",
      "Epoch 28270, Training-Loss 2.7001e+03, Data-loss 1.9319e+03                  , pde-loss 7.7659e+02, initc-loss 1.4792e+04                    bc_loss 6.1245e+04\n",
      "Epoch 28280, Training-Loss 4.2991e+03, Data-loss 3.1207e+03                  , pde-loss 1.3307e+03, initc-loss 1.5773e+04                    bc_loss 1.0073e+05\n",
      "Epoch 28290, Training-Loss 3.0099e+03, Data-loss 2.4514e+03                  , pde-loss 1.0307e+03, initc-loss 1.5665e+04                    bc_loss 3.9157e+04\n",
      "Epoch 28300, Training-Loss 1.0538e+04, Data-loss 5.7671e+03                  , pde-loss 4.9375e+02, initc-loss 1.9772e+04                    bc_loss 4.5678e+05\n",
      "Epoch 28310, Training-Loss 7.2224e+03, Data-loss 4.5999e+03                  , pde-loss 1.0027e+03, initc-loss 1.8889e+04                    bc_loss 2.4235e+05\n",
      "Epoch 28320, Training-Loss 7.3420e+03, Data-loss 2.2569e+03                  , pde-loss 4.3730e+03, initc-loss 1.2299e+04                    bc_loss 4.9184e+05\n",
      "Epoch 28330, Training-Loss 4.3613e+03, Data-loss 2.4988e+03                  , pde-loss 5.9163e+02, initc-loss 1.4219e+04                    bc_loss 1.7143e+05\n",
      "Epoch 28340, Training-Loss 5.9024e+03, Data-loss 1.8615e+03                  , pde-loss 1.7570e+03, initc-loss 9.7248e+03                    bc_loss 3.9261e+05\n",
      "Epoch 28350, Training-Loss 3.2712e+03, Data-loss 2.4359e+03                  , pde-loss 1.4378e+03, initc-loss 1.3045e+04                    bc_loss 6.9052e+04\n",
      "Epoch 28360, Training-Loss 8.3964e+03, Data-loss 3.8649e+03                  , pde-loss 6.4933e+02, initc-loss 1.6327e+04                    bc_loss 4.3617e+05\n",
      "Epoch 28370, Training-Loss 4.2383e+03, Data-loss 3.7815e+03                  , pde-loss 1.0694e+03, initc-loss 1.2742e+04                    bc_loss 3.1874e+04\n",
      "Epoch 28380, Training-Loss 2.5994e+03, Data-loss 1.6028e+03                  , pde-loss 1.5866e+03, initc-loss 1.3978e+04                    bc_loss 8.4088e+04\n",
      "Epoch 28390, Training-Loss 3.4072e+03, Data-loss 2.9572e+03                  , pde-loss 9.8976e+02, initc-loss 1.2943e+04                    bc_loss 3.1062e+04\n",
      "Epoch 28400, Training-Loss 1.8430e+03, Data-loss 1.4153e+03                  , pde-loss 1.4045e+03, initc-loss 1.2536e+04                    bc_loss 2.8831e+04\n",
      "Epoch 28410, Training-Loss 2.3245e+03, Data-loss 1.7063e+03                  , pde-loss 1.1973e+03, initc-loss 1.2551e+04                    bc_loss 4.8074e+04\n",
      "Epoch 28420, Training-Loss 5.5178e+03, Data-loss 1.2529e+03                  , pde-loss 7.2686e+02, initc-loss 1.4464e+04                    bc_loss 4.1130e+05\n",
      "Epoch 28430, Training-Loss 3.0457e+03, Data-loss 2.3379e+03                  , pde-loss 8.8125e+02, initc-loss 1.1016e+04                    bc_loss 5.8884e+04\n",
      "Epoch 28440, Training-Loss 2.6345e+03, Data-loss 1.1831e+03                  , pde-loss 1.6268e+03, initc-loss 1.2580e+04                    bc_loss 1.3093e+05\n",
      "Epoch 28450, Training-Loss 3.3360e+03, Data-loss 2.7701e+03                  , pde-loss 8.0801e+02, initc-loss 1.4178e+04                    bc_loss 4.1609e+04\n",
      "Epoch 28460, Training-Loss 2.5902e+03, Data-loss 2.1245e+03                  , pde-loss 1.4769e+03, initc-loss 1.4864e+04                    bc_loss 3.0229e+04\n",
      "Epoch 28470, Training-Loss 2.0923e+03, Data-loss 1.7225e+03                  , pde-loss 1.1040e+03, initc-loss 1.3393e+04                    bc_loss 2.2483e+04\n",
      "Epoch 28480, Training-Loss 1.9664e+03, Data-loss 1.4745e+03                  , pde-loss 1.2469e+03, initc-loss 1.5420e+04                    bc_loss 3.2522e+04\n",
      "Epoch 28490, Training-Loss 4.9916e+03, Data-loss 1.7983e+03                  , pde-loss 1.0552e+03, initc-loss 1.7288e+04                    bc_loss 3.0099e+05\n",
      "Epoch 28500, Training-Loss 4.8820e+03, Data-loss 2.4381e+03                  , pde-loss 4.0947e+02, initc-loss 1.3505e+04                    bc_loss 2.3047e+05\n",
      "Epoch 28510, Training-Loss 6.3943e+03, Data-loss 2.8499e+03                  , pde-loss 1.3128e+03, initc-loss 1.3021e+04                    bc_loss 3.4011e+05\n",
      "Epoch 28520, Training-Loss 8.1431e+03, Data-loss 5.0874e+03                  , pde-loss 5.3637e+03, initc-loss 1.1811e+04                    bc_loss 2.8840e+05\n",
      "Epoch 28530, Training-Loss 4.7855e+03, Data-loss 1.7283e+03                  , pde-loss 1.3179e+03, initc-loss 1.0829e+04                    bc_loss 2.9357e+05\n",
      "Epoch 28540, Training-Loss 3.1314e+03, Data-loss 1.6553e+03                  , pde-loss 6.3431e+02, initc-loss 1.2183e+04                    bc_loss 1.3480e+05\n",
      "Epoch 28550, Training-Loss 2.9929e+03, Data-loss 1.6718e+03                  , pde-loss 1.3308e+03, initc-loss 1.4509e+04                    bc_loss 1.1627e+05\n",
      "Epoch 28560, Training-Loss 1.3600e+03, Data-loss 8.8926e+02                  , pde-loss 1.1242e+03, initc-loss 1.2230e+04                    bc_loss 3.3720e+04\n",
      "Epoch 28570, Training-Loss 2.0132e+03, Data-loss 9.6060e+02                  , pde-loss 1.2365e+03, initc-loss 1.2334e+04                    bc_loss 9.1685e+04\n",
      "Epoch 28580, Training-Loss 3.1964e+03, Data-loss 2.5567e+03                  , pde-loss 1.1466e+03, initc-loss 1.5947e+04                    bc_loss 4.6875e+04\n",
      "Epoch 28590, Training-Loss 2.6872e+03, Data-loss 1.2556e+03                  , pde-loss 9.5985e+02, initc-loss 1.5344e+04                    bc_loss 1.2686e+05\n",
      "Epoch 28600, Training-Loss 4.7738e+03, Data-loss 3.0495e+03                  , pde-loss 4.3954e+02, initc-loss 1.2626e+04                    bc_loss 1.5936e+05\n",
      "Epoch 28610, Training-Loss 2.8350e+03, Data-loss 2.0858e+03                  , pde-loss 1.8585e+03, initc-loss 1.6090e+04                    bc_loss 5.6972e+04\n",
      "Epoch 28620, Training-Loss 3.7732e+03, Data-loss 2.7638e+03                  , pde-loss 8.4895e+02, initc-loss 1.4269e+04                    bc_loss 8.5821e+04\n",
      "Epoch 28630, Training-Loss 1.8522e+03, Data-loss 1.4199e+03                  , pde-loss 1.1412e+03, initc-loss 1.2824e+04                    bc_loss 2.9260e+04\n",
      "Epoch 28640, Training-Loss 2.6274e+03, Data-loss 2.2484e+03                  , pde-loss 1.2684e+03, initc-loss 1.4588e+04                    bc_loss 2.2049e+04\n",
      "Epoch 28650, Training-Loss 1.3721e+03, Data-loss 9.2075e+02                  , pde-loss 1.2871e+03, initc-loss 1.2795e+04                    bc_loss 3.1048e+04\n",
      "Epoch 28660, Training-Loss 2.3555e+03, Data-loss 1.7835e+03                  , pde-loss 1.2867e+03, initc-loss 1.3315e+04                    bc_loss 4.2597e+04\n",
      "Epoch 28670, Training-Loss 1.9654e+03, Data-loss 1.4416e+03                  , pde-loss 1.1233e+03, initc-loss 1.2214e+04                    bc_loss 3.9045e+04\n",
      "Epoch 28680, Training-Loss 9.6809e+03, Data-loss 4.5722e+03                  , pde-loss 4.5435e+02, initc-loss 1.7660e+04                    bc_loss 4.9275e+05\n",
      "Epoch 28690, Training-Loss 2.9863e+03, Data-loss 2.2005e+03                  , pde-loss 3.6211e+02, initc-loss 1.4757e+04                    bc_loss 6.3462e+04\n",
      "Epoch 28700, Training-Loss 1.2387e+04, Data-loss 2.0895e+03                  , pde-loss 2.8214e+03, initc-loss 1.8698e+04                    bc_loss 1.0082e+06\n",
      "Epoch 28710, Training-Loss 5.2323e+03, Data-loss 2.6877e+03                  , pde-loss 3.1685e+03, initc-loss 1.2084e+04                    bc_loss 2.3920e+05\n",
      "Epoch 28720, Training-Loss 3.5627e+03, Data-loss 2.0718e+03                  , pde-loss 1.2668e+03, initc-loss 7.4302e+03                    bc_loss 1.4039e+05\n",
      "Epoch 28730, Training-Loss 2.7407e+03, Data-loss 1.6302e+03                  , pde-loss 1.4765e+03, initc-loss 1.1121e+04                    bc_loss 9.8450e+04\n",
      "Epoch 28740, Training-Loss 8.9606e+03, Data-loss 1.7168e+03                  , pde-loss 1.7231e+03, initc-loss 8.4774e+03                    bc_loss 7.1418e+05\n",
      "Epoch 28750, Training-Loss 7.2485e+03, Data-loss 3.4069e+03                  , pde-loss 4.0986e+02, initc-loss 1.4871e+04                    bc_loss 3.6888e+05\n",
      "Epoch 28760, Training-Loss 2.3744e+03, Data-loss 1.8980e+03                  , pde-loss 1.4308e+03, initc-loss 1.4816e+04                    bc_loss 3.1395e+04\n",
      "Epoch 28770, Training-Loss 3.7824e+03, Data-loss 2.7474e+03                  , pde-loss 1.2357e+03, initc-loss 1.4001e+04                    bc_loss 8.8267e+04\n",
      "Epoch 28780, Training-Loss 3.5942e+03, Data-loss 3.0364e+03                  , pde-loss 8.4105e+02, initc-loss 1.0560e+04                    bc_loss 4.4383e+04\n",
      "Epoch 28790, Training-Loss 1.1836e+03, Data-loss 8.0469e+02                  , pde-loss 1.4957e+03, initc-loss 1.3303e+04                    bc_loss 2.3095e+04\n",
      "Epoch 28800, Training-Loss 2.4180e+03, Data-loss 2.0919e+03                  , pde-loss 1.0820e+03, initc-loss 1.3846e+04                    bc_loss 1.7685e+04\n",
      "Epoch 28810, Training-Loss 2.1797e+03, Data-loss 1.8425e+03                  , pde-loss 1.3254e+03, initc-loss 1.1891e+04                    bc_loss 2.0508e+04\n",
      "Epoch 28820, Training-Loss 1.4897e+03, Data-loss 1.1934e+03                  , pde-loss 1.0665e+03, initc-loss 1.3209e+04                    bc_loss 1.5350e+04\n",
      "Epoch 28830, Training-Loss 3.6438e+03, Data-loss 2.1061e+03                  , pde-loss 7.8020e+02, initc-loss 1.7631e+04                    bc_loss 1.3536e+05\n",
      "Epoch 28840, Training-Loss 2.1985e+03, Data-loss 8.3405e+02                  , pde-loss 4.5788e+02, initc-loss 9.3465e+03                    bc_loss 1.2664e+05\n",
      "Epoch 28850, Training-Loss 4.4384e+03, Data-loss 2.0107e+03                  , pde-loss 2.6422e+03, initc-loss 1.7227e+04                    bc_loss 2.2289e+05\n",
      "Epoch 28860, Training-Loss 2.6062e+03, Data-loss 1.6637e+03                  , pde-loss 2.9386e+03, initc-loss 1.2867e+04                    bc_loss 7.8446e+04\n",
      "Epoch 28870, Training-Loss 5.1233e+03, Data-loss 4.3916e+03                  , pde-loss 6.7372e+02, initc-loss 1.5604e+04                    bc_loss 5.6891e+04\n",
      "Epoch 28880, Training-Loss 2.6761e+03, Data-loss 1.5753e+03                  , pde-loss 1.2196e+03, initc-loss 1.4572e+04                    bc_loss 9.4289e+04\n",
      "Epoch 28890, Training-Loss 3.4487e+03, Data-loss 2.9426e+03                  , pde-loss 1.2159e+03, initc-loss 1.3341e+04                    bc_loss 3.6054e+04\n",
      "Epoch 28900, Training-Loss 7.6053e+03, Data-loss 1.4185e+03                  , pde-loss 9.2436e+02, initc-loss 1.6024e+04                    bc_loss 6.0173e+05\n",
      "Epoch 28910, Training-Loss 2.1410e+03, Data-loss 1.3749e+03                  , pde-loss 7.4517e+02, initc-loss 1.2483e+04                    bc_loss 6.3383e+04\n",
      "Epoch 28920, Training-Loss 2.2598e+03, Data-loss 1.8645e+03                  , pde-loss 1.8814e+03, initc-loss 1.5879e+04                    bc_loss 2.1771e+04\n",
      "Epoch 28930, Training-Loss 2.2462e+03, Data-loss 1.7506e+03                  , pde-loss 1.1471e+03, initc-loss 1.5627e+04                    bc_loss 3.2780e+04\n",
      "Epoch 28940, Training-Loss 2.2188e+03, Data-loss 1.4836e+03                  , pde-loss 1.3546e+03, initc-loss 1.2128e+04                    bc_loss 6.0034e+04\n",
      "Epoch 28950, Training-Loss 9.8324e+02, Data-loss 7.1439e+02                  , pde-loss 1.0261e+03, initc-loss 1.3496e+04                    bc_loss 1.2363e+04\n",
      "Epoch 28960, Training-Loss 1.7684e+03, Data-loss 1.5166e+03                  , pde-loss 1.0599e+03, initc-loss 1.1961e+04                    bc_loss 1.2159e+04\n",
      "Epoch 28970, Training-Loss 2.0329e+03, Data-loss 1.5861e+03                  , pde-loss 1.3689e+03, initc-loss 1.3834e+04                    bc_loss 2.9470e+04\n",
      "Epoch 28980, Training-Loss 2.0881e+03, Data-loss 1.3490e+03                  , pde-loss 1.2264e+03, initc-loss 1.4142e+04                    bc_loss 5.8533e+04\n",
      "Epoch 28990, Training-Loss 1.0167e+04, Data-loss 6.1544e+03                  , pde-loss 5.6672e+02, initc-loss 2.2016e+04                    bc_loss 3.7864e+05\n",
      "Epoch 29000, Training-Loss 9.9753e+03, Data-loss 5.5624e+03                  , pde-loss 4.7523e+02, initc-loss 2.1406e+04                    bc_loss 4.1940e+05\n",
      "Epoch 29010, Training-Loss 1.5421e+04, Data-loss 4.6447e+03                  , pde-loss 3.6438e+03, initc-loss 1.8983e+04                    bc_loss 1.0550e+06\n",
      "Epoch 29020, Training-Loss 8.0645e+03, Data-loss 3.5693e+03                  , pde-loss 3.4523e+02, initc-loss 1.6422e+04                    bc_loss 4.3275e+05\n",
      "Epoch 29030, Training-Loss 1.7787e+03, Data-loss 1.3052e+03                  , pde-loss 1.7477e+03, initc-loss 2.0438e+04                    bc_loss 2.5165e+04\n",
      "Epoch 29040, Training-Loss 2.1201e+03, Data-loss 1.5432e+03                  , pde-loss 1.9466e+03, initc-loss 1.4155e+04                    bc_loss 4.1587e+04\n",
      "Epoch 29050, Training-Loss 2.8115e+03, Data-loss 2.3424e+03                  , pde-loss 8.4743e+02, initc-loss 1.2559e+04                    bc_loss 3.3509e+04\n",
      "Epoch 29060, Training-Loss 2.6473e+03, Data-loss 2.2490e+03                  , pde-loss 1.5492e+03, initc-loss 1.4557e+04                    bc_loss 2.3728e+04\n",
      "Epoch 29070, Training-Loss 1.8085e+03, Data-loss 1.4835e+03                  , pde-loss 1.3679e+03, initc-loss 1.2925e+04                    bc_loss 1.8200e+04\n",
      "Epoch 29080, Training-Loss 2.5507e+03, Data-loss 1.7419e+03                  , pde-loss 1.0558e+03, initc-loss 1.2387e+04                    bc_loss 6.7435e+04\n",
      "Epoch 29090, Training-Loss 3.1880e+03, Data-loss 2.3591e+03                  , pde-loss 1.2019e+03, initc-loss 1.7066e+04                    bc_loss 6.4623e+04\n",
      "Epoch 29100, Training-Loss 1.2415e+03, Data-loss 9.1863e+02                  , pde-loss 1.3910e+03, initc-loss 1.5114e+04                    bc_loss 1.5786e+04\n",
      "Epoch 29110, Training-Loss 3.9271e+03, Data-loss 2.0739e+03                  , pde-loss 1.0767e+03, initc-loss 1.5837e+04                    bc_loss 1.6841e+05\n",
      "Epoch 29120, Training-Loss 4.0115e+03, Data-loss 2.5615e+03                  , pde-loss 6.0765e+02, initc-loss 1.3738e+04                    bc_loss 1.3066e+05\n",
      "Epoch 29130, Training-Loss 1.5789e+03, Data-loss 1.2616e+03                  , pde-loss 1.6067e+03, initc-loss 1.4327e+04                    bc_loss 1.5794e+04\n",
      "Epoch 29140, Training-Loss 1.7343e+03, Data-loss 1.4679e+03                  , pde-loss 1.4767e+03, initc-loss 1.4742e+04                    bc_loss 1.0418e+04\n",
      "Epoch 29150, Training-Loss 1.3321e+03, Data-loss 9.6482e+02                  , pde-loss 9.8335e+02, initc-loss 1.3871e+04                    bc_loss 2.1874e+04\n",
      "Epoch 29160, Training-Loss 2.0694e+03, Data-loss 1.2974e+03                  , pde-loss 1.3885e+03, initc-loss 1.2789e+04                    bc_loss 6.3025e+04\n",
      "Epoch 29170, Training-Loss 1.1243e+03, Data-loss 8.6141e+02                  , pde-loss 1.3710e+03, initc-loss 1.0653e+04                    bc_loss 1.4269e+04\n",
      "Epoch 29180, Training-Loss 1.3574e+03, Data-loss 1.1359e+03                  , pde-loss 1.2761e+03, initc-loss 1.3800e+04                    bc_loss 7.0700e+03\n",
      "Epoch 29190, Training-Loss 3.1319e+03, Data-loss 1.6650e+03                  , pde-loss 1.5538e+03, initc-loss 1.5673e+04                    bc_loss 1.2947e+05\n",
      "Epoch 29200, Training-Loss 9.1864e+03, Data-loss 4.1586e+03                  , pde-loss 4.0853e+03, initc-loss 2.5436e+04                    bc_loss 4.7326e+05\n",
      "Epoch 29210, Training-Loss 1.2028e+04, Data-loss 1.9811e+03                  , pde-loss 1.4890e+03, initc-loss 1.8612e+04                    bc_loss 9.8459e+05\n",
      "Epoch 29220, Training-Loss 1.2895e+04, Data-loss 6.0850e+03                  , pde-loss 6.3194e+02, initc-loss 1.6310e+04                    bc_loss 6.6410e+05\n",
      "Epoch 29230, Training-Loss 4.9860e+03, Data-loss 2.9176e+03                  , pde-loss 6.7915e+02, initc-loss 2.0075e+04                    bc_loss 1.8608e+05\n",
      "Epoch 29240, Training-Loss 3.1023e+03, Data-loss 2.4854e+03                  , pde-loss 6.9569e+02, initc-loss 1.3009e+04                    bc_loss 4.7984e+04\n",
      "Epoch 29250, Training-Loss 2.1754e+03, Data-loss 1.6929e+03                  , pde-loss 1.2335e+03, initc-loss 1.8208e+04                    bc_loss 2.8811e+04\n",
      "Epoch 29260, Training-Loss 1.9086e+03, Data-loss 1.4884e+03                  , pde-loss 1.7220e+03, initc-loss 1.4506e+04                    bc_loss 2.5790e+04\n",
      "Epoch 29270, Training-Loss 1.8141e+03, Data-loss 1.3915e+03                  , pde-loss 1.1805e+03, initc-loss 1.2373e+04                    bc_loss 2.8705e+04\n",
      "Epoch 29280, Training-Loss 2.3454e+03, Data-loss 1.9645e+03                  , pde-loss 1.3567e+03, initc-loss 1.4071e+04                    bc_loss 2.2656e+04\n",
      "Epoch 29290, Training-Loss 2.6960e+03, Data-loss 2.2998e+03                  , pde-loss 1.5016e+03, initc-loss 1.5480e+04                    bc_loss 2.2632e+04\n",
      "Epoch 29300, Training-Loss 1.0224e+03, Data-loss 7.8140e+02                  , pde-loss 1.3948e+03, initc-loss 1.3497e+04                    bc_loss 9.2035e+03\n",
      "Epoch 29310, Training-Loss 2.2421e+03, Data-loss 1.7345e+03                  , pde-loss 1.1700e+03, initc-loss 1.6168e+04                    bc_loss 3.3417e+04\n",
      "Epoch 29320, Training-Loss 2.2675e+03, Data-loss 1.9688e+03                  , pde-loss 1.4054e+03, initc-loss 1.4512e+04                    bc_loss 1.3953e+04\n",
      "Epoch 29330, Training-Loss 1.8719e+03, Data-loss 1.5990e+03                  , pde-loss 1.1949e+03, initc-loss 1.4614e+04                    bc_loss 1.1490e+04\n",
      "Epoch 29340, Training-Loss 3.5173e+03, Data-loss 2.7036e+03                  , pde-loss 1.2567e+03, initc-loss 2.5802e+04                    bc_loss 5.4313e+04\n",
      "Epoch 29350, Training-Loss 1.7634e+04, Data-loss 9.5677e+03                  , pde-loss 3.4889e+02, initc-loss 3.0665e+04                    bc_loss 7.7564e+05\n",
      "Epoch 29360, Training-Loss 1.0237e+04, Data-loss 8.4494e+03                  , pde-loss 3.2631e+02, initc-loss 1.2794e+04                    bc_loss 1.6567e+05\n",
      "Epoch 29370, Training-Loss 7.3463e+03, Data-loss 2.8097e+03                  , pde-loss 1.4874e+03, initc-loss 1.8737e+04                    bc_loss 4.3344e+05\n",
      "Epoch 29380, Training-Loss 3.9738e+03, Data-loss 2.8887e+03                  , pde-loss 5.5440e+02, initc-loss 1.4901e+04                    bc_loss 9.3057e+04\n",
      "Epoch 29390, Training-Loss 3.1611e+03, Data-loss 1.8017e+03                  , pde-loss 7.6583e+02, initc-loss 9.6144e+03                    bc_loss 1.2556e+05\n",
      "Epoch 29400, Training-Loss 1.0199e+04, Data-loss 4.2837e+03                  , pde-loss 3.8804e+03, initc-loss 2.1405e+04                    bc_loss 5.6620e+05\n",
      "Epoch 29410, Training-Loss 4.0623e+03, Data-loss 2.4313e+03                  , pde-loss 3.1926e+03, initc-loss 9.5395e+03                    bc_loss 1.5036e+05\n",
      "Epoch 29420, Training-Loss 4.1065e+03, Data-loss 3.0281e+03                  , pde-loss 5.6449e+02, initc-loss 1.3256e+04                    bc_loss 9.4021e+04\n",
      "Epoch 29430, Training-Loss 1.7376e+03, Data-loss 1.4364e+03                  , pde-loss 1.4767e+03, initc-loss 1.4367e+04                    bc_loss 1.4272e+04\n",
      "Epoch 29440, Training-Loss 2.3067e+03, Data-loss 2.0062e+03                  , pde-loss 1.5048e+03, initc-loss 1.3585e+04                    bc_loss 1.4952e+04\n",
      "Epoch 29450, Training-Loss 3.1493e+03, Data-loss 2.9161e+03                  , pde-loss 9.9786e+02, initc-loss 1.3273e+04                    bc_loss 9.0577e+03\n",
      "Epoch 29460, Training-Loss 6.1495e+02, Data-loss 3.9071e+02                  , pde-loss 1.3217e+03, initc-loss 1.3930e+04                    bc_loss 7.1721e+03\n",
      "Epoch 29470, Training-Loss 1.3485e+03, Data-loss 1.0636e+03                  , pde-loss 1.5674e+03, initc-loss 1.1221e+04                    bc_loss 1.5702e+04\n",
      "Epoch 29480, Training-Loss 1.6946e+03, Data-loss 8.9893e+02                  , pde-loss 1.2221e+03, initc-loss 1.1344e+04                    bc_loss 6.7003e+04\n",
      "Epoch 29490, Training-Loss 1.7598e+03, Data-loss 1.0450e+03                  , pde-loss 1.0896e+03, initc-loss 1.3028e+04                    bc_loss 5.7355e+04\n",
      "Epoch 29500, Training-Loss 1.3543e+03, Data-loss 1.0999e+03                  , pde-loss 1.4864e+03, initc-loss 1.4435e+04                    bc_loss 9.5150e+03\n",
      "Epoch 29510, Training-Loss 1.9435e+03, Data-loss 1.4679e+03                  , pde-loss 1.3809e+03, initc-loss 1.3223e+04                    bc_loss 3.2951e+04\n",
      "Epoch 29520, Training-Loss 8.5294e+03, Data-loss 2.8177e+03                  , pde-loss 4.7700e+02, initc-loss 1.2654e+04                    bc_loss 5.5804e+05\n",
      "Epoch 29530, Training-Loss 3.4824e+03, Data-loss 2.5060e+03                  , pde-loss 8.8202e+02, initc-loss 9.3331e+03                    bc_loss 8.7428e+04\n",
      "Epoch 29540, Training-Loss 2.6180e+03, Data-loss 2.1210e+03                  , pde-loss 2.0649e+03, initc-loss 1.2814e+04                    bc_loss 3.4820e+04\n",
      "Epoch 29550, Training-Loss 1.1074e+03, Data-loss 8.2519e+02                  , pde-loss 1.3579e+03, initc-loss 1.2181e+04                    bc_loss 1.4685e+04\n",
      "Epoch 29560, Training-Loss 6.7009e+03, Data-loss 1.1905e+03                  , pde-loss 1.1659e+03, initc-loss 1.3259e+04                    bc_loss 5.3662e+05\n",
      "Epoch 29570, Training-Loss 1.5283e+03, Data-loss 1.1687e+03                  , pde-loss 1.4237e+03, initc-loss 9.8181e+03                    bc_loss 2.4718e+04\n",
      "Epoch 29580, Training-Loss 8.9429e+02, Data-loss 6.6996e+02                  , pde-loss 1.3542e+03, initc-loss 1.2001e+04                    bc_loss 9.0768e+03\n",
      "Epoch 29590, Training-Loss 1.2139e+03, Data-loss 8.9135e+02                  , pde-loss 1.3251e+03, initc-loss 1.0682e+04                    bc_loss 2.0251e+04\n",
      "Epoch 29600, Training-Loss 2.8813e+03, Data-loss 1.6255e+03                  , pde-loss 1.3299e+03, initc-loss 1.3604e+04                    bc_loss 1.1064e+05\n",
      "Epoch 29610, Training-Loss 1.7840e+03, Data-loss 1.3855e+03                  , pde-loss 1.0460e+03, initc-loss 1.1410e+04                    bc_loss 2.7388e+04\n",
      "Epoch 29620, Training-Loss 1.1755e+03, Data-loss 9.3780e+02                  , pde-loss 1.3239e+03, initc-loss 1.1452e+04                    bc_loss 1.0990e+04\n",
      "Epoch 29630, Training-Loss 4.3185e+03, Data-loss 1.0687e+03                  , pde-loss 1.7588e+03, initc-loss 1.7693e+04                    bc_loss 3.0552e+05\n",
      "Epoch 29640, Training-Loss 8.3342e+03, Data-loss 4.6043e+03                  , pde-loss 6.1121e+03, initc-loss 1.0463e+04                    bc_loss 3.5642e+05\n",
      "Epoch 29650, Training-Loss 3.9818e+03, Data-loss 1.8824e+03                  , pde-loss 2.6748e+03, initc-loss 1.3992e+04                    bc_loss 1.9327e+05\n",
      "Epoch 29660, Training-Loss 1.0726e+04, Data-loss 4.2250e+03                  , pde-loss 4.7545e+02, initc-loss 2.0231e+04                    bc_loss 6.2937e+05\n",
      "Epoch 29670, Training-Loss 3.8177e+03, Data-loss 2.9275e+03                  , pde-loss 1.6164e+03, initc-loss 6.9839e+03                    bc_loss 8.0422e+04\n",
      "Epoch 29680, Training-Loss 3.0498e+03, Data-loss 2.2618e+03                  , pde-loss 1.3885e+03, initc-loss 1.3098e+04                    bc_loss 6.4318e+04\n",
      "Epoch 29690, Training-Loss 1.4682e+03, Data-loss 8.1882e+02                  , pde-loss 9.8631e+02, initc-loss 1.4198e+04                    bc_loss 4.9749e+04\n",
      "Epoch 29700, Training-Loss 2.0343e+03, Data-loss 1.2494e+03                  , pde-loss 1.3562e+03, initc-loss 1.4002e+04                    bc_loss 6.3127e+04\n",
      "Epoch 29710, Training-Loss 1.2824e+03, Data-loss 9.9998e+02                  , pde-loss 1.2214e+03, initc-loss 1.2084e+04                    bc_loss 1.4933e+04\n",
      "Epoch 29720, Training-Loss 9.0810e+02, Data-loss 5.4099e+02                  , pde-loss 1.1538e+03, initc-loss 1.2670e+04                    bc_loss 2.2887e+04\n",
      "Epoch 29730, Training-Loss 8.4446e+02, Data-loss 3.6981e+02                  , pde-loss 1.2489e+03, initc-loss 1.3004e+04                    bc_loss 3.3212e+04\n",
      "Epoch 29740, Training-Loss 1.3308e+03, Data-loss 1.0512e+03                  , pde-loss 1.2584e+03, initc-loss 1.1779e+04                    bc_loss 1.4926e+04\n",
      "Epoch 29750, Training-Loss 1.7059e+03, Data-loss 1.3559e+03                  , pde-loss 1.1010e+03, initc-loss 1.0034e+04                    bc_loss 2.3871e+04\n",
      "Epoch 29760, Training-Loss 2.0068e+03, Data-loss 1.4156e+03                  , pde-loss 1.0695e+03, initc-loss 1.2476e+04                    bc_loss 4.5574e+04\n",
      "Epoch 29770, Training-Loss 1.1776e+03, Data-loss 9.1689e+02                  , pde-loss 1.2089e+03, initc-loss 1.3667e+04                    bc_loss 1.1193e+04\n",
      "Epoch 29780, Training-Loss 1.2721e+03, Data-loss 1.0132e+03                  , pde-loss 1.1586e+03, initc-loss 1.1224e+04                    bc_loss 1.3510e+04\n",
      "Epoch 29790, Training-Loss 1.0776e+03, Data-loss 7.5817e+02                  , pde-loss 1.3184e+03, initc-loss 1.3240e+04                    bc_loss 1.7382e+04\n",
      "Epoch 29800, Training-Loss 8.6456e+03, Data-loss 3.4177e+03                  , pde-loss 5.3863e+02, initc-loss 2.5107e+04                    bc_loss 4.9714e+05\n",
      "Epoch 29810, Training-Loss 2.5716e+03, Data-loss 1.7900e+03                  , pde-loss 7.2673e+02, initc-loss 2.0869e+04                    bc_loss 5.6563e+04\n",
      "Epoch 29820, Training-Loss 2.7118e+03, Data-loss 1.5859e+03                  , pde-loss 1.2041e+03, initc-loss 1.4122e+04                    bc_loss 9.7262e+04\n",
      "Epoch 29830, Training-Loss 1.8249e+03, Data-loss 1.5092e+03                  , pde-loss 1.2646e+03, initc-loss 1.4400e+04                    bc_loss 1.5903e+04\n",
      "Epoch 29840, Training-Loss 3.5444e+03, Data-loss 8.1049e+02                  , pde-loss 1.2965e+03, initc-loss 1.2901e+04                    bc_loss 2.5919e+05\n",
      "Epoch 29850, Training-Loss 3.6760e+03, Data-loss 1.0182e+03                  , pde-loss 1.5529e+03, initc-loss 1.3529e+04                    bc_loss 2.5070e+05\n",
      "Epoch 29860, Training-Loss 2.0141e+03, Data-loss 1.2775e+03                  , pde-loss 1.3691e+03, initc-loss 1.1376e+04                    bc_loss 6.0912e+04\n",
      "Epoch 29870, Training-Loss 1.5022e+03, Data-loss 1.1987e+03                  , pde-loss 1.1606e+03, initc-loss 1.2911e+04                    bc_loss 1.6281e+04\n",
      "Epoch 29880, Training-Loss 1.4517e+03, Data-loss 9.9259e+02                  , pde-loss 1.2607e+03, initc-loss 1.0575e+04                    bc_loss 3.4071e+04\n",
      "Epoch 29890, Training-Loss 4.8210e+03, Data-loss 1.1489e+03                  , pde-loss 1.8027e+03, initc-loss 1.4933e+04                    bc_loss 3.5047e+05\n",
      "Epoch 29900, Training-Loss 5.7128e+03, Data-loss 1.7269e+03                  , pde-loss 3.7233e+03, initc-loss 1.4846e+04                    bc_loss 3.8002e+05\n",
      "Epoch 29910, Training-Loss 1.1929e+04, Data-loss 4.3051e+03                  , pde-loss 7.2378e+02, initc-loss 3.0635e+04                    bc_loss 7.3103e+05\n",
      "Epoch 29920, Training-Loss 5.2061e+03, Data-loss 2.4197e+03                  , pde-loss 2.8431e+02, initc-loss 1.8368e+04                    bc_loss 2.5999e+05\n",
      "Epoch 29930, Training-Loss 2.6735e+03, Data-loss 1.6825e+03                  , pde-loss 3.7672e+02, initc-loss 1.4495e+04                    bc_loss 8.4223e+04\n",
      "Epoch 29940, Training-Loss 1.5599e+03, Data-loss 9.8259e+02                  , pde-loss 7.6466e+02, initc-loss 1.6181e+04                    bc_loss 4.0782e+04\n",
      "Epoch 29950, Training-Loss 2.5222e+03, Data-loss 1.7329e+03                  , pde-loss 1.7011e+03, initc-loss 1.6040e+04                    bc_loss 6.1190e+04\n",
      "Epoch 29960, Training-Loss 1.3491e+03, Data-loss 1.0675e+03                  , pde-loss 2.2128e+03, initc-loss 1.1579e+04                    bc_loss 1.4373e+04\n",
      "Epoch 29970, Training-Loss 3.2125e+03, Data-loss 2.8042e+03                  , pde-loss 1.5382e+03, initc-loss 1.3848e+04                    bc_loss 2.5446e+04\n",
      "Epoch 29980, Training-Loss 1.6278e+03, Data-loss 1.2680e+03                  , pde-loss 1.2873e+03, initc-loss 1.1289e+04                    bc_loss 2.3397e+04\n",
      "Epoch 29990, Training-Loss 1.2282e+03, Data-loss 7.3827e+02                  , pde-loss 1.2620e+03, initc-loss 1.2433e+04                    bc_loss 3.5295e+04\n",
      "Epoch 30000, Test-Loss 5.7574e+02, Test-Accuracy 2.1102e-02\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses, val_losses = training_loop(epochs, model, loss_fn_data, optimizer,train_loader)  # Train the model\n",
    " \n",
    "test_losses = test_loop(epochs, model, loss_fn_data, optimizer, train_loader, test_loader)  # Test the model\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_nn = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).cpu().detach().numpy() # Get the predictions from the model\n",
    "\n",
    "temp_nn = temp_nn.reshape(num_steps+1, num_points) # Reshape the predictions to a 2D array\n",
    "time_ss= np.linspace(0, time_end, num_steps+1)\n",
    "plt.figure\n",
    "plt.plot(time_ss, temp_nn[:,num_points//2], label='Predicted Temperature')\n",
    "plt.plot(time_ss, temperature_history[:,num_points//2], label='Actual Temperature')\n",
    "plt.xlabel('Time(s)')\n",
    "plt.ylabel('Temperature (K)')\n",
    "plt.title('Predicted vs Actual Temperature at x = 7.5mm')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
