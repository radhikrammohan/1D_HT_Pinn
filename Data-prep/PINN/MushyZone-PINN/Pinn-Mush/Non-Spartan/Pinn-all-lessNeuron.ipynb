{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Three Phase Simulation of Alloys and PINN model development \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the simulation of 1D Phase change of aluminium alloy. There will be three phases (solid,liquid and mushy).   \n",
    "\n",
    "The approach used is finite difference method and the physics involved in heat conduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import csv\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "\n",
    "from pinn_loss import loss_fn_data, l1_regularization, pde_loss, boundary_loss, ic_loss, accuracy\n",
    "from Input_vec_gen import input_gen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the constants and inital geometric domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_l = 3.394878564540885e-05, alpha_s = 3.686205086349929e-05, m_eff = 6.296953764744878e-06\n",
      "dx is 0.0003061224489795918\n",
      "dt is  0.0012711033647622566\n",
      "num_steps is 31469\n",
      "cfl is 0.0012711033647622566\n",
      "stability criteria satisfied\n"
     ]
    }
   ],
   "source": [
    "# Geometry\n",
    "length = 15.0e-3             # Length of the rod\n",
    "\n",
    "# Material properties\n",
    "rho = 2300.0                     # Density of AL380 (kg/m^3)\n",
    "rho_l = 2460.0                   # Density of AL380 (kg/m^3)\n",
    "rho_s = 2710.0                    # Density of AL380 (kg/m^3)\n",
    "rho_m = (rho_l + rho_s )/2       # Desnity in mushy zone is taken as average of liquid and solid density\n",
    "\n",
    "k = 104.0                       # W/m-K\n",
    "k_l = k                       # W/m-K\n",
    "k_s = 96.2                    # W/m-K\n",
    "k_m =  (k_l+k_s)/2                     # W/m-K\n",
    "k_mo = 41.5\n",
    "\n",
    "\n",
    "cp = 1245.3                      # Specific heat of aluminum (J/kg-K)\n",
    "cp_l = cp                      # Specific heat of aluminum (J/kg-K)\n",
    "cp_s = 963.0                 # Specific heat of aluminum (J/kg-K)\n",
    "cp_m =  (cp_l+cp_s)/2                 # Specific heat of mushy zone is taken as average of liquid and solid specific heat\n",
    "# cp_m = cp\n",
    "           # Thermal diffusivity\n",
    "alpha_l = k_l / (rho_l * cp_l) \n",
    "alpha_s = k_s / (rho_s*cp_s)\n",
    "alpha_m = k_m / (rho_m * cp_m)          #`Thermal diffusivity in mushy zone is taken as average of liquid and solid thermal diffusivity`\n",
    "\n",
    "\n",
    "#L_fusion = 3.9e3                 # J/kg\n",
    "L_fusion = 389.0e3               # J/kg  # Latent heat of fusion of aluminum\n",
    "         # Thermal diffusivity\n",
    "\n",
    "\n",
    "T_L = 574.4 +273.0                       #  K -Liquidus Temperature (615 c) AL 380\n",
    "T_S = 497.3 +273.0                     # K- Solidus Temperature (550 C)\n",
    "m_eff =(k_m/(rho_m*(cp_m + (L_fusion/(T_L-T_S)))))\n",
    "print (f\"alpha_l = {alpha_l}, alpha_s = {alpha_s}, m_eff = {m_eff}\")\n",
    "\n",
    "# htc = 10.0                   # W/m^2-K\n",
    "# q = htc*(919.0-723.0)\n",
    "# q = 10000.0\n",
    "\n",
    "\n",
    "num_points = 50                        # Number of spatial points\n",
    "dx = length / (num_points - 1)         # Distance between two spatial points\n",
    "print('dx is',dx)\n",
    "\n",
    "                                                              \n",
    "# Time Discretization  \n",
    "# \n",
    "time_end = 40        # seconds                         \n",
    "\n",
    "maxi = max(alpha_s,alpha_l,alpha_m)\n",
    "dt = abs(0.5*((dx**2) /maxi)) \n",
    "\n",
    "print('dt is ',dt)\n",
    "num_steps = round(time_end/dt)\n",
    "print('num_steps is',num_steps)\n",
    "cfl = 0.5 *(dx**2/max(alpha_l,alpha_s,alpha_m))\n",
    "print('cfl is',cfl)\n",
    "\n",
    "time_steps = np.linspace(0, time_end, num_steps + 1)\n",
    "step_coeff = dt / (dx ** 2)\n",
    "\n",
    "if dt <= cfl:\n",
    "    print('stability criteria satisfied')\n",
    "else:\n",
    "    print('stability criteria not satisfied')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial and Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_init = 919.0\n",
    "# Initial temperature and phase fields\n",
    "temperature = np.full(num_points+2, 919.0)            # Initial temperature of the rod with ghost points at both ends\n",
    "phase = np.zeros(num_points+2)*0.0                    # Initial phase of the rod with ghost points at both ends\n",
    "\n",
    "# Set boundary conditions\n",
    "# temperature[-1] = 919.0 \n",
    "phase[-1] = 1.0\n",
    "\n",
    "# temperature[0] = 919.0 #(40 C)\n",
    "phase[0] = 1.0\n",
    "\n",
    "# Store initial state in history\n",
    "temperature_history = [temperature.copy()]    # List to store temperature at each time step\n",
    "phi_history = [phase.copy()]                    # List to store phase at each time step\n",
    "temp_init = temperature.copy()                 # Initial temperature of the rod\n",
    "# print(temperature_history,phi_history)\n",
    "# Array to store temperature at midpoint over time\n",
    "midpoint_index = num_points // 2                          # Index of the midpoint\n",
    "\n",
    "midpoint_temperature_history = [temperature[midpoint_index]]            # List to store temperature at midpoint over time\n",
    "dm = 60.0e-3                                                            # die thickness in m\n",
    "\n",
    "# r_m =  (k_mo / dm) + (1/htc)\n",
    "\n",
    "t_surr = 500.0                                        # Surrounding temperature in K\n",
    "# t_surr = h()\n",
    "\n",
    "def kramp(temp,v1,v2,T_L,T_s):                                      # Function to calculate thermal conductivity in Mushy Zone\n",
    "        slope = (v1-v2)/(T_L-T_S)\n",
    "        if temp > T_L:\n",
    "            k_m = k_l\n",
    "        elif temp < T_S:\n",
    "            k_m = k_s\n",
    "        else:\n",
    "            k_m = k_s + slope*(temp-T_S)\n",
    "        return k_m\n",
    "\n",
    "def cp_ramp(temp,v1,v2,T_L,T_s):                                    # Function to calculate specific heat capacity in Mushy Zone\n",
    "    slope = (v1-v2)/(T_L-T_S)\n",
    "    if temp > T_L:\n",
    "        cp_m = cp_l\n",
    "    elif temp < T_S:\n",
    "        cp_m = cp_s\n",
    "    else:\n",
    "        cp_m = cp_s + slope*(temp-T_S)\n",
    "    return cp_m\n",
    "\n",
    "def rho_ramp(temp,v1,v2,T_L,T_s):                                       # Function to calculate density in Mushy Zone\n",
    "    slope = (v1-v2)/(T_L-T_S)\n",
    "    if temp > T_L:\n",
    "        rho_m = rho_l\n",
    "    elif temp < T_S:\n",
    "        rho_m = rho_s\n",
    "    else:\n",
    "        rho_m = rho_s + slope*(temp-T_S)\n",
    "    return rho_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the HT equation and phase change numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for m in range(1, num_steps+1):                                                                            # time loop\n",
    "    htc = 10.0                   # htc of Still air in W/m^2-K\n",
    "    q1 = htc*(temp_init[0]-t_surr)   # Heat flux at the left boundary\n",
    "    \n",
    "    # print(f\"q1 is {q1}\")\n",
    "    temperature[0] = temp_init[0] + alpha_l * step_coeff * ((2.0*temp_init[1]) - (2.0 * temp_init[0])-(2.0*dx*(q1)))  # Update boundary condition temperature\n",
    "    \n",
    "    q2 = htc*(temp_init[-1]-t_surr)                   # Heat flux at the right boundary\n",
    "    temperature[-1] = temp_init[-1] + alpha_l * step_coeff * ((2.0*temp_init[-2]) - (2.0 * temp_init[-1])-(2.0*dx*(q2)))  # Update boundary condition temperature\n",
    "    \n",
    "    for n in range(1,num_points+1):              # space loop, adjusted range\n",
    "       \n",
    "        if temperature[n] >= T_L:\n",
    "            temperature[n] += ((alpha_l * step_coeff) * (temp_init[n+1] - (2.0 * temp_init[n]) + temp_init[n-1]))\n",
    "            phase[n] = 0\n",
    "            \n",
    "            # print(f\" Time-Step{m},Spatial point{n},Temperature{temperature[n]}\")\n",
    "        elif T_S < temperature[n] < T_L:\n",
    "            \n",
    "            k_m = kramp(temperature[n],k_l,k_s,T_L,T_S)\n",
    "            cp_m = cp_ramp(temperature[n],cp_l,cp_s,T_L,T_S)\n",
    "            rho_m = rho_ramp(temperature[n],rho_l,rho_s,T_L,T_S)\n",
    "            m_eff =(k_m/(rho_m*(cp_m + (L_fusion/(T_L-T_S)))))\n",
    "            \n",
    "            temperature[n] += ((m_eff * step_coeff)* (temp_init[n+1] - (2.0 * temp_init[n]) + temp_init[n-1]))\n",
    "            \n",
    "            phase[n] = (T_L - temperature[n]) / (T_L - T_S)\n",
    "            # print(m,n,temperature[n],phase[n])\n",
    "         \n",
    "        elif temperature[n]<T_S:\n",
    "            temperature[n] += ((alpha_s * step_coeff) * (temp_init[n+1] - (2.0 * temp_init[n])+ temp_init[n-1]))\n",
    "            phase[n] = 1\n",
    "                     \n",
    "        else:\n",
    "            print(\"ERROR: should not be here\")\n",
    "\n",
    "     \n",
    "          \n",
    "    temperature = temperature.copy()                                                                # Update temperature\n",
    "    phase = phase.copy()                                                                            # Update phase\n",
    "    temp_init = temperature.copy()                                                                  # Update last time step temperature\n",
    "    temperature_history.append(temperature.copy())                                                  # Append the temperature history to add ghost points\n",
    "    phi_history.append(phase.copy())                                                                # Append the phase history to add ghost points\n",
    "    midpoint_temperature_history.append(temperature[midpoint_index])                                # Store midpoint temperature\n",
    "    \n",
    "    \n",
    "    # print(f\"Step {m}, Temperature: {temperature}\")\n",
    "    \n",
    "\n",
    "\n",
    "# print(midpoint_temperature_history)\n",
    "#print(phi_history)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot temperature history for debugging\n",
    "# temperature_history_1 = np.array(temperature_history)\n",
    "# print(temperature_history_1.shape)\n",
    "# time_ss= np.linspace(0, time_end, num_steps+1)\n",
    "# # print(time_ss.shape)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(time_ss, midpoint_temperature_history, label='Midpoint Temperature')\n",
    "# plt.axhline(y=T_L, color='r', linestyle='--', label='Liquidus Temperature')\n",
    "# plt.axhline(y=T_S, color='g', linestyle='--', label='Solidus Temperature')\n",
    "# plt.xlabel('Time(s)')\n",
    "# plt.ylabel('Temperature (K)')\n",
    "# plt.title('Temperature Distribution Over Time at x = 7.5mm') \n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data into Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_history = np.array(temperature_history)\n",
    "\n",
    "phi_history = np.array(phi_history)\n",
    "\n",
    "t_hist = np.array(temperature_history[:,1:-1])\n",
    "p_hist = np.array(phi_history[:,1:-1])\n",
    "\n",
    "t_hist_init = t_hist[0,:]\n",
    "t_hist_bc_l = t_hist[:,0]\n",
    "t_hist_bc_r = t_hist[:,-1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have temperature_history and phi_history as lists of arrays\n",
    "\n",
    "\n",
    "# # Check the new shape after transposing\n",
    "# print(\"Transposed Temperature History Shape:\", temperature_history.shape)\n",
    "# print(\"Transposed Phi History Shape:\", phi_history.shape)\n",
    "\n",
    "# # Create a meshgrid for space and time coordinates\n",
    "# space_coord, time_coord = np.meshgrid(np.arange(temperature_history.shape[1]), np.arange(temperature_history.shape[0]))\n",
    "\n",
    "# time_coord = time_coord * dt \n",
    "# # Create a figure with two subplots\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# # Plot the temperature history on the left subplot\n",
    "# im1 = ax1.pcolormesh(space_coord, time_coord, temperature_history, cmap='viridis')\n",
    "# ax1.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=16)\n",
    "# ax1.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "# ax1.set_title('Temperature Variation Over Time',fontname='Times New Roman', fontsize=20)\n",
    "# fig.colorbar(im1, ax=ax1, label='Temperature')\n",
    "\n",
    "# # Plot the phase history on the right subplot\n",
    "# im2 = ax2.pcolormesh(space_coord, time_coord, phi_history, cmap='viridis')\n",
    "# ax2.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=18)\n",
    "# ax2.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "# ax2.set_title('Phase Variation Over Time',fontname='Times New Roman', fontsize=20)\n",
    "# fig.colorbar(im2, ax=ax2, label='Phase')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# #plot the main\n",
    "# fig, ax = plt.subplots(figsize=(14, 6))\n",
    "# im = ax.pcolormesh(space_coord, time_coord, Dim_ny, cmap='viridis')\n",
    "# ax.set_xlabel('Space Coordinate')\n",
    "# ax.set_ylabel('Time')\n",
    "# ax.set_title('Niyama Variation Over Time')\n",
    "# fig.colorbar(im, ax=ax, label='Main')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU/CPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check for gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (31470,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "space = np.linspace(0, length, num_points) # Spatial points\n",
    "time = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "print(space.shape,time.shape)\n",
    "\n",
    "sp_i = np.linspace(0, length, num_points) # Spatial points\n",
    "time_i = np.zeros(num_points) # Time points\n",
    "\n",
    "sp_b_l = np.zeros(num_steps+1) # Spatial points\n",
    "time_b_l = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "\n",
    "sp_b_r = np.ones(num_steps+1)*length # Spatial points\n",
    "time_b_r = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = input_gen(space,time,'mgrid')\n",
    "inputs_i = input_gen(sp_i,time_i,'scr')\n",
    "inputs_b_l = input_gen(sp_b_l,time_b_l,'scr')\n",
    "inputs_b_r = input_gen(sp_b_r,time_b_r,'scr')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1573500, 2) (50, 2) (31470, 2) (31470, 2)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape,inputs_i.shape,inputs_b_l.shape,inputs_b_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2])\n",
      "torch.Size([1573500, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "inputs = torch.tensor(inputs).float().to(device) # Convert the inputs to a tensor\n",
    "\n",
    "\n",
    "inputs_init = torch.tensor(inputs_i).float().to(device) # Convert the inputs to a tensor\n",
    "inputs_b_l = torch.tensor(inputs_b_l).float().to(device)# Convert the inputs to a tensor\n",
    "inputs_b_r = torch.tensor(inputs_b_r).float().to(device)# Convert the inputs to a tensor\n",
    "\n",
    "print(inputs_init.shape)\n",
    "# label/temp data\n",
    "temp_tr = torch.tensor(t_hist).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp = temp_tr.reshape(-1,1).float().to(device) # Reshape the temperature tensor to a column vector\n",
    "temp_inp_init = torch.tensor(t_hist_init).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp_bc_l = torch.tensor(t_hist_bc_l).float().to(device)# Convert the temperature history to a tensor\n",
    "temp_inp_bc_r = torch.tensor(t_hist_bc_r).float().to(device)# Convert the temperature history to a tensor\n",
    "print(temp_inp.shape)\n",
    "\n",
    "\n",
    "\n",
    "#Data Splitting\n",
    "\n",
    "# train_inputs, val_test_inputs, train_temp_inp, val_test_temp_inp = train_test_split(inputs, temp_inp, test_size=0.2, random_state=42)\n",
    "# val_inputs, test_inputs, val_temp_inp, test_temp_inp = train_test_split(val_test_inputs, val_test_temp_inp, test_size=0.8, random_state=42)\n",
    "\n",
    "train_inputs, test_inputs, train_temp_inp, test_temp_inp = train_test_split(inputs, temp_inp, test_size=0.2, random_state=42)\n",
    "train_inputs_init, test_inputs_init, train_temp_inp_init, test_temp_inp_init = train_test_split(inputs_init, temp_inp_init, test_size=0.2, random_state=42)\n",
    "train_inputs_bc_l, test_inputs_bc_l, train_temp_inp_bc_l, test_temp_inp_bc_l = train_test_split(inputs_b_l, temp_inp_bc_l, test_size=0.2, random_state=42)\n",
    "train_inputs_bc_r, test_inputs_bc_r, train_temp_inp_bc_r, test_temp_inp_bc_r = train_test_split(inputs_b_r, temp_inp_bc_r, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, temp_inp,transform=None, target_transform =None):\n",
    "        self.inputs = inputs\n",
    "        self.temp_inp = temp_inp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.temp_inp[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "  \n",
    "train_dataset = TensorDataset(train_inputs, train_temp_inp) # Create the training dataset\n",
    "# val_dataset = TensorDataset(val_inputs, val_temp_inp) # Create the validation dataset\n",
    "test_dataset = TensorDataset(test_inputs, test_temp_inp) # Create the test dataset\n",
    "\n",
    "train_dataset_init = TensorDataset(train_inputs_init, train_temp_inp_init) # Create the training dataset\n",
    "test_dataset_init = TensorDataset(test_inputs_init, test_temp_inp_init) # Create the test dataset\n",
    "train_dataset_bc_l = TensorDataset(train_inputs_bc_l, train_temp_inp_bc_l) # Create the training dataset\n",
    "test_dataset_bc_l = TensorDataset(test_inputs_bc_l, test_temp_inp_bc_l) # Create the test dataset\n",
    "train_dataset_bc_r = TensorDataset(train_inputs_bc_r, train_temp_inp_bc_r) # Create the training dataset\n",
    "test_dataset_bc_r = TensorDataset(test_inputs_bc_r, test_temp_inp_bc_r) # Create the test dataset\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "random_sampler_train = RandomSampler(train_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "# random_sampler_val = RandomSampler(val_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the validation dataset\n",
    "random_sampler_test = RandomSampler(test_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "\n",
    "random_sampler_train_init = RandomSampler(train_dataset_init, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_init = RandomSampler(test_dataset_init, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "random_sampler_train_bc_l = RandomSampler(train_dataset_bc_l, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_bc_l = RandomSampler(test_dataset_bc_l, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "random_sampler_train_bc_r = RandomSampler(train_dataset_bc_r, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_bc_r = RandomSampler(test_dataset_bc_r, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=random_sampler_train) # Create the training dataloader\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=random_sampler_val) # Create the validation dataloader\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, sampler=random_sampler_test) # Create the test dataloader\n",
    "\n",
    "train_loader_init = DataLoader(train_dataset_init, batch_size=batch_size, sampler=random_sampler_train_init) # Create the training dataloader\n",
    "test_loader_init = DataLoader(test_dataset_init, batch_size=batch_size, sampler=random_sampler_test_init) # Create the test dataloader\n",
    "train_loader_bc_l = DataLoader(train_dataset_bc_l, batch_size=batch_size, sampler=random_sampler_train_bc_l) # Create the training dataloader\n",
    "test_loader_bc_l = DataLoader(test_dataset_bc_l, batch_size=batch_size, sampler=random_sampler_test_bc_l) # Create the test dataloader\n",
    "train_loader_bc_r = DataLoader(train_dataset_bc_r, batch_size=batch_size, sampler=random_sampler_train_bc_r) # Create the training dataloader\n",
    "test_loader_bc_r = DataLoader(test_dataset_bc_r, batch_size=batch_size, sampler=random_sampler_test_bc_r) # Create the test dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the neural network architecture\n",
    "class Mushydata(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size): # This is the constructor\n",
    "        super(Mushydata, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t):                               # This is the forward pass\n",
    "        input_features = torch.cat([x, t], dim=1)          # Concatenate the input features\n",
    "        m = self.base(input_features)                                 # Pass through the third layer\n",
    "        return m                    # Return the output of the network\n",
    "\n",
    "\n",
    "# features = torch.rand(1, 2)\n",
    "# model = HeatPINN(2, 20, 1)\n",
    "# output = model(features[:, 0:1], features[:, 1:2])\n",
    "# print(output)\n",
    "\n",
    "\n",
    "# Loss function for data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamters Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 30\n",
    "learning_rate = 0.003\n",
    "epochs = 30000\n",
    "# alpha = 0.01  # Adjust this value based on your problem\n",
    "# boundary_value = 313.0\n",
    "# initial_value = init_temp\n",
    "# Initialize the model\n",
    "model = Mushydata(input_size=2, hidden_size=hidden_size,output_size=1).to(device)\n",
    "lambd = 0.1\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss List Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of train_loader is <class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(f\"Datatype of train_loader is {type(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_fn_data(u_pred, u_true):\n",
    "#     return nn.MSELoss()(u_pred, u_true)\n",
    "\n",
    "# def l1_regularization(model, lambd):\n",
    "#     l1_reg = sum(param.abs().sum() for param in model.parameters())\n",
    "#     return l1_reg * lambd\n",
    "\n",
    "# def pde_loss(u_pred,x,t):\n",
    "#     # u_pred.requires_grad = True\n",
    "#     x.requires_grad = True\n",
    "#     t.requires_grad = True\n",
    "    \n",
    "#     u_pred = model(x,t).requires_grad_()\n",
    "#     u_t = torch.autograd.grad(u_pred, t, \n",
    "#                                 torch.ones_like(u_pred).to(device),\n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused=True,\n",
    "#                                 )[0] # Calculate the first time derivative\n",
    "#     if u_t is None:\n",
    "#         raise RuntimeError(\"u_t is None\")\n",
    "\n",
    "#     u_x = torch.autograd.grad(u_pred, \n",
    "#                                 x, \n",
    "#                                 torch.ones_like(u_pred).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused =True)[0] # Calculate the first space derivative\n",
    "            \n",
    "#     u_xx = torch.autograd.grad(u_x, \n",
    "#                                 x, \n",
    "#                                 torch.ones_like(u_x).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused=True)[0] \n",
    "    \n",
    "#     T_S_tensor = torch.tensor(T_S, device=device)\n",
    "#     T_L_tensor = torch.tensor(T_L, device=device)\n",
    "    \n",
    "#     k_m = torch.where((u_pred >= T_S_tensor) * (u_pred <= T_L_tensor),\\\n",
    "#                        kramp(u_pred, k_l,k_s,T_L,T_S),torch.tensor(0.0,device=device))\n",
    "#     cp_m = torch.where(u_pred >= T_S_tensor * u_pred <= T_L_tensor, cp_ramp((u_pred), cp_l,cp_s,T_L,T_S))\n",
    "#     rho_m = torch.where(u_pred >= T_S_tensor * u_pred <= T_L_tensor, rho_ramp((u_pred), rho_l,rho_s,T_L,T_S))\n",
    "#     m_eff = (k_m / (rho_m * (cp_m + (L_fusion / (T_L - T_S)))))\n",
    "\n",
    "#     alpha_T = torch.where(u_pred >= T_L_tensor, alpha_l, torch.where(u_pred<=T_S_tensor,alpha_s ,m_eff))\n",
    "#     alpha_T = 1\n",
    "#     residual = u_t - alpha_T * u_xx\n",
    "\n",
    "#     return nn.MSELoss()(residual,torch.zeros_like(residual))\n",
    "\n",
    "# def boundary_loss(u_pred,x,t,t_surr):\n",
    "    \n",
    "#     u_x = torch.autograd.grad(u_pred,x, \n",
    "#                                 torch.ones_like(u_pred).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused =True)[0] # Calculate the first space derivative\n",
    "#     t_surr_t = torch.tensor(t_surr, device=device)\n",
    "#     res_l = u_x -(htc* (u_pred-t_surr_t))\n",
    "   \n",
    "\n",
    "#     return nn.MSELoss()(res_l,torch.zeros_like(res_l))\n",
    "\n",
    "# def ic_loss(u_pred):\n",
    "#     temp_init_tsr = torch.tensor(temp_init[1:-1],device=device)\n",
    "#     ic = u_pred -temp_init_tsr\n",
    "#     return nn.MSELoss()(ic,torch.zeros_like(ic))\n",
    "\n",
    "def accuracy(u_pred, u_true):\n",
    "    return torch.mean(torch.abs(u_pred - u_true) / u_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation and Testing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, model, loss_fn_data, optimizer, train_dataloader,test_dataloader,train_loader_init,\\\n",
    "                  train_loader_bc_l,train_loader_bc_r):\n",
    "    train_losses = []  # Initialize the list to store the training losses\n",
    "    # val_losses = []    # Initialize the list to store the validation losses\n",
    "    test_losses = []   # Initialize the list to store the test losses\n",
    "    data_losses = []   # Initialize the list to store the data losses\n",
    "    pde_losses = []   # Initialize the list to store the PDE losses\n",
    "    ic_losses = []   # Initialize the list to store the initial condition losses\n",
    "    bc_losses = []   # Initialize the list to store the boundary condition losses\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()                                                                           # Set the model to training mode\n",
    "        train_loss = 0                                                                              # Initialize the training loss\n",
    "        train_accuracy = 0\n",
    "        for (batch,batch_init,batch_left,batch_right) in \\\n",
    "             zip (train_dataloader,train_loader_init,train_loader_bc_l,train_loader_bc_r):                                                          # Loop through the training dataloader\n",
    "            inputs, temp_inp= batch                                                             # Get the inputs and the true values\n",
    "            inputs_init, temp_inp_init= batch_init                                                             # Get the inputs and the true values \n",
    "            inputs_left, temp_inp_left= batch_left                                                             # Get the inputs and the true values\n",
    "            inputs_right, temp_inp_right= batch_right                                                             # Get the inputs and the true values\n",
    "\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)                             # Move the inputs and true values to the GPU\n",
    "            inputs_init, temp_inp_init= inputs_init.to(device), temp_inp_init.to(device)                             # Move the initial condition inputs and temperature to the GPU\n",
    "            inputs_left, temp_inp_left= inputs_left.to(device), temp_inp_left.to(device)                             # Move the left boundary condition inputs and temperature values to the GPU\n",
    "            inputs_right, temp_inp_right= inputs_right.to(device), temp_inp_right.to(device)                             # Move the right boundary condition inputs and temperature values to the GPU\n",
    "\n",
    "            optimizer.zero_grad()                                                                    # Zero the gradients\n",
    "            \n",
    "            # Forward pass\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).to(device)                       # Get the predictions\n",
    "            u_initl = model(inputs_init[:,0].unsqueeze(1), inputs_init[:,1].unsqueeze(1)).to(device)                       # Get the predictions\n",
    "            \n",
    "            u_left = model(inputs_b_l[:,0].unsqueeze(1), inputs_b_l[:,1].unsqueeze(1)).to(device)               # Left boundary of the temperature\n",
    "            u_right = model(inputs_b_r[:,0].unsqueeze(1), inputs_b_r[:,1].unsqueeze(1)).to(device)             # Right boundary of the temperature\n",
    "\n",
    "            # Loss calculation\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp)                                              # Calculate the data loss\n",
    "            \n",
    "            pd_loss = pde_loss(model,inputs[:,0].unsqueeze(1),inputs[:,1].unsqueeze(1))             # Calculate the PDE loss\n",
    "            # pd_loss = 0\n",
    "            \n",
    "            initc_loss = ic_loss(u_initl) \n",
    "            # initc_loss =0                                                      # Calculate initial condition loss\n",
    "            \n",
    "            bc_loss_left = boundary_loss(model,inputs_b_l[:,0].unsqueeze(1),inputs_b_l[:,1].unsqueeze(1),t_surr) # Calculate the left boundary condition loss\n",
    "            bc_loss_right = boundary_loss(model,inputs_b_r[:,0].unsqueeze(1),inputs_b_r[:,1].unsqueeze(1),t_surr) # Calculate the right boundary condition loss\n",
    "            bc_loss = bc_loss_left + bc_loss_right\n",
    "            # l1_regularization_loss = l1_regularization(model, lambda_l1)                      # Calculate the L1 regularization loss\n",
    "            # loss = data_loss  + pd_loss + initc_loss + bc_loss                                              # Calculate the total loss\n",
    "            w1 = 0.0001\n",
    "            w2 = 0.0001\n",
    "            w3 = 0.0001\n",
    "            loss = data_loss + w1* pd_loss + w2 *initc_loss + w3* bc_loss\n",
    "            train_accuracy += accuracy(u_pred, temp_inp)                                                              # Calculate the total loss\n",
    "            # Backpropagation\n",
    "            loss.backward(retain_graph=True)                                                        # Backpropagate the gradients\n",
    "            \n",
    "            optimizer.step()                                                                           # Update the weights\n",
    "            \n",
    "            train_loss += loss.item()                                                           # Add the loss to the training set loss  \n",
    "            data_losses.append(data_loss.item())               \n",
    "            pde_losses.append(pd_loss.item())\n",
    "            ic_losses.append(initc_loss.item())\n",
    "            bc_losses.append(bc_loss.item())\n",
    "        \n",
    "\n",
    "        # model.eval()\n",
    "        # test_loss = 0\n",
    "        # test_accuracy = 0\n",
    "        # with torch.no_grad():   \n",
    "        #     for batch in test_dataloader:\n",
    "        #         inputs, temp_inp= batch\n",
    "        #         inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "        #         u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "        #         data_loss = loss_fn_data(u_pred, temp_inp)\n",
    "        #         # l1_regularization_loss = l1_regularization(model, lambd)\n",
    "        #         # loss = data_loss  + l1_regularization_loss\n",
    "        #         loss = data_loss\n",
    "        #         test_accuracy = accuracy(u_pred, temp_inp)\n",
    "        #         test_loss += loss.item()\n",
    "        #     test_losses.append(test_loss)\n",
    "\n",
    "        train_losses.append(train_loss)                                                   # Append the training loss to the list of training losses\n",
    "        \n",
    "        # if epoch % 10 == 0:\n",
    "        #     print(f\"Epoch {epoch}, Training-Loss {train_loss:.4e}\")\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_accuracy = 0\n",
    "        with torch.no_grad():   \n",
    "            for batch in test_dataloader:\n",
    "                inputs, temp_inp= batch\n",
    "                inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "                u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "                data_loss = loss_fn_data(u_pred, temp_inp)\n",
    "                # l1_regularization_loss = l1_regularization(model, lambd)\n",
    "                # loss = data_loss  + l1_regularization_loss\n",
    "                loss = data_loss\n",
    "                test_accuracy = accuracy(u_pred, temp_inp)\n",
    "                test_loss += loss.item()\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Training-Loss {train_loss:.4e}, Data-loss {data_loss:.4e}\\\n",
    "                  , pde-loss {pd_loss:.4e}, initc-loss {initc_loss:.4e}\\\n",
    "                    bc_loss {bc_loss:.4e}, Test-Loss {test_loss:.4e}\") \n",
    "\n",
    "    return train_losses, test_losses , pde_losses , bc_losses , ic_losses, data_losses                                                      # Return the training and validation losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(epochs, model, loss_fn_data, optimizer, train_dataloader, test_dataloader):\n",
    "      \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    with torch.no_grad():   \n",
    "        for batch in test_dataloader:\n",
    "            inputs, temp_inp= batch\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp)\n",
    "            # l1_regularization_loss = l1_regularization(model, lambd)\n",
    "            # loss = data_loss  + l1_regularization_loss\n",
    "            loss = data_loss\n",
    "            test_accuracy = accuracy(u_pred, temp_inp)\n",
    "            test_loss += loss.item()\n",
    "        test_losses.append(test_loss)\n",
    "    if epochs % 10 == 0:\n",
    "        print(f\"Epoch {epochs}, Test-Loss {test_loss:.4e}, Test-Accuracy {test_accuracy:.4e}\")      \n",
    "    return test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Button "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training-Loss 6.5436e+05, Data-loss 6.4688e+05                  , pde-loss 2.3581e-07, initc-loss 8.4289e+05                    bc_loss 4.9819e+07, Test-Loss 6.4688e+05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training-Loss 6.6148e+05, Data-loss 6.5285e+05                  , pde-loss 1.0018e-06, initc-loss 8.4122e+05                    bc_loss 4.9636e+07, Test-Loss 6.5285e+05\n",
      "Epoch 20, Training-Loss 6.6080e+05, Data-loss 6.4477e+05                  , pde-loss 1.3255e-07, initc-loss 8.3924e+05                    bc_loss 4.9422e+07, Test-Loss 6.4477e+05\n",
      "Epoch 30, Training-Loss 6.5584e+05, Data-loss 6.5264e+05                  , pde-loss 7.5523e-06, initc-loss 8.3702e+05                    bc_loss 4.9181e+07, Test-Loss 6.5264e+05\n",
      "Epoch 40, Training-Loss 6.6335e+05, Data-loss 6.3766e+05                  , pde-loss 1.2589e-05, initc-loss 8.3486e+05                    bc_loss 4.8947e+07, Test-Loss 6.3766e+05\n",
      "Epoch 50, Training-Loss 6.4697e+05, Data-loss 6.4728e+05                  , pde-loss 8.5799e-06, initc-loss 8.3292e+05                    bc_loss 4.8737e+07, Test-Loss 6.4728e+05\n",
      "Epoch 60, Training-Loss 6.5279e+05, Data-loss 6.4568e+05                  , pde-loss 3.6844e-06, initc-loss 8.3112e+05                    bc_loss 4.8542e+07, Test-Loss 6.4568e+05\n",
      "Epoch 70, Training-Loss 6.5304e+05, Data-loss 6.5235e+05                  , pde-loss 1.8398e-06, initc-loss 8.2939e+05                    bc_loss 4.8355e+07, Test-Loss 6.5235e+05\n",
      "Epoch 80, Training-Loss 6.5336e+05, Data-loss 6.4461e+05                  , pde-loss 1.0296e-06, initc-loss 8.2764e+05                    bc_loss 4.8167e+07, Test-Loss 6.4461e+05\n",
      "Epoch 90, Training-Loss 6.4191e+05, Data-loss 6.4239e+05                  , pde-loss 7.3402e-07, initc-loss 8.2586e+05                    bc_loss 4.7974e+07, Test-Loss 6.4239e+05\n",
      "Epoch 100, Training-Loss 6.4407e+05, Data-loss 6.4294e+05                  , pde-loss 6.0335e-07, initc-loss 8.2403e+05                    bc_loss 4.7778e+07, Test-Loss 6.4294e+05\n",
      "Epoch 110, Training-Loss 6.4000e+05, Data-loss 6.2551e+05                  , pde-loss 4.8343e-07, initc-loss 8.2224e+05                    bc_loss 4.7585e+07, Test-Loss 6.2551e+05\n",
      "Epoch 120, Training-Loss 6.3763e+05, Data-loss 6.2727e+05                  , pde-loss 3.7374e-07, initc-loss 8.2050e+05                    bc_loss 4.7397e+07, Test-Loss 6.2727e+05\n",
      "Epoch 130, Training-Loss 6.3624e+05, Data-loss 6.3242e+05                  , pde-loss 2.9373e-07, initc-loss 8.1878e+05                    bc_loss 4.7213e+07, Test-Loss 6.3242e+05\n",
      "Epoch 140, Training-Loss 6.3184e+05, Data-loss 6.3327e+05                  , pde-loss 2.0218e-07, initc-loss 8.1707e+05                    bc_loss 4.7029e+07, Test-Loss 6.3327e+05\n",
      "Epoch 150, Training-Loss 6.3810e+05, Data-loss 6.4477e+05                  , pde-loss 2.3380e-07, initc-loss 8.1531e+05                    bc_loss 4.6841e+07, Test-Loss 6.4477e+05\n",
      "Epoch 160, Training-Loss 6.3108e+05, Data-loss 6.2858e+05                  , pde-loss 2.1596e-07, initc-loss 8.1349e+05                    bc_loss 4.6646e+07, Test-Loss 6.2858e+05\n",
      "Epoch 170, Training-Loss 6.2519e+05, Data-loss 6.3143e+05                  , pde-loss 1.3251e-07, initc-loss 8.1170e+05                    bc_loss 4.6455e+07, Test-Loss 6.3143e+05\n",
      "Epoch 180, Training-Loss 6.3105e+05, Data-loss 6.2002e+05                  , pde-loss 9.4298e-08, initc-loss 8.0995e+05                    bc_loss 4.6267e+07, Test-Loss 6.2002e+05\n",
      "Epoch 190, Training-Loss 6.2815e+05, Data-loss 6.2426e+05                  , pde-loss 6.8610e-08, initc-loss 8.0822e+05                    bc_loss 4.6082e+07, Test-Loss 6.2426e+05\n",
      "Epoch 200, Training-Loss 6.2881e+05, Data-loss 6.1921e+05                  , pde-loss 6.0161e-08, initc-loss 8.0651e+05                    bc_loss 4.5900e+07, Test-Loss 6.1921e+05\n",
      "Epoch 210, Training-Loss 6.2214e+05, Data-loss 6.1953e+05                  , pde-loss 4.6559e-08, initc-loss 8.0482e+05                    bc_loss 4.5719e+07, Test-Loss 6.1953e+05\n",
      "Epoch 220, Training-Loss 6.2283e+05, Data-loss 6.2102e+05                  , pde-loss 3.5879e-08, initc-loss 8.0314e+05                    bc_loss 4.5540e+07, Test-Loss 6.2102e+05\n",
      "Epoch 230, Training-Loss 6.1991e+05, Data-loss 6.2737e+05                  , pde-loss 3.0022e-08, initc-loss 8.0146e+05                    bc_loss 4.5361e+07, Test-Loss 6.2737e+05\n",
      "Epoch 240, Training-Loss 6.2141e+05, Data-loss 6.1567e+05                  , pde-loss 5.5350e-08, initc-loss 7.9969e+05                    bc_loss 4.5173e+07, Test-Loss 6.1567e+05\n",
      "Epoch 250, Training-Loss 6.2484e+05, Data-loss 6.1167e+05                  , pde-loss 5.2650e-08, initc-loss 7.9782e+05                    bc_loss 4.4975e+07, Test-Loss 6.1167e+05\n",
      "Epoch 260, Training-Loss 6.1652e+05, Data-loss 6.2030e+05                  , pde-loss 3.4426e-08, initc-loss 7.9601e+05                    bc_loss 4.4782e+07, Test-Loss 6.2030e+05\n",
      "Epoch 270, Training-Loss 6.2274e+05, Data-loss 6.1175e+05                  , pde-loss 2.4853e-08, initc-loss 7.9423e+05                    bc_loss 4.4594e+07, Test-Loss 6.1175e+05\n",
      "Epoch 280, Training-Loss 6.1027e+05, Data-loss 6.0913e+05                  , pde-loss 1.9898e-08, initc-loss 7.9247e+05                    bc_loss 4.4408e+07, Test-Loss 6.0913e+05\n",
      "Epoch 290, Training-Loss 6.2816e+05, Data-loss 6.0943e+05                  , pde-loss 1.5277e-08, initc-loss 7.9073e+05                    bc_loss 4.4224e+07, Test-Loss 6.0943e+05\n",
      "Epoch 300, Training-Loss 6.1512e+05, Data-loss 6.0717e+05                  , pde-loss 1.4090e-08, initc-loss 7.8901e+05                    bc_loss 4.4041e+07, Test-Loss 6.0717e+05\n",
      "Epoch 310, Training-Loss 6.0509e+05, Data-loss 6.0127e+05                  , pde-loss 1.1525e-08, initc-loss 7.8727e+05                    bc_loss 4.3858e+07, Test-Loss 6.0127e+05\n",
      "Epoch 320, Training-Loss 6.0272e+05, Data-loss 5.9769e+05                  , pde-loss 2.8179e-08, initc-loss 7.8545e+05                    bc_loss 4.3665e+07, Test-Loss 5.9769e+05\n",
      "Epoch 330, Training-Loss 5.9630e+05, Data-loss 6.1151e+05                  , pde-loss 2.1458e-08, initc-loss 7.8356e+05                    bc_loss 4.3466e+07, Test-Loss 6.1151e+05\n",
      "Epoch 340, Training-Loss 6.1088e+05, Data-loss 5.9950e+05                  , pde-loss 1.4319e-08, initc-loss 7.8171e+05                    bc_loss 4.3271e+07, Test-Loss 5.9950e+05\n",
      "Epoch 350, Training-Loss 6.0131e+05, Data-loss 6.0047e+05                  , pde-loss 1.1734e-08, initc-loss 7.7988e+05                    bc_loss 4.3079e+07, Test-Loss 6.0047e+05\n",
      "Epoch 360, Training-Loss 5.9596e+05, Data-loss 5.9638e+05                  , pde-loss 9.6919e-09, initc-loss 7.7808e+05                    bc_loss 4.2890e+07, Test-Loss 5.9638e+05\n",
      "Epoch 370, Training-Loss 6.0317e+05, Data-loss 5.9254e+05                  , pde-loss 8.5338e-09, initc-loss 7.7630e+05                    bc_loss 4.2703e+07, Test-Loss 5.9254e+05\n",
      "Epoch 380, Training-Loss 5.9734e+05, Data-loss 5.9994e+05                  , pde-loss 7.9793e-09, initc-loss 7.7453e+05                    bc_loss 4.2518e+07, Test-Loss 5.9994e+05\n",
      "Epoch 390, Training-Loss 5.9763e+05, Data-loss 6.0692e+05                  , pde-loss 6.7304e-09, initc-loss 7.7278e+05                    bc_loss 4.2335e+07, Test-Loss 6.0692e+05\n",
      "Epoch 400, Training-Loss 6.0550e+05, Data-loss 5.8978e+05                  , pde-loss 5.7719e-09, initc-loss 7.7104e+05                    bc_loss 4.2153e+07, Test-Loss 5.8978e+05\n",
      "Epoch 410, Training-Loss 5.9472e+05, Data-loss 5.9329e+05                  , pde-loss 5.6329e-09, initc-loss 7.6932e+05                    bc_loss 4.1972e+07, Test-Loss 5.9329e+05\n",
      "Epoch 420, Training-Loss 6.0438e+05, Data-loss 5.9580e+05                  , pde-loss 4.8461e-09, initc-loss 7.6760e+05                    bc_loss 4.1793e+07, Test-Loss 5.9580e+05\n",
      "Epoch 430, Training-Loss 5.9569e+05, Data-loss 5.8340e+05                  , pde-loss 4.8221e-09, initc-loss 7.6589e+05                    bc_loss 4.1615e+07, Test-Loss 5.8340e+05\n",
      "Epoch 440, Training-Loss 5.8420e+05, Data-loss 5.8667e+05                  , pde-loss 4.4051e-09, initc-loss 7.6419e+05                    bc_loss 4.1438e+07, Test-Loss 5.8667e+05\n",
      "Epoch 450, Training-Loss 5.8147e+05, Data-loss 5.8405e+05                  , pde-loss 3.9665e-09, initc-loss 7.6250e+05                    bc_loss 4.1262e+07, Test-Loss 5.8405e+05\n",
      "Epoch 460, Training-Loss 5.8988e+05, Data-loss 5.8521e+05                  , pde-loss 3.4721e-09, initc-loss 7.6082e+05                    bc_loss 4.1087e+07, Test-Loss 5.8521e+05\n",
      "Epoch 470, Training-Loss 5.8205e+05, Data-loss 5.7948e+05                  , pde-loss 3.3971e-09, initc-loss 7.5915e+05                    bc_loss 4.0913e+07, Test-Loss 5.7948e+05\n",
      "Epoch 480, Training-Loss 5.8636e+05, Data-loss 5.8053e+05                  , pde-loss 2.9581e-09, initc-loss 7.5748e+05                    bc_loss 4.0740e+07, Test-Loss 5.8053e+05\n",
      "Epoch 490, Training-Loss 5.7864e+05, Data-loss 5.6888e+05                  , pde-loss 2.7055e-09, initc-loss 7.5582e+05                    bc_loss 4.0568e+07, Test-Loss 5.6888e+05\n",
      "Epoch 500, Training-Loss 5.8648e+05, Data-loss 5.7585e+05                  , pde-loss 2.3802e-09, initc-loss 7.5416e+05                    bc_loss 4.0396e+07, Test-Loss 5.7585e+05\n",
      "Epoch 510, Training-Loss 5.8811e+05, Data-loss 5.7201e+05                  , pde-loss 2.0153e-09, initc-loss 7.5251e+05                    bc_loss 4.0226e+07, Test-Loss 5.7201e+05\n",
      "Epoch 520, Training-Loss 5.7724e+05, Data-loss 5.7649e+05                  , pde-loss 1.9146e-09, initc-loss 7.5086e+05                    bc_loss 4.0055e+07, Test-Loss 5.7649e+05\n",
      "Epoch 530, Training-Loss 5.8104e+05, Data-loss 5.7533e+05                  , pde-loss 1.8062e-09, initc-loss 7.4922e+05                    bc_loss 3.9886e+07, Test-Loss 5.7533e+05\n",
      "Epoch 540, Training-Loss 5.7473e+05, Data-loss 5.8344e+05                  , pde-loss 1.6230e-09, initc-loss 7.4759e+05                    bc_loss 3.9717e+07, Test-Loss 5.8344e+05\n",
      "Epoch 550, Training-Loss 5.7540e+05, Data-loss 5.6878e+05                  , pde-loss 1.5773e-09, initc-loss 7.4595e+05                    bc_loss 3.9549e+07, Test-Loss 5.6878e+05\n",
      "Epoch 560, Training-Loss 5.7169e+05, Data-loss 5.7688e+05                  , pde-loss 1.4189e-09, initc-loss 7.4433e+05                    bc_loss 3.9382e+07, Test-Loss 5.7688e+05\n",
      "Epoch 570, Training-Loss 5.6918e+05, Data-loss 5.6091e+05                  , pde-loss 1.2899e-09, initc-loss 7.4271e+05                    bc_loss 3.9215e+07, Test-Loss 5.6091e+05\n",
      "Epoch 580, Training-Loss 5.7021e+05, Data-loss 5.7378e+05                  , pde-loss 1.2950e-09, initc-loss 7.4109e+05                    bc_loss 3.9049e+07, Test-Loss 5.7378e+05\n",
      "Epoch 590, Training-Loss 5.6997e+05, Data-loss 5.6615e+05                  , pde-loss 1.0960e-09, initc-loss 7.3948e+05                    bc_loss 3.8883e+07, Test-Loss 5.6615e+05\n",
      "Epoch 600, Training-Loss 5.7443e+05, Data-loss 5.6432e+05                  , pde-loss 1.0485e-09, initc-loss 7.3787e+05                    bc_loss 3.8719e+07, Test-Loss 5.6432e+05\n",
      "Epoch 610, Training-Loss 5.6334e+05, Data-loss 5.6245e+05                  , pde-loss 1.0618e-09, initc-loss 7.3626e+05                    bc_loss 3.8554e+07, Test-Loss 5.6245e+05\n",
      "Epoch 620, Training-Loss 5.6364e+05, Data-loss 5.6015e+05                  , pde-loss 9.7724e-10, initc-loss 7.3466e+05                    bc_loss 3.8391e+07, Test-Loss 5.6015e+05\n",
      "Epoch 630, Training-Loss 5.6178e+05, Data-loss 5.5723e+05                  , pde-loss 9.1644e-10, initc-loss 7.3307e+05                    bc_loss 3.8228e+07, Test-Loss 5.5723e+05\n",
      "Epoch 640, Training-Loss 5.5905e+05, Data-loss 5.5514e+05                  , pde-loss 8.6789e-10, initc-loss 7.3148e+05                    bc_loss 3.8065e+07, Test-Loss 5.5514e+05\n",
      "Epoch 650, Training-Loss 5.5188e+05, Data-loss 5.5363e+05                  , pde-loss 8.1207e-10, initc-loss 7.2989e+05                    bc_loss 3.7903e+07, Test-Loss 5.5363e+05\n",
      "Epoch 660, Training-Loss 5.6109e+05, Data-loss 5.4543e+05                  , pde-loss 7.7691e-10, initc-loss 7.2830e+05                    bc_loss 3.7742e+07, Test-Loss 5.4543e+05\n",
      "Epoch 670, Training-Loss 5.5227e+05, Data-loss 5.5358e+05                  , pde-loss 7.5688e-10, initc-loss 7.2672e+05                    bc_loss 3.7581e+07, Test-Loss 5.5358e+05\n",
      "Epoch 680, Training-Loss 5.5807e+05, Data-loss 5.4864e+05                  , pde-loss 7.2658e-10, initc-loss 7.2514e+05                    bc_loss 3.7421e+07, Test-Loss 5.4864e+05\n",
      "Epoch 690, Training-Loss 5.5880e+05, Data-loss 5.5578e+05                  , pde-loss 6.7965e-10, initc-loss 7.2357e+05                    bc_loss 3.7261e+07, Test-Loss 5.5578e+05\n",
      "Epoch 700, Training-Loss 5.5168e+05, Data-loss 5.5659e+05                  , pde-loss 6.7250e-10, initc-loss 7.2200e+05                    bc_loss 3.7102e+07, Test-Loss 5.5659e+05\n",
      "Epoch 710, Training-Loss 5.4916e+05, Data-loss 5.4424e+05                  , pde-loss 5.7772e-10, initc-loss 7.2044e+05                    bc_loss 3.6943e+07, Test-Loss 5.4424e+05\n",
      "Epoch 720, Training-Loss 5.5449e+05, Data-loss 5.4788e+05                  , pde-loss 5.5883e-10, initc-loss 7.1887e+05                    bc_loss 3.6785e+07, Test-Loss 5.4788e+05\n",
      "Epoch 730, Training-Loss 5.4700e+05, Data-loss 5.3927e+05                  , pde-loss 5.3048e-10, initc-loss 7.1731e+05                    bc_loss 3.6627e+07, Test-Loss 5.3927e+05\n",
      "Epoch 740, Training-Loss 5.5184e+05, Data-loss 5.4251e+05                  , pde-loss 4.7289e-10, initc-loss 7.1576e+05                    bc_loss 3.6470e+07, Test-Loss 5.4251e+05\n",
      "Epoch 750, Training-Loss 5.5536e+05, Data-loss 5.4003e+05                  , pde-loss 4.6480e-10, initc-loss 7.1421e+05                    bc_loss 3.6313e+07, Test-Loss 5.4003e+05\n",
      "Epoch 760, Training-Loss 5.4144e+05, Data-loss 5.4379e+05                  , pde-loss 4.8757e-10, initc-loss 7.1266e+05                    bc_loss 3.6157e+07, Test-Loss 5.4379e+05\n",
      "Epoch 770, Training-Loss 5.4019e+05, Data-loss 5.4329e+05                  , pde-loss 4.4238e-10, initc-loss 7.1111e+05                    bc_loss 3.6002e+07, Test-Loss 5.4329e+05\n",
      "Epoch 780, Training-Loss 5.3524e+05, Data-loss 5.3199e+05                  , pde-loss 4.3473e-10, initc-loss 7.0957e+05                    bc_loss 3.5846e+07, Test-Loss 5.3199e+05\n",
      "Epoch 790, Training-Loss 5.3544e+05, Data-loss 5.2976e+05                  , pde-loss 4.1905e-10, initc-loss 7.0803e+05                    bc_loss 3.5692e+07, Test-Loss 5.2976e+05\n",
      "Epoch 800, Training-Loss 5.4435e+05, Data-loss 5.3209e+05                  , pde-loss 3.8015e-10, initc-loss 7.0649e+05                    bc_loss 3.5538e+07, Test-Loss 5.3209e+05\n",
      "Epoch 810, Training-Loss 5.2982e+05, Data-loss 5.2912e+05                  , pde-loss 3.5576e-10, initc-loss 7.0496e+05                    bc_loss 3.5384e+07, Test-Loss 5.2912e+05\n",
      "Epoch 820, Training-Loss 5.3409e+05, Data-loss 5.3325e+05                  , pde-loss 3.5823e-10, initc-loss 7.0344e+05                    bc_loss 3.5231e+07, Test-Loss 5.3325e+05\n",
      "Epoch 830, Training-Loss 5.3062e+05, Data-loss 5.4315e+05                  , pde-loss 3.2587e-10, initc-loss 7.0191e+05                    bc_loss 3.5079e+07, Test-Loss 5.4315e+05\n",
      "Epoch 840, Training-Loss 5.2937e+05, Data-loss 5.1660e+05                  , pde-loss 3.1939e-10, initc-loss 7.0039e+05                    bc_loss 3.4927e+07, Test-Loss 5.1660e+05\n",
      "Epoch 850, Training-Loss 5.3197e+05, Data-loss 5.3942e+05                  , pde-loss 3.0239e-10, initc-loss 6.9887e+05                    bc_loss 3.4775e+07, Test-Loss 5.3942e+05\n",
      "Epoch 860, Training-Loss 5.2412e+05, Data-loss 5.2912e+05                  , pde-loss 2.9252e-10, initc-loss 6.9735e+05                    bc_loss 3.4623e+07, Test-Loss 5.2912e+05\n",
      "Epoch 870, Training-Loss 5.3519e+05, Data-loss 5.2592e+05                  , pde-loss 2.7188e-10, initc-loss 6.9583e+05                    bc_loss 3.4472e+07, Test-Loss 5.2592e+05\n",
      "Epoch 880, Training-Loss 5.2946e+05, Data-loss 5.2200e+05                  , pde-loss 2.6809e-10, initc-loss 6.9432e+05                    bc_loss 3.4322e+07, Test-Loss 5.2200e+05\n",
      "Epoch 890, Training-Loss 5.2785e+05, Data-loss 5.1729e+05                  , pde-loss 2.4410e-10, initc-loss 6.9281e+05                    bc_loss 3.4172e+07, Test-Loss 5.1729e+05\n",
      "Epoch 900, Training-Loss 5.2895e+05, Data-loss 5.2376e+05                  , pde-loss 2.2797e-10, initc-loss 6.9131e+05                    bc_loss 3.4023e+07, Test-Loss 5.2376e+05\n",
      "Epoch 910, Training-Loss 5.2151e+05, Data-loss 5.1436e+05                  , pde-loss 2.2726e-10, initc-loss 6.8980e+05                    bc_loss 3.3874e+07, Test-Loss 5.1436e+05\n",
      "Epoch 920, Training-Loss 5.2148e+05, Data-loss 5.2429e+05                  , pde-loss 2.1664e-10, initc-loss 6.8831e+05                    bc_loss 3.3725e+07, Test-Loss 5.2429e+05\n",
      "Epoch 930, Training-Loss 5.2743e+05, Data-loss 5.0731e+05                  , pde-loss 2.1008e-10, initc-loss 6.8681e+05                    bc_loss 3.3577e+07, Test-Loss 5.0731e+05\n",
      "Epoch 940, Training-Loss 5.2260e+05, Data-loss 5.2233e+05                  , pde-loss 1.8794e-10, initc-loss 6.8531e+05                    bc_loss 3.3429e+07, Test-Loss 5.2233e+05\n",
      "Epoch 950, Training-Loss 5.1997e+05, Data-loss 5.2284e+05                  , pde-loss 1.9810e-10, initc-loss 6.8382e+05                    bc_loss 3.3282e+07, Test-Loss 5.2284e+05\n",
      "Epoch 960, Training-Loss 5.1750e+05, Data-loss 5.0892e+05                  , pde-loss 1.9853e-10, initc-loss 6.8233e+05                    bc_loss 3.3135e+07, Test-Loss 5.0892e+05\n",
      "Epoch 970, Training-Loss 5.3250e+05, Data-loss 5.0721e+05                  , pde-loss 1.6543e-10, initc-loss 6.8085e+05                    bc_loss 3.2989e+07, Test-Loss 5.0721e+05\n",
      "Epoch 980, Training-Loss 5.0938e+05, Data-loss 5.1091e+05                  , pde-loss 1.7465e-10, initc-loss 6.7936e+05                    bc_loss 3.2843e+07, Test-Loss 5.1091e+05\n",
      "Epoch 990, Training-Loss 5.1415e+05, Data-loss 5.1132e+05                  , pde-loss 1.6186e-10, initc-loss 6.7788e+05                    bc_loss 3.2697e+07, Test-Loss 5.1132e+05\n",
      "Epoch 1000, Training-Loss 5.2083e+05, Data-loss 5.0799e+05                  , pde-loss 1.6415e-10, initc-loss 6.7640e+05                    bc_loss 3.2553e+07, Test-Loss 5.0799e+05\n",
      "Epoch 1010, Training-Loss 5.1285e+05, Data-loss 5.0391e+05                  , pde-loss 1.5119e-10, initc-loss 6.7493e+05                    bc_loss 3.2408e+07, Test-Loss 5.0391e+05\n",
      "Epoch 1020, Training-Loss 5.0954e+05, Data-loss 4.9935e+05                  , pde-loss 1.4781e-10, initc-loss 6.7345e+05                    bc_loss 3.2263e+07, Test-Loss 4.9935e+05\n",
      "Epoch 1030, Training-Loss 5.0922e+05, Data-loss 4.9954e+05                  , pde-loss 1.5477e-10, initc-loss 6.7198e+05                    bc_loss 3.2119e+07, Test-Loss 4.9954e+05\n",
      "Epoch 1040, Training-Loss 5.1207e+05, Data-loss 4.9699e+05                  , pde-loss 1.3160e-10, initc-loss 6.7051e+05                    bc_loss 3.1976e+07, Test-Loss 4.9699e+05\n",
      "Epoch 1050, Training-Loss 4.9935e+05, Data-loss 5.1164e+05                  , pde-loss 1.4774e-10, initc-loss 6.6905e+05                    bc_loss 3.1833e+07, Test-Loss 5.1164e+05\n",
      "Epoch 1060, Training-Loss 5.0688e+05, Data-loss 5.0199e+05                  , pde-loss 1.3104e-10, initc-loss 6.6759e+05                    bc_loss 3.1690e+07, Test-Loss 5.0199e+05\n",
      "Epoch 1070, Training-Loss 5.0114e+05, Data-loss 5.0118e+05                  , pde-loss 1.2897e-10, initc-loss 6.6613e+05                    bc_loss 3.1548e+07, Test-Loss 5.0118e+05\n",
      "Epoch 1080, Training-Loss 4.9581e+05, Data-loss 4.8591e+05                  , pde-loss 1.3038e-10, initc-loss 6.6467e+05                    bc_loss 3.1407e+07, Test-Loss 4.8591e+05\n",
      "Epoch 1090, Training-Loss 5.0329e+05, Data-loss 4.9875e+05                  , pde-loss 1.1693e-10, initc-loss 6.6322e+05                    bc_loss 3.1266e+07, Test-Loss 4.9875e+05\n",
      "Epoch 1100, Training-Loss 4.9562e+05, Data-loss 4.9594e+05                  , pde-loss 1.1298e-10, initc-loss 6.6177e+05                    bc_loss 3.1125e+07, Test-Loss 4.9594e+05\n",
      "Epoch 1110, Training-Loss 5.0124e+05, Data-loss 5.0511e+05                  , pde-loss 1.0311e-10, initc-loss 6.6032e+05                    bc_loss 3.0985e+07, Test-Loss 5.0511e+05\n",
      "Epoch 1120, Training-Loss 4.9911e+05, Data-loss 4.9420e+05                  , pde-loss 9.7023e-11, initc-loss 6.5888e+05                    bc_loss 3.0845e+07, Test-Loss 4.9420e+05\n",
      "Epoch 1130, Training-Loss 4.9382e+05, Data-loss 4.9362e+05                  , pde-loss 1.0822e-10, initc-loss 6.5744e+05                    bc_loss 3.0705e+07, Test-Loss 4.9362e+05\n",
      "Epoch 1140, Training-Loss 4.9909e+05, Data-loss 4.8893e+05                  , pde-loss 8.9003e-11, initc-loss 6.5600e+05                    bc_loss 3.0566e+07, Test-Loss 4.8893e+05\n",
      "Epoch 1150, Training-Loss 4.8725e+05, Data-loss 4.8245e+05                  , pde-loss 9.6404e-11, initc-loss 6.5455e+05                    bc_loss 3.0427e+07, Test-Loss 4.8245e+05\n",
      "Epoch 1160, Training-Loss 4.9151e+05, Data-loss 4.8977e+05                  , pde-loss 9.6133e-11, initc-loss 6.5312e+05                    bc_loss 3.0289e+07, Test-Loss 4.8977e+05\n",
      "Epoch 1170, Training-Loss 4.8763e+05, Data-loss 4.9445e+05                  , pde-loss 8.7595e-11, initc-loss 6.5168e+05                    bc_loss 3.0150e+07, Test-Loss 4.9445e+05\n",
      "Epoch 1180, Training-Loss 4.8864e+05, Data-loss 4.8820e+05                  , pde-loss 7.8519e-11, initc-loss 6.5025e+05                    bc_loss 3.0013e+07, Test-Loss 4.8820e+05\n",
      "Epoch 1190, Training-Loss 4.8578e+05, Data-loss 4.8830e+05                  , pde-loss 8.3286e-11, initc-loss 6.4882e+05                    bc_loss 2.9875e+07, Test-Loss 4.8830e+05\n",
      "Epoch 1200, Training-Loss 4.9151e+05, Data-loss 4.7878e+05                  , pde-loss 7.3776e-11, initc-loss 6.4739e+05                    bc_loss 2.9739e+07, Test-Loss 4.7878e+05\n",
      "Epoch 1210, Training-Loss 4.8355e+05, Data-loss 4.8556e+05                  , pde-loss 7.6257e-11, initc-loss 6.4597e+05                    bc_loss 2.9602e+07, Test-Loss 4.8556e+05\n",
      "Epoch 1220, Training-Loss 4.8663e+05, Data-loss 4.7448e+05                  , pde-loss 7.0050e-11, initc-loss 6.4455e+05                    bc_loss 2.9466e+07, Test-Loss 4.7448e+05\n",
      "Epoch 1230, Training-Loss 4.7709e+05, Data-loss 4.7799e+05                  , pde-loss 7.4346e-11, initc-loss 6.4313e+05                    bc_loss 2.9331e+07, Test-Loss 4.7799e+05\n",
      "Epoch 1240, Training-Loss 4.8217e+05, Data-loss 4.8028e+05                  , pde-loss 6.9351e-11, initc-loss 6.4171e+05                    bc_loss 2.9195e+07, Test-Loss 4.8028e+05\n",
      "Epoch 1250, Training-Loss 4.7824e+05, Data-loss 4.8018e+05                  , pde-loss 6.7926e-11, initc-loss 6.4029e+05                    bc_loss 2.9060e+07, Test-Loss 4.8018e+05\n",
      "Epoch 1260, Training-Loss 4.7550e+05, Data-loss 4.7421e+05                  , pde-loss 6.6610e-11, initc-loss 6.3888e+05                    bc_loss 2.8926e+07, Test-Loss 4.7421e+05\n",
      "Epoch 1270, Training-Loss 4.8094e+05, Data-loss 4.7682e+05                  , pde-loss 6.4304e-11, initc-loss 6.3747e+05                    bc_loss 2.8792e+07, Test-Loss 4.7682e+05\n",
      "Epoch 1280, Training-Loss 4.7844e+05, Data-loss 4.7246e+05                  , pde-loss 6.2915e-11, initc-loss 6.3607e+05                    bc_loss 2.8658e+07, Test-Loss 4.7246e+05\n",
      "Epoch 1290, Training-Loss 4.7560e+05, Data-loss 4.7313e+05                  , pde-loss 6.2329e-11, initc-loss 6.3466e+05                    bc_loss 2.8525e+07, Test-Loss 4.7313e+05\n",
      "Epoch 1300, Training-Loss 4.7083e+05, Data-loss 4.6679e+05                  , pde-loss 5.9076e-11, initc-loss 6.3326e+05                    bc_loss 2.8392e+07, Test-Loss 4.6679e+05\n",
      "Epoch 1310, Training-Loss 4.7208e+05, Data-loss 4.7463e+05                  , pde-loss 5.9129e-11, initc-loss 6.3186e+05                    bc_loss 2.8259e+07, Test-Loss 4.7463e+05\n",
      "Epoch 1320, Training-Loss 4.7577e+05, Data-loss 4.6970e+05                  , pde-loss 5.5628e-11, initc-loss 6.3046e+05                    bc_loss 2.8128e+07, Test-Loss 4.6970e+05\n",
      "Epoch 1330, Training-Loss 4.7584e+05, Data-loss 4.6934e+05                  , pde-loss 5.3826e-11, initc-loss 6.2907e+05                    bc_loss 2.7996e+07, Test-Loss 4.6934e+05\n",
      "Epoch 1340, Training-Loss 4.6706e+05, Data-loss 4.5515e+05                  , pde-loss 5.4273e-11, initc-loss 6.2768e+05                    bc_loss 2.7865e+07, Test-Loss 4.5515e+05\n",
      "Epoch 1350, Training-Loss 4.6421e+05, Data-loss 4.5696e+05                  , pde-loss 4.9885e-11, initc-loss 6.2629e+05                    bc_loss 2.7734e+07, Test-Loss 4.5696e+05\n",
      "Epoch 1360, Training-Loss 4.7173e+05, Data-loss 4.6588e+05                  , pde-loss 4.7109e-11, initc-loss 6.2490e+05                    bc_loss 2.7603e+07, Test-Loss 4.6588e+05\n",
      "Epoch 1370, Training-Loss 4.6791e+05, Data-loss 4.5688e+05                  , pde-loss 4.6787e-11, initc-loss 6.2351e+05                    bc_loss 2.7473e+07, Test-Loss 4.5688e+05\n",
      "Epoch 1380, Training-Loss 4.5847e+05, Data-loss 4.6657e+05                  , pde-loss 5.0290e-11, initc-loss 6.2213e+05                    bc_loss 2.7343e+07, Test-Loss 4.6657e+05\n",
      "Epoch 1390, Training-Loss 4.6473e+05, Data-loss 4.6238e+05                  , pde-loss 4.6237e-11, initc-loss 6.2074e+05                    bc_loss 2.7213e+07, Test-Loss 4.6238e+05\n",
      "Epoch 1400, Training-Loss 4.6466e+05, Data-loss 4.5883e+05                  , pde-loss 4.8550e-11, initc-loss 6.1936e+05                    bc_loss 2.7084e+07, Test-Loss 4.5883e+05\n",
      "Epoch 1410, Training-Loss 4.5970e+05, Data-loss 4.5706e+05                  , pde-loss 4.2340e-11, initc-loss 6.1799e+05                    bc_loss 2.6955e+07, Test-Loss 4.5706e+05\n",
      "Epoch 1420, Training-Loss 4.5247e+05, Data-loss 4.5305e+05                  , pde-loss 4.2937e-11, initc-loss 6.1661e+05                    bc_loss 2.6827e+07, Test-Loss 4.5305e+05\n",
      "Epoch 1430, Training-Loss 4.6499e+05, Data-loss 4.5585e+05                  , pde-loss 3.9878e-11, initc-loss 6.1524e+05                    bc_loss 2.6700e+07, Test-Loss 4.5585e+05\n",
      "Epoch 1440, Training-Loss 4.5409e+05, Data-loss 4.6108e+05                  , pde-loss 4.0818e-11, initc-loss 6.1387e+05                    bc_loss 2.6572e+07, Test-Loss 4.6108e+05\n",
      "Epoch 1450, Training-Loss 4.5732e+05, Data-loss 4.5243e+05                  , pde-loss 3.9401e-11, initc-loss 6.1251e+05                    bc_loss 2.6445e+07, Test-Loss 4.5243e+05\n",
      "Epoch 1460, Training-Loss 4.5563e+05, Data-loss 4.5554e+05                  , pde-loss 3.7322e-11, initc-loss 6.1114e+05                    bc_loss 2.6318e+07, Test-Loss 4.5554e+05\n",
      "Epoch 1470, Training-Loss 4.4169e+05, Data-loss 4.4262e+05                  , pde-loss 3.7125e-11, initc-loss 6.0978e+05                    bc_loss 2.6192e+07, Test-Loss 4.4262e+05\n",
      "Epoch 1480, Training-Loss 4.5730e+05, Data-loss 4.4886e+05                  , pde-loss 3.4132e-11, initc-loss 6.0842e+05                    bc_loss 2.6066e+07, Test-Loss 4.4886e+05\n",
      "Epoch 1490, Training-Loss 4.5380e+05, Data-loss 4.4885e+05                  , pde-loss 3.3248e-11, initc-loss 6.0706e+05                    bc_loss 2.5940e+07, Test-Loss 4.4885e+05\n",
      "Epoch 1500, Training-Loss 4.4552e+05, Data-loss 4.4126e+05                  , pde-loss 3.5228e-11, initc-loss 6.0570e+05                    bc_loss 2.5815e+07, Test-Loss 4.4126e+05\n",
      "Epoch 1510, Training-Loss 4.4276e+05, Data-loss 4.4779e+05                  , pde-loss 3.3434e-11, initc-loss 6.0435e+05                    bc_loss 2.5690e+07, Test-Loss 4.4779e+05\n",
      "Epoch 1520, Training-Loss 4.3971e+05, Data-loss 4.4532e+05                  , pde-loss 3.1976e-11, initc-loss 6.0299e+05                    bc_loss 2.5565e+07, Test-Loss 4.4532e+05\n",
      "Epoch 1530, Training-Loss 4.5009e+05, Data-loss 4.3912e+05                  , pde-loss 3.1402e-11, initc-loss 6.0164e+05                    bc_loss 2.5441e+07, Test-Loss 4.3912e+05\n",
      "Epoch 1540, Training-Loss 4.4313e+05, Data-loss 4.3947e+05                  , pde-loss 2.9377e-11, initc-loss 6.0030e+05                    bc_loss 2.5317e+07, Test-Loss 4.3947e+05\n",
      "Epoch 1550, Training-Loss 4.4289e+05, Data-loss 4.4394e+05                  , pde-loss 2.9658e-11, initc-loss 5.9895e+05                    bc_loss 2.5193e+07, Test-Loss 4.4394e+05\n",
      "Epoch 1560, Training-Loss 4.4257e+05, Data-loss 4.4621e+05                  , pde-loss 2.9960e-11, initc-loss 5.9760e+05                    bc_loss 2.5070e+07, Test-Loss 4.4621e+05\n",
      "Epoch 1570, Training-Loss 4.3947e+05, Data-loss 4.3784e+05                  , pde-loss 2.7599e-11, initc-loss 5.9626e+05                    bc_loss 2.4947e+07, Test-Loss 4.3784e+05\n",
      "Epoch 1580, Training-Loss 4.3622e+05, Data-loss 4.2802e+05                  , pde-loss 2.8238e-11, initc-loss 5.9493e+05                    bc_loss 2.4825e+07, Test-Loss 4.2802e+05\n",
      "Epoch 1590, Training-Loss 4.3878e+05, Data-loss 4.4165e+05                  , pde-loss 2.6477e-11, initc-loss 5.9359e+05                    bc_loss 2.4703e+07, Test-Loss 4.4165e+05\n",
      "Epoch 1600, Training-Loss 4.3435e+05, Data-loss 4.3366e+05                  , pde-loss 2.7535e-11, initc-loss 5.9226e+05                    bc_loss 2.4582e+07, Test-Loss 4.3366e+05\n",
      "Epoch 1610, Training-Loss 4.3587e+05, Data-loss 4.3897e+05                  , pde-loss 2.5195e-11, initc-loss 5.9093e+05                    bc_loss 2.4460e+07, Test-Loss 4.3897e+05\n",
      "Epoch 1620, Training-Loss 4.3770e+05, Data-loss 4.4214e+05                  , pde-loss 2.4427e-11, initc-loss 5.8960e+05                    bc_loss 2.4340e+07, Test-Loss 4.4214e+05\n",
      "Epoch 1630, Training-Loss 4.3376e+05, Data-loss 4.2821e+05                  , pde-loss 2.4799e-11, initc-loss 5.8827e+05                    bc_loss 2.4219e+07, Test-Loss 4.2821e+05\n",
      "Epoch 1640, Training-Loss 4.3261e+05, Data-loss 4.2866e+05                  , pde-loss 2.3803e-11, initc-loss 5.8694e+05                    bc_loss 2.4099e+07, Test-Loss 4.2866e+05\n",
      "Epoch 1650, Training-Loss 4.3035e+05, Data-loss 4.3169e+05                  , pde-loss 2.3164e-11, initc-loss 5.8562e+05                    bc_loss 2.3979e+07, Test-Loss 4.3169e+05\n",
      "Epoch 1660, Training-Loss 4.2562e+05, Data-loss 4.2216e+05                  , pde-loss 2.4219e-11, initc-loss 5.8430e+05                    bc_loss 2.3859e+07, Test-Loss 4.2216e+05\n",
      "Epoch 1670, Training-Loss 4.3268e+05, Data-loss 4.2737e+05                  , pde-loss 1.9768e-11, initc-loss 5.8298e+05                    bc_loss 2.3740e+07, Test-Loss 4.2737e+05\n",
      "Epoch 1680, Training-Loss 4.2817e+05, Data-loss 4.2635e+05                  , pde-loss 2.1928e-11, initc-loss 5.8166e+05                    bc_loss 2.3622e+07, Test-Loss 4.2635e+05\n",
      "Epoch 1690, Training-Loss 4.2354e+05, Data-loss 4.1681e+05                  , pde-loss 2.1922e-11, initc-loss 5.8035e+05                    bc_loss 2.3503e+07, Test-Loss 4.1681e+05\n",
      "Epoch 1700, Training-Loss 4.2150e+05, Data-loss 4.2497e+05                  , pde-loss 2.1583e-11, initc-loss 5.7903e+05                    bc_loss 2.3385e+07, Test-Loss 4.2497e+05\n",
      "Epoch 1710, Training-Loss 4.3051e+05, Data-loss 4.2163e+05                  , pde-loss 1.8948e-11, initc-loss 5.7772e+05                    bc_loss 2.3267e+07, Test-Loss 4.2163e+05\n",
      "Epoch 1720, Training-Loss 4.2130e+05, Data-loss 4.2766e+05                  , pde-loss 2.0134e-11, initc-loss 5.7641e+05                    bc_loss 2.3149e+07, Test-Loss 4.2766e+05\n",
      "Epoch 1730, Training-Loss 4.2344e+05, Data-loss 4.1199e+05                  , pde-loss 1.9641e-11, initc-loss 5.7510e+05                    bc_loss 2.3032e+07, Test-Loss 4.1199e+05\n",
      "Epoch 1740, Training-Loss 4.2476e+05, Data-loss 4.0833e+05                  , pde-loss 1.8006e-11, initc-loss 5.7380e+05                    bc_loss 2.2916e+07, Test-Loss 4.0833e+05\n",
      "Epoch 1750, Training-Loss 4.1755e+05, Data-loss 4.3099e+05                  , pde-loss 1.9408e-11, initc-loss 5.7249e+05                    bc_loss 2.2799e+07, Test-Loss 4.3099e+05\n",
      "Epoch 1760, Training-Loss 4.1150e+05, Data-loss 4.1112e+05                  , pde-loss 1.8209e-11, initc-loss 5.7119e+05                    bc_loss 2.2683e+07, Test-Loss 4.1112e+05\n",
      "Epoch 1770, Training-Loss 4.1489e+05, Data-loss 4.0999e+05                  , pde-loss 1.8154e-11, initc-loss 5.6989e+05                    bc_loss 2.2568e+07, Test-Loss 4.0999e+05\n",
      "Epoch 1780, Training-Loss 4.1585e+05, Data-loss 4.1268e+05                  , pde-loss 1.6047e-11, initc-loss 5.6860e+05                    bc_loss 2.2452e+07, Test-Loss 4.1268e+05\n",
      "Epoch 1790, Training-Loss 4.1895e+05, Data-loss 4.0390e+05                  , pde-loss 1.6044e-11, initc-loss 5.6730e+05                    bc_loss 2.2337e+07, Test-Loss 4.0390e+05\n",
      "Epoch 1800, Training-Loss 4.2109e+05, Data-loss 4.1141e+05                  , pde-loss 1.6432e-11, initc-loss 5.6601e+05                    bc_loss 2.2223e+07, Test-Loss 4.1141e+05\n",
      "Epoch 1810, Training-Loss 4.1399e+05, Data-loss 4.0688e+05                  , pde-loss 1.5680e-11, initc-loss 5.6472e+05                    bc_loss 2.2108e+07, Test-Loss 4.0688e+05\n",
      "Epoch 1820, Training-Loss 4.0679e+05, Data-loss 4.1414e+05                  , pde-loss 1.6810e-11, initc-loss 5.6343e+05                    bc_loss 2.1995e+07, Test-Loss 4.1414e+05\n",
      "Epoch 1830, Training-Loss 4.1986e+05, Data-loss 4.0769e+05                  , pde-loss 1.4407e-11, initc-loss 5.6215e+05                    bc_loss 2.1881e+07, Test-Loss 4.0769e+05\n",
      "Epoch 1840, Training-Loss 4.1229e+05, Data-loss 4.1759e+05                  , pde-loss 1.4625e-11, initc-loss 5.6086e+05                    bc_loss 2.1768e+07, Test-Loss 4.1759e+05\n",
      "Epoch 1850, Training-Loss 4.0643e+05, Data-loss 4.1118e+05                  , pde-loss 1.4745e-11, initc-loss 5.5958e+05                    bc_loss 2.1655e+07, Test-Loss 4.1118e+05\n",
      "Epoch 1860, Training-Loss 4.0775e+05, Data-loss 4.1205e+05                  , pde-loss 1.4396e-11, initc-loss 5.5830e+05                    bc_loss 2.1542e+07, Test-Loss 4.1205e+05\n",
      "Epoch 1870, Training-Loss 4.0111e+05, Data-loss 4.0398e+05                  , pde-loss 1.5231e-11, initc-loss 5.5702e+05                    bc_loss 2.1430e+07, Test-Loss 4.0398e+05\n",
      "Epoch 1880, Training-Loss 4.0819e+05, Data-loss 4.0854e+05                  , pde-loss 1.3678e-11, initc-loss 5.5575e+05                    bc_loss 2.1319e+07, Test-Loss 4.0854e+05\n",
      "Epoch 1890, Training-Loss 3.9453e+05, Data-loss 3.9722e+05                  , pde-loss 1.4277e-11, initc-loss 5.5447e+05                    bc_loss 2.1207e+07, Test-Loss 3.9722e+05\n",
      "Epoch 1900, Training-Loss 4.0975e+05, Data-loss 4.1434e+05                  , pde-loss 1.2433e-11, initc-loss 5.5320e+05                    bc_loss 2.1096e+07, Test-Loss 4.1434e+05\n",
      "Epoch 1910, Training-Loss 3.9937e+05, Data-loss 4.0032e+05                  , pde-loss 1.2702e-11, initc-loss 5.5193e+05                    bc_loss 2.0985e+07, Test-Loss 4.0032e+05\n",
      "Epoch 1920, Training-Loss 4.0262e+05, Data-loss 4.1112e+05                  , pde-loss 1.2438e-11, initc-loss 5.5067e+05                    bc_loss 2.0875e+07, Test-Loss 4.1112e+05\n",
      "Epoch 1930, Training-Loss 4.0702e+05, Data-loss 3.9990e+05                  , pde-loss 1.1722e-11, initc-loss 5.4940e+05                    bc_loss 2.0765e+07, Test-Loss 3.9990e+05\n",
      "Epoch 1940, Training-Loss 3.9194e+05, Data-loss 3.9650e+05                  , pde-loss 1.2927e-11, initc-loss 5.4814e+05                    bc_loss 2.0655e+07, Test-Loss 3.9650e+05\n",
      "Epoch 1950, Training-Loss 3.9342e+05, Data-loss 3.9690e+05                  , pde-loss 1.2182e-11, initc-loss 5.4688e+05                    bc_loss 2.0546e+07, Test-Loss 3.9690e+05\n",
      "Epoch 1960, Training-Loss 3.9694e+05, Data-loss 3.9851e+05                  , pde-loss 1.1873e-11, initc-loss 5.4562e+05                    bc_loss 2.0437e+07, Test-Loss 3.9851e+05\n",
      "Epoch 1970, Training-Loss 3.9647e+05, Data-loss 3.9712e+05                  , pde-loss 1.1423e-11, initc-loss 5.4436e+05                    bc_loss 2.0328e+07, Test-Loss 3.9712e+05\n",
      "Epoch 1980, Training-Loss 4.0735e+05, Data-loss 3.9264e+05                  , pde-loss 9.2612e-12, initc-loss 5.4310e+05                    bc_loss 2.0219e+07, Test-Loss 3.9264e+05\n",
      "Epoch 1990, Training-Loss 3.9497e+05, Data-loss 3.8984e+05                  , pde-loss 1.0470e-11, initc-loss 5.4185e+05                    bc_loss 2.0111e+07, Test-Loss 3.8984e+05\n",
      "Epoch 2000, Training-Loss 3.9425e+05, Data-loss 3.8726e+05                  , pde-loss 1.0009e-11, initc-loss 5.4059e+05                    bc_loss 2.0003e+07, Test-Loss 3.8726e+05\n",
      "Epoch 2010, Training-Loss 3.9286e+05, Data-loss 3.8960e+05                  , pde-loss 1.0610e-11, initc-loss 5.3934e+05                    bc_loss 1.9895e+07, Test-Loss 3.8960e+05\n",
      "Epoch 2020, Training-Loss 3.9097e+05, Data-loss 3.8725e+05                  , pde-loss 1.0331e-11, initc-loss 5.3809e+05                    bc_loss 1.9788e+07, Test-Loss 3.8725e+05\n",
      "Epoch 2030, Training-Loss 3.9409e+05, Data-loss 3.8785e+05                  , pde-loss 9.9389e-12, initc-loss 5.3684e+05                    bc_loss 1.9681e+07, Test-Loss 3.8785e+05\n",
      "Epoch 2040, Training-Loss 3.9317e+05, Data-loss 3.8800e+05                  , pde-loss 9.3185e-12, initc-loss 5.3560e+05                    bc_loss 1.9575e+07, Test-Loss 3.8800e+05\n",
      "Epoch 2050, Training-Loss 3.8487e+05, Data-loss 3.8663e+05                  , pde-loss 9.7847e-12, initc-loss 5.3435e+05                    bc_loss 1.9468e+07, Test-Loss 3.8663e+05\n",
      "Epoch 2060, Training-Loss 3.8252e+05, Data-loss 3.9075e+05                  , pde-loss 9.7137e-12, initc-loss 5.3311e+05                    bc_loss 1.9362e+07, Test-Loss 3.9075e+05\n",
      "Epoch 2070, Training-Loss 3.8503e+05, Data-loss 3.8008e+05                  , pde-loss 9.0554e-12, initc-loss 5.3187e+05                    bc_loss 1.9257e+07, Test-Loss 3.8008e+05\n",
      "Epoch 2080, Training-Loss 3.8768e+05, Data-loss 3.8092e+05                  , pde-loss 9.2659e-12, initc-loss 5.3064e+05                    bc_loss 1.9152e+07, Test-Loss 3.8092e+05\n",
      "Epoch 2090, Training-Loss 3.8383e+05, Data-loss 3.7771e+05                  , pde-loss 9.2436e-12, initc-loss 5.2940e+05                    bc_loss 1.9047e+07, Test-Loss 3.7771e+05\n",
      "Epoch 2100, Training-Loss 3.8610e+05, Data-loss 3.7848e+05                  , pde-loss 8.1079e-12, initc-loss 5.2817e+05                    bc_loss 1.8942e+07, Test-Loss 3.7848e+05\n",
      "Epoch 2110, Training-Loss 3.8486e+05, Data-loss 3.7872e+05                  , pde-loss 8.6344e-12, initc-loss 5.2694e+05                    bc_loss 1.8838e+07, Test-Loss 3.7872e+05\n",
      "Epoch 2120, Training-Loss 3.8644e+05, Data-loss 3.7407e+05                  , pde-loss 8.1489e-12, initc-loss 5.2571e+05                    bc_loss 1.8734e+07, Test-Loss 3.7407e+05\n",
      "Epoch 2130, Training-Loss 3.8450e+05, Data-loss 3.7988e+05                  , pde-loss 8.2820e-12, initc-loss 5.2448e+05                    bc_loss 1.8630e+07, Test-Loss 3.7988e+05\n",
      "Epoch 2140, Training-Loss 3.8681e+05, Data-loss 3.7715e+05                  , pde-loss 7.9188e-12, initc-loss 5.2325e+05                    bc_loss 1.8527e+07, Test-Loss 3.7715e+05\n",
      "Epoch 2150, Training-Loss 3.7964e+05, Data-loss 3.7443e+05                  , pde-loss 8.2219e-12, initc-loss 5.2203e+05                    bc_loss 1.8424e+07, Test-Loss 3.7443e+05\n",
      "Epoch 2160, Training-Loss 3.7161e+05, Data-loss 3.6639e+05                  , pde-loss 8.3974e-12, initc-loss 5.2080e+05                    bc_loss 1.8321e+07, Test-Loss 3.6639e+05\n",
      "Epoch 2170, Training-Loss 3.8070e+05, Data-loss 3.7654e+05                  , pde-loss 8.1119e-12, initc-loss 5.1958e+05                    bc_loss 1.8219e+07, Test-Loss 3.7654e+05\n",
      "Epoch 2180, Training-Loss 3.7834e+05, Data-loss 3.7775e+05                  , pde-loss 7.8673e-12, initc-loss 5.1837e+05                    bc_loss 1.8117e+07, Test-Loss 3.7775e+05\n",
      "Epoch 2190, Training-Loss 3.7784e+05, Data-loss 3.7272e+05                  , pde-loss 6.9771e-12, initc-loss 5.1715e+05                    bc_loss 1.8016e+07, Test-Loss 3.7272e+05\n",
      "Epoch 2200, Training-Loss 3.6972e+05, Data-loss 3.7669e+05                  , pde-loss 7.8723e-12, initc-loss 5.1594e+05                    bc_loss 1.7915e+07, Test-Loss 3.7669e+05\n",
      "Epoch 2210, Training-Loss 3.6889e+05, Data-loss 3.7155e+05                  , pde-loss 8.0184e-12, initc-loss 5.1473e+05                    bc_loss 1.7814e+07, Test-Loss 3.7155e+05\n",
      "Epoch 2220, Training-Loss 3.7175e+05, Data-loss 3.6879e+05                  , pde-loss 7.6177e-12, initc-loss 5.1352e+05                    bc_loss 1.7713e+07, Test-Loss 3.6879e+05\n",
      "Epoch 2230, Training-Loss 3.6970e+05, Data-loss 3.6894e+05                  , pde-loss 7.1035e-12, initc-loss 5.1231e+05                    bc_loss 1.7613e+07, Test-Loss 3.6894e+05\n",
      "Epoch 2240, Training-Loss 3.6368e+05, Data-loss 3.6414e+05                  , pde-loss 7.2339e-12, initc-loss 5.1111e+05                    bc_loss 1.7513e+07, Test-Loss 3.6414e+05\n",
      "Epoch 2250, Training-Loss 3.6356e+05, Data-loss 3.6313e+05                  , pde-loss 6.6158e-12, initc-loss 5.0990e+05                    bc_loss 1.7414e+07, Test-Loss 3.6313e+05\n",
      "Epoch 2260, Training-Loss 3.6376e+05, Data-loss 3.6551e+05                  , pde-loss 6.8318e-12, initc-loss 5.0870e+05                    bc_loss 1.7315e+07, Test-Loss 3.6551e+05\n",
      "Epoch 2270, Training-Loss 3.6427e+05, Data-loss 3.6415e+05                  , pde-loss 6.6136e-12, initc-loss 5.0750e+05                    bc_loss 1.7216e+07, Test-Loss 3.6415e+05\n",
      "Epoch 2280, Training-Loss 3.6174e+05, Data-loss 3.6148e+05                  , pde-loss 6.5414e-12, initc-loss 5.0630e+05                    bc_loss 1.7117e+07, Test-Loss 3.6148e+05\n",
      "Epoch 2290, Training-Loss 3.6245e+05, Data-loss 3.6098e+05                  , pde-loss 6.1368e-12, initc-loss 5.0511e+05                    bc_loss 1.7019e+07, Test-Loss 3.6098e+05\n",
      "Epoch 2300, Training-Loss 3.6651e+05, Data-loss 3.6359e+05                  , pde-loss 6.2187e-12, initc-loss 5.0392e+05                    bc_loss 1.6921e+07, Test-Loss 3.6359e+05\n",
      "Epoch 2310, Training-Loss 3.7101e+05, Data-loss 3.5913e+05                  , pde-loss 5.6731e-12, initc-loss 5.0273e+05                    bc_loss 1.6824e+07, Test-Loss 3.5913e+05\n",
      "Epoch 2320, Training-Loss 3.5886e+05, Data-loss 3.6094e+05                  , pde-loss 5.8515e-12, initc-loss 5.0153e+05                    bc_loss 1.6726e+07, Test-Loss 3.6094e+05\n",
      "Epoch 2330, Training-Loss 3.6283e+05, Data-loss 3.5165e+05                  , pde-loss 5.7865e-12, initc-loss 5.0035e+05                    bc_loss 1.6629e+07, Test-Loss 3.5165e+05\n",
      "Epoch 2340, Training-Loss 3.6166e+05, Data-loss 3.5524e+05                  , pde-loss 5.8600e-12, initc-loss 4.9916e+05                    bc_loss 1.6532e+07, Test-Loss 3.5524e+05\n",
      "Epoch 2350, Training-Loss 3.6235e+05, Data-loss 3.5841e+05                  , pde-loss 5.3067e-12, initc-loss 4.9797e+05                    bc_loss 1.6436e+07, Test-Loss 3.5841e+05\n",
      "Epoch 2360, Training-Loss 3.5459e+05, Data-loss 3.5980e+05                  , pde-loss 5.6169e-12, initc-loss 4.9679e+05                    bc_loss 1.6340e+07, Test-Loss 3.5980e+05\n",
      "Epoch 2370, Training-Loss 3.4979e+05, Data-loss 3.5946e+05                  , pde-loss 5.5222e-12, initc-loss 4.9561e+05                    bc_loss 1.6244e+07, Test-Loss 3.5946e+05\n",
      "Epoch 2380, Training-Loss 3.5296e+05, Data-loss 3.5753e+05                  , pde-loss 5.2677e-12, initc-loss 4.9443e+05                    bc_loss 1.6149e+07, Test-Loss 3.5753e+05\n",
      "Epoch 2390, Training-Loss 3.4393e+05, Data-loss 3.5193e+05                  , pde-loss 5.8073e-12, initc-loss 4.9325e+05                    bc_loss 1.6054e+07, Test-Loss 3.5193e+05\n",
      "Epoch 2400, Training-Loss 3.5452e+05, Data-loss 3.4765e+05                  , pde-loss 5.4579e-12, initc-loss 4.9207e+05                    bc_loss 1.5959e+07, Test-Loss 3.4765e+05\n",
      "Epoch 2410, Training-Loss 3.5460e+05, Data-loss 3.4838e+05                  , pde-loss 4.9672e-12, initc-loss 4.9090e+05                    bc_loss 1.5864e+07, Test-Loss 3.4838e+05\n",
      "Epoch 2420, Training-Loss 3.4980e+05, Data-loss 3.4827e+05                  , pde-loss 4.8110e-12, initc-loss 4.8973e+05                    bc_loss 1.5770e+07, Test-Loss 3.4827e+05\n",
      "Epoch 2430, Training-Loss 3.4777e+05, Data-loss 3.4161e+05                  , pde-loss 4.9378e-12, initc-loss 4.8856e+05                    bc_loss 1.5676e+07, Test-Loss 3.4161e+05\n",
      "Epoch 2440, Training-Loss 3.5495e+05, Data-loss 3.4872e+05                  , pde-loss 4.7881e-12, initc-loss 4.8739e+05                    bc_loss 1.5583e+07, Test-Loss 3.4872e+05\n",
      "Epoch 2450, Training-Loss 3.4227e+05, Data-loss 3.4012e+05                  , pde-loss 4.9602e-12, initc-loss 4.8622e+05                    bc_loss 1.5490e+07, Test-Loss 3.4012e+05\n",
      "Epoch 2460, Training-Loss 3.4142e+05, Data-loss 3.4735e+05                  , pde-loss 4.9106e-12, initc-loss 4.8506e+05                    bc_loss 1.5397e+07, Test-Loss 3.4735e+05\n",
      "Epoch 2470, Training-Loss 3.4837e+05, Data-loss 3.4742e+05                  , pde-loss 4.7887e-12, initc-loss 4.8389e+05                    bc_loss 1.5304e+07, Test-Loss 3.4742e+05\n",
      "Epoch 2480, Training-Loss 3.4631e+05, Data-loss 3.4813e+05                  , pde-loss 4.8997e-12, initc-loss 4.8273e+05                    bc_loss 1.5212e+07, Test-Loss 3.4813e+05\n",
      "Epoch 2490, Training-Loss 3.3906e+05, Data-loss 3.4117e+05                  , pde-loss 4.6113e-12, initc-loss 4.8157e+05                    bc_loss 1.5120e+07, Test-Loss 3.4117e+05\n",
      "Epoch 2500, Training-Loss 3.4337e+05, Data-loss 3.4027e+05                  , pde-loss 4.3105e-12, initc-loss 4.8041e+05                    bc_loss 1.5028e+07, Test-Loss 3.4027e+05\n",
      "Epoch 2510, Training-Loss 3.4678e+05, Data-loss 3.3915e+05                  , pde-loss 4.1993e-12, initc-loss 4.7925e+05                    bc_loss 1.4936e+07, Test-Loss 3.3915e+05\n",
      "Epoch 2520, Training-Loss 3.3629e+05, Data-loss 3.3697e+05                  , pde-loss 4.5866e-12, initc-loss 4.7810e+05                    bc_loss 1.4845e+07, Test-Loss 3.3697e+05\n",
      "Epoch 2530, Training-Loss 3.3733e+05, Data-loss 3.2919e+05                  , pde-loss 4.4739e-12, initc-loss 4.7695e+05                    bc_loss 1.4755e+07, Test-Loss 3.2919e+05\n",
      "Epoch 2540, Training-Loss 3.3613e+05, Data-loss 3.3616e+05                  , pde-loss 4.1265e-12, initc-loss 4.7580e+05                    bc_loss 1.4664e+07, Test-Loss 3.3616e+05\n",
      "Epoch 2550, Training-Loss 3.3816e+05, Data-loss 3.3589e+05                  , pde-loss 4.0520e-12, initc-loss 4.7465e+05                    bc_loss 1.4574e+07, Test-Loss 3.3589e+05\n",
      "Epoch 2560, Training-Loss 3.3644e+05, Data-loss 3.3961e+05                  , pde-loss 4.0432e-12, initc-loss 4.7350e+05                    bc_loss 1.4485e+07, Test-Loss 3.3961e+05\n",
      "Epoch 2570, Training-Loss 3.3643e+05, Data-loss 3.3980e+05                  , pde-loss 3.9578e-12, initc-loss 4.7236e+05                    bc_loss 1.4395e+07, Test-Loss 3.3980e+05\n",
      "Epoch 2580, Training-Loss 3.3759e+05, Data-loss 3.3348e+05                  , pde-loss 3.8219e-12, initc-loss 4.7121e+05                    bc_loss 1.4306e+07, Test-Loss 3.3348e+05\n",
      "Epoch 2590, Training-Loss 3.3229e+05, Data-loss 3.3023e+05                  , pde-loss 4.0206e-12, initc-loss 4.7007e+05                    bc_loss 1.4217e+07, Test-Loss 3.3023e+05\n",
      "Epoch 2600, Training-Loss 3.2884e+05, Data-loss 3.2681e+05                  , pde-loss 3.9436e-12, initc-loss 4.6893e+05                    bc_loss 1.4128e+07, Test-Loss 3.2681e+05\n",
      "Epoch 2610, Training-Loss 3.3232e+05, Data-loss 3.3096e+05                  , pde-loss 3.7931e-12, initc-loss 4.6779e+05                    bc_loss 1.4040e+07, Test-Loss 3.3096e+05\n",
      "Epoch 2620, Training-Loss 3.3099e+05, Data-loss 3.3026e+05                  , pde-loss 3.7939e-12, initc-loss 4.6666e+05                    bc_loss 1.3952e+07, Test-Loss 3.3026e+05\n",
      "Epoch 2630, Training-Loss 3.3074e+05, Data-loss 3.2643e+05                  , pde-loss 3.6407e-12, initc-loss 4.6553e+05                    bc_loss 1.3865e+07, Test-Loss 3.2643e+05\n",
      "Epoch 2640, Training-Loss 3.2868e+05, Data-loss 3.2356e+05                  , pde-loss 3.4662e-12, initc-loss 4.6440e+05                    bc_loss 1.3778e+07, Test-Loss 3.2356e+05\n",
      "Epoch 2650, Training-Loss 3.2813e+05, Data-loss 3.2615e+05                  , pde-loss 3.8275e-12, initc-loss 4.6327e+05                    bc_loss 1.3691e+07, Test-Loss 3.2615e+05\n",
      "Epoch 2660, Training-Loss 3.2122e+05, Data-loss 3.2358e+05                  , pde-loss 3.6514e-12, initc-loss 4.6214e+05                    bc_loss 1.3604e+07, Test-Loss 3.2358e+05\n",
      "Epoch 2670, Training-Loss 3.2595e+05, Data-loss 3.3241e+05                  , pde-loss 3.6325e-12, initc-loss 4.6101e+05                    bc_loss 1.3518e+07, Test-Loss 3.3241e+05\n",
      "Epoch 2680, Training-Loss 3.2945e+05, Data-loss 3.2168e+05                  , pde-loss 3.3551e-12, initc-loss 4.5989e+05                    bc_loss 1.3432e+07, Test-Loss 3.2168e+05\n",
      "Epoch 2690, Training-Loss 3.2577e+05, Data-loss 3.1615e+05                  , pde-loss 3.1772e-12, initc-loss 4.5876e+05                    bc_loss 1.3346e+07, Test-Loss 3.1615e+05\n",
      "Epoch 2700, Training-Loss 3.2698e+05, Data-loss 3.1689e+05                  , pde-loss 3.0430e-12, initc-loss 4.5764e+05                    bc_loss 1.3260e+07, Test-Loss 3.1689e+05\n",
      "Epoch 2710, Training-Loss 3.2362e+05, Data-loss 3.2786e+05                  , pde-loss 3.3158e-12, initc-loss 4.5652e+05                    bc_loss 1.3175e+07, Test-Loss 3.2786e+05\n",
      "Epoch 2720, Training-Loss 3.2110e+05, Data-loss 3.1703e+05                  , pde-loss 3.1924e-12, initc-loss 4.5540e+05                    bc_loss 1.3090e+07, Test-Loss 3.1703e+05\n",
      "Epoch 2730, Training-Loss 3.2114e+05, Data-loss 3.1650e+05                  , pde-loss 3.2335e-12, initc-loss 4.5429e+05                    bc_loss 1.3006e+07, Test-Loss 3.1650e+05\n",
      "Epoch 2740, Training-Loss 3.2244e+05, Data-loss 3.1467e+05                  , pde-loss 3.0969e-12, initc-loss 4.5317e+05                    bc_loss 1.2922e+07, Test-Loss 3.1467e+05\n",
      "Epoch 2750, Training-Loss 3.1144e+05, Data-loss 3.2381e+05                  , pde-loss 3.0906e-12, initc-loss 4.5206e+05                    bc_loss 1.2838e+07, Test-Loss 3.2381e+05\n",
      "Epoch 2760, Training-Loss 3.2057e+05, Data-loss 3.1875e+05                  , pde-loss 3.0443e-12, initc-loss 4.5095e+05                    bc_loss 1.2754e+07, Test-Loss 3.1875e+05\n",
      "Epoch 2770, Training-Loss 3.1782e+05, Data-loss 3.1690e+05                  , pde-loss 2.9141e-12, initc-loss 4.4984e+05                    bc_loss 1.2670e+07, Test-Loss 3.1690e+05\n",
      "Epoch 2780, Training-Loss 3.1551e+05, Data-loss 3.1426e+05                  , pde-loss 3.0849e-12, initc-loss 4.4873e+05                    bc_loss 1.2587e+07, Test-Loss 3.1426e+05\n",
      "Epoch 2790, Training-Loss 3.1858e+05, Data-loss 3.0862e+05                  , pde-loss 2.9522e-12, initc-loss 4.4762e+05                    bc_loss 1.2504e+07, Test-Loss 3.0862e+05\n",
      "Epoch 2800, Training-Loss 3.1746e+05, Data-loss 3.0766e+05                  , pde-loss 2.6653e-12, initc-loss 4.4651e+05                    bc_loss 1.2422e+07, Test-Loss 3.0766e+05\n",
      "Epoch 2810, Training-Loss 3.1039e+05, Data-loss 3.1567e+05                  , pde-loss 2.8719e-12, initc-loss 4.4541e+05                    bc_loss 1.2339e+07, Test-Loss 3.1567e+05\n",
      "Epoch 2820, Training-Loss 3.0434e+05, Data-loss 3.0947e+05                  , pde-loss 2.9622e-12, initc-loss 4.4431e+05                    bc_loss 1.2258e+07, Test-Loss 3.0947e+05\n",
      "Epoch 2830, Training-Loss 3.1762e+05, Data-loss 3.1048e+05                  , pde-loss 2.6326e-12, initc-loss 4.4321e+05                    bc_loss 1.2176e+07, Test-Loss 3.1048e+05\n",
      "Epoch 2840, Training-Loss 3.1211e+05, Data-loss 3.0875e+05                  , pde-loss 2.8213e-12, initc-loss 4.4211e+05                    bc_loss 1.2095e+07, Test-Loss 3.0875e+05\n",
      "Epoch 2850, Training-Loss 3.0641e+05, Data-loss 3.0934e+05                  , pde-loss 2.7983e-12, initc-loss 4.4101e+05                    bc_loss 1.2014e+07, Test-Loss 3.0934e+05\n",
      "Epoch 2860, Training-Loss 3.0927e+05, Data-loss 3.0258e+05                  , pde-loss 2.7752e-12, initc-loss 4.3992e+05                    bc_loss 1.1933e+07, Test-Loss 3.0258e+05\n",
      "Epoch 2870, Training-Loss 3.0811e+05, Data-loss 3.0502e+05                  , pde-loss 2.7351e-12, initc-loss 4.3883e+05                    bc_loss 1.1853e+07, Test-Loss 3.0502e+05\n",
      "Epoch 2880, Training-Loss 3.0721e+05, Data-loss 3.0563e+05                  , pde-loss 2.4737e-12, initc-loss 4.3774e+05                    bc_loss 1.1773e+07, Test-Loss 3.0563e+05\n",
      "Epoch 2890, Training-Loss 3.1120e+05, Data-loss 3.0348e+05                  , pde-loss 2.4715e-12, initc-loss 4.3665e+05                    bc_loss 1.1693e+07, Test-Loss 3.0348e+05\n",
      "Epoch 2900, Training-Loss 3.0234e+05, Data-loss 2.9795e+05                  , pde-loss 2.4676e-12, initc-loss 4.3556e+05                    bc_loss 1.1614e+07, Test-Loss 2.9795e+05\n",
      "Epoch 2910, Training-Loss 3.0122e+05, Data-loss 3.0304e+05                  , pde-loss 2.5556e-12, initc-loss 4.3448e+05                    bc_loss 1.1534e+07, Test-Loss 3.0304e+05\n",
      "Epoch 2920, Training-Loss 3.0415e+05, Data-loss 3.0078e+05                  , pde-loss 2.5929e-12, initc-loss 4.3339e+05                    bc_loss 1.1455e+07, Test-Loss 3.0078e+05\n",
      "Epoch 2930, Training-Loss 3.0016e+05, Data-loss 3.0000e+05                  , pde-loss 2.4459e-12, initc-loss 4.3231e+05                    bc_loss 1.1377e+07, Test-Loss 3.0000e+05\n",
      "Epoch 2940, Training-Loss 3.0749e+05, Data-loss 2.9976e+05                  , pde-loss 2.4144e-12, initc-loss 4.3123e+05                    bc_loss 1.1299e+07, Test-Loss 2.9976e+05\n",
      "Epoch 2950, Training-Loss 3.0132e+05, Data-loss 2.9447e+05                  , pde-loss 2.4472e-12, initc-loss 4.3015e+05                    bc_loss 1.1221e+07, Test-Loss 2.9447e+05\n",
      "Epoch 2960, Training-Loss 3.0134e+05, Data-loss 3.0027e+05                  , pde-loss 2.3311e-12, initc-loss 4.2908e+05                    bc_loss 1.1143e+07, Test-Loss 3.0027e+05\n",
      "Epoch 2970, Training-Loss 2.9429e+05, Data-loss 2.9485e+05                  , pde-loss 2.2762e-12, initc-loss 4.2800e+05                    bc_loss 1.1066e+07, Test-Loss 2.9485e+05\n",
      "Epoch 2980, Training-Loss 2.9630e+05, Data-loss 2.9745e+05                  , pde-loss 2.4982e-12, initc-loss 4.2693e+05                    bc_loss 1.0988e+07, Test-Loss 2.9745e+05\n",
      "Epoch 2990, Training-Loss 2.9736e+05, Data-loss 2.9880e+05                  , pde-loss 2.3401e-12, initc-loss 4.2586e+05                    bc_loss 1.0912e+07, Test-Loss 2.9880e+05\n",
      "Epoch 3000, Training-Loss 3.0093e+05, Data-loss 2.9146e+05                  , pde-loss 2.2894e-12, initc-loss 4.2478e+05                    bc_loss 1.0835e+07, Test-Loss 2.9146e+05\n",
      "Epoch 3010, Training-Loss 3.0045e+05, Data-loss 2.9572e+05                  , pde-loss 2.1166e-12, initc-loss 4.2371e+05                    bc_loss 1.0758e+07, Test-Loss 2.9572e+05\n",
      "Epoch 3020, Training-Loss 3.0210e+05, Data-loss 2.9860e+05                  , pde-loss 2.1071e-12, initc-loss 4.2264e+05                    bc_loss 1.0682e+07, Test-Loss 2.9860e+05\n",
      "Epoch 3030, Training-Loss 2.9389e+05, Data-loss 2.9172e+05                  , pde-loss 2.1572e-12, initc-loss 4.2158e+05                    bc_loss 1.0607e+07, Test-Loss 2.9172e+05\n",
      "Epoch 3040, Training-Loss 2.9646e+05, Data-loss 2.9214e+05                  , pde-loss 2.1101e-12, initc-loss 4.2052e+05                    bc_loss 1.0531e+07, Test-Loss 2.9214e+05\n",
      "Epoch 3050, Training-Loss 2.9444e+05, Data-loss 2.9047e+05                  , pde-loss 1.9781e-12, initc-loss 4.1945e+05                    bc_loss 1.0456e+07, Test-Loss 2.9047e+05\n",
      "Epoch 3060, Training-Loss 2.9280e+05, Data-loss 2.8647e+05                  , pde-loss 2.0662e-12, initc-loss 4.1840e+05                    bc_loss 1.0382e+07, Test-Loss 2.8647e+05\n",
      "Epoch 3070, Training-Loss 2.8785e+05, Data-loss 2.8519e+05                  , pde-loss 2.0818e-12, initc-loss 4.1734e+05                    bc_loss 1.0307e+07, Test-Loss 2.8519e+05\n",
      "Epoch 3080, Training-Loss 2.8999e+05, Data-loss 2.8889e+05                  , pde-loss 2.0457e-12, initc-loss 4.1628e+05                    bc_loss 1.0233e+07, Test-Loss 2.8889e+05\n",
      "Epoch 3090, Training-Loss 2.8782e+05, Data-loss 2.8402e+05                  , pde-loss 2.0598e-12, initc-loss 4.1523e+05                    bc_loss 1.0159e+07, Test-Loss 2.8402e+05\n",
      "Epoch 3100, Training-Loss 2.8870e+05, Data-loss 2.8431e+05                  , pde-loss 2.0479e-12, initc-loss 4.1418e+05                    bc_loss 1.0086e+07, Test-Loss 2.8431e+05\n",
      "Epoch 3110, Training-Loss 2.8836e+05, Data-loss 2.8671e+05                  , pde-loss 1.9352e-12, initc-loss 4.1313e+05                    bc_loss 1.0013e+07, Test-Loss 2.8671e+05\n",
      "Epoch 3120, Training-Loss 2.8818e+05, Data-loss 2.8015e+05                  , pde-loss 1.8337e-12, initc-loss 4.1208e+05                    bc_loss 9.9397e+06, Test-Loss 2.8015e+05\n",
      "Epoch 3130, Training-Loss 2.8712e+05, Data-loss 2.7698e+05                  , pde-loss 1.8648e-12, initc-loss 4.1103e+05                    bc_loss 9.8671e+06, Test-Loss 2.7698e+05\n",
      "Epoch 3140, Training-Loss 2.8325e+05, Data-loss 2.8817e+05                  , pde-loss 1.8498e-12, initc-loss 4.0998e+05                    bc_loss 9.7948e+06, Test-Loss 2.8817e+05\n",
      "Epoch 3150, Training-Loss 2.8272e+05, Data-loss 2.7780e+05                  , pde-loss 1.8594e-12, initc-loss 4.0894e+05                    bc_loss 9.7226e+06, Test-Loss 2.7780e+05\n",
      "Epoch 3160, Training-Loss 2.8730e+05, Data-loss 2.7791e+05                  , pde-loss 1.7640e-12, initc-loss 4.0790e+05                    bc_loss 9.6508e+06, Test-Loss 2.7791e+05\n",
      "Epoch 3170, Training-Loss 2.8883e+05, Data-loss 2.7916e+05                  , pde-loss 1.6746e-12, initc-loss 4.0685e+05                    bc_loss 9.5792e+06, Test-Loss 2.7916e+05\n",
      "Epoch 3180, Training-Loss 2.8642e+05, Data-loss 2.8207e+05                  , pde-loss 1.7495e-12, initc-loss 4.0581e+05                    bc_loss 9.5078e+06, Test-Loss 2.8207e+05\n",
      "Epoch 3190, Training-Loss 2.7041e+05, Data-loss 2.7237e+05                  , pde-loss 1.8736e-12, initc-loss 4.0477e+05                    bc_loss 9.4367e+06, Test-Loss 2.7237e+05\n",
      "Epoch 3200, Training-Loss 2.7990e+05, Data-loss 2.8119e+05                  , pde-loss 1.7041e-12, initc-loss 4.0374e+05                    bc_loss 9.3662e+06, Test-Loss 2.8119e+05\n",
      "Epoch 3210, Training-Loss 2.7916e+05, Data-loss 2.7874e+05                  , pde-loss 1.7221e-12, initc-loss 4.0270e+05                    bc_loss 9.2958e+06, Test-Loss 2.7874e+05\n",
      "Epoch 3220, Training-Loss 2.7762e+05, Data-loss 2.7424e+05                  , pde-loss 1.7017e-12, initc-loss 4.0167e+05                    bc_loss 9.2257e+06, Test-Loss 2.7424e+05\n",
      "Epoch 3230, Training-Loss 2.7323e+05, Data-loss 2.7226e+05                  , pde-loss 1.7341e-12, initc-loss 4.0064e+05                    bc_loss 9.1560e+06, Test-Loss 2.7226e+05\n",
      "Epoch 3240, Training-Loss 2.7510e+05, Data-loss 2.7789e+05                  , pde-loss 1.7519e-12, initc-loss 3.9961e+05                    bc_loss 9.0865e+06, Test-Loss 2.7789e+05\n",
      "Epoch 3250, Training-Loss 2.7460e+05, Data-loss 2.7520e+05                  , pde-loss 1.5699e-12, initc-loss 3.9858e+05                    bc_loss 9.0172e+06, Test-Loss 2.7520e+05\n",
      "Epoch 3260, Training-Loss 2.7189e+05, Data-loss 2.7038e+05                  , pde-loss 1.6415e-12, initc-loss 3.9756e+05                    bc_loss 8.9484e+06, Test-Loss 2.7038e+05\n",
      "Epoch 3270, Training-Loss 2.7817e+05, Data-loss 2.7748e+05                  , pde-loss 1.5702e-12, initc-loss 3.9654e+05                    bc_loss 8.8800e+06, Test-Loss 2.7748e+05\n",
      "Epoch 3280, Training-Loss 2.7218e+05, Data-loss 2.7007e+05                  , pde-loss 1.5705e-12, initc-loss 3.9552e+05                    bc_loss 8.8118e+06, Test-Loss 2.7007e+05\n",
      "Epoch 3290, Training-Loss 2.7773e+05, Data-loss 2.7214e+05                  , pde-loss 1.3958e-12, initc-loss 3.9450e+05                    bc_loss 8.7438e+06, Test-Loss 2.7214e+05\n",
      "Epoch 3300, Training-Loss 2.7006e+05, Data-loss 2.7227e+05                  , pde-loss 1.5767e-12, initc-loss 3.9348e+05                    bc_loss 8.6760e+06, Test-Loss 2.7227e+05\n",
      "Epoch 3310, Training-Loss 2.6811e+05, Data-loss 2.6715e+05                  , pde-loss 1.4778e-12, initc-loss 3.9246e+05                    bc_loss 8.6086e+06, Test-Loss 2.6715e+05\n",
      "Epoch 3320, Training-Loss 2.6175e+05, Data-loss 2.6210e+05                  , pde-loss 1.5365e-12, initc-loss 3.9145e+05                    bc_loss 8.5414e+06, Test-Loss 2.6210e+05\n",
      "Epoch 3330, Training-Loss 2.6426e+05, Data-loss 2.6407e+05                  , pde-loss 1.5562e-12, initc-loss 3.9043e+05                    bc_loss 8.4745e+06, Test-Loss 2.6407e+05\n",
      "Epoch 3340, Training-Loss 2.6717e+05, Data-loss 2.6551e+05                  , pde-loss 1.4735e-12, initc-loss 3.8942e+05                    bc_loss 8.4080e+06, Test-Loss 2.6551e+05\n",
      "Epoch 3350, Training-Loss 2.7284e+05, Data-loss 2.6723e+05                  , pde-loss 1.3707e-12, initc-loss 3.8841e+05                    bc_loss 8.3417e+06, Test-Loss 2.6723e+05\n",
      "Epoch 3360, Training-Loss 2.6530e+05, Data-loss 2.6754e+05                  , pde-loss 1.4247e-12, initc-loss 3.8740e+05                    bc_loss 8.2757e+06, Test-Loss 2.6754e+05\n",
      "Epoch 3370, Training-Loss 2.6681e+05, Data-loss 2.5843e+05                  , pde-loss 1.4427e-12, initc-loss 3.8639e+05                    bc_loss 8.2098e+06, Test-Loss 2.5843e+05\n",
      "Epoch 3380, Training-Loss 2.6313e+05, Data-loss 2.6139e+05                  , pde-loss 1.4610e-12, initc-loss 3.8539e+05                    bc_loss 8.1444e+06, Test-Loss 2.6139e+05\n",
      "Epoch 3390, Training-Loss 2.6192e+05, Data-loss 2.6256e+05                  , pde-loss 1.4172e-12, initc-loss 3.8438e+05                    bc_loss 8.0792e+06, Test-Loss 2.6256e+05\n",
      "Epoch 3400, Training-Loss 2.6647e+05, Data-loss 2.5940e+05                  , pde-loss 1.3245e-12, initc-loss 3.8338e+05                    bc_loss 8.0143e+06, Test-Loss 2.5940e+05\n",
      "Epoch 3410, Training-Loss 2.6473e+05, Data-loss 2.6344e+05                  , pde-loss 1.3227e-12, initc-loss 3.8238e+05                    bc_loss 7.9497e+06, Test-Loss 2.6344e+05\n",
      "Epoch 3420, Training-Loss 2.6281e+05, Data-loss 2.5698e+05                  , pde-loss 1.3932e-12, initc-loss 3.8138e+05                    bc_loss 7.8854e+06, Test-Loss 2.5698e+05\n",
      "Epoch 3430, Training-Loss 2.5956e+05, Data-loss 2.5667e+05                  , pde-loss 1.3590e-12, initc-loss 3.8038e+05                    bc_loss 7.8213e+06, Test-Loss 2.5667e+05\n",
      "Epoch 3440, Training-Loss 2.5436e+05, Data-loss 2.4841e+05                  , pde-loss 1.3937e-12, initc-loss 3.7939e+05                    bc_loss 7.7574e+06, Test-Loss 2.4841e+05\n",
      "Epoch 3450, Training-Loss 2.5789e+05, Data-loss 2.5222e+05                  , pde-loss 1.2840e-12, initc-loss 3.7839e+05                    bc_loss 7.6939e+06, Test-Loss 2.5222e+05\n",
      "Epoch 3460, Training-Loss 2.5686e+05, Data-loss 2.5246e+05                  , pde-loss 1.2663e-12, initc-loss 3.7740e+05                    bc_loss 7.6307e+06, Test-Loss 2.5246e+05\n",
      "Epoch 3470, Training-Loss 2.5465e+05, Data-loss 2.5911e+05                  , pde-loss 1.2239e-12, initc-loss 3.7641e+05                    bc_loss 7.5678e+06, Test-Loss 2.5911e+05\n",
      "Epoch 3480, Training-Loss 2.4965e+05, Data-loss 2.4981e+05                  , pde-loss 1.2250e-12, initc-loss 3.7542e+05                    bc_loss 7.5052e+06, Test-Loss 2.4981e+05\n",
      "Epoch 3490, Training-Loss 2.6019e+05, Data-loss 2.5754e+05                  , pde-loss 1.1614e-12, initc-loss 3.7444e+05                    bc_loss 7.4430e+06, Test-Loss 2.5754e+05\n",
      "Epoch 3500, Training-Loss 2.5920e+05, Data-loss 2.5376e+05                  , pde-loss 1.1890e-12, initc-loss 3.7345e+05                    bc_loss 7.3809e+06, Test-Loss 2.5376e+05\n",
      "Epoch 3510, Training-Loss 2.4718e+05, Data-loss 2.5241e+05                  , pde-loss 1.3105e-12, initc-loss 3.7247e+05                    bc_loss 7.3191e+06, Test-Loss 2.5241e+05\n",
      "Epoch 3520, Training-Loss 2.5221e+05, Data-loss 2.5032e+05                  , pde-loss 1.2053e-12, initc-loss 3.7148e+05                    bc_loss 7.2576e+06, Test-Loss 2.5032e+05\n",
      "Epoch 3530, Training-Loss 2.4681e+05, Data-loss 2.4478e+05                  , pde-loss 1.2946e-12, initc-loss 3.7050e+05                    bc_loss 7.1963e+06, Test-Loss 2.4478e+05\n",
      "Epoch 3540, Training-Loss 2.4487e+05, Data-loss 2.5227e+05                  , pde-loss 1.3241e-12, initc-loss 3.6952e+05                    bc_loss 7.1354e+06, Test-Loss 2.5227e+05\n",
      "Epoch 3550, Training-Loss 2.4767e+05, Data-loss 2.4642e+05                  , pde-loss 1.2531e-12, initc-loss 3.6855e+05                    bc_loss 7.0749e+06, Test-Loss 2.4642e+05\n",
      "Epoch 3560, Training-Loss 2.4394e+05, Data-loss 2.4369e+05                  , pde-loss 1.2458e-12, initc-loss 3.6757e+05                    bc_loss 7.0146e+06, Test-Loss 2.4369e+05\n",
      "Epoch 3570, Training-Loss 2.4379e+05, Data-loss 2.5175e+05                  , pde-loss 1.1917e-12, initc-loss 3.6660e+05                    bc_loss 6.9546e+06, Test-Loss 2.5175e+05\n",
      "Epoch 3580, Training-Loss 2.4336e+05, Data-loss 2.4106e+05                  , pde-loss 1.1455e-12, initc-loss 3.6563e+05                    bc_loss 6.8949e+06, Test-Loss 2.4106e+05\n",
      "Epoch 3590, Training-Loss 2.4376e+05, Data-loss 2.5235e+05                  , pde-loss 1.1311e-12, initc-loss 3.6466e+05                    bc_loss 6.8354e+06, Test-Loss 2.5235e+05\n",
      "Epoch 3600, Training-Loss 2.4997e+05, Data-loss 2.4520e+05                  , pde-loss 1.0172e-12, initc-loss 3.6369e+05                    bc_loss 6.7761e+06, Test-Loss 2.4520e+05\n",
      "Epoch 3610, Training-Loss 2.4000e+05, Data-loss 2.4279e+05                  , pde-loss 1.0671e-12, initc-loss 3.6272e+05                    bc_loss 6.7170e+06, Test-Loss 2.4279e+05\n",
      "Epoch 3620, Training-Loss 2.4065e+05, Data-loss 2.4291e+05                  , pde-loss 1.0995e-12, initc-loss 3.6175e+05                    bc_loss 6.6582e+06, Test-Loss 2.4291e+05\n",
      "Epoch 3630, Training-Loss 2.4306e+05, Data-loss 2.3887e+05                  , pde-loss 1.0300e-12, initc-loss 3.6079e+05                    bc_loss 6.5998e+06, Test-Loss 2.3887e+05\n",
      "Epoch 3640, Training-Loss 2.3805e+05, Data-loss 2.4372e+05                  , pde-loss 1.0893e-12, initc-loss 3.5983e+05                    bc_loss 6.5417e+06, Test-Loss 2.4372e+05\n",
      "Epoch 3650, Training-Loss 2.4142e+05, Data-loss 2.3929e+05                  , pde-loss 1.0658e-12, initc-loss 3.5886e+05                    bc_loss 6.4838e+06, Test-Loss 2.3929e+05\n",
      "Epoch 3660, Training-Loss 2.3785e+05, Data-loss 2.3810e+05                  , pde-loss 1.0120e-12, initc-loss 3.5791e+05                    bc_loss 6.4262e+06, Test-Loss 2.3810e+05\n",
      "Epoch 3670, Training-Loss 2.3932e+05, Data-loss 2.3727e+05                  , pde-loss 1.0412e-12, initc-loss 3.5695e+05                    bc_loss 6.3689e+06, Test-Loss 2.3727e+05\n",
      "Epoch 3680, Training-Loss 2.3941e+05, Data-loss 2.3507e+05                  , pde-loss 9.8721e-13, initc-loss 3.5599e+05                    bc_loss 6.3119e+06, Test-Loss 2.3507e+05\n",
      "Epoch 3690, Training-Loss 2.4038e+05, Data-loss 2.3646e+05                  , pde-loss 9.3013e-13, initc-loss 3.5503e+05                    bc_loss 6.2550e+06, Test-Loss 2.3646e+05\n",
      "Epoch 3700, Training-Loss 2.3873e+05, Data-loss 2.3690e+05                  , pde-loss 8.9317e-13, initc-loss 3.5408e+05                    bc_loss 6.1985e+06, Test-Loss 2.3690e+05\n",
      "Epoch 3710, Training-Loss 2.3792e+05, Data-loss 2.3075e+05                  , pde-loss 9.3089e-13, initc-loss 3.5313e+05                    bc_loss 6.1422e+06, Test-Loss 2.3075e+05\n",
      "Epoch 3720, Training-Loss 2.3420e+05, Data-loss 2.4002e+05                  , pde-loss 9.1680e-13, initc-loss 3.5218e+05                    bc_loss 6.0863e+06, Test-Loss 2.4002e+05\n",
      "Epoch 3730, Training-Loss 2.3039e+05, Data-loss 2.3695e+05                  , pde-loss 9.6261e-13, initc-loss 3.5123e+05                    bc_loss 6.0306e+06, Test-Loss 2.3695e+05\n",
      "Epoch 3740, Training-Loss 2.3645e+05, Data-loss 2.3424e+05                  , pde-loss 9.5351e-13, initc-loss 3.5028e+05                    bc_loss 5.9753e+06, Test-Loss 2.3424e+05\n",
      "Epoch 3750, Training-Loss 2.3109e+05, Data-loss 2.3179e+05                  , pde-loss 9.3352e-13, initc-loss 3.4934e+05                    bc_loss 5.9202e+06, Test-Loss 2.3179e+05\n",
      "Epoch 3760, Training-Loss 2.3803e+05, Data-loss 2.2944e+05                  , pde-loss 8.2993e-13, initc-loss 3.4840e+05                    bc_loss 5.8655e+06, Test-Loss 2.2944e+05\n",
      "Epoch 3770, Training-Loss 2.3115e+05, Data-loss 2.2873e+05                  , pde-loss 8.8889e-13, initc-loss 3.4745e+05                    bc_loss 5.8108e+06, Test-Loss 2.2873e+05\n",
      "Epoch 3780, Training-Loss 2.3444e+05, Data-loss 2.3270e+05                  , pde-loss 8.9671e-13, initc-loss 3.4651e+05                    bc_loss 5.7564e+06, Test-Loss 2.3270e+05\n",
      "Epoch 3790, Training-Loss 2.3900e+05, Data-loss 2.2900e+05                  , pde-loss 7.8014e-13, initc-loss 3.4557e+05                    bc_loss 5.7022e+06, Test-Loss 2.2900e+05\n",
      "Epoch 3800, Training-Loss 2.2848e+05, Data-loss 2.2174e+05                  , pde-loss 8.3730e-13, initc-loss 3.4463e+05                    bc_loss 5.6484e+06, Test-Loss 2.2174e+05\n",
      "Epoch 3810, Training-Loss 2.2656e+05, Data-loss 2.2825e+05                  , pde-loss 9.1612e-13, initc-loss 3.4370e+05                    bc_loss 5.5949e+06, Test-Loss 2.2825e+05\n",
      "Epoch 3820, Training-Loss 2.2899e+05, Data-loss 2.2376e+05                  , pde-loss 8.6245e-13, initc-loss 3.4276e+05                    bc_loss 5.5416e+06, Test-Loss 2.2376e+05\n",
      "Epoch 3830, Training-Loss 2.2467e+05, Data-loss 2.2415e+05                  , pde-loss 8.2603e-13, initc-loss 3.4183e+05                    bc_loss 5.4886e+06, Test-Loss 2.2415e+05\n",
      "Epoch 3840, Training-Loss 2.2722e+05, Data-loss 2.2038e+05                  , pde-loss 8.4643e-13, initc-loss 3.4090e+05                    bc_loss 5.4360e+06, Test-Loss 2.2038e+05\n",
      "Epoch 3850, Training-Loss 2.3227e+05, Data-loss 2.2684e+05                  , pde-loss 7.9656e-13, initc-loss 3.3997e+05                    bc_loss 5.3837e+06, Test-Loss 2.2684e+05\n",
      "Epoch 3860, Training-Loss 2.2703e+05, Data-loss 2.1861e+05                  , pde-loss 7.8115e-13, initc-loss 3.3904e+05                    bc_loss 5.3315e+06, Test-Loss 2.1861e+05\n",
      "Epoch 3870, Training-Loss 2.2672e+05, Data-loss 2.2669e+05                  , pde-loss 7.6832e-13, initc-loss 3.3811e+05                    bc_loss 5.2796e+06, Test-Loss 2.2669e+05\n",
      "Epoch 3880, Training-Loss 2.2168e+05, Data-loss 2.2194e+05                  , pde-loss 7.5399e-13, initc-loss 3.3719e+05                    bc_loss 5.2280e+06, Test-Loss 2.2194e+05\n",
      "Epoch 3890, Training-Loss 2.2092e+05, Data-loss 2.2458e+05                  , pde-loss 7.8768e-13, initc-loss 3.3626e+05                    bc_loss 5.1766e+06, Test-Loss 2.2458e+05\n",
      "Epoch 3900, Training-Loss 2.2672e+05, Data-loss 2.2255e+05                  , pde-loss 7.7019e-13, initc-loss 3.3534e+05                    bc_loss 5.1256e+06, Test-Loss 2.2255e+05\n",
      "Epoch 3910, Training-Loss 2.2179e+05, Data-loss 2.2465e+05                  , pde-loss 7.9206e-13, initc-loss 3.3442e+05                    bc_loss 5.0747e+06, Test-Loss 2.2465e+05\n",
      "Epoch 3920, Training-Loss 2.1883e+05, Data-loss 2.2088e+05                  , pde-loss 7.5652e-13, initc-loss 3.3350e+05                    bc_loss 5.0241e+06, Test-Loss 2.2088e+05\n",
      "Epoch 3930, Training-Loss 2.2229e+05, Data-loss 2.1637e+05                  , pde-loss 7.3111e-13, initc-loss 3.3258e+05                    bc_loss 4.9739e+06, Test-Loss 2.1637e+05\n",
      "Epoch 3940, Training-Loss 2.1494e+05, Data-loss 2.1884e+05                  , pde-loss 7.7820e-13, initc-loss 3.3167e+05                    bc_loss 4.9239e+06, Test-Loss 2.1884e+05\n",
      "Epoch 3950, Training-Loss 2.1400e+05, Data-loss 2.1653e+05                  , pde-loss 7.9501e-13, initc-loss 3.3075e+05                    bc_loss 4.8742e+06, Test-Loss 2.1653e+05\n",
      "Epoch 3960, Training-Loss 2.1466e+05, Data-loss 2.1679e+05                  , pde-loss 7.1431e-13, initc-loss 3.2984e+05                    bc_loss 4.8247e+06, Test-Loss 2.1679e+05\n",
      "Epoch 3970, Training-Loss 2.1566e+05, Data-loss 2.1386e+05                  , pde-loss 7.4250e-13, initc-loss 3.2893e+05                    bc_loss 4.7756e+06, Test-Loss 2.1386e+05\n",
      "Epoch 3980, Training-Loss 2.0938e+05, Data-loss 2.1279e+05                  , pde-loss 7.6015e-13, initc-loss 3.2802e+05                    bc_loss 4.7267e+06, Test-Loss 2.1279e+05\n",
      "Epoch 3990, Training-Loss 2.1678e+05, Data-loss 2.1371e+05                  , pde-loss 7.2862e-13, initc-loss 3.2712e+05                    bc_loss 4.6781e+06, Test-Loss 2.1371e+05\n",
      "Epoch 4000, Training-Loss 2.1859e+05, Data-loss 2.1264e+05                  , pde-loss 7.0653e-13, initc-loss 3.2621e+05                    bc_loss 4.6298e+06, Test-Loss 2.1264e+05\n",
      "Epoch 4010, Training-Loss 2.1372e+05, Data-loss 2.1386e+05                  , pde-loss 7.4388e-13, initc-loss 3.2530e+05                    bc_loss 4.5816e+06, Test-Loss 2.1386e+05\n",
      "Epoch 4020, Training-Loss 2.1556e+05, Data-loss 2.1270e+05                  , pde-loss 6.7749e-13, initc-loss 3.2440e+05                    bc_loss 4.5338e+06, Test-Loss 2.1270e+05\n",
      "Epoch 4030, Training-Loss 2.0896e+05, Data-loss 2.0867e+05                  , pde-loss 6.9898e-13, initc-loss 3.2350e+05                    bc_loss 4.4862e+06, Test-Loss 2.0867e+05\n",
      "Epoch 4040, Training-Loss 2.1607e+05, Data-loss 2.0622e+05                  , pde-loss 6.0705e-13, initc-loss 3.2260e+05                    bc_loss 4.4389e+06, Test-Loss 2.0622e+05\n",
      "Epoch 4050, Training-Loss 2.1003e+05, Data-loss 2.0693e+05                  , pde-loss 6.9180e-13, initc-loss 3.2170e+05                    bc_loss 4.3919e+06, Test-Loss 2.0693e+05\n",
      "Epoch 4060, Training-Loss 2.1435e+05, Data-loss 2.0478e+05                  , pde-loss 5.7679e-13, initc-loss 3.2081e+05                    bc_loss 4.3452e+06, Test-Loss 2.0478e+05\n",
      "Epoch 4070, Training-Loss 2.0606e+05, Data-loss 2.0861e+05                  , pde-loss 6.0355e-13, initc-loss 3.1991e+05                    bc_loss 4.2986e+06, Test-Loss 2.0861e+05\n",
      "Epoch 4080, Training-Loss 2.0338e+05, Data-loss 2.1415e+05                  , pde-loss 6.3574e-13, initc-loss 3.1902e+05                    bc_loss 4.2524e+06, Test-Loss 2.1415e+05\n",
      "Epoch 4090, Training-Loss 2.1445e+05, Data-loss 2.1307e+05                  , pde-loss 5.6587e-13, initc-loss 3.1813e+05                    bc_loss 4.2065e+06, Test-Loss 2.1307e+05\n",
      "Epoch 4100, Training-Loss 2.0468e+05, Data-loss 2.0977e+05                  , pde-loss 5.6890e-13, initc-loss 3.1724e+05                    bc_loss 4.1608e+06, Test-Loss 2.0977e+05\n",
      "Epoch 4110, Training-Loss 2.0405e+05, Data-loss 2.0983e+05                  , pde-loss 6.2321e-13, initc-loss 3.1635e+05                    bc_loss 4.1154e+06, Test-Loss 2.0983e+05\n",
      "Epoch 4120, Training-Loss 2.0162e+05, Data-loss 2.0573e+05                  , pde-loss 6.0519e-13, initc-loss 3.1546e+05                    bc_loss 4.0702e+06, Test-Loss 2.0573e+05\n",
      "Epoch 4130, Training-Loss 2.0323e+05, Data-loss 2.0501e+05                  , pde-loss 5.8830e-13, initc-loss 3.1457e+05                    bc_loss 4.0253e+06, Test-Loss 2.0501e+05\n",
      "Epoch 4140, Training-Loss 2.0936e+05, Data-loss 1.9701e+05                  , pde-loss 5.1473e-13, initc-loss 3.1369e+05                    bc_loss 3.9807e+06, Test-Loss 1.9701e+05\n",
      "Epoch 4150, Training-Loss 2.0545e+05, Data-loss 2.0489e+05                  , pde-loss 5.5117e-13, initc-loss 3.1280e+05                    bc_loss 3.9362e+06, Test-Loss 2.0489e+05\n",
      "Epoch 4160, Training-Loss 2.0218e+05, Data-loss 2.0513e+05                  , pde-loss 6.1117e-13, initc-loss 3.1192e+05                    bc_loss 3.8920e+06, Test-Loss 2.0513e+05\n",
      "Epoch 4170, Training-Loss 2.0473e+05, Data-loss 2.0834e+05                  , pde-loss 5.8694e-13, initc-loss 3.1104e+05                    bc_loss 3.8481e+06, Test-Loss 2.0834e+05\n",
      "Epoch 4180, Training-Loss 1.9797e+05, Data-loss 1.9912e+05                  , pde-loss 6.1528e-13, initc-loss 3.1016e+05                    bc_loss 3.8045e+06, Test-Loss 1.9912e+05\n",
      "Epoch 4190, Training-Loss 1.9734e+05, Data-loss 2.0270e+05                  , pde-loss 6.1909e-13, initc-loss 3.0928e+05                    bc_loss 3.7611e+06, Test-Loss 2.0270e+05\n",
      "Epoch 4200, Training-Loss 2.0370e+05, Data-loss 1.9572e+05                  , pde-loss 5.4659e-13, initc-loss 3.0841e+05                    bc_loss 3.7181e+06, Test-Loss 1.9572e+05\n",
      "Epoch 4210, Training-Loss 1.9258e+05, Data-loss 1.9879e+05                  , pde-loss 5.9441e-13, initc-loss 3.0754e+05                    bc_loss 3.6753e+06, Test-Loss 1.9879e+05\n",
      "Epoch 4220, Training-Loss 1.9977e+05, Data-loss 2.0028e+05                  , pde-loss 5.7398e-13, initc-loss 3.0667e+05                    bc_loss 3.6329e+06, Test-Loss 2.0028e+05\n",
      "Epoch 4230, Training-Loss 2.0112e+05, Data-loss 1.9843e+05                  , pde-loss 5.5057e-13, initc-loss 3.0580e+05                    bc_loss 3.5908e+06, Test-Loss 1.9843e+05\n",
      "Epoch 4240, Training-Loss 1.9889e+05, Data-loss 1.9406e+05                  , pde-loss 5.7160e-13, initc-loss 3.0493e+05                    bc_loss 3.5489e+06, Test-Loss 1.9406e+05\n",
      "Epoch 4250, Training-Loss 1.9887e+05, Data-loss 1.9512e+05                  , pde-loss 5.7331e-13, initc-loss 3.0407e+05                    bc_loss 3.5071e+06, Test-Loss 1.9512e+05\n",
      "Epoch 4260, Training-Loss 1.9396e+05, Data-loss 1.9742e+05                  , pde-loss 5.6601e-13, initc-loss 3.0320e+05                    bc_loss 3.4657e+06, Test-Loss 1.9742e+05\n",
      "Epoch 4270, Training-Loss 1.9249e+05, Data-loss 1.9394e+05                  , pde-loss 5.8627e-13, initc-loss 3.0234e+05                    bc_loss 3.4244e+06, Test-Loss 1.9394e+05\n",
      "Epoch 4280, Training-Loss 1.9585e+05, Data-loss 1.9220e+05                  , pde-loss 5.1239e-13, initc-loss 3.0148e+05                    bc_loss 3.3835e+06, Test-Loss 1.9220e+05\n",
      "Epoch 4290, Training-Loss 1.9569e+05, Data-loss 1.9514e+05                  , pde-loss 5.0329e-13, initc-loss 3.0061e+05                    bc_loss 3.3428e+06, Test-Loss 1.9514e+05\n",
      "Epoch 4300, Training-Loss 1.9315e+05, Data-loss 1.8995e+05                  , pde-loss 5.0621e-13, initc-loss 2.9976e+05                    bc_loss 3.3025e+06, Test-Loss 1.8995e+05\n",
      "Epoch 4310, Training-Loss 1.9549e+05, Data-loss 1.9237e+05                  , pde-loss 4.8239e-13, initc-loss 2.9890e+05                    bc_loss 3.2624e+06, Test-Loss 1.9237e+05\n",
      "Epoch 4320, Training-Loss 1.9055e+05, Data-loss 1.8955e+05                  , pde-loss 4.9949e-13, initc-loss 2.9804e+05                    bc_loss 3.2225e+06, Test-Loss 1.8955e+05\n",
      "Epoch 4330, Training-Loss 1.9350e+05, Data-loss 1.9170e+05                  , pde-loss 5.1065e-13, initc-loss 2.9719e+05                    bc_loss 3.1827e+06, Test-Loss 1.9170e+05\n",
      "Epoch 4340, Training-Loss 1.8971e+05, Data-loss 1.9345e+05                  , pde-loss 5.0929e-13, initc-loss 2.9633e+05                    bc_loss 3.1433e+06, Test-Loss 1.9345e+05\n",
      "Epoch 4350, Training-Loss 1.8969e+05, Data-loss 1.9131e+05                  , pde-loss 4.8219e-13, initc-loss 2.9548e+05                    bc_loss 3.1041e+06, Test-Loss 1.9131e+05\n",
      "Epoch 4360, Training-Loss 1.8761e+05, Data-loss 1.8847e+05                  , pde-loss 5.0563e-13, initc-loss 2.9463e+05                    bc_loss 3.0652e+06, Test-Loss 1.8847e+05\n",
      "Epoch 4370, Training-Loss 1.8880e+05, Data-loss 1.8769e+05                  , pde-loss 4.8074e-13, initc-loss 2.9378e+05                    bc_loss 3.0266e+06, Test-Loss 1.8769e+05\n",
      "Epoch 4380, Training-Loss 1.8647e+05, Data-loss 1.8364e+05                  , pde-loss 4.7812e-13, initc-loss 2.9293e+05                    bc_loss 2.9882e+06, Test-Loss 1.8364e+05\n",
      "Epoch 4390, Training-Loss 1.8800e+05, Data-loss 1.8542e+05                  , pde-loss 4.3853e-13, initc-loss 2.9209e+05                    bc_loss 2.9500e+06, Test-Loss 1.8542e+05\n",
      "Epoch 4400, Training-Loss 1.8395e+05, Data-loss 1.8599e+05                  , pde-loss 4.3337e-13, initc-loss 2.9124e+05                    bc_loss 2.9121e+06, Test-Loss 1.8599e+05\n",
      "Epoch 4410, Training-Loss 1.8074e+05, Data-loss 1.8578e+05                  , pde-loss 4.5721e-13, initc-loss 2.9040e+05                    bc_loss 2.8745e+06, Test-Loss 1.8578e+05\n",
      "Epoch 4420, Training-Loss 1.8727e+05, Data-loss 1.8360e+05                  , pde-loss 4.0097e-13, initc-loss 2.8956e+05                    bc_loss 2.8372e+06, Test-Loss 1.8360e+05\n",
      "Epoch 4430, Training-Loss 1.8258e+05, Data-loss 1.8370e+05                  , pde-loss 4.4424e-13, initc-loss 2.8872e+05                    bc_loss 2.8001e+06, Test-Loss 1.8370e+05\n",
      "Epoch 4440, Training-Loss 1.8216e+05, Data-loss 1.8637e+05                  , pde-loss 4.3438e-13, initc-loss 2.8788e+05                    bc_loss 2.7633e+06, Test-Loss 1.8637e+05\n",
      "Epoch 4450, Training-Loss 1.8074e+05, Data-loss 1.8136e+05                  , pde-loss 4.3531e-13, initc-loss 2.8704e+05                    bc_loss 2.7266e+06, Test-Loss 1.8136e+05\n",
      "Epoch 4460, Training-Loss 1.8963e+05, Data-loss 1.8103e+05                  , pde-loss 3.8515e-13, initc-loss 2.8620e+05                    bc_loss 2.6903e+06, Test-Loss 1.8103e+05\n",
      "Epoch 4470, Training-Loss 1.8446e+05, Data-loss 1.7747e+05                  , pde-loss 4.0184e-13, initc-loss 2.8537e+05                    bc_loss 2.6543e+06, Test-Loss 1.7747e+05\n",
      "Epoch 4480, Training-Loss 1.8339e+05, Data-loss 1.7517e+05                  , pde-loss 3.9619e-13, initc-loss 2.8454e+05                    bc_loss 2.6185e+06, Test-Loss 1.7517e+05\n",
      "Epoch 4490, Training-Loss 1.8276e+05, Data-loss 1.7738e+05                  , pde-loss 3.7983e-13, initc-loss 2.8371e+05                    bc_loss 2.5830e+06, Test-Loss 1.7738e+05\n",
      "Epoch 4500, Training-Loss 1.7726e+05, Data-loss 1.7906e+05                  , pde-loss 3.9729e-13, initc-loss 2.8288e+05                    bc_loss 2.5477e+06, Test-Loss 1.7906e+05\n",
      "Epoch 4510, Training-Loss 1.7937e+05, Data-loss 1.7889e+05                  , pde-loss 4.1020e-13, initc-loss 2.8205e+05                    bc_loss 2.5126e+06, Test-Loss 1.7889e+05\n",
      "Epoch 4520, Training-Loss 1.7722e+05, Data-loss 1.7920e+05                  , pde-loss 3.9259e-13, initc-loss 2.8123e+05                    bc_loss 2.4779e+06, Test-Loss 1.7920e+05\n",
      "Epoch 4530, Training-Loss 1.7461e+05, Data-loss 1.8211e+05                  , pde-loss 4.1658e-13, initc-loss 2.8040e+05                    bc_loss 2.4433e+06, Test-Loss 1.8211e+05\n",
      "Epoch 4540, Training-Loss 1.7878e+05, Data-loss 1.7265e+05                  , pde-loss 4.1555e-13, initc-loss 2.7958e+05                    bc_loss 2.4091e+06, Test-Loss 1.7265e+05\n",
      "Epoch 4550, Training-Loss 1.8022e+05, Data-loss 1.7178e+05                  , pde-loss 3.8181e-13, initc-loss 2.7876e+05                    bc_loss 2.3751e+06, Test-Loss 1.7178e+05\n",
      "Epoch 4560, Training-Loss 1.7791e+05, Data-loss 1.7504e+05                  , pde-loss 3.6125e-13, initc-loss 2.7793e+05                    bc_loss 2.3412e+06, Test-Loss 1.7504e+05\n",
      "Epoch 4570, Training-Loss 1.7399e+05, Data-loss 1.7675e+05                  , pde-loss 3.6820e-13, initc-loss 2.7711e+05                    bc_loss 2.3077e+06, Test-Loss 1.7675e+05\n",
      "Epoch 4580, Training-Loss 1.6936e+05, Data-loss 1.7277e+05                  , pde-loss 3.8379e-13, initc-loss 2.7630e+05                    bc_loss 2.2744e+06, Test-Loss 1.7277e+05\n",
      "Epoch 4590, Training-Loss 1.7360e+05, Data-loss 1.7005e+05                  , pde-loss 3.5253e-13, initc-loss 2.7548e+05                    bc_loss 2.2415e+06, Test-Loss 1.7005e+05\n",
      "Epoch 4600, Training-Loss 1.7035e+05, Data-loss 1.7066e+05                  , pde-loss 3.5974e-13, initc-loss 2.7467e+05                    bc_loss 2.2087e+06, Test-Loss 1.7066e+05\n",
      "Epoch 4610, Training-Loss 1.7342e+05, Data-loss 1.7109e+05                  , pde-loss 3.6463e-13, initc-loss 2.7386e+05                    bc_loss 2.1762e+06, Test-Loss 1.7109e+05\n",
      "Epoch 4620, Training-Loss 1.7545e+05, Data-loss 1.6515e+05                  , pde-loss 3.3684e-13, initc-loss 2.7304e+05                    bc_loss 2.1440e+06, Test-Loss 1.6515e+05\n",
      "Epoch 4630, Training-Loss 1.7155e+05, Data-loss 1.7146e+05                  , pde-loss 3.4669e-13, initc-loss 2.7223e+05                    bc_loss 2.1119e+06, Test-Loss 1.7146e+05\n",
      "Epoch 4640, Training-Loss 1.7199e+05, Data-loss 1.6823e+05                  , pde-loss 3.4094e-13, initc-loss 2.7142e+05                    bc_loss 2.0802e+06, Test-Loss 1.6823e+05\n",
      "Epoch 4650, Training-Loss 1.6952e+05, Data-loss 1.6285e+05                  , pde-loss 3.5291e-13, initc-loss 2.7062e+05                    bc_loss 2.0487e+06, Test-Loss 1.6285e+05\n",
      "Epoch 4660, Training-Loss 1.6909e+05, Data-loss 1.6999e+05                  , pde-loss 3.4843e-13, initc-loss 2.6981e+05                    bc_loss 2.0175e+06, Test-Loss 1.6999e+05\n",
      "Epoch 4670, Training-Loss 1.6397e+05, Data-loss 1.6593e+05                  , pde-loss 3.7585e-13, initc-loss 2.6901e+05                    bc_loss 1.9865e+06, Test-Loss 1.6593e+05\n",
      "Epoch 4680, Training-Loss 1.7172e+05, Data-loss 1.6828e+05                  , pde-loss 3.2303e-13, initc-loss 2.6821e+05                    bc_loss 1.9558e+06, Test-Loss 1.6828e+05\n",
      "Epoch 4690, Training-Loss 1.6869e+05, Data-loss 1.6751e+05                  , pde-loss 3.3661e-13, initc-loss 2.6741e+05                    bc_loss 1.9254e+06, Test-Loss 1.6751e+05\n",
      "Epoch 4700, Training-Loss 1.6619e+05, Data-loss 1.6355e+05                  , pde-loss 3.4457e-13, initc-loss 2.6661e+05                    bc_loss 1.8951e+06, Test-Loss 1.6355e+05\n",
      "Epoch 4710, Training-Loss 1.6852e+05, Data-loss 1.6962e+05                  , pde-loss 3.3648e-13, initc-loss 2.6581e+05                    bc_loss 1.8651e+06, Test-Loss 1.6962e+05\n",
      "Epoch 4720, Training-Loss 1.6284e+05, Data-loss 1.6709e+05                  , pde-loss 3.5422e-13, initc-loss 2.6501e+05                    bc_loss 1.8353e+06, Test-Loss 1.6709e+05\n",
      "Epoch 4730, Training-Loss 1.6551e+05, Data-loss 1.6740e+05                  , pde-loss 3.3008e-13, initc-loss 2.6422e+05                    bc_loss 1.8057e+06, Test-Loss 1.6740e+05\n",
      "Epoch 4740, Training-Loss 1.6734e+05, Data-loss 1.6877e+05                  , pde-loss 3.2838e-13, initc-loss 2.6342e+05                    bc_loss 1.7764e+06, Test-Loss 1.6877e+05\n",
      "Epoch 4750, Training-Loss 1.6731e+05, Data-loss 1.6067e+05                  , pde-loss 3.1442e-13, initc-loss 2.6262e+05                    bc_loss 1.7473e+06, Test-Loss 1.6067e+05\n",
      "Epoch 4760, Training-Loss 1.6311e+05, Data-loss 1.6425e+05                  , pde-loss 3.1365e-13, initc-loss 2.6183e+05                    bc_loss 1.7185e+06, Test-Loss 1.6425e+05\n",
      "Epoch 4770, Training-Loss 1.6180e+05, Data-loss 1.6330e+05                  , pde-loss 3.2538e-13, initc-loss 2.6104e+05                    bc_loss 1.6900e+06, Test-Loss 1.6330e+05\n",
      "Epoch 4780, Training-Loss 1.6190e+05, Data-loss 1.6266e+05                  , pde-loss 3.0604e-13, initc-loss 2.6025e+05                    bc_loss 1.6617e+06, Test-Loss 1.6266e+05\n",
      "Epoch 4790, Training-Loss 1.5983e+05, Data-loss 1.6068e+05                  , pde-loss 3.0600e-13, initc-loss 2.5947e+05                    bc_loss 1.6336e+06, Test-Loss 1.6068e+05\n",
      "Epoch 4800, Training-Loss 1.6169e+05, Data-loss 1.5967e+05                  , pde-loss 2.8955e-13, initc-loss 2.5868e+05                    bc_loss 1.6059e+06, Test-Loss 1.5967e+05\n",
      "Epoch 4810, Training-Loss 1.5990e+05, Data-loss 1.5836e+05                  , pde-loss 3.0162e-13, initc-loss 2.5790e+05                    bc_loss 1.5785e+06, Test-Loss 1.5836e+05\n",
      "Epoch 4820, Training-Loss 1.5749e+05, Data-loss 1.5628e+05                  , pde-loss 3.0685e-13, initc-loss 2.5712e+05                    bc_loss 1.5512e+06, Test-Loss 1.5628e+05\n",
      "Epoch 4830, Training-Loss 1.6175e+05, Data-loss 1.5854e+05                  , pde-loss 2.8180e-13, initc-loss 2.5634e+05                    bc_loss 1.5242e+06, Test-Loss 1.5854e+05\n",
      "Epoch 4840, Training-Loss 1.5693e+05, Data-loss 1.6223e+05                  , pde-loss 2.9470e-13, initc-loss 2.5556e+05                    bc_loss 1.4975e+06, Test-Loss 1.6223e+05\n",
      "Epoch 4850, Training-Loss 1.5714e+05, Data-loss 1.5624e+05                  , pde-loss 3.0422e-13, initc-loss 2.5478e+05                    bc_loss 1.4710e+06, Test-Loss 1.5624e+05\n",
      "Epoch 4860, Training-Loss 1.5823e+05, Data-loss 1.5368e+05                  , pde-loss 3.0624e-13, initc-loss 2.5401e+05                    bc_loss 1.4447e+06, Test-Loss 1.5368e+05\n",
      "Epoch 4870, Training-Loss 1.5495e+05, Data-loss 1.5053e+05                  , pde-loss 2.8759e-13, initc-loss 2.5323e+05                    bc_loss 1.4186e+06, Test-Loss 1.5053e+05\n",
      "Epoch 4880, Training-Loss 1.5467e+05, Data-loss 1.5340e+05                  , pde-loss 2.9012e-13, initc-loss 2.5246e+05                    bc_loss 1.3928e+06, Test-Loss 1.5340e+05\n",
      "Epoch 4890, Training-Loss 1.5675e+05, Data-loss 1.5630e+05                  , pde-loss 3.0008e-13, initc-loss 2.5168e+05                    bc_loss 1.3672e+06, Test-Loss 1.5630e+05\n",
      "Epoch 4900, Training-Loss 1.4803e+05, Data-loss 1.5222e+05                  , pde-loss 3.1533e-13, initc-loss 2.5091e+05                    bc_loss 1.3419e+06, Test-Loss 1.5222e+05\n",
      "Epoch 4910, Training-Loss 1.4891e+05, Data-loss 1.5298e+05                  , pde-loss 2.9798e-13, initc-loss 2.5014e+05                    bc_loss 1.3168e+06, Test-Loss 1.5298e+05\n",
      "Epoch 4920, Training-Loss 1.4944e+05, Data-loss 1.4938e+05                  , pde-loss 2.8870e-13, initc-loss 2.4938e+05                    bc_loss 1.2920e+06, Test-Loss 1.4938e+05\n",
      "Epoch 4930, Training-Loss 1.4877e+05, Data-loss 1.5395e+05                  , pde-loss 2.8733e-13, initc-loss 2.4861e+05                    bc_loss 1.2675e+06, Test-Loss 1.5395e+05\n",
      "Epoch 4940, Training-Loss 1.5501e+05, Data-loss 1.4810e+05                  , pde-loss 2.5596e-13, initc-loss 2.4785e+05                    bc_loss 1.2433e+06, Test-Loss 1.4810e+05\n",
      "Epoch 4950, Training-Loss 1.4948e+05, Data-loss 1.4882e+05                  , pde-loss 2.6283e-13, initc-loss 2.4709e+05                    bc_loss 1.2192e+06, Test-Loss 1.4882e+05\n",
      "Epoch 4960, Training-Loss 1.5149e+05, Data-loss 1.5054e+05                  , pde-loss 2.3249e-13, initc-loss 2.4632e+05                    bc_loss 1.1954e+06, Test-Loss 1.5054e+05\n",
      "Epoch 4970, Training-Loss 1.4913e+05, Data-loss 1.4203e+05                  , pde-loss 2.3758e-13, initc-loss 2.4557e+05                    bc_loss 1.1718e+06, Test-Loss 1.4203e+05\n",
      "Epoch 4980, Training-Loss 1.4704e+05, Data-loss 1.4882e+05                  , pde-loss 2.5741e-13, initc-loss 2.4481e+05                    bc_loss 1.1485e+06, Test-Loss 1.4882e+05\n",
      "Epoch 4990, Training-Loss 1.4952e+05, Data-loss 1.4916e+05                  , pde-loss 2.3485e-13, initc-loss 2.4405e+05                    bc_loss 1.1255e+06, Test-Loss 1.4916e+05\n",
      "Epoch 5000, Training-Loss 1.4723e+05, Data-loss 1.5133e+05                  , pde-loss 2.3876e-13, initc-loss 2.4330e+05                    bc_loss 1.1026e+06, Test-Loss 1.5133e+05\n",
      "Epoch 5010, Training-Loss 1.5301e+05, Data-loss 1.4664e+05                  , pde-loss 2.1270e-13, initc-loss 2.4254e+05                    bc_loss 1.0800e+06, Test-Loss 1.4664e+05\n",
      "Epoch 5020, Training-Loss 1.4225e+05, Data-loss 1.4784e+05                  , pde-loss 2.4764e-13, initc-loss 2.4179e+05                    bc_loss 1.0576e+06, Test-Loss 1.4784e+05\n",
      "Epoch 5030, Training-Loss 1.4414e+05, Data-loss 1.4369e+05                  , pde-loss 2.4781e-13, initc-loss 2.4103e+05                    bc_loss 1.0354e+06, Test-Loss 1.4369e+05\n",
      "Epoch 5040, Training-Loss 1.4424e+05, Data-loss 1.4497e+05                  , pde-loss 2.3844e-13, initc-loss 2.4028e+05                    bc_loss 1.0135e+06, Test-Loss 1.4497e+05\n",
      "Epoch 5050, Training-Loss 1.4546e+05, Data-loss 1.4777e+05                  , pde-loss 2.4036e-13, initc-loss 2.3954e+05                    bc_loss 9.9191e+05, Test-Loss 1.4777e+05\n",
      "Epoch 5060, Training-Loss 1.4586e+05, Data-loss 1.4117e+05                  , pde-loss 2.3630e-13, initc-loss 2.3879e+05                    bc_loss 9.7056e+05, Test-Loss 1.4117e+05\n",
      "Epoch 5070, Training-Loss 1.4643e+05, Data-loss 1.4521e+05                  , pde-loss 2.2065e-13, initc-loss 2.3805e+05                    bc_loss 9.4948e+05, Test-Loss 1.4521e+05\n",
      "Epoch 5080, Training-Loss 1.4462e+05, Data-loss 1.4561e+05                  , pde-loss 2.3925e-13, initc-loss 2.3730e+05                    bc_loss 9.2855e+05, Test-Loss 1.4561e+05\n",
      "Epoch 5090, Training-Loss 1.4125e+05, Data-loss 1.3914e+05                  , pde-loss 2.4558e-13, initc-loss 2.3656e+05                    bc_loss 9.0785e+05, Test-Loss 1.3914e+05\n",
      "Epoch 5100, Training-Loss 1.4254e+05, Data-loss 1.4255e+05                  , pde-loss 2.4523e-13, initc-loss 2.3582e+05                    bc_loss 8.8739e+05, Test-Loss 1.4255e+05\n",
      "Epoch 5110, Training-Loss 1.4097e+05, Data-loss 1.3827e+05                  , pde-loss 2.5236e-13, initc-loss 2.3508e+05                    bc_loss 8.6720e+05, Test-Loss 1.3827e+05\n",
      "Epoch 5120, Training-Loss 1.4181e+05, Data-loss 1.3639e+05                  , pde-loss 2.3269e-13, initc-loss 2.3434e+05                    bc_loss 8.4731e+05, Test-Loss 1.3639e+05\n",
      "Epoch 5130, Training-Loss 1.3993e+05, Data-loss 1.3679e+05                  , pde-loss 2.2860e-13, initc-loss 2.3361e+05                    bc_loss 8.2766e+05, Test-Loss 1.3679e+05\n",
      "Epoch 5140, Training-Loss 1.4010e+05, Data-loss 1.4564e+05                  , pde-loss 2.2340e-13, initc-loss 2.3287e+05                    bc_loss 8.0819e+05, Test-Loss 1.4564e+05\n",
      "Epoch 5150, Training-Loss 1.3488e+05, Data-loss 1.4243e+05                  , pde-loss 2.2211e-13, initc-loss 2.3214e+05                    bc_loss 7.8898e+05, Test-Loss 1.4243e+05\n",
      "Epoch 5160, Training-Loss 1.3646e+05, Data-loss 1.3663e+05                  , pde-loss 2.1584e-13, initc-loss 2.3141e+05                    bc_loss 7.7003e+05, Test-Loss 1.3663e+05\n",
      "Epoch 5170, Training-Loss 1.3791e+05, Data-loss 1.3773e+05                  , pde-loss 2.0198e-13, initc-loss 2.3068e+05                    bc_loss 7.5128e+05, Test-Loss 1.3773e+05\n",
      "Epoch 5180, Training-Loss 1.3728e+05, Data-loss 1.3590e+05                  , pde-loss 2.1452e-13, initc-loss 2.2995e+05                    bc_loss 7.3277e+05, Test-Loss 1.3590e+05\n",
      "Epoch 5190, Training-Loss 1.3597e+05, Data-loss 1.4204e+05                  , pde-loss 2.1336e-13, initc-loss 2.2922e+05                    bc_loss 7.1448e+05, Test-Loss 1.4204e+05\n",
      "Epoch 5200, Training-Loss 1.3702e+05, Data-loss 1.3628e+05                  , pde-loss 2.1265e-13, initc-loss 2.2849e+05                    bc_loss 6.9644e+05, Test-Loss 1.3628e+05\n",
      "Epoch 5210, Training-Loss 1.3996e+05, Data-loss 1.3465e+05                  , pde-loss 1.9328e-13, initc-loss 2.2777e+05                    bc_loss 6.7860e+05, Test-Loss 1.3465e+05\n",
      "Epoch 5220, Training-Loss 1.3430e+05, Data-loss 1.3651e+05                  , pde-loss 2.1292e-13, initc-loss 2.2704e+05                    bc_loss 6.6102e+05, Test-Loss 1.3651e+05\n",
      "Epoch 5230, Training-Loss 1.3373e+05, Data-loss 1.4037e+05                  , pde-loss 2.1639e-13, initc-loss 2.2632e+05                    bc_loss 6.4369e+05, Test-Loss 1.4037e+05\n",
      "Epoch 5240, Training-Loss 1.3226e+05, Data-loss 1.3219e+05                  , pde-loss 2.1086e-13, initc-loss 2.2560e+05                    bc_loss 6.2653e+05, Test-Loss 1.3219e+05\n",
      "Epoch 5250, Training-Loss 1.3854e+05, Data-loss 1.3066e+05                  , pde-loss 1.8712e-13, initc-loss 2.2487e+05                    bc_loss 6.0959e+05, Test-Loss 1.3066e+05\n",
      "Epoch 5260, Training-Loss 1.3478e+05, Data-loss 1.3785e+05                  , pde-loss 2.0293e-13, initc-loss 2.2415e+05                    bc_loss 5.9287e+05, Test-Loss 1.3785e+05\n",
      "Epoch 5270, Training-Loss 1.3325e+05, Data-loss 1.3070e+05                  , pde-loss 1.9033e-13, initc-loss 2.2343e+05                    bc_loss 5.7644e+05, Test-Loss 1.3070e+05\n",
      "Epoch 5280, Training-Loss 1.3725e+05, Data-loss 1.3419e+05                  , pde-loss 1.7884e-13, initc-loss 2.2272e+05                    bc_loss 5.6029e+05, Test-Loss 1.3419e+05\n",
      "Epoch 5290, Training-Loss 1.3667e+05, Data-loss 1.2894e+05                  , pde-loss 1.7983e-13, initc-loss 2.2200e+05                    bc_loss 5.4438e+05, Test-Loss 1.2894e+05\n",
      "Epoch 5300, Training-Loss 1.3099e+05, Data-loss 1.3108e+05                  , pde-loss 1.9925e-13, initc-loss 2.2129e+05                    bc_loss 5.2866e+05, Test-Loss 1.3108e+05\n",
      "Epoch 5310, Training-Loss 1.3204e+05, Data-loss 1.2952e+05                  , pde-loss 1.8311e-13, initc-loss 2.2058e+05                    bc_loss 5.1321e+05, Test-Loss 1.2952e+05\n",
      "Epoch 5320, Training-Loss 1.3095e+05, Data-loss 1.2674e+05                  , pde-loss 1.8910e-13, initc-loss 2.1987e+05                    bc_loss 4.9799e+05, Test-Loss 1.2674e+05\n",
      "Epoch 5330, Training-Loss 1.3364e+05, Data-loss 1.2900e+05                  , pde-loss 1.7453e-13, initc-loss 2.1916e+05                    bc_loss 4.8301e+05, Test-Loss 1.2900e+05\n",
      "Epoch 5340, Training-Loss 1.2990e+05, Data-loss 1.2869e+05                  , pde-loss 1.9218e-13, initc-loss 2.1845e+05                    bc_loss 4.6826e+05, Test-Loss 1.2869e+05\n",
      "Epoch 5350, Training-Loss 1.3464e+05, Data-loss 1.3022e+05                  , pde-loss 1.7601e-13, initc-loss 2.1775e+05                    bc_loss 4.5376e+05, Test-Loss 1.3022e+05\n",
      "Epoch 5360, Training-Loss 1.2490e+05, Data-loss 1.2916e+05                  , pde-loss 1.9545e-13, initc-loss 2.1704e+05                    bc_loss 4.3949e+05, Test-Loss 1.2916e+05\n",
      "Epoch 5370, Training-Loss 1.2287e+05, Data-loss 1.2792e+05                  , pde-loss 2.0383e-13, initc-loss 2.1634e+05                    bc_loss 4.2549e+05, Test-Loss 1.2792e+05\n",
      "Epoch 5380, Training-Loss 1.2543e+05, Data-loss 1.2663e+05                  , pde-loss 1.8689e-13, initc-loss 2.1564e+05                    bc_loss 4.1174e+05, Test-Loss 1.2663e+05\n",
      "Epoch 5390, Training-Loss 1.2565e+05, Data-loss 1.2579e+05                  , pde-loss 1.8876e-13, initc-loss 2.1494e+05                    bc_loss 3.9819e+05, Test-Loss 1.2579e+05\n",
      "Epoch 5400, Training-Loss 1.2276e+05, Data-loss 1.2474e+05                  , pde-loss 1.9864e-13, initc-loss 2.1424e+05                    bc_loss 3.8484e+05, Test-Loss 1.2474e+05\n",
      "Epoch 5410, Training-Loss 1.2204e+05, Data-loss 1.2340e+05                  , pde-loss 2.0812e-13, initc-loss 2.1355e+05                    bc_loss 3.7175e+05, Test-Loss 1.2340e+05\n",
      "Epoch 5420, Training-Loss 1.2584e+05, Data-loss 1.2609e+05                  , pde-loss 1.8743e-13, initc-loss 2.1285e+05                    bc_loss 3.5890e+05, Test-Loss 1.2609e+05\n",
      "Epoch 5430, Training-Loss 1.2579e+05, Data-loss 1.2388e+05                  , pde-loss 2.0311e-13, initc-loss 2.1216e+05                    bc_loss 3.4628e+05, Test-Loss 1.2388e+05\n",
      "Epoch 5440, Training-Loss 1.2340e+05, Data-loss 1.2392e+05                  , pde-loss 1.9657e-13, initc-loss 2.1147e+05                    bc_loss 3.3388e+05, Test-Loss 1.2392e+05\n",
      "Epoch 5450, Training-Loss 1.2643e+05, Data-loss 1.2313e+05                  , pde-loss 2.0441e-13, initc-loss 2.1078e+05                    bc_loss 3.2173e+05, Test-Loss 1.2313e+05\n",
      "Epoch 5460, Training-Loss 1.2387e+05, Data-loss 1.2135e+05                  , pde-loss 1.9239e-13, initc-loss 2.1009e+05                    bc_loss 3.0979e+05, Test-Loss 1.2135e+05\n",
      "Epoch 5470, Training-Loss 1.2640e+05, Data-loss 1.2185e+05                  , pde-loss 1.8225e-13, initc-loss 2.0940e+05                    bc_loss 2.9805e+05, Test-Loss 1.2185e+05\n",
      "Epoch 5480, Training-Loss 1.2079e+05, Data-loss 1.3151e+05                  , pde-loss 1.8562e-13, initc-loss 2.0871e+05                    bc_loss 2.8652e+05, Test-Loss 1.3151e+05\n",
      "Epoch 5490, Training-Loss 1.2198e+05, Data-loss 1.2283e+05                  , pde-loss 1.7842e-13, initc-loss 2.0803e+05                    bc_loss 2.7526e+05, Test-Loss 1.2283e+05\n",
      "Epoch 5500, Training-Loss 1.1981e+05, Data-loss 1.2069e+05                  , pde-loss 1.7279e-13, initc-loss 2.0734e+05                    bc_loss 2.6425e+05, Test-Loss 1.2069e+05\n",
      "Epoch 5510, Training-Loss 1.1770e+05, Data-loss 1.2011e+05                  , pde-loss 1.8268e-13, initc-loss 2.0666e+05                    bc_loss 2.5347e+05, Test-Loss 1.2011e+05\n",
      "Epoch 5520, Training-Loss 1.1779e+05, Data-loss 1.1944e+05                  , pde-loss 1.7902e-13, initc-loss 2.0598e+05                    bc_loss 2.4295e+05, Test-Loss 1.1944e+05\n",
      "Epoch 5530, Training-Loss 1.1518e+05, Data-loss 1.2252e+05                  , pde-loss 1.8371e-13, initc-loss 2.0531e+05                    bc_loss 2.3265e+05, Test-Loss 1.2252e+05\n",
      "Epoch 5540, Training-Loss 1.2002e+05, Data-loss 1.1692e+05                  , pde-loss 1.8572e-13, initc-loss 2.0463e+05                    bc_loss 2.2259e+05, Test-Loss 1.1692e+05\n",
      "Epoch 5550, Training-Loss 1.1747e+05, Data-loss 1.1364e+05                  , pde-loss 1.8089e-13, initc-loss 2.0395e+05                    bc_loss 2.1273e+05, Test-Loss 1.1364e+05\n",
      "Epoch 5560, Training-Loss 1.1858e+05, Data-loss 1.1508e+05                  , pde-loss 1.7898e-13, initc-loss 2.0328e+05                    bc_loss 2.0307e+05, Test-Loss 1.1508e+05\n",
      "Epoch 5570, Training-Loss 1.1549e+05, Data-loss 1.2109e+05                  , pde-loss 1.7920e-13, initc-loss 2.0260e+05                    bc_loss 1.9364e+05, Test-Loss 1.2109e+05\n",
      "Epoch 5580, Training-Loss 1.1771e+05, Data-loss 1.1550e+05                  , pde-loss 1.7615e-13, initc-loss 2.0193e+05                    bc_loss 1.8446e+05, Test-Loss 1.1550e+05\n",
      "Epoch 5590, Training-Loss 1.1622e+05, Data-loss 1.1736e+05                  , pde-loss 1.6819e-13, initc-loss 2.0126e+05                    bc_loss 1.7548e+05, Test-Loss 1.1736e+05\n",
      "Epoch 5600, Training-Loss 1.1441e+05, Data-loss 1.1444e+05                  , pde-loss 1.7854e-13, initc-loss 2.0059e+05                    bc_loss 1.6671e+05, Test-Loss 1.1444e+05\n",
      "Epoch 5610, Training-Loss 1.1530e+05, Data-loss 1.1850e+05                  , pde-loss 1.7667e-13, initc-loss 1.9992e+05                    bc_loss 1.5818e+05, Test-Loss 1.1850e+05\n",
      "Epoch 5620, Training-Loss 1.1356e+05, Data-loss 1.1507e+05                  , pde-loss 1.7403e-13, initc-loss 1.9925e+05                    bc_loss 1.4990e+05, Test-Loss 1.1507e+05\n",
      "Epoch 5630, Training-Loss 1.1073e+05, Data-loss 1.1563e+05                  , pde-loss 1.8587e-13, initc-loss 1.9859e+05                    bc_loss 1.4185e+05, Test-Loss 1.1563e+05\n",
      "Epoch 5640, Training-Loss 1.1476e+05, Data-loss 1.1427e+05                  , pde-loss 1.6836e-13, initc-loss 1.9793e+05                    bc_loss 1.3405e+05, Test-Loss 1.1427e+05\n",
      "Epoch 5650, Training-Loss 1.1049e+05, Data-loss 1.1357e+05                  , pde-loss 1.7138e-13, initc-loss 1.9726e+05                    bc_loss 1.2645e+05, Test-Loss 1.1357e+05\n",
      "Epoch 5660, Training-Loss 1.0875e+05, Data-loss 1.0902e+05                  , pde-loss 1.8237e-13, initc-loss 1.9661e+05                    bc_loss 1.1909e+05, Test-Loss 1.0902e+05\n",
      "Epoch 5670, Training-Loss 1.1071e+05, Data-loss 1.1540e+05                  , pde-loss 1.7034e-13, initc-loss 1.9595e+05                    bc_loss 1.1196e+05, Test-Loss 1.1540e+05\n",
      "Epoch 5680, Training-Loss 1.1217e+05, Data-loss 1.1197e+05                  , pde-loss 1.6718e-13, initc-loss 1.9529e+05                    bc_loss 1.0506e+05, Test-Loss 1.1197e+05\n",
      "Epoch 5690, Training-Loss 1.1241e+05, Data-loss 1.1053e+05                  , pde-loss 1.6399e-13, initc-loss 1.9464e+05                    bc_loss 9.8370e+04, Test-Loss 1.1053e+05\n",
      "Epoch 5700, Training-Loss 1.1244e+05, Data-loss 1.0914e+05                  , pde-loss 1.5393e-13, initc-loss 1.9398e+05                    bc_loss 9.1890e+04, Test-Loss 1.0914e+05\n",
      "Epoch 5710, Training-Loss 1.0701e+05, Data-loss 1.1132e+05                  , pde-loss 1.6896e-13, initc-loss 1.9333e+05                    bc_loss 8.5625e+04, Test-Loss 1.1132e+05\n",
      "Epoch 5720, Training-Loss 1.1021e+05, Data-loss 1.0981e+05                  , pde-loss 1.6502e-13, initc-loss 1.9268e+05                    bc_loss 7.9585e+04, Test-Loss 1.0981e+05\n",
      "Epoch 5730, Training-Loss 1.0715e+05, Data-loss 1.1133e+05                  , pde-loss 1.6079e-13, initc-loss 1.9202e+05                    bc_loss 7.3774e+04, Test-Loss 1.1133e+05\n",
      "Epoch 5740, Training-Loss 1.0712e+05, Data-loss 1.0886e+05                  , pde-loss 1.5361e-13, initc-loss 1.9138e+05                    bc_loss 6.8189e+04, Test-Loss 1.0886e+05\n",
      "Epoch 5750, Training-Loss 1.0817e+05, Data-loss 1.0642e+05                  , pde-loss 1.5288e-13, initc-loss 1.9073e+05                    bc_loss 6.2824e+04, Test-Loss 1.0642e+05\n",
      "Epoch 5760, Training-Loss 1.0765e+05, Data-loss 1.0594e+05                  , pde-loss 1.4485e-13, initc-loss 1.9008e+05                    bc_loss 5.7678e+04, Test-Loss 1.0594e+05\n",
      "Epoch 5770, Training-Loss 1.0964e+05, Data-loss 1.0627e+05                  , pde-loss 1.4559e-13, initc-loss 1.8943e+05                    bc_loss 5.2753e+04, Test-Loss 1.0627e+05\n",
      "Epoch 5780, Training-Loss 1.0157e+05, Data-loss 1.0675e+05                  , pde-loss 1.5673e-13, initc-loss 1.8879e+05                    bc_loss 4.8039e+04, Test-Loss 1.0675e+05\n",
      "Epoch 5790, Training-Loss 1.1031e+05, Data-loss 1.0601e+05                  , pde-loss 1.3042e-13, initc-loss 1.8814e+05                    bc_loss 4.3552e+04, Test-Loss 1.0601e+05\n",
      "Epoch 5800, Training-Loss 1.0380e+05, Data-loss 1.0361e+05                  , pde-loss 1.5223e-13, initc-loss 1.8750e+05                    bc_loss 3.9282e+04, Test-Loss 1.0361e+05\n",
      "Epoch 5810, Training-Loss 1.0374e+05, Data-loss 1.0579e+05                  , pde-loss 1.5206e-13, initc-loss 1.8686e+05                    bc_loss 3.5243e+04, Test-Loss 1.0579e+05\n",
      "Epoch 5820, Training-Loss 1.0579e+05, Data-loss 1.0504e+05                  , pde-loss 1.4537e-13, initc-loss 1.8622e+05                    bc_loss 3.1426e+04, Test-Loss 1.0504e+05\n",
      "Epoch 5830, Training-Loss 1.0035e+05, Data-loss 1.0247e+05                  , pde-loss 1.5573e-13, initc-loss 1.8558e+05                    bc_loss 2.7827e+04, Test-Loss 1.0247e+05\n",
      "Epoch 5840, Training-Loss 1.0601e+05, Data-loss 1.0203e+05                  , pde-loss 1.4426e-13, initc-loss 1.8495e+05                    bc_loss 2.4457e+04, Test-Loss 1.0203e+05\n",
      "Epoch 5850, Training-Loss 1.0507e+05, Data-loss 1.0145e+05                  , pde-loss 1.4461e-13, initc-loss 1.8432e+05                    bc_loss 2.1300e+04, Test-Loss 1.0145e+05\n",
      "Epoch 5860, Training-Loss 1.0168e+05, Data-loss 1.0254e+05                  , pde-loss 1.4999e-13, initc-loss 1.8368e+05                    bc_loss 1.8363e+04, Test-Loss 1.0254e+05\n",
      "Epoch 5870, Training-Loss 1.0040e+05, Data-loss 1.0293e+05                  , pde-loss 1.4517e-13, initc-loss 1.8305e+05                    bc_loss 1.5648e+04, Test-Loss 1.0293e+05\n",
      "Epoch 5880, Training-Loss 1.0185e+05, Data-loss 1.0474e+05                  , pde-loss 1.3952e-13, initc-loss 1.8242e+05                    bc_loss 1.3151e+04, Test-Loss 1.0474e+05\n",
      "Epoch 5890, Training-Loss 1.0057e+05, Data-loss 1.0339e+05                  , pde-loss 1.3650e-13, initc-loss 1.8180e+05                    bc_loss 1.0877e+04, Test-Loss 1.0339e+05\n",
      "Epoch 5900, Training-Loss 1.0327e+05, Data-loss 1.0171e+05                  , pde-loss 1.2322e-13, initc-loss 1.8117e+05                    bc_loss 8.8208e+03, Test-Loss 1.0171e+05\n",
      "Epoch 5910, Training-Loss 9.7583e+04, Data-loss 9.8833e+04                  , pde-loss 1.3450e-13, initc-loss 1.8054e+05                    bc_loss 6.9738e+03, Test-Loss 9.8833e+04\n",
      "Epoch 5920, Training-Loss 9.9909e+04, Data-loss 1.0058e+05                  , pde-loss 1.2592e-13, initc-loss 1.7992e+05                    bc_loss 5.3457e+03, Test-Loss 1.0058e+05\n",
      "Epoch 5930, Training-Loss 1.0102e+05, Data-loss 1.0058e+05                  , pde-loss 1.2698e-13, initc-loss 1.7930e+05                    bc_loss 3.9342e+03, Test-Loss 1.0058e+05\n",
      "Epoch 5940, Training-Loss 9.7597e+04, Data-loss 1.0403e+05                  , pde-loss 1.3305e-13, initc-loss 1.7868e+05                    bc_loss 2.7386e+03, Test-Loss 1.0403e+05\n",
      "Epoch 5950, Training-Loss 9.6589e+04, Data-loss 1.0070e+05                  , pde-loss 1.3361e-13, initc-loss 1.7806e+05                    bc_loss 1.7598e+03, Test-Loss 1.0070e+05\n",
      "Epoch 5960, Training-Loss 9.8810e+04, Data-loss 9.5858e+04                  , pde-loss 1.2713e-13, initc-loss 1.7744e+05                    bc_loss 9.9625e+02, Test-Loss 9.5858e+04\n",
      "Epoch 5970, Training-Loss 9.6822e+04, Data-loss 9.8322e+04                  , pde-loss 1.2707e-13, initc-loss 1.7682e+05                    bc_loss 4.4879e+02, Test-Loss 9.8322e+04\n",
      "Epoch 5980, Training-Loss 9.6788e+04, Data-loss 9.8119e+04                  , pde-loss 1.2150e-13, initc-loss 1.7620e+05                    bc_loss 1.1683e+02, Test-Loss 9.8119e+04\n",
      "Epoch 5990, Training-Loss 9.6239e+04, Data-loss 1.0221e+05                  , pde-loss 1.1697e-13, initc-loss 1.7559e+05                    bc_loss 1.9799e-01, Test-Loss 1.0221e+05\n",
      "Epoch 6000, Training-Loss 9.6056e+04, Data-loss 9.5850e+04                  , pde-loss 1.1271e-13, initc-loss 1.7497e+05                    bc_loss 9.8063e+01, Test-Loss 9.5850e+04\n",
      "Epoch 6010, Training-Loss 9.4649e+04, Data-loss 9.3638e+04                  , pde-loss 1.1476e-13, initc-loss 1.7436e+05                    bc_loss 4.0962e+02, Test-Loss 9.3638e+04\n",
      "Epoch 6020, Training-Loss 9.5490e+04, Data-loss 9.5620e+04                  , pde-loss 1.0975e-13, initc-loss 1.7375e+05                    bc_loss 9.3661e+02, Test-Loss 9.5620e+04\n",
      "Epoch 6030, Training-Loss 9.6068e+04, Data-loss 9.4189e+04                  , pde-loss 1.0902e-13, initc-loss 1.7314e+05                    bc_loss 1.6792e+03, Test-Loss 9.4189e+04\n",
      "Epoch 6040, Training-Loss 9.7270e+04, Data-loss 9.1929e+04                  , pde-loss 1.0223e-13, initc-loss 1.7253e+05                    bc_loss 2.6326e+03, Test-Loss 9.1929e+04\n",
      "Epoch 6050, Training-Loss 9.3103e+04, Data-loss 9.1027e+04                  , pde-loss 1.1205e-13, initc-loss 1.7193e+05                    bc_loss 3.8007e+03, Test-Loss 9.1027e+04\n",
      "Epoch 6060, Training-Loss 9.3340e+04, Data-loss 9.1994e+04                  , pde-loss 1.1215e-13, initc-loss 1.7132e+05                    bc_loss 5.1818e+03, Test-Loss 9.1994e+04\n",
      "Epoch 6070, Training-Loss 9.2043e+04, Data-loss 8.9441e+04                  , pde-loss 1.1683e-13, initc-loss 1.7072e+05                    bc_loss 6.7777e+03, Test-Loss 8.9441e+04\n",
      "Epoch 6080, Training-Loss 9.3685e+04, Data-loss 8.7772e+04                  , pde-loss 1.1069e-13, initc-loss 1.7011e+05                    bc_loss 8.5828e+03, Test-Loss 8.7772e+04\n",
      "Epoch 6090, Training-Loss 9.2041e+04, Data-loss 9.1052e+04                  , pde-loss 1.0740e-13, initc-loss 1.6951e+05                    bc_loss 1.0602e+04, Test-Loss 9.1052e+04\n",
      "Epoch 6100, Training-Loss 8.9150e+04, Data-loss 9.4692e+04                  , pde-loss 1.0971e-13, initc-loss 1.6891e+05                    bc_loss 1.2828e+04, Test-Loss 9.4692e+04\n",
      "Epoch 6110, Training-Loss 9.0376e+04, Data-loss 9.0754e+04                  , pde-loss 1.0471e-13, initc-loss 1.6832e+05                    bc_loss 1.5262e+04, Test-Loss 9.0754e+04\n",
      "Epoch 6120, Training-Loss 9.1732e+04, Data-loss 9.2160e+04                  , pde-loss 1.0165e-13, initc-loss 1.6772e+05                    bc_loss 1.7908e+04, Test-Loss 9.2160e+04\n",
      "Epoch 6130, Training-Loss 9.0784e+04, Data-loss 8.9283e+04                  , pde-loss 9.5923e-14, initc-loss 1.6713e+05                    bc_loss 2.0766e+04, Test-Loss 8.9283e+04\n",
      "Epoch 6140, Training-Loss 8.9868e+04, Data-loss 9.1246e+04                  , pde-loss 9.4872e-14, initc-loss 1.6653e+05                    bc_loss 2.3837e+04, Test-Loss 9.1246e+04\n",
      "Epoch 6150, Training-Loss 8.7462e+04, Data-loss 9.0822e+04                  , pde-loss 9.8714e-14, initc-loss 1.6594e+05                    bc_loss 2.7120e+04, Test-Loss 9.0822e+04\n",
      "Epoch 6160, Training-Loss 8.7136e+04, Data-loss 8.9248e+04                  , pde-loss 9.3178e-14, initc-loss 1.6535e+05                    bc_loss 3.0602e+04, Test-Loss 8.9248e+04\n",
      "Epoch 6170, Training-Loss 8.9117e+04, Data-loss 9.0809e+04                  , pde-loss 8.7573e-14, initc-loss 1.6476e+05                    bc_loss 3.4286e+04, Test-Loss 9.0809e+04\n",
      "Epoch 6180, Training-Loss 8.8401e+04, Data-loss 8.7308e+04                  , pde-loss 9.3842e-14, initc-loss 1.6417e+05                    bc_loss 3.8188e+04, Test-Loss 8.7308e+04\n",
      "Epoch 6190, Training-Loss 8.7722e+04, Data-loss 8.5567e+04                  , pde-loss 9.0515e-14, initc-loss 1.6358e+05                    bc_loss 4.2312e+04, Test-Loss 8.5567e+04\n",
      "Epoch 6200, Training-Loss 8.4744e+04, Data-loss 8.6781e+04                  , pde-loss 9.5651e-14, initc-loss 1.6300e+05                    bc_loss 4.6655e+04, Test-Loss 8.6781e+04\n",
      "Epoch 6210, Training-Loss 8.8948e+04, Data-loss 8.9224e+04                  , pde-loss 8.9509e-14, initc-loss 1.6241e+05                    bc_loss 5.1184e+04, Test-Loss 8.9224e+04\n",
      "Epoch 6220, Training-Loss 8.5694e+04, Data-loss 8.3447e+04                  , pde-loss 9.9520e-14, initc-loss 1.6183e+05                    bc_loss 5.5912e+04, Test-Loss 8.3447e+04\n",
      "Epoch 6230, Training-Loss 8.8281e+04, Data-loss 8.1621e+04                  , pde-loss 9.1353e-14, initc-loss 1.6125e+05                    bc_loss 6.0850e+04, Test-Loss 8.1621e+04\n",
      "Epoch 6240, Training-Loss 8.7798e+04, Data-loss 8.3850e+04                  , pde-loss 8.8811e-14, initc-loss 1.6067e+05                    bc_loss 6.6000e+04, Test-Loss 8.3850e+04\n",
      "Epoch 6250, Training-Loss 8.4145e+04, Data-loss 8.4866e+04                  , pde-loss 9.6488e-14, initc-loss 1.6009e+05                    bc_loss 7.1357e+04, Test-Loss 8.4866e+04\n",
      "Epoch 6260, Training-Loss 8.6055e+04, Data-loss 8.5355e+04                  , pde-loss 9.0453e-14, initc-loss 1.5951e+05                    bc_loss 7.6927e+04, Test-Loss 8.5355e+04\n",
      "Epoch 6270, Training-Loss 8.4598e+04, Data-loss 8.2855e+04                  , pde-loss 9.2830e-14, initc-loss 1.5894e+05                    bc_loss 8.2686e+04, Test-Loss 8.2855e+04\n",
      "Epoch 6280, Training-Loss 7.9634e+04, Data-loss 8.3035e+04                  , pde-loss 1.0299e-13, initc-loss 1.5836e+05                    bc_loss 8.8652e+04, Test-Loss 8.3035e+04\n",
      "Epoch 6290, Training-Loss 8.2748e+04, Data-loss 8.5453e+04                  , pde-loss 9.9563e-14, initc-loss 1.5779e+05                    bc_loss 9.4796e+04, Test-Loss 8.5453e+04\n",
      "Epoch 6300, Training-Loss 8.5579e+04, Data-loss 8.1393e+04                  , pde-loss 8.9416e-14, initc-loss 1.5722e+05                    bc_loss 1.0115e+05, Test-Loss 8.1393e+04\n",
      "Epoch 6310, Training-Loss 8.2265e+04, Data-loss 8.5931e+04                  , pde-loss 9.6636e-14, initc-loss 1.5665e+05                    bc_loss 1.0773e+05, Test-Loss 8.5931e+04\n",
      "Epoch 6320, Training-Loss 8.2895e+04, Data-loss 8.4159e+04                  , pde-loss 9.1140e-14, initc-loss 1.5608e+05                    bc_loss 1.1450e+05, Test-Loss 8.4159e+04\n",
      "Epoch 6330, Training-Loss 8.0750e+04, Data-loss 8.2081e+04                  , pde-loss 9.8436e-14, initc-loss 1.5552e+05                    bc_loss 1.2147e+05, Test-Loss 8.2081e+04\n",
      "Epoch 6340, Training-Loss 8.1327e+04, Data-loss 8.1753e+04                  , pde-loss 9.0875e-14, initc-loss 1.5495e+05                    bc_loss 1.2865e+05, Test-Loss 8.1753e+04\n",
      "Epoch 6350, Training-Loss 7.5389e+04, Data-loss 8.1110e+04                  , pde-loss 1.0176e-13, initc-loss 1.5439e+05                    bc_loss 1.3602e+05, Test-Loss 8.1110e+04\n",
      "Epoch 6360, Training-Loss 8.0887e+04, Data-loss 8.0373e+04                  , pde-loss 9.0448e-14, initc-loss 1.5383e+05                    bc_loss 1.4358e+05, Test-Loss 8.0373e+04\n",
      "Epoch 6370, Training-Loss 8.2923e+04, Data-loss 7.8565e+04                  , pde-loss 8.1371e-14, initc-loss 1.5326e+05                    bc_loss 1.5137e+05, Test-Loss 7.8565e+04\n",
      "Epoch 6380, Training-Loss 7.5721e+04, Data-loss 8.0630e+04                  , pde-loss 8.2024e-14, initc-loss 1.5270e+05                    bc_loss 1.5940e+05, Test-Loss 8.0630e+04\n",
      "Epoch 6390, Training-Loss 8.1111e+04, Data-loss 7.8056e+04                  , pde-loss 7.1710e-14, initc-loss 1.5214e+05                    bc_loss 1.6760e+05, Test-Loss 7.8056e+04\n",
      "Epoch 6400, Training-Loss 7.8607e+04, Data-loss 7.8353e+04                  , pde-loss 6.9406e-14, initc-loss 1.5158e+05                    bc_loss 1.7601e+05, Test-Loss 7.8353e+04\n",
      "Epoch 6410, Training-Loss 7.5822e+04, Data-loss 7.9103e+04                  , pde-loss 7.3743e-14, initc-loss 1.5102e+05                    bc_loss 1.8460e+05, Test-Loss 7.9103e+04\n",
      "Epoch 6420, Training-Loss 7.7679e+04, Data-loss 7.7217e+04                  , pde-loss 7.0491e-14, initc-loss 1.5047e+05                    bc_loss 1.9341e+05, Test-Loss 7.7217e+04\n",
      "Epoch 6430, Training-Loss 7.9337e+04, Data-loss 7.6228e+04                  , pde-loss 6.7499e-14, initc-loss 1.4991e+05                    bc_loss 2.0244e+05, Test-Loss 7.6228e+04\n",
      "Epoch 6440, Training-Loss 7.5073e+04, Data-loss 7.7570e+04                  , pde-loss 6.7338e-14, initc-loss 1.4936e+05                    bc_loss 2.1165e+05, Test-Loss 7.7570e+04\n",
      "Epoch 6450, Training-Loss 7.9514e+04, Data-loss 8.1095e+04                  , pde-loss 6.3625e-14, initc-loss 1.4881e+05                    bc_loss 2.2104e+05, Test-Loss 8.1095e+04\n",
      "Epoch 6460, Training-Loss 7.8242e+04, Data-loss 7.4410e+04                  , pde-loss 6.0530e-14, initc-loss 1.4826e+05                    bc_loss 2.3063e+05, Test-Loss 7.4410e+04\n",
      "Epoch 6470, Training-Loss 7.7068e+04, Data-loss 7.6444e+04                  , pde-loss 6.2387e-14, initc-loss 1.4771e+05                    bc_loss 2.4042e+05, Test-Loss 7.6444e+04\n",
      "Epoch 6480, Training-Loss 7.5691e+04, Data-loss 7.4474e+04                  , pde-loss 6.0711e-14, initc-loss 1.4716e+05                    bc_loss 2.5039e+05, Test-Loss 7.4474e+04\n",
      "Epoch 6490, Training-Loss 7.4863e+04, Data-loss 7.4451e+04                  , pde-loss 6.2491e-14, initc-loss 1.4662e+05                    bc_loss 2.6056e+05, Test-Loss 7.4451e+04\n",
      "Epoch 6500, Training-Loss 7.6302e+04, Data-loss 7.6532e+04                  , pde-loss 6.2540e-14, initc-loss 1.4607e+05                    bc_loss 2.7099e+05, Test-Loss 7.6532e+04\n",
      "Epoch 6510, Training-Loss 7.8971e+04, Data-loss 7.4597e+04                  , pde-loss 5.6048e-14, initc-loss 1.4553e+05                    bc_loss 2.8159e+05, Test-Loss 7.4597e+04\n",
      "Epoch 6520, Training-Loss 7.4253e+04, Data-loss 7.1968e+04                  , pde-loss 5.9984e-14, initc-loss 1.4498e+05                    bc_loss 2.9237e+05, Test-Loss 7.1968e+04\n",
      "Epoch 6530, Training-Loss 7.7366e+04, Data-loss 7.4163e+04                  , pde-loss 5.7653e-14, initc-loss 1.4444e+05                    bc_loss 3.0335e+05, Test-Loss 7.4163e+04\n",
      "Epoch 6540, Training-Loss 7.5763e+04, Data-loss 7.5849e+04                  , pde-loss 5.9281e-14, initc-loss 1.4390e+05                    bc_loss 3.1454e+05, Test-Loss 7.5849e+04\n",
      "Epoch 6550, Training-Loss 7.0326e+04, Data-loss 7.5279e+04                  , pde-loss 6.5251e-14, initc-loss 1.4336e+05                    bc_loss 3.2591e+05, Test-Loss 7.5279e+04\n",
      "Epoch 6560, Training-Loss 7.7607e+04, Data-loss 7.3088e+04                  , pde-loss 5.8068e-14, initc-loss 1.4283e+05                    bc_loss 3.3745e+05, Test-Loss 7.3088e+04\n",
      "Epoch 6570, Training-Loss 7.3378e+04, Data-loss 7.4222e+04                  , pde-loss 6.0860e-14, initc-loss 1.4229e+05                    bc_loss 3.4923e+05, Test-Loss 7.4222e+04\n",
      "Epoch 6580, Training-Loss 7.1516e+04, Data-loss 6.8494e+04                  , pde-loss 6.2716e-14, initc-loss 1.4175e+05                    bc_loss 3.6121e+05, Test-Loss 6.8494e+04\n",
      "Epoch 6590, Training-Loss 7.2732e+04, Data-loss 7.2539e+04                  , pde-loss 6.1482e-14, initc-loss 1.4122e+05                    bc_loss 3.7336e+05, Test-Loss 7.2539e+04\n",
      "Epoch 6600, Training-Loss 6.9351e+04, Data-loss 6.9702e+04                  , pde-loss 6.6345e-14, initc-loss 1.4069e+05                    bc_loss 3.8572e+05, Test-Loss 6.9702e+04\n",
      "Epoch 6610, Training-Loss 6.8743e+04, Data-loss 6.9433e+04                  , pde-loss 6.6505e-14, initc-loss 1.4016e+05                    bc_loss 3.9825e+05, Test-Loss 6.9433e+04\n",
      "Epoch 6620, Training-Loss 7.2373e+04, Data-loss 7.1458e+04                  , pde-loss 6.3006e-14, initc-loss 1.3963e+05                    bc_loss 4.1099e+05, Test-Loss 7.1458e+04\n",
      "Epoch 6630, Training-Loss 7.2694e+04, Data-loss 6.9627e+04                  , pde-loss 6.1546e-14, initc-loss 1.3910e+05                    bc_loss 4.2392e+05, Test-Loss 6.9627e+04\n",
      "Epoch 6640, Training-Loss 6.7093e+04, Data-loss 6.6262e+04                  , pde-loss 6.4595e-14, initc-loss 1.3857e+05                    bc_loss 4.3704e+05, Test-Loss 6.6262e+04\n",
      "Epoch 6650, Training-Loss 7.1727e+04, Data-loss 7.2260e+04                  , pde-loss 6.3867e-14, initc-loss 1.3805e+05                    bc_loss 4.5032e+05, Test-Loss 7.2260e+04\n",
      "Epoch 6660, Training-Loss 6.7073e+04, Data-loss 6.8456e+04                  , pde-loss 6.7494e-14, initc-loss 1.3752e+05                    bc_loss 4.6382e+05, Test-Loss 6.8456e+04\n",
      "Epoch 6670, Training-Loss 6.7504e+04, Data-loss 6.8026e+04                  , pde-loss 6.2874e-14, initc-loss 1.3700e+05                    bc_loss 4.7753e+05, Test-Loss 6.8026e+04\n",
      "Epoch 6680, Training-Loss 6.9096e+04, Data-loss 6.9004e+04                  , pde-loss 6.2014e-14, initc-loss 1.3648e+05                    bc_loss 4.9138e+05, Test-Loss 6.9004e+04\n",
      "Epoch 6690, Training-Loss 6.9670e+04, Data-loss 6.9904e+04                  , pde-loss 5.8758e-14, initc-loss 1.3596e+05                    bc_loss 5.0549e+05, Test-Loss 6.9904e+04\n",
      "Epoch 6700, Training-Loss 6.7714e+04, Data-loss 6.8293e+04                  , pde-loss 5.9960e-14, initc-loss 1.3544e+05                    bc_loss 5.1981e+05, Test-Loss 6.8293e+04\n",
      "Epoch 6710, Training-Loss 6.7842e+04, Data-loss 6.9211e+04                  , pde-loss 6.1215e-14, initc-loss 1.3492e+05                    bc_loss 5.3426e+05, Test-Loss 6.9211e+04\n",
      "Epoch 6720, Training-Loss 6.4546e+04, Data-loss 6.5452e+04                  , pde-loss 6.4269e-14, initc-loss 1.3441e+05                    bc_loss 5.4887e+05, Test-Loss 6.5452e+04\n",
      "Epoch 6730, Training-Loss 6.5290e+04, Data-loss 7.0287e+04                  , pde-loss 6.4376e-14, initc-loss 1.3389e+05                    bc_loss 5.6363e+05, Test-Loss 7.0287e+04\n",
      "Epoch 6740, Training-Loss 6.5590e+04, Data-loss 6.7123e+04                  , pde-loss 6.2839e-14, initc-loss 1.3338e+05                    bc_loss 5.7867e+05, Test-Loss 6.7123e+04\n",
      "Epoch 6750, Training-Loss 6.6142e+04, Data-loss 6.2651e+04                  , pde-loss 6.2680e-14, initc-loss 1.3287e+05                    bc_loss 5.9386e+05, Test-Loss 6.2651e+04\n",
      "Epoch 6760, Training-Loss 6.8256e+04, Data-loss 6.5279e+04                  , pde-loss 5.8695e-14, initc-loss 1.3235e+05                    bc_loss 6.0930e+05, Test-Loss 6.5279e+04\n",
      "Epoch 6770, Training-Loss 6.2760e+04, Data-loss 6.2568e+04                  , pde-loss 6.4312e-14, initc-loss 1.3184e+05                    bc_loss 6.2494e+05, Test-Loss 6.2568e+04\n",
      "Epoch 6780, Training-Loss 6.7393e+04, Data-loss 6.4045e+04                  , pde-loss 5.9475e-14, initc-loss 1.3133e+05                    bc_loss 6.4074e+05, Test-Loss 6.4045e+04\n",
      "Epoch 6790, Training-Loss 6.7794e+04, Data-loss 6.5211e+04                  , pde-loss 6.0136e-14, initc-loss 1.3082e+05                    bc_loss 6.5673e+05, Test-Loss 6.5211e+04\n",
      "Epoch 6800, Training-Loss 6.4285e+04, Data-loss 6.6777e+04                  , pde-loss 6.5562e-14, initc-loss 1.3032e+05                    bc_loss 6.7291e+05, Test-Loss 6.6777e+04\n",
      "Epoch 6810, Training-Loss 6.1465e+04, Data-loss 6.4483e+04                  , pde-loss 6.4302e-14, initc-loss 1.2981e+05                    bc_loss 6.8922e+05, Test-Loss 6.4483e+04\n",
      "Epoch 6820, Training-Loss 6.2567e+04, Data-loss 6.0675e+04                  , pde-loss 6.5466e-14, initc-loss 1.2931e+05                    bc_loss 7.0575e+05, Test-Loss 6.0675e+04\n",
      "Epoch 6830, Training-Loss 6.2455e+04, Data-loss 6.6364e+04                  , pde-loss 6.6285e-14, initc-loss 1.2881e+05                    bc_loss 7.2248e+05, Test-Loss 6.6364e+04\n",
      "Epoch 6840, Training-Loss 6.6619e+04, Data-loss 6.3484e+04                  , pde-loss 5.6985e-14, initc-loss 1.2831e+05                    bc_loss 7.3932e+05, Test-Loss 6.3484e+04\n",
      "Epoch 6850, Training-Loss 6.2427e+04, Data-loss 6.1909e+04                  , pde-loss 6.5279e-14, initc-loss 1.2781e+05                    bc_loss 7.5642e+05, Test-Loss 6.1909e+04\n",
      "Epoch 6860, Training-Loss 6.0916e+04, Data-loss 6.0724e+04                  , pde-loss 6.7937e-14, initc-loss 1.2731e+05                    bc_loss 7.7369e+05, Test-Loss 6.0724e+04\n",
      "Epoch 6870, Training-Loss 6.4141e+04, Data-loss 6.3698e+04                  , pde-loss 6.2790e-14, initc-loss 1.2681e+05                    bc_loss 7.9111e+05, Test-Loss 6.3698e+04\n",
      "Epoch 6880, Training-Loss 6.4118e+04, Data-loss 5.9951e+04                  , pde-loss 6.3669e-14, initc-loss 1.2632e+05                    bc_loss 8.0873e+05, Test-Loss 5.9951e+04\n",
      "Epoch 6890, Training-Loss 5.9444e+04, Data-loss 6.1277e+04                  , pde-loss 6.5846e-14, initc-loss 1.2582e+05                    bc_loss 8.2656e+05, Test-Loss 6.1277e+04\n",
      "Epoch 6900, Training-Loss 6.2205e+04, Data-loss 6.1574e+04                  , pde-loss 6.5129e-14, initc-loss 1.2533e+05                    bc_loss 8.4456e+05, Test-Loss 6.1574e+04\n",
      "Epoch 6910, Training-Loss 6.3478e+04, Data-loss 6.2414e+04                  , pde-loss 6.1791e-14, initc-loss 1.2483e+05                    bc_loss 8.6281e+05, Test-Loss 6.2414e+04\n",
      "Epoch 6920, Training-Loss 6.1817e+04, Data-loss 6.0179e+04                  , pde-loss 6.5643e-14, initc-loss 1.2434e+05                    bc_loss 8.8120e+05, Test-Loss 6.0179e+04\n",
      "Epoch 6930, Training-Loss 6.1407e+04, Data-loss 6.0660e+04                  , pde-loss 5.8462e-14, initc-loss 1.2385e+05                    bc_loss 8.9975e+05, Test-Loss 6.0660e+04\n",
      "Epoch 6940, Training-Loss 5.8784e+04, Data-loss 5.9410e+04                  , pde-loss 6.1443e-14, initc-loss 1.2337e+05                    bc_loss 9.1840e+05, Test-Loss 5.9410e+04\n",
      "Epoch 6950, Training-Loss 5.9321e+04, Data-loss 5.6350e+04                  , pde-loss 5.6518e-14, initc-loss 1.2288e+05                    bc_loss 9.3723e+05, Test-Loss 5.6350e+04\n",
      "Epoch 6960, Training-Loss 6.0876e+04, Data-loss 6.0958e+04                  , pde-loss 5.4315e-14, initc-loss 1.2240e+05                    bc_loss 9.5622e+05, Test-Loss 6.0958e+04\n",
      "Epoch 6970, Training-Loss 6.1410e+04, Data-loss 5.8750e+04                  , pde-loss 5.4102e-14, initc-loss 1.2191e+05                    bc_loss 9.7545e+05, Test-Loss 5.8750e+04\n",
      "Epoch 6980, Training-Loss 5.6769e+04, Data-loss 6.1507e+04                  , pde-loss 5.9356e-14, initc-loss 1.2143e+05                    bc_loss 9.9488e+05, Test-Loss 6.1507e+04\n",
      "Epoch 6990, Training-Loss 5.6464e+04, Data-loss 5.7820e+04                  , pde-loss 5.8680e-14, initc-loss 1.2095e+05                    bc_loss 1.0145e+06, Test-Loss 5.7820e+04\n",
      "Epoch 7000, Training-Loss 5.9803e+04, Data-loss 5.5344e+04                  , pde-loss 5.4805e-14, initc-loss 1.2047e+05                    bc_loss 1.0343e+06, Test-Loss 5.5344e+04\n",
      "Epoch 7010, Training-Loss 5.8153e+04, Data-loss 5.7422e+04                  , pde-loss 5.7813e-14, initc-loss 1.1999e+05                    bc_loss 1.0542e+06, Test-Loss 5.7422e+04\n",
      "Epoch 7020, Training-Loss 5.7340e+04, Data-loss 5.4564e+04                  , pde-loss 5.6338e-14, initc-loss 1.1951e+05                    bc_loss 1.0743e+06, Test-Loss 5.4564e+04\n",
      "Epoch 7030, Training-Loss 5.5342e+04, Data-loss 5.5980e+04                  , pde-loss 5.6984e-14, initc-loss 1.1904e+05                    bc_loss 1.0946e+06, Test-Loss 5.5980e+04\n",
      "Epoch 7040, Training-Loss 5.4797e+04, Data-loss 5.5557e+04                  , pde-loss 6.1461e-14, initc-loss 1.1857e+05                    bc_loss 1.1150e+06, Test-Loss 5.5557e+04\n",
      "Epoch 7050, Training-Loss 5.2063e+04, Data-loss 5.6461e+04                  , pde-loss 6.3325e-14, initc-loss 1.1810e+05                    bc_loss 1.1355e+06, Test-Loss 5.6461e+04\n",
      "Epoch 7060, Training-Loss 5.6441e+04, Data-loss 5.5286e+04                  , pde-loss 5.6611e-14, initc-loss 1.1763e+05                    bc_loss 1.1561e+06, Test-Loss 5.5286e+04\n",
      "Epoch 7070, Training-Loss 5.6665e+04, Data-loss 5.5708e+04                  , pde-loss 5.3978e-14, initc-loss 1.1716e+05                    bc_loss 1.1771e+06, Test-Loss 5.5708e+04\n",
      "Epoch 7080, Training-Loss 5.4619e+04, Data-loss 5.5517e+04                  , pde-loss 5.5100e-14, initc-loss 1.1669e+05                    bc_loss 1.1983e+06, Test-Loss 5.5517e+04\n",
      "Epoch 7090, Training-Loss 5.6816e+04, Data-loss 5.0870e+04                  , pde-loss 5.0806e-14, initc-loss 1.1622e+05                    bc_loss 1.2197e+06, Test-Loss 5.0870e+04\n",
      "Epoch 7100, Training-Loss 5.6551e+04, Data-loss 5.1559e+04                  , pde-loss 5.0181e-14, initc-loss 1.1575e+05                    bc_loss 1.2413e+06, Test-Loss 5.1559e+04\n",
      "Epoch 7110, Training-Loss 5.5236e+04, Data-loss 5.4718e+04                  , pde-loss 4.8527e-14, initc-loss 1.1528e+05                    bc_loss 1.2630e+06, Test-Loss 5.4718e+04\n",
      "Epoch 7120, Training-Loss 5.2801e+04, Data-loss 5.3081e+04                  , pde-loss 5.0512e-14, initc-loss 1.1482e+05                    bc_loss 1.2850e+06, Test-Loss 5.3081e+04\n",
      "Epoch 7130, Training-Loss 5.4433e+04, Data-loss 5.2412e+04                  , pde-loss 4.9246e-14, initc-loss 1.1435e+05                    bc_loss 1.3070e+06, Test-Loss 5.2412e+04\n",
      "Epoch 7140, Training-Loss 5.1119e+04, Data-loss 5.2485e+04                  , pde-loss 5.2067e-14, initc-loss 1.1389e+05                    bc_loss 1.3291e+06, Test-Loss 5.2485e+04\n",
      "Epoch 7150, Training-Loss 5.2148e+04, Data-loss 5.4534e+04                  , pde-loss 5.0346e-14, initc-loss 1.1343e+05                    bc_loss 1.3514e+06, Test-Loss 5.4534e+04\n",
      "Epoch 7160, Training-Loss 5.2950e+04, Data-loss 5.2914e+04                  , pde-loss 4.9917e-14, initc-loss 1.1298e+05                    bc_loss 1.3739e+06, Test-Loss 5.2914e+04\n",
      "Epoch 7170, Training-Loss 5.0824e+04, Data-loss 5.3661e+04                  , pde-loss 5.0539e-14, initc-loss 1.1252e+05                    bc_loss 1.3965e+06, Test-Loss 5.3661e+04\n",
      "Epoch 7180, Training-Loss 4.9863e+04, Data-loss 5.0376e+04                  , pde-loss 5.1522e-14, initc-loss 1.1206e+05                    bc_loss 1.4194e+06, Test-Loss 5.0376e+04\n",
      "Epoch 7190, Training-Loss 5.3098e+04, Data-loss 5.3207e+04                  , pde-loss 5.0460e-14, initc-loss 1.1161e+05                    bc_loss 1.4424e+06, Test-Loss 5.3207e+04\n",
      "Epoch 7200, Training-Loss 5.3114e+04, Data-loss 4.8733e+04                  , pde-loss 4.8711e-14, initc-loss 1.1115e+05                    bc_loss 1.4656e+06, Test-Loss 4.8733e+04\n",
      "Epoch 7210, Training-Loss 5.1873e+04, Data-loss 4.8421e+04                  , pde-loss 4.9552e-14, initc-loss 1.1070e+05                    bc_loss 1.4890e+06, Test-Loss 4.8421e+04\n",
      "Epoch 7220, Training-Loss 5.0571e+04, Data-loss 5.0216e+04                  , pde-loss 5.1743e-14, initc-loss 1.1025e+05                    bc_loss 1.5126e+06, Test-Loss 5.0216e+04\n",
      "Epoch 7230, Training-Loss 5.1076e+04, Data-loss 5.0996e+04                  , pde-loss 5.0982e-14, initc-loss 1.0980e+05                    bc_loss 1.5362e+06, Test-Loss 5.0996e+04\n",
      "Epoch 7240, Training-Loss 4.8189e+04, Data-loss 4.8955e+04                  , pde-loss 5.3404e-14, initc-loss 1.0935e+05                    bc_loss 1.5601e+06, Test-Loss 4.8955e+04\n",
      "Epoch 7250, Training-Loss 5.0402e+04, Data-loss 5.1130e+04                  , pde-loss 5.1426e-14, initc-loss 1.0890e+05                    bc_loss 1.5842e+06, Test-Loss 5.1130e+04\n",
      "Epoch 7260, Training-Loss 5.0107e+04, Data-loss 5.0221e+04                  , pde-loss 5.3823e-14, initc-loss 1.0846e+05                    bc_loss 1.6082e+06, Test-Loss 5.0221e+04\n",
      "Epoch 7270, Training-Loss 4.7718e+04, Data-loss 5.0754e+04                  , pde-loss 5.4192e-14, initc-loss 1.0801e+05                    bc_loss 1.6325e+06, Test-Loss 5.0754e+04\n",
      "Epoch 7280, Training-Loss 4.8075e+04, Data-loss 4.9440e+04                  , pde-loss 5.5186e-14, initc-loss 1.0757e+05                    bc_loss 1.6570e+06, Test-Loss 4.9440e+04\n",
      "Epoch 7290, Training-Loss 4.5025e+04, Data-loss 4.6103e+04                  , pde-loss 5.6857e-14, initc-loss 1.0713e+05                    bc_loss 1.6816e+06, Test-Loss 4.6103e+04\n",
      "Epoch 7300, Training-Loss 4.6615e+04, Data-loss 5.3898e+04                  , pde-loss 5.2969e-14, initc-loss 1.0669e+05                    bc_loss 1.7064e+06, Test-Loss 5.3898e+04\n",
      "Epoch 7310, Training-Loss 4.8070e+04, Data-loss 4.5030e+04                  , pde-loss 5.4365e-14, initc-loss 1.0625e+05                    bc_loss 1.7314e+06, Test-Loss 4.5030e+04\n",
      "Epoch 7320, Training-Loss 4.4464e+04, Data-loss 4.7425e+04                  , pde-loss 5.6915e-14, initc-loss 1.0581e+05                    bc_loss 1.7565e+06, Test-Loss 4.7425e+04\n",
      "Epoch 7330, Training-Loss 4.3176e+04, Data-loss 4.5764e+04                  , pde-loss 5.8958e-14, initc-loss 1.0537e+05                    bc_loss 1.7818e+06, Test-Loss 4.5764e+04\n",
      "Epoch 7340, Training-Loss 4.5685e+04, Data-loss 4.9123e+04                  , pde-loss 5.4283e-14, initc-loss 1.0494e+05                    bc_loss 1.8072e+06, Test-Loss 4.9123e+04\n",
      "Epoch 7350, Training-Loss 4.6559e+04, Data-loss 4.9040e+04                  , pde-loss 5.5269e-14, initc-loss 1.0451e+05                    bc_loss 1.8327e+06, Test-Loss 4.9040e+04\n",
      "Epoch 7360, Training-Loss 4.4475e+04, Data-loss 4.7496e+04                  , pde-loss 5.7325e-14, initc-loss 1.0407e+05                    bc_loss 1.8585e+06, Test-Loss 4.7496e+04\n",
      "Epoch 7370, Training-Loss 4.6352e+04, Data-loss 4.6718e+04                  , pde-loss 5.5983e-14, initc-loss 1.0364e+05                    bc_loss 1.8844e+06, Test-Loss 4.6718e+04\n",
      "Epoch 7380, Training-Loss 4.5955e+04, Data-loss 4.5827e+04                  , pde-loss 5.4039e-14, initc-loss 1.0321e+05                    bc_loss 1.9105e+06, Test-Loss 4.5827e+04\n",
      "Epoch 7390, Training-Loss 4.4863e+04, Data-loss 4.7340e+04                  , pde-loss 5.5543e-14, initc-loss 1.0278e+05                    bc_loss 1.9367e+06, Test-Loss 4.7340e+04\n",
      "Epoch 7400, Training-Loss 4.2315e+04, Data-loss 4.3163e+04                  , pde-loss 5.8066e-14, initc-loss 1.0235e+05                    bc_loss 1.9631e+06, Test-Loss 4.3163e+04\n",
      "Epoch 7410, Training-Loss 4.2454e+04, Data-loss 4.1340e+04                  , pde-loss 5.9190e-14, initc-loss 1.0193e+05                    bc_loss 1.9895e+06, Test-Loss 4.1340e+04\n",
      "Epoch 7420, Training-Loss 4.7303e+04, Data-loss 4.6482e+04                  , pde-loss 5.3643e-14, initc-loss 1.0150e+05                    bc_loss 2.0161e+06, Test-Loss 4.6482e+04\n",
      "Epoch 7430, Training-Loss 4.4046e+04, Data-loss 4.5500e+04                  , pde-loss 5.7271e-14, initc-loss 1.0108e+05                    bc_loss 2.0430e+06, Test-Loss 4.5500e+04\n",
      "Epoch 7440, Training-Loss 4.3318e+04, Data-loss 4.5303e+04                  , pde-loss 5.6525e-14, initc-loss 1.0066e+05                    bc_loss 2.0700e+06, Test-Loss 4.5303e+04\n",
      "Epoch 7450, Training-Loss 4.2744e+04, Data-loss 4.4324e+04                  , pde-loss 5.8278e-14, initc-loss 1.0023e+05                    bc_loss 2.0972e+06, Test-Loss 4.4324e+04\n",
      "Epoch 7460, Training-Loss 4.5466e+04, Data-loss 4.4099e+04                  , pde-loss 5.3072e-14, initc-loss 9.9814e+04                    bc_loss 2.1245e+06, Test-Loss 4.4099e+04\n",
      "Epoch 7470, Training-Loss 4.3521e+04, Data-loss 4.3712e+04                  , pde-loss 5.7120e-14, initc-loss 9.9394e+04                    bc_loss 2.1520e+06, Test-Loss 4.3712e+04\n",
      "Epoch 7480, Training-Loss 4.5294e+04, Data-loss 4.1180e+04                  , pde-loss 5.4681e-14, initc-loss 9.8975e+04                    bc_loss 2.1798e+06, Test-Loss 4.1180e+04\n",
      "Epoch 7490, Training-Loss 4.3101e+04, Data-loss 4.5131e+04                  , pde-loss 5.7969e-14, initc-loss 9.8555e+04                    bc_loss 2.2078e+06, Test-Loss 4.5131e+04\n",
      "Epoch 7500, Training-Loss 4.5927e+04, Data-loss 4.1166e+04                  , pde-loss 5.3248e-14, initc-loss 9.8138e+04                    bc_loss 2.2358e+06, Test-Loss 4.1166e+04\n",
      "Epoch 7510, Training-Loss 4.2220e+04, Data-loss 4.3207e+04                  , pde-loss 5.7052e-14, initc-loss 9.7721e+04                    bc_loss 2.2640e+06, Test-Loss 4.3207e+04\n",
      "Epoch 7520, Training-Loss 4.1721e+04, Data-loss 4.3863e+04                  , pde-loss 5.9037e-14, initc-loss 9.7305e+04                    bc_loss 2.2925e+06, Test-Loss 4.3863e+04\n",
      "Epoch 7530, Training-Loss 3.9953e+04, Data-loss 4.0496e+04                  , pde-loss 6.0770e-14, initc-loss 9.6892e+04                    bc_loss 2.3210e+06, Test-Loss 4.0496e+04\n",
      "Epoch 7540, Training-Loss 4.2959e+04, Data-loss 4.1193e+04                  , pde-loss 5.3343e-14, initc-loss 9.6481e+04                    bc_loss 2.3495e+06, Test-Loss 4.1193e+04\n",
      "Epoch 7550, Training-Loss 4.0304e+04, Data-loss 4.0187e+04                  , pde-loss 5.4778e-14, initc-loss 9.6074e+04                    bc_loss 2.3780e+06, Test-Loss 4.0187e+04\n",
      "Epoch 7560, Training-Loss 4.1065e+04, Data-loss 4.1088e+04                  , pde-loss 5.3167e-14, initc-loss 9.5669e+04                    bc_loss 2.4066e+06, Test-Loss 4.1088e+04\n",
      "Epoch 7570, Training-Loss 4.3167e+04, Data-loss 3.9513e+04                  , pde-loss 5.1990e-14, initc-loss 9.5264e+04                    bc_loss 2.4355e+06, Test-Loss 3.9513e+04\n",
      "Epoch 7580, Training-Loss 4.0757e+04, Data-loss 4.0148e+04                  , pde-loss 5.1740e-14, initc-loss 9.4858e+04                    bc_loss 2.4646e+06, Test-Loss 4.0148e+04\n",
      "Epoch 7590, Training-Loss 3.8201e+04, Data-loss 3.9715e+04                  , pde-loss 5.3724e-14, initc-loss 9.4454e+04                    bc_loss 2.4939e+06, Test-Loss 3.9715e+04\n",
      "Epoch 7600, Training-Loss 4.1237e+04, Data-loss 4.1297e+04                  , pde-loss 5.0476e-14, initc-loss 9.4050e+04                    bc_loss 2.5233e+06, Test-Loss 4.1297e+04\n",
      "Epoch 7610, Training-Loss 4.3962e+04, Data-loss 3.9508e+04                  , pde-loss 4.4947e-14, initc-loss 9.3645e+04                    bc_loss 2.5531e+06, Test-Loss 3.9508e+04\n",
      "Epoch 7620, Training-Loss 4.0454e+04, Data-loss 4.0289e+04                  , pde-loss 4.8497e-14, initc-loss 9.3242e+04                    bc_loss 2.5830e+06, Test-Loss 4.0289e+04\n",
      "Epoch 7630, Training-Loss 3.9088e+04, Data-loss 3.8985e+04                  , pde-loss 4.9100e-14, initc-loss 9.2842e+04                    bc_loss 2.6129e+06, Test-Loss 3.8985e+04\n",
      "Epoch 7640, Training-Loss 3.8564e+04, Data-loss 3.9798e+04                  , pde-loss 5.0816e-14, initc-loss 9.2442e+04                    bc_loss 2.6430e+06, Test-Loss 3.9798e+04\n",
      "Epoch 7650, Training-Loss 3.8235e+04, Data-loss 3.8543e+04                  , pde-loss 5.2005e-14, initc-loss 9.2043e+04                    bc_loss 2.6733e+06, Test-Loss 3.8543e+04\n",
      "Epoch 7660, Training-Loss 3.9131e+04, Data-loss 3.8228e+04                  , pde-loss 4.8053e-14, initc-loss 9.1645e+04                    bc_loss 2.7038e+06, Test-Loss 3.8228e+04\n",
      "Epoch 7670, Training-Loss 3.8485e+04, Data-loss 3.9901e+04                  , pde-loss 4.6315e-14, initc-loss 9.1250e+04                    bc_loss 2.7342e+06, Test-Loss 3.9901e+04\n",
      "Epoch 7680, Training-Loss 3.9140e+04, Data-loss 3.9330e+04                  , pde-loss 4.4795e-14, initc-loss 9.0858e+04                    bc_loss 2.7647e+06, Test-Loss 3.9330e+04\n",
      "Epoch 7690, Training-Loss 3.8162e+04, Data-loss 3.6870e+04                  , pde-loss 4.5676e-14, initc-loss 9.0466e+04                    bc_loss 2.7954e+06, Test-Loss 3.6870e+04\n",
      "Epoch 7700, Training-Loss 3.7243e+04, Data-loss 3.6748e+04                  , pde-loss 4.2845e-14, initc-loss 9.0075e+04                    bc_loss 2.8263e+06, Test-Loss 3.6748e+04\n",
      "Epoch 7710, Training-Loss 3.6233e+04, Data-loss 4.1358e+04                  , pde-loss 4.3177e-14, initc-loss 8.9687e+04                    bc_loss 2.8571e+06, Test-Loss 4.1358e+04\n",
      "Epoch 7720, Training-Loss 3.9605e+04, Data-loss 3.4718e+04                  , pde-loss 3.5824e-14, initc-loss 8.9300e+04                    bc_loss 2.8881e+06, Test-Loss 3.4718e+04\n",
      "Epoch 7730, Training-Loss 3.6810e+04, Data-loss 3.6876e+04                  , pde-loss 3.6853e-14, initc-loss 8.8912e+04                    bc_loss 2.9195e+06, Test-Loss 3.6876e+04\n",
      "Epoch 7740, Training-Loss 3.8305e+04, Data-loss 3.4983e+04                  , pde-loss 3.1148e-14, initc-loss 8.8524e+04                    bc_loss 2.9510e+06, Test-Loss 3.4983e+04\n",
      "Epoch 7750, Training-Loss 3.6270e+04, Data-loss 3.4567e+04                  , pde-loss 3.2678e-14, initc-loss 8.8139e+04                    bc_loss 2.9825e+06, Test-Loss 3.4567e+04\n",
      "Epoch 7760, Training-Loss 3.5748e+04, Data-loss 3.7815e+04                  , pde-loss 3.1181e-14, initc-loss 8.7756e+04                    bc_loss 3.0142e+06, Test-Loss 3.7815e+04\n",
      "Epoch 7770, Training-Loss 3.4144e+04, Data-loss 3.6380e+04                  , pde-loss 3.2797e-14, initc-loss 8.7373e+04                    bc_loss 3.0460e+06, Test-Loss 3.6380e+04\n",
      "Epoch 7780, Training-Loss 3.2191e+04, Data-loss 3.3795e+04                  , pde-loss 3.3216e-14, initc-loss 8.6992e+04                    bc_loss 3.0780e+06, Test-Loss 3.3795e+04\n",
      "Epoch 7790, Training-Loss 3.6132e+04, Data-loss 3.6769e+04                  , pde-loss 2.9044e-14, initc-loss 8.6614e+04                    bc_loss 3.1099e+06, Test-Loss 3.6769e+04\n",
      "Epoch 7800, Training-Loss 3.6537e+04, Data-loss 3.3917e+04                  , pde-loss 2.8031e-14, initc-loss 8.6236e+04                    bc_loss 3.1421e+06, Test-Loss 3.3917e+04\n",
      "Epoch 7810, Training-Loss 3.5567e+04, Data-loss 3.5240e+04                  , pde-loss 2.7182e-14, initc-loss 8.5858e+04                    bc_loss 3.1744e+06, Test-Loss 3.5240e+04\n",
      "Epoch 7820, Training-Loss 3.5474e+04, Data-loss 3.3973e+04                  , pde-loss 2.6904e-14, initc-loss 8.5481e+04                    bc_loss 3.2070e+06, Test-Loss 3.3973e+04\n",
      "Epoch 7830, Training-Loss 3.4725e+04, Data-loss 3.5451e+04                  , pde-loss 2.6978e-14, initc-loss 8.5103e+04                    bc_loss 3.2398e+06, Test-Loss 3.5451e+04\n",
      "Epoch 7840, Training-Loss 3.2354e+04, Data-loss 3.5568e+04                  , pde-loss 2.8826e-14, initc-loss 8.4728e+04                    bc_loss 3.2727e+06, Test-Loss 3.5568e+04\n",
      "Epoch 7850, Training-Loss 3.6823e+04, Data-loss 3.4610e+04                  , pde-loss 2.4064e-14, initc-loss 8.4354e+04                    bc_loss 3.3056e+06, Test-Loss 3.4610e+04\n",
      "Epoch 7860, Training-Loss 3.5315e+04, Data-loss 3.3740e+04                  , pde-loss 2.3161e-14, initc-loss 8.3981e+04                    bc_loss 3.3388e+06, Test-Loss 3.3740e+04\n",
      "Epoch 7870, Training-Loss 3.4704e+04, Data-loss 3.4362e+04                  , pde-loss 2.3051e-14, initc-loss 8.3610e+04                    bc_loss 3.3720e+06, Test-Loss 3.4362e+04\n",
      "Epoch 7880, Training-Loss 3.2743e+04, Data-loss 3.3451e+04                  , pde-loss 2.5070e-14, initc-loss 8.3240e+04                    bc_loss 3.4054e+06, Test-Loss 3.3451e+04\n",
      "Epoch 7890, Training-Loss 3.2683e+04, Data-loss 3.2438e+04                  , pde-loss 2.3613e-14, initc-loss 8.2871e+04                    bc_loss 3.4389e+06, Test-Loss 3.2438e+04\n",
      "Epoch 7900, Training-Loss 3.4004e+04, Data-loss 3.4636e+04                  , pde-loss 2.2432e-14, initc-loss 8.2504e+04                    bc_loss 3.4724e+06, Test-Loss 3.4636e+04\n",
      "Epoch 7910, Training-Loss 3.1764e+04, Data-loss 3.0398e+04                  , pde-loss 2.3643e-14, initc-loss 8.2137e+04                    bc_loss 3.5062e+06, Test-Loss 3.0398e+04\n",
      "Epoch 7920, Training-Loss 3.2988e+04, Data-loss 3.3850e+04                  , pde-loss 2.2424e-14, initc-loss 8.1774e+04                    bc_loss 3.5398e+06, Test-Loss 3.3850e+04\n",
      "Epoch 7930, Training-Loss 3.1118e+04, Data-loss 3.1442e+04                  , pde-loss 2.3240e-14, initc-loss 8.1412e+04                    bc_loss 3.5736e+06, Test-Loss 3.1442e+04\n",
      "Epoch 7940, Training-Loss 3.2309e+04, Data-loss 3.2228e+04                  , pde-loss 2.3012e-14, initc-loss 8.1050e+04                    bc_loss 3.6077e+06, Test-Loss 3.2228e+04\n",
      "Epoch 7950, Training-Loss 3.0410e+04, Data-loss 3.0887e+04                  , pde-loss 2.3518e-14, initc-loss 8.0688e+04                    bc_loss 3.6420e+06, Test-Loss 3.0887e+04\n",
      "Epoch 7960, Training-Loss 3.0470e+04, Data-loss 3.2206e+04                  , pde-loss 2.3885e-14, initc-loss 8.0328e+04                    bc_loss 3.6763e+06, Test-Loss 3.2206e+04\n",
      "Epoch 7970, Training-Loss 3.1785e+04, Data-loss 3.1804e+04                  , pde-loss 2.0186e-14, initc-loss 7.9969e+04                    bc_loss 3.7107e+06, Test-Loss 3.1804e+04\n",
      "Epoch 7980, Training-Loss 3.0815e+04, Data-loss 3.2149e+04                  , pde-loss 2.0699e-14, initc-loss 7.9610e+04                    bc_loss 3.7454e+06, Test-Loss 3.2149e+04\n",
      "Epoch 7990, Training-Loss 3.3880e+04, Data-loss 3.1879e+04                  , pde-loss 1.8473e-14, initc-loss 7.9253e+04                    bc_loss 3.7802e+06, Test-Loss 3.1879e+04\n",
      "Epoch 8000, Training-Loss 3.1368e+04, Data-loss 3.0372e+04                  , pde-loss 1.9452e-14, initc-loss 7.8895e+04                    bc_loss 3.8153e+06, Test-Loss 3.0372e+04\n",
      "Epoch 8010, Training-Loss 2.9778e+04, Data-loss 2.9898e+04                  , pde-loss 1.9825e-14, initc-loss 7.8540e+04                    bc_loss 3.8504e+06, Test-Loss 2.9898e+04\n",
      "Epoch 8020, Training-Loss 3.2556e+04, Data-loss 3.0154e+04                  , pde-loss 1.8681e-14, initc-loss 7.8185e+04                    bc_loss 3.8856e+06, Test-Loss 3.0154e+04\n",
      "Epoch 8030, Training-Loss 3.0854e+04, Data-loss 2.9274e+04                  , pde-loss 1.9228e-14, initc-loss 7.7832e+04                    bc_loss 3.9209e+06, Test-Loss 2.9274e+04\n",
      "Epoch 8040, Training-Loss 3.1846e+04, Data-loss 3.1136e+04                  , pde-loss 1.9049e-14, initc-loss 7.7481e+04                    bc_loss 3.9563e+06, Test-Loss 3.1136e+04\n",
      "Epoch 8050, Training-Loss 3.0630e+04, Data-loss 2.9436e+04                  , pde-loss 1.8746e-14, initc-loss 7.7131e+04                    bc_loss 3.9917e+06, Test-Loss 2.9436e+04\n",
      "Epoch 8060, Training-Loss 3.1162e+04, Data-loss 2.8500e+04                  , pde-loss 1.8979e-14, initc-loss 7.6783e+04                    bc_loss 4.0273e+06, Test-Loss 2.8500e+04\n",
      "Epoch 8070, Training-Loss 2.9097e+04, Data-loss 2.9943e+04                  , pde-loss 1.8658e-14, initc-loss 7.6433e+04                    bc_loss 4.0632e+06, Test-Loss 2.9943e+04\n",
      "Epoch 8080, Training-Loss 2.9660e+04, Data-loss 2.7119e+04                  , pde-loss 1.6614e-14, initc-loss 7.6086e+04                    bc_loss 4.0991e+06, Test-Loss 2.7119e+04\n",
      "Epoch 8090, Training-Loss 2.8507e+04, Data-loss 2.6880e+04                  , pde-loss 1.5410e-14, initc-loss 7.5740e+04                    bc_loss 4.1351e+06, Test-Loss 2.6880e+04\n",
      "Epoch 8100, Training-Loss 2.6541e+04, Data-loss 2.7348e+04                  , pde-loss 1.5940e-14, initc-loss 7.5394e+04                    bc_loss 4.1714e+06, Test-Loss 2.7348e+04\n",
      "Epoch 8110, Training-Loss 2.9951e+04, Data-loss 2.9603e+04                  , pde-loss 1.2267e-14, initc-loss 7.5052e+04                    bc_loss 4.2076e+06, Test-Loss 2.9603e+04\n",
      "Epoch 8120, Training-Loss 2.8481e+04, Data-loss 2.9885e+04                  , pde-loss 1.1882e-14, initc-loss 7.4712e+04                    bc_loss 4.2437e+06, Test-Loss 2.9885e+04\n",
      "Epoch 8130, Training-Loss 2.8244e+04, Data-loss 2.6387e+04                  , pde-loss 1.1179e-14, initc-loss 7.4373e+04                    bc_loss 4.2799e+06, Test-Loss 2.6387e+04\n",
      "Epoch 8140, Training-Loss 2.8988e+04, Data-loss 2.7783e+04                  , pde-loss 1.0924e-14, initc-loss 7.4035e+04                    bc_loss 4.3163e+06, Test-Loss 2.7783e+04\n",
      "Epoch 8150, Training-Loss 2.8064e+04, Data-loss 2.7234e+04                  , pde-loss 1.0354e-14, initc-loss 7.3699e+04                    bc_loss 4.3527e+06, Test-Loss 2.7234e+04\n",
      "Epoch 8160, Training-Loss 2.9764e+04, Data-loss 2.8204e+04                  , pde-loss 9.6227e-15, initc-loss 7.3364e+04                    bc_loss 4.3892e+06, Test-Loss 2.8204e+04\n",
      "Epoch 8170, Training-Loss 2.7575e+04, Data-loss 2.6884e+04                  , pde-loss 1.0409e-14, initc-loss 7.3030e+04                    bc_loss 4.4259e+06, Test-Loss 2.6884e+04\n",
      "Epoch 8180, Training-Loss 2.9312e+04, Data-loss 2.5618e+04                  , pde-loss 9.7357e-15, initc-loss 7.2699e+04                    bc_loss 4.4625e+06, Test-Loss 2.5618e+04\n",
      "Epoch 8190, Training-Loss 2.8323e+04, Data-loss 2.6311e+04                  , pde-loss 9.7099e-15, initc-loss 7.2368e+04                    bc_loss 4.4993e+06, Test-Loss 2.6311e+04\n",
      "Epoch 8200, Training-Loss 2.5863e+04, Data-loss 2.7806e+04                  , pde-loss 1.0979e-14, initc-loss 7.2035e+04                    bc_loss 4.5365e+06, Test-Loss 2.7806e+04\n",
      "Epoch 8210, Training-Loss 2.8920e+04, Data-loss 2.7928e+04                  , pde-loss 9.5133e-15, initc-loss 7.1705e+04                    bc_loss 4.5736e+06, Test-Loss 2.7928e+04\n",
      "Epoch 8220, Training-Loss 2.7143e+04, Data-loss 2.5977e+04                  , pde-loss 1.0011e-14, initc-loss 7.1373e+04                    bc_loss 4.6112e+06, Test-Loss 2.5977e+04\n",
      "Epoch 8230, Training-Loss 2.7897e+04, Data-loss 2.6267e+04                  , pde-loss 9.7462e-15, initc-loss 7.1043e+04                    bc_loss 4.6489e+06, Test-Loss 2.6267e+04\n",
      "Epoch 8240, Training-Loss 2.5581e+04, Data-loss 2.3349e+04                  , pde-loss 1.0419e-14, initc-loss 7.0715e+04                    bc_loss 4.6865e+06, Test-Loss 2.3349e+04\n",
      "Epoch 8250, Training-Loss 2.5313e+04, Data-loss 2.6660e+04                  , pde-loss 9.9649e-15, initc-loss 7.0389e+04                    bc_loss 4.7242e+06, Test-Loss 2.6660e+04\n",
      "Epoch 8260, Training-Loss 2.4779e+04, Data-loss 2.8322e+04                  , pde-loss 8.8365e-15, initc-loss 7.0065e+04                    bc_loss 4.7618e+06, Test-Loss 2.8322e+04\n",
      "Epoch 8270, Training-Loss 2.5394e+04, Data-loss 2.5699e+04                  , pde-loss 8.7614e-15, initc-loss 6.9742e+04                    bc_loss 4.7996e+06, Test-Loss 2.5699e+04\n",
      "Epoch 8280, Training-Loss 2.7077e+04, Data-loss 2.5648e+04                  , pde-loss 7.1842e-15, initc-loss 6.9420e+04                    bc_loss 4.8375e+06, Test-Loss 2.5648e+04\n",
      "Epoch 8290, Training-Loss 2.6460e+04, Data-loss 2.3797e+04                  , pde-loss 6.7237e-15, initc-loss 6.9098e+04                    bc_loss 4.8757e+06, Test-Loss 2.3797e+04\n",
      "Epoch 8300, Training-Loss 2.4785e+04, Data-loss 2.5107e+04                  , pde-loss 6.1755e-15, initc-loss 6.8777e+04                    bc_loss 4.9139e+06, Test-Loss 2.5107e+04\n",
      "Epoch 8310, Training-Loss 2.4148e+04, Data-loss 2.4716e+04                  , pde-loss 5.6770e-15, initc-loss 6.8459e+04                    bc_loss 4.9521e+06, Test-Loss 2.4716e+04\n",
      "Epoch 8320, Training-Loss 2.3748e+04, Data-loss 2.5251e+04                  , pde-loss 5.4829e-15, initc-loss 6.8142e+04                    bc_loss 4.9902e+06, Test-Loss 2.5251e+04\n",
      "Epoch 8330, Training-Loss 2.6231e+04, Data-loss 2.3290e+04                  , pde-loss 3.8658e-15, initc-loss 6.7828e+04                    bc_loss 5.0283e+06, Test-Loss 2.3290e+04\n",
      "Epoch 8340, Training-Loss 2.6315e+04, Data-loss 2.4965e+04                  , pde-loss 3.9833e-15, initc-loss 6.7515e+04                    bc_loss 5.0666e+06, Test-Loss 2.4965e+04\n",
      "Epoch 8350, Training-Loss 2.4573e+04, Data-loss 2.3070e+04                  , pde-loss 4.1969e-15, initc-loss 6.7202e+04                    bc_loss 5.1051e+06, Test-Loss 2.3070e+04\n",
      "Epoch 8360, Training-Loss 2.3619e+04, Data-loss 2.1654e+04                  , pde-loss 4.0925e-15, initc-loss 6.6889e+04                    bc_loss 5.1438e+06, Test-Loss 2.1654e+04\n",
      "Epoch 8370, Training-Loss 2.4911e+04, Data-loss 2.0984e+04                  , pde-loss 4.0010e-15, initc-loss 6.6576e+04                    bc_loss 5.1827e+06, Test-Loss 2.0984e+04\n",
      "Epoch 8380, Training-Loss 2.2779e+04, Data-loss 2.3000e+04                  , pde-loss 3.8236e-15, initc-loss 6.6265e+04                    bc_loss 5.2216e+06, Test-Loss 2.3000e+04\n",
      "Epoch 8390, Training-Loss 2.5337e+04, Data-loss 2.4911e+04                  , pde-loss 3.3829e-15, initc-loss 6.5958e+04                    bc_loss 5.2603e+06, Test-Loss 2.4911e+04\n",
      "Epoch 8400, Training-Loss 2.4934e+04, Data-loss 2.2449e+04                  , pde-loss 3.5912e-15, initc-loss 6.5650e+04                    bc_loss 5.2993e+06, Test-Loss 2.2449e+04\n",
      "Epoch 8410, Training-Loss 2.4062e+04, Data-loss 2.0870e+04                  , pde-loss 3.9764e-15, initc-loss 6.5343e+04                    bc_loss 5.3385e+06, Test-Loss 2.0870e+04\n",
      "Epoch 8420, Training-Loss 2.4026e+04, Data-loss 2.1176e+04                  , pde-loss 3.5509e-15, initc-loss 6.5036e+04                    bc_loss 5.3778e+06, Test-Loss 2.1176e+04\n",
      "Epoch 8430, Training-Loss 2.3371e+04, Data-loss 2.0898e+04                  , pde-loss 3.7936e-15, initc-loss 6.4730e+04                    bc_loss 5.4172e+06, Test-Loss 2.0898e+04\n",
      "Epoch 8440, Training-Loss 2.2687e+04, Data-loss 2.2425e+04                  , pde-loss 3.9735e-15, initc-loss 6.4426e+04                    bc_loss 5.4567e+06, Test-Loss 2.2425e+04\n",
      "Epoch 8450, Training-Loss 2.1225e+04, Data-loss 2.1980e+04                  , pde-loss 3.8445e-15, initc-loss 6.4121e+04                    bc_loss 5.4965e+06, Test-Loss 2.1980e+04\n",
      "Epoch 8460, Training-Loss 2.2491e+04, Data-loss 2.1972e+04                  , pde-loss 3.5784e-15, initc-loss 6.3818e+04                    bc_loss 5.5362e+06, Test-Loss 2.1972e+04\n",
      "Epoch 8470, Training-Loss 2.2058e+04, Data-loss 2.1579e+04                  , pde-loss 3.6250e-15, initc-loss 6.3518e+04                    bc_loss 5.5760e+06, Test-Loss 2.1579e+04\n",
      "Epoch 8480, Training-Loss 2.2414e+04, Data-loss 2.3039e+04                  , pde-loss 3.7179e-15, initc-loss 6.3218e+04                    bc_loss 5.6158e+06, Test-Loss 2.3039e+04\n",
      "Epoch 8490, Training-Loss 2.1628e+04, Data-loss 2.0504e+04                  , pde-loss 3.7403e-15, initc-loss 6.2919e+04                    bc_loss 5.6558e+06, Test-Loss 2.0504e+04\n",
      "Epoch 8500, Training-Loss 2.2936e+04, Data-loss 2.3952e+04                  , pde-loss 3.4920e-15, initc-loss 6.2622e+04                    bc_loss 5.6957e+06, Test-Loss 2.3952e+04\n",
      "Epoch 8510, Training-Loss 2.1605e+04, Data-loss 2.1935e+04                  , pde-loss 3.5720e-15, initc-loss 6.2325e+04                    bc_loss 5.7358e+06, Test-Loss 2.1935e+04\n",
      "Epoch 8520, Training-Loss 2.1652e+04, Data-loss 2.1646e+04                  , pde-loss 3.5834e-15, initc-loss 6.2033e+04                    bc_loss 5.7756e+06, Test-Loss 2.1646e+04\n",
      "Epoch 8530, Training-Loss 2.2744e+04, Data-loss 2.0526e+04                  , pde-loss 3.5054e-15, initc-loss 6.1741e+04                    bc_loss 5.8156e+06, Test-Loss 2.0526e+04\n",
      "Epoch 8540, Training-Loss 2.0187e+04, Data-loss 1.9208e+04                  , pde-loss 3.7283e-15, initc-loss 6.1449e+04                    bc_loss 5.8559e+06, Test-Loss 1.9208e+04\n",
      "Epoch 8550, Training-Loss 2.0894e+04, Data-loss 1.9759e+04                  , pde-loss 3.9651e-15, initc-loss 6.1156e+04                    bc_loss 5.8963e+06, Test-Loss 1.9759e+04\n",
      "Epoch 8560, Training-Loss 2.0295e+04, Data-loss 2.1198e+04                  , pde-loss 3.8079e-15, initc-loss 6.0866e+04                    bc_loss 5.9368e+06, Test-Loss 2.1198e+04\n",
      "Epoch 8570, Training-Loss 2.1109e+04, Data-loss 1.8929e+04                  , pde-loss 3.5872e-15, initc-loss 6.0574e+04                    bc_loss 5.9776e+06, Test-Loss 1.8929e+04\n",
      "Epoch 8580, Training-Loss 2.0107e+04, Data-loss 1.6977e+04                  , pde-loss 3.8579e-15, initc-loss 6.0286e+04                    bc_loss 6.0183e+06, Test-Loss 1.6977e+04\n",
      "Epoch 8590, Training-Loss 1.9158e+04, Data-loss 1.8699e+04                  , pde-loss 3.7997e-15, initc-loss 5.9999e+04                    bc_loss 6.0590e+06, Test-Loss 1.8699e+04\n",
      "Epoch 8600, Training-Loss 2.2744e+04, Data-loss 1.9632e+04                  , pde-loss 3.3485e-15, initc-loss 5.9715e+04                    bc_loss 6.0993e+06, Test-Loss 1.9632e+04\n",
      "Epoch 8610, Training-Loss 1.8844e+04, Data-loss 1.8810e+04                  , pde-loss 3.8479e-15, initc-loss 5.9431e+04                    bc_loss 6.1400e+06, Test-Loss 1.8810e+04\n",
      "Epoch 8620, Training-Loss 2.0298e+04, Data-loss 1.8832e+04                  , pde-loss 2.9579e-15, initc-loss 5.9145e+04                    bc_loss 6.1812e+06, Test-Loss 1.8832e+04\n",
      "Epoch 8630, Training-Loss 1.8411e+04, Data-loss 1.8579e+04                  , pde-loss 2.7015e-15, initc-loss 5.8863e+04                    bc_loss 6.2222e+06, Test-Loss 1.8579e+04\n",
      "Epoch 8640, Training-Loss 2.1131e+04, Data-loss 1.7505e+04                  , pde-loss 2.1266e-15, initc-loss 5.8582e+04                    bc_loss 6.2632e+06, Test-Loss 1.7505e+04\n",
      "Epoch 8650, Training-Loss 1.7475e+04, Data-loss 1.6659e+04                  , pde-loss 1.8017e-15, initc-loss 5.8300e+04                    bc_loss 6.3045e+06, Test-Loss 1.6659e+04\n",
      "Epoch 8660, Training-Loss 1.9548e+04, Data-loss 1.9140e+04                  , pde-loss 1.2775e-15, initc-loss 5.8020e+04                    bc_loss 6.3458e+06, Test-Loss 1.9140e+04\n",
      "Epoch 8670, Training-Loss 1.9306e+04, Data-loss 2.0152e+04                  , pde-loss 1.0186e-15, initc-loss 5.7743e+04                    bc_loss 6.3869e+06, Test-Loss 2.0152e+04\n",
      "Epoch 8680, Training-Loss 1.8967e+04, Data-loss 1.8597e+04                  , pde-loss 7.0370e-16, initc-loss 5.7467e+04                    bc_loss 6.4280e+06, Test-Loss 1.8597e+04\n",
      "Epoch 8690, Training-Loss 1.8923e+04, Data-loss 1.8771e+04                  , pde-loss 6.2899e-16, initc-loss 5.7192e+04                    bc_loss 6.4693e+06, Test-Loss 1.8771e+04\n",
      "Epoch 8700, Training-Loss 1.9807e+04, Data-loss 1.6277e+04                  , pde-loss 6.7092e-16, initc-loss 5.6917e+04                    bc_loss 6.5108e+06, Test-Loss 1.6277e+04\n",
      "Epoch 8710, Training-Loss 1.7652e+04, Data-loss 1.7683e+04                  , pde-loss 7.0835e-16, initc-loss 5.6642e+04                    bc_loss 6.5526e+06, Test-Loss 1.7683e+04\n",
      "Epoch 8720, Training-Loss 1.8347e+04, Data-loss 1.7882e+04                  , pde-loss 3.1210e-16, initc-loss 5.6370e+04                    bc_loss 6.5941e+06, Test-Loss 1.7882e+04\n",
      "Epoch 8730, Training-Loss 1.8330e+04, Data-loss 1.8659e+04                  , pde-loss 2.3010e-16, initc-loss 5.6098e+04                    bc_loss 6.6357e+06, Test-Loss 1.8659e+04\n",
      "Epoch 8740, Training-Loss 1.9455e+04, Data-loss 1.7670e+04                  , pde-loss 2.4668e-16, initc-loss 5.5826e+04                    bc_loss 6.6776e+06, Test-Loss 1.7670e+04\n",
      "Epoch 8750, Training-Loss 1.7450e+04, Data-loss 1.6841e+04                  , pde-loss 3.2705e-16, initc-loss 5.5554e+04                    bc_loss 6.7199e+06, Test-Loss 1.6841e+04\n",
      "Epoch 8760, Training-Loss 1.7530e+04, Data-loss 1.6638e+04                  , pde-loss 1.3254e-16, initc-loss 5.5283e+04                    bc_loss 6.7622e+06, Test-Loss 1.6638e+04\n",
      "Epoch 8770, Training-Loss 1.9227e+04, Data-loss 1.7862e+04                  , pde-loss 5.0305e-17, initc-loss 5.5015e+04                    bc_loss 6.8041e+06, Test-Loss 1.7862e+04\n",
      "Epoch 8780, Training-Loss 1.6040e+04, Data-loss 1.7183e+04                  , pde-loss 9.1704e-17, initc-loss 5.4750e+04                    bc_loss 6.8460e+06, Test-Loss 1.7183e+04\n",
      "Epoch 8790, Training-Loss 1.7068e+04, Data-loss 1.5871e+04                  , pde-loss 6.3659e-17, initc-loss 5.4485e+04                    bc_loss 6.8880e+06, Test-Loss 1.5871e+04\n",
      "Epoch 8800, Training-Loss 1.7187e+04, Data-loss 1.6636e+04                  , pde-loss 7.9283e-17, initc-loss 5.4221e+04                    bc_loss 6.9300e+06, Test-Loss 1.6636e+04\n",
      "Epoch 8810, Training-Loss 1.6344e+04, Data-loss 1.7150e+04                  , pde-loss 2.1045e-16, initc-loss 5.3959e+04                    bc_loss 6.9721e+06, Test-Loss 1.7150e+04\n",
      "Epoch 8820, Training-Loss 1.8280e+04, Data-loss 1.6654e+04                  , pde-loss 1.3833e-16, initc-loss 5.3698e+04                    bc_loss 7.0141e+06, Test-Loss 1.6654e+04\n",
      "Epoch 8830, Training-Loss 1.7461e+04, Data-loss 1.5123e+04                  , pde-loss 1.8928e-16, initc-loss 5.3436e+04                    bc_loss 7.0567e+06, Test-Loss 1.5123e+04\n",
      "Epoch 8840, Training-Loss 1.7022e+04, Data-loss 1.5299e+04                  , pde-loss 3.2739e-16, initc-loss 5.3175e+04                    bc_loss 7.0992e+06, Test-Loss 1.5299e+04\n",
      "Epoch 8850, Training-Loss 1.5192e+04, Data-loss 1.7377e+04                  , pde-loss 1.9621e-16, initc-loss 5.2918e+04                    bc_loss 7.1413e+06, Test-Loss 1.7377e+04\n",
      "Epoch 8860, Training-Loss 1.5810e+04, Data-loss 1.6355e+04                  , pde-loss 8.0653e-17, initc-loss 5.2662e+04                    bc_loss 7.1834e+06, Test-Loss 1.6355e+04\n",
      "Epoch 8870, Training-Loss 1.6307e+04, Data-loss 1.5177e+04                  , pde-loss 1.9448e-16, initc-loss 5.2407e+04                    bc_loss 7.2257e+06, Test-Loss 1.5177e+04\n",
      "Epoch 8880, Training-Loss 1.5875e+04, Data-loss 1.5507e+04                  , pde-loss 1.3915e-16, initc-loss 5.2151e+04                    bc_loss 7.2682e+06, Test-Loss 1.5507e+04\n",
      "Epoch 8890, Training-Loss 1.4335e+04, Data-loss 1.4520e+04                  , pde-loss 6.5302e-17, initc-loss 5.1898e+04                    bc_loss 7.3106e+06, Test-Loss 1.4520e+04\n",
      "Epoch 8900, Training-Loss 1.6573e+04, Data-loss 1.4277e+04                  , pde-loss 8.5364e-17, initc-loss 5.1646e+04                    bc_loss 7.3531e+06, Test-Loss 1.4277e+04\n",
      "Epoch 8910, Training-Loss 1.6285e+04, Data-loss 1.4469e+04                  , pde-loss 1.6199e-16, initc-loss 5.1393e+04                    bc_loss 7.3959e+06, Test-Loss 1.4469e+04\n",
      "Epoch 8920, Training-Loss 1.6163e+04, Data-loss 1.5246e+04                  , pde-loss 4.1188e-17, initc-loss 5.1142e+04                    bc_loss 7.4386e+06, Test-Loss 1.5246e+04\n",
      "Epoch 8930, Training-Loss 1.4887e+04, Data-loss 1.4605e+04                  , pde-loss 6.0472e-17, initc-loss 5.0890e+04                    bc_loss 7.4816e+06, Test-Loss 1.4605e+04\n",
      "Epoch 8940, Training-Loss 1.5903e+04, Data-loss 1.3984e+04                  , pde-loss 4.2122e-17, initc-loss 5.0640e+04                    bc_loss 7.5246e+06, Test-Loss 1.3984e+04\n",
      "Epoch 8950, Training-Loss 1.5133e+04, Data-loss 1.4421e+04                  , pde-loss 7.6500e-17, initc-loss 5.0392e+04                    bc_loss 7.5675e+06, Test-Loss 1.4421e+04\n",
      "Epoch 8960, Training-Loss 1.6006e+04, Data-loss 1.4866e+04                  , pde-loss 0.0000e+00, initc-loss 5.0146e+04                    bc_loss 7.6102e+06, Test-Loss 1.4866e+04\n",
      "Epoch 8970, Training-Loss 1.4940e+04, Data-loss 1.3268e+04                  , pde-loss 7.6441e-17, initc-loss 4.9901e+04                    bc_loss 7.6531e+06, Test-Loss 1.3268e+04\n",
      "Epoch 8980, Training-Loss 1.4314e+04, Data-loss 1.4681e+04                  , pde-loss 0.0000e+00, initc-loss 4.9657e+04                    bc_loss 7.6959e+06, Test-Loss 1.4681e+04\n",
      "Epoch 8990, Training-Loss 1.4861e+04, Data-loss 1.5137e+04                  , pde-loss 4.1997e-17, initc-loss 4.9416e+04                    bc_loss 7.7385e+06, Test-Loss 1.5137e+04\n",
      "Epoch 9000, Training-Loss 1.5508e+04, Data-loss 1.2655e+04                  , pde-loss 4.1833e-17, initc-loss 4.9175e+04                    bc_loss 7.7811e+06, Test-Loss 1.2655e+04\n",
      "Epoch 9010, Training-Loss 1.2793e+04, Data-loss 1.3856e+04                  , pde-loss 8.1859e-17, initc-loss 4.8933e+04                    bc_loss 7.8243e+06, Test-Loss 1.3856e+04\n",
      "Epoch 9020, Training-Loss 1.3108e+04, Data-loss 1.3166e+04                  , pde-loss 1.4126e-16, initc-loss 4.8694e+04                    bc_loss 7.8672e+06, Test-Loss 1.3166e+04\n",
      "Epoch 9030, Training-Loss 1.4401e+04, Data-loss 1.2701e+04                  , pde-loss 3.9706e-17, initc-loss 4.8454e+04                    bc_loss 7.9104e+06, Test-Loss 1.2701e+04\n",
      "Epoch 9040, Training-Loss 1.4327e+04, Data-loss 1.3233e+04                  , pde-loss 0.0000e+00, initc-loss 4.8216e+04                    bc_loss 7.9535e+06, Test-Loss 1.3233e+04\n",
      "Epoch 9050, Training-Loss 1.4127e+04, Data-loss 1.3522e+04                  , pde-loss 5.2376e-17, initc-loss 4.7979e+04                    bc_loss 7.9968e+06, Test-Loss 1.3522e+04\n",
      "Epoch 9060, Training-Loss 1.3971e+04, Data-loss 1.3112e+04                  , pde-loss 0.0000e+00, initc-loss 4.7743e+04                    bc_loss 8.0398e+06, Test-Loss 1.3112e+04\n",
      "Epoch 9070, Training-Loss 1.2492e+04, Data-loss 1.2452e+04                  , pde-loss 1.5500e-16, initc-loss 4.7507e+04                    bc_loss 8.0833e+06, Test-Loss 1.2452e+04\n",
      "Epoch 9080, Training-Loss 1.4500e+04, Data-loss 1.2280e+04                  , pde-loss 5.6520e-17, initc-loss 4.7274e+04                    bc_loss 8.1264e+06, Test-Loss 1.2280e+04\n",
      "Epoch 9090, Training-Loss 1.4906e+04, Data-loss 1.1372e+04                  , pde-loss 4.7539e-17, initc-loss 4.7042e+04                    bc_loss 8.1696e+06, Test-Loss 1.1372e+04\n",
      "Epoch 9100, Training-Loss 1.4056e+04, Data-loss 1.2025e+04                  , pde-loss 0.0000e+00, initc-loss 4.6811e+04                    bc_loss 8.2128e+06, Test-Loss 1.2025e+04\n",
      "Epoch 9110, Training-Loss 1.3675e+04, Data-loss 1.3138e+04                  , pde-loss 2.5992e-17, initc-loss 4.6579e+04                    bc_loss 8.2563e+06, Test-Loss 1.3138e+04\n",
      "Epoch 9120, Training-Loss 1.3329e+04, Data-loss 1.1886e+04                  , pde-loss 0.0000e+00, initc-loss 4.6348e+04                    bc_loss 8.2998e+06, Test-Loss 1.1886e+04\n",
      "Epoch 9130, Training-Loss 1.3516e+04, Data-loss 1.2241e+04                  , pde-loss 2.6485e-18, initc-loss 4.6119e+04                    bc_loss 8.3433e+06, Test-Loss 1.2241e+04\n",
      "Epoch 9140, Training-Loss 1.4056e+04, Data-loss 1.3085e+04                  , pde-loss 0.0000e+00, initc-loss 4.5892e+04                    bc_loss 8.3867e+06, Test-Loss 1.3085e+04\n",
      "Epoch 9150, Training-Loss 1.2568e+04, Data-loss 1.1998e+04                  , pde-loss 0.0000e+00, initc-loss 4.5663e+04                    bc_loss 8.4304e+06, Test-Loss 1.1998e+04\n",
      "Epoch 9160, Training-Loss 1.3287e+04, Data-loss 1.1587e+04                  , pde-loss 4.2211e-17, initc-loss 4.5437e+04                    bc_loss 8.4741e+06, Test-Loss 1.1587e+04\n",
      "Epoch 9170, Training-Loss 1.1534e+04, Data-loss 1.2751e+04                  , pde-loss 0.0000e+00, initc-loss 4.5212e+04                    bc_loss 8.5176e+06, Test-Loss 1.2751e+04\n",
      "Epoch 9180, Training-Loss 1.3009e+04, Data-loss 1.1328e+04                  , pde-loss 9.9570e-18, initc-loss 4.4988e+04                    bc_loss 8.5613e+06, Test-Loss 1.1328e+04\n",
      "Epoch 9190, Training-Loss 1.2284e+04, Data-loss 1.2131e+04                  , pde-loss 3.7400e-17, initc-loss 4.4765e+04                    bc_loss 8.6049e+06, Test-Loss 1.2131e+04\n",
      "Epoch 9200, Training-Loss 1.3425e+04, Data-loss 1.1549e+04                  , pde-loss 0.0000e+00, initc-loss 4.4543e+04                    bc_loss 8.6484e+06, Test-Loss 1.1549e+04\n",
      "Epoch 9210, Training-Loss 1.2863e+04, Data-loss 1.1598e+04                  , pde-loss 0.0000e+00, initc-loss 4.4321e+04                    bc_loss 8.6923e+06, Test-Loss 1.1598e+04\n",
      "Epoch 9220, Training-Loss 1.3386e+04, Data-loss 1.0254e+04                  , pde-loss 4.1444e-17, initc-loss 4.4099e+04                    bc_loss 8.7364e+06, Test-Loss 1.0254e+04\n",
      "Epoch 9230, Training-Loss 1.1014e+04, Data-loss 1.0636e+04                  , pde-loss 0.0000e+00, initc-loss 4.3878e+04                    bc_loss 8.7805e+06, Test-Loss 1.0636e+04\n",
      "Epoch 9240, Training-Loss 1.2293e+04, Data-loss 1.1343e+04                  , pde-loss 3.9958e-17, initc-loss 4.3659e+04                    bc_loss 8.8244e+06, Test-Loss 1.1343e+04\n",
      "Epoch 9250, Training-Loss 1.1928e+04, Data-loss 1.1408e+04                  , pde-loss 0.0000e+00, initc-loss 4.3443e+04                    bc_loss 8.8681e+06, Test-Loss 1.1408e+04\n",
      "Epoch 9260, Training-Loss 1.1496e+04, Data-loss 1.0300e+04                  , pde-loss 6.8840e-17, initc-loss 4.3226e+04                    bc_loss 8.9119e+06, Test-Loss 1.0300e+04\n",
      "Epoch 9270, Training-Loss 1.0498e+04, Data-loss 1.0389e+04                  , pde-loss 1.0463e-17, initc-loss 4.3011e+04                    bc_loss 8.9556e+06, Test-Loss 1.0389e+04\n",
      "Epoch 9280, Training-Loss 1.1302e+04, Data-loss 1.0484e+04                  , pde-loss 0.0000e+00, initc-loss 4.2800e+04                    bc_loss 8.9989e+06, Test-Loss 1.0484e+04\n",
      "Epoch 9290, Training-Loss 1.3780e+04, Data-loss 1.0218e+04                  , pde-loss 0.0000e+00, initc-loss 4.2587e+04                    bc_loss 9.0425e+06, Test-Loss 1.0218e+04\n",
      "Epoch 9300, Training-Loss 1.1513e+04, Data-loss 1.0601e+04                  , pde-loss 0.0000e+00, initc-loss 4.2376e+04                    bc_loss 9.0863e+06, Test-Loss 1.0601e+04\n",
      "Epoch 9310, Training-Loss 1.2340e+04, Data-loss 1.0904e+04                  , pde-loss 0.0000e+00, initc-loss 4.2168e+04                    bc_loss 9.1295e+06, Test-Loss 1.0904e+04\n",
      "Epoch 9320, Training-Loss 1.1285e+04, Data-loss 9.3471e+03                  , pde-loss 0.0000e+00, initc-loss 4.1959e+04                    bc_loss 9.1730e+06, Test-Loss 9.3471e+03\n",
      "Epoch 9330, Training-Loss 1.1664e+04, Data-loss 1.0547e+04                  , pde-loss 0.0000e+00, initc-loss 4.1750e+04                    bc_loss 9.2167e+06, Test-Loss 1.0547e+04\n",
      "Epoch 9340, Training-Loss 1.2026e+04, Data-loss 1.0256e+04                  , pde-loss 0.0000e+00, initc-loss 4.1542e+04                    bc_loss 9.2607e+06, Test-Loss 1.0256e+04\n",
      "Epoch 9350, Training-Loss 1.0864e+04, Data-loss 1.0125e+04                  , pde-loss 4.4042e-17, initc-loss 4.1333e+04                    bc_loss 9.3048e+06, Test-Loss 1.0125e+04\n",
      "Epoch 9360, Training-Loss 1.0327e+04, Data-loss 9.3637e+03                  , pde-loss 0.0000e+00, initc-loss 4.1126e+04                    bc_loss 9.3490e+06, Test-Loss 9.3637e+03\n",
      "Epoch 9370, Training-Loss 1.0959e+04, Data-loss 8.9688e+03                  , pde-loss 0.0000e+00, initc-loss 4.0923e+04                    bc_loss 9.3924e+06, Test-Loss 8.9688e+03\n",
      "Epoch 9380, Training-Loss 1.0429e+04, Data-loss 1.0032e+04                  , pde-loss 9.4251e-17, initc-loss 4.0719e+04                    bc_loss 9.4361e+06, Test-Loss 1.0032e+04\n",
      "Epoch 9390, Training-Loss 1.2114e+04, Data-loss 1.0166e+04                  , pde-loss 0.0000e+00, initc-loss 4.0517e+04                    bc_loss 9.4796e+06, Test-Loss 1.0166e+04\n",
      "Epoch 9400, Training-Loss 9.6587e+03, Data-loss 1.0202e+04                  , pde-loss 1.1492e-16, initc-loss 4.0314e+04                    bc_loss 9.5236e+06, Test-Loss 1.0202e+04\n",
      "Epoch 9410, Training-Loss 1.0951e+04, Data-loss 9.2803e+03                  , pde-loss 0.0000e+00, initc-loss 4.0114e+04                    bc_loss 9.5672e+06, Test-Loss 9.2803e+03\n",
      "Epoch 9420, Training-Loss 1.0716e+04, Data-loss 8.1656e+03                  , pde-loss 3.6564e-17, initc-loss 3.9915e+04                    bc_loss 9.6108e+06, Test-Loss 8.1656e+03\n",
      "Epoch 9430, Training-Loss 1.1520e+04, Data-loss 9.8086e+03                  , pde-loss 4.3758e-17, initc-loss 3.9715e+04                    bc_loss 9.6549e+06, Test-Loss 9.8086e+03\n",
      "Epoch 9440, Training-Loss 1.0900e+04, Data-loss 9.3141e+03                  , pde-loss 4.2346e-17, initc-loss 3.9515e+04                    bc_loss 9.6990e+06, Test-Loss 9.3141e+03\n",
      "Epoch 9450, Training-Loss 1.0318e+04, Data-loss 9.3177e+03                  , pde-loss 0.0000e+00, initc-loss 3.9317e+04                    bc_loss 9.7430e+06, Test-Loss 9.3177e+03\n",
      "Epoch 9460, Training-Loss 9.0248e+03, Data-loss 9.0811e+03                  , pde-loss 0.0000e+00, initc-loss 3.9119e+04                    bc_loss 9.7871e+06, Test-Loss 9.0811e+03\n",
      "Epoch 9470, Training-Loss 1.0243e+04, Data-loss 8.3065e+03                  , pde-loss 4.4897e-17, initc-loss 3.8926e+04                    bc_loss 9.8305e+06, Test-Loss 8.3065e+03\n",
      "Epoch 9480, Training-Loss 1.0990e+04, Data-loss 8.4008e+03                  , pde-loss 0.0000e+00, initc-loss 3.8732e+04                    bc_loss 9.8741e+06, Test-Loss 8.4008e+03\n",
      "Epoch 9490, Training-Loss 9.2799e+03, Data-loss 8.7143e+03                  , pde-loss 2.3339e-17, initc-loss 3.8539e+04                    bc_loss 9.9179e+06, Test-Loss 8.7143e+03\n",
      "Epoch 9500, Training-Loss 1.0008e+04, Data-loss 9.7983e+03                  , pde-loss 4.3359e-17, initc-loss 3.8347e+04                    bc_loss 9.9616e+06, Test-Loss 9.7983e+03\n",
      "Epoch 9510, Training-Loss 9.6187e+03, Data-loss 9.4990e+03                  , pde-loss 0.0000e+00, initc-loss 3.8152e+04                    bc_loss 1.0006e+07, Test-Loss 9.4990e+03\n",
      "Epoch 9520, Training-Loss 9.5222e+03, Data-loss 8.9645e+03                  , pde-loss 3.9754e-17, initc-loss 3.7961e+04                    bc_loss 1.0050e+07, Test-Loss 8.9645e+03\n",
      "Epoch 9530, Training-Loss 1.1050e+04, Data-loss 9.1602e+03                  , pde-loss 2.1765e-16, initc-loss 3.7771e+04                    bc_loss 1.0094e+07, Test-Loss 9.1602e+03\n",
      "Epoch 9540, Training-Loss 9.3898e+03, Data-loss 8.2626e+03                  , pde-loss 8.0855e-17, initc-loss 3.7581e+04                    bc_loss 1.0138e+07, Test-Loss 8.2626e+03\n",
      "Epoch 9550, Training-Loss 9.2796e+03, Data-loss 8.4082e+03                  , pde-loss 0.0000e+00, initc-loss 3.7393e+04                    bc_loss 1.0182e+07, Test-Loss 8.4082e+03\n",
      "Epoch 9560, Training-Loss 8.9876e+03, Data-loss 7.1759e+03                  , pde-loss 0.0000e+00, initc-loss 3.7206e+04                    bc_loss 1.0225e+07, Test-Loss 7.1759e+03\n",
      "Epoch 9570, Training-Loss 8.3652e+03, Data-loss 8.1796e+03                  , pde-loss 1.9411e-16, initc-loss 3.7020e+04                    bc_loss 1.0269e+07, Test-Loss 8.1796e+03\n",
      "Epoch 9580, Training-Loss 8.0137e+03, Data-loss 8.6231e+03                  , pde-loss 6.2646e-17, initc-loss 3.6835e+04                    bc_loss 1.0313e+07, Test-Loss 8.6231e+03\n",
      "Epoch 9590, Training-Loss 8.7423e+03, Data-loss 9.1941e+03                  , pde-loss 0.0000e+00, initc-loss 3.6651e+04                    bc_loss 1.0356e+07, Test-Loss 9.1941e+03\n",
      "Epoch 9600, Training-Loss 7.8411e+03, Data-loss 8.0764e+03                  , pde-loss 4.3791e-17, initc-loss 3.6469e+04                    bc_loss 1.0400e+07, Test-Loss 8.0764e+03\n",
      "Epoch 9610, Training-Loss 7.5228e+03, Data-loss 8.6882e+03                  , pde-loss 0.0000e+00, initc-loss 3.6287e+04                    bc_loss 1.0443e+07, Test-Loss 8.6882e+03\n",
      "Epoch 9620, Training-Loss 1.0869e+04, Data-loss 6.5809e+03                  , pde-loss 0.0000e+00, initc-loss 3.6107e+04                    bc_loss 1.0486e+07, Test-Loss 6.5809e+03\n",
      "Epoch 9630, Training-Loss 9.0836e+03, Data-loss 7.1101e+03                  , pde-loss 0.0000e+00, initc-loss 3.5927e+04                    bc_loss 1.0530e+07, Test-Loss 7.1101e+03\n",
      "Epoch 9640, Training-Loss 8.2827e+03, Data-loss 6.7188e+03                  , pde-loss 0.0000e+00, initc-loss 3.5746e+04                    bc_loss 1.0574e+07, Test-Loss 6.7188e+03\n",
      "Epoch 9650, Training-Loss 9.3145e+03, Data-loss 7.5059e+03                  , pde-loss 3.6330e-17, initc-loss 3.5567e+04                    bc_loss 1.0618e+07, Test-Loss 7.5059e+03\n",
      "Epoch 9660, Training-Loss 8.1164e+03, Data-loss 7.0552e+03                  , pde-loss 0.0000e+00, initc-loss 3.5387e+04                    bc_loss 1.0662e+07, Test-Loss 7.0552e+03\n",
      "Epoch 9670, Training-Loss 1.0085e+04, Data-loss 8.0199e+03                  , pde-loss 5.6066e-17, initc-loss 3.5210e+04                    bc_loss 1.0705e+07, Test-Loss 8.0199e+03\n",
      "Epoch 9680, Training-Loss 9.0689e+03, Data-loss 7.2629e+03                  , pde-loss 1.4309e-16, initc-loss 3.5034e+04                    bc_loss 1.0749e+07, Test-Loss 7.2629e+03\n",
      "Epoch 9690, Training-Loss 8.3209e+03, Data-loss 8.6341e+03                  , pde-loss 1.1181e-16, initc-loss 3.4859e+04                    bc_loss 1.0792e+07, Test-Loss 8.6341e+03\n",
      "Epoch 9700, Training-Loss 7.8037e+03, Data-loss 6.7310e+03                  , pde-loss 0.0000e+00, initc-loss 3.4686e+04                    bc_loss 1.0835e+07, Test-Loss 6.7310e+03\n",
      "Epoch 9710, Training-Loss 8.1400e+03, Data-loss 6.5625e+03                  , pde-loss 4.2170e-17, initc-loss 3.4513e+04                    bc_loss 1.0879e+07, Test-Loss 6.5625e+03\n",
      "Epoch 9720, Training-Loss 8.4496e+03, Data-loss 7.7357e+03                  , pde-loss 4.2815e-17, initc-loss 3.4339e+04                    bc_loss 1.0922e+07, Test-Loss 7.7357e+03\n",
      "Epoch 9730, Training-Loss 8.0365e+03, Data-loss 7.8822e+03                  , pde-loss 0.0000e+00, initc-loss 3.4169e+04                    bc_loss 1.0965e+07, Test-Loss 7.8822e+03\n",
      "Epoch 9740, Training-Loss 7.7307e+03, Data-loss 6.8673e+03                  , pde-loss 1.8708e-16, initc-loss 3.3999e+04                    bc_loss 1.1009e+07, Test-Loss 6.8673e+03\n",
      "Epoch 9750, Training-Loss 8.9569e+03, Data-loss 7.2760e+03                  , pde-loss 3.6703e-17, initc-loss 3.3830e+04                    bc_loss 1.1052e+07, Test-Loss 7.2760e+03\n",
      "Epoch 9760, Training-Loss 7.8034e+03, Data-loss 6.9602e+03                  , pde-loss 6.2079e-17, initc-loss 3.3661e+04                    bc_loss 1.1095e+07, Test-Loss 6.9602e+03\n",
      "Epoch 9770, Training-Loss 7.8399e+03, Data-loss 6.8808e+03                  , pde-loss 6.0402e-17, initc-loss 3.3494e+04                    bc_loss 1.1138e+07, Test-Loss 6.8808e+03\n",
      "Epoch 9780, Training-Loss 8.0565e+03, Data-loss 5.9916e+03                  , pde-loss 6.0080e-17, initc-loss 3.3328e+04                    bc_loss 1.1181e+07, Test-Loss 5.9916e+03\n",
      "Epoch 9790, Training-Loss 8.1601e+03, Data-loss 5.3630e+03                  , pde-loss 0.0000e+00, initc-loss 3.3161e+04                    bc_loss 1.1224e+07, Test-Loss 5.3630e+03\n",
      "Epoch 9800, Training-Loss 8.1436e+03, Data-loss 6.7786e+03                  , pde-loss 3.6988e-17, initc-loss 3.2996e+04                    bc_loss 1.1267e+07, Test-Loss 6.7786e+03\n",
      "Epoch 9810, Training-Loss 8.0502e+03, Data-loss 5.5827e+03                  , pde-loss 4.7065e-17, initc-loss 3.2833e+04                    bc_loss 1.1310e+07, Test-Loss 5.5827e+03\n",
      "Epoch 9820, Training-Loss 7.7821e+03, Data-loss 6.5556e+03                  , pde-loss 2.6939e-18, initc-loss 3.2672e+04                    bc_loss 1.1352e+07, Test-Loss 6.5556e+03\n",
      "Epoch 9830, Training-Loss 6.9770e+03, Data-loss 6.5064e+03                  , pde-loss 4.4921e-17, initc-loss 3.2512e+04                    bc_loss 1.1394e+07, Test-Loss 6.5064e+03\n",
      "Epoch 9840, Training-Loss 7.1474e+03, Data-loss 5.9417e+03                  , pde-loss 0.0000e+00, initc-loss 3.2353e+04                    bc_loss 1.1437e+07, Test-Loss 5.9417e+03\n",
      "Epoch 9850, Training-Loss 8.1207e+03, Data-loss 6.2942e+03                  , pde-loss 2.7035e-18, initc-loss 3.2193e+04                    bc_loss 1.1479e+07, Test-Loss 6.2942e+03\n",
      "Epoch 9860, Training-Loss 5.9832e+03, Data-loss 5.1325e+03                  , pde-loss 0.0000e+00, initc-loss 3.2032e+04                    bc_loss 1.1522e+07, Test-Loss 5.1325e+03\n",
      "Epoch 9870, Training-Loss 6.9910e+03, Data-loss 6.3873e+03                  , pde-loss 0.0000e+00, initc-loss 3.1875e+04                    bc_loss 1.1565e+07, Test-Loss 6.3873e+03\n",
      "Epoch 9880, Training-Loss 6.5396e+03, Data-loss 5.8161e+03                  , pde-loss 4.6734e-17, initc-loss 3.1717e+04                    bc_loss 1.1607e+07, Test-Loss 5.8161e+03\n",
      "Epoch 9890, Training-Loss 7.2562e+03, Data-loss 5.8169e+03                  , pde-loss 5.9093e-17, initc-loss 3.1561e+04                    bc_loss 1.1650e+07, Test-Loss 5.8169e+03\n",
      "Epoch 9900, Training-Loss 6.7242e+03, Data-loss 7.0609e+03                  , pde-loss 0.0000e+00, initc-loss 3.1407e+04                    bc_loss 1.1692e+07, Test-Loss 7.0609e+03\n",
      "Epoch 9910, Training-Loss 6.8306e+03, Data-loss 6.8230e+03                  , pde-loss 1.1298e-16, initc-loss 3.1253e+04                    bc_loss 1.1734e+07, Test-Loss 6.8230e+03\n",
      "Epoch 9920, Training-Loss 7.1440e+03, Data-loss 6.1945e+03                  , pde-loss 2.5318e-18, initc-loss 3.1100e+04                    bc_loss 1.1776e+07, Test-Loss 6.1945e+03\n",
      "Epoch 9930, Training-Loss 6.0809e+03, Data-loss 5.8843e+03                  , pde-loss 1.1993e-17, initc-loss 3.0946e+04                    bc_loss 1.1818e+07, Test-Loss 5.8843e+03\n",
      "Epoch 9940, Training-Loss 7.2724e+03, Data-loss 6.4069e+03                  , pde-loss 0.0000e+00, initc-loss 3.0795e+04                    bc_loss 1.1860e+07, Test-Loss 6.4069e+03\n",
      "Epoch 9950, Training-Loss 6.7051e+03, Data-loss 6.0766e+03                  , pde-loss 0.0000e+00, initc-loss 3.0644e+04                    bc_loss 1.1902e+07, Test-Loss 6.0766e+03\n",
      "Epoch 9960, Training-Loss 6.9970e+03, Data-loss 5.4150e+03                  , pde-loss 6.5585e-17, initc-loss 3.0496e+04                    bc_loss 1.1943e+07, Test-Loss 5.4150e+03\n",
      "Epoch 9970, Training-Loss 6.8149e+03, Data-loss 5.1532e+03                  , pde-loss 5.1174e-17, initc-loss 3.0348e+04                    bc_loss 1.1985e+07, Test-Loss 5.1532e+03\n",
      "Epoch 9980, Training-Loss 8.4325e+03, Data-loss 6.0946e+03                  , pde-loss 1.2864e-16, initc-loss 3.0201e+04                    bc_loss 1.2026e+07, Test-Loss 6.0946e+03\n",
      "Epoch 9990, Training-Loss 6.0240e+03, Data-loss 5.1730e+03                  , pde-loss 5.2127e-17, initc-loss 3.0050e+04                    bc_loss 1.2069e+07, Test-Loss 5.1730e+03\n",
      "Epoch 10000, Training-Loss 6.4257e+03, Data-loss 5.1996e+03                  , pde-loss 0.0000e+00, initc-loss 2.9901e+04                    bc_loss 1.2111e+07, Test-Loss 5.1996e+03\n",
      "Epoch 10010, Training-Loss 5.6704e+03, Data-loss 5.9804e+03                  , pde-loss 0.0000e+00, initc-loss 2.9755e+04                    bc_loss 1.2153e+07, Test-Loss 5.9804e+03\n",
      "Epoch 10020, Training-Loss 5.7945e+03, Data-loss 5.0277e+03                  , pde-loss 0.0000e+00, initc-loss 2.9612e+04                    bc_loss 1.2194e+07, Test-Loss 5.0277e+03\n",
      "Epoch 10030, Training-Loss 5.1860e+03, Data-loss 4.0140e+03                  , pde-loss 9.8241e-17, initc-loss 2.9468e+04                    bc_loss 1.2235e+07, Test-Loss 4.0140e+03\n",
      "Epoch 10040, Training-Loss 6.0154e+03, Data-loss 5.3750e+03                  , pde-loss 8.6962e-17, initc-loss 2.9324e+04                    bc_loss 1.2277e+07, Test-Loss 5.3750e+03\n",
      "Epoch 10050, Training-Loss 6.2980e+03, Data-loss 5.9092e+03                  , pde-loss 3.9626e-17, initc-loss 2.9180e+04                    bc_loss 1.2318e+07, Test-Loss 5.9092e+03\n",
      "Epoch 10060, Training-Loss 5.9882e+03, Data-loss 5.4718e+03                  , pde-loss 2.4722e-18, initc-loss 2.9035e+04                    bc_loss 1.2361e+07, Test-Loss 5.4718e+03\n",
      "Epoch 10070, Training-Loss 6.5545e+03, Data-loss 4.3087e+03                  , pde-loss 0.0000e+00, initc-loss 2.8892e+04                    bc_loss 1.2402e+07, Test-Loss 4.3087e+03\n",
      "Epoch 10080, Training-Loss 6.1505e+03, Data-loss 4.8583e+03                  , pde-loss 5.3969e-17, initc-loss 2.8750e+04                    bc_loss 1.2444e+07, Test-Loss 4.8583e+03\n",
      "Epoch 10090, Training-Loss 5.6313e+03, Data-loss 5.2832e+03                  , pde-loss 1.8552e-16, initc-loss 2.8609e+04                    bc_loss 1.2486e+07, Test-Loss 5.2832e+03\n",
      "Epoch 10100, Training-Loss 6.1748e+03, Data-loss 5.0296e+03                  , pde-loss 4.6046e-17, initc-loss 2.8472e+04                    bc_loss 1.2526e+07, Test-Loss 5.0296e+03\n",
      "Epoch 10110, Training-Loss 5.5844e+03, Data-loss 4.7282e+03                  , pde-loss 1.7917e-16, initc-loss 2.8334e+04                    bc_loss 1.2567e+07, Test-Loss 4.7282e+03\n",
      "Epoch 10120, Training-Loss 6.0748e+03, Data-loss 4.8384e+03                  , pde-loss 6.1288e-17, initc-loss 2.8197e+04                    bc_loss 1.2608e+07, Test-Loss 4.8384e+03\n",
      "Epoch 10130, Training-Loss 5.9080e+03, Data-loss 5.6198e+03                  , pde-loss 1.4003e-16, initc-loss 2.8061e+04                    bc_loss 1.2649e+07, Test-Loss 5.6198e+03\n",
      "Epoch 10140, Training-Loss 5.3949e+03, Data-loss 4.4671e+03                  , pde-loss 1.4124e-16, initc-loss 2.7926e+04                    bc_loss 1.2690e+07, Test-Loss 4.4671e+03\n",
      "Epoch 10150, Training-Loss 5.4623e+03, Data-loss 4.0739e+03                  , pde-loss 2.1697e-16, initc-loss 2.7795e+04                    bc_loss 1.2729e+07, Test-Loss 4.0739e+03\n",
      "Epoch 10160, Training-Loss 6.6195e+03, Data-loss 4.8937e+03                  , pde-loss 8.8399e-18, initc-loss 2.7664e+04                    bc_loss 1.2769e+07, Test-Loss 4.8937e+03\n",
      "Epoch 10170, Training-Loss 5.9673e+03, Data-loss 4.6795e+03                  , pde-loss 1.4258e-16, initc-loss 2.7529e+04                    bc_loss 1.2810e+07, Test-Loss 4.6795e+03\n",
      "Epoch 10180, Training-Loss 5.4656e+03, Data-loss 4.2789e+03                  , pde-loss 2.7844e-16, initc-loss 2.7398e+04                    bc_loss 1.2850e+07, Test-Loss 4.2789e+03\n",
      "Epoch 10190, Training-Loss 6.3897e+03, Data-loss 5.7075e+03                  , pde-loss 5.4453e-17, initc-loss 2.7268e+04                    bc_loss 1.2890e+07, Test-Loss 5.7075e+03\n",
      "Epoch 10200, Training-Loss 5.4797e+03, Data-loss 4.9568e+03                  , pde-loss 2.6716e-16, initc-loss 2.7140e+04                    bc_loss 1.2929e+07, Test-Loss 4.9568e+03\n",
      "Epoch 10210, Training-Loss 5.3647e+03, Data-loss 4.5382e+03                  , pde-loss 2.0450e-16, initc-loss 2.7013e+04                    bc_loss 1.2969e+07, Test-Loss 4.5382e+03\n",
      "Epoch 10220, Training-Loss 5.3348e+03, Data-loss 3.7077e+03                  , pde-loss 5.1234e-16, initc-loss 2.6887e+04                    bc_loss 1.3008e+07, Test-Loss 3.7077e+03\n",
      "Epoch 10230, Training-Loss 6.8078e+03, Data-loss 4.2237e+03                  , pde-loss 3.4053e-16, initc-loss 2.6761e+04                    bc_loss 1.3047e+07, Test-Loss 4.2237e+03\n",
      "Epoch 10240, Training-Loss 5.3058e+03, Data-loss 4.1565e+03                  , pde-loss 4.4982e-16, initc-loss 2.6635e+04                    bc_loss 1.3087e+07, Test-Loss 4.1565e+03\n",
      "Epoch 10250, Training-Loss 5.8896e+03, Data-loss 3.2693e+03                  , pde-loss 2.0348e-16, initc-loss 2.6510e+04                    bc_loss 1.3126e+07, Test-Loss 3.2693e+03\n",
      "Epoch 10260, Training-Loss 5.4621e+03, Data-loss 3.8127e+03                  , pde-loss 3.6281e-16, initc-loss 2.6384e+04                    bc_loss 1.3166e+07, Test-Loss 3.8127e+03\n",
      "Epoch 10270, Training-Loss 4.7888e+03, Data-loss 4.3457e+03                  , pde-loss 4.4859e-16, initc-loss 2.6257e+04                    bc_loss 1.3206e+07, Test-Loss 4.3457e+03\n",
      "Epoch 10280, Training-Loss 4.7500e+03, Data-loss 4.7898e+03                  , pde-loss 3.6691e-16, initc-loss 2.6134e+04                    bc_loss 1.3245e+07, Test-Loss 4.7898e+03\n",
      "Epoch 10290, Training-Loss 5.1463e+03, Data-loss 4.5864e+03                  , pde-loss 8.1852e-16, initc-loss 2.6014e+04                    bc_loss 1.3283e+07, Test-Loss 4.5864e+03\n",
      "Epoch 10300, Training-Loss 5.0186e+03, Data-loss 3.0707e+03                  , pde-loss 4.5921e-16, initc-loss 2.5894e+04                    bc_loss 1.3321e+07, Test-Loss 3.0707e+03\n",
      "Epoch 10310, Training-Loss 5.1198e+03, Data-loss 3.9849e+03                  , pde-loss 9.2866e-16, initc-loss 2.5775e+04                    bc_loss 1.3360e+07, Test-Loss 3.9849e+03\n",
      "Epoch 10320, Training-Loss 5.0893e+03, Data-loss 4.0827e+03                  , pde-loss 7.5222e-16, initc-loss 2.5658e+04                    bc_loss 1.3397e+07, Test-Loss 4.0827e+03\n",
      "Epoch 10330, Training-Loss 5.2185e+03, Data-loss 4.3038e+03                  , pde-loss 9.2582e-16, initc-loss 2.5541e+04                    bc_loss 1.3435e+07, Test-Loss 4.3038e+03\n",
      "Epoch 10340, Training-Loss 6.0627e+03, Data-loss 3.2194e+03                  , pde-loss 5.9419e-16, initc-loss 2.5422e+04                    bc_loss 1.3474e+07, Test-Loss 3.2194e+03\n",
      "Epoch 10350, Training-Loss 4.8991e+03, Data-loss 3.6403e+03                  , pde-loss 9.8109e-16, initc-loss 2.5303e+04                    bc_loss 1.3513e+07, Test-Loss 3.6403e+03\n",
      "Epoch 10360, Training-Loss 5.1576e+03, Data-loss 4.2141e+03                  , pde-loss 9.8454e-16, initc-loss 2.5187e+04                    bc_loss 1.3551e+07, Test-Loss 4.2141e+03\n",
      "Epoch 10370, Training-Loss 4.5496e+03, Data-loss 3.6992e+03                  , pde-loss 1.1138e-15, initc-loss 2.5071e+04                    bc_loss 1.3589e+07, Test-Loss 3.6992e+03\n",
      "Epoch 10380, Training-Loss 5.0310e+03, Data-loss 4.0870e+03                  , pde-loss 1.3674e-15, initc-loss 2.4956e+04                    bc_loss 1.3627e+07, Test-Loss 4.0870e+03\n",
      "Epoch 10390, Training-Loss 4.8684e+03, Data-loss 3.2764e+03                  , pde-loss 1.0106e-15, initc-loss 2.4842e+04                    bc_loss 1.3665e+07, Test-Loss 3.2764e+03\n",
      "Epoch 10400, Training-Loss 4.7849e+03, Data-loss 3.8290e+03                  , pde-loss 1.5002e-15, initc-loss 2.4726e+04                    bc_loss 1.3703e+07, Test-Loss 3.8290e+03\n",
      "Epoch 10410, Training-Loss 4.9524e+03, Data-loss 2.9673e+03                  , pde-loss 1.1164e-15, initc-loss 2.4611e+04                    bc_loss 1.3741e+07, Test-Loss 2.9673e+03\n",
      "Epoch 10420, Training-Loss 4.7463e+03, Data-loss 3.3970e+03                  , pde-loss 1.3707e-15, initc-loss 2.4498e+04                    bc_loss 1.3779e+07, Test-Loss 3.3970e+03\n",
      "Epoch 10430, Training-Loss 5.3939e+03, Data-loss 3.7679e+03                  , pde-loss 1.7261e-15, initc-loss 2.4386e+04                    bc_loss 1.3817e+07, Test-Loss 3.7679e+03\n",
      "Epoch 10440, Training-Loss 4.7520e+03, Data-loss 3.4767e+03                  , pde-loss 1.6425e-15, initc-loss 2.4276e+04                    bc_loss 1.3854e+07, Test-Loss 3.4767e+03\n",
      "Epoch 10450, Training-Loss 4.1409e+03, Data-loss 4.3866e+03                  , pde-loss 1.9129e-15, initc-loss 2.4169e+04                    bc_loss 1.3890e+07, Test-Loss 4.3866e+03\n",
      "Epoch 10460, Training-Loss 4.5511e+03, Data-loss 3.9597e+03                  , pde-loss 1.5823e-15, initc-loss 2.4063e+04                    bc_loss 1.3926e+07, Test-Loss 3.9597e+03\n",
      "Epoch 10470, Training-Loss 5.0539e+03, Data-loss 3.2365e+03                  , pde-loss 1.8132e-15, initc-loss 2.3954e+04                    bc_loss 1.3963e+07, Test-Loss 3.2365e+03\n",
      "Epoch 10480, Training-Loss 4.1942e+03, Data-loss 3.7741e+03                  , pde-loss 1.9985e-15, initc-loss 2.3846e+04                    bc_loss 1.4000e+07, Test-Loss 3.7741e+03\n",
      "Epoch 10490, Training-Loss 4.7639e+03, Data-loss 3.5420e+03                  , pde-loss 2.2504e-15, initc-loss 2.3740e+04                    bc_loss 1.4037e+07, Test-Loss 3.5420e+03\n",
      "Epoch 10500, Training-Loss 4.9385e+03, Data-loss 3.5482e+03                  , pde-loss 2.0382e-15, initc-loss 2.3632e+04                    bc_loss 1.4074e+07, Test-Loss 3.5482e+03\n",
      "Epoch 10510, Training-Loss 4.8320e+03, Data-loss 3.7665e+03                  , pde-loss 2.0181e-15, initc-loss 2.3525e+04                    bc_loss 1.4111e+07, Test-Loss 3.7665e+03\n",
      "Epoch 10520, Training-Loss 4.1628e+03, Data-loss 2.9114e+03                  , pde-loss 2.4129e-15, initc-loss 2.3422e+04                    bc_loss 1.4147e+07, Test-Loss 2.9114e+03\n",
      "Epoch 10530, Training-Loss 4.7883e+03, Data-loss 3.0889e+03                  , pde-loss 2.2705e-15, initc-loss 2.3320e+04                    bc_loss 1.4182e+07, Test-Loss 3.0889e+03\n",
      "Epoch 10540, Training-Loss 4.6035e+03, Data-loss 3.7163e+03                  , pde-loss 2.2227e-15, initc-loss 2.3218e+04                    bc_loss 1.4218e+07, Test-Loss 3.7163e+03\n",
      "Epoch 10550, Training-Loss 5.2764e+03, Data-loss 2.9015e+03                  , pde-loss 2.0714e-15, initc-loss 2.3119e+04                    bc_loss 1.4253e+07, Test-Loss 2.9015e+03\n",
      "Epoch 10560, Training-Loss 4.3517e+03, Data-loss 3.1694e+03                  , pde-loss 2.9277e-15, initc-loss 2.3019e+04                    bc_loss 1.4288e+07, Test-Loss 3.1694e+03\n",
      "Epoch 10570, Training-Loss 5.2774e+03, Data-loss 2.9448e+03                  , pde-loss 3.0857e-15, initc-loss 2.2916e+04                    bc_loss 1.4324e+07, Test-Loss 2.9448e+03\n",
      "Epoch 10580, Training-Loss 4.9996e+03, Data-loss 3.2148e+03                  , pde-loss 2.8675e-15, initc-loss 2.2815e+04                    bc_loss 1.4360e+07, Test-Loss 3.2148e+03\n",
      "Epoch 10590, Training-Loss 4.7984e+03, Data-loss 3.2361e+03                  , pde-loss 3.8230e-15, initc-loss 2.2717e+04                    bc_loss 1.4395e+07, Test-Loss 3.2361e+03\n",
      "Epoch 10600, Training-Loss 4.1193e+03, Data-loss 3.2475e+03                  , pde-loss 4.1953e-15, initc-loss 2.2619e+04                    bc_loss 1.4430e+07, Test-Loss 3.2475e+03\n",
      "Epoch 10610, Training-Loss 4.7778e+03, Data-loss 3.6022e+03                  , pde-loss 3.3300e-15, initc-loss 2.2521e+04                    bc_loss 1.4465e+07, Test-Loss 3.6022e+03\n",
      "Epoch 10620, Training-Loss 4.3385e+03, Data-loss 3.1087e+03                  , pde-loss 4.1067e-15, initc-loss 2.2420e+04                    bc_loss 1.4501e+07, Test-Loss 3.1087e+03\n",
      "Epoch 10630, Training-Loss 5.0712e+03, Data-loss 3.4993e+03                  , pde-loss 4.7369e-15, initc-loss 2.2323e+04                    bc_loss 1.4536e+07, Test-Loss 3.4993e+03\n",
      "Epoch 10640, Training-Loss 4.6238e+03, Data-loss 3.1268e+03                  , pde-loss 5.4837e-15, initc-loss 2.2227e+04                    bc_loss 1.4570e+07, Test-Loss 3.1268e+03\n",
      "Epoch 10650, Training-Loss 4.1921e+03, Data-loss 2.6285e+03                  , pde-loss 5.7062e-15, initc-loss 2.2132e+04                    bc_loss 1.4605e+07, Test-Loss 2.6285e+03\n",
      "Epoch 10660, Training-Loss 4.1162e+03, Data-loss 3.1899e+03                  , pde-loss 5.3305e-15, initc-loss 2.2038e+04                    bc_loss 1.4639e+07, Test-Loss 3.1899e+03\n",
      "Epoch 10670, Training-Loss 3.8413e+03, Data-loss 2.3356e+03                  , pde-loss 7.6140e-15, initc-loss 2.1944e+04                    bc_loss 1.4674e+07, Test-Loss 2.3356e+03\n",
      "Epoch 10680, Training-Loss 4.4214e+03, Data-loss 2.9759e+03                  , pde-loss 8.1529e-15, initc-loss 2.1851e+04                    bc_loss 1.4707e+07, Test-Loss 2.9759e+03\n",
      "Epoch 10690, Training-Loss 4.6896e+03, Data-loss 2.8569e+03                  , pde-loss 7.8329e-15, initc-loss 2.1762e+04                    bc_loss 1.4740e+07, Test-Loss 2.8569e+03\n",
      "Epoch 10700, Training-Loss 3.9411e+03, Data-loss 2.8499e+03                  , pde-loss 8.4959e-15, initc-loss 2.1672e+04                    bc_loss 1.4773e+07, Test-Loss 2.8499e+03\n",
      "Epoch 10710, Training-Loss 4.5875e+03, Data-loss 2.7852e+03                  , pde-loss 7.5066e-15, initc-loss 2.1581e+04                    bc_loss 1.4807e+07, Test-Loss 2.7852e+03\n",
      "Epoch 10720, Training-Loss 4.1874e+03, Data-loss 2.8351e+03                  , pde-loss 7.9591e-15, initc-loss 2.1490e+04                    bc_loss 1.4841e+07, Test-Loss 2.8351e+03\n",
      "Epoch 10730, Training-Loss 4.0173e+03, Data-loss 2.6757e+03                  , pde-loss 8.7957e-15, initc-loss 2.1397e+04                    bc_loss 1.4875e+07, Test-Loss 2.6757e+03\n",
      "Epoch 10740, Training-Loss 4.4729e+03, Data-loss 2.8309e+03                  , pde-loss 8.7823e-15, initc-loss 2.1309e+04                    bc_loss 1.4909e+07, Test-Loss 2.8309e+03\n",
      "Epoch 10750, Training-Loss 4.0856e+03, Data-loss 2.3832e+03                  , pde-loss 9.7432e-15, initc-loss 2.1217e+04                    bc_loss 1.4943e+07, Test-Loss 2.3832e+03\n",
      "Epoch 10760, Training-Loss 3.9916e+03, Data-loss 2.6695e+03                  , pde-loss 1.1713e-14, initc-loss 2.1127e+04                    bc_loss 1.4977e+07, Test-Loss 2.6695e+03\n",
      "Epoch 10770, Training-Loss 4.8804e+03, Data-loss 2.7639e+03                  , pde-loss 8.8068e-15, initc-loss 2.1041e+04                    bc_loss 1.5009e+07, Test-Loss 2.7639e+03\n",
      "Epoch 10780, Training-Loss 4.1280e+03, Data-loss 2.7397e+03                  , pde-loss 1.4131e-14, initc-loss 2.0955e+04                    bc_loss 1.5042e+07, Test-Loss 2.7397e+03\n",
      "Epoch 10790, Training-Loss 4.3143e+03, Data-loss 2.1258e+03                  , pde-loss 1.2661e-14, initc-loss 2.0871e+04                    bc_loss 1.5074e+07, Test-Loss 2.1258e+03\n",
      "Epoch 10800, Training-Loss 4.1471e+03, Data-loss 2.2834e+03                  , pde-loss 1.5574e-14, initc-loss 2.0784e+04                    bc_loss 1.5107e+07, Test-Loss 2.2834e+03\n",
      "Epoch 10810, Training-Loss 4.2113e+03, Data-loss 2.8164e+03                  , pde-loss 1.4823e-14, initc-loss 2.0701e+04                    bc_loss 1.5138e+07, Test-Loss 2.8164e+03\n",
      "Epoch 10820, Training-Loss 3.9819e+03, Data-loss 3.0723e+03                  , pde-loss 1.6355e-14, initc-loss 2.0618e+04                    bc_loss 1.5170e+07, Test-Loss 3.0723e+03\n",
      "Epoch 10830, Training-Loss 4.2715e+03, Data-loss 3.0254e+03                  , pde-loss 1.5508e-14, initc-loss 2.0533e+04                    bc_loss 1.5203e+07, Test-Loss 3.0254e+03\n",
      "Epoch 10840, Training-Loss 4.1906e+03, Data-loss 2.6519e+03                  , pde-loss 1.8397e-14, initc-loss 2.0447e+04                    bc_loss 1.5236e+07, Test-Loss 2.6519e+03\n",
      "Epoch 10850, Training-Loss 3.9850e+03, Data-loss 2.1532e+03                  , pde-loss 1.9641e-14, initc-loss 2.0362e+04                    bc_loss 1.5269e+07, Test-Loss 2.1532e+03\n",
      "Epoch 10860, Training-Loss 4.3467e+03, Data-loss 3.2286e+03                  , pde-loss 1.7255e-14, initc-loss 2.0280e+04                    bc_loss 1.5301e+07, Test-Loss 3.2286e+03\n",
      "Epoch 10870, Training-Loss 3.5156e+03, Data-loss 2.3480e+03                  , pde-loss 2.4093e-14, initc-loss 2.0198e+04                    bc_loss 1.5333e+07, Test-Loss 2.3480e+03\n",
      "Epoch 10880, Training-Loss 3.5745e+03, Data-loss 2.1307e+03                  , pde-loss 2.4568e-14, initc-loss 2.0116e+04                    bc_loss 1.5364e+07, Test-Loss 2.1307e+03\n",
      "Epoch 10890, Training-Loss 5.2189e+03, Data-loss 2.1461e+03                  , pde-loss 2.4096e-14, initc-loss 2.0038e+04                    bc_loss 1.5395e+07, Test-Loss 2.1461e+03\n",
      "Epoch 10900, Training-Loss 4.0269e+03, Data-loss 1.8271e+03                  , pde-loss 2.5577e-14, initc-loss 1.9961e+04                    bc_loss 1.5425e+07, Test-Loss 1.8271e+03\n",
      "Epoch 10910, Training-Loss 3.7838e+03, Data-loss 1.5710e+03                  , pde-loss 2.7349e-14, initc-loss 1.9884e+04                    bc_loss 1.5455e+07, Test-Loss 1.5710e+03\n",
      "Epoch 10920, Training-Loss 3.6671e+03, Data-loss 3.0074e+03                  , pde-loss 2.5676e-14, initc-loss 1.9811e+04                    bc_loss 1.5485e+07, Test-Loss 3.0074e+03\n",
      "Epoch 10930, Training-Loss 3.4833e+03, Data-loss 1.8508e+03                  , pde-loss 2.9758e-14, initc-loss 1.9737e+04                    bc_loss 1.5514e+07, Test-Loss 1.8508e+03\n",
      "Epoch 10940, Training-Loss 3.9992e+03, Data-loss 2.2824e+03                  , pde-loss 3.0964e-14, initc-loss 1.9661e+04                    bc_loss 1.5544e+07, Test-Loss 2.2824e+03\n",
      "Epoch 10950, Training-Loss 4.0294e+03, Data-loss 2.8469e+03                  , pde-loss 2.8714e-14, initc-loss 1.9584e+04                    bc_loss 1.5574e+07, Test-Loss 2.8469e+03\n",
      "Epoch 10960, Training-Loss 4.1836e+03, Data-loss 2.4044e+03                  , pde-loss 3.0624e-14, initc-loss 1.9507e+04                    bc_loss 1.5606e+07, Test-Loss 2.4044e+03\n",
      "Epoch 10970, Training-Loss 4.0395e+03, Data-loss 2.1768e+03                  , pde-loss 3.3065e-14, initc-loss 1.9431e+04                    bc_loss 1.5636e+07, Test-Loss 2.1768e+03\n",
      "Epoch 10980, Training-Loss 3.5693e+03, Data-loss 2.4506e+03                  , pde-loss 3.5184e-14, initc-loss 1.9354e+04                    bc_loss 1.5667e+07, Test-Loss 2.4506e+03\n",
      "Epoch 10990, Training-Loss 4.2843e+03, Data-loss 1.9823e+03                  , pde-loss 3.4008e-14, initc-loss 1.9281e+04                    bc_loss 1.5696e+07, Test-Loss 1.9823e+03\n",
      "Epoch 11000, Training-Loss 4.1488e+03, Data-loss 1.7927e+03                  , pde-loss 3.4535e-14, initc-loss 1.9208e+04                    bc_loss 1.5726e+07, Test-Loss 1.7927e+03\n",
      "Epoch 11010, Training-Loss 3.4550e+03, Data-loss 2.3116e+03                  , pde-loss 3.8972e-14, initc-loss 1.9136e+04                    bc_loss 1.5755e+07, Test-Loss 2.3116e+03\n",
      "Epoch 11020, Training-Loss 3.9156e+03, Data-loss 1.9194e+03                  , pde-loss 4.1931e-14, initc-loss 1.9064e+04                    bc_loss 1.5784e+07, Test-Loss 1.9194e+03\n",
      "Epoch 11030, Training-Loss 3.9752e+03, Data-loss 2.6660e+03                  , pde-loss 4.2903e-14, initc-loss 1.8995e+04                    bc_loss 1.5812e+07, Test-Loss 2.6660e+03\n",
      "Epoch 11040, Training-Loss 3.7202e+03, Data-loss 2.5290e+03                  , pde-loss 4.4737e-14, initc-loss 1.8926e+04                    bc_loss 1.5840e+07, Test-Loss 2.5290e+03\n",
      "Epoch 11050, Training-Loss 4.1313e+03, Data-loss 1.9713e+03                  , pde-loss 4.4985e-14, initc-loss 1.8858e+04                    bc_loss 1.5868e+07, Test-Loss 1.9713e+03\n",
      "Epoch 11060, Training-Loss 3.4504e+03, Data-loss 1.9277e+03                  , pde-loss 5.3309e-14, initc-loss 1.8790e+04                    bc_loss 1.5896e+07, Test-Loss 1.9277e+03\n",
      "Epoch 11070, Training-Loss 3.2054e+03, Data-loss 1.9968e+03                  , pde-loss 6.5483e-14, initc-loss 1.8725e+04                    bc_loss 1.5923e+07, Test-Loss 1.9968e+03\n",
      "Epoch 11080, Training-Loss 3.4271e+03, Data-loss 2.2016e+03                  , pde-loss 6.7888e-14, initc-loss 1.8659e+04                    bc_loss 1.5950e+07, Test-Loss 2.2016e+03\n",
      "Epoch 11090, Training-Loss 4.1732e+03, Data-loss 1.8364e+03                  , pde-loss 5.5703e-14, initc-loss 1.8595e+04                    bc_loss 1.5977e+07, Test-Loss 1.8364e+03\n",
      "Epoch 11100, Training-Loss 3.8673e+03, Data-loss 1.5340e+03                  , pde-loss 6.4494e-14, initc-loss 1.8527e+04                    bc_loss 1.6005e+07, Test-Loss 1.5340e+03\n",
      "Epoch 11110, Training-Loss 3.4593e+03, Data-loss 2.0268e+03                  , pde-loss 7.5829e-14, initc-loss 1.8455e+04                    bc_loss 1.6035e+07, Test-Loss 2.0268e+03\n",
      "Epoch 11120, Training-Loss 3.8333e+03, Data-loss 2.5621e+03                  , pde-loss 7.6402e-14, initc-loss 1.8392e+04                    bc_loss 1.6061e+07, Test-Loss 2.5621e+03\n",
      "Epoch 11130, Training-Loss 3.9292e+03, Data-loss 2.5348e+03                  , pde-loss 8.5873e-14, initc-loss 1.8329e+04                    bc_loss 1.6087e+07, Test-Loss 2.5348e+03\n",
      "Epoch 11140, Training-Loss 3.5381e+03, Data-loss 1.9184e+03                  , pde-loss 1.0168e-13, initc-loss 1.8264e+04                    bc_loss 1.6115e+07, Test-Loss 1.9184e+03\n",
      "Epoch 11150, Training-Loss 3.4848e+03, Data-loss 1.9850e+03                  , pde-loss 9.7954e-14, initc-loss 1.8201e+04                    bc_loss 1.6141e+07, Test-Loss 1.9850e+03\n",
      "Epoch 11160, Training-Loss 3.7573e+03, Data-loss 1.8554e+03                  , pde-loss 1.1323e-13, initc-loss 1.8140e+04                    bc_loss 1.6167e+07, Test-Loss 1.8554e+03\n",
      "Epoch 11170, Training-Loss 3.8008e+03, Data-loss 2.0085e+03                  , pde-loss 1.1261e-13, initc-loss 1.8076e+04                    bc_loss 1.6194e+07, Test-Loss 2.0085e+03\n",
      "Epoch 11180, Training-Loss 3.7396e+03, Data-loss 2.3736e+03                  , pde-loss 1.2057e-13, initc-loss 1.8014e+04                    bc_loss 1.6220e+07, Test-Loss 2.3736e+03\n",
      "Epoch 11190, Training-Loss 3.5390e+03, Data-loss 1.9856e+03                  , pde-loss 1.1614e-13, initc-loss 1.7954e+04                    bc_loss 1.6246e+07, Test-Loss 1.9856e+03\n",
      "Epoch 11200, Training-Loss 3.5272e+03, Data-loss 2.1057e+03                  , pde-loss 1.3818e-13, initc-loss 1.7893e+04                    bc_loss 1.6272e+07, Test-Loss 2.1057e+03\n",
      "Epoch 11210, Training-Loss 3.7908e+03, Data-loss 1.6792e+03                  , pde-loss 1.2798e-13, initc-loss 1.7834e+04                    bc_loss 1.6297e+07, Test-Loss 1.6792e+03\n",
      "Epoch 11220, Training-Loss 4.2213e+03, Data-loss 2.1979e+03                  , pde-loss 1.1870e-13, initc-loss 1.7777e+04                    bc_loss 1.6321e+07, Test-Loss 2.1979e+03\n",
      "Epoch 11230, Training-Loss 3.2334e+03, Data-loss 2.0667e+03                  , pde-loss 1.5437e-13, initc-loss 1.7720e+04                    bc_loss 1.6346e+07, Test-Loss 2.0667e+03\n",
      "Epoch 11240, Training-Loss 4.3206e+03, Data-loss 2.5601e+03                  , pde-loss 1.2166e-13, initc-loss 1.7666e+04                    bc_loss 1.6369e+07, Test-Loss 2.5601e+03\n",
      "Epoch 11250, Training-Loss 3.9699e+03, Data-loss 1.9598e+03                  , pde-loss 1.4609e-13, initc-loss 1.7611e+04                    bc_loss 1.6393e+07, Test-Loss 1.9598e+03\n",
      "Epoch 11260, Training-Loss 3.3267e+03, Data-loss 1.6688e+03                  , pde-loss 1.6452e-13, initc-loss 1.7553e+04                    bc_loss 1.6418e+07, Test-Loss 1.6688e+03\n",
      "Epoch 11270, Training-Loss 3.3587e+03, Data-loss 1.9879e+03                  , pde-loss 1.6008e-13, initc-loss 1.7497e+04                    bc_loss 1.6442e+07, Test-Loss 1.9879e+03\n",
      "Epoch 11280, Training-Loss 3.1808e+03, Data-loss 1.8251e+03                  , pde-loss 1.6555e-13, initc-loss 1.7444e+04                    bc_loss 1.6465e+07, Test-Loss 1.8251e+03\n",
      "Epoch 11290, Training-Loss 3.7356e+03, Data-loss 2.2912e+03                  , pde-loss 1.6340e-13, initc-loss 1.7387e+04                    bc_loss 1.6490e+07, Test-Loss 2.2912e+03\n",
      "Epoch 11300, Training-Loss 3.5233e+03, Data-loss 1.7684e+03                  , pde-loss 1.7083e-13, initc-loss 1.7331e+04                    bc_loss 1.6514e+07, Test-Loss 1.7684e+03\n",
      "Epoch 11310, Training-Loss 3.4010e+03, Data-loss 1.7838e+03                  , pde-loss 1.7423e-13, initc-loss 1.7277e+04                    bc_loss 1.6538e+07, Test-Loss 1.7838e+03\n",
      "Epoch 11320, Training-Loss 3.3668e+03, Data-loss 1.8608e+03                  , pde-loss 1.9756e-13, initc-loss 1.7221e+04                    bc_loss 1.6562e+07, Test-Loss 1.8608e+03\n",
      "Epoch 11330, Training-Loss 3.6365e+03, Data-loss 3.1187e+03                  , pde-loss 1.8770e-13, initc-loss 1.7167e+04                    bc_loss 1.6586e+07, Test-Loss 3.1187e+03\n",
      "Epoch 11340, Training-Loss 3.2378e+03, Data-loss 2.0208e+03                  , pde-loss 2.0253e-13, initc-loss 1.7117e+04                    bc_loss 1.6608e+07, Test-Loss 2.0208e+03\n",
      "Epoch 11350, Training-Loss 3.7538e+03, Data-loss 1.9755e+03                  , pde-loss 2.2347e-13, initc-loss 1.7070e+04                    bc_loss 1.6629e+07, Test-Loss 1.9755e+03\n",
      "Epoch 11360, Training-Loss 3.5712e+03, Data-loss 2.1327e+03                  , pde-loss 2.3318e-13, initc-loss 1.7024e+04                    bc_loss 1.6649e+07, Test-Loss 2.1327e+03\n",
      "Epoch 11370, Training-Loss 2.9514e+03, Data-loss 1.7613e+03                  , pde-loss 2.6043e-13, initc-loss 1.6971e+04                    bc_loss 1.6673e+07, Test-Loss 1.7613e+03\n",
      "Epoch 11380, Training-Loss 4.1709e+03, Data-loss 1.6906e+03                  , pde-loss 2.5499e-13, initc-loss 1.6922e+04                    bc_loss 1.6694e+07, Test-Loss 1.6906e+03\n",
      "Epoch 11390, Training-Loss 3.4661e+03, Data-loss 1.7182e+03                  , pde-loss 2.9187e-13, initc-loss 1.6873e+04                    bc_loss 1.6716e+07, Test-Loss 1.7182e+03\n",
      "Epoch 11400, Training-Loss 3.5269e+03, Data-loss 2.3458e+03                  , pde-loss 2.9000e-13, initc-loss 1.6824e+04                    bc_loss 1.6738e+07, Test-Loss 2.3458e+03\n",
      "Epoch 11410, Training-Loss 3.2602e+03, Data-loss 1.8379e+03                  , pde-loss 3.3534e-13, initc-loss 1.6775e+04                    bc_loss 1.6760e+07, Test-Loss 1.8379e+03\n",
      "Epoch 11420, Training-Loss 3.4094e+03, Data-loss 1.8780e+03                  , pde-loss 3.2526e-13, initc-loss 1.6727e+04                    bc_loss 1.6781e+07, Test-Loss 1.8780e+03\n",
      "Epoch 11430, Training-Loss 3.1347e+03, Data-loss 1.4899e+03                  , pde-loss 3.6138e-13, initc-loss 1.6678e+04                    bc_loss 1.6804e+07, Test-Loss 1.4899e+03\n",
      "Epoch 11440, Training-Loss 3.1602e+03, Data-loss 1.6674e+03                  , pde-loss 3.6882e-13, initc-loss 1.6633e+04                    bc_loss 1.6823e+07, Test-Loss 1.6674e+03\n",
      "Epoch 11450, Training-Loss 3.6287e+03, Data-loss 2.0240e+03                  , pde-loss 3.6073e-13, initc-loss 1.6593e+04                    bc_loss 1.6842e+07, Test-Loss 2.0240e+03\n",
      "Epoch 11460, Training-Loss 3.4315e+03, Data-loss 1.8645e+03                  , pde-loss 4.0671e-13, initc-loss 1.6550e+04                    bc_loss 1.6861e+07, Test-Loss 1.8645e+03\n",
      "Epoch 11470, Training-Loss 3.3362e+03, Data-loss 1.8703e+03                  , pde-loss 4.1000e-13, initc-loss 1.6504e+04                    bc_loss 1.6882e+07, Test-Loss 1.8703e+03\n",
      "Epoch 11480, Training-Loss 3.6275e+03, Data-loss 1.8116e+03                  , pde-loss 4.2933e-13, initc-loss 1.6459e+04                    bc_loss 1.6902e+07, Test-Loss 1.8116e+03\n",
      "Epoch 11490, Training-Loss 3.2794e+03, Data-loss 1.6898e+03                  , pde-loss 5.0534e-13, initc-loss 1.6416e+04                    bc_loss 1.6922e+07, Test-Loss 1.6898e+03\n",
      "Epoch 11500, Training-Loss 3.2880e+03, Data-loss 1.7187e+03                  , pde-loss 5.2618e-13, initc-loss 1.6375e+04                    bc_loss 1.6940e+07, Test-Loss 1.7187e+03\n",
      "Epoch 11510, Training-Loss 3.5940e+03, Data-loss 1.6915e+03                  , pde-loss 5.0099e-13, initc-loss 1.6331e+04                    bc_loss 1.6961e+07, Test-Loss 1.6915e+03\n",
      "Epoch 11520, Training-Loss 3.4518e+03, Data-loss 1.5939e+03                  , pde-loss 5.8470e-13, initc-loss 1.6283e+04                    bc_loss 1.6982e+07, Test-Loss 1.5939e+03\n",
      "Epoch 11530, Training-Loss 3.8224e+03, Data-loss 1.7059e+03                  , pde-loss 5.8245e-13, initc-loss 1.6241e+04                    bc_loss 1.7002e+07, Test-Loss 1.7059e+03\n",
      "Epoch 11540, Training-Loss 3.5174e+03, Data-loss 1.5358e+03                  , pde-loss 6.2909e-13, initc-loss 1.6199e+04                    bc_loss 1.7021e+07, Test-Loss 1.5358e+03\n",
      "Epoch 11550, Training-Loss 3.3772e+03, Data-loss 1.4853e+03                  , pde-loss 6.7993e-13, initc-loss 1.6160e+04                    bc_loss 1.7038e+07, Test-Loss 1.4853e+03\n",
      "Epoch 11560, Training-Loss 3.3235e+03, Data-loss 2.2267e+03                  , pde-loss 7.2578e-13, initc-loss 1.6122e+04                    bc_loss 1.7056e+07, Test-Loss 2.2267e+03\n",
      "Epoch 11570, Training-Loss 3.2832e+03, Data-loss 1.7534e+03                  , pde-loss 7.2931e-13, initc-loss 1.6085e+04                    bc_loss 1.7073e+07, Test-Loss 1.7534e+03\n",
      "Epoch 11580, Training-Loss 3.4937e+03, Data-loss 2.2035e+03                  , pde-loss 7.5838e-13, initc-loss 1.6050e+04                    bc_loss 1.7089e+07, Test-Loss 2.2035e+03\n",
      "Epoch 11590, Training-Loss 3.3375e+03, Data-loss 1.6429e+03                  , pde-loss 8.0093e-13, initc-loss 1.6010e+04                    bc_loss 1.7108e+07, Test-Loss 1.6429e+03\n",
      "Epoch 11600, Training-Loss 3.0986e+03, Data-loss 1.8714e+03                  , pde-loss 9.7250e-13, initc-loss 1.5971e+04                    bc_loss 1.7126e+07, Test-Loss 1.8714e+03\n",
      "Epoch 11610, Training-Loss 3.3523e+03, Data-loss 1.9772e+03                  , pde-loss 8.9737e-13, initc-loss 1.5937e+04                    bc_loss 1.7142e+07, Test-Loss 1.9772e+03\n",
      "Epoch 11620, Training-Loss 3.4648e+03, Data-loss 1.8702e+03                  , pde-loss 9.7488e-13, initc-loss 1.5901e+04                    bc_loss 1.7158e+07, Test-Loss 1.8702e+03\n",
      "Epoch 11630, Training-Loss 3.2866e+03, Data-loss 1.6791e+03                  , pde-loss 1.0577e-12, initc-loss 1.5864e+04                    bc_loss 1.7175e+07, Test-Loss 1.6791e+03\n",
      "Epoch 11640, Training-Loss 3.2557e+03, Data-loss 1.5062e+03                  , pde-loss 1.0957e-12, initc-loss 1.5832e+04                    bc_loss 1.7190e+07, Test-Loss 1.5062e+03\n",
      "Epoch 11650, Training-Loss 3.8463e+03, Data-loss 2.0914e+03                  , pde-loss 1.0731e-12, initc-loss 1.5799e+04                    bc_loss 1.7206e+07, Test-Loss 2.0914e+03\n",
      "Epoch 11660, Training-Loss 3.4026e+03, Data-loss 1.7908e+03                  , pde-loss 1.0546e-12, initc-loss 1.5763e+04                    bc_loss 1.7222e+07, Test-Loss 1.7908e+03\n",
      "Epoch 11670, Training-Loss 3.2507e+03, Data-loss 1.8916e+03                  , pde-loss 1.1821e-12, initc-loss 1.5728e+04                    bc_loss 1.7239e+07, Test-Loss 1.8916e+03\n",
      "Epoch 11680, Training-Loss 3.6195e+03, Data-loss 2.2118e+03                  , pde-loss 1.1348e-12, initc-loss 1.5690e+04                    bc_loss 1.7256e+07, Test-Loss 2.2118e+03\n",
      "Epoch 11690, Training-Loss 3.4595e+03, Data-loss 1.8158e+03                  , pde-loss 1.1986e-12, initc-loss 1.5650e+04                    bc_loss 1.7276e+07, Test-Loss 1.8158e+03\n",
      "Epoch 11700, Training-Loss 3.3630e+03, Data-loss 1.6047e+03                  , pde-loss 1.2841e-12, initc-loss 1.5611e+04                    bc_loss 1.7294e+07, Test-Loss 1.6047e+03\n",
      "Epoch 11710, Training-Loss 3.2364e+03, Data-loss 1.3525e+03                  , pde-loss 1.3918e-12, initc-loss 1.5576e+04                    bc_loss 1.7310e+07, Test-Loss 1.3525e+03\n",
      "Epoch 11720, Training-Loss 3.4396e+03, Data-loss 1.7366e+03                  , pde-loss 1.3791e-12, initc-loss 1.5542e+04                    bc_loss 1.7326e+07, Test-Loss 1.7366e+03\n",
      "Epoch 11730, Training-Loss 3.5414e+03, Data-loss 1.6223e+03                  , pde-loss 1.4128e-12, initc-loss 1.5508e+04                    bc_loss 1.7342e+07, Test-Loss 1.6223e+03\n",
      "Epoch 11740, Training-Loss 3.4667e+03, Data-loss 1.5780e+03                  , pde-loss 1.5128e-12, initc-loss 1.5475e+04                    bc_loss 1.7358e+07, Test-Loss 1.5780e+03\n",
      "Epoch 11750, Training-Loss 3.2911e+03, Data-loss 1.5630e+03                  , pde-loss 1.6041e-12, initc-loss 1.5443e+04                    bc_loss 1.7373e+07, Test-Loss 1.5630e+03\n",
      "Epoch 11760, Training-Loss 3.2881e+03, Data-loss 1.5662e+03                  , pde-loss 1.6692e-12, initc-loss 1.5411e+04                    bc_loss 1.7388e+07, Test-Loss 1.5662e+03\n",
      "Epoch 11770, Training-Loss 2.9577e+03, Data-loss 1.5877e+03                  , pde-loss 1.7108e-12, initc-loss 1.5382e+04                    bc_loss 1.7402e+07, Test-Loss 1.5877e+03\n",
      "Epoch 11780, Training-Loss 3.3954e+03, Data-loss 1.8738e+03                  , pde-loss 1.7277e-12, initc-loss 1.5348e+04                    bc_loss 1.7418e+07, Test-Loss 1.8738e+03\n",
      "Epoch 11790, Training-Loss 3.2530e+03, Data-loss 1.6471e+03                  , pde-loss 1.7637e-12, initc-loss 1.5315e+04                    bc_loss 1.7434e+07, Test-Loss 1.6471e+03\n",
      "Epoch 11800, Training-Loss 3.3058e+03, Data-loss 1.5310e+03                  , pde-loss 2.1000e-12, initc-loss 1.5286e+04                    bc_loss 1.7448e+07, Test-Loss 1.5310e+03\n",
      "Epoch 11810, Training-Loss 3.9719e+03, Data-loss 1.9611e+03                  , pde-loss 1.9270e-12, initc-loss 1.5259e+04                    bc_loss 1.7461e+07, Test-Loss 1.9611e+03\n",
      "Epoch 11820, Training-Loss 3.5788e+03, Data-loss 1.7304e+03                  , pde-loss 1.9697e-12, initc-loss 1.5227e+04                    bc_loss 1.7476e+07, Test-Loss 1.7304e+03\n",
      "Epoch 11830, Training-Loss 3.1960e+03, Data-loss 1.8598e+03                  , pde-loss 2.0937e-12, initc-loss 1.5196e+04                    bc_loss 1.7491e+07, Test-Loss 1.8598e+03\n",
      "Epoch 11840, Training-Loss 3.4574e+03, Data-loss 1.6327e+03                  , pde-loss 2.1262e-12, initc-loss 1.5165e+04                    bc_loss 1.7506e+07, Test-Loss 1.6327e+03\n",
      "Epoch 11850, Training-Loss 3.1006e+03, Data-loss 1.5661e+03                  , pde-loss 2.2125e-12, initc-loss 1.5133e+04                    bc_loss 1.7521e+07, Test-Loss 1.5661e+03\n",
      "Epoch 11860, Training-Loss 3.1071e+03, Data-loss 1.2688e+03                  , pde-loss 2.2908e-12, initc-loss 1.5100e+04                    bc_loss 1.7537e+07, Test-Loss 1.2688e+03\n",
      "Epoch 11870, Training-Loss 3.1589e+03, Data-loss 1.4614e+03                  , pde-loss 2.4761e-12, initc-loss 1.5073e+04                    bc_loss 1.7550e+07, Test-Loss 1.4614e+03\n",
      "Epoch 11880, Training-Loss 3.5441e+03, Data-loss 1.4670e+03                  , pde-loss 2.3829e-12, initc-loss 1.5047e+04                    bc_loss 1.7563e+07, Test-Loss 1.4670e+03\n",
      "Epoch 11890, Training-Loss 3.3837e+03, Data-loss 1.7878e+03                  , pde-loss 2.6993e-12, initc-loss 1.5023e+04                    bc_loss 1.7574e+07, Test-Loss 1.7878e+03\n",
      "Epoch 11900, Training-Loss 3.1366e+03, Data-loss 1.4224e+03                  , pde-loss 2.7965e-12, initc-loss 1.5003e+04                    bc_loss 1.7584e+07, Test-Loss 1.4224e+03\n",
      "Epoch 11910, Training-Loss 3.0321e+03, Data-loss 1.8015e+03                  , pde-loss 2.6987e-12, initc-loss 1.4981e+04                    bc_loss 1.7595e+07, Test-Loss 1.8015e+03\n",
      "Epoch 11920, Training-Loss 3.2678e+03, Data-loss 1.5333e+03                  , pde-loss 2.7299e-12, initc-loss 1.4956e+04                    bc_loss 1.7607e+07, Test-Loss 1.5333e+03\n",
      "Epoch 11930, Training-Loss 3.1775e+03, Data-loss 1.8965e+03                  , pde-loss 3.1220e-12, initc-loss 1.4933e+04                    bc_loss 1.7618e+07, Test-Loss 1.8965e+03\n",
      "Epoch 11940, Training-Loss 3.4394e+03, Data-loss 1.5121e+03                  , pde-loss 3.2220e-12, initc-loss 1.4908e+04                    bc_loss 1.7630e+07, Test-Loss 1.5121e+03\n",
      "Epoch 11950, Training-Loss 3.1777e+03, Data-loss 1.5757e+03                  , pde-loss 3.2727e-12, initc-loss 1.4884e+04                    bc_loss 1.7642e+07, Test-Loss 1.5757e+03\n",
      "Epoch 11960, Training-Loss 3.3517e+03, Data-loss 1.8995e+03                  , pde-loss 3.5857e-12, initc-loss 1.4862e+04                    bc_loss 1.7653e+07, Test-Loss 1.8995e+03\n",
      "Epoch 11970, Training-Loss 3.4846e+03, Data-loss 1.2419e+03                  , pde-loss 3.6204e-12, initc-loss 1.4842e+04                    bc_loss 1.7662e+07, Test-Loss 1.2419e+03\n",
      "Epoch 11980, Training-Loss 3.2841e+03, Data-loss 1.5777e+03                  , pde-loss 3.3373e-12, initc-loss 1.4820e+04                    bc_loss 1.7673e+07, Test-Loss 1.5777e+03\n",
      "Epoch 11990, Training-Loss 3.7344e+03, Data-loss 1.5120e+03                  , pde-loss 3.5783e-12, initc-loss 1.4797e+04                    bc_loss 1.7684e+07, Test-Loss 1.5120e+03\n",
      "Epoch 12000, Training-Loss 3.3176e+03, Data-loss 1.2297e+03                  , pde-loss 3.8546e-12, initc-loss 1.4774e+04                    bc_loss 1.7696e+07, Test-Loss 1.2297e+03\n",
      "Epoch 12010, Training-Loss 3.0116e+03, Data-loss 1.3883e+03                  , pde-loss 3.7114e-12, initc-loss 1.4751e+04                    bc_loss 1.7707e+07, Test-Loss 1.3883e+03\n",
      "Epoch 12020, Training-Loss 3.7649e+03, Data-loss 1.3039e+03                  , pde-loss 3.6363e-12, initc-loss 1.4728e+04                    bc_loss 1.7718e+07, Test-Loss 1.3039e+03\n",
      "Epoch 12030, Training-Loss 3.3482e+03, Data-loss 1.7082e+03                  , pde-loss 4.3331e-12, initc-loss 1.4705e+04                    bc_loss 1.7729e+07, Test-Loss 1.7082e+03\n",
      "Epoch 12040, Training-Loss 3.5341e+03, Data-loss 1.4161e+03                  , pde-loss 3.9755e-12, initc-loss 1.4683e+04                    bc_loss 1.7740e+07, Test-Loss 1.4161e+03\n",
      "Epoch 12050, Training-Loss 3.3895e+03, Data-loss 1.8770e+03                  , pde-loss 4.2831e-12, initc-loss 1.4656e+04                    bc_loss 1.7753e+07, Test-Loss 1.8770e+03\n",
      "Epoch 12060, Training-Loss 2.8576e+03, Data-loss 1.6769e+03                  , pde-loss 4.9748e-12, initc-loss 1.4633e+04                    bc_loss 1.7765e+07, Test-Loss 1.6769e+03\n",
      "Epoch 12070, Training-Loss 3.3882e+03, Data-loss 1.6557e+03                  , pde-loss 4.6041e-12, initc-loss 1.4613e+04                    bc_loss 1.7775e+07, Test-Loss 1.6557e+03\n",
      "Epoch 12080, Training-Loss 3.3331e+03, Data-loss 1.8579e+03                  , pde-loss 5.2247e-12, initc-loss 1.4594e+04                    bc_loss 1.7784e+07, Test-Loss 1.8579e+03\n",
      "Epoch 12090, Training-Loss 3.2631e+03, Data-loss 2.0196e+03                  , pde-loss 5.3467e-12, initc-loss 1.4571e+04                    bc_loss 1.7795e+07, Test-Loss 2.0196e+03\n",
      "Epoch 12100, Training-Loss 3.6891e+03, Data-loss 1.6414e+03                  , pde-loss 5.6721e-12, initc-loss 1.4549e+04                    bc_loss 1.7806e+07, Test-Loss 1.6414e+03\n",
      "Epoch 12110, Training-Loss 2.9634e+03, Data-loss 1.7255e+03                  , pde-loss 6.0161e-12, initc-loss 1.4526e+04                    bc_loss 1.7818e+07, Test-Loss 1.7255e+03\n",
      "Epoch 12120, Training-Loss 3.2885e+03, Data-loss 1.5958e+03                  , pde-loss 6.9816e-12, initc-loss 1.4505e+04                    bc_loss 1.7828e+07, Test-Loss 1.5958e+03\n",
      "Epoch 12130, Training-Loss 3.6084e+03, Data-loss 1.7050e+03                  , pde-loss 5.1249e-12, initc-loss 1.4491e+04                    bc_loss 1.7835e+07, Test-Loss 1.7050e+03\n",
      "Epoch 12140, Training-Loss 3.2984e+03, Data-loss 1.3065e+03                  , pde-loss 6.1212e-12, initc-loss 1.4471e+04                    bc_loss 1.7845e+07, Test-Loss 1.3065e+03\n",
      "Epoch 12150, Training-Loss 3.2742e+03, Data-loss 1.4724e+03                  , pde-loss 6.7390e-12, initc-loss 1.4452e+04                    bc_loss 1.7854e+07, Test-Loss 1.4724e+03\n",
      "Epoch 12160, Training-Loss 3.0046e+03, Data-loss 1.5598e+03                  , pde-loss 7.5355e-12, initc-loss 1.4436e+04                    bc_loss 1.7863e+07, Test-Loss 1.5598e+03\n",
      "Epoch 12170, Training-Loss 3.0529e+03, Data-loss 1.4713e+03                  , pde-loss 7.8190e-12, initc-loss 1.4418e+04                    bc_loss 1.7871e+07, Test-Loss 1.4713e+03\n",
      "Epoch 12180, Training-Loss 3.5662e+03, Data-loss 1.6707e+03                  , pde-loss 6.7295e-12, initc-loss 1.4397e+04                    bc_loss 1.7882e+07, Test-Loss 1.6707e+03\n",
      "Epoch 12190, Training-Loss 3.5990e+03, Data-loss 1.6192e+03                  , pde-loss 8.7898e-12, initc-loss 1.4376e+04                    bc_loss 1.7892e+07, Test-Loss 1.6192e+03\n",
      "Epoch 12200, Training-Loss 3.4528e+03, Data-loss 1.6813e+03                  , pde-loss 9.0326e-12, initc-loss 1.4359e+04                    bc_loss 1.7901e+07, Test-Loss 1.6813e+03\n",
      "Epoch 12210, Training-Loss 3.2229e+03, Data-loss 1.6163e+03                  , pde-loss 8.1395e-12, initc-loss 1.4344e+04                    bc_loss 1.7908e+07, Test-Loss 1.6163e+03\n",
      "Epoch 12220, Training-Loss 3.1617e+03, Data-loss 1.6639e+03                  , pde-loss 8.9339e-12, initc-loss 1.4323e+04                    bc_loss 1.7919e+07, Test-Loss 1.6639e+03\n",
      "Epoch 12230, Training-Loss 3.4753e+03, Data-loss 1.6971e+03                  , pde-loss 9.5321e-12, initc-loss 1.4306e+04                    bc_loss 1.7927e+07, Test-Loss 1.6971e+03\n",
      "Epoch 12240, Training-Loss 3.0437e+03, Data-loss 1.3356e+03                  , pde-loss 1.0487e-11, initc-loss 1.4289e+04                    bc_loss 1.7936e+07, Test-Loss 1.3356e+03\n",
      "Epoch 12250, Training-Loss 3.2961e+03, Data-loss 1.4379e+03                  , pde-loss 1.0492e-11, initc-loss 1.4274e+04                    bc_loss 1.7943e+07, Test-Loss 1.4379e+03\n",
      "Epoch 12260, Training-Loss 3.3033e+03, Data-loss 1.2844e+03                  , pde-loss 1.1800e-11, initc-loss 1.4258e+04                    bc_loss 1.7951e+07, Test-Loss 1.2844e+03\n",
      "Epoch 12270, Training-Loss 3.5121e+03, Data-loss 1.6800e+03                  , pde-loss 1.1492e-11, initc-loss 1.4245e+04                    bc_loss 1.7958e+07, Test-Loss 1.6800e+03\n",
      "Epoch 12280, Training-Loss 3.3785e+03, Data-loss 1.0861e+03                  , pde-loss 1.1325e-11, initc-loss 1.4232e+04                    bc_loss 1.7964e+07, Test-Loss 1.0861e+03\n",
      "Epoch 12290, Training-Loss 3.6422e+03, Data-loss 1.4919e+03                  , pde-loss 1.1212e-11, initc-loss 1.4219e+04                    bc_loss 1.7971e+07, Test-Loss 1.4919e+03\n",
      "Epoch 12300, Training-Loss 3.8316e+03, Data-loss 1.2205e+03                  , pde-loss 1.0939e-11, initc-loss 1.4204e+04                    bc_loss 1.7978e+07, Test-Loss 1.2205e+03\n",
      "Epoch 12310, Training-Loss 3.4042e+03, Data-loss 1.4653e+03                  , pde-loss 1.3662e-11, initc-loss 1.4185e+04                    bc_loss 1.7988e+07, Test-Loss 1.4653e+03\n",
      "Epoch 12320, Training-Loss 3.1088e+03, Data-loss 1.4637e+03                  , pde-loss 1.4178e-11, initc-loss 1.4169e+04                    bc_loss 1.7996e+07, Test-Loss 1.4637e+03\n",
      "Epoch 12330, Training-Loss 3.6060e+03, Data-loss 1.4780e+03                  , pde-loss 1.3461e-11, initc-loss 1.4157e+04                    bc_loss 1.8002e+07, Test-Loss 1.4780e+03\n",
      "Epoch 12340, Training-Loss 3.3768e+03, Data-loss 1.3775e+03                  , pde-loss 1.5118e-11, initc-loss 1.4142e+04                    bc_loss 1.8009e+07, Test-Loss 1.3775e+03\n",
      "Epoch 12350, Training-Loss 3.3026e+03, Data-loss 1.3245e+03                  , pde-loss 1.5618e-11, initc-loss 1.4131e+04                    bc_loss 1.8015e+07, Test-Loss 1.3245e+03\n",
      "Epoch 12360, Training-Loss 3.2828e+03, Data-loss 1.4894e+03                  , pde-loss 1.7731e-11, initc-loss 1.4115e+04                    bc_loss 1.8023e+07, Test-Loss 1.4894e+03\n",
      "Epoch 12370, Training-Loss 3.2413e+03, Data-loss 1.6245e+03                  , pde-loss 2.1104e-11, initc-loss 1.4096e+04                    bc_loss 1.8033e+07, Test-Loss 1.6245e+03\n",
      "Epoch 12380, Training-Loss 3.3596e+03, Data-loss 1.2347e+03                  , pde-loss 1.8417e-11, initc-loss 1.4081e+04                    bc_loss 1.8040e+07, Test-Loss 1.2347e+03\n",
      "Epoch 12390, Training-Loss 3.1535e+03, Data-loss 1.5687e+03                  , pde-loss 1.7912e-11, initc-loss 1.4063e+04                    bc_loss 1.8050e+07, Test-Loss 1.5687e+03\n",
      "Epoch 12400, Training-Loss 2.8136e+03, Data-loss 1.9331e+03                  , pde-loss 1.6934e-11, initc-loss 1.4046e+04                    bc_loss 1.8058e+07, Test-Loss 1.9331e+03\n",
      "Epoch 12410, Training-Loss 3.5407e+03, Data-loss 1.4145e+03                  , pde-loss 2.2107e-11, initc-loss 1.4022e+04                    bc_loss 1.8070e+07, Test-Loss 1.4145e+03\n",
      "Epoch 12420, Training-Loss 3.6979e+03, Data-loss 1.3534e+03                  , pde-loss 2.3633e-11, initc-loss 1.3998e+04                    bc_loss 1.8082e+07, Test-Loss 1.3534e+03\n",
      "Epoch 12430, Training-Loss 3.8875e+03, Data-loss 1.4893e+03                  , pde-loss 2.0126e-11, initc-loss 1.3985e+04                    bc_loss 1.8089e+07, Test-Loss 1.4893e+03\n",
      "Epoch 12440, Training-Loss 3.4385e+03, Data-loss 1.5943e+03                  , pde-loss 2.9619e-11, initc-loss 1.3970e+04                    bc_loss 1.8097e+07, Test-Loss 1.5943e+03\n",
      "Epoch 12450, Training-Loss 3.4119e+03, Data-loss 1.2329e+03                  , pde-loss 2.3425e-11, initc-loss 1.3959e+04                    bc_loss 1.8102e+07, Test-Loss 1.2329e+03\n",
      "Epoch 12460, Training-Loss 3.5829e+03, Data-loss 1.6276e+03                  , pde-loss 2.8958e-11, initc-loss 1.3947e+04                    bc_loss 1.8109e+07, Test-Loss 1.6276e+03\n",
      "Epoch 12470, Training-Loss 3.2230e+03, Data-loss 1.7321e+03                  , pde-loss 3.4710e-11, initc-loss 1.3939e+04                    bc_loss 1.8112e+07, Test-Loss 1.7321e+03\n",
      "Epoch 12480, Training-Loss 3.4280e+03, Data-loss 1.7641e+03                  , pde-loss 3.1054e-11, initc-loss 1.3935e+04                    bc_loss 1.8115e+07, Test-Loss 1.7641e+03\n",
      "Epoch 12490, Training-Loss 3.0842e+03, Data-loss 1.5239e+03                  , pde-loss 3.0675e-11, initc-loss 1.3927e+04                    bc_loss 1.8119e+07, Test-Loss 1.5239e+03\n",
      "Epoch 12500, Training-Loss 3.2780e+03, Data-loss 1.8713e+03                  , pde-loss 3.6404e-11, initc-loss 1.3915e+04                    bc_loss 1.8125e+07, Test-Loss 1.8713e+03\n",
      "Epoch 12510, Training-Loss 3.7416e+03, Data-loss 1.8929e+03                  , pde-loss 4.4586e-11, initc-loss 1.3901e+04                    bc_loss 1.8132e+07, Test-Loss 1.8929e+03\n",
      "Epoch 12520, Training-Loss 3.5103e+03, Data-loss 1.4584e+03                  , pde-loss 4.6502e-11, initc-loss 1.3887e+04                    bc_loss 1.8139e+07, Test-Loss 1.4584e+03\n",
      "Epoch 12530, Training-Loss 2.9354e+03, Data-loss 1.5953e+03                  , pde-loss 3.9331e-11, initc-loss 1.3880e+04                    bc_loss 1.8143e+07, Test-Loss 1.5953e+03\n",
      "Epoch 12540, Training-Loss 3.0238e+03, Data-loss 1.4659e+03                  , pde-loss 4.4768e-11, initc-loss 1.3870e+04                    bc_loss 1.8148e+07, Test-Loss 1.4659e+03\n",
      "Epoch 12550, Training-Loss 3.1649e+03, Data-loss 1.3529e+03                  , pde-loss 5.1054e-11, initc-loss 1.3867e+04                    bc_loss 1.8149e+07, Test-Loss 1.3529e+03\n",
      "Epoch 12560, Training-Loss 3.0453e+03, Data-loss 1.5118e+03                  , pde-loss 4.5786e-11, initc-loss 1.3863e+04                    bc_loss 1.8151e+07, Test-Loss 1.5118e+03\n",
      "Epoch 12570, Training-Loss 3.3505e+03, Data-loss 1.7104e+03                  , pde-loss 5.1951e-11, initc-loss 1.3853e+04                    bc_loss 1.8156e+07, Test-Loss 1.7104e+03\n",
      "Epoch 12580, Training-Loss 3.4859e+03, Data-loss 1.4849e+03                  , pde-loss 5.4646e-11, initc-loss 1.3836e+04                    bc_loss 1.8165e+07, Test-Loss 1.4849e+03\n",
      "Epoch 12590, Training-Loss 3.5361e+03, Data-loss 1.5919e+03                  , pde-loss 5.2884e-11, initc-loss 1.3825e+04                    bc_loss 1.8171e+07, Test-Loss 1.5919e+03\n",
      "Epoch 12600, Training-Loss 3.4965e+03, Data-loss 1.7316e+03                  , pde-loss 6.0026e-11, initc-loss 1.3817e+04                    bc_loss 1.8175e+07, Test-Loss 1.7316e+03\n",
      "Epoch 12610, Training-Loss 3.8824e+03, Data-loss 1.6871e+03                  , pde-loss 6.7617e-11, initc-loss 1.3812e+04                    bc_loss 1.8177e+07, Test-Loss 1.6871e+03\n",
      "Epoch 12620, Training-Loss 3.2906e+03, Data-loss 1.3024e+03                  , pde-loss 6.7199e-11, initc-loss 1.3806e+04                    bc_loss 1.8180e+07, Test-Loss 1.3024e+03\n",
      "Epoch 12630, Training-Loss 3.2489e+03, Data-loss 1.2331e+03                  , pde-loss 8.1476e-11, initc-loss 1.3798e+04                    bc_loss 1.8185e+07, Test-Loss 1.2331e+03\n",
      "Epoch 12640, Training-Loss 3.4422e+03, Data-loss 1.3748e+03                  , pde-loss 8.5079e-11, initc-loss 1.3793e+04                    bc_loss 1.8187e+07, Test-Loss 1.3748e+03\n",
      "Epoch 12650, Training-Loss 3.9528e+03, Data-loss 1.2084e+03                  , pde-loss 8.6638e-11, initc-loss 1.3788e+04                    bc_loss 1.8190e+07, Test-Loss 1.2084e+03\n",
      "Epoch 12660, Training-Loss 3.3734e+03, Data-loss 1.4455e+03                  , pde-loss 1.0149e-10, initc-loss 1.3774e+04                    bc_loss 1.8197e+07, Test-Loss 1.4455e+03\n",
      "Epoch 12670, Training-Loss 3.2987e+03, Data-loss 1.2277e+03                  , pde-loss 1.0288e-10, initc-loss 1.3761e+04                    bc_loss 1.8204e+07, Test-Loss 1.2277e+03\n",
      "Epoch 12680, Training-Loss 3.4032e+03, Data-loss 1.5574e+03                  , pde-loss 1.1846e-10, initc-loss 1.3749e+04                    bc_loss 1.8210e+07, Test-Loss 1.5574e+03\n",
      "Epoch 12690, Training-Loss 2.9291e+03, Data-loss 1.3808e+03                  , pde-loss 1.3719e-10, initc-loss 1.3737e+04                    bc_loss 1.8216e+07, Test-Loss 1.3808e+03\n",
      "Epoch 12700, Training-Loss 3.2313e+03, Data-loss 1.3712e+03                  , pde-loss 1.5537e-10, initc-loss 1.3729e+04                    bc_loss 1.8220e+07, Test-Loss 1.3712e+03\n",
      "Epoch 12710, Training-Loss 3.1306e+03, Data-loss 1.9031e+03                  , pde-loss 1.1933e-10, initc-loss 1.3721e+04                    bc_loss 1.8224e+07, Test-Loss 1.9031e+03\n",
      "Epoch 12720, Training-Loss 3.7057e+03, Data-loss 1.5970e+03                  , pde-loss 2.0268e-10, initc-loss 1.3714e+04                    bc_loss 1.8228e+07, Test-Loss 1.5970e+03\n",
      "Epoch 12730, Training-Loss 3.0866e+03, Data-loss 1.7767e+03                  , pde-loss 1.7652e-10, initc-loss 1.3711e+04                    bc_loss 1.8229e+07, Test-Loss 1.7767e+03\n",
      "Epoch 12740, Training-Loss 3.7163e+03, Data-loss 1.5213e+03                  , pde-loss 1.7031e-10, initc-loss 1.3706e+04                    bc_loss 1.8232e+07, Test-Loss 1.5213e+03\n",
      "Epoch 12750, Training-Loss 3.7128e+03, Data-loss 1.3293e+03                  , pde-loss 2.0945e-10, initc-loss 1.3700e+04                    bc_loss 1.8235e+07, Test-Loss 1.3293e+03\n",
      "Epoch 12760, Training-Loss 3.8839e+03, Data-loss 1.6369e+03                  , pde-loss 2.5058e-10, initc-loss 1.3692e+04                    bc_loss 1.8239e+07, Test-Loss 1.6369e+03\n",
      "Epoch 12770, Training-Loss 3.3739e+03, Data-loss 1.4676e+03                  , pde-loss 2.8813e-10, initc-loss 1.3685e+04                    bc_loss 1.8243e+07, Test-Loss 1.4676e+03\n",
      "Epoch 12780, Training-Loss 3.1970e+03, Data-loss 1.5790e+03                  , pde-loss 2.8313e-10, initc-loss 1.3683e+04                    bc_loss 1.8244e+07, Test-Loss 1.5790e+03\n",
      "Epoch 12790, Training-Loss 3.1908e+03, Data-loss 1.9876e+03                  , pde-loss 3.2481e-10, initc-loss 1.3680e+04                    bc_loss 1.8246e+07, Test-Loss 1.9876e+03\n",
      "Epoch 12800, Training-Loss 3.4071e+03, Data-loss 1.2043e+03                  , pde-loss 4.2451e-10, initc-loss 1.3679e+04                    bc_loss 1.8246e+07, Test-Loss 1.2043e+03\n",
      "Epoch 12810, Training-Loss 3.0729e+03, Data-loss 1.4928e+03                  , pde-loss 3.8170e-10, initc-loss 1.3676e+04                    bc_loss 1.8248e+07, Test-Loss 1.4928e+03\n",
      "Epoch 12820, Training-Loss 3.1060e+03, Data-loss 1.3360e+03                  , pde-loss 3.5581e-10, initc-loss 1.3672e+04                    bc_loss 1.8250e+07, Test-Loss 1.3360e+03\n",
      "Epoch 12830, Training-Loss 3.0887e+03, Data-loss 1.3436e+03                  , pde-loss 5.3859e-10, initc-loss 1.3663e+04                    bc_loss 1.8254e+07, Test-Loss 1.3436e+03\n",
      "Epoch 12840, Training-Loss 3.3787e+03, Data-loss 1.1382e+03                  , pde-loss 5.8454e-10, initc-loss 1.3658e+04                    bc_loss 1.8257e+07, Test-Loss 1.1382e+03\n",
      "Epoch 12850, Training-Loss 3.2833e+03, Data-loss 1.4061e+03                  , pde-loss 6.2442e-10, initc-loss 1.3655e+04                    bc_loss 1.8258e+07, Test-Loss 1.4061e+03\n",
      "Epoch 12860, Training-Loss 3.5634e+03, Data-loss 1.5234e+03                  , pde-loss 6.1270e-10, initc-loss 1.3647e+04                    bc_loss 1.8263e+07, Test-Loss 1.5234e+03\n",
      "Epoch 12870, Training-Loss 3.0358e+03, Data-loss 1.7512e+03                  , pde-loss 6.7564e-10, initc-loss 1.3634e+04                    bc_loss 1.8269e+07, Test-Loss 1.7512e+03\n",
      "Epoch 12880, Training-Loss 3.2598e+03, Data-loss 1.6225e+03                  , pde-loss 1.0258e-09, initc-loss 1.3627e+04                    bc_loss 1.8273e+07, Test-Loss 1.6225e+03\n",
      "Epoch 12890, Training-Loss 3.0599e+03, Data-loss 1.4127e+03                  , pde-loss 1.0031e-09, initc-loss 1.3626e+04                    bc_loss 1.8273e+07, Test-Loss 1.4127e+03\n",
      "Epoch 12900, Training-Loss 3.4153e+03, Data-loss 1.4689e+03                  , pde-loss 1.2245e-09, initc-loss 1.3626e+04                    bc_loss 1.8273e+07, Test-Loss 1.4689e+03\n",
      "Epoch 12910, Training-Loss 3.4371e+03, Data-loss 1.5926e+03                  , pde-loss 1.5898e-09, initc-loss 1.3625e+04                    bc_loss 1.8274e+07, Test-Loss 1.5926e+03\n",
      "Epoch 12920, Training-Loss 3.0858e+03, Data-loss 1.4636e+03                  , pde-loss 1.2651e-09, initc-loss 1.3621e+04                    bc_loss 1.8276e+07, Test-Loss 1.4636e+03\n",
      "Epoch 12930, Training-Loss 3.5549e+03, Data-loss 1.8016e+03                  , pde-loss 2.0892e-09, initc-loss 1.3616e+04                    bc_loss 1.8278e+07, Test-Loss 1.8016e+03\n",
      "Epoch 12940, Training-Loss 3.3748e+03, Data-loss 1.6739e+03                  , pde-loss 1.9328e-09, initc-loss 1.3610e+04                    bc_loss 1.8282e+07, Test-Loss 1.6739e+03\n",
      "Epoch 12950, Training-Loss 3.1367e+03, Data-loss 1.2748e+03                  , pde-loss 4.9593e-09, initc-loss 1.3607e+04                    bc_loss 1.8283e+07, Test-Loss 1.2748e+03\n",
      "Epoch 12960, Training-Loss 3.5167e+03, Data-loss 1.4540e+03                  , pde-loss 4.2804e-09, initc-loss 1.3599e+04                    bc_loss 1.8288e+07, Test-Loss 1.4540e+03\n",
      "Epoch 12970, Training-Loss 3.4330e+03, Data-loss 1.6800e+03                  , pde-loss 8.7300e-09, initc-loss 1.3583e+04                    bc_loss 1.8296e+07, Test-Loss 1.6800e+03\n",
      "Epoch 12980, Training-Loss 3.3806e+03, Data-loss 1.6169e+03                  , pde-loss 1.2407e-08, initc-loss 1.3581e+04                    bc_loss 1.8297e+07, Test-Loss 1.6169e+03\n",
      "Epoch 12990, Training-Loss 3.5239e+03, Data-loss 1.5220e+03                  , pde-loss 1.8769e-08, initc-loss 1.3582e+04                    bc_loss 1.8296e+07, Test-Loss 1.5220e+03\n",
      "Epoch 13000, Training-Loss 3.3126e+03, Data-loss 1.4219e+03                  , pde-loss 2.6759e-08, initc-loss 1.3583e+04                    bc_loss 1.8296e+07, Test-Loss 1.4219e+03\n",
      "Epoch 13010, Training-Loss 3.5598e+03, Data-loss 1.8545e+03                  , pde-loss 8.4918e-08, initc-loss 1.3578e+04                    bc_loss 1.8298e+07, Test-Loss 1.8545e+03\n",
      "Epoch 13020, Training-Loss 3.1341e+03, Data-loss 1.4297e+03                  , pde-loss 9.0611e-08, initc-loss 1.3577e+04                    bc_loss 1.8299e+07, Test-Loss 1.4297e+03\n",
      "Epoch 13030, Training-Loss 3.3912e+03, Data-loss 9.8890e+02                  , pde-loss 7.4533e-07, initc-loss 1.3577e+04                    bc_loss 1.8299e+07, Test-Loss 9.8890e+02\n",
      "Epoch 13040, Training-Loss 3.2659e+03, Data-loss 1.3447e+03                  , pde-loss 2.5429e-06, initc-loss 1.3576e+04                    bc_loss 1.8299e+07, Test-Loss 1.3447e+03\n",
      "Epoch 13050, Training-Loss 3.4450e+03, Data-loss 1.4248e+03                  , pde-loss 1.6257e-05, initc-loss 1.3572e+04                    bc_loss 1.8301e+07, Test-Loss 1.4248e+03\n",
      "Epoch 13060, Training-Loss 3.2490e+03, Data-loss 1.2690e+03                  , pde-loss 1.4715e-04, initc-loss 1.3573e+04                    bc_loss 1.8301e+07, Test-Loss 1.2690e+03\n",
      "Epoch 13070, Training-Loss 3.4564e+03, Data-loss 1.5957e+03                  , pde-loss 2.4893e-03, initc-loss 1.3578e+04                    bc_loss 1.8297e+07, Test-Loss 1.5957e+03\n",
      "Epoch 13080, Training-Loss 3.1481e+03, Data-loss 1.1254e+03                  , pde-loss 6.7898e-01, initc-loss 1.3580e+04                    bc_loss 1.8255e+07, Test-Loss 1.1254e+03\n",
      "Epoch 13090, Training-Loss 2.7223e+03, Data-loss 1.2258e+03                  , pde-loss 1.8338e+02, initc-loss 1.5440e+04                    bc_loss 1.6562e+07, Test-Loss 1.2258e+03\n",
      "Epoch 13100, Training-Loss 2.8851e+03, Data-loss 1.3759e+03                  , pde-loss 4.9838e+02, initc-loss 1.3956e+04                    bc_loss 1.6739e+07, Test-Loss 1.3759e+03\n",
      "Epoch 13110, Training-Loss 2.7384e+03, Data-loss 1.1926e+03                  , pde-loss 6.3386e+02, initc-loss 1.3652e+04                    bc_loss 1.6968e+07, Test-Loss 1.1926e+03\n",
      "Epoch 13120, Training-Loss 2.7410e+03, Data-loss 9.0716e+02                  , pde-loss 5.2118e+02, initc-loss 1.3486e+04                    bc_loss 1.6990e+07, Test-Loss 9.0716e+02\n",
      "Epoch 13130, Training-Loss 2.6138e+03, Data-loss 1.1613e+03                  , pde-loss 6.4798e+02, initc-loss 1.3374e+04                    bc_loss 1.6965e+07, Test-Loss 1.1613e+03\n",
      "Epoch 13140, Training-Loss 2.6428e+03, Data-loss 8.4332e+02                  , pde-loss 6.7714e+02, initc-loss 1.3296e+04                    bc_loss 1.6912e+07, Test-Loss 8.4332e+02\n",
      "Epoch 13150, Training-Loss 2.5824e+03, Data-loss 1.1387e+03                  , pde-loss 7.6825e+02, initc-loss 1.3189e+04                    bc_loss 1.7041e+07, Test-Loss 1.1387e+03\n",
      "Epoch 13160, Training-Loss 2.6355e+03, Data-loss 9.5030e+02                  , pde-loss 6.9436e+02, initc-loss 1.3157e+04                    bc_loss 1.6908e+07, Test-Loss 9.5030e+02\n",
      "Epoch 13170, Training-Loss 2.8495e+03, Data-loss 9.0995e+02                  , pde-loss 5.6294e+02, initc-loss 1.3077e+04                    bc_loss 1.6977e+07, Test-Loss 9.0995e+02\n",
      "Epoch 13180, Training-Loss 2.7332e+03, Data-loss 7.6491e+02                  , pde-loss 6.9999e+02, initc-loss 1.2987e+04                    bc_loss 1.7062e+07, Test-Loss 7.6491e+02\n",
      "Epoch 13190, Training-Loss 2.7384e+03, Data-loss 1.0760e+03                  , pde-loss 5.8418e+02, initc-loss 1.2931e+04                    bc_loss 1.7080e+07, Test-Loss 1.0760e+03\n",
      "Epoch 13200, Training-Loss 2.4379e+03, Data-loss 1.1693e+03                  , pde-loss 5.0490e+02, initc-loss 1.2964e+04                    bc_loss 1.6999e+07, Test-Loss 1.1693e+03\n",
      "Epoch 13210, Training-Loss 2.8681e+03, Data-loss 1.1860e+03                  , pde-loss 5.6094e+02, initc-loss 1.2958e+04                    bc_loss 1.6977e+07, Test-Loss 1.1860e+03\n",
      "Epoch 13220, Training-Loss 2.5647e+03, Data-loss 9.2558e+02                  , pde-loss 6.9637e+02, initc-loss 1.2918e+04                    bc_loss 1.7027e+07, Test-Loss 9.2558e+02\n",
      "Epoch 13230, Training-Loss 2.8165e+03, Data-loss 7.7228e+02                  , pde-loss 7.9211e+02, initc-loss 1.3016e+04                    bc_loss 1.6882e+07, Test-Loss 7.7228e+02\n",
      "Epoch 13240, Training-Loss 2.6945e+03, Data-loss 8.1190e+02                  , pde-loss 7.9689e+02, initc-loss 1.2885e+04                    bc_loss 1.7011e+07, Test-Loss 8.1190e+02\n",
      "Epoch 13250, Training-Loss 2.7380e+03, Data-loss 6.7170e+02                  , pde-loss 6.3720e+02, initc-loss 1.3049e+04                    bc_loss 1.6995e+07, Test-Loss 6.7170e+02\n",
      "Epoch 13260, Training-Loss 2.7760e+03, Data-loss 9.4846e+02                  , pde-loss 5.7646e+02, initc-loss 1.2963e+04                    bc_loss 1.7099e+07, Test-Loss 9.4846e+02\n",
      "Epoch 13270, Training-Loss 2.5318e+03, Data-loss 7.4947e+02                  , pde-loss 7.5395e+02, initc-loss 1.2991e+04                    bc_loss 1.7088e+07, Test-Loss 7.4947e+02\n",
      "Epoch 13280, Training-Loss 2.4578e+03, Data-loss 7.2077e+02                  , pde-loss 6.7681e+02, initc-loss 1.3053e+04                    bc_loss 1.6987e+07, Test-Loss 7.2077e+02\n",
      "Epoch 13290, Training-Loss 2.5709e+03, Data-loss 1.0063e+03                  , pde-loss 6.2683e+02, initc-loss 1.3173e+04                    bc_loss 1.6949e+07, Test-Loss 1.0063e+03\n",
      "Epoch 13300, Training-Loss 2.6459e+03, Data-loss 9.9780e+02                  , pde-loss 5.6512e+02, initc-loss 1.3007e+04                    bc_loss 1.7089e+07, Test-Loss 9.9780e+02\n",
      "Epoch 13310, Training-Loss 2.2220e+03, Data-loss 7.7305e+02                  , pde-loss 6.3041e+02, initc-loss 1.3012e+04                    bc_loss 1.7180e+07, Test-Loss 7.7305e+02\n",
      "Epoch 13320, Training-Loss 2.3025e+03, Data-loss 8.9268e+02                  , pde-loss 6.1306e+02, initc-loss 1.3172e+04                    bc_loss 1.7041e+07, Test-Loss 8.9268e+02\n",
      "Epoch 13330, Training-Loss 2.6294e+03, Data-loss 9.6226e+02                  , pde-loss 6.4100e+02, initc-loss 1.2929e+04                    bc_loss 1.7073e+07, Test-Loss 9.6226e+02\n",
      "Epoch 13340, Training-Loss 2.1177e+03, Data-loss 8.5528e+02                  , pde-loss 7.2190e+02, initc-loss 1.3059e+04                    bc_loss 1.7100e+07, Test-Loss 8.5528e+02\n",
      "Epoch 13350, Training-Loss 2.5724e+03, Data-loss 8.7632e+02                  , pde-loss 6.0396e+02, initc-loss 1.3684e+04                    bc_loss 1.6931e+07, Test-Loss 8.7632e+02\n",
      "Epoch 13360, Training-Loss 2.4200e+03, Data-loss 6.5399e+02                  , pde-loss 6.7828e+02, initc-loss 1.3291e+04                    bc_loss 1.7058e+07, Test-Loss 6.5399e+02\n",
      "Epoch 13370, Training-Loss 2.6927e+03, Data-loss 8.4087e+02                  , pde-loss 6.2724e+02, initc-loss 1.3601e+04                    bc_loss 1.7026e+07, Test-Loss 8.4087e+02\n",
      "Epoch 13380, Training-Loss 2.4183e+03, Data-loss 8.3736e+02                  , pde-loss 5.4958e+02, initc-loss 1.3559e+04                    bc_loss 1.7106e+07, Test-Loss 8.3736e+02\n",
      "Epoch 13390, Training-Loss 2.2300e+03, Data-loss 7.2477e+02                  , pde-loss 5.3921e+02, initc-loss 1.3476e+04                    bc_loss 1.7165e+07, Test-Loss 7.2477e+02\n",
      "Epoch 13400, Training-Loss 2.7886e+03, Data-loss 7.3833e+02                  , pde-loss 6.3205e+02, initc-loss 1.3321e+04                    bc_loss 1.7176e+07, Test-Loss 7.3833e+02\n",
      "Epoch 13410, Training-Loss 2.4271e+03, Data-loss 7.6747e+02                  , pde-loss 6.6866e+02, initc-loss 1.3796e+04                    bc_loss 1.7021e+07, Test-Loss 7.6747e+02\n",
      "Epoch 13420, Training-Loss 2.1300e+03, Data-loss 8.4972e+02                  , pde-loss 7.7205e+02, initc-loss 1.4210e+04                    bc_loss 1.6947e+07, Test-Loss 8.4972e+02\n",
      "Epoch 13430, Training-Loss 2.4490e+03, Data-loss 3.7431e+02                  , pde-loss 6.4994e+02, initc-loss 1.4451e+04                    bc_loss 1.6965e+07, Test-Loss 3.7431e+02\n",
      "Epoch 13440, Training-Loss 2.7147e+03, Data-loss 8.4069e+02                  , pde-loss 6.8670e+02, initc-loss 1.4158e+04                    bc_loss 1.7077e+07, Test-Loss 8.4069e+02\n",
      "Epoch 13450, Training-Loss 2.3494e+03, Data-loss 8.1082e+02                  , pde-loss 8.2939e+02, initc-loss 1.4294e+04                    bc_loss 1.7080e+07, Test-Loss 8.1082e+02\n",
      "Epoch 13460, Training-Loss 2.5069e+03, Data-loss 4.8796e+02                  , pde-loss 7.6755e+02, initc-loss 1.4628e+04                    bc_loss 1.7070e+07, Test-Loss 4.8796e+02\n",
      "Epoch 13470, Training-Loss 2.6667e+03, Data-loss 9.7299e+02                  , pde-loss 7.2773e+02, initc-loss 1.4306e+04                    bc_loss 1.7057e+07, Test-Loss 9.7299e+02\n",
      "Epoch 13480, Training-Loss 2.4406e+03, Data-loss 8.9021e+02                  , pde-loss 7.7890e+02, initc-loss 1.4520e+04                    bc_loss 1.7091e+07, Test-Loss 8.9021e+02\n",
      "Epoch 13490, Training-Loss 2.3982e+03, Data-loss 4.9113e+02                  , pde-loss 7.6953e+02, initc-loss 1.4459e+04                    bc_loss 1.7141e+07, Test-Loss 4.9113e+02\n",
      "Epoch 13500, Training-Loss 2.5431e+03, Data-loss 5.9026e+02                  , pde-loss 6.8453e+02, initc-loss 1.4431e+04                    bc_loss 1.7136e+07, Test-Loss 5.9026e+02\n",
      "Epoch 13510, Training-Loss 2.3053e+03, Data-loss 7.0188e+02                  , pde-loss 9.6774e+02, initc-loss 1.4829e+04                    bc_loss 1.7092e+07, Test-Loss 7.0188e+02\n",
      "Epoch 13520, Training-Loss 2.3689e+03, Data-loss 5.4140e+02                  , pde-loss 7.7597e+02, initc-loss 1.4318e+04                    bc_loss 1.7252e+07, Test-Loss 5.4140e+02\n",
      "Epoch 13530, Training-Loss 2.4373e+03, Data-loss 5.6497e+02                  , pde-loss 7.6233e+02, initc-loss 1.4354e+04                    bc_loss 1.7249e+07, Test-Loss 5.6497e+02\n",
      "Epoch 13540, Training-Loss 2.5700e+03, Data-loss 7.0544e+02                  , pde-loss 8.3867e+02, initc-loss 1.4500e+04                    bc_loss 1.7147e+07, Test-Loss 7.0544e+02\n",
      "Epoch 13550, Training-Loss 2.2007e+03, Data-loss 6.8286e+02                  , pde-loss 9.0482e+02, initc-loss 1.4392e+04                    bc_loss 1.7240e+07, Test-Loss 6.8286e+02\n",
      "Epoch 13560, Training-Loss 2.2090e+03, Data-loss 5.6287e+02                  , pde-loss 9.5280e+02, initc-loss 1.4151e+04                    bc_loss 1.7412e+07, Test-Loss 5.6287e+02\n",
      "Epoch 13570, Training-Loss 2.5282e+03, Data-loss 4.9085e+02                  , pde-loss 8.4628e+02, initc-loss 1.3884e+04                    bc_loss 1.7469e+07, Test-Loss 4.9085e+02\n",
      "Epoch 13580, Training-Loss 2.1934e+03, Data-loss 5.8169e+02                  , pde-loss 7.8319e+02, initc-loss 1.4027e+04                    bc_loss 1.7397e+07, Test-Loss 5.8169e+02\n",
      "Epoch 13590, Training-Loss 2.2265e+03, Data-loss 6.0853e+02                  , pde-loss 9.9736e+02, initc-loss 1.4209e+04                    bc_loss 1.7325e+07, Test-Loss 6.0853e+02\n",
      "Epoch 13600, Training-Loss 2.5357e+03, Data-loss 6.0455e+02                  , pde-loss 8.9129e+02, initc-loss 1.4769e+04                    bc_loss 1.7231e+07, Test-Loss 6.0455e+02\n",
      "Epoch 13610, Training-Loss 2.3005e+03, Data-loss 5.2995e+02                  , pde-loss 9.8794e+02, initc-loss 1.4564e+04                    bc_loss 1.7313e+07, Test-Loss 5.2995e+02\n",
      "Epoch 13620, Training-Loss 2.3301e+03, Data-loss 4.8936e+02                  , pde-loss 1.1115e+03, initc-loss 1.5185e+04                    bc_loss 1.7208e+07, Test-Loss 4.8936e+02\n",
      "Epoch 13630, Training-Loss 2.4018e+03, Data-loss 3.0238e+02                  , pde-loss 1.0802e+03, initc-loss 1.4660e+04                    bc_loss 1.7292e+07, Test-Loss 3.0238e+02\n",
      "Epoch 13640, Training-Loss 2.5066e+03, Data-loss 6.6208e+02                  , pde-loss 1.0679e+03, initc-loss 1.5522e+04                    bc_loss 1.7126e+07, Test-Loss 6.6208e+02\n",
      "Epoch 13650, Training-Loss 2.2506e+03, Data-loss 5.1072e+02                  , pde-loss 1.1685e+03, initc-loss 1.5266e+04                    bc_loss 1.7147e+07, Test-Loss 5.1072e+02\n",
      "Epoch 13660, Training-Loss 2.3261e+03, Data-loss 8.2479e+02                  , pde-loss 1.0640e+03, initc-loss 1.5139e+04                    bc_loss 1.7246e+07, Test-Loss 8.2479e+02\n",
      "Epoch 13670, Training-Loss 2.3984e+03, Data-loss 7.3208e+02                  , pde-loss 9.4649e+02, initc-loss 1.4337e+04                    bc_loss 1.7355e+07, Test-Loss 7.3208e+02\n",
      "Epoch 13680, Training-Loss 2.0784e+03, Data-loss 6.2614e+02                  , pde-loss 1.1804e+03, initc-loss 1.4815e+04                    bc_loss 1.7386e+07, Test-Loss 6.2614e+02\n",
      "Epoch 13690, Training-Loss 2.2741e+03, Data-loss 5.2169e+02                  , pde-loss 9.9757e+02, initc-loss 1.5256e+04                    bc_loss 1.7325e+07, Test-Loss 5.2169e+02\n",
      "Epoch 13700, Training-Loss 2.2559e+03, Data-loss 6.5794e+02                  , pde-loss 1.1261e+03, initc-loss 1.5371e+04                    bc_loss 1.7273e+07, Test-Loss 6.5794e+02\n",
      "Epoch 13710, Training-Loss 2.1761e+03, Data-loss 6.4624e+02                  , pde-loss 1.0639e+03, initc-loss 1.5074e+04                    bc_loss 1.7322e+07, Test-Loss 6.4624e+02\n",
      "Epoch 13720, Training-Loss 2.3850e+03, Data-loss 4.0383e+02                  , pde-loss 1.1807e+03, initc-loss 1.4545e+04                    bc_loss 1.7488e+07, Test-Loss 4.0383e+02\n",
      "Epoch 13730, Training-Loss 2.3675e+03, Data-loss 7.5404e+02                  , pde-loss 1.0982e+03, initc-loss 1.4246e+04                    bc_loss 1.7524e+07, Test-Loss 7.5404e+02\n",
      "Epoch 13740, Training-Loss 2.1394e+03, Data-loss 4.7298e+02                  , pde-loss 1.3765e+03, initc-loss 1.5380e+04                    bc_loss 1.7286e+07, Test-Loss 4.7298e+02\n",
      "Epoch 13750, Training-Loss 2.3377e+03, Data-loss 4.7106e+02                  , pde-loss 1.1605e+03, initc-loss 1.5813e+04                    bc_loss 1.7236e+07, Test-Loss 4.7106e+02\n",
      "Epoch 13760, Training-Loss 2.2008e+03, Data-loss 5.1660e+02                  , pde-loss 1.2132e+03, initc-loss 1.4951e+04                    bc_loss 1.7381e+07, Test-Loss 5.1660e+02\n",
      "Epoch 13770, Training-Loss 2.3507e+03, Data-loss 5.6764e+02                  , pde-loss 1.2246e+03, initc-loss 1.4617e+04                    bc_loss 1.7430e+07, Test-Loss 5.6764e+02\n",
      "Epoch 13780, Training-Loss 2.1406e+03, Data-loss 6.1200e+02                  , pde-loss 1.1542e+03, initc-loss 1.4882e+04                    bc_loss 1.7478e+07, Test-Loss 6.1200e+02\n",
      "Epoch 13790, Training-Loss 2.2062e+03, Data-loss 3.1784e+02                  , pde-loss 1.0687e+03, initc-loss 1.4864e+04                    bc_loss 1.7497e+07, Test-Loss 3.1784e+02\n",
      "Epoch 13800, Training-Loss 2.3916e+03, Data-loss 5.1099e+02                  , pde-loss 1.2504e+03, initc-loss 1.5117e+04                    bc_loss 1.7302e+07, Test-Loss 5.1099e+02\n",
      "Epoch 13810, Training-Loss 2.4044e+03, Data-loss 4.6029e+02                  , pde-loss 8.3929e+02, initc-loss 1.5057e+04                    bc_loss 1.7380e+07, Test-Loss 4.6029e+02\n",
      "Epoch 13820, Training-Loss 2.4484e+03, Data-loss 5.0540e+02                  , pde-loss 1.0022e+03, initc-loss 1.5503e+04                    bc_loss 1.7406e+07, Test-Loss 5.0540e+02\n",
      "Epoch 13830, Training-Loss 2.1956e+03, Data-loss 5.1459e+02                  , pde-loss 1.0860e+03, initc-loss 1.5224e+04                    bc_loss 1.7362e+07, Test-Loss 5.1459e+02\n",
      "Epoch 13840, Training-Loss 2.2547e+03, Data-loss 4.6711e+02                  , pde-loss 1.1663e+03, initc-loss 1.5038e+04                    bc_loss 1.7422e+07, Test-Loss 4.6711e+02\n",
      "Epoch 13850, Training-Loss 2.2032e+03, Data-loss 5.0866e+02                  , pde-loss 1.2040e+03, initc-loss 1.4942e+04                    bc_loss 1.7452e+07, Test-Loss 5.0866e+02\n",
      "Epoch 13860, Training-Loss 2.1639e+03, Data-loss 5.0644e+02                  , pde-loss 9.9932e+02, initc-loss 1.5360e+04                    bc_loss 1.7404e+07, Test-Loss 5.0644e+02\n",
      "Epoch 13870, Training-Loss 2.2653e+03, Data-loss 2.4395e+02                  , pde-loss 1.2251e+03, initc-loss 1.5314e+04                    bc_loss 1.7367e+07, Test-Loss 2.4395e+02\n",
      "Epoch 13880, Training-Loss 2.2619e+03, Data-loss 3.7052e+02                  , pde-loss 9.1668e+02, initc-loss 1.5101e+04                    bc_loss 1.7461e+07, Test-Loss 3.7052e+02\n",
      "Epoch 13890, Training-Loss 2.1792e+03, Data-loss 5.8341e+02                  , pde-loss 1.0217e+03, initc-loss 1.5240e+04                    bc_loss 1.7486e+07, Test-Loss 5.8341e+02\n",
      "Epoch 13900, Training-Loss 2.2394e+03, Data-loss 4.4311e+02                  , pde-loss 1.2544e+03, initc-loss 1.4612e+04                    bc_loss 1.7521e+07, Test-Loss 4.4311e+02\n",
      "Epoch 13910, Training-Loss 2.0551e+03, Data-loss 4.1811e+02                  , pde-loss 1.1295e+03, initc-loss 1.4809e+04                    bc_loss 1.7561e+07, Test-Loss 4.1811e+02\n",
      "Epoch 13920, Training-Loss 2.1465e+03, Data-loss 4.9990e+02                  , pde-loss 1.1967e+03, initc-loss 1.5048e+04                    bc_loss 1.7490e+07, Test-Loss 4.9990e+02\n",
      "Epoch 13930, Training-Loss 2.3076e+03, Data-loss 3.5064e+02                  , pde-loss 1.2073e+03, initc-loss 1.5372e+04                    bc_loss 1.7444e+07, Test-Loss 3.5064e+02\n",
      "Epoch 13940, Training-Loss 2.0278e+03, Data-loss 6.8749e+02                  , pde-loss 1.1891e+03, initc-loss 1.4869e+04                    bc_loss 1.7564e+07, Test-Loss 6.8749e+02\n",
      "Epoch 13950, Training-Loss 2.1820e+03, Data-loss 6.3723e+02                  , pde-loss 1.0015e+03, initc-loss 1.5094e+04                    bc_loss 1.7514e+07, Test-Loss 6.3723e+02\n",
      "Epoch 13960, Training-Loss 2.2855e+03, Data-loss 3.6649e+02                  , pde-loss 1.1148e+03, initc-loss 1.4977e+04                    bc_loss 1.7528e+07, Test-Loss 3.6649e+02\n",
      "Epoch 13970, Training-Loss 2.0784e+03, Data-loss 6.9196e+02                  , pde-loss 1.3192e+03, initc-loss 1.5205e+04                    bc_loss 1.7446e+07, Test-Loss 6.9196e+02\n",
      "Epoch 13980, Training-Loss 2.3225e+03, Data-loss 5.2324e+02                  , pde-loss 1.0470e+03, initc-loss 1.4441e+04                    bc_loss 1.7608e+07, Test-Loss 5.2324e+02\n",
      "Epoch 13990, Training-Loss 2.3110e+03, Data-loss 4.7868e+02                  , pde-loss 1.1405e+03, initc-loss 1.4907e+04                    bc_loss 1.7605e+07, Test-Loss 4.7868e+02\n",
      "Epoch 14000, Training-Loss 2.1471e+03, Data-loss 3.4992e+02                  , pde-loss 1.1929e+03, initc-loss 1.4054e+04                    bc_loss 1.7793e+07, Test-Loss 3.4992e+02\n",
      "Epoch 14010, Training-Loss 2.1976e+03, Data-loss 3.3839e+02                  , pde-loss 9.7448e+02, initc-loss 1.4548e+04                    bc_loss 1.7694e+07, Test-Loss 3.3839e+02\n",
      "Epoch 14020, Training-Loss 2.2775e+03, Data-loss 4.6145e+02                  , pde-loss 9.9417e+02, initc-loss 1.4965e+04                    bc_loss 1.7561e+07, Test-Loss 4.6145e+02\n",
      "Epoch 14030, Training-Loss 2.2004e+03, Data-loss 3.7040e+02                  , pde-loss 1.3166e+03, initc-loss 1.4105e+04                    bc_loss 1.7726e+07, Test-Loss 3.7040e+02\n",
      "Epoch 14040, Training-Loss 2.1590e+03, Data-loss 5.5810e+02                  , pde-loss 9.7720e+02, initc-loss 1.4899e+04                    bc_loss 1.7582e+07, Test-Loss 5.5810e+02\n",
      "Epoch 14050, Training-Loss 2.1490e+03, Data-loss 3.0452e+02                  , pde-loss 1.3040e+03, initc-loss 1.5061e+04                    bc_loss 1.7552e+07, Test-Loss 3.0452e+02\n",
      "Epoch 14060, Training-Loss 2.2179e+03, Data-loss 2.6735e+02                  , pde-loss 1.2041e+03, initc-loss 1.4716e+04                    bc_loss 1.7531e+07, Test-Loss 2.6735e+02\n",
      "Epoch 14070, Training-Loss 2.1687e+03, Data-loss 2.8320e+02                  , pde-loss 1.0637e+03, initc-loss 1.5391e+04                    bc_loss 1.7436e+07, Test-Loss 2.8320e+02\n",
      "Epoch 14080, Training-Loss 2.0705e+03, Data-loss 4.7030e+02                  , pde-loss 1.0230e+03, initc-loss 1.4396e+04                    bc_loss 1.7721e+07, Test-Loss 4.7030e+02\n",
      "Epoch 14090, Training-Loss 2.0755e+03, Data-loss 2.3788e+02                  , pde-loss 1.1984e+03, initc-loss 1.4698e+04                    bc_loss 1.7703e+07, Test-Loss 2.3788e+02\n",
      "Epoch 14100, Training-Loss 2.0916e+03, Data-loss 3.9012e+02                  , pde-loss 1.1948e+03, initc-loss 1.4940e+04                    bc_loss 1.7567e+07, Test-Loss 3.9012e+02\n",
      "Epoch 14110, Training-Loss 2.2465e+03, Data-loss 3.5739e+02                  , pde-loss 1.2277e+03, initc-loss 1.4849e+04                    bc_loss 1.7505e+07, Test-Loss 3.5739e+02\n",
      "Epoch 14120, Training-Loss 2.1051e+03, Data-loss 3.7773e+02                  , pde-loss 1.1429e+03, initc-loss 1.5278e+04                    bc_loss 1.7519e+07, Test-Loss 3.7773e+02\n",
      "Epoch 14130, Training-Loss 2.2001e+03, Data-loss 4.3028e+02                  , pde-loss 1.2660e+03, initc-loss 1.5039e+04                    bc_loss 1.7494e+07, Test-Loss 4.3028e+02\n",
      "Epoch 14140, Training-Loss 2.1314e+03, Data-loss 4.2707e+02                  , pde-loss 1.2755e+03, initc-loss 1.5110e+04                    bc_loss 1.7571e+07, Test-Loss 4.2707e+02\n",
      "Epoch 14150, Training-Loss 2.0694e+03, Data-loss 3.8971e+02                  , pde-loss 1.1763e+03, initc-loss 1.4499e+04                    bc_loss 1.7705e+07, Test-Loss 3.8971e+02\n",
      "Epoch 14160, Training-Loss 2.1496e+03, Data-loss 3.9919e+02                  , pde-loss 1.0725e+03, initc-loss 1.4511e+04                    bc_loss 1.7714e+07, Test-Loss 3.9919e+02\n",
      "Epoch 14170, Training-Loss 2.0076e+03, Data-loss 3.7428e+02                  , pde-loss 1.1855e+03, initc-loss 1.4093e+04                    bc_loss 1.7869e+07, Test-Loss 3.7428e+02\n",
      "Epoch 14180, Training-Loss 2.3667e+03, Data-loss 4.1326e+02                  , pde-loss 1.1155e+03, initc-loss 1.3999e+04                    bc_loss 1.7885e+07, Test-Loss 4.1326e+02\n",
      "Epoch 14190, Training-Loss 2.0460e+03, Data-loss 4.2813e+02                  , pde-loss 1.3218e+03, initc-loss 1.4357e+04                    bc_loss 1.7775e+07, Test-Loss 4.2813e+02\n",
      "Epoch 14200, Training-Loss 1.9247e+03, Data-loss 4.4745e+02                  , pde-loss 1.1381e+03, initc-loss 1.4431e+04                    bc_loss 1.7772e+07, Test-Loss 4.4745e+02\n",
      "Epoch 14210, Training-Loss 2.1541e+03, Data-loss 4.7660e+02                  , pde-loss 1.2850e+03, initc-loss 1.4572e+04                    bc_loss 1.7647e+07, Test-Loss 4.7660e+02\n",
      "Epoch 14220, Training-Loss 2.1728e+03, Data-loss 2.4938e+02                  , pde-loss 1.2407e+03, initc-loss 1.4840e+04                    bc_loss 1.7700e+07, Test-Loss 2.4938e+02\n",
      "Epoch 14230, Training-Loss 2.2036e+03, Data-loss 3.1506e+02                  , pde-loss 1.1975e+03, initc-loss 1.4811e+04                    bc_loss 1.7671e+07, Test-Loss 3.1506e+02\n",
      "Epoch 14240, Training-Loss 2.0628e+03, Data-loss 2.7168e+02                  , pde-loss 1.3123e+03, initc-loss 1.4654e+04                    bc_loss 1.7721e+07, Test-Loss 2.7168e+02\n",
      "Epoch 14250, Training-Loss 2.0863e+03, Data-loss 3.8232e+02                  , pde-loss 1.2473e+03, initc-loss 1.4825e+04                    bc_loss 1.7709e+07, Test-Loss 3.8232e+02\n",
      "Epoch 14260, Training-Loss 2.0090e+03, Data-loss 3.2340e+02                  , pde-loss 1.1664e+03, initc-loss 1.4821e+04                    bc_loss 1.7633e+07, Test-Loss 3.2340e+02\n",
      "Epoch 14270, Training-Loss 2.0840e+03, Data-loss 3.2190e+02                  , pde-loss 1.2568e+03, initc-loss 1.5345e+04                    bc_loss 1.7529e+07, Test-Loss 3.2190e+02\n",
      "Epoch 14280, Training-Loss 1.8755e+03, Data-loss 3.1589e+02                  , pde-loss 1.3491e+03, initc-loss 1.4493e+04                    bc_loss 1.7720e+07, Test-Loss 3.1589e+02\n",
      "Epoch 14290, Training-Loss 2.0200e+03, Data-loss 3.8059e+02                  , pde-loss 1.1831e+03, initc-loss 1.4296e+04                    bc_loss 1.7759e+07, Test-Loss 3.8059e+02\n",
      "Epoch 14300, Training-Loss 1.9307e+03, Data-loss 4.0400e+02                  , pde-loss 1.2738e+03, initc-loss 1.4445e+04                    bc_loss 1.7780e+07, Test-Loss 4.0400e+02\n",
      "Epoch 14310, Training-Loss 2.1531e+03, Data-loss 3.6246e+02                  , pde-loss 1.2660e+03, initc-loss 1.4772e+04                    bc_loss 1.7615e+07, Test-Loss 3.6246e+02\n",
      "Epoch 14320, Training-Loss 2.3205e+03, Data-loss 2.8637e+02                  , pde-loss 1.1254e+03, initc-loss 1.4777e+04                    bc_loss 1.7628e+07, Test-Loss 2.8637e+02\n",
      "Epoch 14330, Training-Loss 2.1137e+03, Data-loss 2.4683e+02                  , pde-loss 1.1125e+03, initc-loss 1.4544e+04                    bc_loss 1.7723e+07, Test-Loss 2.4683e+02\n",
      "Epoch 14340, Training-Loss 2.1818e+03, Data-loss 4.0139e+02                  , pde-loss 1.3141e+03, initc-loss 1.4694e+04                    bc_loss 1.7680e+07, Test-Loss 4.0139e+02\n",
      "Epoch 14350, Training-Loss 2.1385e+03, Data-loss 3.6149e+02                  , pde-loss 1.3222e+03, initc-loss 1.4438e+04                    bc_loss 1.7694e+07, Test-Loss 3.6149e+02\n",
      "Epoch 14360, Training-Loss 2.0321e+03, Data-loss 2.6473e+02                  , pde-loss 1.3492e+03, initc-loss 1.4291e+04                    bc_loss 1.7734e+07, Test-Loss 2.6473e+02\n",
      "Epoch 14370, Training-Loss 2.0997e+03, Data-loss 2.4522e+02                  , pde-loss 1.3176e+03, initc-loss 1.4745e+04                    bc_loss 1.7642e+07, Test-Loss 2.4522e+02\n",
      "Epoch 14380, Training-Loss 2.2162e+03, Data-loss 2.9383e+02                  , pde-loss 1.1023e+03, initc-loss 1.5093e+04                    bc_loss 1.7569e+07, Test-Loss 2.9383e+02\n",
      "Epoch 14390, Training-Loss 2.0352e+03, Data-loss 2.2876e+02                  , pde-loss 1.1868e+03, initc-loss 1.4541e+04                    bc_loss 1.7687e+07, Test-Loss 2.2876e+02\n",
      "Epoch 14400, Training-Loss 2.0750e+03, Data-loss 5.1479e+02                  , pde-loss 1.4069e+03, initc-loss 1.5232e+04                    bc_loss 1.7519e+07, Test-Loss 5.1479e+02\n",
      "Epoch 14410, Training-Loss 2.2306e+03, Data-loss 3.0293e+02                  , pde-loss 1.0866e+03, initc-loss 1.4945e+04                    bc_loss 1.7637e+07, Test-Loss 3.0293e+02\n",
      "Epoch 14420, Training-Loss 2.1028e+03, Data-loss 3.5535e+02                  , pde-loss 1.2350e+03, initc-loss 1.4817e+04                    bc_loss 1.7630e+07, Test-Loss 3.5535e+02\n",
      "Epoch 14430, Training-Loss 2.0184e+03, Data-loss 3.3610e+02                  , pde-loss 1.4235e+03, initc-loss 1.4336e+04                    bc_loss 1.7786e+07, Test-Loss 3.3610e+02\n",
      "Epoch 14440, Training-Loss 2.2456e+03, Data-loss 2.0152e+02                  , pde-loss 1.2861e+03, initc-loss 1.4135e+04                    bc_loss 1.7832e+07, Test-Loss 2.0152e+02\n",
      "Epoch 14450, Training-Loss 2.0338e+03, Data-loss 3.9309e+02                  , pde-loss 1.3370e+03, initc-loss 1.3846e+04                    bc_loss 1.7948e+07, Test-Loss 3.9309e+02\n",
      "Epoch 14460, Training-Loss 2.0244e+03, Data-loss 3.5976e+02                  , pde-loss 1.2859e+03, initc-loss 1.4314e+04                    bc_loss 1.7758e+07, Test-Loss 3.5976e+02\n",
      "Epoch 14470, Training-Loss 2.0183e+03, Data-loss 3.2690e+02                  , pde-loss 1.4154e+03, initc-loss 1.4140e+04                    bc_loss 1.7828e+07, Test-Loss 3.2690e+02\n",
      "Epoch 14480, Training-Loss 2.0059e+03, Data-loss 2.8796e+02                  , pde-loss 1.2652e+03, initc-loss 1.4536e+04                    bc_loss 1.7733e+07, Test-Loss 2.8796e+02\n",
      "Epoch 14490, Training-Loss 2.1483e+03, Data-loss 3.5328e+02                  , pde-loss 1.3128e+03, initc-loss 1.4471e+04                    bc_loss 1.7706e+07, Test-Loss 3.5328e+02\n",
      "Epoch 14500, Training-Loss 1.9923e+03, Data-loss 3.0422e+02                  , pde-loss 1.2332e+03, initc-loss 1.4278e+04                    bc_loss 1.7813e+07, Test-Loss 3.0422e+02\n",
      "Epoch 14510, Training-Loss 1.9294e+03, Data-loss 2.7234e+02                  , pde-loss 1.4047e+03, initc-loss 1.4625e+04                    bc_loss 1.7640e+07, Test-Loss 2.7234e+02\n",
      "Epoch 14520, Training-Loss 2.0681e+03, Data-loss 2.5388e+02                  , pde-loss 1.2129e+03, initc-loss 1.4570e+04                    bc_loss 1.7719e+07, Test-Loss 2.5388e+02\n",
      "Epoch 14530, Training-Loss 2.0791e+03, Data-loss 4.3316e+02                  , pde-loss 1.1598e+03, initc-loss 1.4067e+04                    bc_loss 1.7892e+07, Test-Loss 4.3316e+02\n",
      "Epoch 14540, Training-Loss 2.0868e+03, Data-loss 3.5336e+02                  , pde-loss 1.3400e+03, initc-loss 1.4349e+04                    bc_loss 1.7796e+07, Test-Loss 3.5336e+02\n",
      "Epoch 14550, Training-Loss 2.0303e+03, Data-loss 3.1390e+02                  , pde-loss 1.1973e+03, initc-loss 1.4711e+04                    bc_loss 1.7681e+07, Test-Loss 3.1390e+02\n",
      "Epoch 14560, Training-Loss 2.0935e+03, Data-loss 3.8414e+02                  , pde-loss 1.3474e+03, initc-loss 1.4682e+04                    bc_loss 1.7718e+07, Test-Loss 3.8414e+02\n",
      "Epoch 14570, Training-Loss 2.2350e+03, Data-loss 4.1174e+02                  , pde-loss 1.1973e+03, initc-loss 1.4280e+04                    bc_loss 1.7828e+07, Test-Loss 4.1174e+02\n",
      "Epoch 14580, Training-Loss 2.0334e+03, Data-loss 1.8068e+02                  , pde-loss 1.4390e+03, initc-loss 1.4195e+04                    bc_loss 1.7886e+07, Test-Loss 1.8068e+02\n",
      "Epoch 14590, Training-Loss 2.0942e+03, Data-loss 4.0809e+02                  , pde-loss 1.3273e+03, initc-loss 1.4145e+04                    bc_loss 1.7859e+07, Test-Loss 4.0809e+02\n",
      "Epoch 14600, Training-Loss 2.1078e+03, Data-loss 2.1318e+02                  , pde-loss 1.2284e+03, initc-loss 1.4109e+04                    bc_loss 1.7890e+07, Test-Loss 2.1318e+02\n",
      "Epoch 14610, Training-Loss 2.1334e+03, Data-loss 3.6977e+02                  , pde-loss 1.3524e+03, initc-loss 1.3854e+04                    bc_loss 1.7961e+07, Test-Loss 3.6977e+02\n",
      "Epoch 14620, Training-Loss 2.0639e+03, Data-loss 2.9247e+02                  , pde-loss 1.1473e+03, initc-loss 1.4619e+04                    bc_loss 1.7726e+07, Test-Loss 2.9247e+02\n",
      "Epoch 14630, Training-Loss 1.9891e+03, Data-loss 1.7893e+02                  , pde-loss 1.4353e+03, initc-loss 1.4467e+04                    bc_loss 1.7704e+07, Test-Loss 1.7893e+02\n",
      "Epoch 14640, Training-Loss 1.9371e+03, Data-loss 3.8837e+02                  , pde-loss 1.2869e+03, initc-loss 1.4229e+04                    bc_loss 1.7818e+07, Test-Loss 3.8837e+02\n",
      "Epoch 14650, Training-Loss 2.0185e+03, Data-loss 2.5978e+02                  , pde-loss 1.4228e+03, initc-loss 1.4654e+04                    bc_loss 1.7622e+07, Test-Loss 2.5978e+02\n",
      "Epoch 14660, Training-Loss 2.0038e+03, Data-loss 1.6773e+02                  , pde-loss 1.2167e+03, initc-loss 1.4518e+04                    bc_loss 1.7717e+07, Test-Loss 1.6773e+02\n",
      "Epoch 14670, Training-Loss 2.1701e+03, Data-loss 1.9503e+02                  , pde-loss 1.4515e+03, initc-loss 1.4262e+04                    bc_loss 1.7797e+07, Test-Loss 1.9503e+02\n",
      "Epoch 14680, Training-Loss 2.1443e+03, Data-loss 4.0259e+02                  , pde-loss 1.3893e+03, initc-loss 1.4615e+04                    bc_loss 1.7682e+07, Test-Loss 4.0259e+02\n",
      "Epoch 14690, Training-Loss 2.0769e+03, Data-loss 3.4933e+02                  , pde-loss 1.3228e+03, initc-loss 1.4391e+04                    bc_loss 1.7776e+07, Test-Loss 3.4933e+02\n",
      "Epoch 14700, Training-Loss 1.9742e+03, Data-loss 2.1238e+02                  , pde-loss 1.2814e+03, initc-loss 1.4296e+04                    bc_loss 1.7814e+07, Test-Loss 2.1238e+02\n",
      "Epoch 14710, Training-Loss 2.1344e+03, Data-loss 2.5702e+02                  , pde-loss 1.2837e+03, initc-loss 1.4376e+04                    bc_loss 1.7742e+07, Test-Loss 2.5702e+02\n",
      "Epoch 14720, Training-Loss 1.9965e+03, Data-loss 1.8082e+02                  , pde-loss 1.3127e+03, initc-loss 1.4149e+04                    bc_loss 1.7800e+07, Test-Loss 1.8082e+02\n",
      "Epoch 14730, Training-Loss 2.0170e+03, Data-loss 1.7605e+02                  , pde-loss 1.2389e+03, initc-loss 1.4352e+04                    bc_loss 1.7757e+07, Test-Loss 1.7605e+02\n",
      "Epoch 14740, Training-Loss 2.0705e+03, Data-loss 2.3253e+02                  , pde-loss 1.4637e+03, initc-loss 1.4333e+04                    bc_loss 1.7732e+07, Test-Loss 2.3253e+02\n",
      "Epoch 14750, Training-Loss 1.9919e+03, Data-loss 2.4177e+02                  , pde-loss 1.4059e+03, initc-loss 1.4764e+04                    bc_loss 1.7670e+07, Test-Loss 2.4177e+02\n",
      "Epoch 14760, Training-Loss 2.0785e+03, Data-loss 3.0893e+02                  , pde-loss 1.6465e+03, initc-loss 1.4159e+04                    bc_loss 1.7751e+07, Test-Loss 3.0893e+02\n",
      "Epoch 14770, Training-Loss 1.9365e+03, Data-loss 2.6186e+02                  , pde-loss 1.3330e+03, initc-loss 1.4633e+04                    bc_loss 1.7626e+07, Test-Loss 2.6186e+02\n",
      "Epoch 14780, Training-Loss 1.9739e+03, Data-loss 1.8648e+02                  , pde-loss 1.7202e+03, initc-loss 1.4264e+04                    bc_loss 1.7717e+07, Test-Loss 1.8648e+02\n",
      "Epoch 14790, Training-Loss 1.9010e+03, Data-loss 2.7418e+02                  , pde-loss 1.6074e+03, initc-loss 1.4797e+04                    bc_loss 1.7615e+07, Test-Loss 2.7418e+02\n",
      "Epoch 14800, Training-Loss 2.0663e+03, Data-loss 2.7069e+02                  , pde-loss 1.4009e+03, initc-loss 1.4938e+04                    bc_loss 1.7600e+07, Test-Loss 2.7069e+02\n",
      "Epoch 14810, Training-Loss 2.0360e+03, Data-loss 2.9946e+02                  , pde-loss 1.2833e+03, initc-loss 1.4314e+04                    bc_loss 1.7716e+07, Test-Loss 2.9946e+02\n",
      "Epoch 14820, Training-Loss 2.0398e+03, Data-loss 2.2716e+02                  , pde-loss 1.5573e+03, initc-loss 1.4187e+04                    bc_loss 1.7777e+07, Test-Loss 2.2716e+02\n",
      "Epoch 14830, Training-Loss 1.9968e+03, Data-loss 2.2856e+02                  , pde-loss 1.3517e+03, initc-loss 1.4258e+04                    bc_loss 1.7778e+07, Test-Loss 2.2856e+02\n",
      "Epoch 14840, Training-Loss 1.9834e+03, Data-loss 3.0923e+02                  , pde-loss 1.5463e+03, initc-loss 1.4324e+04                    bc_loss 1.7776e+07, Test-Loss 3.0923e+02\n",
      "Epoch 14850, Training-Loss 2.0716e+03, Data-loss 1.9191e+02                  , pde-loss 1.3056e+03, initc-loss 1.4410e+04                    bc_loss 1.7727e+07, Test-Loss 1.9191e+02\n",
      "Epoch 14860, Training-Loss 2.0990e+03, Data-loss 2.9119e+02                  , pde-loss 1.4214e+03, initc-loss 1.4130e+04                    bc_loss 1.7825e+07, Test-Loss 2.9119e+02\n",
      "Epoch 14870, Training-Loss 2.0601e+03, Data-loss 2.4748e+02                  , pde-loss 1.3837e+03, initc-loss 1.4021e+04                    bc_loss 1.7868e+07, Test-Loss 2.4748e+02\n",
      "Epoch 14880, Training-Loss 1.9563e+03, Data-loss 2.8343e+02                  , pde-loss 1.5893e+03, initc-loss 1.3414e+04                    bc_loss 1.8076e+07, Test-Loss 2.8343e+02\n",
      "Epoch 14890, Training-Loss 2.0491e+03, Data-loss 2.0712e+02                  , pde-loss 1.3827e+03, initc-loss 1.3629e+04                    bc_loss 1.8075e+07, Test-Loss 2.0712e+02\n",
      "Epoch 14900, Training-Loss 1.9946e+03, Data-loss 1.4801e+02                  , pde-loss 1.2751e+03, initc-loss 1.3920e+04                    bc_loss 1.7905e+07, Test-Loss 1.4801e+02\n",
      "Epoch 14910, Training-Loss 1.9857e+03, Data-loss 2.9432e+02                  , pde-loss 1.6110e+03, initc-loss 1.3669e+04                    bc_loss 1.8009e+07, Test-Loss 2.9432e+02\n",
      "Epoch 14920, Training-Loss 2.0248e+03, Data-loss 2.3834e+02                  , pde-loss 1.1391e+03, initc-loss 1.4288e+04                    bc_loss 1.7951e+07, Test-Loss 2.3834e+02\n",
      "Epoch 14930, Training-Loss 2.1637e+03, Data-loss 2.4228e+02                  , pde-loss 1.3357e+03, initc-loss 1.3805e+04                    bc_loss 1.7925e+07, Test-Loss 2.4228e+02\n",
      "Epoch 14940, Training-Loss 2.1042e+03, Data-loss 2.5585e+02                  , pde-loss 1.4617e+03, initc-loss 1.4199e+04                    bc_loss 1.7807e+07, Test-Loss 2.5585e+02\n",
      "Epoch 14950, Training-Loss 2.0076e+03, Data-loss 2.8086e+02                  , pde-loss 1.5330e+03, initc-loss 1.3829e+04                    bc_loss 1.7885e+07, Test-Loss 2.8086e+02\n",
      "Epoch 14960, Training-Loss 1.9770e+03, Data-loss 2.7888e+02                  , pde-loss 1.4763e+03, initc-loss 1.4085e+04                    bc_loss 1.7875e+07, Test-Loss 2.7888e+02\n",
      "Epoch 14970, Training-Loss 2.1566e+03, Data-loss 2.3906e+02                  , pde-loss 1.4515e+03, initc-loss 1.4241e+04                    bc_loss 1.7792e+07, Test-Loss 2.3906e+02\n",
      "Epoch 14980, Training-Loss 1.9445e+03, Data-loss 2.2608e+02                  , pde-loss 1.5238e+03, initc-loss 1.4705e+04                    bc_loss 1.7686e+07, Test-Loss 2.2608e+02\n",
      "Epoch 14990, Training-Loss 2.0147e+03, Data-loss 3.4773e+02                  , pde-loss 1.4863e+03, initc-loss 1.4421e+04                    bc_loss 1.7671e+07, Test-Loss 3.4773e+02\n",
      "Epoch 15000, Training-Loss 1.9744e+03, Data-loss 1.5777e+02                  , pde-loss 1.5057e+03, initc-loss 1.4400e+04                    bc_loss 1.7740e+07, Test-Loss 1.5777e+02\n",
      "Epoch 15010, Training-Loss 2.0286e+03, Data-loss 2.7663e+02                  , pde-loss 1.5042e+03, initc-loss 1.4465e+04                    bc_loss 1.7742e+07, Test-Loss 2.7663e+02\n",
      "Epoch 15020, Training-Loss 1.9589e+03, Data-loss 1.4774e+02                  , pde-loss 1.4899e+03, initc-loss 1.4152e+04                    bc_loss 1.7847e+07, Test-Loss 1.4774e+02\n",
      "Epoch 15030, Training-Loss 2.0309e+03, Data-loss 1.8635e+02                  , pde-loss 1.2992e+03, initc-loss 1.4005e+04                    bc_loss 1.7899e+07, Test-Loss 1.8635e+02\n",
      "Epoch 15040, Training-Loss 2.0548e+03, Data-loss 1.9356e+02                  , pde-loss 1.4171e+03, initc-loss 1.4338e+04                    bc_loss 1.7761e+07, Test-Loss 1.9356e+02\n",
      "Epoch 15050, Training-Loss 2.0193e+03, Data-loss 1.8492e+02                  , pde-loss 1.5982e+03, initc-loss 1.4075e+04                    bc_loss 1.7808e+07, Test-Loss 1.8492e+02\n",
      "Epoch 15060, Training-Loss 1.9881e+03, Data-loss 2.6629e+02                  , pde-loss 1.6061e+03, initc-loss 1.4061e+04                    bc_loss 1.7808e+07, Test-Loss 2.6629e+02\n",
      "Epoch 15070, Training-Loss 1.9575e+03, Data-loss 2.0284e+02                  , pde-loss 1.7231e+03, initc-loss 1.3965e+04                    bc_loss 1.7906e+07, Test-Loss 2.0284e+02\n",
      "Epoch 15080, Training-Loss 2.0290e+03, Data-loss 2.9981e+02                  , pde-loss 1.3937e+03, initc-loss 1.3776e+04                    bc_loss 1.7958e+07, Test-Loss 2.9981e+02\n",
      "Epoch 15090, Training-Loss 1.9252e+03, Data-loss 1.9411e+02                  , pde-loss 1.4431e+03, initc-loss 1.3859e+04                    bc_loss 1.7957e+07, Test-Loss 1.9411e+02\n",
      "Epoch 15100, Training-Loss 1.9453e+03, Data-loss 2.4944e+02                  , pde-loss 1.5042e+03, initc-loss 1.4132e+04                    bc_loss 1.7825e+07, Test-Loss 2.4944e+02\n",
      "Epoch 15110, Training-Loss 2.0222e+03, Data-loss 1.8695e+02                  , pde-loss 1.4012e+03, initc-loss 1.3700e+04                    bc_loss 1.7912e+07, Test-Loss 1.8695e+02\n",
      "Epoch 15120, Training-Loss 1.9704e+03, Data-loss 2.3951e+02                  , pde-loss 1.5418e+03, initc-loss 1.3836e+04                    bc_loss 1.7933e+07, Test-Loss 2.3951e+02\n",
      "Epoch 15130, Training-Loss 1.9334e+03, Data-loss 2.3940e+02                  , pde-loss 1.6268e+03, initc-loss 1.3576e+04                    bc_loss 1.7934e+07, Test-Loss 2.3940e+02\n",
      "Epoch 15140, Training-Loss 1.9289e+03, Data-loss 2.0862e+02                  , pde-loss 1.9831e+03, initc-loss 1.4338e+04                    bc_loss 1.7690e+07, Test-Loss 2.0862e+02\n",
      "Epoch 15150, Training-Loss 2.1594e+03, Data-loss 2.4962e+02                  , pde-loss 1.4529e+03, initc-loss 1.4383e+04                    bc_loss 1.7678e+07, Test-Loss 2.4962e+02\n",
      "Epoch 15160, Training-Loss 2.0031e+03, Data-loss 2.5569e+02                  , pde-loss 1.6382e+03, initc-loss 1.4366e+04                    bc_loss 1.7734e+07, Test-Loss 2.5569e+02\n",
      "Epoch 15170, Training-Loss 1.9733e+03, Data-loss 2.6361e+02                  , pde-loss 1.6552e+03, initc-loss 1.4254e+04                    bc_loss 1.7698e+07, Test-Loss 2.6361e+02\n",
      "Epoch 15180, Training-Loss 2.0164e+03, Data-loss 2.3093e+02                  , pde-loss 1.3819e+03, initc-loss 1.3859e+04                    bc_loss 1.7824e+07, Test-Loss 2.3093e+02\n",
      "Epoch 15190, Training-Loss 1.9926e+03, Data-loss 1.9079e+02                  , pde-loss 1.8317e+03, initc-loss 1.3742e+04                    bc_loss 1.7873e+07, Test-Loss 1.9079e+02\n",
      "Epoch 15200, Training-Loss 2.0474e+03, Data-loss 1.8196e+02                  , pde-loss 1.6827e+03, initc-loss 1.3806e+04                    bc_loss 1.7995e+07, Test-Loss 1.8196e+02\n",
      "Epoch 15210, Training-Loss 2.0329e+03, Data-loss 2.4725e+02                  , pde-loss 1.5800e+03, initc-loss 1.3768e+04                    bc_loss 1.7965e+07, Test-Loss 2.4725e+02\n",
      "Epoch 15220, Training-Loss 1.9876e+03, Data-loss 1.5990e+02                  , pde-loss 1.4565e+03, initc-loss 1.3977e+04                    bc_loss 1.7812e+07, Test-Loss 1.5990e+02\n",
      "Epoch 15230, Training-Loss 1.8906e+03, Data-loss 2.7500e+02                  , pde-loss 1.7475e+03, initc-loss 1.4319e+04                    bc_loss 1.7761e+07, Test-Loss 2.7500e+02\n",
      "Epoch 15240, Training-Loss 1.9472e+03, Data-loss 1.9947e+02                  , pde-loss 1.5176e+03, initc-loss 1.4034e+04                    bc_loss 1.7802e+07, Test-Loss 1.9947e+02\n",
      "Epoch 15250, Training-Loss 1.9434e+03, Data-loss 1.8407e+02                  , pde-loss 1.4473e+03, initc-loss 1.3898e+04                    bc_loss 1.7809e+07, Test-Loss 1.8407e+02\n",
      "Epoch 15260, Training-Loss 2.0212e+03, Data-loss 1.9138e+02                  , pde-loss 1.7870e+03, initc-loss 1.4158e+04                    bc_loss 1.7681e+07, Test-Loss 1.9138e+02\n",
      "Epoch 15270, Training-Loss 2.0551e+03, Data-loss 2.0266e+02                  , pde-loss 1.4545e+03, initc-loss 1.4506e+04                    bc_loss 1.7666e+07, Test-Loss 2.0266e+02\n",
      "Epoch 15280, Training-Loss 2.0767e+03, Data-loss 1.5343e+02                  , pde-loss 1.6289e+03, initc-loss 1.4358e+04                    bc_loss 1.7675e+07, Test-Loss 1.5343e+02\n",
      "Epoch 15290, Training-Loss 2.0170e+03, Data-loss 2.6921e+02                  , pde-loss 1.9876e+03, initc-loss 1.4648e+04                    bc_loss 1.7592e+07, Test-Loss 2.6921e+02\n",
      "Epoch 15300, Training-Loss 1.9629e+03, Data-loss 1.9892e+02                  , pde-loss 1.6737e+03, initc-loss 1.4163e+04                    bc_loss 1.7707e+07, Test-Loss 1.9892e+02\n",
      "Epoch 15310, Training-Loss 1.9892e+03, Data-loss 2.3517e+02                  , pde-loss 1.5523e+03, initc-loss 1.4783e+04                    bc_loss 1.7542e+07, Test-Loss 2.3517e+02\n",
      "Epoch 15320, Training-Loss 2.0257e+03, Data-loss 2.2085e+02                  , pde-loss 1.6011e+03, initc-loss 1.4598e+04                    bc_loss 1.7562e+07, Test-Loss 2.2085e+02\n",
      "Epoch 15330, Training-Loss 2.0123e+03, Data-loss 2.3819e+02                  , pde-loss 1.6545e+03, initc-loss 1.4173e+04                    bc_loss 1.7604e+07, Test-Loss 2.3819e+02\n",
      "Epoch 15340, Training-Loss 2.0264e+03, Data-loss 1.7345e+02                  , pde-loss 1.9637e+03, initc-loss 1.4231e+04                    bc_loss 1.7673e+07, Test-Loss 1.7345e+02\n",
      "Epoch 15350, Training-Loss 1.9877e+03, Data-loss 2.6720e+02                  , pde-loss 1.8450e+03, initc-loss 1.4350e+04                    bc_loss 1.7620e+07, Test-Loss 2.6720e+02\n",
      "Epoch 15360, Training-Loss 2.0087e+03, Data-loss 2.6055e+02                  , pde-loss 1.6211e+03, initc-loss 1.4282e+04                    bc_loss 1.7631e+07, Test-Loss 2.6055e+02\n",
      "Epoch 15370, Training-Loss 1.9453e+03, Data-loss 2.5177e+02                  , pde-loss 1.8633e+03, initc-loss 1.4025e+04                    bc_loss 1.7679e+07, Test-Loss 2.5177e+02\n",
      "Epoch 15380, Training-Loss 1.9375e+03, Data-loss 1.7146e+02                  , pde-loss 1.6771e+03, initc-loss 1.3903e+04                    bc_loss 1.7751e+07, Test-Loss 1.7146e+02\n",
      "Epoch 15390, Training-Loss 1.9994e+03, Data-loss 2.1993e+02                  , pde-loss 1.7397e+03, initc-loss 1.4040e+04                    bc_loss 1.7728e+07, Test-Loss 2.1993e+02\n",
      "Epoch 15400, Training-Loss 1.8783e+03, Data-loss 1.1706e+02                  , pde-loss 1.8118e+03, initc-loss 1.4041e+04                    bc_loss 1.7776e+07, Test-Loss 1.1706e+02\n",
      "Epoch 15410, Training-Loss 1.9722e+03, Data-loss 1.5004e+02                  , pde-loss 1.7607e+03, initc-loss 1.3936e+04                    bc_loss 1.7779e+07, Test-Loss 1.5004e+02\n",
      "Epoch 15420, Training-Loss 1.9007e+03, Data-loss 1.9920e+02                  , pde-loss 1.8377e+03, initc-loss 1.3958e+04                    bc_loss 1.7624e+07, Test-Loss 1.9920e+02\n",
      "Epoch 15430, Training-Loss 1.9590e+03, Data-loss 2.9710e+02                  , pde-loss 1.9031e+03, initc-loss 1.4425e+04                    bc_loss 1.7539e+07, Test-Loss 2.9710e+02\n",
      "Epoch 15440, Training-Loss 1.9367e+03, Data-loss 2.0179e+02                  , pde-loss 1.6734e+03, initc-loss 1.4363e+04                    bc_loss 1.7627e+07, Test-Loss 2.0179e+02\n",
      "Epoch 15450, Training-Loss 2.0195e+03, Data-loss 2.3280e+02                  , pde-loss 1.6530e+03, initc-loss 1.4052e+04                    bc_loss 1.7691e+07, Test-Loss 2.3280e+02\n",
      "Epoch 15460, Training-Loss 1.9853e+03, Data-loss 2.2939e+02                  , pde-loss 1.5279e+03, initc-loss 1.4146e+04                    bc_loss 1.7511e+07, Test-Loss 2.2939e+02\n",
      "Epoch 15470, Training-Loss 1.9159e+03, Data-loss 1.8677e+02                  , pde-loss 1.8067e+03, initc-loss 1.4447e+04                    bc_loss 1.7507e+07, Test-Loss 1.8677e+02\n",
      "Epoch 15480, Training-Loss 2.0163e+03, Data-loss 1.7836e+02                  , pde-loss 2.0525e+03, initc-loss 1.3975e+04                    bc_loss 1.7673e+07, Test-Loss 1.7836e+02\n",
      "Epoch 15490, Training-Loss 2.0459e+03, Data-loss 2.0966e+02                  , pde-loss 1.6857e+03, initc-loss 1.3874e+04                    bc_loss 1.7642e+07, Test-Loss 2.0966e+02\n",
      "Epoch 15500, Training-Loss 2.0126e+03, Data-loss 2.4903e+02                  , pde-loss 1.7535e+03, initc-loss 1.4035e+04                    bc_loss 1.7578e+07, Test-Loss 2.4903e+02\n",
      "Epoch 15510, Training-Loss 2.0496e+03, Data-loss 2.4515e+02                  , pde-loss 1.7910e+03, initc-loss 1.3952e+04                    bc_loss 1.7592e+07, Test-Loss 2.4515e+02\n",
      "Epoch 15520, Training-Loss 1.9690e+03, Data-loss 1.8339e+02                  , pde-loss 1.8156e+03, initc-loss 1.4288e+04                    bc_loss 1.7456e+07, Test-Loss 1.8339e+02\n",
      "Epoch 15530, Training-Loss 1.9268e+03, Data-loss 2.1629e+02                  , pde-loss 1.8985e+03, initc-loss 1.4582e+04                    bc_loss 1.7259e+07, Test-Loss 2.1629e+02\n",
      "Epoch 15540, Training-Loss 1.9669e+03, Data-loss 1.9570e+02                  , pde-loss 2.1076e+03, initc-loss 1.4464e+04                    bc_loss 1.7413e+07, Test-Loss 1.9570e+02\n",
      "Epoch 15550, Training-Loss 1.9514e+03, Data-loss 1.5487e+02                  , pde-loss 1.6423e+03, initc-loss 1.4198e+04                    bc_loss 1.7473e+07, Test-Loss 1.5487e+02\n",
      "Epoch 15560, Training-Loss 1.9560e+03, Data-loss 1.3611e+02                  , pde-loss 1.5987e+03, initc-loss 1.3839e+04                    bc_loss 1.7474e+07, Test-Loss 1.3611e+02\n",
      "Epoch 15570, Training-Loss 1.9803e+03, Data-loss 1.9049e+02                  , pde-loss 1.3861e+03, initc-loss 1.3738e+04                    bc_loss 1.7587e+07, Test-Loss 1.9049e+02\n",
      "Epoch 15580, Training-Loss 1.9739e+03, Data-loss 2.8881e+02                  , pde-loss 1.5154e+03, initc-loss 1.3785e+04                    bc_loss 1.7595e+07, Test-Loss 2.8881e+02\n",
      "Epoch 15590, Training-Loss 1.9500e+03, Data-loss 1.6500e+02                  , pde-loss 1.8399e+03, initc-loss 1.4057e+04                    bc_loss 1.7512e+07, Test-Loss 1.6500e+02\n",
      "Epoch 15600, Training-Loss 1.9469e+03, Data-loss 2.0834e+02                  , pde-loss 1.8526e+03, initc-loss 1.4130e+04                    bc_loss 1.7493e+07, Test-Loss 2.0834e+02\n",
      "Epoch 15610, Training-Loss 1.9311e+03, Data-loss 1.9615e+02                  , pde-loss 1.6721e+03, initc-loss 1.4309e+04                    bc_loss 1.7413e+07, Test-Loss 1.9615e+02\n",
      "Epoch 15620, Training-Loss 1.9211e+03, Data-loss 1.5425e+02                  , pde-loss 1.6827e+03, initc-loss 1.4083e+04                    bc_loss 1.7469e+07, Test-Loss 1.5425e+02\n",
      "Epoch 15630, Training-Loss 1.9964e+03, Data-loss 2.0522e+02                  , pde-loss 1.7158e+03, initc-loss 1.3869e+04                    bc_loss 1.7488e+07, Test-Loss 2.0522e+02\n",
      "Epoch 15640, Training-Loss 1.9481e+03, Data-loss 2.1967e+02                  , pde-loss 1.8366e+03, initc-loss 1.4323e+04                    bc_loss 1.7418e+07, Test-Loss 2.1967e+02\n",
      "Epoch 15650, Training-Loss 1.9183e+03, Data-loss 1.9710e+02                  , pde-loss 1.7368e+03, initc-loss 1.4008e+04                    bc_loss 1.7426e+07, Test-Loss 1.9710e+02\n",
      "Epoch 15660, Training-Loss 1.9685e+03, Data-loss 2.0891e+02                  , pde-loss 1.7980e+03, initc-loss 1.4062e+04                    bc_loss 1.7403e+07, Test-Loss 2.0891e+02\n",
      "Epoch 15670, Training-Loss 1.9693e+03, Data-loss 2.3423e+02                  , pde-loss 1.5724e+03, initc-loss 1.3710e+04                    bc_loss 1.7550e+07, Test-Loss 2.3423e+02\n",
      "Epoch 15680, Training-Loss 1.9078e+03, Data-loss 1.4036e+02                  , pde-loss 1.8899e+03, initc-loss 1.4064e+04                    bc_loss 1.7320e+07, Test-Loss 1.4036e+02\n",
      "Epoch 15690, Training-Loss 1.9601e+03, Data-loss 2.0644e+02                  , pde-loss 1.8591e+03, initc-loss 1.4357e+04                    bc_loss 1.7220e+07, Test-Loss 2.0644e+02\n",
      "Epoch 15700, Training-Loss 1.8850e+03, Data-loss 2.4718e+02                  , pde-loss 2.0010e+03, initc-loss 1.4513e+04                    bc_loss 1.7109e+07, Test-Loss 2.4718e+02\n",
      "Epoch 15710, Training-Loss 1.9295e+03, Data-loss 1.5813e+02                  , pde-loss 2.0173e+03, initc-loss 1.4687e+04                    bc_loss 1.7159e+07, Test-Loss 1.5813e+02\n",
      "Epoch 15720, Training-Loss 1.9886e+03, Data-loss 1.6603e+02                  , pde-loss 2.0624e+03, initc-loss 1.4534e+04                    bc_loss 1.7015e+07, Test-Loss 1.6603e+02\n",
      "Epoch 15730, Training-Loss 1.8446e+03, Data-loss 2.8097e+02                  , pde-loss 2.2401e+03, initc-loss 1.4584e+04                    bc_loss 1.7028e+07, Test-Loss 2.8097e+02\n",
      "Epoch 15740, Training-Loss 1.9391e+03, Data-loss 1.8022e+02                  , pde-loss 2.0592e+03, initc-loss 1.4194e+04                    bc_loss 1.7078e+07, Test-Loss 1.8022e+02\n",
      "Epoch 15750, Training-Loss 1.9881e+03, Data-loss 1.7227e+02                  , pde-loss 1.7009e+03, initc-loss 1.3810e+04                    bc_loss 1.7383e+07, Test-Loss 1.7227e+02\n",
      "Epoch 15760, Training-Loss 1.9221e+03, Data-loss 1.9315e+02                  , pde-loss 1.6268e+03, initc-loss 1.3651e+04                    bc_loss 1.7250e+07, Test-Loss 1.9315e+02\n",
      "Epoch 15770, Training-Loss 1.8555e+03, Data-loss 2.0892e+02                  , pde-loss 1.9175e+03, initc-loss 1.4084e+04                    bc_loss 1.7048e+07, Test-Loss 2.0892e+02\n",
      "Epoch 15780, Training-Loss 1.8700e+03, Data-loss 1.9437e+02                  , pde-loss 1.7356e+03, initc-loss 1.4035e+04                    bc_loss 1.7071e+07, Test-Loss 1.9437e+02\n",
      "Epoch 15790, Training-Loss 1.9002e+03, Data-loss 1.7816e+02                  , pde-loss 1.8433e+03, initc-loss 1.4072e+04                    bc_loss 1.7115e+07, Test-Loss 1.7816e+02\n",
      "Epoch 15800, Training-Loss 1.8691e+03, Data-loss 1.7940e+02                  , pde-loss 2.1519e+03, initc-loss 1.3908e+04                    bc_loss 1.6934e+07, Test-Loss 1.7940e+02\n",
      "Epoch 15810, Training-Loss 1.9825e+03, Data-loss 1.6624e+02                  , pde-loss 1.6868e+03, initc-loss 1.4446e+04                    bc_loss 1.7004e+07, Test-Loss 1.6624e+02\n",
      "Epoch 15820, Training-Loss 1.8914e+03, Data-loss 2.3652e+02                  , pde-loss 1.7797e+03, initc-loss 1.4086e+04                    bc_loss 1.7123e+07, Test-Loss 2.3652e+02\n",
      "Epoch 15830, Training-Loss 1.8515e+03, Data-loss 2.3227e+02                  , pde-loss 1.9355e+03, initc-loss 1.3855e+04                    bc_loss 1.7202e+07, Test-Loss 2.3227e+02\n",
      "Epoch 15840, Training-Loss 1.9115e+03, Data-loss 1.9811e+02                  , pde-loss 1.8479e+03, initc-loss 1.3709e+04                    bc_loss 1.7249e+07, Test-Loss 1.9811e+02\n",
      "Epoch 15850, Training-Loss 1.9611e+03, Data-loss 2.3992e+02                  , pde-loss 2.0854e+03, initc-loss 1.3706e+04                    bc_loss 1.7109e+07, Test-Loss 2.3992e+02\n",
      "Epoch 15860, Training-Loss 1.9300e+03, Data-loss 2.1529e+02                  , pde-loss 1.9212e+03, initc-loss 1.4374e+04                    bc_loss 1.7036e+07, Test-Loss 2.1529e+02\n",
      "Epoch 15870, Training-Loss 1.9234e+03, Data-loss 1.8031e+02                  , pde-loss 1.9567e+03, initc-loss 1.3791e+04                    bc_loss 1.7054e+07, Test-Loss 1.8031e+02\n",
      "Epoch 15880, Training-Loss 1.8666e+03, Data-loss 2.4853e+02                  , pde-loss 1.8731e+03, initc-loss 1.3824e+04                    bc_loss 1.6955e+07, Test-Loss 2.4853e+02\n",
      "Epoch 15890, Training-Loss 1.8666e+03, Data-loss 2.0649e+02                  , pde-loss 2.0945e+03, initc-loss 1.3600e+04                    bc_loss 1.7069e+07, Test-Loss 2.0649e+02\n",
      "Epoch 15900, Training-Loss 1.9111e+03, Data-loss 2.1951e+02                  , pde-loss 1.8975e+03, initc-loss 1.3946e+04                    bc_loss 1.6970e+07, Test-Loss 2.1951e+02\n",
      "Epoch 15910, Training-Loss 1.9183e+03, Data-loss 2.6972e+02                  , pde-loss 1.9837e+03, initc-loss 1.4017e+04                    bc_loss 1.6743e+07, Test-Loss 2.6972e+02\n",
      "Epoch 15920, Training-Loss 1.9021e+03, Data-loss 1.8282e+02                  , pde-loss 2.2297e+03, initc-loss 1.3812e+04                    bc_loss 1.6948e+07, Test-Loss 1.8282e+02\n",
      "Epoch 15930, Training-Loss 1.9703e+03, Data-loss 1.7443e+02                  , pde-loss 2.0437e+03, initc-loss 1.3872e+04                    bc_loss 1.6886e+07, Test-Loss 1.7443e+02\n",
      "Epoch 15940, Training-Loss 1.8855e+03, Data-loss 2.2033e+02                  , pde-loss 2.3013e+03, initc-loss 1.4014e+04                    bc_loss 1.6766e+07, Test-Loss 2.2033e+02\n",
      "Epoch 15950, Training-Loss 1.9165e+03, Data-loss 3.0253e+02                  , pde-loss 2.5471e+03, initc-loss 1.4329e+04                    bc_loss 1.6488e+07, Test-Loss 3.0253e+02\n",
      "Epoch 15960, Training-Loss 1.8745e+03, Data-loss 1.8475e+02                  , pde-loss 2.1123e+03, initc-loss 1.4624e+04                    bc_loss 1.6435e+07, Test-Loss 1.8475e+02\n",
      "Epoch 15970, Training-Loss 1.9131e+03, Data-loss 2.9977e+02                  , pde-loss 2.4659e+03, initc-loss 1.5076e+04                    bc_loss 1.6401e+07, Test-Loss 2.9977e+02\n",
      "Epoch 15980, Training-Loss 1.9200e+03, Data-loss 1.7227e+02                  , pde-loss 2.0500e+03, initc-loss 1.4603e+04                    bc_loss 1.6417e+07, Test-Loss 1.7227e+02\n",
      "Epoch 15990, Training-Loss 1.8663e+03, Data-loss 2.5603e+02                  , pde-loss 2.3047e+03, initc-loss 1.4103e+04                    bc_loss 1.6532e+07, Test-Loss 2.5603e+02\n",
      "Epoch 16000, Training-Loss 1.9351e+03, Data-loss 2.9548e+02                  , pde-loss 2.2003e+03, initc-loss 1.4621e+04                    bc_loss 1.6373e+07, Test-Loss 2.9548e+02\n",
      "Epoch 16010, Training-Loss 1.9237e+03, Data-loss 2.4311e+02                  , pde-loss 1.8052e+03, initc-loss 1.4327e+04                    bc_loss 1.6311e+07, Test-Loss 2.4311e+02\n",
      "Epoch 16020, Training-Loss 1.9150e+03, Data-loss 2.1882e+02                  , pde-loss 2.2711e+03, initc-loss 1.4418e+04                    bc_loss 1.6329e+07, Test-Loss 2.1882e+02\n",
      "Epoch 16030, Training-Loss 1.8634e+03, Data-loss 2.0702e+02                  , pde-loss 1.9187e+03, initc-loss 1.4256e+04                    bc_loss 1.6506e+07, Test-Loss 2.0702e+02\n",
      "Epoch 16040, Training-Loss 1.8841e+03, Data-loss 1.6479e+02                  , pde-loss 2.4935e+03, initc-loss 1.3913e+04                    bc_loss 1.6378e+07, Test-Loss 1.6479e+02\n",
      "Epoch 16050, Training-Loss 1.9292e+03, Data-loss 2.0823e+02                  , pde-loss 2.0831e+03, initc-loss 1.4702e+04                    bc_loss 1.6183e+07, Test-Loss 2.0823e+02\n",
      "Epoch 16060, Training-Loss 1.8463e+03, Data-loss 2.5345e+02                  , pde-loss 2.4802e+03, initc-loss 1.3968e+04                    bc_loss 1.6380e+07, Test-Loss 2.5345e+02\n",
      "Epoch 16070, Training-Loss 1.8874e+03, Data-loss 2.3780e+02                  , pde-loss 2.1915e+03, initc-loss 1.4250e+04                    bc_loss 1.6053e+07, Test-Loss 2.3780e+02\n",
      "Epoch 16080, Training-Loss 1.8205e+03, Data-loss 1.9952e+02                  , pde-loss 2.4463e+03, initc-loss 1.4089e+04                    bc_loss 1.6134e+07, Test-Loss 1.9952e+02\n",
      "Epoch 16090, Training-Loss 1.8519e+03, Data-loss 2.7275e+02                  , pde-loss 2.0608e+03, initc-loss 1.4099e+04                    bc_loss 1.6268e+07, Test-Loss 2.7275e+02\n",
      "Epoch 16100, Training-Loss 1.8245e+03, Data-loss 2.2092e+02                  , pde-loss 2.1253e+03, initc-loss 1.3647e+04                    bc_loss 1.6303e+07, Test-Loss 2.2092e+02\n",
      "Epoch 16110, Training-Loss 1.7932e+03, Data-loss 2.4082e+02                  , pde-loss 2.8398e+03, initc-loss 1.3903e+04                    bc_loss 1.6465e+07, Test-Loss 2.4082e+02\n",
      "Epoch 16120, Training-Loss 1.8667e+03, Data-loss 1.8601e+02                  , pde-loss 2.4197e+03, initc-loss 1.3783e+04                    bc_loss 1.6221e+07, Test-Loss 1.8601e+02\n",
      "Epoch 16130, Training-Loss 1.8701e+03, Data-loss 1.8349e+02                  , pde-loss 2.4097e+03, initc-loss 1.4304e+04                    bc_loss 1.6102e+07, Test-Loss 1.8349e+02\n",
      "Epoch 16140, Training-Loss 1.8231e+03, Data-loss 2.6534e+02                  , pde-loss 2.2025e+03, initc-loss 1.3948e+04                    bc_loss 1.6127e+07, Test-Loss 2.6534e+02\n",
      "Epoch 16150, Training-Loss 1.7868e+03, Data-loss 2.5212e+02                  , pde-loss 2.3743e+03, initc-loss 1.4295e+04                    bc_loss 1.5857e+07, Test-Loss 2.5212e+02\n",
      "Epoch 16160, Training-Loss 1.9066e+03, Data-loss 2.3017e+02                  , pde-loss 2.1968e+03, initc-loss 1.4191e+04                    bc_loss 1.5989e+07, Test-Loss 2.3017e+02\n",
      "Epoch 16170, Training-Loss 1.8270e+03, Data-loss 2.3584e+02                  , pde-loss 2.2126e+03, initc-loss 1.3833e+04                    bc_loss 1.6058e+07, Test-Loss 2.3584e+02\n",
      "Epoch 16180, Training-Loss 1.8452e+03, Data-loss 2.3063e+02                  , pde-loss 2.3081e+03, initc-loss 1.4213e+04                    bc_loss 1.5999e+07, Test-Loss 2.3063e+02\n",
      "Epoch 16190, Training-Loss 1.8080e+03, Data-loss 2.6335e+02                  , pde-loss 2.0151e+03, initc-loss 1.4366e+04                    bc_loss 1.5920e+07, Test-Loss 2.6335e+02\n",
      "Epoch 16200, Training-Loss 1.7558e+03, Data-loss 2.6720e+02                  , pde-loss 2.4461e+03, initc-loss 1.3736e+04                    bc_loss 1.5848e+07, Test-Loss 2.6720e+02\n",
      "Epoch 16210, Training-Loss 1.8669e+03, Data-loss 2.5622e+02                  , pde-loss 2.4117e+03, initc-loss 1.4046e+04                    bc_loss 1.5740e+07, Test-Loss 2.5622e+02\n",
      "Epoch 16220, Training-Loss 1.8274e+03, Data-loss 2.5914e+02                  , pde-loss 2.3781e+03, initc-loss 1.4259e+04                    bc_loss 1.5932e+07, Test-Loss 2.5914e+02\n",
      "Epoch 16230, Training-Loss 1.8441e+03, Data-loss 2.3912e+02                  , pde-loss 1.8432e+03, initc-loss 1.4187e+04                    bc_loss 1.5783e+07, Test-Loss 2.3912e+02\n",
      "Epoch 16240, Training-Loss 1.8578e+03, Data-loss 2.1546e+02                  , pde-loss 2.4695e+03, initc-loss 1.3810e+04                    bc_loss 1.5886e+07, Test-Loss 2.1546e+02\n",
      "Epoch 16250, Training-Loss 1.7367e+03, Data-loss 2.2047e+02                  , pde-loss 2.1101e+03, initc-loss 1.4143e+04                    bc_loss 1.5611e+07, Test-Loss 2.2047e+02\n",
      "Epoch 16260, Training-Loss 1.8102e+03, Data-loss 2.0054e+02                  , pde-loss 2.3774e+03, initc-loss 1.5032e+04                    bc_loss 1.5254e+07, Test-Loss 2.0054e+02\n",
      "Epoch 16270, Training-Loss 1.8443e+03, Data-loss 2.7787e+02                  , pde-loss 2.5345e+03, initc-loss 1.5344e+04                    bc_loss 1.4925e+07, Test-Loss 2.7787e+02\n",
      "Epoch 16280, Training-Loss 1.7513e+03, Data-loss 3.8065e+02                  , pde-loss 2.6558e+03, initc-loss 1.5459e+04                    bc_loss 1.5030e+07, Test-Loss 3.8065e+02\n",
      "Epoch 16290, Training-Loss 1.8513e+03, Data-loss 3.7791e+02                  , pde-loss 2.4986e+03, initc-loss 1.5001e+04                    bc_loss 1.5107e+07, Test-Loss 3.7791e+02\n",
      "Epoch 16300, Training-Loss 1.7931e+03, Data-loss 3.3211e+02                  , pde-loss 1.9879e+03, initc-loss 1.4749e+04                    bc_loss 1.5343e+07, Test-Loss 3.3211e+02\n",
      "Epoch 16310, Training-Loss 1.8508e+03, Data-loss 2.5899e+02                  , pde-loss 2.2344e+03, initc-loss 1.3303e+04                    bc_loss 1.5539e+07, Test-Loss 2.5899e+02\n",
      "Epoch 16320, Training-Loss 1.7736e+03, Data-loss 2.3557e+02                  , pde-loss 1.9803e+03, initc-loss 1.4634e+04                    bc_loss 1.5177e+07, Test-Loss 2.3557e+02\n",
      "Epoch 16330, Training-Loss 1.8022e+03, Data-loss 2.1683e+02                  , pde-loss 2.3449e+03, initc-loss 1.3569e+04                    bc_loss 1.5343e+07, Test-Loss 2.1683e+02\n",
      "Epoch 16340, Training-Loss 1.8191e+03, Data-loss 2.9175e+02                  , pde-loss 3.0422e+03, initc-loss 1.4416e+04                    bc_loss 1.5252e+07, Test-Loss 2.9175e+02\n",
      "Epoch 16350, Training-Loss 1.8326e+03, Data-loss 3.6639e+02                  , pde-loss 2.1655e+03, initc-loss 1.4788e+04                    bc_loss 1.4904e+07, Test-Loss 3.6639e+02\n",
      "Epoch 16360, Training-Loss 1.8263e+03, Data-loss 3.0451e+02                  , pde-loss 2.3425e+03, initc-loss 1.3959e+04                    bc_loss 1.5078e+07, Test-Loss 3.0451e+02\n",
      "Epoch 16370, Training-Loss 1.7418e+03, Data-loss 3.0015e+02                  , pde-loss 2.5983e+03, initc-loss 1.4136e+04                    bc_loss 1.5035e+07, Test-Loss 3.0015e+02\n",
      "Epoch 16380, Training-Loss 1.7070e+03, Data-loss 1.8362e+02                  , pde-loss 2.4106e+03, initc-loss 1.3778e+04                    bc_loss 1.5316e+07, Test-Loss 1.8362e+02\n",
      "Epoch 16390, Training-Loss 1.7893e+03, Data-loss 2.5524e+02                  , pde-loss 2.6195e+03, initc-loss 1.4186e+04                    bc_loss 1.5116e+07, Test-Loss 2.5524e+02\n",
      "Epoch 16400, Training-Loss 1.7270e+03, Data-loss 3.0834e+02                  , pde-loss 2.4420e+03, initc-loss 1.4248e+04                    bc_loss 1.5168e+07, Test-Loss 3.0834e+02\n",
      "Epoch 16410, Training-Loss 1.8002e+03, Data-loss 2.1588e+02                  , pde-loss 2.6730e+03, initc-loss 1.4077e+04                    bc_loss 1.5169e+07, Test-Loss 2.1588e+02\n",
      "Epoch 16420, Training-Loss 1.7084e+03, Data-loss 2.7815e+02                  , pde-loss 2.6495e+03, initc-loss 1.3616e+04                    bc_loss 1.5060e+07, Test-Loss 2.7815e+02\n",
      "Epoch 16430, Training-Loss 1.7537e+03, Data-loss 1.8221e+02                  , pde-loss 2.9179e+03, initc-loss 1.3112e+04                    bc_loss 1.5010e+07, Test-Loss 1.8221e+02\n",
      "Epoch 16440, Training-Loss 1.7572e+03, Data-loss 2.5326e+02                  , pde-loss 2.4410e+03, initc-loss 1.3805e+04                    bc_loss 1.4764e+07, Test-Loss 2.5326e+02\n",
      "Epoch 16450, Training-Loss 1.8282e+03, Data-loss 3.5922e+02                  , pde-loss 2.1654e+03, initc-loss 1.5576e+04                    bc_loss 1.4191e+07, Test-Loss 3.5922e+02\n",
      "Epoch 16460, Training-Loss 1.6659e+03, Data-loss 2.7821e+02                  , pde-loss 2.0545e+03, initc-loss 1.4431e+04                    bc_loss 1.4362e+07, Test-Loss 2.7821e+02\n",
      "Epoch 16470, Training-Loss 1.6649e+03, Data-loss 2.5657e+02                  , pde-loss 2.4867e+03, initc-loss 1.4634e+04                    bc_loss 1.4227e+07, Test-Loss 2.5657e+02\n",
      "Epoch 16480, Training-Loss 1.7273e+03, Data-loss 2.5734e+02                  , pde-loss 2.3413e+03, initc-loss 1.4711e+04                    bc_loss 1.4227e+07, Test-Loss 2.5734e+02\n",
      "Epoch 16490, Training-Loss 1.7631e+03, Data-loss 2.6266e+02                  , pde-loss 2.5097e+03, initc-loss 1.5088e+04                    bc_loss 1.4119e+07, Test-Loss 2.6266e+02\n",
      "Epoch 16500, Training-Loss 1.7238e+03, Data-loss 3.0727e+02                  , pde-loss 2.2251e+03, initc-loss 1.4544e+04                    bc_loss 1.4138e+07, Test-Loss 3.0727e+02\n",
      "Epoch 16510, Training-Loss 1.6112e+03, Data-loss 3.0040e+02                  , pde-loss 2.1700e+03, initc-loss 1.4284e+04                    bc_loss 1.4149e+07, Test-Loss 3.0040e+02\n",
      "Epoch 16520, Training-Loss 1.6784e+03, Data-loss 2.1926e+02                  , pde-loss 1.9889e+03, initc-loss 1.3958e+04                    bc_loss 1.4056e+07, Test-Loss 2.1926e+02\n",
      "Epoch 16530, Training-Loss 1.7239e+03, Data-loss 3.0213e+02                  , pde-loss 2.7559e+03, initc-loss 1.4788e+04                    bc_loss 1.3728e+07, Test-Loss 3.0213e+02\n",
      "Epoch 16540, Training-Loss 1.6936e+03, Data-loss 3.0092e+02                  , pde-loss 2.6357e+03, initc-loss 1.4781e+04                    bc_loss 1.3751e+07, Test-Loss 3.0092e+02\n",
      "Epoch 16550, Training-Loss 1.7140e+03, Data-loss 2.5448e+02                  , pde-loss 1.9150e+03, initc-loss 1.5028e+04                    bc_loss 1.3803e+07, Test-Loss 2.5448e+02\n",
      "Epoch 16560, Training-Loss 1.5866e+03, Data-loss 2.4087e+02                  , pde-loss 2.4185e+03, initc-loss 1.4339e+04                    bc_loss 1.3898e+07, Test-Loss 2.4087e+02\n",
      "Epoch 16570, Training-Loss 1.7399e+03, Data-loss 2.2608e+02                  , pde-loss 2.9682e+03, initc-loss 1.4567e+04                    bc_loss 1.3688e+07, Test-Loss 2.2608e+02\n",
      "Epoch 16580, Training-Loss 1.6460e+03, Data-loss 3.5372e+02                  , pde-loss 1.8335e+03, initc-loss 1.4264e+04                    bc_loss 1.3962e+07, Test-Loss 3.5372e+02\n",
      "Epoch 16590, Training-Loss 1.7458e+03, Data-loss 2.9548e+02                  , pde-loss 2.9743e+03, initc-loss 1.5051e+04                    bc_loss 1.3285e+07, Test-Loss 2.9548e+02\n",
      "Epoch 16600, Training-Loss 1.5928e+03, Data-loss 4.2804e+02                  , pde-loss 3.2944e+03, initc-loss 1.4353e+04                    bc_loss 1.3023e+07, Test-Loss 4.2804e+02\n",
      "Epoch 16610, Training-Loss 1.7133e+03, Data-loss 4.0127e+02                  , pde-loss 2.3205e+03, initc-loss 1.4180e+04                    bc_loss 1.3084e+07, Test-Loss 4.0127e+02\n",
      "Epoch 16620, Training-Loss 1.7368e+03, Data-loss 2.4777e+02                  , pde-loss 2.3052e+03, initc-loss 1.4239e+04                    bc_loss 1.3188e+07, Test-Loss 2.4777e+02\n",
      "Epoch 16630, Training-Loss 1.5951e+03, Data-loss 2.8368e+02                  , pde-loss 2.2713e+03, initc-loss 1.4053e+04                    bc_loss 1.3223e+07, Test-Loss 2.8368e+02\n",
      "Epoch 16640, Training-Loss 1.6637e+03, Data-loss 2.4798e+02                  , pde-loss 2.3723e+03, initc-loss 1.3481e+04                    bc_loss 1.3758e+07, Test-Loss 2.4798e+02\n",
      "Epoch 16650, Training-Loss 1.7581e+03, Data-loss 2.6330e+02                  , pde-loss 2.5315e+03, initc-loss 1.3280e+04                    bc_loss 1.3647e+07, Test-Loss 2.6330e+02\n",
      "Epoch 16660, Training-Loss 1.7122e+03, Data-loss 3.1988e+02                  , pde-loss 2.8518e+03, initc-loss 1.3268e+04                    bc_loss 1.3594e+07, Test-Loss 3.1988e+02\n",
      "Epoch 16670, Training-Loss 1.6307e+03, Data-loss 4.3548e+02                  , pde-loss 2.4393e+03, initc-loss 1.4843e+04                    bc_loss 1.2255e+07, Test-Loss 4.3548e+02\n",
      "Epoch 16680, Training-Loss 1.6019e+03, Data-loss 3.8579e+02                  , pde-loss 2.8719e+03, initc-loss 1.4277e+04                    bc_loss 1.2516e+07, Test-Loss 3.8579e+02\n",
      "Epoch 16690, Training-Loss 1.5671e+03, Data-loss 3.1718e+02                  , pde-loss 3.0363e+03, initc-loss 1.4459e+04                    bc_loss 1.2381e+07, Test-Loss 3.1718e+02\n",
      "Epoch 16700, Training-Loss 1.8203e+03, Data-loss 2.8224e+02                  , pde-loss 2.2770e+03, initc-loss 1.3462e+04                    bc_loss 1.2774e+07, Test-Loss 2.8224e+02\n",
      "Epoch 16710, Training-Loss 1.5439e+03, Data-loss 4.4604e+02                  , pde-loss 2.5128e+03, initc-loss 1.4385e+04                    bc_loss 1.2401e+07, Test-Loss 4.4604e+02\n",
      "Epoch 16720, Training-Loss 1.6069e+03, Data-loss 3.4678e+02                  , pde-loss 3.3306e+03, initc-loss 1.5418e+04                    bc_loss 1.1976e+07, Test-Loss 3.4678e+02\n",
      "Epoch 16730, Training-Loss 1.5888e+03, Data-loss 3.6487e+02                  , pde-loss 2.6420e+03, initc-loss 1.3933e+04                    bc_loss 1.2258e+07, Test-Loss 3.6487e+02\n",
      "Epoch 16740, Training-Loss 1.5585e+03, Data-loss 4.7647e+02                  , pde-loss 3.3643e+03, initc-loss 1.4383e+04                    bc_loss 1.2045e+07, Test-Loss 4.7647e+02\n",
      "Epoch 16750, Training-Loss 1.5387e+03, Data-loss 3.7876e+02                  , pde-loss 2.2349e+03, initc-loss 1.4411e+04                    bc_loss 1.2749e+07, Test-Loss 3.7876e+02\n",
      "Epoch 16760, Training-Loss 1.5657e+03, Data-loss 3.2000e+02                  , pde-loss 4.3980e+03, initc-loss 1.4009e+04                    bc_loss 1.2031e+07, Test-Loss 3.2000e+02\n",
      "Epoch 16770, Training-Loss 1.5725e+03, Data-loss 3.1654e+02                  , pde-loss 2.0423e+03, initc-loss 1.2506e+04                    bc_loss 1.2643e+07, Test-Loss 3.1654e+02\n",
      "Epoch 16780, Training-Loss 1.6287e+03, Data-loss 2.3972e+02                  , pde-loss 2.3387e+03, initc-loss 1.3550e+04                    bc_loss 1.2748e+07, Test-Loss 2.3972e+02\n",
      "Epoch 16790, Training-Loss 1.5981e+03, Data-loss 2.5794e+02                  , pde-loss 2.6096e+03, initc-loss 1.2911e+04                    bc_loss 1.3061e+07, Test-Loss 2.5794e+02\n",
      "Epoch 16800, Training-Loss 1.4791e+03, Data-loss 1.5661e+02                  , pde-loss 2.9108e+03, initc-loss 1.4534e+04                    bc_loss 1.2050e+07, Test-Loss 1.5661e+02\n",
      "Epoch 16810, Training-Loss 1.4854e+03, Data-loss 4.2943e+02                  , pde-loss 2.2088e+03, initc-loss 1.5215e+04                    bc_loss 1.1119e+07, Test-Loss 4.2943e+02\n",
      "Epoch 16820, Training-Loss 1.4655e+03, Data-loss 4.0111e+02                  , pde-loss 2.3316e+03, initc-loss 1.3473e+04                    bc_loss 1.1610e+07, Test-Loss 4.0111e+02\n",
      "Epoch 16830, Training-Loss 1.5515e+03, Data-loss 2.6621e+02                  , pde-loss 2.0126e+03, initc-loss 1.2980e+04                    bc_loss 1.2534e+07, Test-Loss 2.6621e+02\n",
      "Epoch 16840, Training-Loss 1.5165e+03, Data-loss 3.0623e+02                  , pde-loss 2.0086e+03, initc-loss 1.3237e+04                    bc_loss 1.2304e+07, Test-Loss 3.0623e+02\n",
      "Epoch 16850, Training-Loss 1.4578e+03, Data-loss 2.2696e+02                  , pde-loss 2.2847e+03, initc-loss 1.4378e+04                    bc_loss 1.1640e+07, Test-Loss 2.2696e+02\n",
      "Epoch 16860, Training-Loss 1.4668e+03, Data-loss 2.2422e+02                  , pde-loss 1.9770e+03, initc-loss 1.4828e+04                    bc_loss 1.1639e+07, Test-Loss 2.2422e+02\n",
      "Epoch 16870, Training-Loss 1.5928e+03, Data-loss 2.5709e+02                  , pde-loss 3.2626e+03, initc-loss 1.4038e+04                    bc_loss 1.1240e+07, Test-Loss 2.5709e+02\n",
      "Epoch 16880, Training-Loss 1.4546e+03, Data-loss 2.9674e+02                  , pde-loss 2.6504e+03, initc-loss 1.3951e+04                    bc_loss 1.0992e+07, Test-Loss 2.9674e+02\n",
      "Epoch 16890, Training-Loss 1.3921e+03, Data-loss 4.7536e+02                  , pde-loss 3.3074e+03, initc-loss 1.4732e+04                    bc_loss 1.0503e+07, Test-Loss 4.7536e+02\n",
      "Epoch 16900, Training-Loss 1.5613e+03, Data-loss 3.8111e+02                  , pde-loss 2.2008e+03, initc-loss 1.3927e+04                    bc_loss 1.0972e+07, Test-Loss 3.8111e+02\n",
      "Epoch 16910, Training-Loss 1.2639e+03, Data-loss 3.9630e+02                  , pde-loss 2.7780e+03, initc-loss 1.5133e+04                    bc_loss 1.0091e+07, Test-Loss 3.9630e+02\n",
      "Epoch 16920, Training-Loss 1.3611e+03, Data-loss 7.7390e+02                  , pde-loss 3.2202e+03, initc-loss 1.3861e+04                    bc_loss 9.8920e+06, Test-Loss 7.7390e+02\n",
      "Epoch 16930, Training-Loss 1.4203e+03, Data-loss 4.4352e+02                  , pde-loss 2.3659e+03, initc-loss 1.4606e+04                    bc_loss 1.0650e+07, Test-Loss 4.4352e+02\n",
      "Epoch 16940, Training-Loss 1.3885e+03, Data-loss 4.2210e+02                  , pde-loss 1.9188e+03, initc-loss 1.3064e+04                    bc_loss 1.0584e+07, Test-Loss 4.2210e+02\n",
      "Epoch 16950, Training-Loss 1.4856e+03, Data-loss 2.0399e+02                  , pde-loss 2.4893e+03, initc-loss 1.4205e+04                    bc_loss 1.0389e+07, Test-Loss 2.0399e+02\n",
      "Epoch 16960, Training-Loss 1.3598e+03, Data-loss 3.9778e+02                  , pde-loss 2.9370e+03, initc-loss 1.4122e+04                    bc_loss 1.0208e+07, Test-Loss 3.9778e+02\n",
      "Epoch 16970, Training-Loss 1.5022e+03, Data-loss 4.4459e+02                  , pde-loss 3.1370e+03, initc-loss 1.5868e+04                    bc_loss 9.1574e+06, Test-Loss 4.4459e+02\n",
      "Epoch 16980, Training-Loss 1.4924e+03, Data-loss 4.2153e+02                  , pde-loss 2.9259e+03, initc-loss 1.4256e+04                    bc_loss 1.0085e+07, Test-Loss 4.2153e+02\n",
      "Epoch 16990, Training-Loss 1.4037e+03, Data-loss 3.9302e+02                  , pde-loss 2.1280e+03, initc-loss 1.3324e+04                    bc_loss 1.0449e+07, Test-Loss 3.9302e+02\n",
      "Epoch 17000, Training-Loss 1.3829e+03, Data-loss 4.1626e+02                  , pde-loss 3.5509e+03, initc-loss 1.4394e+04                    bc_loss 9.8314e+06, Test-Loss 4.1626e+02\n",
      "Epoch 17010, Training-Loss 1.3351e+03, Data-loss 3.2971e+02                  , pde-loss 2.3342e+03, initc-loss 1.2981e+04                    bc_loss 1.0006e+07, Test-Loss 3.2971e+02\n",
      "Epoch 17020, Training-Loss 1.3279e+03, Data-loss 2.9918e+02                  , pde-loss 3.1572e+03, initc-loss 1.3566e+04                    bc_loss 9.7419e+06, Test-Loss 2.9918e+02\n",
      "Epoch 17030, Training-Loss 1.2294e+03, Data-loss 3.7567e+02                  , pde-loss 2.3545e+03, initc-loss 1.2599e+04                    bc_loss 9.8512e+06, Test-Loss 3.7567e+02\n",
      "Epoch 17040, Training-Loss 1.1158e+03, Data-loss 5.3668e+02                  , pde-loss 2.7423e+03, initc-loss 1.5659e+04                    bc_loss 8.2825e+06, Test-Loss 5.3668e+02\n",
      "Epoch 17050, Training-Loss 1.3526e+03, Data-loss 4.4939e+02                  , pde-loss 3.8773e+03, initc-loss 1.3699e+04                    bc_loss 8.7482e+06, Test-Loss 4.4939e+02\n",
      "Epoch 17060, Training-Loss 1.4061e+03, Data-loss 2.8951e+02                  , pde-loss 2.3185e+03, initc-loss 1.3651e+04                    bc_loss 8.7060e+06, Test-Loss 2.8951e+02\n",
      "Epoch 17070, Training-Loss 1.2355e+03, Data-loss 3.4222e+02                  , pde-loss 3.0319e+03, initc-loss 1.5455e+04                    bc_loss 8.7670e+06, Test-Loss 3.4222e+02\n",
      "Epoch 17080, Training-Loss 1.1923e+03, Data-loss 4.1253e+02                  , pde-loss 3.0426e+03, initc-loss 1.4130e+04                    bc_loss 8.6732e+06, Test-Loss 4.1253e+02\n",
      "Epoch 17090, Training-Loss 1.2316e+03, Data-loss 7.0696e+02                  , pde-loss 2.5208e+03, initc-loss 1.5668e+04                    bc_loss 7.1956e+06, Test-Loss 7.0696e+02\n",
      "Epoch 17100, Training-Loss 1.0739e+03, Data-loss 5.3676e+02                  , pde-loss 3.2854e+03, initc-loss 1.4919e+04                    bc_loss 7.6140e+06, Test-Loss 5.3676e+02\n",
      "Epoch 17110, Training-Loss 1.2369e+03, Data-loss 3.7104e+02                  , pde-loss 2.6283e+03, initc-loss 1.4109e+04                    bc_loss 8.3557e+06, Test-Loss 3.7104e+02\n",
      "Epoch 17120, Training-Loss 1.1154e+03, Data-loss 4.3983e+02                  , pde-loss 1.9856e+03, initc-loss 1.3459e+04                    bc_loss 8.9600e+06, Test-Loss 4.3983e+02\n",
      "Epoch 17130, Training-Loss 1.1482e+03, Data-loss 1.8805e+02                  , pde-loss 2.5176e+03, initc-loss 1.4103e+04                    bc_loss 8.1173e+06, Test-Loss 1.8805e+02\n",
      "Epoch 17140, Training-Loss 1.0909e+03, Data-loss 3.6465e+02                  , pde-loss 1.8279e+03, initc-loss 1.4630e+04                    bc_loss 6.7624e+06, Test-Loss 3.6465e+02\n",
      "Epoch 17150, Training-Loss 1.1203e+03, Data-loss 4.5129e+02                  , pde-loss 2.4157e+03, initc-loss 1.5461e+04                    bc_loss 7.3255e+06, Test-Loss 4.5129e+02\n",
      "Epoch 17160, Training-Loss 1.2350e+03, Data-loss 3.0538e+02                  , pde-loss 2.7052e+03, initc-loss 1.3421e+04                    bc_loss 8.3196e+06, Test-Loss 3.0538e+02\n",
      "Epoch 17170, Training-Loss 9.8337e+02, Data-loss 4.9550e+02                  , pde-loss 2.4726e+03, initc-loss 1.7059e+04                    bc_loss 6.5939e+06, Test-Loss 4.9550e+02\n",
      "Epoch 17180, Training-Loss 9.7585e+02, Data-loss 6.7733e+02                  , pde-loss 2.1020e+03, initc-loss 1.4200e+04                    bc_loss 6.3194e+06, Test-Loss 6.7733e+02\n",
      "Epoch 17190, Training-Loss 1.0872e+03, Data-loss 4.5098e+02                  , pde-loss 2.3589e+03, initc-loss 1.4334e+04                    bc_loss 7.2997e+06, Test-Loss 4.5098e+02\n",
      "Epoch 17200, Training-Loss 1.0737e+03, Data-loss 3.0710e+02                  , pde-loss 2.2990e+03, initc-loss 1.3493e+04                    bc_loss 7.4190e+06, Test-Loss 3.0710e+02\n",
      "Epoch 17210, Training-Loss 9.8887e+02, Data-loss 3.6248e+02                  , pde-loss 2.4868e+03, initc-loss 1.4613e+04                    bc_loss 5.5495e+06, Test-Loss 3.6248e+02\n",
      "Epoch 17220, Training-Loss 1.2072e+03, Data-loss 4.4152e+02                  , pde-loss 3.8022e+03, initc-loss 1.4788e+04                    bc_loss 5.8525e+06, Test-Loss 4.4152e+02\n",
      "Epoch 17230, Training-Loss 9.2299e+02, Data-loss 4.0002e+02                  , pde-loss 2.3185e+03, initc-loss 1.4951e+04                    bc_loss 5.8796e+06, Test-Loss 4.0002e+02\n",
      "Epoch 17240, Training-Loss 1.1030e+03, Data-loss 4.9213e+02                  , pde-loss 2.5762e+03, initc-loss 1.4687e+04                    bc_loss 5.8075e+06, Test-Loss 4.9213e+02\n",
      "Epoch 17250, Training-Loss 1.0104e+03, Data-loss 5.5984e+02                  , pde-loss 2.0510e+03, initc-loss 1.3554e+04                    bc_loss 5.9464e+06, Test-Loss 5.5984e+02\n",
      "Epoch 17260, Training-Loss 9.5100e+02, Data-loss 3.9617e+02                  , pde-loss 2.1279e+03, initc-loss 1.4583e+04                    bc_loss 4.7542e+06, Test-Loss 3.9617e+02\n",
      "Epoch 17270, Training-Loss 1.0423e+03, Data-loss 1.9407e+02                  , pde-loss 3.1929e+03, initc-loss 1.2769e+04                    bc_loss 5.3311e+06, Test-Loss 1.9407e+02\n",
      "Epoch 17280, Training-Loss 1.1019e+03, Data-loss 5.4895e+02                  , pde-loss 2.8433e+03, initc-loss 1.4171e+04                    bc_loss 4.6029e+06, Test-Loss 5.4895e+02\n",
      "Epoch 17290, Training-Loss 1.2541e+03, Data-loss 7.5820e+02                  , pde-loss 2.9138e+03, initc-loss 1.5046e+04                    bc_loss 4.8586e+06, Test-Loss 7.5820e+02\n",
      "Epoch 17300, Training-Loss 7.0927e+02, Data-loss 4.0175e+02                  , pde-loss 2.3684e+03, initc-loss 1.5215e+04                    bc_loss 4.8452e+06, Test-Loss 4.0175e+02\n",
      "Epoch 17310, Training-Loss 1.0607e+03, Data-loss 3.7066e+02                  , pde-loss 2.1292e+03, initc-loss 1.3518e+04                    bc_loss 5.5165e+06, Test-Loss 3.7066e+02\n",
      "Epoch 17320, Training-Loss 7.6831e+02, Data-loss 1.5939e+02                  , pde-loss 2.6273e+03, initc-loss 1.3556e+04                    bc_loss 5.2410e+06, Test-Loss 1.5939e+02\n",
      "Epoch 17330, Training-Loss 6.7995e+02, Data-loss 5.1808e+02                  , pde-loss 2.2309e+03, initc-loss 1.3744e+04                    bc_loss 4.3097e+06, Test-Loss 5.1808e+02\n",
      "Epoch 17340, Training-Loss 8.8395e+02, Data-loss 4.3527e+02                  , pde-loss 2.5857e+03, initc-loss 1.5562e+04                    bc_loss 3.4872e+06, Test-Loss 4.3527e+02\n",
      "Epoch 17350, Training-Loss 8.8520e+02, Data-loss 3.8034e+02                  , pde-loss 3.7355e+03, initc-loss 1.4234e+04                    bc_loss 3.6217e+06, Test-Loss 3.8034e+02\n",
      "Epoch 17360, Training-Loss 8.7596e+02, Data-loss 5.3013e+02                  , pde-loss 2.4561e+03, initc-loss 1.4587e+04                    bc_loss 3.6794e+06, Test-Loss 5.3013e+02\n",
      "Epoch 17370, Training-Loss 8.7092e+02, Data-loss 3.3026e+02                  , pde-loss 2.2151e+03, initc-loss 1.2301e+04                    bc_loss 4.9440e+06, Test-Loss 3.3026e+02\n",
      "Epoch 17380, Training-Loss 4.7197e+02, Data-loss 1.0378e+03                  , pde-loss 2.0319e+03, initc-loss 1.5772e+04                    bc_loss 2.7170e+06, Test-Loss 1.0378e+03\n",
      "Epoch 17390, Training-Loss 7.3122e+02, Data-loss 4.0391e+02                  , pde-loss 2.8880e+03, initc-loss 1.4785e+04                    bc_loss 3.1591e+06, Test-Loss 4.0391e+02\n",
      "Epoch 17400, Training-Loss 8.3667e+02, Data-loss 2.9903e+02                  , pde-loss 2.5499e+03, initc-loss 1.3480e+04                    bc_loss 3.8295e+06, Test-Loss 2.9903e+02\n",
      "Epoch 17410, Training-Loss 6.7740e+02, Data-loss 9.0514e+02                  , pde-loss 2.4041e+03, initc-loss 1.5280e+04                    bc_loss 2.8816e+06, Test-Loss 9.0514e+02\n",
      "Epoch 17420, Training-Loss 8.5914e+02, Data-loss 3.5716e+02                  , pde-loss 3.2233e+03, initc-loss 1.4542e+04                    bc_loss 2.8194e+06, Test-Loss 3.5716e+02\n",
      "Epoch 17430, Training-Loss 7.2291e+02, Data-loss 4.4759e+02                  , pde-loss 3.1636e+03, initc-loss 1.3283e+04                    bc_loss 3.4008e+06, Test-Loss 4.4759e+02\n",
      "Epoch 17440, Training-Loss 5.3467e+02, Data-loss 6.4313e+02                  , pde-loss 2.4592e+03, initc-loss 1.4301e+04                    bc_loss 2.5769e+06, Test-Loss 6.4313e+02\n",
      "Epoch 17450, Training-Loss 7.1195e+02, Data-loss 2.6227e+02                  , pde-loss 3.1916e+03, initc-loss 1.2921e+04                    bc_loss 2.8301e+06, Test-Loss 2.6227e+02\n",
      "Epoch 17460, Training-Loss 4.3711e+02, Data-loss 4.1341e+02                  , pde-loss 2.6198e+03, initc-loss 1.2782e+04                    bc_loss 3.1530e+06, Test-Loss 4.1341e+02\n",
      "Epoch 17470, Training-Loss 3.9789e+02, Data-loss 2.8867e+02                  , pde-loss 2.9009e+03, initc-loss 1.3934e+04                    bc_loss 2.1596e+06, Test-Loss 2.8867e+02\n",
      "Epoch 17480, Training-Loss 7.0987e+02, Data-loss 1.3313e+02                  , pde-loss 3.4011e+03, initc-loss 1.3665e+04                    bc_loss 2.4314e+06, Test-Loss 1.3313e+02\n",
      "Epoch 17490, Training-Loss 7.8248e+02, Data-loss 3.7554e+02                  , pde-loss 3.6067e+03, initc-loss 1.4549e+04                    bc_loss 2.1864e+06, Test-Loss 3.7554e+02\n",
      "Epoch 17500, Training-Loss 6.3455e+02, Data-loss 5.5881e+02                  , pde-loss 3.1815e+03, initc-loss 1.5111e+04                    bc_loss 1.6238e+06, Test-Loss 5.5881e+02\n",
      "Epoch 17510, Training-Loss 5.4501e+02, Data-loss 6.1511e+02                  , pde-loss 2.3496e+03, initc-loss 1.3750e+04                    bc_loss 2.1684e+06, Test-Loss 6.1511e+02\n",
      "Epoch 17520, Training-Loss 4.0360e+02, Data-loss 5.4048e+02                  , pde-loss 2.7604e+03, initc-loss 1.2788e+04                    bc_loss 2.2982e+06, Test-Loss 5.4048e+02\n",
      "Epoch 17530, Training-Loss 7.3332e+02, Data-loss 3.6924e+02                  , pde-loss 3.1371e+03, initc-loss 1.5263e+04                    bc_loss 1.2216e+06, Test-Loss 3.6924e+02\n",
      "Epoch 17540, Training-Loss 6.9878e+02, Data-loss 2.3103e+02                  , pde-loss 3.2056e+03, initc-loss 1.5147e+04                    bc_loss 1.5877e+06, Test-Loss 2.3103e+02\n",
      "Epoch 17550, Training-Loss 6.3292e+02, Data-loss 4.9473e+02                  , pde-loss 3.4683e+03, initc-loss 1.3802e+04                    bc_loss 1.9048e+06, Test-Loss 4.9473e+02\n",
      "Epoch 17560, Training-Loss 6.4989e+02, Data-loss 3.2087e+02                  , pde-loss 3.0260e+03, initc-loss 1.4806e+04                    bc_loss 1.7562e+06, Test-Loss 3.2087e+02\n",
      "Epoch 17570, Training-Loss 3.4224e+02, Data-loss 4.0174e+02                  , pde-loss 2.0536e+03, initc-loss 1.4233e+04                    bc_loss 1.5181e+06, Test-Loss 4.0174e+02\n",
      "Epoch 17580, Training-Loss 4.0538e+02, Data-loss 4.2666e+02                  , pde-loss 2.7766e+03, initc-loss 1.2307e+04                    bc_loss 1.9933e+06, Test-Loss 4.2666e+02\n",
      "Epoch 17590, Training-Loss 6.1716e+02, Data-loss 2.6641e+02                  , pde-loss 4.3465e+03, initc-loss 1.3555e+04                    bc_loss 1.8096e+06, Test-Loss 2.6641e+02\n",
      "Epoch 17600, Training-Loss 5.3609e+02, Data-loss 2.0674e+02                  , pde-loss 3.4280e+03, initc-loss 1.3585e+04                    bc_loss 2.5203e+06, Test-Loss 2.0674e+02\n",
      "Epoch 17610, Training-Loss 6.4253e+02, Data-loss 3.9878e+02                  , pde-loss 2.3221e+03, initc-loss 1.5343e+04                    bc_loss 1.6514e+06, Test-Loss 3.9878e+02\n",
      "Epoch 17620, Training-Loss 4.5781e+02, Data-loss 5.2271e+02                  , pde-loss 2.2421e+03, initc-loss 1.3681e+04                    bc_loss 1.8292e+06, Test-Loss 5.2271e+02\n",
      "Epoch 17630, Training-Loss 6.4787e+02, Data-loss 8.8879e+01                  , pde-loss 2.0054e+03, initc-loss 1.5323e+04                    bc_loss 7.6573e+05, Test-Loss 8.8879e+01\n",
      "Epoch 17640, Training-Loss 6.6985e+02, Data-loss 3.5389e+02                  , pde-loss 2.4032e+03, initc-loss 1.3459e+04                    bc_loss 1.3691e+06, Test-Loss 3.5389e+02\n",
      "Epoch 17650, Training-Loss 6.0438e+02, Data-loss 3.3441e+02                  , pde-loss 3.0032e+03, initc-loss 1.3706e+04                    bc_loss 1.5228e+06, Test-Loss 3.3441e+02\n",
      "Epoch 17660, Training-Loss 4.8418e+02, Data-loss 2.0362e+02                  , pde-loss 3.3471e+03, initc-loss 1.3546e+04                    bc_loss 1.6751e+06, Test-Loss 2.0362e+02\n",
      "Epoch 17670, Training-Loss 5.2171e+02, Data-loss 2.7145e+02                  , pde-loss 2.8771e+03, initc-loss 1.4069e+04                    bc_loss 9.8352e+05, Test-Loss 2.7145e+02\n",
      "Epoch 17680, Training-Loss 1.7478e+02, Data-loss 3.1852e+02                  , pde-loss 2.5679e+03, initc-loss 1.4204e+04                    bc_loss 8.1441e+05, Test-Loss 3.1852e+02\n",
      "Epoch 17690, Training-Loss 3.7870e+02, Data-loss 7.5351e+02                  , pde-loss 2.5853e+03, initc-loss 1.4230e+04                    bc_loss 1.2485e+06, Test-Loss 7.5351e+02\n",
      "Epoch 17700, Training-Loss 5.7009e+02, Data-loss 2.0147e+02                  , pde-loss 2.9512e+03, initc-loss 1.3356e+04                    bc_loss 1.2279e+06, Test-Loss 2.0147e+02\n",
      "Epoch 17710, Training-Loss 2.9992e+02, Data-loss 3.5977e+02                  , pde-loss 2.4118e+03, initc-loss 1.4947e+04                    bc_loss 7.7090e+05, Test-Loss 3.5977e+02\n",
      "Epoch 17720, Training-Loss 4.2904e+02, Data-loss 4.4219e+02                  , pde-loss 2.5238e+03, initc-loss 1.3524e+04                    bc_loss 1.1023e+06, Test-Loss 4.4219e+02\n",
      "Epoch 17730, Training-Loss 5.0373e+02, Data-loss 2.0542e+02                  , pde-loss 2.7565e+03, initc-loss 1.4505e+04                    bc_loss 8.0276e+05, Test-Loss 2.0542e+02\n",
      "Epoch 17740, Training-Loss 3.7851e+02, Data-loss 1.7502e+02                  , pde-loss 2.4515e+03, initc-loss 1.3462e+04                    bc_loss 7.7002e+05, Test-Loss 1.7502e+02\n",
      "Epoch 17750, Training-Loss 4.8363e+02, Data-loss 2.8709e+02                  , pde-loss 2.8054e+03, initc-loss 1.3412e+04                    bc_loss 1.0479e+06, Test-Loss 2.8709e+02\n",
      "Epoch 17760, Training-Loss 4.0207e+02, Data-loss 1.9753e+02                  , pde-loss 2.2827e+03, initc-loss 1.3556e+04                    bc_loss 1.1187e+06, Test-Loss 1.9753e+02\n",
      "Epoch 17770, Training-Loss 5.0301e+02, Data-loss 1.9342e+02                  , pde-loss 2.1883e+03, initc-loss 1.3311e+04                    bc_loss 1.2931e+06, Test-Loss 1.9342e+02\n",
      "Epoch 17780, Training-Loss 2.4401e+02, Data-loss 2.3427e+02                  , pde-loss 2.8268e+03, initc-loss 1.3425e+04                    bc_loss 1.0055e+06, Test-Loss 2.3427e+02\n",
      "Epoch 17790, Training-Loss 5.4042e+02, Data-loss 4.5517e+02                  , pde-loss 2.9061e+03, initc-loss 1.2964e+04                    bc_loss 1.1731e+06, Test-Loss 4.5517e+02\n",
      "Epoch 17800, Training-Loss 3.9242e+02, Data-loss 2.3363e+02                  , pde-loss 2.3543e+03, initc-loss 1.3406e+04                    bc_loss 8.3580e+05, Test-Loss 2.3363e+02\n",
      "Epoch 17810, Training-Loss 3.6074e+02, Data-loss 1.2351e+02                  , pde-loss 3.5985e+03, initc-loss 1.3742e+04                    bc_loss 8.7592e+05, Test-Loss 1.2351e+02\n",
      "Epoch 17820, Training-Loss 5.1281e+02, Data-loss 2.1526e+02                  , pde-loss 2.2820e+03, initc-loss 1.3506e+04                    bc_loss 1.0091e+06, Test-Loss 2.1526e+02\n",
      "Epoch 17830, Training-Loss 4.0022e+02, Data-loss 2.8413e+02                  , pde-loss 3.0221e+03, initc-loss 1.3605e+04                    bc_loss 6.6376e+05, Test-Loss 2.8413e+02\n",
      "Epoch 17840, Training-Loss 7.1732e+02, Data-loss 2.6158e+02                  , pde-loss 2.4282e+03, initc-loss 1.3654e+04                    bc_loss 9.0277e+05, Test-Loss 2.6158e+02\n",
      "Epoch 17850, Training-Loss 3.9006e+02, Data-loss 1.4543e+02                  , pde-loss 3.2198e+03, initc-loss 1.4886e+04                    bc_loss 7.0192e+05, Test-Loss 1.4543e+02\n",
      "Epoch 17860, Training-Loss 3.9349e+02, Data-loss 2.5662e+02                  , pde-loss 2.8385e+03, initc-loss 1.3616e+04                    bc_loss 7.8739e+05, Test-Loss 2.5662e+02\n",
      "Epoch 17870, Training-Loss 2.7039e+02, Data-loss 2.9767e+02                  , pde-loss 2.0005e+03, initc-loss 1.3325e+04                    bc_loss 5.8316e+05, Test-Loss 2.9767e+02\n",
      "Epoch 17880, Training-Loss 3.4566e+02, Data-loss 3.2750e+02                  , pde-loss 2.4208e+03, initc-loss 1.3928e+04                    bc_loss 6.0222e+05, Test-Loss 3.2750e+02\n",
      "Epoch 17890, Training-Loss 3.3996e+02, Data-loss 3.1913e+02                  , pde-loss 3.0565e+03, initc-loss 1.2770e+04                    bc_loss 7.5170e+05, Test-Loss 3.1913e+02\n",
      "Epoch 17900, Training-Loss 6.4479e+02, Data-loss 2.1167e+02                  , pde-loss 2.1559e+03, initc-loss 1.5114e+04                    bc_loss 3.2375e+05, Test-Loss 2.1167e+02\n",
      "Epoch 17910, Training-Loss 4.1213e+02, Data-loss 4.1703e+02                  , pde-loss 2.5364e+03, initc-loss 1.3192e+04                    bc_loss 6.6227e+05, Test-Loss 4.1703e+02\n",
      "Epoch 17920, Training-Loss 1.6210e+02, Data-loss 2.3692e+02                  , pde-loss 2.7372e+03, initc-loss 1.3250e+04                    bc_loss 8.0346e+05, Test-Loss 2.3692e+02\n",
      "Epoch 17930, Training-Loss 2.7563e+02, Data-loss 1.8925e+02                  , pde-loss 2.5511e+03, initc-loss 1.4029e+04                    bc_loss 8.0210e+05, Test-Loss 1.8925e+02\n",
      "Epoch 17940, Training-Loss 3.5466e+02, Data-loss 1.3247e+02                  , pde-loss 2.8108e+03, initc-loss 1.2997e+04                    bc_loss 9.8834e+05, Test-Loss 1.3247e+02\n",
      "Epoch 17950, Training-Loss 3.0188e+02, Data-loss 6.9691e+02                  , pde-loss 2.2029e+03, initc-loss 1.4539e+04                    bc_loss 1.5657e+05, Test-Loss 6.9691e+02\n",
      "Epoch 17960, Training-Loss 2.6009e+02, Data-loss 2.2307e+02                  , pde-loss 3.0492e+03, initc-loss 1.4082e+04                    bc_loss 3.6248e+05, Test-Loss 2.2307e+02\n",
      "Epoch 17970, Training-Loss 1.8437e+02, Data-loss 2.2544e+02                  , pde-loss 2.4693e+03, initc-loss 1.2767e+04                    bc_loss 9.5686e+05, Test-Loss 2.2544e+02\n",
      "Epoch 17980, Training-Loss 2.1939e+02, Data-loss 1.3745e+02                  , pde-loss 2.2151e+03, initc-loss 1.3452e+04                    bc_loss 6.3542e+05, Test-Loss 1.3745e+02\n",
      "Epoch 17990, Training-Loss 3.8110e+02, Data-loss 2.9179e+02                  , pde-loss 3.1767e+03, initc-loss 1.4107e+04                    bc_loss 1.8283e+05, Test-Loss 2.9179e+02\n",
      "Epoch 18000, Training-Loss 3.0204e+02, Data-loss 3.0272e+02                  , pde-loss 3.1171e+03, initc-loss 1.3057e+04                    bc_loss 4.8425e+05, Test-Loss 3.0272e+02\n",
      "Epoch 18010, Training-Loss 3.3145e+02, Data-loss 2.0395e+02                  , pde-loss 3.3772e+03, initc-loss 1.3550e+04                    bc_loss 3.6554e+05, Test-Loss 2.0395e+02\n",
      "Epoch 18020, Training-Loss 5.0889e+02, Data-loss 2.4353e+02                  , pde-loss 5.0788e+03, initc-loss 1.3960e+04                    bc_loss 1.8750e+05, Test-Loss 2.4353e+02\n",
      "Epoch 18030, Training-Loss 1.6181e+02, Data-loss 2.9524e+02                  , pde-loss 1.7653e+03, initc-loss 1.3835e+04                    bc_loss 6.3331e+05, Test-Loss 2.9524e+02\n",
      "Epoch 18040, Training-Loss 2.4648e+02, Data-loss 1.9704e+02                  , pde-loss 3.3585e+03, initc-loss 1.3386e+04                    bc_loss 4.5019e+05, Test-Loss 1.9704e+02\n",
      "Epoch 18050, Training-Loss 3.1310e+02, Data-loss 3.0722e+02                  , pde-loss 1.7712e+03, initc-loss 1.2646e+04                    bc_loss 4.4910e+05, Test-Loss 3.0722e+02\n",
      "Epoch 18060, Training-Loss 2.9838e+02, Data-loss 1.7831e+02                  , pde-loss 2.5190e+03, initc-loss 1.3522e+04                    bc_loss 6.2204e+05, Test-Loss 1.7831e+02\n",
      "Epoch 18070, Training-Loss 3.2950e+02, Data-loss 3.2953e+02                  , pde-loss 3.9088e+03, initc-loss 1.3174e+04                    bc_loss 4.0160e+05, Test-Loss 3.2953e+02\n",
      "Epoch 18080, Training-Loss 1.8910e+02, Data-loss 7.0460e+01                  , pde-loss 2.5149e+03, initc-loss 1.3492e+04                    bc_loss 3.0799e+05, Test-Loss 7.0460e+01\n",
      "Epoch 18090, Training-Loss 2.6970e+02, Data-loss 2.3156e+02                  , pde-loss 2.6989e+03, initc-loss 1.4580e+04                    bc_loss 6.4248e+05, Test-Loss 2.3156e+02\n",
      "Epoch 18100, Training-Loss 3.0338e+02, Data-loss 1.6169e+02                  , pde-loss 2.3486e+03, initc-loss 1.2823e+04                    bc_loss 8.7114e+05, Test-Loss 1.6169e+02\n",
      "Epoch 18110, Training-Loss 1.5373e+02, Data-loss 2.0763e+02                  , pde-loss 3.0369e+03, initc-loss 1.3974e+04                    bc_loss 3.3055e+05, Test-Loss 2.0763e+02\n",
      "Epoch 18120, Training-Loss 3.3511e+02, Data-loss 3.8241e+02                  , pde-loss 3.0124e+03, initc-loss 1.2972e+04                    bc_loss 5.4636e+05, Test-Loss 3.8241e+02\n",
      "Epoch 18130, Training-Loss 2.6359e+02, Data-loss 6.4426e+01                  , pde-loss 2.8404e+03, initc-loss 1.2929e+04                    bc_loss 5.6540e+05, Test-Loss 6.4426e+01\n",
      "Epoch 18140, Training-Loss 1.9091e+02, Data-loss 1.2880e+02                  , pde-loss 3.4592e+03, initc-loss 1.2947e+04                    bc_loss 3.2559e+05, Test-Loss 1.2880e+02\n",
      "Epoch 18150, Training-Loss 2.2878e+02, Data-loss 2.2514e+02                  , pde-loss 2.9491e+03, initc-loss 1.3766e+04                    bc_loss 2.3766e+05, Test-Loss 2.2514e+02\n",
      "Epoch 18160, Training-Loss 3.5094e+02, Data-loss 3.8714e+02                  , pde-loss 2.3611e+03, initc-loss 1.3465e+04                    bc_loss 4.9516e+05, Test-Loss 3.8714e+02\n",
      "Epoch 18170, Training-Loss 3.0114e+02, Data-loss 2.7079e+02                  , pde-loss 2.7735e+03, initc-loss 1.3594e+04                    bc_loss 3.7516e+05, Test-Loss 2.7079e+02\n",
      "Epoch 18180, Training-Loss 1.5906e+02, Data-loss 4.8533e+01                  , pde-loss 3.1798e+03, initc-loss 1.3047e+04                    bc_loss 4.1483e+05, Test-Loss 4.8533e+01\n",
      "Epoch 18190, Training-Loss 1.1018e+02, Data-loss 1.9680e+02                  , pde-loss 2.3195e+03, initc-loss 1.3933e+04                    bc_loss 1.8153e+05, Test-Loss 1.9680e+02\n",
      "Epoch 18200, Training-Loss 1.3945e+02, Data-loss 1.1631e+02                  , pde-loss 3.3165e+03, initc-loss 1.3354e+04                    bc_loss 2.4095e+05, Test-Loss 1.1631e+02\n",
      "Epoch 18210, Training-Loss 1.4854e+02, Data-loss 2.1801e+02                  , pde-loss 2.9622e+03, initc-loss 1.3521e+04                    bc_loss 3.9660e+05, Test-Loss 2.1801e+02\n",
      "Epoch 18220, Training-Loss 1.9292e+02, Data-loss 2.4624e+02                  , pde-loss 2.4157e+03, initc-loss 1.3424e+04                    bc_loss 4.5103e+05, Test-Loss 2.4624e+02\n",
      "Epoch 18230, Training-Loss 9.5111e+01, Data-loss 1.8147e+02                  , pde-loss 2.8639e+03, initc-loss 1.4023e+04                    bc_loss 3.5681e+05, Test-Loss 1.8147e+02\n",
      "Epoch 18240, Training-Loss 5.2346e+02, Data-loss 2.2841e+02                  , pde-loss 3.2477e+03, initc-loss 1.3702e+04                    bc_loss 4.0602e+05, Test-Loss 2.2841e+02\n",
      "Epoch 18250, Training-Loss 3.2595e+02, Data-loss 2.1567e+02                  , pde-loss 2.8196e+03, initc-loss 1.4069e+04                    bc_loss 2.7550e+05, Test-Loss 2.1567e+02\n",
      "Epoch 18260, Training-Loss 4.1882e+02, Data-loss 1.4424e+02                  , pde-loss 2.7910e+03, initc-loss 1.3941e+04                    bc_loss 1.4374e+05, Test-Loss 1.4424e+02\n",
      "Epoch 18270, Training-Loss 8.0300e+01, Data-loss 2.1827e+02                  , pde-loss 3.3614e+03, initc-loss 1.4101e+04                    bc_loss 2.2237e+05, Test-Loss 2.1827e+02\n",
      "Epoch 18280, Training-Loss 3.3158e+02, Data-loss 4.2435e+01                  , pde-loss 2.7486e+03, initc-loss 1.3144e+04                    bc_loss 3.2828e+05, Test-Loss 4.2435e+01\n",
      "Epoch 18290, Training-Loss 2.5901e+02, Data-loss 1.4068e+02                  , pde-loss 3.2249e+03, initc-loss 1.4083e+04                    bc_loss 3.3312e+05, Test-Loss 1.4068e+02\n",
      "Epoch 18300, Training-Loss 2.6791e+02, Data-loss 3.9854e+02                  , pde-loss 2.9270e+03, initc-loss 1.4260e+04                    bc_loss 2.0507e+05, Test-Loss 3.9854e+02\n",
      "Epoch 18310, Training-Loss 3.1984e+02, Data-loss 1.4193e+02                  , pde-loss 4.2130e+03, initc-loss 1.3282e+04                    bc_loss 4.8394e+05, Test-Loss 1.4193e+02\n",
      "Epoch 18320, Training-Loss 2.5251e+02, Data-loss 1.7915e+02                  , pde-loss 3.1034e+03, initc-loss 1.4050e+04                    bc_loss 1.9648e+05, Test-Loss 1.7915e+02\n",
      "Epoch 18330, Training-Loss 2.5592e+02, Data-loss 5.7556e+01                  , pde-loss 3.6082e+03, initc-loss 1.3622e+04                    bc_loss 2.7341e+05, Test-Loss 5.7556e+01\n",
      "Epoch 18340, Training-Loss 2.5409e+02, Data-loss 2.4642e+02                  , pde-loss 3.0687e+03, initc-loss 1.3638e+04                    bc_loss 3.9863e+05, Test-Loss 2.4642e+02\n",
      "Epoch 18350, Training-Loss 2.7017e+02, Data-loss 3.0214e+02                  , pde-loss 2.5343e+03, initc-loss 1.4405e+04                    bc_loss 2.5025e+05, Test-Loss 3.0214e+02\n",
      "Epoch 18360, Training-Loss 3.3808e+02, Data-loss 1.3668e+02                  , pde-loss 4.0835e+03, initc-loss 1.2820e+04                    bc_loss 4.5940e+05, Test-Loss 1.3668e+02\n",
      "Epoch 18370, Training-Loss 8.3960e+01, Data-loss 2.9994e+02                  , pde-loss 3.3746e+03, initc-loss 1.3959e+04                    bc_loss 2.7141e+05, Test-Loss 2.9994e+02\n",
      "Epoch 18380, Training-Loss 2.2421e+02, Data-loss 7.5737e+01                  , pde-loss 2.7757e+03, initc-loss 1.3683e+04                    bc_loss 2.1949e+05, Test-Loss 7.5737e+01\n",
      "Epoch 18390, Training-Loss 7.0688e+01, Data-loss 2.1814e+02                  , pde-loss 3.3212e+03, initc-loss 1.4034e+04                    bc_loss 2.6158e+05, Test-Loss 2.1814e+02\n",
      "Epoch 18400, Training-Loss 2.0264e+02, Data-loss 8.3147e+01                  , pde-loss 3.3868e+03, initc-loss 1.2558e+04                    bc_loss 4.6262e+05, Test-Loss 8.3147e+01\n",
      "Epoch 18410, Training-Loss 2.4549e+02, Data-loss 9.0487e+01                  , pde-loss 3.3551e+03, initc-loss 1.3298e+04                    bc_loss 4.1198e+05, Test-Loss 9.0487e+01\n",
      "Epoch 18420, Training-Loss 1.8064e+02, Data-loss 1.5168e+02                  , pde-loss 2.4769e+03, initc-loss 1.4040e+04                    bc_loss 1.5071e+05, Test-Loss 1.5168e+02\n",
      "Epoch 18430, Training-Loss 1.5593e+02, Data-loss 2.2696e+02                  , pde-loss 3.3780e+03, initc-loss 1.3226e+04                    bc_loss 2.4258e+05, Test-Loss 2.2696e+02\n",
      "Epoch 18440, Training-Loss 2.3866e+02, Data-loss 1.1377e+02                  , pde-loss 3.4807e+03, initc-loss 1.3767e+04                    bc_loss 1.6886e+05, Test-Loss 1.1377e+02\n",
      "Epoch 18450, Training-Loss 1.6115e+02, Data-loss 1.1540e+02                  , pde-loss 2.5996e+03, initc-loss 1.3213e+04                    bc_loss 3.2460e+05, Test-Loss 1.1540e+02\n",
      "Epoch 18460, Training-Loss 9.0538e+01, Data-loss 1.5441e+02                  , pde-loss 3.4125e+03, initc-loss 1.2784e+04                    bc_loss 4.0007e+05, Test-Loss 1.5441e+02\n",
      "Epoch 18470, Training-Loss 1.7082e+02, Data-loss 1.5485e+02                  , pde-loss 3.1727e+03, initc-loss 1.4125e+04                    bc_loss 1.9589e+05, Test-Loss 1.5485e+02\n",
      "Epoch 18480, Training-Loss 2.6746e+02, Data-loss 2.9169e+02                  , pde-loss 3.9864e+03, initc-loss 1.4020e+04                    bc_loss 2.5889e+05, Test-Loss 2.9169e+02\n",
      "Epoch 18490, Training-Loss 1.2546e+02, Data-loss 1.2488e+02                  , pde-loss 3.1680e+03, initc-loss 1.3444e+04                    bc_loss 1.5335e+05, Test-Loss 1.2488e+02\n",
      "Epoch 18500, Training-Loss 3.9478e+02, Data-loss 1.9576e+02                  , pde-loss 3.1492e+03, initc-loss 1.2812e+04                    bc_loss 2.5845e+05, Test-Loss 1.9576e+02\n",
      "Epoch 18510, Training-Loss 8.6552e+01, Data-loss 2.2733e+02                  , pde-loss 3.5919e+03, initc-loss 1.4261e+04                    bc_loss 9.3656e+04, Test-Loss 2.2733e+02\n",
      "Epoch 18520, Training-Loss 2.6337e+02, Data-loss 2.9807e+02                  , pde-loss 3.1010e+03, initc-loss 1.2847e+04                    bc_loss 1.7738e+05, Test-Loss 2.9807e+02\n",
      "Epoch 18530, Training-Loss 2.4886e+02, Data-loss 1.8596e+02                  , pde-loss 3.2000e+03, initc-loss 1.3435e+04                    bc_loss 2.7556e+05, Test-Loss 1.8596e+02\n",
      "Epoch 18540, Training-Loss 1.0172e+02, Data-loss 2.6936e+02                  , pde-loss 3.3666e+03, initc-loss 1.4024e+04                    bc_loss 1.6425e+05, Test-Loss 2.6936e+02\n",
      "Epoch 18550, Training-Loss 4.5291e+02, Data-loss 2.6155e+02                  , pde-loss 4.5989e+03, initc-loss 1.3651e+04                    bc_loss 1.7623e+05, Test-Loss 2.6155e+02\n",
      "Epoch 18560, Training-Loss 7.1166e+01, Data-loss 2.2269e+02                  , pde-loss 4.6575e+03, initc-loss 1.5069e+04                    bc_loss 1.2185e+05, Test-Loss 2.2269e+02\n",
      "Epoch 18570, Training-Loss 2.6095e+02, Data-loss 1.3482e+02                  , pde-loss 2.2320e+03, initc-loss 1.3465e+04                    bc_loss 1.7671e+05, Test-Loss 1.3482e+02\n",
      "Epoch 18580, Training-Loss 8.1323e+01, Data-loss 6.8231e+01                  , pde-loss 3.3933e+03, initc-loss 1.3686e+04                    bc_loss 2.6197e+05, Test-Loss 6.8231e+01\n",
      "Epoch 18590, Training-Loss 2.9083e+02, Data-loss 1.4779e+02                  , pde-loss 4.8140e+03, initc-loss 1.2989e+04                    bc_loss 2.0343e+05, Test-Loss 1.4779e+02\n",
      "Epoch 18600, Training-Loss 5.3008e+02, Data-loss 1.0456e+02                  , pde-loss 4.9245e+03, initc-loss 1.3876e+04                    bc_loss 2.3098e+05, Test-Loss 1.0456e+02\n",
      "Epoch 18610, Training-Loss 7.1965e+01, Data-loss 1.0973e+02                  , pde-loss 2.5357e+03, initc-loss 1.3791e+04                    bc_loss 1.0090e+05, Test-Loss 1.0973e+02\n",
      "Epoch 18620, Training-Loss 1.7609e+02, Data-loss 2.0520e+02                  , pde-loss 2.7138e+03, initc-loss 1.2720e+04                    bc_loss 1.6118e+05, Test-Loss 2.0520e+02\n",
      "Epoch 18630, Training-Loss 1.8045e+02, Data-loss 2.1173e+02                  , pde-loss 3.9071e+03, initc-loss 1.3344e+04                    bc_loss 4.3810e+05, Test-Loss 2.1173e+02\n",
      "Epoch 18640, Training-Loss 1.7203e+02, Data-loss 5.9414e+01                  , pde-loss 3.5432e+03, initc-loss 1.3857e+04                    bc_loss 2.4933e+05, Test-Loss 5.9414e+01\n",
      "Epoch 18650, Training-Loss 1.3900e+02, Data-loss 6.0369e+01                  , pde-loss 3.7777e+03, initc-loss 1.3571e+04                    bc_loss 1.5146e+05, Test-Loss 6.0369e+01\n",
      "Epoch 18660, Training-Loss 1.6675e+02, Data-loss 1.1506e+02                  , pde-loss 2.7806e+03, initc-loss 1.3495e+04                    bc_loss 2.0422e+05, Test-Loss 1.1506e+02\n",
      "Epoch 18670, Training-Loss 1.4465e+02, Data-loss 1.0402e+02                  , pde-loss 3.2326e+03, initc-loss 1.3521e+04                    bc_loss 2.5628e+05, Test-Loss 1.0402e+02\n",
      "Epoch 18680, Training-Loss 1.8111e+02, Data-loss 1.1058e+02                  , pde-loss 3.3408e+03, initc-loss 1.2782e+04                    bc_loss 2.3639e+05, Test-Loss 1.1058e+02\n",
      "Epoch 18690, Training-Loss 1.4483e+02, Data-loss 1.4315e+02                  , pde-loss 2.9291e+03, initc-loss 1.3834e+04                    bc_loss 1.4917e+05, Test-Loss 1.4315e+02\n",
      "Epoch 18700, Training-Loss 1.3023e+02, Data-loss 1.8546e+02                  , pde-loss 4.1509e+03, initc-loss 1.3433e+04                    bc_loss 1.2054e+05, Test-Loss 1.8546e+02\n",
      "Epoch 18710, Training-Loss 1.1420e+02, Data-loss 5.1452e+01                  , pde-loss 2.9586e+03, initc-loss 1.2948e+04                    bc_loss 3.6026e+05, Test-Loss 5.1452e+01\n",
      "Epoch 18720, Training-Loss 1.4650e+02, Data-loss 6.4950e+01                  , pde-loss 3.7280e+03, initc-loss 1.3152e+04                    bc_loss 2.7517e+05, Test-Loss 6.4950e+01\n",
      "Epoch 18730, Training-Loss 2.0526e+02, Data-loss 1.8200e+02                  , pde-loss 2.9984e+03, initc-loss 1.2962e+04                    bc_loss 3.1070e+05, Test-Loss 1.8200e+02\n",
      "Epoch 18740, Training-Loss 1.0145e+02, Data-loss 1.4014e+02                  , pde-loss 3.6695e+03, initc-loss 1.3702e+04                    bc_loss 3.3625e+05, Test-Loss 1.4014e+02\n",
      "Epoch 18750, Training-Loss 1.4608e+02, Data-loss 1.0554e+02                  , pde-loss 3.0147e+03, initc-loss 1.3747e+04                    bc_loss 1.0372e+05, Test-Loss 1.0554e+02\n",
      "Epoch 18760, Training-Loss 2.1751e+02, Data-loss 7.2639e+01                  , pde-loss 3.3827e+03, initc-loss 1.2855e+04                    bc_loss 1.1613e+05, Test-Loss 7.2639e+01\n",
      "Epoch 18770, Training-Loss 8.3111e+01, Data-loss 1.7066e+02                  , pde-loss 4.0067e+03, initc-loss 1.4049e+04                    bc_loss 3.2632e+05, Test-Loss 1.7066e+02\n",
      "Epoch 18780, Training-Loss 9.9203e+01, Data-loss 3.5370e+01                  , pde-loss 3.7458e+03, initc-loss 1.3158e+04                    bc_loss 2.4624e+05, Test-Loss 3.5370e+01\n",
      "Epoch 18790, Training-Loss 1.8551e+02, Data-loss 1.6450e+02                  , pde-loss 3.0195e+03, initc-loss 1.2907e+04                    bc_loss 1.8292e+05, Test-Loss 1.6450e+02\n",
      "Epoch 18800, Training-Loss 1.5840e+02, Data-loss 2.2172e+02                  , pde-loss 2.6416e+03, initc-loss 1.3265e+04                    bc_loss 2.2502e+05, Test-Loss 2.2172e+02\n",
      "Epoch 18810, Training-Loss 9.2587e+01, Data-loss 7.0180e+01                  , pde-loss 3.5436e+03, initc-loss 1.3592e+04                    bc_loss 1.3318e+05, Test-Loss 7.0180e+01\n",
      "Epoch 18820, Training-Loss 1.0963e+02, Data-loss 9.5996e+01                  , pde-loss 3.9252e+03, initc-loss 1.3081e+04                    bc_loss 1.8952e+05, Test-Loss 9.5996e+01\n",
      "Epoch 18830, Training-Loss 7.0991e+01, Data-loss 6.1661e+01                  , pde-loss 3.3041e+03, initc-loss 1.4067e+04                    bc_loss 9.4110e+04, Test-Loss 6.1661e+01\n",
      "Epoch 18840, Training-Loss 2.0505e+02, Data-loss 2.7705e+02                  , pde-loss 3.3650e+03, initc-loss 1.3355e+04                    bc_loss 1.0374e+05, Test-Loss 2.7705e+02\n",
      "Epoch 18850, Training-Loss 1.1233e+02, Data-loss 1.5461e+02                  , pde-loss 3.3223e+03, initc-loss 1.3294e+04                    bc_loss 1.2728e+05, Test-Loss 1.5461e+02\n",
      "Epoch 18860, Training-Loss 1.1411e+02, Data-loss 1.1498e+02                  , pde-loss 3.0408e+03, initc-loss 1.3435e+04                    bc_loss 2.6756e+05, Test-Loss 1.1498e+02\n",
      "Epoch 18870, Training-Loss 1.6070e+02, Data-loss 1.7353e+02                  , pde-loss 3.9530e+03, initc-loss 1.2389e+04                    bc_loss 2.0597e+05, Test-Loss 1.7353e+02\n",
      "Epoch 18880, Training-Loss 1.7200e+02, Data-loss 1.5638e+02                  , pde-loss 3.3584e+03, initc-loss 1.3279e+04                    bc_loss 1.0199e+05, Test-Loss 1.5638e+02\n",
      "Epoch 18890, Training-Loss 1.2867e+02, Data-loss 8.9914e+01                  , pde-loss 2.9140e+03, initc-loss 1.3598e+04                    bc_loss 1.2372e+05, Test-Loss 8.9914e+01\n",
      "Epoch 18900, Training-Loss 1.4173e+02, Data-loss 2.9254e+02                  , pde-loss 3.4636e+03, initc-loss 1.3393e+04                    bc_loss 1.7328e+05, Test-Loss 2.9254e+02\n",
      "Epoch 18910, Training-Loss 1.1592e+02, Data-loss 1.0147e+02                  , pde-loss 2.8333e+03, initc-loss 1.2977e+04                    bc_loss 1.8859e+05, Test-Loss 1.0147e+02\n",
      "Epoch 18920, Training-Loss 2.8170e+02, Data-loss 1.8202e+02                  , pde-loss 2.8932e+03, initc-loss 1.2761e+04                    bc_loss 1.9785e+05, Test-Loss 1.8202e+02\n",
      "Epoch 18930, Training-Loss 2.5840e+02, Data-loss 1.2956e+02                  , pde-loss 3.9237e+03, initc-loss 1.4041e+04                    bc_loss 1.3308e+05, Test-Loss 1.2956e+02\n",
      "Epoch 18940, Training-Loss 7.7078e+01, Data-loss 1.1213e+02                  , pde-loss 4.0291e+03, initc-loss 1.3951e+04                    bc_loss 6.4168e+04, Test-Loss 1.1213e+02\n",
      "Epoch 18950, Training-Loss 8.1831e+01, Data-loss 7.7840e+01                  , pde-loss 2.8483e+03, initc-loss 1.3595e+04                    bc_loss 1.0797e+05, Test-Loss 7.7840e+01\n",
      "Epoch 18960, Training-Loss 2.9133e+02, Data-loss 7.6455e+01                  , pde-loss 3.0226e+03, initc-loss 1.3260e+04                    bc_loss 1.2714e+05, Test-Loss 7.6455e+01\n",
      "Epoch 18970, Training-Loss 9.0097e+01, Data-loss 1.6798e+02                  , pde-loss 3.8308e+03, initc-loss 1.3304e+04                    bc_loss 1.4823e+05, Test-Loss 1.6798e+02\n",
      "Epoch 18980, Training-Loss 1.4927e+02, Data-loss 4.8819e+01                  , pde-loss 4.0039e+03, initc-loss 1.3673e+04                    bc_loss 2.0823e+05, Test-Loss 4.8819e+01\n",
      "Epoch 18990, Training-Loss 8.5599e+01, Data-loss 5.6371e+01                  , pde-loss 3.3950e+03, initc-loss 1.4297e+04                    bc_loss 7.1089e+04, Test-Loss 5.6371e+01\n",
      "Epoch 19000, Training-Loss 8.5037e+01, Data-loss 1.4827e+02                  , pde-loss 3.2857e+03, initc-loss 1.3114e+04                    bc_loss 1.4495e+05, Test-Loss 1.4827e+02\n",
      "Epoch 19010, Training-Loss 2.5986e+02, Data-loss 2.0344e+02                  , pde-loss 3.3852e+03, initc-loss 1.2808e+04                    bc_loss 2.0997e+05, Test-Loss 2.0344e+02\n",
      "Epoch 19020, Training-Loss 1.5797e+02, Data-loss 2.2681e+02                  , pde-loss 3.3584e+03, initc-loss 1.3733e+04                    bc_loss 1.8396e+05, Test-Loss 2.2681e+02\n",
      "Epoch 19030, Training-Loss 2.0809e+02, Data-loss 1.0477e+02                  , pde-loss 4.0663e+03, initc-loss 1.3360e+04                    bc_loss 1.0186e+05, Test-Loss 1.0477e+02\n",
      "Epoch 19040, Training-Loss 1.0197e+02, Data-loss 2.8573e+02                  , pde-loss 3.4232e+03, initc-loss 1.3221e+04                    bc_loss 9.1483e+04, Test-Loss 2.8573e+02\n",
      "Epoch 19050, Training-Loss 2.1612e+02, Data-loss 5.6580e+01                  , pde-loss 3.3073e+03, initc-loss 1.2973e+04                    bc_loss 1.1293e+05, Test-Loss 5.6580e+01\n",
      "Epoch 19060, Training-Loss 1.7917e+02, Data-loss 1.0195e+02                  , pde-loss 3.5616e+03, initc-loss 1.4072e+04                    bc_loss 8.8770e+04, Test-Loss 1.0195e+02\n",
      "Epoch 19070, Training-Loss 2.1809e+02, Data-loss 9.9134e+01                  , pde-loss 3.0993e+03, initc-loss 1.3004e+04                    bc_loss 1.2518e+05, Test-Loss 9.9134e+01\n",
      "Epoch 19080, Training-Loss 1.5258e+02, Data-loss 1.9625e+02                  , pde-loss 4.0177e+03, initc-loss 1.3773e+04                    bc_loss 5.1546e+04, Test-Loss 1.9625e+02\n",
      "Epoch 19090, Training-Loss 1.9061e+02, Data-loss 1.7531e+02                  , pde-loss 2.7132e+03, initc-loss 1.3276e+04                    bc_loss 1.0666e+05, Test-Loss 1.7531e+02\n",
      "Epoch 19100, Training-Loss 2.1887e+02, Data-loss 1.9276e+02                  , pde-loss 4.2933e+03, initc-loss 1.3101e+04                    bc_loss 1.8778e+05, Test-Loss 1.9276e+02\n",
      "Epoch 19110, Training-Loss 2.2815e+02, Data-loss 4.8084e+01                  , pde-loss 3.2945e+03, initc-loss 1.3342e+04                    bc_loss 6.9570e+04, Test-Loss 4.8084e+01\n",
      "Epoch 19120, Training-Loss 1.5712e+02, Data-loss 1.3096e+02                  , pde-loss 4.3742e+03, initc-loss 1.3936e+04                    bc_loss 4.5611e+04, Test-Loss 1.3096e+02\n",
      "Epoch 19130, Training-Loss 7.3555e+01, Data-loss 3.2594e+01                  , pde-loss 4.1822e+03, initc-loss 1.3250e+04                    bc_loss 1.0664e+05, Test-Loss 3.2594e+01\n",
      "Epoch 19140, Training-Loss 1.1729e+02, Data-loss 1.2253e+02                  , pde-loss 3.6618e+03, initc-loss 1.2765e+04                    bc_loss 2.4217e+05, Test-Loss 1.2253e+02\n",
      "Epoch 19150, Training-Loss 1.3350e+02, Data-loss 6.5635e+01                  , pde-loss 3.8603e+03, initc-loss 1.3206e+04                    bc_loss 1.0495e+05, Test-Loss 6.5635e+01\n",
      "Epoch 19160, Training-Loss 1.2665e+02, Data-loss 8.7176e+01                  , pde-loss 3.2675e+03, initc-loss 1.3854e+04                    bc_loss 1.0141e+05, Test-Loss 8.7176e+01\n",
      "Epoch 19170, Training-Loss 1.9947e+02, Data-loss 4.3647e+01                  , pde-loss 3.7099e+03, initc-loss 1.4524e+04                    bc_loss 7.4249e+04, Test-Loss 4.3647e+01\n",
      "Epoch 19180, Training-Loss 2.1798e+02, Data-loss 6.3990e+01                  , pde-loss 3.2897e+03, initc-loss 1.2921e+04                    bc_loss 1.3557e+05, Test-Loss 6.3990e+01\n",
      "Epoch 19190, Training-Loss 1.2739e+02, Data-loss 8.0587e+01                  , pde-loss 3.8770e+03, initc-loss 1.3107e+04                    bc_loss 1.6377e+05, Test-Loss 8.0587e+01\n",
      "Epoch 19200, Training-Loss 9.2427e+01, Data-loss 7.4384e+01                  , pde-loss 4.4296e+03, initc-loss 1.3295e+04                    bc_loss 9.6423e+04, Test-Loss 7.4384e+01\n",
      "Epoch 19210, Training-Loss 1.2217e+02, Data-loss 1.2120e+02                  , pde-loss 3.2545e+03, initc-loss 1.3235e+04                    bc_loss 1.1491e+05, Test-Loss 1.2120e+02\n",
      "Epoch 19220, Training-Loss 1.4704e+02, Data-loss 9.5698e+01                  , pde-loss 3.9536e+03, initc-loss 1.3765e+04                    bc_loss 7.6990e+04, Test-Loss 9.5698e+01\n",
      "Epoch 19230, Training-Loss 8.0296e+01, Data-loss 1.3161e+02                  , pde-loss 3.7278e+03, initc-loss 1.3370e+04                    bc_loss 1.6520e+05, Test-Loss 1.3161e+02\n",
      "Epoch 19240, Training-Loss 2.7183e+02, Data-loss 1.1863e+02                  , pde-loss 4.4577e+03, initc-loss 1.3147e+04                    bc_loss 1.2617e+05, Test-Loss 1.1863e+02\n",
      "Epoch 19250, Training-Loss 4.9809e+01, Data-loss 1.0145e+02                  , pde-loss 3.3684e+03, initc-loss 1.3671e+04                    bc_loss 9.6402e+04, Test-Loss 1.0145e+02\n",
      "Epoch 19260, Training-Loss 1.3218e+02, Data-loss 1.2108e+02                  , pde-loss 5.1100e+03, initc-loss 1.3901e+04                    bc_loss 4.7545e+04, Test-Loss 1.2108e+02\n",
      "Epoch 19270, Training-Loss 9.5618e+01, Data-loss 5.0734e+01                  , pde-loss 2.9780e+03, initc-loss 1.2860e+04                    bc_loss 1.0752e+05, Test-Loss 5.0734e+01\n",
      "Epoch 19280, Training-Loss 6.7213e+01, Data-loss 7.4926e+01                  , pde-loss 4.2890e+03, initc-loss 1.3723e+04                    bc_loss 9.5558e+04, Test-Loss 7.4926e+01\n",
      "Epoch 19290, Training-Loss 8.4921e+01, Data-loss 7.6569e+01                  , pde-loss 2.3576e+03, initc-loss 1.3276e+04                    bc_loss 6.7602e+04, Test-Loss 7.6569e+01\n",
      "Epoch 19300, Training-Loss 1.3789e+02, Data-loss 1.4939e+02                  , pde-loss 4.1964e+03, initc-loss 1.3121e+04                    bc_loss 9.2760e+04, Test-Loss 1.4939e+02\n",
      "Epoch 19310, Training-Loss 8.7410e+01, Data-loss 1.1085e+02                  , pde-loss 3.2907e+03, initc-loss 1.3816e+04                    bc_loss 5.5714e+04, Test-Loss 1.1085e+02\n",
      "Epoch 19320, Training-Loss 5.1957e+01, Data-loss 2.7203e+01                  , pde-loss 4.2095e+03, initc-loss 1.3735e+04                    bc_loss 7.0546e+04, Test-Loss 2.7203e+01\n",
      "Epoch 19330, Training-Loss 1.5269e+02, Data-loss 7.6687e+01                  , pde-loss 4.1879e+03, initc-loss 1.3386e+04                    bc_loss 1.2419e+05, Test-Loss 7.6687e+01\n",
      "Epoch 19340, Training-Loss 1.3387e+02, Data-loss 1.1121e+02                  , pde-loss 3.5767e+03, initc-loss 1.3044e+04                    bc_loss 9.9690e+04, Test-Loss 1.1121e+02\n",
      "Epoch 19350, Training-Loss 4.2975e+01, Data-loss 1.7748e+02                  , pde-loss 4.5964e+03, initc-loss 1.3270e+04                    bc_loss 6.8750e+04, Test-Loss 1.7748e+02\n",
      "Epoch 19360, Training-Loss 1.6089e+02, Data-loss 1.9170e+01                  , pde-loss 3.5924e+03, initc-loss 1.3023e+04                    bc_loss 7.6755e+04, Test-Loss 1.9170e+01\n",
      "Epoch 19370, Training-Loss 1.8896e+02, Data-loss 1.4155e+02                  , pde-loss 2.8032e+03, initc-loss 1.3622e+04                    bc_loss 4.5925e+04, Test-Loss 1.4155e+02\n",
      "Epoch 19380, Training-Loss 9.1114e+01, Data-loss 9.1998e+01                  , pde-loss 3.2741e+03, initc-loss 1.3383e+04                    bc_loss 5.6974e+04, Test-Loss 9.1998e+01\n",
      "Epoch 19390, Training-Loss 9.8116e+01, Data-loss 1.3207e+02                  , pde-loss 3.4180e+03, initc-loss 1.3743e+04                    bc_loss 8.4428e+04, Test-Loss 1.3207e+02\n",
      "Epoch 19400, Training-Loss 1.0618e+02, Data-loss 5.9211e+01                  , pde-loss 3.8150e+03, initc-loss 1.3227e+04                    bc_loss 7.4491e+04, Test-Loss 5.9211e+01\n",
      "Epoch 19410, Training-Loss 6.5608e+01, Data-loss 6.6988e+01                  , pde-loss 3.4062e+03, initc-loss 1.3302e+04                    bc_loss 7.8444e+04, Test-Loss 6.6988e+01\n",
      "Epoch 19420, Training-Loss 3.2792e+01, Data-loss 1.0454e+02                  , pde-loss 4.1304e+03, initc-loss 1.3450e+04                    bc_loss 5.8568e+04, Test-Loss 1.0454e+02\n",
      "Epoch 19430, Training-Loss 2.1481e+02, Data-loss 3.7940e+01                  , pde-loss 3.4816e+03, initc-loss 1.3652e+04                    bc_loss 1.2187e+05, Test-Loss 3.7940e+01\n",
      "Epoch 19440, Training-Loss 7.9036e+01, Data-loss 1.0871e+02                  , pde-loss 4.7329e+03, initc-loss 1.3218e+04                    bc_loss 7.8376e+04, Test-Loss 1.0871e+02\n",
      "Epoch 19450, Training-Loss 1.5374e+02, Data-loss 1.7712e+02                  , pde-loss 3.9145e+03, initc-loss 1.3807e+04                    bc_loss 6.7122e+04, Test-Loss 1.7712e+02\n",
      "Epoch 19460, Training-Loss 1.6102e+02, Data-loss 9.9507e+01                  , pde-loss 3.9081e+03, initc-loss 1.3042e+04                    bc_loss 1.0484e+05, Test-Loss 9.9507e+01\n",
      "Epoch 19470, Training-Loss 1.3914e+02, Data-loss 9.0360e+01                  , pde-loss 3.9987e+03, initc-loss 1.2894e+04                    bc_loss 1.2064e+05, Test-Loss 9.0360e+01\n",
      "Epoch 19480, Training-Loss 1.1973e+02, Data-loss 9.1575e+01                  , pde-loss 3.5279e+03, initc-loss 1.3424e+04                    bc_loss 4.9727e+04, Test-Loss 9.1575e+01\n",
      "Epoch 19490, Training-Loss 2.9038e+01, Data-loss 7.3420e+01                  , pde-loss 3.9505e+03, initc-loss 1.3258e+04                    bc_loss 5.7145e+04, Test-Loss 7.3420e+01\n",
      "Epoch 19500, Training-Loss 1.0310e+02, Data-loss 7.7155e+01                  , pde-loss 3.7225e+03, initc-loss 1.3215e+04                    bc_loss 7.7804e+04, Test-Loss 7.7155e+01\n",
      "Epoch 19510, Training-Loss 1.0676e+02, Data-loss 1.3302e+02                  , pde-loss 2.4356e+03, initc-loss 1.2688e+04                    bc_loss 1.3862e+05, Test-Loss 1.3302e+02\n",
      "Epoch 19520, Training-Loss 6.9740e+01, Data-loss 5.2900e+01                  , pde-loss 3.7980e+03, initc-loss 1.2986e+04                    bc_loss 1.4857e+05, Test-Loss 5.2900e+01\n",
      "Epoch 19530, Training-Loss 5.3605e+01, Data-loss 7.2888e+01                  , pde-loss 4.0736e+03, initc-loss 1.3453e+04                    bc_loss 5.6202e+04, Test-Loss 7.2888e+01\n",
      "Epoch 19540, Training-Loss 1.8829e+02, Data-loss 1.6124e+02                  , pde-loss 4.1741e+03, initc-loss 1.3688e+04                    bc_loss 4.8789e+04, Test-Loss 1.6124e+02\n",
      "Epoch 19550, Training-Loss 8.3822e+01, Data-loss 1.0902e+02                  , pde-loss 3.8324e+03, initc-loss 1.3355e+04                    bc_loss 9.0852e+04, Test-Loss 1.0902e+02\n",
      "Epoch 19560, Training-Loss 7.8139e+01, Data-loss 1.0782e+02                  , pde-loss 4.1657e+03, initc-loss 1.3029e+04                    bc_loss 9.2956e+04, Test-Loss 1.0782e+02\n",
      "Epoch 19570, Training-Loss 1.8932e+02, Data-loss 6.4779e+01                  , pde-loss 5.4973e+03, initc-loss 1.3128e+04                    bc_loss 1.4629e+05, Test-Loss 6.4779e+01\n",
      "Epoch 19580, Training-Loss 5.3067e+01, Data-loss 8.9272e+01                  , pde-loss 4.2484e+03, initc-loss 1.3796e+04                    bc_loss 1.2732e+05, Test-Loss 8.9272e+01\n",
      "Epoch 19590, Training-Loss 8.0032e+01, Data-loss 4.8339e+01                  , pde-loss 4.5425e+03, initc-loss 1.3099e+04                    bc_loss 8.3795e+04, Test-Loss 4.8339e+01\n",
      "Epoch 19600, Training-Loss 8.6580e+01, Data-loss 6.6385e+01                  , pde-loss 4.0546e+03, initc-loss 1.3123e+04                    bc_loss 1.5245e+05, Test-Loss 6.6385e+01\n",
      "Epoch 19610, Training-Loss 1.2840e+02, Data-loss 6.4215e+01                  , pde-loss 4.2957e+03, initc-loss 1.2955e+04                    bc_loss 1.0095e+05, Test-Loss 6.4215e+01\n",
      "Epoch 19620, Training-Loss 7.1047e+01, Data-loss 3.7841e+01                  , pde-loss 3.8657e+03, initc-loss 1.3408e+04                    bc_loss 1.0325e+05, Test-Loss 3.7841e+01\n",
      "Epoch 19630, Training-Loss 4.9985e+01, Data-loss 1.2211e+02                  , pde-loss 5.7566e+03, initc-loss 1.3521e+04                    bc_loss 7.6537e+04, Test-Loss 1.2211e+02\n",
      "Epoch 19640, Training-Loss 7.2254e+01, Data-loss 7.7132e+01                  , pde-loss 3.9476e+03, initc-loss 1.3270e+04                    bc_loss 4.6804e+04, Test-Loss 7.7132e+01\n",
      "Epoch 19650, Training-Loss 1.3952e+02, Data-loss 3.4299e+01                  , pde-loss 4.0531e+03, initc-loss 1.3079e+04                    bc_loss 1.2523e+05, Test-Loss 3.4299e+01\n",
      "Epoch 19660, Training-Loss 6.0484e+01, Data-loss 8.5628e+01                  , pde-loss 6.4061e+03, initc-loss 1.3041e+04                    bc_loss 5.8602e+04, Test-Loss 8.5628e+01\n",
      "Epoch 19670, Training-Loss 1.1797e+02, Data-loss 1.2949e+02                  , pde-loss 4.5886e+03, initc-loss 1.3603e+04                    bc_loss 8.0210e+04, Test-Loss 1.2949e+02\n",
      "Epoch 19680, Training-Loss 9.7528e+01, Data-loss 1.7232e+02                  , pde-loss 3.9232e+03, initc-loss 1.3544e+04                    bc_loss 7.1121e+04, Test-Loss 1.7232e+02\n",
      "Epoch 19690, Training-Loss 8.6851e+01, Data-loss 8.8016e+01                  , pde-loss 4.7740e+03, initc-loss 1.2948e+04                    bc_loss 1.4432e+05, Test-Loss 8.8016e+01\n",
      "Epoch 19700, Training-Loss 5.8561e+01, Data-loss 9.2532e+01                  , pde-loss 4.5614e+03, initc-loss 1.3216e+04                    bc_loss 1.3592e+05, Test-Loss 9.2532e+01\n",
      "Epoch 19710, Training-Loss 1.1371e+02, Data-loss 7.6011e+01                  , pde-loss 4.2660e+03, initc-loss 1.3542e+04                    bc_loss 8.2959e+04, Test-Loss 7.6011e+01\n",
      "Epoch 19720, Training-Loss 6.9402e+01, Data-loss 7.8005e+01                  , pde-loss 4.8102e+03, initc-loss 1.2729e+04                    bc_loss 1.5106e+05, Test-Loss 7.8005e+01\n",
      "Epoch 19730, Training-Loss 4.2293e+01, Data-loss 5.0245e+01                  , pde-loss 4.6185e+03, initc-loss 1.2785e+04                    bc_loss 1.2517e+05, Test-Loss 5.0245e+01\n",
      "Epoch 19740, Training-Loss 3.9589e+01, Data-loss 1.8019e+02                  , pde-loss 4.5250e+03, initc-loss 1.3794e+04                    bc_loss 5.4407e+04, Test-Loss 1.8019e+02\n",
      "Epoch 19750, Training-Loss 4.2399e+01, Data-loss 1.1581e+02                  , pde-loss 3.3882e+03, initc-loss 1.3227e+04                    bc_loss 1.0024e+05, Test-Loss 1.1581e+02\n",
      "Epoch 19760, Training-Loss 1.0943e+02, Data-loss 1.6627e+02                  , pde-loss 4.5881e+03, initc-loss 1.2907e+04                    bc_loss 6.8549e+04, Test-Loss 1.6627e+02\n",
      "Epoch 19770, Training-Loss 5.4841e+01, Data-loss 6.7961e+01                  , pde-loss 3.6331e+03, initc-loss 1.3333e+04                    bc_loss 4.9183e+04, Test-Loss 6.7961e+01\n",
      "Epoch 19780, Training-Loss 5.6169e+01, Data-loss 1.3734e+02                  , pde-loss 4.3856e+03, initc-loss 1.3486e+04                    bc_loss 6.8064e+04, Test-Loss 1.3734e+02\n",
      "Epoch 19790, Training-Loss 7.3984e+01, Data-loss 1.1374e+02                  , pde-loss 4.2082e+03, initc-loss 1.3246e+04                    bc_loss 6.3543e+04, Test-Loss 1.1374e+02\n",
      "Epoch 19800, Training-Loss 1.0628e+02, Data-loss 1.7119e+02                  , pde-loss 5.7090e+03, initc-loss 1.3458e+04                    bc_loss 6.3364e+04, Test-Loss 1.7119e+02\n",
      "Epoch 19810, Training-Loss 9.1688e+01, Data-loss 6.4101e+01                  , pde-loss 4.5949e+03, initc-loss 1.3082e+04                    bc_loss 4.4598e+04, Test-Loss 6.4101e+01\n",
      "Epoch 19820, Training-Loss 5.9658e+01, Data-loss 2.9259e+01                  , pde-loss 4.6471e+03, initc-loss 1.3462e+04                    bc_loss 5.1728e+04, Test-Loss 2.9259e+01\n",
      "Epoch 19830, Training-Loss 1.8280e+02, Data-loss 5.8907e+01                  , pde-loss 2.7763e+03, initc-loss 1.3033e+04                    bc_loss 6.4638e+04, Test-Loss 5.8907e+01\n",
      "Epoch 19840, Training-Loss 8.0418e+01, Data-loss 6.0500e+01                  , pde-loss 4.6973e+03, initc-loss 1.3425e+04                    bc_loss 4.7875e+04, Test-Loss 6.0500e+01\n",
      "Epoch 19850, Training-Loss 2.9241e+01, Data-loss 6.1798e+01                  , pde-loss 4.8100e+03, initc-loss 1.3702e+04                    bc_loss 4.2735e+04, Test-Loss 6.1798e+01\n",
      "Epoch 19860, Training-Loss 6.5870e+01, Data-loss 1.6680e+02                  , pde-loss 4.2375e+03, initc-loss 1.3461e+04                    bc_loss 5.0197e+04, Test-Loss 1.6680e+02\n",
      "Epoch 19870, Training-Loss 8.2767e+01, Data-loss 3.8516e+01                  , pde-loss 4.4845e+03, initc-loss 1.2905e+04                    bc_loss 2.0261e+05, Test-Loss 3.8516e+01\n",
      "Epoch 19880, Training-Loss 6.5531e+01, Data-loss 1.0271e+02                  , pde-loss 3.5988e+03, initc-loss 1.2956e+04                    bc_loss 7.4744e+04, Test-Loss 1.0271e+02\n",
      "Epoch 19890, Training-Loss 8.7992e+01, Data-loss 6.3304e+01                  , pde-loss 4.4070e+03, initc-loss 1.3028e+04                    bc_loss 1.3784e+05, Test-Loss 6.3304e+01\n",
      "Epoch 19900, Training-Loss 4.9228e+01, Data-loss 7.8196e+01                  , pde-loss 4.1188e+03, initc-loss 1.2700e+04                    bc_loss 1.3727e+05, Test-Loss 7.8196e+01\n",
      "Epoch 19910, Training-Loss 6.2535e+01, Data-loss 1.6538e+01                  , pde-loss 3.1289e+03, initc-loss 1.3282e+04                    bc_loss 4.0699e+04, Test-Loss 1.6538e+01\n",
      "Epoch 19920, Training-Loss 5.0443e+01, Data-loss 7.9128e+01                  , pde-loss 4.3602e+03, initc-loss 1.3769e+04                    bc_loss 5.0931e+04, Test-Loss 7.9128e+01\n",
      "Epoch 19930, Training-Loss 8.0787e+01, Data-loss 5.7709e+01                  , pde-loss 4.4502e+03, initc-loss 1.3196e+04                    bc_loss 4.4993e+04, Test-Loss 5.7709e+01\n",
      "Epoch 19940, Training-Loss 6.5900e+01, Data-loss 6.2906e+01                  , pde-loss 4.4887e+03, initc-loss 1.3379e+04                    bc_loss 7.3589e+04, Test-Loss 6.2906e+01\n",
      "Epoch 19950, Training-Loss 8.2619e+01, Data-loss 1.4139e+02                  , pde-loss 3.2388e+03, initc-loss 1.2518e+04                    bc_loss 1.2676e+05, Test-Loss 1.4139e+02\n",
      "Epoch 19960, Training-Loss 9.2631e+01, Data-loss 4.5555e+01                  , pde-loss 3.6886e+03, initc-loss 1.3226e+04                    bc_loss 9.8595e+04, Test-Loss 4.5555e+01\n",
      "Epoch 19970, Training-Loss 3.0644e+01, Data-loss 6.7268e+01                  , pde-loss 3.4176e+03, initc-loss 1.2821e+04                    bc_loss 7.9841e+04, Test-Loss 6.7268e+01\n",
      "Epoch 19980, Training-Loss 9.7833e+01, Data-loss 2.2839e+01                  , pde-loss 3.9625e+03, initc-loss 1.3006e+04                    bc_loss 3.7640e+04, Test-Loss 2.2839e+01\n",
      "Epoch 19990, Training-Loss 1.1892e+02, Data-loss 4.8126e+01                  , pde-loss 3.7016e+03, initc-loss 1.3527e+04                    bc_loss 7.6431e+04, Test-Loss 4.8126e+01\n",
      "Epoch 20000, Training-Loss 8.1420e+01, Data-loss 5.7246e+01                  , pde-loss 3.7975e+03, initc-loss 1.3051e+04                    bc_loss 8.2037e+04, Test-Loss 5.7246e+01\n",
      "Epoch 20010, Training-Loss 6.3435e+01, Data-loss 4.2880e+01                  , pde-loss 5.0113e+03, initc-loss 1.2990e+04                    bc_loss 6.7385e+04, Test-Loss 4.2880e+01\n",
      "Epoch 20020, Training-Loss 3.3887e+01, Data-loss 9.3844e+01                  , pde-loss 3.7673e+03, initc-loss 1.3509e+04                    bc_loss 3.0459e+04, Test-Loss 9.3844e+01\n",
      "Epoch 20030, Training-Loss 1.0784e+02, Data-loss 1.0504e+02                  , pde-loss 3.7573e+03, initc-loss 1.3083e+04                    bc_loss 6.5419e+04, Test-Loss 1.0504e+02\n",
      "Epoch 20040, Training-Loss 7.1415e+01, Data-loss 4.3018e+01                  , pde-loss 3.8554e+03, initc-loss 1.3326e+04                    bc_loss 9.4220e+04, Test-Loss 4.3018e+01\n",
      "Epoch 20050, Training-Loss 4.4590e+01, Data-loss 6.2931e+01                  , pde-loss 3.9779e+03, initc-loss 1.2979e+04                    bc_loss 5.6262e+04, Test-Loss 6.2931e+01\n",
      "Epoch 20060, Training-Loss 9.4314e+01, Data-loss 1.5312e+01                  , pde-loss 4.2340e+03, initc-loss 1.3249e+04                    bc_loss 5.3945e+04, Test-Loss 1.5312e+01\n",
      "Epoch 20070, Training-Loss 8.2656e+01, Data-loss 6.1626e+01                  , pde-loss 3.4050e+03, initc-loss 1.2992e+04                    bc_loss 1.0300e+05, Test-Loss 6.1626e+01\n",
      "Epoch 20080, Training-Loss 8.6435e+01, Data-loss 9.7321e+01                  , pde-loss 4.5592e+03, initc-loss 1.2796e+04                    bc_loss 6.7410e+04, Test-Loss 9.7321e+01\n",
      "Epoch 20090, Training-Loss 6.8890e+01, Data-loss 6.4533e+01                  , pde-loss 3.6917e+03, initc-loss 1.3114e+04                    bc_loss 4.9603e+04, Test-Loss 6.4533e+01\n",
      "Epoch 20100, Training-Loss 5.6308e+01, Data-loss 3.1982e+01                  , pde-loss 3.4125e+03, initc-loss 1.3409e+04                    bc_loss 5.5649e+04, Test-Loss 3.1982e+01\n",
      "Epoch 20110, Training-Loss 4.3233e+01, Data-loss 7.2217e+01                  , pde-loss 4.1655e+03, initc-loss 1.3166e+04                    bc_loss 4.0193e+04, Test-Loss 7.2217e+01\n",
      "Epoch 20120, Training-Loss 4.9869e+01, Data-loss 5.3746e+01                  , pde-loss 5.6657e+03, initc-loss 1.3167e+04                    bc_loss 6.9409e+04, Test-Loss 5.3746e+01\n",
      "Epoch 20130, Training-Loss 1.1640e+02, Data-loss 5.4903e+01                  , pde-loss 3.9237e+03, initc-loss 1.3055e+04                    bc_loss 7.0012e+04, Test-Loss 5.4903e+01\n",
      "Epoch 20140, Training-Loss 7.3085e+01, Data-loss 6.6595e+01                  , pde-loss 4.7472e+03, initc-loss 1.3461e+04                    bc_loss 4.9274e+04, Test-Loss 6.6595e+01\n",
      "Epoch 20150, Training-Loss 3.5601e+01, Data-loss 5.7977e+01                  , pde-loss 3.3929e+03, initc-loss 1.3428e+04                    bc_loss 5.6024e+04, Test-Loss 5.7977e+01\n",
      "Epoch 20160, Training-Loss 1.0682e+02, Data-loss 2.5542e+01                  , pde-loss 5.7051e+03, initc-loss 1.3403e+04                    bc_loss 3.9709e+04, Test-Loss 2.5542e+01\n",
      "Epoch 20170, Training-Loss 3.8743e+01, Data-loss 3.3936e+01                  , pde-loss 3.6751e+03, initc-loss 1.3429e+04                    bc_loss 4.0404e+04, Test-Loss 3.3936e+01\n",
      "Epoch 20180, Training-Loss 7.1566e+01, Data-loss 8.2028e+01                  , pde-loss 3.7728e+03, initc-loss 1.2957e+04                    bc_loss 4.4917e+04, Test-Loss 8.2028e+01\n",
      "Epoch 20190, Training-Loss 1.0695e+02, Data-loss 5.5546e+01                  , pde-loss 5.3497e+03, initc-loss 1.2910e+04                    bc_loss 5.6778e+04, Test-Loss 5.5546e+01\n",
      "Epoch 20200, Training-Loss 9.3863e+01, Data-loss 8.0958e+01                  , pde-loss 4.5636e+03, initc-loss 1.3076e+04                    bc_loss 4.6451e+04, Test-Loss 8.0958e+01\n",
      "Epoch 20210, Training-Loss 3.6771e+01, Data-loss 2.5589e+01                  , pde-loss 5.0422e+03, initc-loss 1.3473e+04                    bc_loss 3.2783e+04, Test-Loss 2.5589e+01\n",
      "Epoch 20220, Training-Loss 2.6805e+01, Data-loss 6.1437e+01                  , pde-loss 3.8604e+03, initc-loss 1.3510e+04                    bc_loss 3.0203e+04, Test-Loss 6.1437e+01\n",
      "Epoch 20230, Training-Loss 6.2969e+01, Data-loss 6.1932e+01                  , pde-loss 3.7680e+03, initc-loss 1.3574e+04                    bc_loss 3.5616e+04, Test-Loss 6.1932e+01\n",
      "Epoch 20240, Training-Loss 4.7735e+01, Data-loss 2.1872e+01                  , pde-loss 4.6288e+03, initc-loss 1.2912e+04                    bc_loss 1.4369e+05, Test-Loss 2.1872e+01\n",
      "Epoch 20250, Training-Loss 5.9716e+01, Data-loss 2.2736e+01                  , pde-loss 3.9947e+03, initc-loss 1.2523e+04                    bc_loss 1.4807e+05, Test-Loss 2.2736e+01\n",
      "Epoch 20260, Training-Loss 2.5977e+01, Data-loss 8.9576e+01                  , pde-loss 4.3818e+03, initc-loss 1.2870e+04                    bc_loss 9.1932e+04, Test-Loss 8.9576e+01\n",
      "Epoch 20270, Training-Loss 1.7647e+02, Data-loss 6.4777e+01                  , pde-loss 4.3540e+03, initc-loss 1.3273e+04                    bc_loss 3.5878e+04, Test-Loss 6.4777e+01\n",
      "Epoch 20280, Training-Loss 1.4572e+02, Data-loss 8.8663e+01                  , pde-loss 3.6068e+03, initc-loss 1.3530e+04                    bc_loss 3.4176e+04, Test-Loss 8.8663e+01\n",
      "Epoch 20290, Training-Loss 6.2987e+01, Data-loss 3.5521e+01                  , pde-loss 4.3419e+03, initc-loss 1.3332e+04                    bc_loss 4.2138e+04, Test-Loss 3.5521e+01\n",
      "Epoch 20300, Training-Loss 5.0033e+01, Data-loss 3.7587e+01                  , pde-loss 4.0787e+03, initc-loss 1.3012e+04                    bc_loss 6.8255e+04, Test-Loss 3.7587e+01\n",
      "Epoch 20310, Training-Loss 6.2434e+01, Data-loss 4.9151e+01                  , pde-loss 4.6846e+03, initc-loss 1.3249e+04                    bc_loss 4.6506e+04, Test-Loss 4.9151e+01\n",
      "Epoch 20320, Training-Loss 2.9075e+01, Data-loss 2.7110e+01                  , pde-loss 4.0738e+03, initc-loss 1.3077e+04                    bc_loss 4.4812e+04, Test-Loss 2.7110e+01\n",
      "Epoch 20330, Training-Loss 4.7421e+01, Data-loss 2.8192e+01                  , pde-loss 3.7160e+03, initc-loss 1.2693e+04                    bc_loss 8.7905e+04, Test-Loss 2.8192e+01\n",
      "Epoch 20340, Training-Loss 8.4485e+01, Data-loss 6.1111e+01                  , pde-loss 4.1337e+03, initc-loss 1.2759e+04                    bc_loss 6.1490e+04, Test-Loss 6.1111e+01\n",
      "Epoch 20350, Training-Loss 2.9309e+01, Data-loss 3.5336e+01                  , pde-loss 3.7538e+03, initc-loss 1.3039e+04                    bc_loss 6.7758e+04, Test-Loss 3.5336e+01\n",
      "Epoch 20360, Training-Loss 9.4592e+01, Data-loss 4.3552e+01                  , pde-loss 3.9497e+03, initc-loss 1.3355e+04                    bc_loss 3.3413e+04, Test-Loss 4.3552e+01\n",
      "Epoch 20370, Training-Loss 3.2145e+01, Data-loss 7.2411e+01                  , pde-loss 3.5377e+03, initc-loss 1.3340e+04                    bc_loss 4.0498e+04, Test-Loss 7.2411e+01\n",
      "Epoch 20380, Training-Loss 1.0377e+02, Data-loss 7.3705e+01                  , pde-loss 4.3404e+03, initc-loss 1.3344e+04                    bc_loss 4.0590e+04, Test-Loss 7.3705e+01\n",
      "Epoch 20390, Training-Loss 3.3835e+01, Data-loss 5.5561e+01                  , pde-loss 5.0176e+03, initc-loss 1.3270e+04                    bc_loss 4.3300e+04, Test-Loss 5.5561e+01\n",
      "Epoch 20400, Training-Loss 3.9872e+01, Data-loss 4.2001e+01                  , pde-loss 4.3315e+03, initc-loss 1.3063e+04                    bc_loss 7.3355e+04, Test-Loss 4.2001e+01\n",
      "Epoch 20410, Training-Loss 6.0345e+01, Data-loss 4.7671e+01                  , pde-loss 5.1966e+03, initc-loss 1.3176e+04                    bc_loss 4.6004e+04, Test-Loss 4.7671e+01\n",
      "Epoch 20420, Training-Loss 4.3033e+01, Data-loss 7.7985e+01                  , pde-loss 4.9825e+03, initc-loss 1.3046e+04                    bc_loss 4.4163e+04, Test-Loss 7.7985e+01\n",
      "Epoch 20430, Training-Loss 2.7908e+01, Data-loss 3.5657e+01                  , pde-loss 3.9110e+03, initc-loss 1.2841e+04                    bc_loss 5.6804e+04, Test-Loss 3.5657e+01\n",
      "Epoch 20440, Training-Loss 4.9222e+01, Data-loss 3.7670e+01                  , pde-loss 5.4738e+03, initc-loss 1.2963e+04                    bc_loss 6.5640e+04, Test-Loss 3.7670e+01\n",
      "Epoch 20450, Training-Loss 6.0216e+01, Data-loss 3.0490e+01                  , pde-loss 3.4382e+03, initc-loss 1.2844e+04                    bc_loss 5.6033e+04, Test-Loss 3.0490e+01\n",
      "Epoch 20460, Training-Loss 4.1997e+01, Data-loss 4.4461e+01                  , pde-loss 3.0775e+03, initc-loss 1.3521e+04                    bc_loss 6.6958e+04, Test-Loss 4.4461e+01\n",
      "Epoch 20470, Training-Loss 5.4133e+01, Data-loss 7.5159e+01                  , pde-loss 3.2492e+03, initc-loss 1.3022e+04                    bc_loss 3.4151e+04, Test-Loss 7.5159e+01\n",
      "Epoch 20480, Training-Loss 7.5353e+01, Data-loss 4.5985e+01                  , pde-loss 5.6074e+03, initc-loss 1.3229e+04                    bc_loss 5.5404e+04, Test-Loss 4.5985e+01\n",
      "Epoch 20490, Training-Loss 3.4731e+01, Data-loss 6.7765e+01                  , pde-loss 4.5046e+03, initc-loss 1.3114e+04                    bc_loss 6.4781e+04, Test-Loss 6.7765e+01\n",
      "Epoch 20500, Training-Loss 2.9030e+01, Data-loss 1.2919e+02                  , pde-loss 3.4688e+03, initc-loss 1.2913e+04                    bc_loss 5.6090e+04, Test-Loss 1.2919e+02\n",
      "Epoch 20510, Training-Loss 2.6606e+01, Data-loss 4.0816e+01                  , pde-loss 4.6412e+03, initc-loss 1.3034e+04                    bc_loss 4.4789e+04, Test-Loss 4.0816e+01\n",
      "Epoch 20520, Training-Loss 6.3784e+01, Data-loss 8.6037e+01                  , pde-loss 4.5387e+03, initc-loss 1.3126e+04                    bc_loss 5.2123e+04, Test-Loss 8.6037e+01\n",
      "Epoch 20530, Training-Loss 4.2481e+01, Data-loss 5.7320e+01                  , pde-loss 3.7244e+03, initc-loss 1.3057e+04                    bc_loss 3.3665e+04, Test-Loss 5.7320e+01\n",
      "Epoch 20540, Training-Loss 5.2634e+01, Data-loss 1.4506e+02                  , pde-loss 4.2306e+03, initc-loss 1.3339e+04                    bc_loss 3.1173e+04, Test-Loss 1.4506e+02\n",
      "Epoch 20550, Training-Loss 1.8967e+01, Data-loss 2.7363e+01                  , pde-loss 4.5473e+03, initc-loss 1.3356e+04                    bc_loss 4.0826e+04, Test-Loss 2.7363e+01\n",
      "Epoch 20560, Training-Loss 2.6409e+01, Data-loss 9.2470e+00                  , pde-loss 5.0651e+03, initc-loss 1.2926e+04                    bc_loss 4.6521e+04, Test-Loss 9.2470e+00\n",
      "Epoch 20570, Training-Loss 5.1970e+01, Data-loss 2.6815e+01                  , pde-loss 4.9960e+03, initc-loss 1.2897e+04                    bc_loss 5.4799e+04, Test-Loss 2.6815e+01\n",
      "Epoch 20580, Training-Loss 7.5908e+01, Data-loss 2.4442e+01                  , pde-loss 4.8067e+03, initc-loss 1.2691e+04                    bc_loss 5.7804e+04, Test-Loss 2.4442e+01\n",
      "Epoch 20590, Training-Loss 3.5783e+01, Data-loss 3.9077e+01                  , pde-loss 3.9368e+03, initc-loss 1.3085e+04                    bc_loss 4.7564e+04, Test-Loss 3.9077e+01\n",
      "Epoch 20600, Training-Loss 4.9634e+01, Data-loss 3.3888e+01                  , pde-loss 4.5707e+03, initc-loss 1.2661e+04                    bc_loss 9.2151e+04, Test-Loss 3.3888e+01\n",
      "Epoch 20610, Training-Loss 5.4740e+01, Data-loss 2.1869e+01                  , pde-loss 5.3621e+03, initc-loss 1.3265e+04                    bc_loss 5.5962e+04, Test-Loss 2.1869e+01\n",
      "Epoch 20620, Training-Loss 1.5678e+01, Data-loss 6.6847e+01                  , pde-loss 4.5061e+03, initc-loss 1.3189e+04                    bc_loss 2.4028e+04, Test-Loss 6.6847e+01\n",
      "Epoch 20630, Training-Loss 5.9191e+01, Data-loss 1.8776e+01                  , pde-loss 4.6590e+03, initc-loss 1.3013e+04                    bc_loss 3.0216e+04, Test-Loss 1.8776e+01\n",
      "Epoch 20640, Training-Loss 4.7331e+01, Data-loss 3.3497e+01                  , pde-loss 3.9360e+03, initc-loss 1.3151e+04                    bc_loss 5.3269e+04, Test-Loss 3.3497e+01\n",
      "Epoch 20650, Training-Loss 6.4957e+01, Data-loss 3.3391e+01                  , pde-loss 4.3454e+03, initc-loss 1.3271e+04                    bc_loss 3.1720e+04, Test-Loss 3.3391e+01\n",
      "Epoch 20660, Training-Loss 7.3718e+01, Data-loss 7.2517e+01                  , pde-loss 5.0769e+03, initc-loss 1.3182e+04                    bc_loss 2.7046e+04, Test-Loss 7.2517e+01\n",
      "Epoch 20670, Training-Loss 2.5542e+01, Data-loss 2.5293e+01                  , pde-loss 5.5990e+03, initc-loss 1.3225e+04                    bc_loss 2.8841e+04, Test-Loss 2.5293e+01\n",
      "Epoch 20680, Training-Loss 4.2604e+01, Data-loss 4.4022e+01                  , pde-loss 5.6609e+03, initc-loss 1.2984e+04                    bc_loss 4.0267e+04, Test-Loss 4.4022e+01\n",
      "Epoch 20690, Training-Loss 2.5788e+01, Data-loss 4.3256e+01                  , pde-loss 4.8372e+03, initc-loss 1.2984e+04                    bc_loss 3.0282e+04, Test-Loss 4.3256e+01\n",
      "Epoch 20700, Training-Loss 4.5086e+01, Data-loss 1.7010e+01                  , pde-loss 4.2328e+03, initc-loss 1.3153e+04                    bc_loss 3.1451e+04, Test-Loss 1.7010e+01\n",
      "Epoch 20710, Training-Loss 2.6185e+01, Data-loss 4.9757e+01                  , pde-loss 3.4111e+03, initc-loss 1.3031e+04                    bc_loss 3.3580e+04, Test-Loss 4.9757e+01\n",
      "Epoch 20720, Training-Loss 4.5256e+01, Data-loss 3.5382e+01                  , pde-loss 5.4034e+03, initc-loss 1.2836e+04                    bc_loss 4.3952e+04, Test-Loss 3.5382e+01\n",
      "Epoch 20730, Training-Loss 3.1126e+01, Data-loss 4.1806e+01                  , pde-loss 4.5484e+03, initc-loss 1.2993e+04                    bc_loss 6.9963e+04, Test-Loss 4.1806e+01\n",
      "Epoch 20740, Training-Loss 1.9770e+01, Data-loss 6.2278e+01                  , pde-loss 4.9896e+03, initc-loss 1.2759e+04                    bc_loss 3.6647e+04, Test-Loss 6.2278e+01\n",
      "Epoch 20750, Training-Loss 4.2332e+01, Data-loss 5.2735e+01                  , pde-loss 4.3345e+03, initc-loss 1.2955e+04                    bc_loss 6.3267e+04, Test-Loss 5.2735e+01\n",
      "Epoch 20760, Training-Loss 3.5980e+01, Data-loss 5.1898e+01                  , pde-loss 4.0163e+03, initc-loss 1.2714e+04                    bc_loss 7.8112e+04, Test-Loss 5.1898e+01\n",
      "Epoch 20770, Training-Loss 4.8470e+01, Data-loss 3.0657e+01                  , pde-loss 3.9168e+03, initc-loss 1.3005e+04                    bc_loss 7.3992e+04, Test-Loss 3.0657e+01\n",
      "Epoch 20780, Training-Loss 4.0711e+01, Data-loss 9.5849e+00                  , pde-loss 4.8273e+03, initc-loss 1.2924e+04                    bc_loss 3.0066e+04, Test-Loss 9.5849e+00\n",
      "Epoch 20790, Training-Loss 7.9729e+01, Data-loss 3.5503e+01                  , pde-loss 3.8265e+03, initc-loss 1.2866e+04                    bc_loss 2.9898e+04, Test-Loss 3.5503e+01\n",
      "Epoch 20800, Training-Loss 5.4526e+01, Data-loss 2.4848e+01                  , pde-loss 2.9175e+03, initc-loss 1.3038e+04                    bc_loss 3.5415e+04, Test-Loss 2.4848e+01\n",
      "Epoch 20810, Training-Loss 3.4991e+01, Data-loss 1.6601e+01                  , pde-loss 4.0418e+03, initc-loss 1.3210e+04                    bc_loss 2.7881e+04, Test-Loss 1.6601e+01\n",
      "Epoch 20820, Training-Loss 4.0896e+01, Data-loss 6.3627e+01                  , pde-loss 4.4380e+03, initc-loss 1.3371e+04                    bc_loss 2.1332e+04, Test-Loss 6.3627e+01\n",
      "Epoch 20830, Training-Loss 2.4278e+01, Data-loss 2.7566e+01                  , pde-loss 3.5614e+03, initc-loss 1.3344e+04                    bc_loss 2.3968e+04, Test-Loss 2.7566e+01\n",
      "Epoch 20840, Training-Loss 3.5304e+01, Data-loss 5.4803e+01                  , pde-loss 4.3346e+03, initc-loss 1.3305e+04                    bc_loss 2.5122e+04, Test-Loss 5.4803e+01\n",
      "Epoch 20850, Training-Loss 2.7846e+01, Data-loss 7.8856e+01                  , pde-loss 4.7835e+03, initc-loss 1.3231e+04                    bc_loss 3.9942e+04, Test-Loss 7.8856e+01\n",
      "Epoch 20860, Training-Loss 4.0459e+01, Data-loss 2.3295e+01                  , pde-loss 4.1971e+03, initc-loss 1.2960e+04                    bc_loss 4.6805e+04, Test-Loss 2.3295e+01\n",
      "Epoch 20870, Training-Loss 3.3906e+01, Data-loss 4.8519e+01                  , pde-loss 5.2920e+03, initc-loss 1.2842e+04                    bc_loss 3.4898e+04, Test-Loss 4.8519e+01\n",
      "Epoch 20880, Training-Loss 9.9893e+01, Data-loss 2.3117e+01                  , pde-loss 3.9410e+03, initc-loss 1.3208e+04                    bc_loss 2.3026e+04, Test-Loss 2.3117e+01\n",
      "Epoch 20890, Training-Loss 3.9542e+01, Data-loss 3.6177e+01                  , pde-loss 7.0269e+03, initc-loss 1.3185e+04                    bc_loss 2.7274e+04, Test-Loss 3.6177e+01\n",
      "Epoch 20900, Training-Loss 3.6013e+01, Data-loss 2.1332e+01                  , pde-loss 5.1299e+03, initc-loss 1.3139e+04                    bc_loss 2.5229e+04, Test-Loss 2.1332e+01\n",
      "Epoch 20910, Training-Loss 3.0099e+01, Data-loss 1.8808e+01                  , pde-loss 5.0746e+03, initc-loss 1.2848e+04                    bc_loss 3.3248e+04, Test-Loss 1.8808e+01\n",
      "Epoch 20920, Training-Loss 8.1303e+01, Data-loss 2.0840e+01                  , pde-loss 5.1663e+03, initc-loss 1.2991e+04                    bc_loss 5.7165e+04, Test-Loss 2.0840e+01\n",
      "Epoch 20930, Training-Loss 8.5815e+01, Data-loss 3.1038e+01                  , pde-loss 4.1889e+03, initc-loss 1.2996e+04                    bc_loss 3.3095e+04, Test-Loss 3.1038e+01\n",
      "Epoch 20940, Training-Loss 3.1785e+01, Data-loss 2.5805e+01                  , pde-loss 4.9122e+03, initc-loss 1.2954e+04                    bc_loss 2.3904e+04, Test-Loss 2.5805e+01\n",
      "Epoch 20950, Training-Loss 3.1142e+01, Data-loss 2.6851e+01                  , pde-loss 6.0546e+03, initc-loss 1.3108e+04                    bc_loss 2.4016e+04, Test-Loss 2.6851e+01\n",
      "Epoch 20960, Training-Loss 2.9317e+01, Data-loss 2.6783e+01                  , pde-loss 3.5106e+03, initc-loss 1.3337e+04                    bc_loss 2.2055e+04, Test-Loss 2.6783e+01\n",
      "Epoch 20970, Training-Loss 3.0069e+01, Data-loss 1.2848e+01                  , pde-loss 5.2465e+03, initc-loss 1.2849e+04                    bc_loss 3.3896e+04, Test-Loss 1.2848e+01\n",
      "Epoch 20980, Training-Loss 3.6434e+01, Data-loss 2.6924e+01                  , pde-loss 3.7058e+03, initc-loss 1.3269e+04                    bc_loss 5.6761e+04, Test-Loss 2.6924e+01\n",
      "Epoch 20990, Training-Loss 1.9898e+01, Data-loss 1.1240e+01                  , pde-loss 4.0019e+03, initc-loss 1.2970e+04                    bc_loss 3.4495e+04, Test-Loss 1.1240e+01\n",
      "Epoch 21000, Training-Loss 3.7144e+01, Data-loss 1.9342e+01                  , pde-loss 4.3187e+03, initc-loss 1.2939e+04                    bc_loss 3.1150e+04, Test-Loss 1.9342e+01\n",
      "Epoch 21010, Training-Loss 2.4682e+01, Data-loss 2.8325e+01                  , pde-loss 6.3108e+03, initc-loss 1.3167e+04                    bc_loss 2.7787e+04, Test-Loss 2.8325e+01\n",
      "Epoch 21020, Training-Loss 5.9724e+01, Data-loss 2.4310e+01                  , pde-loss 4.4648e+03, initc-loss 1.2653e+04                    bc_loss 5.9364e+04, Test-Loss 2.4310e+01\n",
      "Epoch 21030, Training-Loss 5.9704e+01, Data-loss 3.2398e+01                  , pde-loss 6.5325e+03, initc-loss 1.2771e+04                    bc_loss 9.0627e+04, Test-Loss 3.2398e+01\n",
      "Epoch 21040, Training-Loss 3.2182e+01, Data-loss 3.9238e+01                  , pde-loss 5.0733e+03, initc-loss 1.2598e+04                    bc_loss 7.8591e+04, Test-Loss 3.9238e+01\n",
      "Epoch 21050, Training-Loss 4.5058e+01, Data-loss 2.7317e+01                  , pde-loss 4.1882e+03, initc-loss 1.2728e+04                    bc_loss 5.8901e+04, Test-Loss 2.7317e+01\n",
      "Epoch 21060, Training-Loss 4.2673e+01, Data-loss 3.9042e+01                  , pde-loss 5.3107e+03, initc-loss 1.2855e+04                    bc_loss 3.6592e+04, Test-Loss 3.9042e+01\n",
      "Epoch 21070, Training-Loss 3.1545e+01, Data-loss 3.5787e+01                  , pde-loss 5.2533e+03, initc-loss 1.3154e+04                    bc_loss 2.2622e+04, Test-Loss 3.5787e+01\n",
      "Epoch 21080, Training-Loss 3.1908e+01, Data-loss 2.1662e+01                  , pde-loss 4.4177e+03, initc-loss 1.2867e+04                    bc_loss 2.2655e+04, Test-Loss 2.1662e+01\n",
      "Epoch 21090, Training-Loss 3.3581e+01, Data-loss 3.1784e+01                  , pde-loss 4.7721e+03, initc-loss 1.3055e+04                    bc_loss 2.4790e+04, Test-Loss 3.1784e+01\n",
      "Epoch 21100, Training-Loss 2.2219e+01, Data-loss 2.2961e+01                  , pde-loss 4.1464e+03, initc-loss 1.3035e+04                    bc_loss 2.6306e+04, Test-Loss 2.2961e+01\n",
      "Epoch 21110, Training-Loss 6.7327e+01, Data-loss 1.9723e+01                  , pde-loss 5.5407e+03, initc-loss 1.2928e+04                    bc_loss 2.4973e+04, Test-Loss 1.9723e+01\n",
      "Epoch 21120, Training-Loss 2.3384e+01, Data-loss 1.6170e+01                  , pde-loss 4.4811e+03, initc-loss 1.3225e+04                    bc_loss 2.2736e+04, Test-Loss 1.6170e+01\n",
      "Epoch 21130, Training-Loss 1.6120e+01, Data-loss 4.7490e+01                  , pde-loss 5.3391e+03, initc-loss 1.3110e+04                    bc_loss 2.1039e+04, Test-Loss 4.7490e+01\n",
      "Epoch 21140, Training-Loss 2.9707e+01, Data-loss 3.3450e+01                  , pde-loss 4.7932e+03, initc-loss 1.3197e+04                    bc_loss 1.9079e+04, Test-Loss 3.3450e+01\n",
      "Epoch 21150, Training-Loss 2.6087e+01, Data-loss 2.0413e+01                  , pde-loss 7.2852e+03, initc-loss 1.3163e+04                    bc_loss 2.3730e+04, Test-Loss 2.0413e+01\n",
      "Epoch 21160, Training-Loss 2.6940e+01, Data-loss 1.7316e+01                  , pde-loss 4.4839e+03, initc-loss 1.3172e+04                    bc_loss 3.7935e+04, Test-Loss 1.7316e+01\n",
      "Epoch 21170, Training-Loss 1.7725e+01, Data-loss 3.1086e+01                  , pde-loss 5.6935e+03, initc-loss 1.3058e+04                    bc_loss 1.9183e+04, Test-Loss 3.1086e+01\n",
      "Epoch 21180, Training-Loss 1.7510e+01, Data-loss 1.9349e+01                  , pde-loss 5.5257e+03, initc-loss 1.2979e+04                    bc_loss 2.7813e+04, Test-Loss 1.9349e+01\n",
      "Epoch 21190, Training-Loss 2.3927e+01, Data-loss 1.3317e+01                  , pde-loss 4.9853e+03, initc-loss 1.3058e+04                    bc_loss 2.7282e+04, Test-Loss 1.3317e+01\n",
      "Epoch 21200, Training-Loss 3.1846e+01, Data-loss 2.1956e+01                  , pde-loss 5.5686e+03, initc-loss 1.2840e+04                    bc_loss 1.7993e+04, Test-Loss 2.1956e+01\n",
      "Epoch 21210, Training-Loss 1.6598e+01, Data-loss 2.4261e+01                  , pde-loss 3.8302e+03, initc-loss 1.3003e+04                    bc_loss 2.1982e+04, Test-Loss 2.4261e+01\n",
      "Epoch 21220, Training-Loss 2.5660e+01, Data-loss 1.3719e+01                  , pde-loss 4.6084e+03, initc-loss 1.3214e+04                    bc_loss 1.7656e+04, Test-Loss 1.3719e+01\n",
      "Epoch 21230, Training-Loss 3.0124e+01, Data-loss 8.2116e+00                  , pde-loss 6.3545e+03, initc-loss 1.3101e+04                    bc_loss 2.3220e+04, Test-Loss 8.2116e+00\n",
      "Epoch 21240, Training-Loss 1.7105e+01, Data-loss 1.6070e+01                  , pde-loss 5.3684e+03, initc-loss 1.3216e+04                    bc_loss 2.1443e+04, Test-Loss 1.6070e+01\n",
      "Epoch 21250, Training-Loss 2.8153e+01, Data-loss 3.0470e+01                  , pde-loss 5.6427e+03, initc-loss 1.3089e+04                    bc_loss 1.6773e+04, Test-Loss 3.0470e+01\n",
      "Epoch 21260, Training-Loss 4.3870e+01, Data-loss 2.1726e+01                  , pde-loss 4.8936e+03, initc-loss 1.2912e+04                    bc_loss 2.2421e+04, Test-Loss 2.1726e+01\n",
      "Epoch 21270, Training-Loss 3.6494e+01, Data-loss 3.4367e+01                  , pde-loss 4.9013e+03, initc-loss 1.3300e+04                    bc_loss 2.3683e+04, Test-Loss 3.4367e+01\n",
      "Epoch 21280, Training-Loss 5.6660e+01, Data-loss 1.5017e+01                  , pde-loss 5.3666e+03, initc-loss 1.3038e+04                    bc_loss 1.6365e+04, Test-Loss 1.5017e+01\n",
      "Epoch 21290, Training-Loss 1.6117e+01, Data-loss 3.3750e+01                  , pde-loss 4.4698e+03, initc-loss 1.3064e+04                    bc_loss 1.7544e+04, Test-Loss 3.3750e+01\n",
      "Epoch 21300, Training-Loss 2.1206e+01, Data-loss 1.2215e+01                  , pde-loss 4.3142e+03, initc-loss 1.3132e+04                    bc_loss 1.6239e+04, Test-Loss 1.2215e+01\n",
      "Epoch 21310, Training-Loss 1.2969e+01, Data-loss 1.6824e+01                  , pde-loss 4.1114e+03, initc-loss 1.2881e+04                    bc_loss 2.5573e+04, Test-Loss 1.6824e+01\n",
      "Epoch 21320, Training-Loss 3.4949e+01, Data-loss 2.5118e+01                  , pde-loss 3.7196e+03, initc-loss 1.2895e+04                    bc_loss 2.2063e+04, Test-Loss 2.5118e+01\n",
      "Epoch 21330, Training-Loss 3.2026e+01, Data-loss 2.9527e+01                  , pde-loss 6.0358e+03, initc-loss 1.2978e+04                    bc_loss 1.5965e+04, Test-Loss 2.9527e+01\n",
      "Epoch 21340, Training-Loss 4.7880e+01, Data-loss 2.6749e+01                  , pde-loss 4.9989e+03, initc-loss 1.2945e+04                    bc_loss 2.6240e+04, Test-Loss 2.6749e+01\n",
      "Epoch 21350, Training-Loss 2.5087e+01, Data-loss 4.8419e+01                  , pde-loss 5.7938e+03, initc-loss 1.2724e+04                    bc_loss 3.8295e+04, Test-Loss 4.8419e+01\n",
      "Epoch 21360, Training-Loss 2.2904e+01, Data-loss 1.6278e+01                  , pde-loss 6.1473e+03, initc-loss 1.2683e+04                    bc_loss 3.1948e+04, Test-Loss 1.6278e+01\n",
      "Epoch 21370, Training-Loss 2.4273e+01, Data-loss 3.7647e+01                  , pde-loss 4.7611e+03, initc-loss 1.2757e+04                    bc_loss 4.3318e+04, Test-Loss 3.7647e+01\n",
      "Epoch 21380, Training-Loss 1.3634e+01, Data-loss 1.3215e+01                  , pde-loss 5.2806e+03, initc-loss 1.3088e+04                    bc_loss 1.6689e+04, Test-Loss 1.3215e+01\n",
      "Epoch 21390, Training-Loss 5.4799e+01, Data-loss 2.5645e+01                  , pde-loss 5.7002e+03, initc-loss 1.2894e+04                    bc_loss 2.2404e+04, Test-Loss 2.5645e+01\n",
      "Epoch 21400, Training-Loss 2.9372e+01, Data-loss 3.3774e+01                  , pde-loss 7.1912e+03, initc-loss 1.3081e+04                    bc_loss 2.0202e+04, Test-Loss 3.3774e+01\n",
      "Epoch 21410, Training-Loss 2.2941e+01, Data-loss 1.2051e+01                  , pde-loss 4.6854e+03, initc-loss 1.2964e+04                    bc_loss 1.2934e+04, Test-Loss 1.2051e+01\n",
      "Epoch 21420, Training-Loss 2.6629e+01, Data-loss 2.1257e+01                  , pde-loss 5.9536e+03, initc-loss 1.3027e+04                    bc_loss 1.9187e+04, Test-Loss 2.1257e+01\n",
      "Epoch 21430, Training-Loss 1.7395e+01, Data-loss 3.0562e+01                  , pde-loss 5.0305e+03, initc-loss 1.3113e+04                    bc_loss 1.3717e+04, Test-Loss 3.0562e+01\n",
      "Epoch 21440, Training-Loss 1.6437e+01, Data-loss 1.6265e+01                  , pde-loss 5.2768e+03, initc-loss 1.3111e+04                    bc_loss 1.5674e+04, Test-Loss 1.6265e+01\n",
      "Epoch 21450, Training-Loss 2.7562e+01, Data-loss 3.4693e+01                  , pde-loss 6.8307e+03, initc-loss 1.2879e+04                    bc_loss 1.4847e+04, Test-Loss 3.4693e+01\n",
      "Epoch 21460, Training-Loss 1.6593e+01, Data-loss 2.0864e+01                  , pde-loss 5.4443e+03, initc-loss 1.3073e+04                    bc_loss 1.4628e+04, Test-Loss 2.0864e+01\n",
      "Epoch 21470, Training-Loss 1.4555e+01, Data-loss 6.8015e+00                  , pde-loss 5.0674e+03, initc-loss 1.3257e+04                    bc_loss 1.6463e+04, Test-Loss 6.8015e+00\n",
      "Epoch 21480, Training-Loss 1.4088e+01, Data-loss 1.9712e+01                  , pde-loss 6.5520e+03, initc-loss 1.3264e+04                    bc_loss 1.9018e+04, Test-Loss 1.9712e+01\n",
      "Epoch 21490, Training-Loss 9.3067e+00, Data-loss 1.6972e+01                  , pde-loss 4.7394e+03, initc-loss 1.3220e+04                    bc_loss 1.3009e+04, Test-Loss 1.6972e+01\n",
      "Epoch 21500, Training-Loss 2.2964e+01, Data-loss 1.5289e+01                  , pde-loss 5.4805e+03, initc-loss 1.2837e+04                    bc_loss 1.4439e+04, Test-Loss 1.5289e+01\n",
      "Epoch 21510, Training-Loss 2.1257e+01, Data-loss 2.0417e+01                  , pde-loss 3.9690e+03, initc-loss 1.2901e+04                    bc_loss 3.4263e+04, Test-Loss 2.0417e+01\n",
      "Epoch 21520, Training-Loss 1.7456e+01, Data-loss 2.8580e+01                  , pde-loss 5.1563e+03, initc-loss 1.2706e+04                    bc_loss 3.7419e+04, Test-Loss 2.8580e+01\n",
      "Epoch 21530, Training-Loss 4.9549e+01, Data-loss 1.9175e+01                  , pde-loss 4.7252e+03, initc-loss 1.3053e+04                    bc_loss 2.5699e+04, Test-Loss 1.9175e+01\n",
      "Epoch 21540, Training-Loss 3.1507e+01, Data-loss 1.3247e+01                  , pde-loss 7.7110e+03, initc-loss 1.3097e+04                    bc_loss 1.7589e+04, Test-Loss 1.3247e+01\n",
      "Epoch 21550, Training-Loss 3.8516e+01, Data-loss 1.7535e+01                  , pde-loss 4.7231e+03, initc-loss 1.3191e+04                    bc_loss 1.1830e+04, Test-Loss 1.7535e+01\n",
      "Epoch 21560, Training-Loss 2.5936e+01, Data-loss 1.4702e+01                  , pde-loss 4.8919e+03, initc-loss 1.3263e+04                    bc_loss 2.5828e+04, Test-Loss 1.4702e+01\n",
      "Epoch 21570, Training-Loss 1.9792e+01, Data-loss 1.7553e+01                  , pde-loss 5.8638e+03, initc-loss 1.3279e+04                    bc_loss 1.8070e+04, Test-Loss 1.7553e+01\n",
      "Epoch 21580, Training-Loss 2.3432e+01, Data-loss 3.0777e+01                  , pde-loss 4.7548e+03, initc-loss 1.3137e+04                    bc_loss 1.3566e+04, Test-Loss 3.0777e+01\n",
      "Epoch 21590, Training-Loss 4.3379e+01, Data-loss 1.8856e+01                  , pde-loss 4.6832e+03, initc-loss 1.3152e+04                    bc_loss 1.4027e+04, Test-Loss 1.8856e+01\n",
      "Epoch 21600, Training-Loss 2.7852e+01, Data-loss 1.8836e+01                  , pde-loss 5.0261e+03, initc-loss 1.2963e+04                    bc_loss 1.8561e+04, Test-Loss 1.8836e+01\n",
      "Epoch 21610, Training-Loss 1.6888e+01, Data-loss 2.1029e+01                  , pde-loss 5.7769e+03, initc-loss 1.2787e+04                    bc_loss 1.6773e+04, Test-Loss 2.1029e+01\n",
      "Epoch 21620, Training-Loss 1.7492e+01, Data-loss 3.9018e+01                  , pde-loss 5.5150e+03, initc-loss 1.2891e+04                    bc_loss 2.0335e+04, Test-Loss 3.9018e+01\n",
      "Epoch 21630, Training-Loss 2.4862e+01, Data-loss 9.9938e+00                  , pde-loss 3.6696e+03, initc-loss 1.2837e+04                    bc_loss 1.7555e+04, Test-Loss 9.9938e+00\n",
      "Epoch 21640, Training-Loss 1.4414e+01, Data-loss 1.7953e+01                  , pde-loss 5.8797e+03, initc-loss 1.2758e+04                    bc_loss 3.0117e+04, Test-Loss 1.7953e+01\n",
      "Epoch 21650, Training-Loss 2.5139e+01, Data-loss 2.6341e+01                  , pde-loss 4.7593e+03, initc-loss 1.2731e+04                    bc_loss 2.3659e+04, Test-Loss 2.6341e+01\n",
      "Epoch 21660, Training-Loss 2.4879e+01, Data-loss 1.7411e+01                  , pde-loss 4.6012e+03, initc-loss 1.2912e+04                    bc_loss 1.7654e+04, Test-Loss 1.7411e+01\n",
      "Epoch 21670, Training-Loss 3.2553e+01, Data-loss 4.8344e+00                  , pde-loss 3.8223e+03, initc-loss 1.3043e+04                    bc_loss 2.4342e+04, Test-Loss 4.8344e+00\n",
      "Epoch 21680, Training-Loss 1.2016e+01, Data-loss 1.7285e+01                  , pde-loss 7.9038e+03, initc-loss 1.2748e+04                    bc_loss 1.5868e+04, Test-Loss 1.7285e+01\n",
      "Epoch 21690, Training-Loss 2.1671e+01, Data-loss 1.0321e+01                  , pde-loss 4.5451e+03, initc-loss 1.3037e+04                    bc_loss 1.4310e+04, Test-Loss 1.0321e+01\n",
      "Epoch 21700, Training-Loss 1.4728e+01, Data-loss 8.7119e+00                  , pde-loss 5.2235e+03, initc-loss 1.2924e+04                    bc_loss 1.4364e+04, Test-Loss 8.7119e+00\n",
      "Epoch 21710, Training-Loss 1.5542e+01, Data-loss 1.3288e+01                  , pde-loss 4.5233e+03, initc-loss 1.3037e+04                    bc_loss 1.0526e+04, Test-Loss 1.3288e+01\n",
      "Epoch 21720, Training-Loss 1.6291e+01, Data-loss 1.8299e+01                  , pde-loss 5.4899e+03, initc-loss 1.3092e+04                    bc_loss 1.2071e+04, Test-Loss 1.8299e+01\n",
      "Epoch 21730, Training-Loss 1.3582e+01, Data-loss 1.9985e+01                  , pde-loss 4.7807e+03, initc-loss 1.3010e+04                    bc_loss 9.2904e+03, Test-Loss 1.9985e+01\n",
      "Epoch 21740, Training-Loss 1.3653e+01, Data-loss 1.3149e+01                  , pde-loss 4.0565e+03, initc-loss 1.3108e+04                    bc_loss 1.0191e+04, Test-Loss 1.3149e+01\n",
      "Epoch 21750, Training-Loss 2.4205e+01, Data-loss 1.1191e+01                  , pde-loss 5.1029e+03, initc-loss 1.2908e+04                    bc_loss 2.7865e+04, Test-Loss 1.1191e+01\n",
      "Epoch 21760, Training-Loss 4.2712e+01, Data-loss 2.3427e+01                  , pde-loss 6.2608e+03, initc-loss 1.2811e+04                    bc_loss 2.1824e+04, Test-Loss 2.3427e+01\n",
      "Epoch 21770, Training-Loss 1.4384e+01, Data-loss 1.0855e+01                  , pde-loss 5.9587e+03, initc-loss 1.2824e+04                    bc_loss 2.6020e+04, Test-Loss 1.0855e+01\n",
      "Epoch 21780, Training-Loss 1.6082e+01, Data-loss 3.8929e+01                  , pde-loss 4.8742e+03, initc-loss 1.2911e+04                    bc_loss 1.3758e+04, Test-Loss 3.8929e+01\n",
      "Epoch 21790, Training-Loss 2.4388e+01, Data-loss 1.7360e+01                  , pde-loss 5.0117e+03, initc-loss 1.3016e+04                    bc_loss 1.3131e+04, Test-Loss 1.7360e+01\n",
      "Epoch 21800, Training-Loss 2.8395e+01, Data-loss 1.6704e+01                  , pde-loss 5.4285e+03, initc-loss 1.3131e+04                    bc_loss 1.7134e+04, Test-Loss 1.6704e+01\n",
      "Epoch 21810, Training-Loss 1.6561e+01, Data-loss 5.9367e+00                  , pde-loss 3.1060e+03, initc-loss 1.2952e+04                    bc_loss 1.2429e+04, Test-Loss 5.9367e+00\n",
      "Epoch 21820, Training-Loss 2.0597e+01, Data-loss 2.2273e+01                  , pde-loss 5.0372e+03, initc-loss 1.2969e+04                    bc_loss 2.4916e+04, Test-Loss 2.2273e+01\n",
      "Epoch 21830, Training-Loss 3.0048e+01, Data-loss 3.9482e+01                  , pde-loss 4.3200e+03, initc-loss 1.2940e+04                    bc_loss 1.8350e+04, Test-Loss 3.9482e+01\n",
      "Epoch 21840, Training-Loss 1.1108e+01, Data-loss 1.8748e+01                  , pde-loss 4.9992e+03, initc-loss 1.2749e+04                    bc_loss 1.1673e+04, Test-Loss 1.8748e+01\n",
      "Epoch 21850, Training-Loss 3.5086e+01, Data-loss 1.0826e+01                  , pde-loss 4.0626e+03, initc-loss 1.2809e+04                    bc_loss 1.7089e+04, Test-Loss 1.0826e+01\n",
      "Epoch 21860, Training-Loss 1.3382e+01, Data-loss 2.0602e+01                  , pde-loss 7.6848e+03, initc-loss 1.3292e+04                    bc_loss 1.2176e+04, Test-Loss 2.0602e+01\n",
      "Epoch 21870, Training-Loss 1.3978e+01, Data-loss 2.0825e+01                  , pde-loss 6.3732e+03, initc-loss 1.3285e+04                    bc_loss 1.9504e+04, Test-Loss 2.0825e+01\n",
      "Epoch 21880, Training-Loss 2.4212e+01, Data-loss 1.4941e+01                  , pde-loss 5.8434e+03, initc-loss 1.3152e+04                    bc_loss 1.1937e+04, Test-Loss 1.4941e+01\n",
      "Epoch 21890, Training-Loss 1.8386e+01, Data-loss 1.9038e+01                  , pde-loss 5.4181e+03, initc-loss 1.3046e+04                    bc_loss 1.4678e+04, Test-Loss 1.9038e+01\n",
      "Epoch 21900, Training-Loss 3.8488e+01, Data-loss 1.1736e+01                  , pde-loss 5.8272e+03, initc-loss 1.2770e+04                    bc_loss 1.8512e+04, Test-Loss 1.1736e+01\n",
      "Epoch 21910, Training-Loss 2.8679e+01, Data-loss 2.4819e+01                  , pde-loss 5.8684e+03, initc-loss 1.2864e+04                    bc_loss 1.6859e+04, Test-Loss 2.4819e+01\n",
      "Epoch 21920, Training-Loss 2.0545e+01, Data-loss 2.0390e+01                  , pde-loss 4.1297e+03, initc-loss 1.2972e+04                    bc_loss 1.6833e+04, Test-Loss 2.0390e+01\n",
      "Epoch 21930, Training-Loss 2.7863e+01, Data-loss 1.2794e+01                  , pde-loss 7.1268e+03, initc-loss 1.3141e+04                    bc_loss 1.6632e+04, Test-Loss 1.2794e+01\n",
      "Epoch 21940, Training-Loss 1.5054e+01, Data-loss 2.8297e+01                  , pde-loss 6.1429e+03, initc-loss 1.3103e+04                    bc_loss 1.1142e+04, Test-Loss 2.8297e+01\n",
      "Epoch 21950, Training-Loss 1.6682e+01, Data-loss 3.0413e+01                  , pde-loss 5.1012e+03, initc-loss 1.2991e+04                    bc_loss 9.3103e+03, Test-Loss 3.0413e+01\n",
      "Epoch 21960, Training-Loss 1.1523e+01, Data-loss 1.1420e+01                  , pde-loss 6.4149e+03, initc-loss 1.2964e+04                    bc_loss 1.4216e+04, Test-Loss 1.1420e+01\n",
      "Epoch 21970, Training-Loss 1.9646e+01, Data-loss 9.6722e+00                  , pde-loss 4.0868e+03, initc-loss 1.2766e+04                    bc_loss 1.0584e+04, Test-Loss 9.6722e+00\n",
      "Epoch 21980, Training-Loss 1.7064e+01, Data-loss 9.4419e+00                  , pde-loss 4.5686e+03, initc-loss 1.2879e+04                    bc_loss 1.4427e+04, Test-Loss 9.4419e+00\n",
      "Epoch 21990, Training-Loss 1.2029e+01, Data-loss 1.5402e+01                  , pde-loss 3.4280e+03, initc-loss 1.2915e+04                    bc_loss 1.0169e+04, Test-Loss 1.5402e+01\n",
      "Epoch 22000, Training-Loss 1.3218e+01, Data-loss 1.2962e+01                  , pde-loss 5.6896e+03, initc-loss 1.2866e+04                    bc_loss 2.3296e+04, Test-Loss 1.2962e+01\n",
      "Epoch 22010, Training-Loss 8.5382e+00, Data-loss 9.6713e+00                  , pde-loss 5.2351e+03, initc-loss 1.3043e+04                    bc_loss 8.2017e+03, Test-Loss 9.6713e+00\n",
      "Epoch 22020, Training-Loss 2.3364e+01, Data-loss 1.2292e+01                  , pde-loss 6.1544e+03, initc-loss 1.3271e+04                    bc_loss 1.6262e+04, Test-Loss 1.2292e+01\n",
      "Epoch 22030, Training-Loss 1.7638e+01, Data-loss 5.1550e+00                  , pde-loss 5.0349e+03, initc-loss 1.2951e+04                    bc_loss 8.4202e+03, Test-Loss 5.1550e+00\n",
      "Epoch 22040, Training-Loss 1.7185e+01, Data-loss 3.4793e+00                  , pde-loss 4.8059e+03, initc-loss 1.2862e+04                    bc_loss 1.6933e+04, Test-Loss 3.4793e+00\n",
      "Epoch 22050, Training-Loss 1.5916e+01, Data-loss 1.2852e+01                  , pde-loss 4.0742e+03, initc-loss 1.2884e+04                    bc_loss 8.3734e+03, Test-Loss 1.2852e+01\n",
      "Epoch 22060, Training-Loss 7.3768e+00, Data-loss 9.5716e+00                  , pde-loss 5.7925e+03, initc-loss 1.2996e+04                    bc_loss 7.8898e+03, Test-Loss 9.5716e+00\n",
      "Epoch 22070, Training-Loss 1.3716e+01, Data-loss 1.2015e+01                  , pde-loss 6.4358e+03, initc-loss 1.2887e+04                    bc_loss 9.2621e+03, Test-Loss 1.2015e+01\n",
      "Epoch 22080, Training-Loss 1.1590e+01, Data-loss 1.3825e+01                  , pde-loss 5.8213e+03, initc-loss 1.3105e+04                    bc_loss 1.0143e+04, Test-Loss 1.3825e+01\n",
      "Epoch 22090, Training-Loss 2.8847e+01, Data-loss 1.9245e+01                  , pde-loss 5.0045e+03, initc-loss 1.2992e+04                    bc_loss 7.8672e+03, Test-Loss 1.9245e+01\n",
      "Epoch 22100, Training-Loss 2.4476e+01, Data-loss 1.0984e+01                  , pde-loss 4.6536e+03, initc-loss 1.3100e+04                    bc_loss 1.0449e+04, Test-Loss 1.0984e+01\n",
      "Epoch 22110, Training-Loss 1.4919e+01, Data-loss 7.5204e+00                  , pde-loss 7.3573e+03, initc-loss 1.2589e+04                    bc_loss 2.2659e+04, Test-Loss 7.5204e+00\n",
      "Epoch 22120, Training-Loss 2.2613e+01, Data-loss 6.8820e+00                  , pde-loss 3.7470e+03, initc-loss 1.2994e+04                    bc_loss 1.0960e+04, Test-Loss 6.8820e+00\n",
      "Epoch 22130, Training-Loss 1.2180e+01, Data-loss 2.0830e+01                  , pde-loss 6.4749e+03, initc-loss 1.2828e+04                    bc_loss 1.8869e+04, Test-Loss 2.0830e+01\n",
      "Epoch 22140, Training-Loss 9.4087e+00, Data-loss 8.3706e+00                  , pde-loss 4.1287e+03, initc-loss 1.2852e+04                    bc_loss 1.0009e+04, Test-Loss 8.3706e+00\n",
      "Epoch 22150, Training-Loss 1.5802e+01, Data-loss 1.5730e+01                  , pde-loss 6.4300e+03, initc-loss 1.2886e+04                    bc_loss 9.6334e+03, Test-Loss 1.5730e+01\n",
      "Epoch 22160, Training-Loss 2.4769e+01, Data-loss 1.3596e+01                  , pde-loss 5.1392e+03, initc-loss 1.2941e+04                    bc_loss 8.5922e+03, Test-Loss 1.3596e+01\n",
      "Epoch 22170, Training-Loss 1.6153e+01, Data-loss 4.1145e+01                  , pde-loss 5.2481e+03, initc-loss 1.2757e+04                    bc_loss 1.1435e+04, Test-Loss 4.1145e+01\n",
      "Epoch 22180, Training-Loss 2.8204e+01, Data-loss 2.0512e+01                  , pde-loss 5.9516e+03, initc-loss 1.3140e+04                    bc_loss 8.8988e+03, Test-Loss 2.0512e+01\n",
      "Epoch 22190, Training-Loss 1.9377e+01, Data-loss 8.4369e+00                  , pde-loss 4.9533e+03, initc-loss 1.3082e+04                    bc_loss 1.0815e+04, Test-Loss 8.4369e+00\n",
      "Epoch 22200, Training-Loss 2.3240e+01, Data-loss 4.8068e+00                  , pde-loss 5.1298e+03, initc-loss 1.3001e+04                    bc_loss 7.2359e+03, Test-Loss 4.8068e+00\n",
      "Epoch 22210, Training-Loss 8.9235e+00, Data-loss 9.3441e+00                  , pde-loss 6.9913e+03, initc-loss 1.2882e+04                    bc_loss 1.1412e+04, Test-Loss 9.3441e+00\n",
      "Epoch 22220, Training-Loss 2.5173e+01, Data-loss 9.9074e+00                  , pde-loss 6.1198e+03, initc-loss 1.3008e+04                    bc_loss 6.9084e+03, Test-Loss 9.9074e+00\n",
      "Epoch 22230, Training-Loss 8.7615e+00, Data-loss 3.2639e+01                  , pde-loss 7.4626e+03, initc-loss 1.3284e+04                    bc_loss 1.7235e+04, Test-Loss 3.2639e+01\n",
      "Epoch 22240, Training-Loss 1.1402e+01, Data-loss 4.2462e+00                  , pde-loss 6.6242e+03, initc-loss 1.2903e+04                    bc_loss 6.6325e+03, Test-Loss 4.2462e+00\n",
      "Epoch 22250, Training-Loss 8.5258e+00, Data-loss 1.1830e+01                  , pde-loss 6.5375e+03, initc-loss 1.3019e+04                    bc_loss 1.1225e+04, Test-Loss 1.1830e+01\n",
      "Epoch 22260, Training-Loss 2.7170e+01, Data-loss 1.2527e+01                  , pde-loss 5.7520e+03, initc-loss 1.3228e+04                    bc_loss 9.4669e+03, Test-Loss 1.2527e+01\n",
      "Epoch 22270, Training-Loss 9.1775e+00, Data-loss 2.5520e+01                  , pde-loss 5.3784e+03, initc-loss 1.2861e+04                    bc_loss 7.3803e+03, Test-Loss 2.5520e+01\n",
      "Epoch 22280, Training-Loss 1.4686e+01, Data-loss 1.1649e+01                  , pde-loss 6.1169e+03, initc-loss 1.2961e+04                    bc_loss 1.1896e+04, Test-Loss 1.1649e+01\n",
      "Epoch 22290, Training-Loss 1.4516e+01, Data-loss 1.1370e+01                  , pde-loss 7.0038e+03, initc-loss 1.2940e+04                    bc_loss 9.4729e+03, Test-Loss 1.1370e+01\n",
      "Epoch 22300, Training-Loss 1.3823e+01, Data-loss 8.2726e+00                  , pde-loss 3.8374e+03, initc-loss 1.3033e+04                    bc_loss 8.3485e+03, Test-Loss 8.2726e+00\n",
      "Epoch 22310, Training-Loss 9.0101e+00, Data-loss 1.0695e+01                  , pde-loss 3.8947e+03, initc-loss 1.2814e+04                    bc_loss 7.7752e+03, Test-Loss 1.0695e+01\n",
      "Epoch 22320, Training-Loss 7.8299e+00, Data-loss 1.1036e+01                  , pde-loss 5.0281e+03, initc-loss 1.2873e+04                    bc_loss 1.1110e+04, Test-Loss 1.1036e+01\n",
      "Epoch 22330, Training-Loss 8.4479e+00, Data-loss 1.5437e+01                  , pde-loss 7.3875e+03, initc-loss 1.3057e+04                    bc_loss 7.0758e+03, Test-Loss 1.5437e+01\n",
      "Epoch 22340, Training-Loss 1.4907e+01, Data-loss 7.0531e+00                  , pde-loss 5.5154e+03, initc-loss 1.2727e+04                    bc_loss 5.9826e+03, Test-Loss 7.0531e+00\n",
      "Epoch 22350, Training-Loss 1.0494e+01, Data-loss 4.5034e+00                  , pde-loss 4.9669e+03, initc-loss 1.2691e+04                    bc_loss 1.1638e+04, Test-Loss 4.5034e+00\n",
      "Epoch 22360, Training-Loss 1.4044e+01, Data-loss 1.0242e+01                  , pde-loss 5.4574e+03, initc-loss 1.2989e+04                    bc_loss 6.6432e+03, Test-Loss 1.0242e+01\n",
      "Epoch 22370, Training-Loss 1.4213e+01, Data-loss 9.3950e+00                  , pde-loss 5.0938e+03, initc-loss 1.3007e+04                    bc_loss 7.1727e+03, Test-Loss 9.3950e+00\n",
      "Epoch 22380, Training-Loss 8.4115e+00, Data-loss 2.5863e+01                  , pde-loss 3.8353e+03, initc-loss 1.2917e+04                    bc_loss 5.3729e+03, Test-Loss 2.5863e+01\n",
      "Epoch 22390, Training-Loss 2.5450e+01, Data-loss 8.3433e+00                  , pde-loss 5.6972e+03, initc-loss 1.2980e+04                    bc_loss 7.2282e+03, Test-Loss 8.3433e+00\n",
      "Epoch 22400, Training-Loss 8.9204e+00, Data-loss 1.1973e+01                  , pde-loss 4.6877e+03, initc-loss 1.3060e+04                    bc_loss 6.8040e+03, Test-Loss 1.1973e+01\n",
      "Epoch 22410, Training-Loss 1.3133e+01, Data-loss 1.3199e+01                  , pde-loss 5.7950e+03, initc-loss 1.3037e+04                    bc_loss 5.9652e+03, Test-Loss 1.3199e+01\n",
      "Epoch 22420, Training-Loss 2.3750e+01, Data-loss 3.5483e+00                  , pde-loss 7.2000e+03, initc-loss 1.2984e+04                    bc_loss 1.1893e+04, Test-Loss 3.5483e+00\n",
      "Epoch 22430, Training-Loss 1.3348e+01, Data-loss 1.1087e+01                  , pde-loss 4.3760e+03, initc-loss 1.3038e+04                    bc_loss 1.2398e+04, Test-Loss 1.1087e+01\n",
      "Epoch 22440, Training-Loss 1.2036e+01, Data-loss 3.0890e+01                  , pde-loss 6.3512e+03, initc-loss 1.2763e+04                    bc_loss 1.0699e+04, Test-Loss 3.0890e+01\n",
      "Epoch 22450, Training-Loss 1.6809e+01, Data-loss 9.9072e+00                  , pde-loss 5.2135e+03, initc-loss 1.2859e+04                    bc_loss 1.0832e+04, Test-Loss 9.9072e+00\n",
      "Epoch 22460, Training-Loss 1.2113e+01, Data-loss 2.1768e+01                  , pde-loss 3.9542e+03, initc-loss 1.2880e+04                    bc_loss 7.9984e+03, Test-Loss 2.1768e+01\n",
      "Epoch 22470, Training-Loss 8.2369e+00, Data-loss 9.1983e+00                  , pde-loss 4.1741e+03, initc-loss 1.2854e+04                    bc_loss 6.5789e+03, Test-Loss 9.1983e+00\n",
      "Epoch 22480, Training-Loss 6.6580e+00, Data-loss 6.4696e+00                  , pde-loss 4.9635e+03, initc-loss 1.2945e+04                    bc_loss 5.4784e+03, Test-Loss 6.4696e+00\n",
      "Epoch 22490, Training-Loss 2.3737e+01, Data-loss 5.9202e+00                  , pde-loss 4.9581e+03, initc-loss 1.2876e+04                    bc_loss 5.8910e+03, Test-Loss 5.9202e+00\n",
      "Epoch 22500, Training-Loss 7.7461e+00, Data-loss 8.8762e+00                  , pde-loss 4.8130e+03, initc-loss 1.2637e+04                    bc_loss 1.1769e+04, Test-Loss 8.8762e+00\n",
      "Epoch 22510, Training-Loss 8.8631e+00, Data-loss 9.7136e+00                  , pde-loss 5.6292e+03, initc-loss 1.2989e+04                    bc_loss 6.2262e+03, Test-Loss 9.7136e+00\n",
      "Epoch 22520, Training-Loss 1.2905e+01, Data-loss 1.1850e+01                  , pde-loss 6.0737e+03, initc-loss 1.2754e+04                    bc_loss 1.1441e+04, Test-Loss 1.1850e+01\n",
      "Epoch 22530, Training-Loss 1.1843e+01, Data-loss 9.3158e+00                  , pde-loss 6.3466e+03, initc-loss 1.2771e+04                    bc_loss 8.8472e+03, Test-Loss 9.3158e+00\n",
      "Epoch 22540, Training-Loss 1.1401e+01, Data-loss 7.2612e+00                  , pde-loss 6.2597e+03, initc-loss 1.2947e+04                    bc_loss 6.8715e+03, Test-Loss 7.2612e+00\n",
      "Epoch 22550, Training-Loss 7.4193e+00, Data-loss 5.8416e+00                  , pde-loss 5.3171e+03, initc-loss 1.2928e+04                    bc_loss 5.6155e+03, Test-Loss 5.8416e+00\n",
      "Epoch 22560, Training-Loss 2.8141e+01, Data-loss 9.0899e+00                  , pde-loss 5.7000e+03, initc-loss 1.2778e+04                    bc_loss 1.1345e+04, Test-Loss 9.0899e+00\n",
      "Epoch 22570, Training-Loss 1.1544e+01, Data-loss 1.7927e+01                  , pde-loss 7.6312e+03, initc-loss 1.2829e+04                    bc_loss 2.1708e+04, Test-Loss 1.7927e+01\n",
      "Epoch 22580, Training-Loss 9.7431e+00, Data-loss 1.6009e+01                  , pde-loss 6.3476e+03, initc-loss 1.2894e+04                    bc_loss 5.8083e+03, Test-Loss 1.6009e+01\n",
      "Epoch 22590, Training-Loss 1.0935e+01, Data-loss 7.6553e+00                  , pde-loss 5.3928e+03, initc-loss 1.2864e+04                    bc_loss 6.8758e+03, Test-Loss 7.6553e+00\n",
      "Epoch 22600, Training-Loss 1.2148e+01, Data-loss 1.6561e+01                  , pde-loss 5.6399e+03, initc-loss 1.2702e+04                    bc_loss 9.3784e+03, Test-Loss 1.6561e+01\n",
      "Epoch 22610, Training-Loss 6.5354e+00, Data-loss 7.3406e+00                  , pde-loss 4.8154e+03, initc-loss 1.3028e+04                    bc_loss 6.0553e+03, Test-Loss 7.3406e+00\n",
      "Epoch 22620, Training-Loss 1.6014e+01, Data-loss 3.0819e+00                  , pde-loss 5.8694e+03, initc-loss 1.3172e+04                    bc_loss 5.6631e+03, Test-Loss 3.0819e+00\n",
      "Epoch 22630, Training-Loss 1.2098e+01, Data-loss 7.8135e+00                  , pde-loss 7.2199e+03, initc-loss 1.2761e+04                    bc_loss 1.1648e+04, Test-Loss 7.8135e+00\n",
      "Epoch 22640, Training-Loss 9.1973e+00, Data-loss 6.4497e+00                  , pde-loss 5.1919e+03, initc-loss 1.2677e+04                    bc_loss 1.2840e+04, Test-Loss 6.4497e+00\n",
      "Epoch 22650, Training-Loss 3.1578e+01, Data-loss 8.0823e+00                  , pde-loss 6.8613e+03, initc-loss 1.2962e+04                    bc_loss 7.5048e+03, Test-Loss 8.0823e+00\n",
      "Epoch 22660, Training-Loss 6.6752e+00, Data-loss 6.2878e+00                  , pde-loss 7.0015e+03, initc-loss 1.2933e+04                    bc_loss 6.7400e+03, Test-Loss 6.2878e+00\n",
      "Epoch 22670, Training-Loss 2.6738e+01, Data-loss 5.6390e+00                  , pde-loss 5.6368e+03, initc-loss 1.3138e+04                    bc_loss 6.1652e+03, Test-Loss 5.6390e+00\n",
      "Epoch 22680, Training-Loss 2.7277e+01, Data-loss 9.3974e+00                  , pde-loss 4.6956e+03, initc-loss 1.3018e+04                    bc_loss 5.2560e+03, Test-Loss 9.3974e+00\n",
      "Epoch 22690, Training-Loss 6.1778e+00, Data-loss 5.5516e+00                  , pde-loss 5.0419e+03, initc-loss 1.2992e+04                    bc_loss 5.0524e+03, Test-Loss 5.5516e+00\n",
      "Epoch 22700, Training-Loss 6.5313e+00, Data-loss 8.9392e+00                  , pde-loss 5.7417e+03, initc-loss 1.2828e+04                    bc_loss 4.7149e+03, Test-Loss 8.9392e+00\n",
      "Epoch 22710, Training-Loss 2.1263e+01, Data-loss 1.7161e+01                  , pde-loss 5.9074e+03, initc-loss 1.2862e+04                    bc_loss 5.0255e+03, Test-Loss 1.7161e+01\n",
      "Epoch 22720, Training-Loss 2.1592e+01, Data-loss 1.5571e+01                  , pde-loss 6.3589e+03, initc-loss 1.2782e+04                    bc_loss 4.8962e+03, Test-Loss 1.5571e+01\n",
      "Epoch 22730, Training-Loss 5.8341e+00, Data-loss 1.8984e+01                  , pde-loss 5.7132e+03, initc-loss 1.2782e+04                    bc_loss 1.1431e+04, Test-Loss 1.8984e+01\n",
      "Epoch 22740, Training-Loss 1.0208e+01, Data-loss 4.7849e+00                  , pde-loss 5.0241e+03, initc-loss 1.2834e+04                    bc_loss 5.5249e+03, Test-Loss 4.7849e+00\n",
      "Epoch 22750, Training-Loss 9.7857e+00, Data-loss 7.6696e+00                  , pde-loss 6.4123e+03, initc-loss 1.2935e+04                    bc_loss 6.0016e+03, Test-Loss 7.6696e+00\n",
      "Epoch 22760, Training-Loss 1.0003e+01, Data-loss 2.5981e+00                  , pde-loss 6.1748e+03, initc-loss 1.2794e+04                    bc_loss 4.8742e+03, Test-Loss 2.5981e+00\n",
      "Epoch 22770, Training-Loss 1.7120e+01, Data-loss 3.9125e+00                  , pde-loss 4.5580e+03, initc-loss 1.2876e+04                    bc_loss 5.8106e+03, Test-Loss 3.9125e+00\n",
      "Epoch 22780, Training-Loss 9.6280e+00, Data-loss 4.7903e+00                  , pde-loss 4.2567e+03, initc-loss 1.2942e+04                    bc_loss 4.9760e+03, Test-Loss 4.7903e+00\n",
      "Epoch 22790, Training-Loss 9.9620e+00, Data-loss 9.9209e+00                  , pde-loss 3.8739e+03, initc-loss 1.2861e+04                    bc_loss 5.6414e+03, Test-Loss 9.9209e+00\n",
      "Epoch 22800, Training-Loss 5.5856e+00, Data-loss 4.1387e+00                  , pde-loss 4.9556e+03, initc-loss 1.2886e+04                    bc_loss 5.4964e+03, Test-Loss 4.1387e+00\n",
      "Epoch 22810, Training-Loss 7.8343e+00, Data-loss 5.0887e+00                  , pde-loss 5.9367e+03, initc-loss 1.2897e+04                    bc_loss 6.7003e+03, Test-Loss 5.0887e+00\n",
      "Epoch 22820, Training-Loss 8.0526e+00, Data-loss 5.4422e+00                  , pde-loss 5.1254e+03, initc-loss 1.2953e+04                    bc_loss 4.2461e+03, Test-Loss 5.4422e+00\n",
      "Epoch 22830, Training-Loss 1.5077e+01, Data-loss 5.0299e+00                  , pde-loss 5.5615e+03, initc-loss 1.2845e+04                    bc_loss 5.2572e+03, Test-Loss 5.0299e+00\n",
      "Epoch 22840, Training-Loss 6.0879e+00, Data-loss 5.0649e+00                  , pde-loss 4.3797e+03, initc-loss 1.2890e+04                    bc_loss 4.4011e+03, Test-Loss 5.0649e+00\n",
      "Epoch 22850, Training-Loss 1.2568e+01, Data-loss 2.0502e+01                  , pde-loss 5.6163e+03, initc-loss 1.2893e+04                    bc_loss 4.8782e+03, Test-Loss 2.0502e+01\n",
      "Epoch 22860, Training-Loss 8.3275e+00, Data-loss 4.0668e+00                  , pde-loss 6.1688e+03, initc-loss 1.2855e+04                    bc_loss 7.0010e+03, Test-Loss 4.0668e+00\n",
      "Epoch 22870, Training-Loss 1.9733e+01, Data-loss 3.8117e+00                  , pde-loss 5.5673e+03, initc-loss 1.2919e+04                    bc_loss 3.6517e+03, Test-Loss 3.8117e+00\n",
      "Epoch 22880, Training-Loss 1.1036e+01, Data-loss 2.4288e+00                  , pde-loss 6.2473e+03, initc-loss 1.2886e+04                    bc_loss 9.6372e+03, Test-Loss 2.4288e+00\n",
      "Epoch 22890, Training-Loss 1.2847e+01, Data-loss 8.2599e+00                  , pde-loss 6.4818e+03, initc-loss 1.2830e+04                    bc_loss 4.6854e+03, Test-Loss 8.2599e+00\n",
      "Epoch 22900, Training-Loss 6.6913e+00, Data-loss 5.0699e+00                  , pde-loss 6.6067e+03, initc-loss 1.2835e+04                    bc_loss 5.8868e+03, Test-Loss 5.0699e+00\n",
      "Epoch 22910, Training-Loss 7.8991e+00, Data-loss 4.0662e+00                  , pde-loss 5.3474e+03, initc-loss 1.2806e+04                    bc_loss 4.5300e+03, Test-Loss 4.0662e+00\n",
      "Epoch 22920, Training-Loss 9.5129e+00, Data-loss 4.8549e+00                  , pde-loss 5.0542e+03, initc-loss 1.3052e+04                    bc_loss 4.9700e+03, Test-Loss 4.8549e+00\n",
      "Epoch 22930, Training-Loss 7.5228e+00, Data-loss 8.6505e+00                  , pde-loss 6.3609e+03, initc-loss 1.3010e+04                    bc_loss 5.9538e+03, Test-Loss 8.6505e+00\n",
      "Epoch 22940, Training-Loss 8.0309e+00, Data-loss 1.4506e+01                  , pde-loss 5.6896e+03, initc-loss 1.2864e+04                    bc_loss 5.4072e+03, Test-Loss 1.4506e+01\n",
      "Epoch 22950, Training-Loss 1.1862e+01, Data-loss 3.7452e+00                  , pde-loss 3.5353e+03, initc-loss 1.2585e+04                    bc_loss 1.3877e+04, Test-Loss 3.7452e+00\n",
      "Epoch 22960, Training-Loss 8.2675e+00, Data-loss 4.3958e+00                  , pde-loss 4.9356e+03, initc-loss 1.2953e+04                    bc_loss 5.2627e+03, Test-Loss 4.3958e+00\n",
      "Epoch 22970, Training-Loss 6.2253e+00, Data-loss 8.4217e+00                  , pde-loss 5.0977e+03, initc-loss 1.2858e+04                    bc_loss 4.9151e+03, Test-Loss 8.4217e+00\n",
      "Epoch 22980, Training-Loss 9.9088e+00, Data-loss 6.3362e+00                  , pde-loss 7.4509e+03, initc-loss 1.2925e+04                    bc_loss 4.7278e+03, Test-Loss 6.3362e+00\n",
      "Epoch 22990, Training-Loss 5.1155e+00, Data-loss 1.0322e+01                  , pde-loss 6.3646e+03, initc-loss 1.2825e+04                    bc_loss 3.8761e+03, Test-Loss 1.0322e+01\n",
      "Epoch 23000, Training-Loss 7.9087e+00, Data-loss 6.4858e+00                  , pde-loss 7.1654e+03, initc-loss 1.2819e+04                    bc_loss 8.7193e+03, Test-Loss 6.4858e+00\n",
      "Epoch 23010, Training-Loss 6.3039e+00, Data-loss 6.0971e+00                  , pde-loss 4.9705e+03, initc-loss 1.2867e+04                    bc_loss 3.8462e+03, Test-Loss 6.0971e+00\n",
      "Epoch 23020, Training-Loss 7.4109e+00, Data-loss 5.6362e+00                  , pde-loss 6.5420e+03, initc-loss 1.2854e+04                    bc_loss 5.5145e+03, Test-Loss 5.6362e+00\n",
      "Epoch 23030, Training-Loss 1.3398e+01, Data-loss 5.9677e+00                  , pde-loss 4.8700e+03, initc-loss 1.2792e+04                    bc_loss 7.9486e+03, Test-Loss 5.9677e+00\n",
      "Epoch 23040, Training-Loss 6.8151e+00, Data-loss 1.5159e+01                  , pde-loss 5.5590e+03, initc-loss 1.2995e+04                    bc_loss 6.4628e+03, Test-Loss 1.5159e+01\n",
      "Epoch 23050, Training-Loss 7.6570e+00, Data-loss 6.5009e+00                  , pde-loss 5.9162e+03, initc-loss 1.2821e+04                    bc_loss 2.3930e+04, Test-Loss 6.5009e+00\n",
      "Epoch 23060, Training-Loss 6.5220e+00, Data-loss 5.4936e+00                  , pde-loss 6.9558e+03, initc-loss 1.2995e+04                    bc_loss 6.5398e+03, Test-Loss 5.4936e+00\n",
      "Epoch 23070, Training-Loss 6.7424e+00, Data-loss 4.0220e+00                  , pde-loss 4.5282e+03, initc-loss 1.2877e+04                    bc_loss 7.4584e+03, Test-Loss 4.0220e+00\n",
      "Epoch 23080, Training-Loss 5.9840e+00, Data-loss 3.9096e+00                  , pde-loss 3.9629e+03, initc-loss 1.2818e+04                    bc_loss 3.6631e+03, Test-Loss 3.9096e+00\n",
      "Epoch 23090, Training-Loss 6.2261e+00, Data-loss 3.9382e+00                  , pde-loss 5.3225e+03, initc-loss 1.2837e+04                    bc_loss 4.8836e+03, Test-Loss 3.9382e+00\n",
      "Epoch 23100, Training-Loss 8.3733e+00, Data-loss 3.1077e+00                  , pde-loss 5.3005e+03, initc-loss 1.2856e+04                    bc_loss 4.3993e+03, Test-Loss 3.1077e+00\n",
      "Epoch 23110, Training-Loss 7.2623e+00, Data-loss 2.9065e+00                  , pde-loss 6.5271e+03, initc-loss 1.2803e+04                    bc_loss 7.2460e+03, Test-Loss 2.9065e+00\n",
      "Epoch 23120, Training-Loss 8.2794e+00, Data-loss 5.5645e+00                  , pde-loss 4.4082e+03, initc-loss 1.2865e+04                    bc_loss 6.2663e+03, Test-Loss 5.5645e+00\n",
      "Epoch 23130, Training-Loss 5.7794e+00, Data-loss 6.2704e+00                  , pde-loss 6.1323e+03, initc-loss 1.2684e+04                    bc_loss 3.2274e+03, Test-Loss 6.2704e+00\n",
      "Epoch 23140, Training-Loss 8.1321e+00, Data-loss 1.4185e+01                  , pde-loss 4.7412e+03, initc-loss 1.2744e+04                    bc_loss 6.2770e+03, Test-Loss 1.4185e+01\n",
      "Epoch 23150, Training-Loss 7.3563e+00, Data-loss 1.4932e+01                  , pde-loss 4.7640e+03, initc-loss 1.2647e+04                    bc_loss 8.1384e+03, Test-Loss 1.4932e+01\n",
      "Epoch 23160, Training-Loss 1.4911e+01, Data-loss 3.6971e+00                  , pde-loss 6.3654e+03, initc-loss 1.2960e+04                    bc_loss 3.5752e+03, Test-Loss 3.6971e+00\n",
      "Epoch 23170, Training-Loss 1.1174e+01, Data-loss 4.8802e+00                  , pde-loss 4.0744e+03, initc-loss 1.2821e+04                    bc_loss 1.2301e+04, Test-Loss 4.8802e+00\n",
      "Epoch 23180, Training-Loss 7.5691e+00, Data-loss 4.1704e+00                  , pde-loss 4.9357e+03, initc-loss 1.2893e+04                    bc_loss 3.6705e+03, Test-Loss 4.1704e+00\n",
      "Epoch 23190, Training-Loss 1.5966e+01, Data-loss 5.0577e+00                  , pde-loss 6.1095e+03, initc-loss 1.2796e+04                    bc_loss 6.2685e+03, Test-Loss 5.0577e+00\n",
      "Epoch 23200, Training-Loss 6.9044e+00, Data-loss 4.2840e+00                  , pde-loss 4.6686e+03, initc-loss 1.2888e+04                    bc_loss 6.9650e+03, Test-Loss 4.2840e+00\n",
      "Epoch 23210, Training-Loss 6.6799e+00, Data-loss 1.2316e+01                  , pde-loss 5.9754e+03, initc-loss 1.2777e+04                    bc_loss 5.1922e+03, Test-Loss 1.2316e+01\n",
      "Epoch 23220, Training-Loss 1.4150e+01, Data-loss 2.5162e+01                  , pde-loss 4.9717e+03, initc-loss 1.2697e+04                    bc_loss 3.2927e+03, Test-Loss 2.5162e+01\n",
      "Epoch 23230, Training-Loss 6.5131e+00, Data-loss 4.9947e+00                  , pde-loss 5.7174e+03, initc-loss 1.2870e+04                    bc_loss 6.4354e+03, Test-Loss 4.9947e+00\n",
      "Epoch 23240, Training-Loss 8.6550e+00, Data-loss 6.0563e+00                  , pde-loss 4.2164e+03, initc-loss 1.3205e+04                    bc_loss 9.2881e+03, Test-Loss 6.0563e+00\n",
      "Epoch 23250, Training-Loss 9.2715e+00, Data-loss 2.9095e+00                  , pde-loss 4.4736e+03, initc-loss 1.2985e+04                    bc_loss 8.0002e+03, Test-Loss 2.9095e+00\n",
      "Epoch 23260, Training-Loss 5.8476e+00, Data-loss 3.4939e+00                  , pde-loss 4.5314e+03, initc-loss 1.3016e+04                    bc_loss 5.2452e+03, Test-Loss 3.4939e+00\n",
      "Epoch 23270, Training-Loss 6.7440e+00, Data-loss 4.6530e+00                  , pde-loss 6.1420e+03, initc-loss 1.2823e+04                    bc_loss 4.4478e+03, Test-Loss 4.6530e+00\n",
      "Epoch 23280, Training-Loss 5.6325e+00, Data-loss 8.2538e+00                  , pde-loss 5.3629e+03, initc-loss 1.2811e+04                    bc_loss 3.9487e+03, Test-Loss 8.2538e+00\n",
      "Epoch 23290, Training-Loss 5.4941e+00, Data-loss 1.5640e+01                  , pde-loss 6.6667e+03, initc-loss 1.2860e+04                    bc_loss 4.6573e+03, Test-Loss 1.5640e+01\n",
      "Epoch 23300, Training-Loss 5.0723e+00, Data-loss 3.5765e+00                  , pde-loss 6.0532e+03, initc-loss 1.2825e+04                    bc_loss 4.3695e+03, Test-Loss 3.5765e+00\n",
      "Epoch 23310, Training-Loss 5.0317e+00, Data-loss 3.9929e+00                  , pde-loss 6.3045e+03, initc-loss 1.2922e+04                    bc_loss 3.6295e+03, Test-Loss 3.9929e+00\n",
      "Epoch 23320, Training-Loss 1.4433e+01, Data-loss 6.3431e+00                  , pde-loss 4.8709e+03, initc-loss 1.2667e+04                    bc_loss 2.8921e+03, Test-Loss 6.3431e+00\n",
      "Epoch 23330, Training-Loss 5.8284e+00, Data-loss 3.5324e+00                  , pde-loss 7.5705e+03, initc-loss 1.3029e+04                    bc_loss 3.2411e+03, Test-Loss 3.5324e+00\n",
      "Epoch 23340, Training-Loss 8.4882e+00, Data-loss 9.6773e+00                  , pde-loss 4.9842e+03, initc-loss 1.2829e+04                    bc_loss 3.3674e+03, Test-Loss 9.6773e+00\n",
      "Epoch 23350, Training-Loss 1.0942e+01, Data-loss 4.6914e+00                  , pde-loss 5.4893e+03, initc-loss 1.2686e+04                    bc_loss 1.0729e+04, Test-Loss 4.6914e+00\n",
      "Epoch 23360, Training-Loss 8.0179e+00, Data-loss 4.7807e+00                  , pde-loss 5.9783e+03, initc-loss 1.2938e+04                    bc_loss 5.2380e+03, Test-Loss 4.7807e+00\n",
      "Epoch 23370, Training-Loss 8.2486e+00, Data-loss 5.7867e+00                  , pde-loss 4.5459e+03, initc-loss 1.2904e+04                    bc_loss 4.6900e+03, Test-Loss 5.7867e+00\n",
      "Epoch 23380, Training-Loss 8.7107e+00, Data-loss 4.4959e+00                  , pde-loss 5.2697e+03, initc-loss 1.2810e+04                    bc_loss 3.0267e+03, Test-Loss 4.4959e+00\n",
      "Epoch 23390, Training-Loss 8.0450e+00, Data-loss 9.4429e+00                  , pde-loss 5.2655e+03, initc-loss 1.2917e+04                    bc_loss 7.6476e+03, Test-Loss 9.4429e+00\n",
      "Epoch 23400, Training-Loss 8.3099e+00, Data-loss 3.5981e+00                  , pde-loss 5.8821e+03, initc-loss 1.2903e+04                    bc_loss 4.4598e+03, Test-Loss 3.5981e+00\n",
      "Epoch 23410, Training-Loss 7.5896e+00, Data-loss 7.3930e+00                  , pde-loss 7.4066e+03, initc-loss 1.2731e+04                    bc_loss 8.3478e+03, Test-Loss 7.3930e+00\n",
      "Epoch 23420, Training-Loss 6.6663e+00, Data-loss 4.6772e+00                  , pde-loss 4.8378e+03, initc-loss 1.2948e+04                    bc_loss 3.2766e+03, Test-Loss 4.6772e+00\n",
      "Epoch 23430, Training-Loss 5.9375e+00, Data-loss 2.1788e+00                  , pde-loss 7.8543e+03, initc-loss 1.2945e+04                    bc_loss 2.6194e+03, Test-Loss 2.1788e+00\n",
      "Epoch 23440, Training-Loss 5.3212e+00, Data-loss 3.5276e+00                  , pde-loss 6.1773e+03, initc-loss 1.2817e+04                    bc_loss 3.8567e+03, Test-Loss 3.5276e+00\n",
      "Epoch 23450, Training-Loss 9.9643e+00, Data-loss 3.8492e+00                  , pde-loss 5.7218e+03, initc-loss 1.3091e+04                    bc_loss 4.8079e+03, Test-Loss 3.8492e+00\n",
      "Epoch 23460, Training-Loss 5.8986e+00, Data-loss 4.3701e+00                  , pde-loss 6.1654e+03, initc-loss 1.2805e+04                    bc_loss 4.8063e+03, Test-Loss 4.3701e+00\n",
      "Epoch 23470, Training-Loss 6.3955e+00, Data-loss 3.6289e+00                  , pde-loss 6.3116e+03, initc-loss 1.2853e+04                    bc_loss 2.8366e+03, Test-Loss 3.6289e+00\n",
      "Epoch 23480, Training-Loss 1.1121e+01, Data-loss 1.1543e+01                  , pde-loss 7.1448e+03, initc-loss 1.2790e+04                    bc_loss 5.5991e+03, Test-Loss 1.1543e+01\n",
      "Epoch 23490, Training-Loss 4.9774e+00, Data-loss 4.4052e+00                  , pde-loss 5.5198e+03, initc-loss 1.2802e+04                    bc_loss 3.3224e+03, Test-Loss 4.4052e+00\n",
      "Epoch 23500, Training-Loss 6.2366e+00, Data-loss 2.7211e+00                  , pde-loss 6.4951e+03, initc-loss 1.2880e+04                    bc_loss 3.4937e+03, Test-Loss 2.7211e+00\n",
      "Epoch 23510, Training-Loss 1.4410e+01, Data-loss 1.1593e+01                  , pde-loss 5.4934e+03, initc-loss 1.2826e+04                    bc_loss 4.3502e+03, Test-Loss 1.1593e+01\n",
      "Epoch 23520, Training-Loss 4.8470e+00, Data-loss 3.6435e+00                  , pde-loss 7.1975e+03, initc-loss 1.2835e+04                    bc_loss 2.6744e+03, Test-Loss 3.6435e+00\n",
      "Epoch 23530, Training-Loss 7.5622e+00, Data-loss 5.2655e+00                  , pde-loss 5.2052e+03, initc-loss 1.2853e+04                    bc_loss 4.7542e+03, Test-Loss 5.2655e+00\n",
      "Epoch 23540, Training-Loss 6.4737e+00, Data-loss 3.3371e+00                  , pde-loss 3.7484e+03, initc-loss 1.3029e+04                    bc_loss 1.1134e+04, Test-Loss 3.3371e+00\n",
      "Epoch 23550, Training-Loss 5.1318e+00, Data-loss 2.5593e+00                  , pde-loss 6.4586e+03, initc-loss 1.2810e+04                    bc_loss 4.2245e+03, Test-Loss 2.5593e+00\n",
      "Epoch 23560, Training-Loss 6.8391e+00, Data-loss 2.2211e+00                  , pde-loss 7.0083e+03, initc-loss 1.2974e+04                    bc_loss 5.3516e+03, Test-Loss 2.2211e+00\n",
      "Epoch 23570, Training-Loss 7.3050e+00, Data-loss 1.0918e+01                  , pde-loss 5.9969e+03, initc-loss 1.2851e+04                    bc_loss 1.4687e+04, Test-Loss 1.0918e+01\n",
      "Epoch 23580, Training-Loss 5.9361e+00, Data-loss 4.1972e+00                  , pde-loss 5.4031e+03, initc-loss 1.2922e+04                    bc_loss 3.2151e+03, Test-Loss 4.1972e+00\n",
      "Epoch 23590, Training-Loss 6.2022e+00, Data-loss 6.6310e+00                  , pde-loss 6.3782e+03, initc-loss 1.2767e+04                    bc_loss 3.3177e+03, Test-Loss 6.6310e+00\n",
      "Epoch 23600, Training-Loss 4.9034e+00, Data-loss 5.5834e+00                  , pde-loss 6.7166e+03, initc-loss 1.2772e+04                    bc_loss 2.6930e+03, Test-Loss 5.5834e+00\n",
      "Epoch 23610, Training-Loss 5.8197e+00, Data-loss 4.3696e+00                  , pde-loss 6.1874e+03, initc-loss 1.2879e+04                    bc_loss 2.8084e+03, Test-Loss 4.3696e+00\n",
      "Epoch 23620, Training-Loss 5.2101e+00, Data-loss 3.0881e+00                  , pde-loss 4.4590e+03, initc-loss 1.2958e+04                    bc_loss 5.6171e+03, Test-Loss 3.0881e+00\n",
      "Epoch 23630, Training-Loss 8.2109e+00, Data-loss 3.9824e+00                  , pde-loss 5.8429e+03, initc-loss 1.2728e+04                    bc_loss 4.9273e+03, Test-Loss 3.9824e+00\n",
      "Epoch 23640, Training-Loss 5.7577e+00, Data-loss 2.4128e+00                  , pde-loss 6.5631e+03, initc-loss 1.2790e+04                    bc_loss 2.4091e+03, Test-Loss 2.4128e+00\n",
      "Epoch 23650, Training-Loss 1.5209e+01, Data-loss 2.9430e+00                  , pde-loss 5.7802e+03, initc-loss 1.2894e+04                    bc_loss 2.7391e+03, Test-Loss 2.9430e+00\n",
      "Epoch 23660, Training-Loss 7.9573e+00, Data-loss 4.9709e+00                  , pde-loss 5.6786e+03, initc-loss 1.2763e+04                    bc_loss 2.7921e+03, Test-Loss 4.9709e+00\n",
      "Epoch 23670, Training-Loss 1.1328e+01, Data-loss 3.2059e+00                  , pde-loss 5.7665e+03, initc-loss 1.2742e+04                    bc_loss 1.2199e+04, Test-Loss 3.2059e+00\n",
      "Epoch 23680, Training-Loss 6.6952e+00, Data-loss 3.6031e+00                  , pde-loss 3.9052e+03, initc-loss 1.2904e+04                    bc_loss 3.1958e+03, Test-Loss 3.6031e+00\n",
      "Epoch 23690, Training-Loss 5.8689e+00, Data-loss 3.6436e+00                  , pde-loss 6.7497e+03, initc-loss 1.2896e+04                    bc_loss 2.6592e+03, Test-Loss 3.6436e+00\n",
      "Epoch 23700, Training-Loss 5.3537e+00, Data-loss 5.7452e+00                  , pde-loss 4.0877e+03, initc-loss 1.2661e+04                    bc_loss 2.7871e+03, Test-Loss 5.7452e+00\n",
      "Epoch 23710, Training-Loss 1.4087e+01, Data-loss 4.0698e+00                  , pde-loss 5.9826e+03, initc-loss 1.2853e+04                    bc_loss 3.1399e+03, Test-Loss 4.0698e+00\n",
      "Epoch 23720, Training-Loss 7.8492e+00, Data-loss 9.8525e+00                  , pde-loss 5.8741e+03, initc-loss 1.2962e+04                    bc_loss 4.4999e+03, Test-Loss 9.8525e+00\n",
      "Epoch 23730, Training-Loss 4.8754e+00, Data-loss 9.8558e+00                  , pde-loss 5.6299e+03, initc-loss 1.2749e+04                    bc_loss 3.1172e+03, Test-Loss 9.8558e+00\n",
      "Epoch 23740, Training-Loss 4.3929e+00, Data-loss 6.3883e+00                  , pde-loss 5.3124e+03, initc-loss 1.2945e+04                    bc_loss 2.1282e+03, Test-Loss 6.3883e+00\n",
      "Epoch 23750, Training-Loss 1.2193e+01, Data-loss 4.1565e+00                  , pde-loss 7.8656e+03, initc-loss 1.2954e+04                    bc_loss 6.6005e+03, Test-Loss 4.1565e+00\n",
      "Epoch 23760, Training-Loss 4.4077e+00, Data-loss 8.8942e+00                  , pde-loss 5.9780e+03, initc-loss 1.2799e+04                    bc_loss 5.1477e+03, Test-Loss 8.8942e+00\n",
      "Epoch 23770, Training-Loss 7.4602e+00, Data-loss 3.2835e+00                  , pde-loss 7.1432e+03, initc-loss 1.2728e+04                    bc_loss 5.8928e+03, Test-Loss 3.2835e+00\n",
      "Epoch 23780, Training-Loss 5.6079e+00, Data-loss 3.8108e+00                  , pde-loss 6.3800e+03, initc-loss 1.2794e+04                    bc_loss 2.6056e+03, Test-Loss 3.8108e+00\n",
      "Epoch 23790, Training-Loss 4.1374e+00, Data-loss 3.4940e+00                  , pde-loss 6.3648e+03, initc-loss 1.2828e+04                    bc_loss 2.2046e+03, Test-Loss 3.4940e+00\n",
      "Epoch 23800, Training-Loss 4.5967e+00, Data-loss 4.1364e+00                  , pde-loss 4.9120e+03, initc-loss 1.2890e+04                    bc_loss 3.4284e+03, Test-Loss 4.1364e+00\n",
      "Epoch 23810, Training-Loss 5.9701e+00, Data-loss 3.2935e+00                  , pde-loss 5.5364e+03, initc-loss 1.2983e+04                    bc_loss 3.0950e+03, Test-Loss 3.2935e+00\n",
      "Epoch 23820, Training-Loss 7.4730e+00, Data-loss 4.4123e+00                  , pde-loss 5.7430e+03, initc-loss 1.2843e+04                    bc_loss 2.1406e+03, Test-Loss 4.4123e+00\n",
      "Epoch 23830, Training-Loss 5.1886e+00, Data-loss 3.7873e+00                  , pde-loss 5.8952e+03, initc-loss 1.2948e+04                    bc_loss 3.0896e+03, Test-Loss 3.7873e+00\n",
      "Epoch 23840, Training-Loss 1.3039e+01, Data-loss 4.4539e+00                  , pde-loss 5.7874e+03, initc-loss 1.2798e+04                    bc_loss 4.7121e+03, Test-Loss 4.4539e+00\n",
      "Epoch 23850, Training-Loss 6.6786e+00, Data-loss 2.4880e+00                  , pde-loss 5.8634e+03, initc-loss 1.2893e+04                    bc_loss 2.1847e+03, Test-Loss 2.4880e+00\n",
      "Epoch 23860, Training-Loss 1.2851e+01, Data-loss 2.2268e+00                  , pde-loss 6.9524e+03, initc-loss 1.2864e+04                    bc_loss 5.8775e+03, Test-Loss 2.2268e+00\n",
      "Epoch 23870, Training-Loss 5.3002e+00, Data-loss 8.9298e+00                  , pde-loss 5.4897e+03, initc-loss 1.2969e+04                    bc_loss 2.0107e+03, Test-Loss 8.9298e+00\n",
      "Epoch 23880, Training-Loss 5.7675e+00, Data-loss 2.7034e+00                  , pde-loss 5.6886e+03, initc-loss 1.2981e+04                    bc_loss 2.8727e+03, Test-Loss 2.7034e+00\n",
      "Epoch 23890, Training-Loss 4.4835e+00, Data-loss 2.7915e+00                  , pde-loss 4.4179e+03, initc-loss 1.2841e+04                    bc_loss 2.0295e+03, Test-Loss 2.7915e+00\n",
      "Epoch 23900, Training-Loss 5.2049e+00, Data-loss 1.9631e+00                  , pde-loss 5.2133e+03, initc-loss 1.2877e+04                    bc_loss 3.3460e+03, Test-Loss 1.9631e+00\n",
      "Epoch 23910, Training-Loss 5.0760e+00, Data-loss 3.4720e+00                  , pde-loss 5.8208e+03, initc-loss 1.2868e+04                    bc_loss 2.0452e+03, Test-Loss 3.4720e+00\n",
      "Epoch 23920, Training-Loss 1.3562e+01, Data-loss 2.5875e+00                  , pde-loss 6.0379e+03, initc-loss 1.2790e+04                    bc_loss 3.0649e+03, Test-Loss 2.5875e+00\n",
      "Epoch 23930, Training-Loss 5.1021e+00, Data-loss 4.2588e+00                  , pde-loss 5.0670e+03, initc-loss 1.2883e+04                    bc_loss 2.1209e+03, Test-Loss 4.2588e+00\n",
      "Epoch 23940, Training-Loss 7.0600e+00, Data-loss 3.9677e+00                  , pde-loss 5.3492e+03, initc-loss 1.2810e+04                    bc_loss 2.7301e+03, Test-Loss 3.9677e+00\n",
      "Epoch 23950, Training-Loss 5.0344e+00, Data-loss 8.3210e+00                  , pde-loss 4.3383e+03, initc-loss 1.2859e+04                    bc_loss 3.1458e+03, Test-Loss 8.3210e+00\n",
      "Epoch 23960, Training-Loss 5.1378e+00, Data-loss 2.4286e+00                  , pde-loss 6.0992e+03, initc-loss 1.2677e+04                    bc_loss 3.7220e+03, Test-Loss 2.4286e+00\n",
      "Epoch 23970, Training-Loss 4.1830e+00, Data-loss 4.5561e+00                  , pde-loss 4.1536e+03, initc-loss 1.2929e+04                    bc_loss 2.3589e+03, Test-Loss 4.5561e+00\n",
      "Epoch 23980, Training-Loss 5.0856e+00, Data-loss 3.2511e+00                  , pde-loss 6.4321e+03, initc-loss 1.2815e+04                    bc_loss 3.1914e+03, Test-Loss 3.2511e+00\n",
      "Epoch 23990, Training-Loss 5.6475e+00, Data-loss 4.0939e+00                  , pde-loss 4.8272e+03, initc-loss 1.2966e+04                    bc_loss 3.0783e+03, Test-Loss 4.0939e+00\n",
      "Epoch 24000, Training-Loss 4.8712e+00, Data-loss 2.4646e+00                  , pde-loss 4.6918e+03, initc-loss 1.2915e+04                    bc_loss 2.8723e+03, Test-Loss 2.4646e+00\n",
      "Epoch 24010, Training-Loss 4.2517e+00, Data-loss 2.8813e+00                  , pde-loss 5.7306e+03, initc-loss 1.2885e+04                    bc_loss 5.9034e+03, Test-Loss 2.8813e+00\n",
      "Epoch 24020, Training-Loss 5.3343e+00, Data-loss 9.2773e+00                  , pde-loss 6.8919e+03, initc-loss 1.2882e+04                    bc_loss 2.3459e+03, Test-Loss 9.2773e+00\n",
      "Epoch 24030, Training-Loss 1.1305e+01, Data-loss 8.2685e+00                  , pde-loss 5.6788e+03, initc-loss 1.2952e+04                    bc_loss 3.3687e+03, Test-Loss 8.2685e+00\n",
      "Epoch 24040, Training-Loss 4.4936e+00, Data-loss 3.9637e+00                  , pde-loss 4.9741e+03, initc-loss 1.2778e+04                    bc_loss 2.7999e+03, Test-Loss 3.9637e+00\n",
      "Epoch 24050, Training-Loss 7.6801e+00, Data-loss 5.9877e+00                  , pde-loss 5.8554e+03, initc-loss 1.2844e+04                    bc_loss 2.9324e+03, Test-Loss 5.9877e+00\n",
      "Epoch 24060, Training-Loss 4.8595e+00, Data-loss 6.2288e+00                  , pde-loss 5.5256e+03, initc-loss 1.2848e+04                    bc_loss 3.4789e+03, Test-Loss 6.2288e+00\n",
      "Epoch 24070, Training-Loss 4.6570e+00, Data-loss 1.7530e+00                  , pde-loss 5.8492e+03, initc-loss 1.2915e+04                    bc_loss 2.1164e+03, Test-Loss 1.7530e+00\n",
      "Epoch 24080, Training-Loss 5.0117e+00, Data-loss 5.9037e+00                  , pde-loss 7.1412e+03, initc-loss 1.2764e+04                    bc_loss 7.6756e+03, Test-Loss 5.9037e+00\n",
      "Epoch 24090, Training-Loss 4.7973e+00, Data-loss 3.6765e+00                  , pde-loss 7.2707e+03, initc-loss 1.2854e+04                    bc_loss 2.2314e+03, Test-Loss 3.6765e+00\n",
      "Epoch 24100, Training-Loss 6.4499e+00, Data-loss 2.7550e+00                  , pde-loss 6.5886e+03, initc-loss 1.2855e+04                    bc_loss 2.7428e+03, Test-Loss 2.7550e+00\n",
      "Epoch 24110, Training-Loss 5.4217e+00, Data-loss 4.7104e+00                  , pde-loss 6.0461e+03, initc-loss 1.3004e+04                    bc_loss 2.3020e+03, Test-Loss 4.7104e+00\n",
      "Epoch 24120, Training-Loss 5.0163e+00, Data-loss 1.8122e+00                  , pde-loss 7.3621e+03, initc-loss 1.2874e+04                    bc_loss 2.0194e+03, Test-Loss 1.8122e+00\n",
      "Epoch 24130, Training-Loss 8.0768e+00, Data-loss 5.6675e+00                  , pde-loss 5.2435e+03, initc-loss 1.2726e+04                    bc_loss 1.7929e+03, Test-Loss 5.6675e+00\n",
      "Epoch 24140, Training-Loss 4.5795e+00, Data-loss 8.0692e+00                  , pde-loss 4.4300e+03, initc-loss 1.3095e+04                    bc_loss 9.3914e+03, Test-Loss 8.0692e+00\n",
      "Epoch 24150, Training-Loss 5.6301e+00, Data-loss 2.7679e+00                  , pde-loss 6.1848e+03, initc-loss 1.2740e+04                    bc_loss 1.9704e+03, Test-Loss 2.7679e+00\n",
      "Epoch 24160, Training-Loss 5.1247e+00, Data-loss 3.1899e+00                  , pde-loss 4.6384e+03, initc-loss 1.2747e+04                    bc_loss 5.0115e+03, Test-Loss 3.1899e+00\n",
      "Epoch 24170, Training-Loss 4.0968e+00, Data-loss 2.5690e+00                  , pde-loss 6.0358e+03, initc-loss 1.3011e+04                    bc_loss 2.1978e+03, Test-Loss 2.5690e+00\n",
      "Epoch 24180, Training-Loss 5.2601e+00, Data-loss 2.7715e+00                  , pde-loss 5.5812e+03, initc-loss 1.2935e+04                    bc_loss 1.9110e+03, Test-Loss 2.7715e+00\n",
      "Epoch 24190, Training-Loss 4.5325e+00, Data-loss 7.8679e+00                  , pde-loss 5.9226e+03, initc-loss 1.2978e+04                    bc_loss 2.4214e+03, Test-Loss 7.8679e+00\n",
      "Epoch 24200, Training-Loss 7.0976e+00, Data-loss 5.9663e+00                  , pde-loss 7.4742e+03, initc-loss 1.2896e+04                    bc_loss 1.6417e+03, Test-Loss 5.9663e+00\n",
      "Epoch 24210, Training-Loss 3.5727e+00, Data-loss 4.1982e+00                  , pde-loss 5.4021e+03, initc-loss 1.2902e+04                    bc_loss 2.7175e+03, Test-Loss 4.1982e+00\n",
      "Epoch 24220, Training-Loss 4.4507e+00, Data-loss 2.2400e+00                  , pde-loss 4.3237e+03, initc-loss 1.3008e+04                    bc_loss 4.6724e+03, Test-Loss 2.2400e+00\n",
      "Epoch 24230, Training-Loss 5.3608e+00, Data-loss 4.0317e+00                  , pde-loss 4.4375e+03, initc-loss 1.2969e+04                    bc_loss 1.5694e+03, Test-Loss 4.0317e+00\n",
      "Epoch 24240, Training-Loss 4.4988e+00, Data-loss 1.0046e+01                  , pde-loss 5.9279e+03, initc-loss 1.2716e+04                    bc_loss 3.1386e+03, Test-Loss 1.0046e+01\n",
      "Epoch 24250, Training-Loss 5.0472e+00, Data-loss 2.4042e+00                  , pde-loss 7.3461e+03, initc-loss 1.2859e+04                    bc_loss 1.8598e+03, Test-Loss 2.4042e+00\n",
      "Epoch 24260, Training-Loss 5.3602e+00, Data-loss 3.0126e+00                  , pde-loss 5.2526e+03, initc-loss 1.2957e+04                    bc_loss 3.3989e+03, Test-Loss 3.0126e+00\n",
      "Epoch 24270, Training-Loss 5.1878e+00, Data-loss 2.2737e+00                  , pde-loss 4.7358e+03, initc-loss 1.2898e+04                    bc_loss 3.1323e+03, Test-Loss 2.2737e+00\n",
      "Epoch 24280, Training-Loss 4.5151e+00, Data-loss 4.1591e+00                  , pde-loss 4.1865e+03, initc-loss 1.2742e+04                    bc_loss 8.0729e+03, Test-Loss 4.1591e+00\n",
      "Epoch 24290, Training-Loss 5.2345e+00, Data-loss 5.6853e+00                  , pde-loss 6.4257e+03, initc-loss 1.2893e+04                    bc_loss 2.0904e+03, Test-Loss 5.6853e+00\n",
      "Epoch 24300, Training-Loss 5.8435e+00, Data-loss 4.5148e+00                  , pde-loss 6.0076e+03, initc-loss 1.2817e+04                    bc_loss 3.9470e+03, Test-Loss 4.5148e+00\n",
      "Epoch 24310, Training-Loss 1.1919e+01, Data-loss 8.3671e+00                  , pde-loss 5.9977e+03, initc-loss 1.2911e+04                    bc_loss 1.9313e+03, Test-Loss 8.3671e+00\n",
      "Epoch 24320, Training-Loss 6.0560e+00, Data-loss 2.8345e+00                  , pde-loss 3.9194e+03, initc-loss 1.3062e+04                    bc_loss 2.8828e+03, Test-Loss 2.8345e+00\n",
      "Epoch 24330, Training-Loss 5.7934e+00, Data-loss 1.6217e+00                  , pde-loss 4.8351e+03, initc-loss 1.2862e+04                    bc_loss 1.9553e+03, Test-Loss 1.6217e+00\n",
      "Epoch 24340, Training-Loss 9.3782e+00, Data-loss 2.5909e+00                  , pde-loss 5.8361e+03, initc-loss 1.2962e+04                    bc_loss 1.5917e+03, Test-Loss 2.5909e+00\n",
      "Epoch 24350, Training-Loss 7.3801e+00, Data-loss 3.0443e+00                  , pde-loss 4.4558e+03, initc-loss 1.3109e+04                    bc_loss 4.4705e+03, Test-Loss 3.0443e+00\n",
      "Epoch 24360, Training-Loss 4.4866e+00, Data-loss 1.8930e+00                  , pde-loss 5.2384e+03, initc-loss 1.2889e+04                    bc_loss 1.5290e+03, Test-Loss 1.8930e+00\n",
      "Epoch 24370, Training-Loss 4.6396e+00, Data-loss 3.1616e+00                  , pde-loss 5.1789e+03, initc-loss 1.3003e+04                    bc_loss 2.5909e+03, Test-Loss 3.1616e+00\n",
      "Epoch 24380, Training-Loss 7.0974e+00, Data-loss 2.6670e+00                  , pde-loss 5.4294e+03, initc-loss 1.2968e+04                    bc_loss 2.6616e+03, Test-Loss 2.6670e+00\n",
      "Epoch 24390, Training-Loss 5.1728e+00, Data-loss 2.5366e+00                  , pde-loss 4.4638e+03, initc-loss 1.3012e+04                    bc_loss 2.4187e+03, Test-Loss 2.5366e+00\n",
      "Epoch 24400, Training-Loss 5.0776e+00, Data-loss 1.5843e+00                  , pde-loss 4.8734e+03, initc-loss 1.2831e+04                    bc_loss 2.2202e+03, Test-Loss 1.5843e+00\n",
      "Epoch 24410, Training-Loss 3.8496e+00, Data-loss 9.7114e+00                  , pde-loss 4.5679e+03, initc-loss 1.2915e+04                    bc_loss 1.4083e+03, Test-Loss 9.7114e+00\n",
      "Epoch 24420, Training-Loss 7.0950e+00, Data-loss 3.3666e+00                  , pde-loss 7.1587e+03, initc-loss 1.2933e+04                    bc_loss 2.2837e+03, Test-Loss 3.3666e+00\n",
      "Epoch 24430, Training-Loss 4.9037e+00, Data-loss 2.0870e+00                  , pde-loss 5.0548e+03, initc-loss 1.2863e+04                    bc_loss 1.8719e+03, Test-Loss 2.0870e+00\n",
      "Epoch 24440, Training-Loss 4.3323e+00, Data-loss 2.6494e+00                  , pde-loss 3.8554e+03, initc-loss 1.2886e+04                    bc_loss 1.9017e+03, Test-Loss 2.6494e+00\n",
      "Epoch 24450, Training-Loss 5.7250e+00, Data-loss 2.4871e+00                  , pde-loss 6.0837e+03, initc-loss 1.2741e+04                    bc_loss 3.4612e+03, Test-Loss 2.4871e+00\n",
      "Epoch 24460, Training-Loss 8.3875e+00, Data-loss 3.3618e+00                  , pde-loss 5.5228e+03, initc-loss 1.2731e+04                    bc_loss 1.6270e+03, Test-Loss 3.3618e+00\n",
      "Epoch 24470, Training-Loss 7.9785e+00, Data-loss 2.7575e+00                  , pde-loss 6.1455e+03, initc-loss 1.2804e+04                    bc_loss 3.8063e+03, Test-Loss 2.7575e+00\n",
      "Epoch 24480, Training-Loss 4.9020e+00, Data-loss 2.9912e+00                  , pde-loss 7.4489e+03, initc-loss 1.2853e+04                    bc_loss 2.0520e+03, Test-Loss 2.9912e+00\n",
      "Epoch 24490, Training-Loss 4.7722e+00, Data-loss 2.5813e+00                  , pde-loss 5.3809e+03, initc-loss 1.2845e+04                    bc_loss 2.4214e+03, Test-Loss 2.5813e+00\n",
      "Epoch 24500, Training-Loss 1.1017e+01, Data-loss 3.8385e+00                  , pde-loss 6.6414e+03, initc-loss 1.2963e+04                    bc_loss 1.9192e+03, Test-Loss 3.8385e+00\n",
      "Epoch 24510, Training-Loss 4.2499e+00, Data-loss 4.7282e+00                  , pde-loss 6.5182e+03, initc-loss 1.2948e+04                    bc_loss 2.5951e+03, Test-Loss 4.7282e+00\n",
      "Epoch 24520, Training-Loss 4.8452e+00, Data-loss 1.6581e+00                  , pde-loss 6.4252e+03, initc-loss 1.2916e+04                    bc_loss 3.6013e+03, Test-Loss 1.6581e+00\n",
      "Epoch 24530, Training-Loss 7.4945e+00, Data-loss 2.0528e+00                  , pde-loss 7.0827e+03, initc-loss 1.2939e+04                    bc_loss 2.8993e+03, Test-Loss 2.0528e+00\n",
      "Epoch 24540, Training-Loss 3.6207e+00, Data-loss 2.3808e+00                  , pde-loss 4.9427e+03, initc-loss 1.2790e+04                    bc_loss 1.2663e+03, Test-Loss 2.3808e+00\n",
      "Epoch 24550, Training-Loss 5.1775e+00, Data-loss 3.3793e+00                  , pde-loss 4.5136e+03, initc-loss 1.2745e+04                    bc_loss 5.9096e+03, Test-Loss 3.3793e+00\n",
      "Epoch 24560, Training-Loss 5.9426e+00, Data-loss 2.4982e+00                  , pde-loss 5.1143e+03, initc-loss 1.2819e+04                    bc_loss 4.8381e+03, Test-Loss 2.4982e+00\n",
      "Epoch 24570, Training-Loss 4.4893e+00, Data-loss 3.3836e+00                  , pde-loss 6.2011e+03, initc-loss 1.2836e+04                    bc_loss 1.4777e+03, Test-Loss 3.3836e+00\n",
      "Epoch 24580, Training-Loss 5.4811e+00, Data-loss 2.4141e+00                  , pde-loss 5.0539e+03, initc-loss 1.2912e+04                    bc_loss 2.8319e+03, Test-Loss 2.4141e+00\n",
      "Epoch 24590, Training-Loss 4.2366e+00, Data-loss 5.7293e+00                  , pde-loss 5.4504e+03, initc-loss 1.2877e+04                    bc_loss 3.2267e+03, Test-Loss 5.7293e+00\n",
      "Epoch 24600, Training-Loss 4.8731e+00, Data-loss 1.8661e+00                  , pde-loss 5.6435e+03, initc-loss 1.3043e+04                    bc_loss 3.0533e+03, Test-Loss 1.8661e+00\n",
      "Epoch 24610, Training-Loss 4.1333e+00, Data-loss 2.1505e+00                  , pde-loss 6.1458e+03, initc-loss 1.2628e+04                    bc_loss 1.3143e+03, Test-Loss 2.1505e+00\n",
      "Epoch 24620, Training-Loss 3.9558e+00, Data-loss 3.0255e+00                  , pde-loss 4.0859e+03, initc-loss 1.2795e+04                    bc_loss 1.7051e+03, Test-Loss 3.0255e+00\n",
      "Epoch 24630, Training-Loss 6.0840e+00, Data-loss 1.5477e+00                  , pde-loss 5.5322e+03, initc-loss 1.2790e+04                    bc_loss 2.1725e+03, Test-Loss 1.5477e+00\n",
      "Epoch 24640, Training-Loss 3.5625e+00, Data-loss 2.7681e+00                  , pde-loss 4.7273e+03, initc-loss 1.2821e+04                    bc_loss 1.1026e+03, Test-Loss 2.7681e+00\n",
      "Epoch 24650, Training-Loss 4.0089e+00, Data-loss 1.8851e+00                  , pde-loss 6.8780e+03, initc-loss 1.2849e+04                    bc_loss 1.1196e+03, Test-Loss 1.8851e+00\n",
      "Epoch 24660, Training-Loss 3.3881e+00, Data-loss 1.5536e+00                  , pde-loss 5.9410e+03, initc-loss 1.2782e+04                    bc_loss 1.4988e+03, Test-Loss 1.5536e+00\n",
      "Epoch 24670, Training-Loss 4.2597e+00, Data-loss 1.9871e+00                  , pde-loss 7.1332e+03, initc-loss 1.2917e+04                    bc_loss 1.1225e+03, Test-Loss 1.9871e+00\n",
      "Epoch 24680, Training-Loss 4.2650e+00, Data-loss 1.9477e+00                  , pde-loss 4.3860e+03, initc-loss 1.3039e+04                    bc_loss 1.3047e+03, Test-Loss 1.9477e+00\n",
      "Epoch 24690, Training-Loss 4.5043e+00, Data-loss 2.2737e+00                  , pde-loss 7.5113e+03, initc-loss 1.2803e+04                    bc_loss 4.3656e+03, Test-Loss 2.2737e+00\n",
      "Epoch 24700, Training-Loss 3.5896e+00, Data-loss 2.2136e+00                  , pde-loss 4.8807e+03, initc-loss 1.3040e+04                    bc_loss 1.5426e+03, Test-Loss 2.2136e+00\n",
      "Epoch 24710, Training-Loss 3.7445e+00, Data-loss 2.2543e+00                  , pde-loss 6.3793e+03, initc-loss 1.3098e+04                    bc_loss 2.9530e+03, Test-Loss 2.2543e+00\n",
      "Epoch 24720, Training-Loss 3.6684e+00, Data-loss 2.4123e+00                  , pde-loss 4.2777e+03, initc-loss 1.2922e+04                    bc_loss 1.6456e+03, Test-Loss 2.4123e+00\n",
      "Epoch 24730, Training-Loss 5.0092e+00, Data-loss 3.4931e+00                  , pde-loss 5.5682e+03, initc-loss 1.2877e+04                    bc_loss 1.2951e+03, Test-Loss 3.4931e+00\n",
      "Epoch 24740, Training-Loss 3.7941e+00, Data-loss 2.7464e+00                  , pde-loss 6.3220e+03, initc-loss 1.2760e+04                    bc_loss 1.2251e+03, Test-Loss 2.7464e+00\n",
      "Epoch 24750, Training-Loss 4.9819e+00, Data-loss 2.7299e+00                  , pde-loss 4.6707e+03, initc-loss 1.2859e+04                    bc_loss 2.9302e+03, Test-Loss 2.7299e+00\n",
      "Epoch 24760, Training-Loss 3.4130e+00, Data-loss 1.6931e+00                  , pde-loss 5.5332e+03, initc-loss 1.2879e+04                    bc_loss 1.3492e+03, Test-Loss 1.6931e+00\n",
      "Epoch 24770, Training-Loss 7.2092e+00, Data-loss 8.4049e+00                  , pde-loss 6.3964e+03, initc-loss 1.2737e+04                    bc_loss 1.3053e+03, Test-Loss 8.4049e+00\n",
      "Epoch 24780, Training-Loss 6.1752e+00, Data-loss 1.6262e+00                  , pde-loss 5.5505e+03, initc-loss 1.2932e+04                    bc_loss 1.2126e+03, Test-Loss 1.6262e+00\n",
      "Epoch 24790, Training-Loss 5.5083e+00, Data-loss 6.7233e+00                  , pde-loss 5.6732e+03, initc-loss 1.2927e+04                    bc_loss 1.7558e+03, Test-Loss 6.7233e+00\n",
      "Epoch 24800, Training-Loss 7.4288e+00, Data-loss 7.8526e+00                  , pde-loss 5.9650e+03, initc-loss 1.2790e+04                    bc_loss 1.0322e+04, Test-Loss 7.8526e+00\n",
      "Epoch 24810, Training-Loss 3.4763e+00, Data-loss 2.9121e+00                  , pde-loss 5.1547e+03, initc-loss 1.2694e+04                    bc_loss 1.5322e+03, Test-Loss 2.9121e+00\n",
      "Epoch 24820, Training-Loss 3.3256e+00, Data-loss 8.9745e+00                  , pde-loss 4.5535e+03, initc-loss 1.2934e+04                    bc_loss 1.2953e+03, Test-Loss 8.9745e+00\n",
      "Epoch 24830, Training-Loss 4.3765e+00, Data-loss 2.7681e+00                  , pde-loss 6.0248e+03, initc-loss 1.2797e+04                    bc_loss 2.8229e+03, Test-Loss 2.7681e+00\n",
      "Epoch 24840, Training-Loss 3.4161e+00, Data-loss 5.0198e+00                  , pde-loss 5.0407e+03, initc-loss 1.2812e+04                    bc_loss 1.0418e+03, Test-Loss 5.0198e+00\n",
      "Epoch 24850, Training-Loss 3.9909e+00, Data-loss 2.0288e+00                  , pde-loss 5.3339e+03, initc-loss 1.2840e+04                    bc_loss 1.2770e+03, Test-Loss 2.0288e+00\n",
      "Epoch 24860, Training-Loss 3.7963e+00, Data-loss 2.4908e+00                  , pde-loss 6.0024e+03, initc-loss 1.2910e+04                    bc_loss 9.3643e+02, Test-Loss 2.4908e+00\n",
      "Epoch 24870, Training-Loss 4.9615e+00, Data-loss 3.0863e+00                  , pde-loss 6.2877e+03, initc-loss 1.2852e+04                    bc_loss 2.7278e+03, Test-Loss 3.0863e+00\n",
      "Epoch 24880, Training-Loss 4.3575e+00, Data-loss 2.2198e+00                  , pde-loss 8.4351e+03, initc-loss 1.2821e+04                    bc_loss 2.7012e+03, Test-Loss 2.2198e+00\n",
      "Epoch 24890, Training-Loss 6.9156e+00, Data-loss 1.8665e+00                  , pde-loss 5.6551e+03, initc-loss 1.2788e+04                    bc_loss 1.2545e+03, Test-Loss 1.8665e+00\n",
      "Epoch 24900, Training-Loss 3.7571e+00, Data-loss 2.4314e+00                  , pde-loss 5.4965e+03, initc-loss 1.2917e+04                    bc_loss 2.2049e+03, Test-Loss 2.4314e+00\n",
      "Epoch 24910, Training-Loss 3.4767e+00, Data-loss 2.3167e+00                  , pde-loss 5.1953e+03, initc-loss 1.2658e+04                    bc_loss 1.3829e+03, Test-Loss 2.3167e+00\n",
      "Epoch 24920, Training-Loss 4.4281e+00, Data-loss 1.9159e+00                  , pde-loss 4.8794e+03, initc-loss 1.2905e+04                    bc_loss 1.8698e+03, Test-Loss 1.9159e+00\n",
      "Epoch 24930, Training-Loss 4.8285e+00, Data-loss 3.6525e+00                  , pde-loss 6.2573e+03, initc-loss 1.2876e+04                    bc_loss 1.4584e+03, Test-Loss 3.6525e+00\n",
      "Epoch 24940, Training-Loss 9.0321e+00, Data-loss 1.9431e+00                  , pde-loss 5.4168e+03, initc-loss 1.2928e+04                    bc_loss 1.7916e+03, Test-Loss 1.9431e+00\n",
      "Epoch 24950, Training-Loss 4.2441e+00, Data-loss 4.2241e+00                  , pde-loss 5.1439e+03, initc-loss 1.3024e+04                    bc_loss 2.0002e+03, Test-Loss 4.2241e+00\n",
      "Epoch 24960, Training-Loss 5.0939e+00, Data-loss 2.0172e+00                  , pde-loss 6.4346e+03, initc-loss 1.2962e+04                    bc_loss 1.7931e+03, Test-Loss 2.0172e+00\n",
      "Epoch 24970, Training-Loss 4.2491e+00, Data-loss 2.2017e+00                  , pde-loss 3.9813e+03, initc-loss 1.2922e+04                    bc_loss 1.3666e+03, Test-Loss 2.2017e+00\n",
      "Epoch 24980, Training-Loss 8.7557e+00, Data-loss 2.0887e+00                  , pde-loss 6.6735e+03, initc-loss 1.3017e+04                    bc_loss 9.2004e+02, Test-Loss 2.0887e+00\n",
      "Epoch 24990, Training-Loss 8.8774e+00, Data-loss 1.8553e+00                  , pde-loss 7.6091e+03, initc-loss 1.2864e+04                    bc_loss 1.0912e+03, Test-Loss 1.8553e+00\n",
      "Epoch 25000, Training-Loss 4.2544e+00, Data-loss 2.3953e+00                  , pde-loss 5.4665e+03, initc-loss 1.2970e+04                    bc_loss 1.2681e+03, Test-Loss 2.3953e+00\n",
      "Epoch 25010, Training-Loss 5.4693e+00, Data-loss 2.3560e+00                  , pde-loss 5.2807e+03, initc-loss 1.2825e+04                    bc_loss 2.7718e+03, Test-Loss 2.3560e+00\n",
      "Epoch 25020, Training-Loss 3.0812e+00, Data-loss 2.1664e+00                  , pde-loss 5.1972e+03, initc-loss 1.2830e+04                    bc_loss 1.6200e+03, Test-Loss 2.1664e+00\n",
      "Epoch 25030, Training-Loss 3.5574e+00, Data-loss 2.2817e+00                  , pde-loss 6.2099e+03, initc-loss 1.2755e+04                    bc_loss 9.4665e+02, Test-Loss 2.2817e+00\n",
      "Epoch 25040, Training-Loss 1.1045e+01, Data-loss 2.8833e+00                  , pde-loss 7.4348e+03, initc-loss 1.2947e+04                    bc_loss 8.3841e+02, Test-Loss 2.8833e+00\n",
      "Epoch 25050, Training-Loss 3.9668e+00, Data-loss 2.3977e+00                  , pde-loss 4.6391e+03, initc-loss 1.2921e+04                    bc_loss 3.9131e+03, Test-Loss 2.3977e+00\n",
      "Epoch 25060, Training-Loss 4.6282e+00, Data-loss 2.8661e+00                  , pde-loss 7.3743e+03, initc-loss 1.2990e+04                    bc_loss 2.0570e+03, Test-Loss 2.8661e+00\n",
      "Epoch 25070, Training-Loss 4.4964e+00, Data-loss 2.4279e+00                  , pde-loss 5.4587e+03, initc-loss 1.2932e+04                    bc_loss 2.4342e+03, Test-Loss 2.4279e+00\n",
      "Epoch 25080, Training-Loss 4.6545e+00, Data-loss 2.3857e+00                  , pde-loss 5.2738e+03, initc-loss 1.2835e+04                    bc_loss 1.2893e+03, Test-Loss 2.3857e+00\n",
      "Epoch 25090, Training-Loss 3.5356e+00, Data-loss 2.3349e+00                  , pde-loss 5.2876e+03, initc-loss 1.2920e+04                    bc_loss 1.1588e+03, Test-Loss 2.3349e+00\n",
      "Epoch 25100, Training-Loss 9.7470e+00, Data-loss 2.8529e+00                  , pde-loss 3.7430e+03, initc-loss 1.3025e+04                    bc_loss 1.1640e+03, Test-Loss 2.8529e+00\n",
      "Epoch 25110, Training-Loss 3.9313e+00, Data-loss 4.4565e+00                  , pde-loss 5.8419e+03, initc-loss 1.2935e+04                    bc_loss 1.2191e+03, Test-Loss 4.4565e+00\n",
      "Epoch 25120, Training-Loss 6.1517e+00, Data-loss 5.2869e+00                  , pde-loss 5.2544e+03, initc-loss 1.2891e+04                    bc_loss 1.6362e+03, Test-Loss 5.2869e+00\n",
      "Epoch 25130, Training-Loss 5.3076e+00, Data-loss 2.0047e+00                  , pde-loss 5.7303e+03, initc-loss 1.2861e+04                    bc_loss 3.2898e+03, Test-Loss 2.0047e+00\n",
      "Epoch 25140, Training-Loss 4.2387e+00, Data-loss 1.9376e+00                  , pde-loss 4.5807e+03, initc-loss 1.2714e+04                    bc_loss 2.3715e+03, Test-Loss 1.9376e+00\n",
      "Epoch 25150, Training-Loss 4.0661e+00, Data-loss 1.6932e+00                  , pde-loss 3.8252e+03, initc-loss 1.2896e+04                    bc_loss 8.0975e+02, Test-Loss 1.6932e+00\n",
      "Epoch 25160, Training-Loss 4.3270e+00, Data-loss 6.8845e+00                  , pde-loss 7.6461e+03, initc-loss 1.2889e+04                    bc_loss 1.7478e+03, Test-Loss 6.8845e+00\n",
      "Epoch 25170, Training-Loss 4.1640e+00, Data-loss 2.1648e+00                  , pde-loss 6.4269e+03, initc-loss 1.2942e+04                    bc_loss 1.5324e+03, Test-Loss 2.1648e+00\n",
      "Epoch 25180, Training-Loss 3.9404e+00, Data-loss 4.1512e+00                  , pde-loss 5.4846e+03, initc-loss 1.2665e+04                    bc_loss 1.2917e+03, Test-Loss 4.1512e+00\n",
      "Epoch 25190, Training-Loss 9.5489e+00, Data-loss 2.7505e+00                  , pde-loss 4.3332e+03, initc-loss 1.2840e+04                    bc_loss 2.6096e+03, Test-Loss 2.7505e+00\n",
      "Epoch 25200, Training-Loss 3.8694e+00, Data-loss 1.7663e+00                  , pde-loss 6.0968e+03, initc-loss 1.3033e+04                    bc_loss 2.7894e+03, Test-Loss 1.7663e+00\n",
      "Epoch 25210, Training-Loss 4.1418e+00, Data-loss 5.1941e+00                  , pde-loss 4.8768e+03, initc-loss 1.2912e+04                    bc_loss 1.3748e+03, Test-Loss 5.1941e+00\n",
      "Epoch 25220, Training-Loss 3.5315e+00, Data-loss 9.2849e+00                  , pde-loss 5.0297e+03, initc-loss 1.2816e+04                    bc_loss 2.2177e+03, Test-Loss 9.2849e+00\n",
      "Epoch 25230, Training-Loss 3.4299e+00, Data-loss 4.9405e+00                  , pde-loss 5.0245e+03, initc-loss 1.2761e+04                    bc_loss 2.1572e+03, Test-Loss 4.9405e+00\n",
      "Epoch 25240, Training-Loss 3.5394e+00, Data-loss 5.6192e+00                  , pde-loss 6.0471e+03, initc-loss 1.2703e+04                    bc_loss 1.3836e+03, Test-Loss 5.6192e+00\n",
      "Epoch 25250, Training-Loss 3.5945e+00, Data-loss 3.6576e+00                  , pde-loss 4.5732e+03, initc-loss 1.2850e+04                    bc_loss 4.1629e+03, Test-Loss 3.6576e+00\n",
      "Epoch 25260, Training-Loss 5.2769e+00, Data-loss 1.6347e+00                  , pde-loss 5.2079e+03, initc-loss 1.2895e+04                    bc_loss 1.9425e+03, Test-Loss 1.6347e+00\n",
      "Epoch 25270, Training-Loss 4.1608e+00, Data-loss 1.6924e+00                  , pde-loss 5.4564e+03, initc-loss 1.2868e+04                    bc_loss 3.8015e+03, Test-Loss 1.6924e+00\n",
      "Epoch 25280, Training-Loss 4.5603e+00, Data-loss 1.4332e+00                  , pde-loss 6.7564e+03, initc-loss 1.2802e+04                    bc_loss 1.4545e+03, Test-Loss 1.4332e+00\n",
      "Epoch 25290, Training-Loss 3.9356e+00, Data-loss 1.4231e+00                  , pde-loss 6.1266e+03, initc-loss 1.3006e+04                    bc_loss 1.0712e+03, Test-Loss 1.4231e+00\n",
      "Epoch 25300, Training-Loss 3.8528e+00, Data-loss 2.6184e+00                  , pde-loss 4.7436e+03, initc-loss 1.2948e+04                    bc_loss 1.1000e+03, Test-Loss 2.6184e+00\n",
      "Epoch 25310, Training-Loss 3.3372e+00, Data-loss 1.5504e+00                  , pde-loss 5.2964e+03, initc-loss 1.2951e+04                    bc_loss 1.4268e+03, Test-Loss 1.5504e+00\n",
      "Epoch 25320, Training-Loss 4.2351e+00, Data-loss 1.7625e+00                  , pde-loss 5.9520e+03, initc-loss 1.2972e+04                    bc_loss 2.7306e+03, Test-Loss 1.7625e+00\n",
      "Epoch 25330, Training-Loss 3.6887e+00, Data-loss 2.8019e+00                  , pde-loss 6.1662e+03, initc-loss 1.2868e+04                    bc_loss 3.3217e+03, Test-Loss 2.8019e+00\n",
      "Epoch 25340, Training-Loss 4.7071e+00, Data-loss 3.4016e+00                  , pde-loss 6.1414e+03, initc-loss 1.2958e+04                    bc_loss 4.5896e+03, Test-Loss 3.4016e+00\n",
      "Epoch 25350, Training-Loss 4.2607e+00, Data-loss 2.0119e+00                  , pde-loss 5.8948e+03, initc-loss 1.2798e+04                    bc_loss 1.9255e+03, Test-Loss 2.0119e+00\n",
      "Epoch 25360, Training-Loss 8.1228e+00, Data-loss 2.6028e+00                  , pde-loss 6.4364e+03, initc-loss 1.2864e+04                    bc_loss 1.2093e+03, Test-Loss 2.6028e+00\n",
      "Epoch 25370, Training-Loss 4.1910e+00, Data-loss 1.8664e+00                  , pde-loss 5.2242e+03, initc-loss 1.2803e+04                    bc_loss 9.1295e+02, Test-Loss 1.8664e+00\n",
      "Epoch 25380, Training-Loss 3.8011e+00, Data-loss 1.5510e+00                  , pde-loss 6.0236e+03, initc-loss 1.2896e+04                    bc_loss 7.9116e+02, Test-Loss 1.5510e+00\n",
      "Epoch 25390, Training-Loss 4.9957e+00, Data-loss 2.0191e+00                  , pde-loss 6.1346e+03, initc-loss 1.2753e+04                    bc_loss 2.2358e+03, Test-Loss 2.0191e+00\n",
      "Epoch 25400, Training-Loss 4.0569e+00, Data-loss 1.7568e+00                  , pde-loss 5.5991e+03, initc-loss 1.2850e+04                    bc_loss 2.6765e+03, Test-Loss 1.7568e+00\n",
      "Epoch 25410, Training-Loss 4.4054e+00, Data-loss 1.6669e+00                  , pde-loss 7.0570e+03, initc-loss 1.2948e+04                    bc_loss 6.5345e+03, Test-Loss 1.6669e+00\n",
      "Epoch 25420, Training-Loss 3.8700e+00, Data-loss 1.4927e+00                  , pde-loss 6.8383e+03, initc-loss 1.2868e+04                    bc_loss 9.2527e+02, Test-Loss 1.4927e+00\n",
      "Epoch 25430, Training-Loss 3.5694e+00, Data-loss 2.5083e+00                  , pde-loss 4.6057e+03, initc-loss 1.2892e+04                    bc_loss 1.1816e+03, Test-Loss 2.5083e+00\n",
      "Epoch 25440, Training-Loss 3.5092e+00, Data-loss 2.6466e+00                  , pde-loss 5.8107e+03, initc-loss 1.2904e+04                    bc_loss 9.5872e+02, Test-Loss 2.6466e+00\n",
      "Epoch 25450, Training-Loss 3.4826e+00, Data-loss 2.1575e+00                  , pde-loss 4.4134e+03, initc-loss 1.2894e+04                    bc_loss 2.4638e+03, Test-Loss 2.1575e+00\n",
      "Epoch 25460, Training-Loss 4.1946e+00, Data-loss 2.7409e+00                  , pde-loss 4.5014e+03, initc-loss 1.2843e+04                    bc_loss 3.8991e+03, Test-Loss 2.7409e+00\n",
      "Epoch 25470, Training-Loss 6.6779e+00, Data-loss 5.0099e+00                  , pde-loss 7.9410e+03, initc-loss 1.2944e+04                    bc_loss 9.9354e+02, Test-Loss 5.0099e+00\n",
      "Epoch 25480, Training-Loss 4.1739e+00, Data-loss 1.5475e+00                  , pde-loss 7.2719e+03, initc-loss 1.2911e+04                    bc_loss 2.0613e+03, Test-Loss 1.5475e+00\n",
      "Epoch 25490, Training-Loss 4.4143e+00, Data-loss 1.9492e+00                  , pde-loss 6.8318e+03, initc-loss 1.3026e+04                    bc_loss 5.8245e+03, Test-Loss 1.9492e+00\n",
      "Epoch 25500, Training-Loss 4.3934e+00, Data-loss 2.1707e+00                  , pde-loss 6.9934e+03, initc-loss 1.2902e+04                    bc_loss 1.4589e+03, Test-Loss 2.1707e+00\n",
      "Epoch 25510, Training-Loss 3.5111e+00, Data-loss 1.9623e+00                  , pde-loss 6.7542e+03, initc-loss 1.2993e+04                    bc_loss 1.7630e+03, Test-Loss 1.9623e+00\n",
      "Epoch 25520, Training-Loss 3.9630e+00, Data-loss 1.7861e+00                  , pde-loss 5.4564e+03, initc-loss 1.2709e+04                    bc_loss 7.5876e+02, Test-Loss 1.7861e+00\n",
      "Epoch 25530, Training-Loss 3.7896e+00, Data-loss 1.7855e+00                  , pde-loss 6.4967e+03, initc-loss 1.2721e+04                    bc_loss 1.0268e+03, Test-Loss 1.7855e+00\n",
      "Epoch 25540, Training-Loss 3.6536e+00, Data-loss 1.6850e+00                  , pde-loss 4.8865e+03, initc-loss 1.2760e+04                    bc_loss 1.5081e+03, Test-Loss 1.6850e+00\n",
      "Epoch 25550, Training-Loss 3.8053e+00, Data-loss 6.8638e+00                  , pde-loss 4.7038e+03, initc-loss 1.2849e+04                    bc_loss 6.1860e+02, Test-Loss 6.8638e+00\n",
      "Epoch 25560, Training-Loss 4.6895e+00, Data-loss 2.2011e+00                  , pde-loss 6.2818e+03, initc-loss 1.2763e+04                    bc_loss 8.0094e+02, Test-Loss 2.2011e+00\n",
      "Epoch 25570, Training-Loss 3.3398e+00, Data-loss 1.4970e+00                  , pde-loss 4.3620e+03, initc-loss 1.3021e+04                    bc_loss 1.4763e+03, Test-Loss 1.4970e+00\n",
      "Epoch 25580, Training-Loss 4.3283e+00, Data-loss 1.3692e+00                  , pde-loss 5.9556e+03, initc-loss 1.2834e+04                    bc_loss 2.9784e+03, Test-Loss 1.3692e+00\n",
      "Epoch 25590, Training-Loss 3.2151e+00, Data-loss 1.9736e+00                  , pde-loss 5.4848e+03, initc-loss 1.2962e+04                    bc_loss 1.2533e+03, Test-Loss 1.9736e+00\n",
      "Epoch 25600, Training-Loss 8.4440e+00, Data-loss 2.2893e+00                  , pde-loss 5.0626e+03, initc-loss 1.2769e+04                    bc_loss 2.5323e+03, Test-Loss 2.2893e+00\n",
      "Epoch 25610, Training-Loss 3.6359e+00, Data-loss 1.8636e+00                  , pde-loss 5.2722e+03, initc-loss 1.2701e+04                    bc_loss 2.4641e+03, Test-Loss 1.8636e+00\n",
      "Epoch 25620, Training-Loss 3.7877e+00, Data-loss 3.0598e+00                  , pde-loss 5.8766e+03, initc-loss 1.2839e+04                    bc_loss 2.3955e+03, Test-Loss 3.0598e+00\n",
      "Epoch 25630, Training-Loss 3.4877e+00, Data-loss 1.5284e+00                  , pde-loss 5.8498e+03, initc-loss 1.2852e+04                    bc_loss 1.0723e+03, Test-Loss 1.5284e+00\n",
      "Epoch 25640, Training-Loss 7.7414e+00, Data-loss 2.3911e+00                  , pde-loss 6.0173e+03, initc-loss 1.2906e+04                    bc_loss 1.3261e+03, Test-Loss 2.3911e+00\n",
      "Epoch 25650, Training-Loss 3.6133e+00, Data-loss 2.2609e+00                  , pde-loss 4.8138e+03, initc-loss 1.2864e+04                    bc_loss 1.6071e+03, Test-Loss 2.2609e+00\n",
      "Epoch 25660, Training-Loss 4.4186e+00, Data-loss 2.0921e+00                  , pde-loss 4.2670e+03, initc-loss 1.3040e+04                    bc_loss 3.1681e+03, Test-Loss 2.0921e+00\n",
      "Epoch 25670, Training-Loss 8.2169e+00, Data-loss 3.6918e+00                  , pde-loss 5.8039e+03, initc-loss 1.2931e+04                    bc_loss 3.2868e+03, Test-Loss 3.6918e+00\n",
      "Epoch 25680, Training-Loss 2.9960e+00, Data-loss 1.7330e+00                  , pde-loss 5.3943e+03, initc-loss 1.2948e+04                    bc_loss 1.2127e+03, Test-Loss 1.7330e+00\n",
      "Epoch 25690, Training-Loss 2.7111e+00, Data-loss 2.5585e+00                  , pde-loss 3.7030e+03, initc-loss 1.2844e+04                    bc_loss 6.6714e+02, Test-Loss 2.5585e+00\n",
      "Epoch 25700, Training-Loss 3.1979e+00, Data-loss 2.0879e+00                  , pde-loss 5.0703e+03, initc-loss 1.2910e+04                    bc_loss 8.4531e+02, Test-Loss 2.0879e+00\n",
      "Epoch 25710, Training-Loss 3.5826e+00, Data-loss 1.8927e+00                  , pde-loss 4.5453e+03, initc-loss 1.2942e+04                    bc_loss 6.5198e+02, Test-Loss 1.8927e+00\n",
      "Epoch 25720, Training-Loss 3.6013e+00, Data-loss 1.8066e+00                  , pde-loss 5.4607e+03, initc-loss 1.2868e+04                    bc_loss 1.2293e+03, Test-Loss 1.8066e+00\n",
      "Epoch 25730, Training-Loss 3.7925e+00, Data-loss 2.0142e+00                  , pde-loss 6.7201e+03, initc-loss 1.2893e+04                    bc_loss 7.1595e+02, Test-Loss 2.0142e+00\n",
      "Epoch 25740, Training-Loss 4.1912e+00, Data-loss 1.9823e+00                  , pde-loss 4.1643e+03, initc-loss 1.3050e+04                    bc_loss 9.6267e+02, Test-Loss 1.9823e+00\n",
      "Epoch 25750, Training-Loss 3.0682e+00, Data-loss 2.3819e+00                  , pde-loss 4.5373e+03, initc-loss 1.2882e+04                    bc_loss 1.1276e+03, Test-Loss 2.3819e+00\n",
      "Epoch 25760, Training-Loss 6.7563e+00, Data-loss 1.0702e+00                  , pde-loss 7.5795e+03, initc-loss 1.3158e+04                    bc_loss 1.4425e+03, Test-Loss 1.0702e+00\n",
      "Epoch 25770, Training-Loss 7.8059e+00, Data-loss 2.3707e+00                  , pde-loss 7.5358e+03, initc-loss 1.2764e+04                    bc_loss 1.0706e+03, Test-Loss 2.3707e+00\n",
      "Epoch 25780, Training-Loss 3.7258e+00, Data-loss 3.8286e+00                  , pde-loss 4.3080e+03, initc-loss 1.2851e+04                    bc_loss 1.8341e+03, Test-Loss 3.8286e+00\n",
      "Epoch 25790, Training-Loss 3.4097e+00, Data-loss 1.4528e+00                  , pde-loss 4.6632e+03, initc-loss 1.2878e+04                    bc_loss 9.6436e+02, Test-Loss 1.4528e+00\n",
      "Epoch 25800, Training-Loss 5.5378e+00, Data-loss 3.0917e+00                  , pde-loss 3.8079e+03, initc-loss 1.2801e+04                    bc_loss 1.2836e+03, Test-Loss 3.0917e+00\n",
      "Epoch 25810, Training-Loss 4.3228e+00, Data-loss 1.3196e+00                  , pde-loss 5.9932e+03, initc-loss 1.2965e+04                    bc_loss 5.6612e+03, Test-Loss 1.3196e+00\n",
      "Epoch 25820, Training-Loss 4.3989e+00, Data-loss 1.2136e+00                  , pde-loss 5.8192e+03, initc-loss 1.2981e+04                    bc_loss 1.9318e+03, Test-Loss 1.2136e+00\n",
      "Epoch 25830, Training-Loss 3.0653e+00, Data-loss 1.7590e+00                  , pde-loss 4.3893e+03, initc-loss 1.2942e+04                    bc_loss 7.8587e+02, Test-Loss 1.7590e+00\n",
      "Epoch 25840, Training-Loss 3.7343e+00, Data-loss 5.3149e+00                  , pde-loss 5.6770e+03, initc-loss 1.2988e+04                    bc_loss 1.5276e+03, Test-Loss 5.3149e+00\n",
      "Epoch 25850, Training-Loss 4.9482e+00, Data-loss 1.7710e+00                  , pde-loss 5.7822e+03, initc-loss 1.2874e+04                    bc_loss 6.4492e+02, Test-Loss 1.7710e+00\n",
      "Epoch 25860, Training-Loss 3.0707e+00, Data-loss 1.8758e+00                  , pde-loss 4.5792e+03, initc-loss 1.2825e+04                    bc_loss 1.2408e+03, Test-Loss 1.8758e+00\n",
      "Epoch 25870, Training-Loss 3.2746e+00, Data-loss 1.5153e+00                  , pde-loss 4.0909e+03, initc-loss 1.2930e+04                    bc_loss 1.1906e+03, Test-Loss 1.5153e+00\n",
      "Epoch 25880, Training-Loss 5.2307e+00, Data-loss 4.8123e+00                  , pde-loss 4.7363e+03, initc-loss 1.2851e+04                    bc_loss 7.3479e+02, Test-Loss 4.8123e+00\n",
      "Epoch 25890, Training-Loss 3.1682e+00, Data-loss 2.0502e+00                  , pde-loss 6.4236e+03, initc-loss 1.2976e+04                    bc_loss 2.9807e+03, Test-Loss 2.0502e+00\n",
      "Epoch 25900, Training-Loss 4.5279e+00, Data-loss 1.8113e+00                  , pde-loss 6.6297e+03, initc-loss 1.2830e+04                    bc_loss 9.0300e+02, Test-Loss 1.8113e+00\n",
      "Epoch 25910, Training-Loss 5.0778e+00, Data-loss 2.7062e+00                  , pde-loss 6.0693e+03, initc-loss 1.2896e+04                    bc_loss 8.3857e+02, Test-Loss 2.7062e+00\n",
      "Epoch 25920, Training-Loss 3.4354e+00, Data-loss 1.8002e+00                  , pde-loss 5.2167e+03, initc-loss 1.2867e+04                    bc_loss 1.6319e+03, Test-Loss 1.8002e+00\n",
      "Epoch 25930, Training-Loss 6.4270e+00, Data-loss 9.0887e-01                  , pde-loss 6.3317e+03, initc-loss 1.2740e+04                    bc_loss 6.5771e+02, Test-Loss 9.0887e-01\n",
      "Epoch 25940, Training-Loss 3.6926e+00, Data-loss 1.5408e+00                  , pde-loss 5.9983e+03, initc-loss 1.2866e+04                    bc_loss 7.8769e+02, Test-Loss 1.5408e+00\n",
      "Epoch 25950, Training-Loss 4.0101e+00, Data-loss 2.4882e+00                  , pde-loss 3.5543e+03, initc-loss 1.2951e+04                    bc_loss 3.0385e+03, Test-Loss 2.4882e+00\n",
      "Epoch 25960, Training-Loss 6.1042e+00, Data-loss 1.3407e+00                  , pde-loss 6.8638e+03, initc-loss 1.2886e+04                    bc_loss 1.4448e+03, Test-Loss 1.3407e+00\n",
      "Epoch 25970, Training-Loss 4.1761e+00, Data-loss 3.0098e+00                  , pde-loss 6.0989e+03, initc-loss 1.2759e+04                    bc_loss 2.4763e+03, Test-Loss 3.0098e+00\n",
      "Epoch 25980, Training-Loss 3.1022e+00, Data-loss 1.8925e+00                  , pde-loss 4.0913e+03, initc-loss 1.2904e+04                    bc_loss 1.1091e+03, Test-Loss 1.8925e+00\n",
      "Epoch 25990, Training-Loss 3.8142e+00, Data-loss 2.0651e+00                  , pde-loss 5.1296e+03, initc-loss 1.3028e+04                    bc_loss 4.0743e+03, Test-Loss 2.0651e+00\n",
      "Epoch 26000, Training-Loss 3.5497e+00, Data-loss 1.8809e+00                  , pde-loss 4.7018e+03, initc-loss 1.2816e+04                    bc_loss 1.7936e+03, Test-Loss 1.8809e+00\n",
      "Epoch 26010, Training-Loss 3.9492e+00, Data-loss 1.8916e+00                  , pde-loss 6.2980e+03, initc-loss 1.2941e+04                    bc_loss 1.8867e+03, Test-Loss 1.8916e+00\n",
      "Epoch 26020, Training-Loss 3.4328e+00, Data-loss 2.2480e+00                  , pde-loss 4.9472e+03, initc-loss 1.2993e+04                    bc_loss 7.5241e+02, Test-Loss 2.2480e+00\n",
      "Epoch 26030, Training-Loss 3.4866e+00, Data-loss 1.3415e+00                  , pde-loss 5.9113e+03, initc-loss 1.2791e+04                    bc_loss 4.1075e+03, Test-Loss 1.3415e+00\n",
      "Epoch 26040, Training-Loss 3.0124e+00, Data-loss 2.4613e+00                  , pde-loss 4.1219e+03, initc-loss 1.2836e+04                    bc_loss 6.2990e+02, Test-Loss 2.4613e+00\n",
      "Epoch 26050, Training-Loss 4.1718e+00, Data-loss 3.3773e+00                  , pde-loss 6.6190e+03, initc-loss 1.2964e+04                    bc_loss 4.8528e+03, Test-Loss 3.3773e+00\n",
      "Epoch 26060, Training-Loss 5.4856e+00, Data-loss 3.3356e+00                  , pde-loss 4.7440e+03, initc-loss 1.2988e+04                    bc_loss 2.9186e+03, Test-Loss 3.3356e+00\n",
      "Epoch 26070, Training-Loss 3.0975e+00, Data-loss 1.8985e+00                  , pde-loss 4.7057e+03, initc-loss 1.3125e+04                    bc_loss 1.1443e+03, Test-Loss 1.8985e+00\n",
      "Epoch 26080, Training-Loss 4.5509e+00, Data-loss 1.4727e+00                  , pde-loss 6.7732e+03, initc-loss 1.3074e+04                    bc_loss 1.7117e+03, Test-Loss 1.4727e+00\n",
      "Epoch 26090, Training-Loss 3.8994e+00, Data-loss 1.3137e+00                  , pde-loss 7.9260e+03, initc-loss 1.2869e+04                    bc_loss 6.3441e+02, Test-Loss 1.3137e+00\n",
      "Epoch 26100, Training-Loss 3.0845e+00, Data-loss 1.4416e+00                  , pde-loss 5.1581e+03, initc-loss 1.2930e+04                    bc_loss 6.8085e+02, Test-Loss 1.4416e+00\n",
      "Epoch 26110, Training-Loss 3.1140e+00, Data-loss 1.5619e+00                  , pde-loss 5.3134e+03, initc-loss 1.2805e+04                    bc_loss 1.1682e+03, Test-Loss 1.5619e+00\n",
      "Epoch 26120, Training-Loss 5.5632e+00, Data-loss 1.6567e+00                  , pde-loss 5.9596e+03, initc-loss 1.2701e+04                    bc_loss 4.0539e+03, Test-Loss 1.6567e+00\n",
      "Epoch 26130, Training-Loss 3.2836e+00, Data-loss 1.2709e+00                  , pde-loss 6.5805e+03, initc-loss 1.2847e+04                    bc_loss 1.6972e+03, Test-Loss 1.2709e+00\n",
      "Epoch 26140, Training-Loss 3.6624e+00, Data-loss 9.7023e-01                  , pde-loss 5.8766e+03, initc-loss 1.2844e+04                    bc_loss 5.7122e+02, Test-Loss 9.7023e-01\n",
      "Epoch 26150, Training-Loss 3.8530e+00, Data-loss 4.6579e+00                  , pde-loss 6.2157e+03, initc-loss 1.3008e+04                    bc_loss 2.7977e+03, Test-Loss 4.6579e+00\n",
      "Epoch 26160, Training-Loss 3.5621e+00, Data-loss 1.7223e+00                  , pde-loss 6.1244e+03, initc-loss 1.2918e+04                    bc_loss 2.6271e+03, Test-Loss 1.7223e+00\n",
      "Epoch 26170, Training-Loss 3.8361e+00, Data-loss 3.9646e+00                  , pde-loss 5.6445e+03, initc-loss 1.2999e+04                    bc_loss 3.3202e+03, Test-Loss 3.9646e+00\n",
      "Epoch 26180, Training-Loss 3.7478e+00, Data-loss 2.0637e+00                  , pde-loss 5.8792e+03, initc-loss 1.2945e+04                    bc_loss 5.6011e+03, Test-Loss 2.0637e+00\n",
      "Epoch 26190, Training-Loss 3.2907e+00, Data-loss 1.3849e+00                  , pde-loss 7.5239e+03, initc-loss 1.2885e+04                    bc_loss 5.9121e+02, Test-Loss 1.3849e+00\n",
      "Epoch 26200, Training-Loss 6.8421e+00, Data-loss 1.6217e+00                  , pde-loss 6.2524e+03, initc-loss 1.2839e+04                    bc_loss 7.9495e+02, Test-Loss 1.6217e+00\n",
      "Epoch 26210, Training-Loss 3.6829e+00, Data-loss 1.1658e+00                  , pde-loss 4.8974e+03, initc-loss 1.2999e+04                    bc_loss 2.5987e+03, Test-Loss 1.1658e+00\n",
      "Epoch 26220, Training-Loss 7.8239e+00, Data-loss 2.1900e+00                  , pde-loss 7.5347e+03, initc-loss 1.2775e+04                    bc_loss 2.5673e+03, Test-Loss 2.1900e+00\n",
      "Epoch 26230, Training-Loss 3.5051e+00, Data-loss 9.7127e-01                  , pde-loss 6.2114e+03, initc-loss 1.2854e+04                    bc_loss 8.4603e+02, Test-Loss 9.7127e-01\n",
      "Epoch 26240, Training-Loss 3.6175e+00, Data-loss 4.0211e+00                  , pde-loss 4.8371e+03, initc-loss 1.2931e+04                    bc_loss 9.0887e+02, Test-Loss 4.0211e+00\n",
      "Epoch 26250, Training-Loss 7.0561e+00, Data-loss 1.7097e+00                  , pde-loss 5.2544e+03, initc-loss 1.2999e+04                    bc_loss 1.6882e+03, Test-Loss 1.7097e+00\n",
      "Epoch 26260, Training-Loss 2.8211e+00, Data-loss 1.2350e+00                  , pde-loss 4.5433e+03, initc-loss 1.2955e+04                    bc_loss 6.2550e+02, Test-Loss 1.2350e+00\n",
      "Epoch 26270, Training-Loss 3.0719e+00, Data-loss 1.8948e+00                  , pde-loss 6.4274e+03, initc-loss 1.2873e+04                    bc_loss 8.9012e+02, Test-Loss 1.8948e+00\n",
      "Epoch 26280, Training-Loss 3.3326e+00, Data-loss 1.5884e+00                  , pde-loss 4.2578e+03, initc-loss 1.2931e+04                    bc_loss 1.1874e+03, Test-Loss 1.5884e+00\n",
      "Epoch 26290, Training-Loss 3.3550e+00, Data-loss 1.4677e+00                  , pde-loss 4.0437e+03, initc-loss 1.2992e+04                    bc_loss 1.0904e+03, Test-Loss 1.4677e+00\n",
      "Epoch 26300, Training-Loss 3.0540e+00, Data-loss 1.2075e+00                  , pde-loss 5.0062e+03, initc-loss 1.3011e+04                    bc_loss 1.2194e+03, Test-Loss 1.2075e+00\n",
      "Epoch 26310, Training-Loss 2.9295e+00, Data-loss 7.8861e-01                  , pde-loss 3.9387e+03, initc-loss 1.2917e+04                    bc_loss 9.1101e+02, Test-Loss 7.8861e-01\n",
      "Epoch 26320, Training-Loss 3.2809e+00, Data-loss 1.2732e+00                  , pde-loss 5.3354e+03, initc-loss 1.2818e+04                    bc_loss 2.2633e+03, Test-Loss 1.2732e+00\n",
      "Epoch 26330, Training-Loss 3.7695e+00, Data-loss 1.2054e+00                  , pde-loss 5.4736e+03, initc-loss 1.2899e+04                    bc_loss 6.8752e+02, Test-Loss 1.2054e+00\n",
      "Epoch 26340, Training-Loss 3.6733e+00, Data-loss 1.1455e+00                  , pde-loss 6.1658e+03, initc-loss 1.2946e+04                    bc_loss 1.9297e+03, Test-Loss 1.1455e+00\n",
      "Epoch 26350, Training-Loss 4.0724e+00, Data-loss 1.6449e+00                  , pde-loss 3.9629e+03, initc-loss 1.3024e+04                    bc_loss 4.5297e+02, Test-Loss 1.6449e+00\n",
      "Epoch 26360, Training-Loss 3.6646e+00, Data-loss 1.3078e+00                  , pde-loss 6.4047e+03, initc-loss 1.2991e+04                    bc_loss 4.7484e+02, Test-Loss 1.3078e+00\n",
      "Epoch 26370, Training-Loss 4.2573e+00, Data-loss 1.3478e+00                  , pde-loss 5.0930e+03, initc-loss 1.2864e+04                    bc_loss 4.3788e+03, Test-Loss 1.3478e+00\n",
      "Epoch 26380, Training-Loss 3.2097e+00, Data-loss 2.7811e+00                  , pde-loss 4.6070e+03, initc-loss 1.2966e+04                    bc_loss 8.1928e+02, Test-Loss 2.7811e+00\n",
      "Epoch 26390, Training-Loss 4.4003e+00, Data-loss 2.2324e+00                  , pde-loss 6.0600e+03, initc-loss 1.2923e+04                    bc_loss 1.4815e+03, Test-Loss 2.2324e+00\n",
      "Epoch 26400, Training-Loss 6.7064e+00, Data-loss 1.3031e+00                  , pde-loss 4.0226e+03, initc-loss 1.2810e+04                    bc_loss 8.1228e+02, Test-Loss 1.3031e+00\n",
      "Epoch 26410, Training-Loss 3.9368e+00, Data-loss 1.1810e+00                  , pde-loss 5.5339e+03, initc-loss 1.2724e+04                    bc_loss 3.8286e+03, Test-Loss 1.1810e+00\n",
      "Epoch 26420, Training-Loss 3.0501e+00, Data-loss 1.3480e+00                  , pde-loss 5.2598e+03, initc-loss 1.3006e+04                    bc_loss 7.6211e+02, Test-Loss 1.3480e+00\n",
      "Epoch 26430, Training-Loss 3.2641e+00, Data-loss 1.4214e+00                  , pde-loss 5.0146e+03, initc-loss 1.2794e+04                    bc_loss 1.5075e+03, Test-Loss 1.4214e+00\n",
      "Epoch 26440, Training-Loss 3.3907e+00, Data-loss 2.4815e+00                  , pde-loss 4.8017e+03, initc-loss 1.2936e+04                    bc_loss 7.5743e+02, Test-Loss 2.4815e+00\n",
      "Epoch 26450, Training-Loss 3.1121e+00, Data-loss 1.3705e+00                  , pde-loss 4.5274e+03, initc-loss 1.3046e+04                    bc_loss 4.1135e+03, Test-Loss 1.3705e+00\n",
      "Epoch 26460, Training-Loss 3.1511e+00, Data-loss 1.3238e+00                  , pde-loss 5.2010e+03, initc-loss 1.2916e+04                    bc_loss 7.6320e+02, Test-Loss 1.3238e+00\n",
      "Epoch 26470, Training-Loss 3.5576e+00, Data-loss 1.4733e+00                  , pde-loss 6.1625e+03, initc-loss 1.2820e+04                    bc_loss 1.5520e+03, Test-Loss 1.4733e+00\n",
      "Epoch 26480, Training-Loss 3.4299e+00, Data-loss 1.6749e+00                  , pde-loss 6.1909e+03, initc-loss 1.2995e+04                    bc_loss 5.9493e+02, Test-Loss 1.6749e+00\n",
      "Epoch 26490, Training-Loss 5.3354e+00, Data-loss 1.2152e+00                  , pde-loss 6.5722e+03, initc-loss 1.2763e+04                    bc_loss 1.5992e+03, Test-Loss 1.2152e+00\n",
      "Epoch 26500, Training-Loss 3.6682e+00, Data-loss 4.3922e+00                  , pde-loss 4.5772e+03, initc-loss 1.2821e+04                    bc_loss 9.7433e+02, Test-Loss 4.3922e+00\n",
      "Epoch 26510, Training-Loss 2.9665e+00, Data-loss 2.6009e+00                  , pde-loss 5.0053e+03, initc-loss 1.2942e+04                    bc_loss 8.9066e+02, Test-Loss 2.6009e+00\n",
      "Epoch 26520, Training-Loss 3.5820e+00, Data-loss 3.5232e+00                  , pde-loss 6.2510e+03, initc-loss 1.2916e+04                    bc_loss 1.4119e+03, Test-Loss 3.5232e+00\n",
      "Epoch 26530, Training-Loss 2.9441e+00, Data-loss 1.8877e+00                  , pde-loss 5.9704e+03, initc-loss 1.2951e+04                    bc_loss 5.0501e+02, Test-Loss 1.8877e+00\n",
      "Epoch 26540, Training-Loss 4.8969e+00, Data-loss 8.0262e+00                  , pde-loss 4.9007e+03, initc-loss 1.2850e+04                    bc_loss 6.9518e+02, Test-Loss 8.0262e+00\n",
      "Epoch 26550, Training-Loss 3.3650e+00, Data-loss 1.7550e+00                  , pde-loss 4.7015e+03, initc-loss 1.2946e+04                    bc_loss 1.2794e+03, Test-Loss 1.7550e+00\n",
      "Epoch 26560, Training-Loss 3.6019e+00, Data-loss 1.2706e+00                  , pde-loss 4.3162e+03, initc-loss 1.2903e+04                    bc_loss 2.9446e+03, Test-Loss 1.2706e+00\n",
      "Epoch 26570, Training-Loss 3.5635e+00, Data-loss 8.7414e-01                  , pde-loss 4.7526e+03, initc-loss 1.2862e+04                    bc_loss 1.0698e+03, Test-Loss 8.7414e-01\n",
      "Epoch 26580, Training-Loss 5.2882e+00, Data-loss 1.0040e+00                  , pde-loss 3.5004e+03, initc-loss 1.3019e+04                    bc_loss 1.4384e+03, Test-Loss 1.0040e+00\n",
      "Epoch 26590, Training-Loss 3.1566e+00, Data-loss 1.0924e+00                  , pde-loss 5.9717e+03, initc-loss 1.3055e+04                    bc_loss 1.3059e+03, Test-Loss 1.0924e+00\n",
      "Epoch 26600, Training-Loss 3.6740e+00, Data-loss 1.1255e+00                  , pde-loss 6.5653e+03, initc-loss 1.2924e+04                    bc_loss 1.1598e+03, Test-Loss 1.1255e+00\n",
      "Epoch 26610, Training-Loss 4.9449e+00, Data-loss 1.4704e+00                  , pde-loss 6.8218e+03, initc-loss 1.2853e+04                    bc_loss 3.1305e+03, Test-Loss 1.4704e+00\n",
      "Epoch 26620, Training-Loss 4.9607e+00, Data-loss 9.9709e-01                  , pde-loss 6.7359e+03, initc-loss 1.2892e+04                    bc_loss 9.1609e+02, Test-Loss 9.9709e-01\n",
      "Epoch 26630, Training-Loss 3.9329e+00, Data-loss 1.2649e+00                  , pde-loss 6.2507e+03, initc-loss 1.2895e+04                    bc_loss 9.8895e+02, Test-Loss 1.2649e+00\n",
      "Epoch 26640, Training-Loss 3.0633e+00, Data-loss 1.3329e+00                  , pde-loss 5.5150e+03, initc-loss 1.2814e+04                    bc_loss 5.0528e+02, Test-Loss 1.3329e+00\n",
      "Epoch 26650, Training-Loss 3.1407e+00, Data-loss 1.6964e+00                  , pde-loss 5.5742e+03, initc-loss 1.3063e+04                    bc_loss 1.0526e+03, Test-Loss 1.6964e+00\n",
      "Epoch 26660, Training-Loss 4.1427e+00, Data-loss 1.7884e+00                  , pde-loss 7.4128e+03, initc-loss 1.2986e+04                    bc_loss 2.1772e+03, Test-Loss 1.7884e+00\n",
      "Epoch 26670, Training-Loss 2.9299e+00, Data-loss 1.7046e+00                  , pde-loss 6.0647e+03, initc-loss 1.2799e+04                    bc_loss 5.9664e+02, Test-Loss 1.7046e+00\n",
      "Epoch 26680, Training-Loss 3.7641e+00, Data-loss 1.5151e+00                  , pde-loss 5.6795e+03, initc-loss 1.2760e+04                    bc_loss 3.4829e+03, Test-Loss 1.5151e+00\n",
      "Epoch 26690, Training-Loss 4.3038e+00, Data-loss 3.4124e+00                  , pde-loss 4.4681e+03, initc-loss 1.2929e+04                    bc_loss 6.1040e+02, Test-Loss 3.4124e+00\n",
      "Epoch 26700, Training-Loss 3.0431e+00, Data-loss 8.7373e-01                  , pde-loss 4.6552e+03, initc-loss 1.2844e+04                    bc_loss 3.5132e+03, Test-Loss 8.7373e-01\n",
      "Epoch 26710, Training-Loss 3.2081e+00, Data-loss 1.2041e+00                  , pde-loss 5.0423e+03, initc-loss 1.2803e+04                    bc_loss 2.9140e+03, Test-Loss 1.2041e+00\n",
      "Epoch 26720, Training-Loss 3.7219e+00, Data-loss 8.7271e-01                  , pde-loss 7.4280e+03, initc-loss 1.2831e+04                    bc_loss 1.3324e+03, Test-Loss 8.7271e-01\n",
      "Epoch 26730, Training-Loss 3.6991e+00, Data-loss 4.8050e+00                  , pde-loss 6.0121e+03, initc-loss 1.2933e+04                    bc_loss 7.3166e+02, Test-Loss 4.8050e+00\n",
      "Epoch 26740, Training-Loss 3.0660e+00, Data-loss 1.1652e+00                  , pde-loss 5.9310e+03, initc-loss 1.2943e+04                    bc_loss 6.6793e+02, Test-Loss 1.1652e+00\n",
      "Epoch 26750, Training-Loss 3.1098e+00, Data-loss 1.7086e+00                  , pde-loss 6.2964e+03, initc-loss 1.2788e+04                    bc_loss 3.8276e+02, Test-Loss 1.7086e+00\n",
      "Epoch 26760, Training-Loss 2.8474e+00, Data-loss 1.5018e+00                  , pde-loss 4.5326e+03, initc-loss 1.2997e+04                    bc_loss 9.8763e+02, Test-Loss 1.5018e+00\n",
      "Epoch 26770, Training-Loss 7.8165e+00, Data-loss 1.3927e+00                  , pde-loss 5.9863e+03, initc-loss 1.2704e+04                    bc_loss 9.2050e+02, Test-Loss 1.3927e+00\n",
      "Epoch 26780, Training-Loss 3.9587e+00, Data-loss 1.3815e+00                  , pde-loss 4.7724e+03, initc-loss 1.2894e+04                    bc_loss 6.2778e+03, Test-Loss 1.3815e+00\n",
      "Epoch 26790, Training-Loss 3.4420e+00, Data-loss 1.7127e+00                  , pde-loss 5.5383e+03, initc-loss 1.2847e+04                    bc_loss 1.1749e+03, Test-Loss 1.7127e+00\n",
      "Epoch 26800, Training-Loss 7.0286e+00, Data-loss 2.8324e+00                  , pde-loss 5.3273e+03, initc-loss 1.3099e+04                    bc_loss 3.2456e+03, Test-Loss 2.8324e+00\n",
      "Epoch 26810, Training-Loss 3.4996e+00, Data-loss 1.9692e+00                  , pde-loss 4.9775e+03, initc-loss 1.2786e+04                    bc_loss 2.5615e+03, Test-Loss 1.9692e+00\n",
      "Epoch 26820, Training-Loss 3.4493e+00, Data-loss 1.2483e+00                  , pde-loss 5.1715e+03, initc-loss 1.3012e+04                    bc_loss 3.3659e+03, Test-Loss 1.2483e+00\n",
      "Epoch 26830, Training-Loss 5.1255e+00, Data-loss 1.2215e+00                  , pde-loss 4.8546e+03, initc-loss 1.2828e+04                    bc_loss 1.6665e+03, Test-Loss 1.2215e+00\n",
      "Epoch 26840, Training-Loss 3.0876e+00, Data-loss 1.4847e+00                  , pde-loss 5.3580e+03, initc-loss 1.2819e+04                    bc_loss 1.7300e+03, Test-Loss 1.4847e+00\n",
      "Epoch 26850, Training-Loss 5.6660e+00, Data-loss 1.4128e+00                  , pde-loss 6.0311e+03, initc-loss 1.2924e+04                    bc_loss 5.6105e+02, Test-Loss 1.4128e+00\n",
      "Epoch 26860, Training-Loss 3.0594e+00, Data-loss 1.5291e+00                  , pde-loss 5.7004e+03, initc-loss 1.2982e+04                    bc_loss 9.7459e+02, Test-Loss 1.5291e+00\n",
      "Epoch 26870, Training-Loss 2.5550e+00, Data-loss 9.3630e-01                  , pde-loss 4.9369e+03, initc-loss 1.2895e+04                    bc_loss 5.3262e+02, Test-Loss 9.3630e-01\n",
      "Epoch 26880, Training-Loss 3.4007e+00, Data-loss 2.1299e+00                  , pde-loss 5.5909e+03, initc-loss 1.2847e+04                    bc_loss 8.3549e+02, Test-Loss 2.1299e+00\n",
      "Epoch 26890, Training-Loss 3.8328e+00, Data-loss 1.5573e+00                  , pde-loss 6.6465e+03, initc-loss 1.2779e+04                    bc_loss 4.2254e+03, Test-Loss 1.5573e+00\n",
      "Epoch 26900, Training-Loss 5.1012e+00, Data-loss 7.7989e-01                  , pde-loss 9.0279e+03, initc-loss 1.2880e+04                    bc_loss 6.5994e+02, Test-Loss 7.7989e-01\n",
      "Epoch 26910, Training-Loss 3.9197e+00, Data-loss 2.7564e+00                  , pde-loss 6.0061e+03, initc-loss 1.2750e+04                    bc_loss 7.4710e+02, Test-Loss 2.7564e+00\n",
      "Epoch 26920, Training-Loss 5.7108e+00, Data-loss 8.4698e-01                  , pde-loss 5.9029e+03, initc-loss 1.2877e+04                    bc_loss 1.8927e+03, Test-Loss 8.4698e-01\n",
      "Epoch 26930, Training-Loss 2.5830e+00, Data-loss 1.7243e+00                  , pde-loss 4.0538e+03, initc-loss 1.2840e+04                    bc_loss 6.1862e+02, Test-Loss 1.7243e+00\n",
      "Epoch 26940, Training-Loss 2.7778e+00, Data-loss 2.7601e+00                  , pde-loss 5.0223e+03, initc-loss 1.2922e+04                    bc_loss 4.7846e+02, Test-Loss 2.7601e+00\n",
      "Epoch 26950, Training-Loss 5.7684e+00, Data-loss 1.2037e+00                  , pde-loss 7.2499e+03, initc-loss 1.2905e+04                    bc_loss 3.8841e+02, Test-Loss 1.2037e+00\n",
      "Epoch 26960, Training-Loss 3.4972e+00, Data-loss 2.1803e+00                  , pde-loss 6.6574e+03, initc-loss 1.2999e+04                    bc_loss 3.3212e+03, Test-Loss 2.1803e+00\n",
      "Epoch 26970, Training-Loss 3.5845e+00, Data-loss 1.7885e+00                  , pde-loss 6.3274e+03, initc-loss 1.2913e+04                    bc_loss 3.9569e+03, Test-Loss 1.7885e+00\n",
      "Epoch 26980, Training-Loss 5.7163e+00, Data-loss 1.1817e+00                  , pde-loss 6.0590e+03, initc-loss 1.3063e+04                    bc_loss 8.9554e+02, Test-Loss 1.1817e+00\n",
      "Epoch 26990, Training-Loss 3.3145e+00, Data-loss 2.5388e+00                  , pde-loss 6.1852e+03, initc-loss 1.2966e+04                    bc_loss 2.3692e+03, Test-Loss 2.5388e+00\n",
      "Epoch 27000, Training-Loss 6.2392e+00, Data-loss 1.2032e+00                  , pde-loss 5.4519e+03, initc-loss 1.2925e+04                    bc_loss 9.7144e+02, Test-Loss 1.2032e+00\n",
      "Epoch 27010, Training-Loss 3.9906e+00, Data-loss 1.2378e+00                  , pde-loss 6.5301e+03, initc-loss 1.2877e+04                    bc_loss 1.8548e+03, Test-Loss 1.2378e+00\n",
      "Epoch 27020, Training-Loss 3.6353e+00, Data-loss 1.3691e+00                  , pde-loss 6.3133e+03, initc-loss 1.2872e+04                    bc_loss 7.4445e+02, Test-Loss 1.3691e+00\n",
      "Epoch 27030, Training-Loss 2.6507e+00, Data-loss 1.0174e+00                  , pde-loss 4.7488e+03, initc-loss 1.2805e+04                    bc_loss 1.0834e+03, Test-Loss 1.0174e+00\n",
      "Epoch 27040, Training-Loss 2.9331e+00, Data-loss 1.3624e+00                  , pde-loss 5.3005e+03, initc-loss 1.2932e+04                    bc_loss 1.5302e+03, Test-Loss 1.3624e+00\n",
      "Epoch 27050, Training-Loss 2.6364e+00, Data-loss 1.9855e+00                  , pde-loss 4.0918e+03, initc-loss 1.2903e+04                    bc_loss 3.7294e+02, Test-Loss 1.9855e+00\n",
      "Epoch 27060, Training-Loss 3.2071e+00, Data-loss 2.1223e+00                  , pde-loss 5.1661e+03, initc-loss 1.2884e+04                    bc_loss 4.2056e+02, Test-Loss 2.1223e+00\n",
      "Epoch 27070, Training-Loss 2.8592e+00, Data-loss 4.9424e+00                  , pde-loss 5.1871e+03, initc-loss 1.3031e+04                    bc_loss 1.2095e+03, Test-Loss 4.9424e+00\n",
      "Epoch 27080, Training-Loss 4.1245e+00, Data-loss 1.9679e+00                  , pde-loss 5.8821e+03, initc-loss 1.2767e+04                    bc_loss 2.2042e+03, Test-Loss 1.9679e+00\n",
      "Epoch 27090, Training-Loss 6.3807e+00, Data-loss 1.2512e+00                  , pde-loss 5.2684e+03, initc-loss 1.2953e+04                    bc_loss 1.1011e+03, Test-Loss 1.2512e+00\n",
      "Epoch 27100, Training-Loss 4.5215e+00, Data-loss 1.3971e+00                  , pde-loss 6.7735e+03, initc-loss 1.2802e+04                    bc_loss 5.5994e+03, Test-Loss 1.3971e+00\n",
      "Epoch 27110, Training-Loss 2.8781e+00, Data-loss 1.0148e+00                  , pde-loss 6.5123e+03, initc-loss 1.2987e+04                    bc_loss 6.5909e+02, Test-Loss 1.0148e+00\n",
      "Epoch 27120, Training-Loss 3.3967e+00, Data-loss 2.2579e+00                  , pde-loss 6.7350e+03, initc-loss 1.2942e+04                    bc_loss 5.4783e+02, Test-Loss 2.2579e+00\n",
      "Epoch 27130, Training-Loss 3.6008e+00, Data-loss 1.2052e+00                  , pde-loss 4.7037e+03, initc-loss 1.2944e+04                    bc_loss 8.1508e+02, Test-Loss 1.2052e+00\n",
      "Epoch 27140, Training-Loss 2.9616e+00, Data-loss 1.0802e+00                  , pde-loss 4.6349e+03, initc-loss 1.2813e+04                    bc_loss 4.0735e+02, Test-Loss 1.0802e+00\n",
      "Epoch 27150, Training-Loss 3.0814e+00, Data-loss 8.4470e-01                  , pde-loss 5.3858e+03, initc-loss 1.2905e+04                    bc_loss 7.6818e+02, Test-Loss 8.4470e-01\n",
      "Epoch 27160, Training-Loss 2.8480e+00, Data-loss 8.0909e-01                  , pde-loss 4.9424e+03, initc-loss 1.2905e+04                    bc_loss 6.0776e+02, Test-Loss 8.0909e-01\n",
      "Epoch 27170, Training-Loss 3.7594e+00, Data-loss 1.2714e+00                  , pde-loss 5.9327e+03, initc-loss 1.2791e+04                    bc_loss 1.6322e+03, Test-Loss 1.2714e+00\n",
      "Epoch 27180, Training-Loss 3.0921e+00, Data-loss 3.7954e+00                  , pde-loss 6.1053e+03, initc-loss 1.3032e+04                    bc_loss 5.5492e+02, Test-Loss 3.7954e+00\n",
      "Epoch 27190, Training-Loss 3.8131e+00, Data-loss 1.2049e+00                  , pde-loss 4.7912e+03, initc-loss 1.2928e+04                    bc_loss 6.6449e+02, Test-Loss 1.2049e+00\n",
      "Epoch 27200, Training-Loss 2.8632e+00, Data-loss 1.6001e+00                  , pde-loss 5.1004e+03, initc-loss 1.2972e+04                    bc_loss 7.4908e+02, Test-Loss 1.6001e+00\n",
      "Epoch 27210, Training-Loss 3.0074e+00, Data-loss 1.7762e+00                  , pde-loss 5.3263e+03, initc-loss 1.2827e+04                    bc_loss 5.3876e+02, Test-Loss 1.7762e+00\n",
      "Epoch 27220, Training-Loss 3.7107e+00, Data-loss 1.5140e+00                  , pde-loss 5.9462e+03, initc-loss 1.2998e+04                    bc_loss 6.9533e+02, Test-Loss 1.5140e+00\n",
      "Epoch 27230, Training-Loss 3.7416e+00, Data-loss 2.1070e+00                  , pde-loss 5.4192e+03, initc-loss 1.2882e+04                    bc_loss 2.2818e+03, Test-Loss 2.1070e+00\n",
      "Epoch 27240, Training-Loss 3.3360e+00, Data-loss 1.2414e+00                  , pde-loss 4.4476e+03, initc-loss 1.2885e+04                    bc_loss 9.9347e+02, Test-Loss 1.2414e+00\n",
      "Epoch 27250, Training-Loss 4.2093e+00, Data-loss 1.3766e+00                  , pde-loss 5.7525e+03, initc-loss 1.2957e+04                    bc_loss 5.4873e+02, Test-Loss 1.3766e+00\n",
      "Epoch 27260, Training-Loss 2.8748e+00, Data-loss 8.1205e-01                  , pde-loss 4.6283e+03, initc-loss 1.3023e+04                    bc_loss 7.9123e+02, Test-Loss 8.1205e-01\n",
      "Epoch 27270, Training-Loss 3.2760e+00, Data-loss 9.0282e-01                  , pde-loss 4.6537e+03, initc-loss 1.2892e+04                    bc_loss 9.9476e+02, Test-Loss 9.0282e-01\n",
      "Epoch 27280, Training-Loss 3.7252e+00, Data-loss 1.5939e+00                  , pde-loss 5.6599e+03, initc-loss 1.3022e+04                    bc_loss 3.0710e+03, Test-Loss 1.5939e+00\n",
      "Epoch 27290, Training-Loss 3.6969e+00, Data-loss 8.6770e-01                  , pde-loss 5.4547e+03, initc-loss 1.2803e+04                    bc_loss 7.4788e+02, Test-Loss 8.6770e-01\n",
      "Epoch 27300, Training-Loss 2.9608e+00, Data-loss 2.3577e+00                  , pde-loss 6.0933e+03, initc-loss 1.3023e+04                    bc_loss 4.4376e+02, Test-Loss 2.3577e+00\n",
      "Epoch 27310, Training-Loss 2.9207e+00, Data-loss 1.2074e+00                  , pde-loss 5.9823e+03, initc-loss 1.2933e+04                    bc_loss 1.2905e+03, Test-Loss 1.2074e+00\n",
      "Epoch 27320, Training-Loss 3.4550e+00, Data-loss 1.5575e+00                  , pde-loss 4.7389e+03, initc-loss 1.2865e+04                    bc_loss 8.2080e+02, Test-Loss 1.5575e+00\n",
      "Epoch 27330, Training-Loss 2.7854e+00, Data-loss 9.4901e-01                  , pde-loss 2.9727e+03, initc-loss 1.2779e+04                    bc_loss 1.4808e+03, Test-Loss 9.4901e-01\n",
      "Epoch 27340, Training-Loss 3.7951e+00, Data-loss 8.9355e-01                  , pde-loss 5.6715e+03, initc-loss 1.2975e+04                    bc_loss 7.2230e+02, Test-Loss 8.9355e-01\n",
      "Epoch 27350, Training-Loss 4.3711e+00, Data-loss 1.6598e+00                  , pde-loss 6.2124e+03, initc-loss 1.2963e+04                    bc_loss 3.8221e+03, Test-Loss 1.6598e+00\n",
      "Epoch 27360, Training-Loss 3.2551e+00, Data-loss 1.5907e+00                  , pde-loss 4.8112e+03, initc-loss 1.2852e+04                    bc_loss 8.5193e+02, Test-Loss 1.5907e+00\n",
      "Epoch 27370, Training-Loss 2.6525e+00, Data-loss 4.4382e+00                  , pde-loss 5.6970e+03, initc-loss 1.2907e+04                    bc_loss 4.6536e+02, Test-Loss 4.4382e+00\n",
      "Epoch 27380, Training-Loss 5.1348e+00, Data-loss 7.9141e-01                  , pde-loss 4.4492e+03, initc-loss 1.2800e+04                    bc_loss 9.4181e+02, Test-Loss 7.9141e-01\n",
      "Epoch 27390, Training-Loss 3.1505e+00, Data-loss 1.5249e+00                  , pde-loss 5.3769e+03, initc-loss 1.2968e+04                    bc_loss 1.8153e+03, Test-Loss 1.5249e+00\n",
      "Epoch 27400, Training-Loss 2.7821e+00, Data-loss 1.1909e+00                  , pde-loss 5.4108e+03, initc-loss 1.2862e+04                    bc_loss 1.4638e+03, Test-Loss 1.1909e+00\n",
      "Epoch 27410, Training-Loss 3.0925e+00, Data-loss 5.4315e+00                  , pde-loss 6.6798e+03, initc-loss 1.3053e+04                    bc_loss 5.5456e+02, Test-Loss 5.4315e+00\n",
      "Epoch 27420, Training-Loss 2.8991e+00, Data-loss 1.4320e+00                  , pde-loss 5.8359e+03, initc-loss 1.2955e+04                    bc_loss 5.3855e+02, Test-Loss 1.4320e+00\n",
      "Epoch 27430, Training-Loss 3.0127e+00, Data-loss 9.7495e-01                  , pde-loss 5.9276e+03, initc-loss 1.2808e+04                    bc_loss 1.2508e+03, Test-Loss 9.7495e-01\n",
      "Epoch 27440, Training-Loss 2.7170e+00, Data-loss 2.0378e+00                  , pde-loss 5.2908e+03, initc-loss 1.2868e+04                    bc_loss 4.7788e+02, Test-Loss 2.0378e+00\n",
      "Epoch 27450, Training-Loss 3.0848e+00, Data-loss 1.1519e+00                  , pde-loss 4.4539e+03, initc-loss 1.3009e+04                    bc_loss 2.3692e+03, Test-Loss 1.1519e+00\n",
      "Epoch 27460, Training-Loss 3.7890e+00, Data-loss 1.5788e+00                  , pde-loss 6.5310e+03, initc-loss 1.2967e+04                    bc_loss 8.7765e+02, Test-Loss 1.5788e+00\n",
      "Epoch 27470, Training-Loss 3.5352e+00, Data-loss 1.7304e+00                  , pde-loss 4.1151e+03, initc-loss 1.2843e+04                    bc_loss 1.4545e+03, Test-Loss 1.7304e+00\n",
      "Epoch 27480, Training-Loss 3.2595e+00, Data-loss 7.8564e-01                  , pde-loss 7.3267e+03, initc-loss 1.2994e+04                    bc_loss 1.9995e+03, Test-Loss 7.8564e-01\n",
      "Epoch 27490, Training-Loss 3.0271e+00, Data-loss 1.5720e+00                  , pde-loss 5.1763e+03, initc-loss 1.2811e+04                    bc_loss 1.3652e+03, Test-Loss 1.5720e+00\n",
      "Epoch 27500, Training-Loss 3.2188e+00, Data-loss 1.7301e+00                  , pde-loss 4.6979e+03, initc-loss 1.2927e+04                    bc_loss 4.8727e+02, Test-Loss 1.7301e+00\n",
      "Epoch 27510, Training-Loss 2.5159e+00, Data-loss 1.9585e+00                  , pde-loss 5.2144e+03, initc-loss 1.2969e+04                    bc_loss 5.4112e+02, Test-Loss 1.9585e+00\n",
      "Epoch 27520, Training-Loss 3.8729e+00, Data-loss 1.0559e+00                  , pde-loss 3.9171e+03, initc-loss 1.2783e+04                    bc_loss 1.6118e+03, Test-Loss 1.0559e+00\n",
      "Epoch 27530, Training-Loss 3.4405e+00, Data-loss 1.5785e+00                  , pde-loss 6.7455e+03, initc-loss 1.2938e+04                    bc_loss 1.2680e+03, Test-Loss 1.5785e+00\n",
      "Epoch 27540, Training-Loss 2.9916e+00, Data-loss 3.1061e+00                  , pde-loss 5.0630e+03, initc-loss 1.3070e+04                    bc_loss 6.6985e+02, Test-Loss 3.1061e+00\n",
      "Epoch 27550, Training-Loss 4.2563e+00, Data-loss 9.6108e-01                  , pde-loss 5.1187e+03, initc-loss 1.2881e+04                    bc_loss 1.2982e+03, Test-Loss 9.6108e-01\n",
      "Epoch 27560, Training-Loss 2.7599e+00, Data-loss 2.3344e+00                  , pde-loss 4.7037e+03, initc-loss 1.2930e+04                    bc_loss 7.9779e+02, Test-Loss 2.3344e+00\n",
      "Epoch 27570, Training-Loss 4.2393e+00, Data-loss 3.6898e+00                  , pde-loss 6.3332e+03, initc-loss 1.2781e+04                    bc_loss 2.7536e+03, Test-Loss 3.6898e+00\n",
      "Epoch 27580, Training-Loss 3.0069e+00, Data-loss 1.6619e+00                  , pde-loss 5.1202e+03, initc-loss 1.2958e+04                    bc_loss 1.1863e+03, Test-Loss 1.6619e+00\n",
      "Epoch 27590, Training-Loss 3.5171e+00, Data-loss 1.4404e+00                  , pde-loss 5.8242e+03, initc-loss 1.2827e+04                    bc_loss 6.6258e+02, Test-Loss 1.4404e+00\n",
      "Epoch 27600, Training-Loss 2.9692e+00, Data-loss 5.6695e+00                  , pde-loss 5.6438e+03, initc-loss 1.2957e+04                    bc_loss 4.8708e+02, Test-Loss 5.6695e+00\n",
      "Epoch 27610, Training-Loss 3.4647e+00, Data-loss 8.3989e-01                  , pde-loss 5.8116e+03, initc-loss 1.2962e+04                    bc_loss 3.8937e+03, Test-Loss 8.3989e-01\n",
      "Epoch 27620, Training-Loss 3.3167e+00, Data-loss 9.3573e-01                  , pde-loss 5.4734e+03, initc-loss 1.2910e+04                    bc_loss 1.2143e+03, Test-Loss 9.3573e-01\n",
      "Epoch 27630, Training-Loss 5.0627e+00, Data-loss 1.0464e+00                  , pde-loss 5.7498e+03, initc-loss 1.2943e+04                    bc_loss 9.0757e+02, Test-Loss 1.0464e+00\n",
      "Epoch 27640, Training-Loss 3.8286e+00, Data-loss 2.3901e+00                  , pde-loss 5.8332e+03, initc-loss 1.2936e+04                    bc_loss 4.4379e+02, Test-Loss 2.3901e+00\n",
      "Epoch 27650, Training-Loss 3.0773e+00, Data-loss 7.8768e-01                  , pde-loss 5.7571e+03, initc-loss 1.3003e+04                    bc_loss 1.0177e+03, Test-Loss 7.8768e-01\n",
      "Epoch 27660, Training-Loss 2.6064e+00, Data-loss 1.8006e+00                  , pde-loss 5.3116e+03, initc-loss 1.2841e+04                    bc_loss 8.6433e+02, Test-Loss 1.8006e+00\n",
      "Epoch 27670, Training-Loss 2.9171e+00, Data-loss 4.6761e-01                  , pde-loss 5.3437e+03, initc-loss 1.2924e+04                    bc_loss 2.1311e+03, Test-Loss 4.6761e-01\n",
      "Epoch 27680, Training-Loss 3.6186e+00, Data-loss 8.2302e-01                  , pde-loss 5.0463e+03, initc-loss 1.2837e+04                    bc_loss 1.7236e+03, Test-Loss 8.2302e-01\n",
      "Epoch 27690, Training-Loss 2.5640e+00, Data-loss 9.4173e-01                  , pde-loss 4.1303e+03, initc-loss 1.2951e+04                    bc_loss 1.5377e+03, Test-Loss 9.4173e-01\n",
      "Epoch 27700, Training-Loss 3.3092e+00, Data-loss 7.8784e-01                  , pde-loss 4.8303e+03, initc-loss 1.2771e+04                    bc_loss 1.0561e+03, Test-Loss 7.8784e-01\n",
      "Epoch 27710, Training-Loss 3.6750e+00, Data-loss 1.3722e+00                  , pde-loss 4.9033e+03, initc-loss 1.2888e+04                    bc_loss 6.2266e+02, Test-Loss 1.3722e+00\n",
      "Epoch 27720, Training-Loss 5.7257e+00, Data-loss 1.1269e+00                  , pde-loss 6.4618e+03, initc-loss 1.2884e+04                    bc_loss 1.0577e+03, Test-Loss 1.1269e+00\n",
      "Epoch 27730, Training-Loss 2.7158e+00, Data-loss 8.7243e-01                  , pde-loss 4.7360e+03, initc-loss 1.2905e+04                    bc_loss 1.9562e+03, Test-Loss 8.7243e-01\n",
      "Epoch 27740, Training-Loss 5.0331e+00, Data-loss 1.2531e+00                  , pde-loss 5.9746e+03, initc-loss 1.2999e+04                    bc_loss 2.9707e+02, Test-Loss 1.2531e+00\n",
      "Epoch 27750, Training-Loss 3.0601e+00, Data-loss 1.2449e+00                  , pde-loss 4.6117e+03, initc-loss 1.2901e+04                    bc_loss 2.9231e+02, Test-Loss 1.2449e+00\n",
      "Epoch 27760, Training-Loss 3.6805e+00, Data-loss 7.8612e-01                  , pde-loss 6.8441e+03, initc-loss 1.3091e+04                    bc_loss 1.0839e+03, Test-Loss 7.8612e-01\n",
      "Epoch 27770, Training-Loss 3.3723e+00, Data-loss 1.2130e+00                  , pde-loss 5.7023e+03, initc-loss 1.2820e+04                    bc_loss 3.8263e+02, Test-Loss 1.2130e+00\n",
      "Epoch 27780, Training-Loss 7.1152e+00, Data-loss 8.1005e-01                  , pde-loss 6.1502e+03, initc-loss 1.3057e+04                    bc_loss 7.4611e+02, Test-Loss 8.1005e-01\n",
      "Epoch 27790, Training-Loss 3.1800e+00, Data-loss 1.7283e+00                  , pde-loss 6.1645e+03, initc-loss 1.2819e+04                    bc_loss 1.3542e+03, Test-Loss 1.7283e+00\n",
      "Epoch 27800, Training-Loss 2.6078e+00, Data-loss 1.3926e+00                  , pde-loss 4.4118e+03, initc-loss 1.3066e+04                    bc_loss 4.6924e+02, Test-Loss 1.3926e+00\n",
      "Epoch 27810, Training-Loss 3.7976e+00, Data-loss 8.3111e-01                  , pde-loss 5.3638e+03, initc-loss 1.2980e+04                    bc_loss 1.0420e+03, Test-Loss 8.3111e-01\n",
      "Epoch 27820, Training-Loss 6.1200e+00, Data-loss 8.1870e-01                  , pde-loss 6.2504e+03, initc-loss 1.2975e+04                    bc_loss 7.9315e+02, Test-Loss 8.1870e-01\n",
      "Epoch 27830, Training-Loss 4.0176e+00, Data-loss 1.0318e+00                  , pde-loss 5.9984e+03, initc-loss 1.2704e+04                    bc_loss 1.6759e+03, Test-Loss 1.0318e+00\n",
      "Epoch 27840, Training-Loss 3.4665e+00, Data-loss 8.0104e-01                  , pde-loss 7.3236e+03, initc-loss 1.3073e+04                    bc_loss 1.8980e+03, Test-Loss 8.0104e-01\n",
      "Epoch 27850, Training-Loss 2.8519e+00, Data-loss 1.1252e+00                  , pde-loss 4.8874e+03, initc-loss 1.2841e+04                    bc_loss 1.0490e+03, Test-Loss 1.1252e+00\n",
      "Epoch 27860, Training-Loss 3.9110e+00, Data-loss 1.0143e+00                  , pde-loss 6.4458e+03, initc-loss 1.2839e+04                    bc_loss 1.2507e+03, Test-Loss 1.0143e+00\n",
      "Epoch 27870, Training-Loss 2.9869e+00, Data-loss 1.2636e+00                  , pde-loss 6.1424e+03, initc-loss 1.3072e+04                    bc_loss 4.1396e+02, Test-Loss 1.2636e+00\n",
      "Epoch 27880, Training-Loss 3.2138e+00, Data-loss 2.2183e+00                  , pde-loss 5.2711e+03, initc-loss 1.2776e+04                    bc_loss 4.4748e+02, Test-Loss 2.2183e+00\n",
      "Epoch 27890, Training-Loss 2.9441e+00, Data-loss 8.7514e-01                  , pde-loss 5.8370e+03, initc-loss 1.3111e+04                    bc_loss 6.0667e+02, Test-Loss 8.7514e-01\n",
      "Epoch 27900, Training-Loss 2.7635e+00, Data-loss 2.9213e+00                  , pde-loss 5.8381e+03, initc-loss 1.2923e+04                    bc_loss 1.6790e+03, Test-Loss 2.9213e+00\n",
      "Epoch 27910, Training-Loss 2.8076e+00, Data-loss 9.5521e-01                  , pde-loss 5.7563e+03, initc-loss 1.2948e+04                    bc_loss 2.7966e+02, Test-Loss 9.5521e-01\n",
      "Epoch 27920, Training-Loss 4.1404e+00, Data-loss 8.6397e-01                  , pde-loss 6.0752e+03, initc-loss 1.2966e+04                    bc_loss 1.3253e+03, Test-Loss 8.6397e-01\n",
      "Epoch 27930, Training-Loss 3.1217e+00, Data-loss 1.0655e+00                  , pde-loss 4.0872e+03, initc-loss 1.2889e+04                    bc_loss 1.2864e+03, Test-Loss 1.0655e+00\n",
      "Epoch 27940, Training-Loss 2.8289e+00, Data-loss 1.1529e+00                  , pde-loss 6.5078e+03, initc-loss 1.2910e+04                    bc_loss 7.6767e+02, Test-Loss 1.1529e+00\n",
      "Epoch 27950, Training-Loss 3.3735e+00, Data-loss 3.2054e+00                  , pde-loss 6.7607e+03, initc-loss 1.2915e+04                    bc_loss 8.9829e+02, Test-Loss 3.2054e+00\n",
      "Epoch 27960, Training-Loss 2.9988e+00, Data-loss 1.0840e+00                  , pde-loss 5.6379e+03, initc-loss 1.3018e+04                    bc_loss 1.7910e+03, Test-Loss 1.0840e+00\n",
      "Epoch 27970, Training-Loss 2.7292e+00, Data-loss 1.0207e+00                  , pde-loss 5.2093e+03, initc-loss 1.3106e+04                    bc_loss 1.3881e+03, Test-Loss 1.0207e+00\n",
      "Epoch 27980, Training-Loss 2.5213e+00, Data-loss 9.4520e-01                  , pde-loss 3.9631e+03, initc-loss 1.2865e+04                    bc_loss 4.5324e+02, Test-Loss 9.4520e-01\n",
      "Epoch 27990, Training-Loss 3.4974e+00, Data-loss 8.4920e-01                  , pde-loss 6.2302e+03, initc-loss 1.2975e+04                    bc_loss 8.1835e+02, Test-Loss 8.4920e-01\n",
      "Epoch 28000, Training-Loss 3.1523e+00, Data-loss 1.3381e+00                  , pde-loss 6.4466e+03, initc-loss 1.2886e+04                    bc_loss 1.2293e+03, Test-Loss 1.3381e+00\n",
      "Epoch 28010, Training-Loss 3.6522e+00, Data-loss 1.2052e+00                  , pde-loss 5.7079e+03, initc-loss 1.2818e+04                    bc_loss 1.6382e+03, Test-Loss 1.2052e+00\n",
      "Epoch 28020, Training-Loss 3.8829e+00, Data-loss 7.6428e-01                  , pde-loss 9.3114e+03, initc-loss 1.2991e+04                    bc_loss 9.4087e+02, Test-Loss 7.6428e-01\n",
      "Epoch 28030, Training-Loss 2.6666e+00, Data-loss 7.5157e-01                  , pde-loss 5.6784e+03, initc-loss 1.2916e+04                    bc_loss 4.2574e+02, Test-Loss 7.5157e-01\n",
      "Epoch 28040, Training-Loss 2.7634e+00, Data-loss 7.4422e-01                  , pde-loss 6.9508e+03, initc-loss 1.2887e+04                    bc_loss 4.9326e+02, Test-Loss 7.4422e-01\n",
      "Epoch 28050, Training-Loss 2.7892e+00, Data-loss 1.9446e+00                  , pde-loss 5.6946e+03, initc-loss 1.2799e+04                    bc_loss 7.4327e+02, Test-Loss 1.9446e+00\n",
      "Epoch 28060, Training-Loss 2.5242e+00, Data-loss 6.7246e-01                  , pde-loss 4.9983e+03, initc-loss 1.2967e+04                    bc_loss 3.3027e+02, Test-Loss 6.7246e-01\n",
      "Epoch 28070, Training-Loss 2.8168e+00, Data-loss 1.6613e+00                  , pde-loss 5.5113e+03, initc-loss 1.2845e+04                    bc_loss 7.6539e+02, Test-Loss 1.6613e+00\n",
      "Epoch 28080, Training-Loss 2.8354e+00, Data-loss 2.8017e+00                  , pde-loss 5.4752e+03, initc-loss 1.2997e+04                    bc_loss 9.7463e+02, Test-Loss 2.8017e+00\n",
      "Epoch 28090, Training-Loss 3.2062e+00, Data-loss 1.4974e+00                  , pde-loss 6.6422e+03, initc-loss 1.2983e+04                    bc_loss 1.3052e+03, Test-Loss 1.4974e+00\n",
      "Epoch 28100, Training-Loss 4.5126e+00, Data-loss 1.0138e+00                  , pde-loss 5.9789e+03, initc-loss 1.2792e+04                    bc_loss 9.9778e+02, Test-Loss 1.0138e+00\n",
      "Epoch 28110, Training-Loss 3.3665e+00, Data-loss 1.5647e+00                  , pde-loss 5.7052e+03, initc-loss 1.2945e+04                    bc_loss 1.4022e+03, Test-Loss 1.5647e+00\n",
      "Epoch 28120, Training-Loss 2.6704e+00, Data-loss 6.8352e-01                  , pde-loss 4.5103e+03, initc-loss 1.2915e+04                    bc_loss 4.3154e+02, Test-Loss 6.8352e-01\n",
      "Epoch 28130, Training-Loss 3.7767e+00, Data-loss 1.6622e+00                  , pde-loss 6.9627e+03, initc-loss 1.3073e+04                    bc_loss 3.8262e+02, Test-Loss 1.6622e+00\n",
      "Epoch 28140, Training-Loss 2.8309e+00, Data-loss 9.9100e-01                  , pde-loss 5.6006e+03, initc-loss 1.2802e+04                    bc_loss 7.8649e+02, Test-Loss 9.9100e-01\n",
      "Epoch 28150, Training-Loss 2.8971e+00, Data-loss 8.5178e-01                  , pde-loss 4.5218e+03, initc-loss 1.2825e+04                    bc_loss 4.3150e+02, Test-Loss 8.5178e-01\n",
      "Epoch 28160, Training-Loss 3.1896e+00, Data-loss 5.5060e-01                  , pde-loss 6.5270e+03, initc-loss 1.2841e+04                    bc_loss 4.6044e+02, Test-Loss 5.5060e-01\n",
      "Epoch 28170, Training-Loss 2.6977e+00, Data-loss 8.2015e-01                  , pde-loss 4.7925e+03, initc-loss 1.2886e+04                    bc_loss 1.4250e+03, Test-Loss 8.2015e-01\n",
      "Epoch 28180, Training-Loss 3.5285e+00, Data-loss 7.8885e-01                  , pde-loss 5.6181e+03, initc-loss 1.2986e+04                    bc_loss 2.5228e+03, Test-Loss 7.8885e-01\n",
      "Epoch 28190, Training-Loss 3.5293e+00, Data-loss 7.2596e-01                  , pde-loss 6.7660e+03, initc-loss 1.2970e+04                    bc_loss 2.6072e+02, Test-Loss 7.2596e-01\n",
      "Epoch 28200, Training-Loss 2.8797e+00, Data-loss 9.0777e-01                  , pde-loss 7.0063e+03, initc-loss 1.3214e+04                    bc_loss 5.0292e+02, Test-Loss 9.0777e-01\n",
      "Epoch 28210, Training-Loss 3.1607e+00, Data-loss 1.3946e+00                  , pde-loss 5.7946e+03, initc-loss 1.2907e+04                    bc_loss 6.1527e+02, Test-Loss 1.3946e+00\n",
      "Epoch 28220, Training-Loss 3.7288e+00, Data-loss 8.0339e-01                  , pde-loss 7.5328e+03, initc-loss 1.2840e+04                    bc_loss 1.4065e+03, Test-Loss 8.0339e-01\n",
      "Epoch 28230, Training-Loss 2.9345e+00, Data-loss 1.4201e+00                  , pde-loss 5.9034e+03, initc-loss 1.3082e+04                    bc_loss 1.2715e+03, Test-Loss 1.4201e+00\n",
      "Epoch 28240, Training-Loss 3.0420e+00, Data-loss 5.6609e-01                  , pde-loss 4.9182e+03, initc-loss 1.2928e+04                    bc_loss 1.4213e+03, Test-Loss 5.6609e-01\n",
      "Epoch 28250, Training-Loss 2.6536e+00, Data-loss 9.0775e-01                  , pde-loss 4.8717e+03, initc-loss 1.2988e+04                    bc_loss 3.7150e+02, Test-Loss 9.0775e-01\n",
      "Epoch 28260, Training-Loss 3.3372e+00, Data-loss 6.9793e-01                  , pde-loss 6.1087e+03, initc-loss 1.2829e+04                    bc_loss 4.3918e+02, Test-Loss 6.9793e-01\n",
      "Epoch 28270, Training-Loss 3.2393e+00, Data-loss 1.7621e+00                  , pde-loss 4.6895e+03, initc-loss 1.2886e+04                    bc_loss 3.9173e+02, Test-Loss 1.7621e+00\n",
      "Epoch 28280, Training-Loss 2.9051e+00, Data-loss 1.9443e+00                  , pde-loss 5.6949e+03, initc-loss 1.2930e+04                    bc_loss 1.1545e+03, Test-Loss 1.9443e+00\n",
      "Epoch 28290, Training-Loss 2.8536e+00, Data-loss 6.1030e-01                  , pde-loss 5.3582e+03, initc-loss 1.2868e+04                    bc_loss 1.9083e+03, Test-Loss 6.1030e-01\n",
      "Epoch 28300, Training-Loss 2.8812e+00, Data-loss 2.1367e+00                  , pde-loss 6.5734e+03, initc-loss 1.2971e+04                    bc_loss 6.3743e+02, Test-Loss 2.1367e+00\n",
      "Epoch 28310, Training-Loss 3.1446e+00, Data-loss 1.3480e+00                  , pde-loss 4.2985e+03, initc-loss 1.3056e+04                    bc_loss 1.7640e+03, Test-Loss 1.3480e+00\n",
      "Epoch 28320, Training-Loss 2.7311e+00, Data-loss 5.9688e-01                  , pde-loss 4.8621e+03, initc-loss 1.3042e+04                    bc_loss 7.4151e+02, Test-Loss 5.9688e-01\n",
      "Epoch 28330, Training-Loss 2.7356e+00, Data-loss 6.3050e-01                  , pde-loss 6.0741e+03, initc-loss 1.2935e+04                    bc_loss 2.0229e+03, Test-Loss 6.3050e-01\n",
      "Epoch 28340, Training-Loss 3.1091e+00, Data-loss 7.8848e-01                  , pde-loss 5.3281e+03, initc-loss 1.2934e+04                    bc_loss 1.3609e+03, Test-Loss 7.8848e-01\n",
      "Epoch 28350, Training-Loss 2.9903e+00, Data-loss 1.3599e+00                  , pde-loss 4.2946e+03, initc-loss 1.2977e+04                    bc_loss 7.3958e+02, Test-Loss 1.3599e+00\n",
      "Epoch 28360, Training-Loss 3.3000e+00, Data-loss 1.3947e+00                  , pde-loss 6.7949e+03, initc-loss 1.2764e+04                    bc_loss 7.1264e+02, Test-Loss 1.3947e+00\n",
      "Epoch 28370, Training-Loss 2.9945e+00, Data-loss 6.3793e-01                  , pde-loss 5.2428e+03, initc-loss 1.3094e+04                    bc_loss 5.2594e+02, Test-Loss 6.3793e-01\n",
      "Epoch 28380, Training-Loss 2.9579e+00, Data-loss 7.1072e-01                  , pde-loss 6.6389e+03, initc-loss 1.2875e+04                    bc_loss 7.2407e+02, Test-Loss 7.1072e-01\n",
      "Epoch 28390, Training-Loss 2.7415e+00, Data-loss 4.9588e-01                  , pde-loss 4.3496e+03, initc-loss 1.2752e+04                    bc_loss 3.7380e+03, Test-Loss 4.9588e-01\n",
      "Epoch 28400, Training-Loss 2.8463e+00, Data-loss 8.2673e-01                  , pde-loss 7.5084e+03, initc-loss 1.2876e+04                    bc_loss 4.3349e+02, Test-Loss 8.2673e-01\n",
      "Epoch 28410, Training-Loss 3.5811e+00, Data-loss 7.8686e-01                  , pde-loss 5.9588e+03, initc-loss 1.2949e+04                    bc_loss 3.8382e+02, Test-Loss 7.8686e-01\n",
      "Epoch 28420, Training-Loss 2.8830e+00, Data-loss 1.1269e+00                  , pde-loss 5.5718e+03, initc-loss 1.2974e+04                    bc_loss 1.2969e+03, Test-Loss 1.1269e+00\n",
      "Epoch 28430, Training-Loss 3.0647e+00, Data-loss 1.0499e+00                  , pde-loss 4.7534e+03, initc-loss 1.2810e+04                    bc_loss 3.8251e+03, Test-Loss 1.0499e+00\n",
      "Epoch 28440, Training-Loss 2.9734e+00, Data-loss 1.0510e+00                  , pde-loss 6.0335e+03, initc-loss 1.3093e+04                    bc_loss 2.1513e+03, Test-Loss 1.0510e+00\n",
      "Epoch 28450, Training-Loss 3.3952e+00, Data-loss 9.4569e-01                  , pde-loss 6.8747e+03, initc-loss 1.2875e+04                    bc_loss 3.8182e+03, Test-Loss 9.4569e-01\n",
      "Epoch 28460, Training-Loss 3.1577e+00, Data-loss 1.0602e+00                  , pde-loss 5.2272e+03, initc-loss 1.2922e+04                    bc_loss 1.3198e+03, Test-Loss 1.0602e+00\n",
      "Epoch 28470, Training-Loss 2.7574e+00, Data-loss 1.1381e+00                  , pde-loss 4.0919e+03, initc-loss 1.2935e+04                    bc_loss 8.5404e+02, Test-Loss 1.1381e+00\n",
      "Epoch 28480, Training-Loss 2.3117e+00, Data-loss 1.2224e+00                  , pde-loss 4.9054e+03, initc-loss 1.2932e+04                    bc_loss 5.5756e+02, Test-Loss 1.2224e+00\n",
      "Epoch 28490, Training-Loss 2.7569e+00, Data-loss 9.2621e-01                  , pde-loss 5.5268e+03, initc-loss 1.2960e+04                    bc_loss 7.7771e+02, Test-Loss 9.2621e-01\n",
      "Epoch 28500, Training-Loss 2.2236e+00, Data-loss 7.2742e-01                  , pde-loss 4.4819e+03, initc-loss 1.2934e+04                    bc_loss 3.0065e+02, Test-Loss 7.2742e-01\n",
      "Epoch 28510, Training-Loss 2.9593e+00, Data-loss 6.3640e-01                  , pde-loss 4.0185e+03, initc-loss 1.3008e+04                    bc_loss 1.2580e+03, Test-Loss 6.3640e-01\n",
      "Epoch 28520, Training-Loss 2.7650e+00, Data-loss 1.0540e+00                  , pde-loss 5.2611e+03, initc-loss 1.2916e+04                    bc_loss 8.6487e+02, Test-Loss 1.0540e+00\n",
      "Epoch 28530, Training-Loss 4.2981e+00, Data-loss 4.4017e-01                  , pde-loss 4.7870e+03, initc-loss 1.2857e+04                    bc_loss 3.7131e+02, Test-Loss 4.4017e-01\n",
      "Epoch 28540, Training-Loss 3.7995e+00, Data-loss 1.5507e+00                  , pde-loss 5.3704e+03, initc-loss 1.2883e+04                    bc_loss 3.6390e+03, Test-Loss 1.5507e+00\n",
      "Epoch 28550, Training-Loss 4.6051e+00, Data-loss 9.7377e-01                  , pde-loss 7.8282e+03, initc-loss 1.2974e+04                    bc_loss 2.1067e+03, Test-Loss 9.7377e-01\n",
      "Epoch 28560, Training-Loss 2.7690e+00, Data-loss 8.0107e-01                  , pde-loss 6.2772e+03, initc-loss 1.2821e+04                    bc_loss 7.5680e+02, Test-Loss 8.0107e-01\n",
      "Epoch 28570, Training-Loss 3.0391e+00, Data-loss 1.4764e+00                  , pde-loss 7.0783e+03, initc-loss 1.2981e+04                    bc_loss 8.4400e+02, Test-Loss 1.4764e+00\n",
      "Epoch 28580, Training-Loss 2.8789e+00, Data-loss 1.0963e+00                  , pde-loss 5.3308e+03, initc-loss 1.2859e+04                    bc_loss 6.7436e+02, Test-Loss 1.0963e+00\n",
      "Epoch 28590, Training-Loss 2.3682e+00, Data-loss 1.0605e+00                  , pde-loss 4.6427e+03, initc-loss 1.3016e+04                    bc_loss 5.9284e+02, Test-Loss 1.0605e+00\n",
      "Epoch 28600, Training-Loss 2.6891e+00, Data-loss 1.1329e+00                  , pde-loss 5.0624e+03, initc-loss 1.2825e+04                    bc_loss 3.8450e+02, Test-Loss 1.1329e+00\n",
      "Epoch 28610, Training-Loss 2.6697e+00, Data-loss 1.2717e+00                  , pde-loss 6.8374e+03, initc-loss 1.2982e+04                    bc_loss 2.2227e+02, Test-Loss 1.2717e+00\n",
      "Epoch 28620, Training-Loss 2.7262e+00, Data-loss 7.2188e-01                  , pde-loss 4.7943e+03, initc-loss 1.2918e+04                    bc_loss 4.0809e+02, Test-Loss 7.2188e-01\n",
      "Epoch 28630, Training-Loss 3.4048e+00, Data-loss 7.7440e-01                  , pde-loss 4.8797e+03, initc-loss 1.2977e+04                    bc_loss 1.0580e+03, Test-Loss 7.7440e-01\n",
      "Epoch 28640, Training-Loss 3.2696e+00, Data-loss 8.7133e-01                  , pde-loss 6.1564e+03, initc-loss 1.2865e+04                    bc_loss 1.6353e+03, Test-Loss 8.7133e-01\n",
      "Epoch 28650, Training-Loss 4.2114e+00, Data-loss 7.7100e-01                  , pde-loss 5.8380e+03, initc-loss 1.2982e+04                    bc_loss 5.0776e+02, Test-Loss 7.7100e-01\n",
      "Epoch 28660, Training-Loss 2.8908e+00, Data-loss 8.5805e-01                  , pde-loss 6.7089e+03, initc-loss 1.2949e+04                    bc_loss 5.0378e+02, Test-Loss 8.5805e-01\n",
      "Epoch 28670, Training-Loss 2.7576e+00, Data-loss 9.3363e-01                  , pde-loss 4.5204e+03, initc-loss 1.2943e+04                    bc_loss 5.9577e+02, Test-Loss 9.3363e-01\n",
      "Epoch 28680, Training-Loss 2.7260e+00, Data-loss 5.8359e-01                  , pde-loss 5.0713e+03, initc-loss 1.2948e+04                    bc_loss 4.7843e+02, Test-Loss 5.8359e-01\n",
      "Epoch 28690, Training-Loss 2.7588e+00, Data-loss 8.7018e-01                  , pde-loss 4.8265e+03, initc-loss 1.2864e+04                    bc_loss 2.5231e+03, Test-Loss 8.7018e-01\n",
      "Epoch 28700, Training-Loss 3.0005e+00, Data-loss 1.3121e+00                  , pde-loss 5.8006e+03, initc-loss 1.2984e+04                    bc_loss 3.1681e+03, Test-Loss 1.3121e+00\n",
      "Epoch 28710, Training-Loss 5.0950e+00, Data-loss 1.0806e+00                  , pde-loss 5.9097e+03, initc-loss 1.3097e+04                    bc_loss 1.5471e+03, Test-Loss 1.0806e+00\n",
      "Epoch 28720, Training-Loss 3.9458e+00, Data-loss 6.0259e-01                  , pde-loss 6.7794e+03, initc-loss 1.2932e+04                    bc_loss 1.5134e+03, Test-Loss 6.0259e-01\n",
      "Epoch 28730, Training-Loss 3.2269e+00, Data-loss 1.4389e+00                  , pde-loss 6.6075e+03, initc-loss 1.2958e+04                    bc_loss 1.1940e+03, Test-Loss 1.4389e+00\n",
      "Epoch 28740, Training-Loss 3.2946e+00, Data-loss 1.9824e+00                  , pde-loss 6.8722e+03, initc-loss 1.2889e+04                    bc_loss 5.3475e+02, Test-Loss 1.9824e+00\n",
      "Epoch 28750, Training-Loss 2.8322e+00, Data-loss 7.4193e-01                  , pde-loss 5.7962e+03, initc-loss 1.2950e+04                    bc_loss 1.1080e+03, Test-Loss 7.4193e-01\n",
      "Epoch 28760, Training-Loss 3.1128e+00, Data-loss 1.3801e+00                  , pde-loss 4.4947e+03, initc-loss 1.2938e+04                    bc_loss 3.2927e+02, Test-Loss 1.3801e+00\n",
      "Epoch 28770, Training-Loss 3.0314e+00, Data-loss 6.9688e-01                  , pde-loss 5.6235e+03, initc-loss 1.2951e+04                    bc_loss 1.1915e+03, Test-Loss 6.9688e-01\n",
      "Epoch 28780, Training-Loss 3.1213e+00, Data-loss 6.3796e-01                  , pde-loss 5.5357e+03, initc-loss 1.2876e+04                    bc_loss 8.1473e+02, Test-Loss 6.3796e-01\n",
      "Epoch 28790, Training-Loss 2.5782e+00, Data-loss 5.8911e-01                  , pde-loss 5.3633e+03, initc-loss 1.3015e+04                    bc_loss 9.7097e+02, Test-Loss 5.8911e-01\n",
      "Epoch 28800, Training-Loss 2.9748e+00, Data-loss 7.7532e-01                  , pde-loss 6.0086e+03, initc-loss 1.2822e+04                    bc_loss 1.5711e+03, Test-Loss 7.7532e-01\n",
      "Epoch 28810, Training-Loss 2.5984e+00, Data-loss 8.8002e-01                  , pde-loss 5.7675e+03, initc-loss 1.2952e+04                    bc_loss 2.9376e+02, Test-Loss 8.8002e-01\n",
      "Epoch 28820, Training-Loss 2.8988e+00, Data-loss 3.5887e+00                  , pde-loss 6.2792e+03, initc-loss 1.2977e+04                    bc_loss 3.6830e+02, Test-Loss 3.5887e+00\n",
      "Epoch 28830, Training-Loss 2.8745e+00, Data-loss 2.1962e+00                  , pde-loss 6.9230e+03, initc-loss 1.3091e+04                    bc_loss 7.4967e+02, Test-Loss 2.1962e+00\n",
      "Epoch 28840, Training-Loss 2.8010e+00, Data-loss 1.0058e+00                  , pde-loss 6.8621e+03, initc-loss 1.2934e+04                    bc_loss 3.4739e+02, Test-Loss 1.0058e+00\n",
      "Epoch 28850, Training-Loss 2.5387e+00, Data-loss 1.2429e+00                  , pde-loss 4.4283e+03, initc-loss 1.2824e+04                    bc_loss 1.2554e+03, Test-Loss 1.2429e+00\n",
      "Epoch 28860, Training-Loss 2.8958e+00, Data-loss 1.3849e+00                  , pde-loss 6.6063e+03, initc-loss 1.2789e+04                    bc_loss 2.4797e+02, Test-Loss 1.3849e+00\n",
      "Epoch 28870, Training-Loss 3.9879e+00, Data-loss 6.4128e-01                  , pde-loss 6.0446e+03, initc-loss 1.2887e+04                    bc_loss 1.4781e+03, Test-Loss 6.4128e-01\n",
      "Epoch 28880, Training-Loss 2.8969e+00, Data-loss 8.0294e-01                  , pde-loss 6.8088e+03, initc-loss 1.2860e+04                    bc_loss 1.5939e+03, Test-Loss 8.0294e-01\n",
      "Epoch 28890, Training-Loss 2.4756e+00, Data-loss 1.0065e+00                  , pde-loss 5.5968e+03, initc-loss 1.2984e+04                    bc_loss 2.9517e+02, Test-Loss 1.0065e+00\n",
      "Epoch 28900, Training-Loss 2.4180e+00, Data-loss 7.2351e-01                  , pde-loss 4.3957e+03, initc-loss 1.2950e+04                    bc_loss 5.0935e+02, Test-Loss 7.2351e-01\n",
      "Epoch 28910, Training-Loss 2.8553e+00, Data-loss 8.8021e-01                  , pde-loss 5.3394e+03, initc-loss 1.2852e+04                    bc_loss 2.6999e+02, Test-Loss 8.8021e-01\n",
      "Epoch 28920, Training-Loss 2.2329e+00, Data-loss 6.7330e-01                  , pde-loss 4.1007e+03, initc-loss 1.2886e+04                    bc_loss 5.0359e+02, Test-Loss 6.7330e-01\n",
      "Epoch 28930, Training-Loss 2.8497e+00, Data-loss 6.1395e-01                  , pde-loss 4.3944e+03, initc-loss 1.2841e+04                    bc_loss 1.3036e+03, Test-Loss 6.1395e-01\n",
      "Epoch 28940, Training-Loss 2.8086e+00, Data-loss 9.9449e-01                  , pde-loss 5.0824e+03, initc-loss 1.3044e+04                    bc_loss 8.5112e+02, Test-Loss 9.9449e-01\n",
      "Epoch 28950, Training-Loss 2.7315e+00, Data-loss 6.8742e-01                  , pde-loss 6.1895e+03, initc-loss 1.2897e+04                    bc_loss 1.2530e+03, Test-Loss 6.8742e-01\n",
      "Epoch 28960, Training-Loss 3.3140e+00, Data-loss 1.6344e+00                  , pde-loss 5.6661e+03, initc-loss 1.2757e+04                    bc_loss 4.1141e+02, Test-Loss 1.6344e+00\n",
      "Epoch 28970, Training-Loss 3.2470e+00, Data-loss 8.9155e-01                  , pde-loss 6.8345e+03, initc-loss 1.2967e+04                    bc_loss 5.1164e+02, Test-Loss 8.9155e-01\n",
      "Epoch 28980, Training-Loss 2.5335e+00, Data-loss 7.0354e-01                  , pde-loss 5.3881e+03, initc-loss 1.2831e+04                    bc_loss 7.9246e+02, Test-Loss 7.0354e-01\n",
      "Epoch 28990, Training-Loss 3.3657e+00, Data-loss 8.1741e-01                  , pde-loss 5.8289e+03, initc-loss 1.2970e+04                    bc_loss 3.2752e+02, Test-Loss 8.1741e-01\n",
      "Epoch 29000, Training-Loss 3.4900e+00, Data-loss 6.3854e-01                  , pde-loss 7.9505e+03, initc-loss 1.3036e+04                    bc_loss 8.1727e+02, Test-Loss 6.3854e-01\n",
      "Epoch 29010, Training-Loss 2.8760e+00, Data-loss 2.1074e+00                  , pde-loss 6.3330e+03, initc-loss 1.2793e+04                    bc_loss 6.6335e+02, Test-Loss 2.1074e+00\n",
      "Epoch 29020, Training-Loss 2.7840e+00, Data-loss 9.5672e-01                  , pde-loss 5.1582e+03, initc-loss 1.3031e+04                    bc_loss 4.2104e+02, Test-Loss 9.5672e-01\n",
      "Epoch 29030, Training-Loss 2.5301e+00, Data-loss 8.4913e-01                  , pde-loss 6.2637e+03, initc-loss 1.2950e+04                    bc_loss 8.3992e+02, Test-Loss 8.4913e-01\n",
      "Epoch 29040, Training-Loss 2.6331e+00, Data-loss 8.7893e-01                  , pde-loss 5.0711e+03, initc-loss 1.2852e+04                    bc_loss 2.8111e+02, Test-Loss 8.7893e-01\n",
      "Epoch 29050, Training-Loss 3.3425e+00, Data-loss 7.9167e-01                  , pde-loss 4.7315e+03, initc-loss 1.2950e+04                    bc_loss 5.6355e+02, Test-Loss 7.9167e-01\n",
      "Epoch 29060, Training-Loss 2.5760e+00, Data-loss 7.8524e-01                  , pde-loss 4.9051e+03, initc-loss 1.2880e+04                    bc_loss 6.5408e+02, Test-Loss 7.8524e-01\n",
      "Epoch 29070, Training-Loss 2.4688e+00, Data-loss 6.4527e-01                  , pde-loss 6.0413e+03, initc-loss 1.2969e+04                    bc_loss 3.2922e+02, Test-Loss 6.4527e-01\n",
      "Epoch 29080, Training-Loss 2.5973e+00, Data-loss 8.9146e-01                  , pde-loss 5.1213e+03, initc-loss 1.2785e+04                    bc_loss 3.0329e+02, Test-Loss 8.9146e-01\n",
      "Epoch 29090, Training-Loss 3.4822e+00, Data-loss 7.7102e-01                  , pde-loss 5.6780e+03, initc-loss 1.2999e+04                    bc_loss 4.3875e+02, Test-Loss 7.7102e-01\n",
      "Epoch 29100, Training-Loss 3.4484e+00, Data-loss 9.3730e-01                  , pde-loss 6.0301e+03, initc-loss 1.2863e+04                    bc_loss 1.0636e+03, Test-Loss 9.3730e-01\n",
      "Epoch 29110, Training-Loss 2.5801e+00, Data-loss 8.0438e-01                  , pde-loss 4.2299e+03, initc-loss 1.2866e+04                    bc_loss 3.3862e+02, Test-Loss 8.0438e-01\n",
      "Epoch 29120, Training-Loss 2.9729e+00, Data-loss 1.4147e+00                  , pde-loss 5.1514e+03, initc-loss 1.2925e+04                    bc_loss 5.1821e+02, Test-Loss 1.4147e+00\n",
      "Epoch 29130, Training-Loss 5.4040e+00, Data-loss 8.5454e-01                  , pde-loss 7.1018e+03, initc-loss 1.2904e+04                    bc_loss 5.1356e+03, Test-Loss 8.5454e-01\n",
      "Epoch 29140, Training-Loss 3.5121e+00, Data-loss 7.6173e-01                  , pde-loss 5.5461e+03, initc-loss 1.2730e+04                    bc_loss 1.9796e+03, Test-Loss 7.6173e-01\n",
      "Epoch 29150, Training-Loss 2.5564e+00, Data-loss 1.5060e+00                  , pde-loss 4.7116e+03, initc-loss 1.2882e+04                    bc_loss 1.1854e+03, Test-Loss 1.5060e+00\n",
      "Epoch 29160, Training-Loss 3.2771e+00, Data-loss 7.8914e-01                  , pde-loss 5.7314e+03, initc-loss 1.3050e+04                    bc_loss 6.0709e+02, Test-Loss 7.8914e-01\n",
      "Epoch 29170, Training-Loss 2.5570e+00, Data-loss 1.1665e+00                  , pde-loss 5.8401e+03, initc-loss 1.2820e+04                    bc_loss 2.0565e+02, Test-Loss 1.1665e+00\n",
      "Epoch 29180, Training-Loss 2.3461e+00, Data-loss 1.0251e+00                  , pde-loss 4.7389e+03, initc-loss 1.3071e+04                    bc_loss 1.2008e+03, Test-Loss 1.0251e+00\n",
      "Epoch 29190, Training-Loss 3.0587e+00, Data-loss 8.1873e-01                  , pde-loss 5.1438e+03, initc-loss 1.3030e+04                    bc_loss 9.3952e+02, Test-Loss 8.1873e-01\n",
      "Epoch 29200, Training-Loss 3.1728e+00, Data-loss 2.1581e+00                  , pde-loss 5.4324e+03, initc-loss 1.2879e+04                    bc_loss 1.4076e+03, Test-Loss 2.1581e+00\n",
      "Epoch 29210, Training-Loss 3.2475e+00, Data-loss 1.4098e+00                  , pde-loss 6.2195e+03, initc-loss 1.3084e+04                    bc_loss 2.3871e+02, Test-Loss 1.4098e+00\n",
      "Epoch 29220, Training-Loss 3.6477e+00, Data-loss 8.2289e-01                  , pde-loss 5.3936e+03, initc-loss 1.2865e+04                    bc_loss 2.0149e+02, Test-Loss 8.2289e-01\n",
      "Epoch 29230, Training-Loss 2.6793e+00, Data-loss 1.2672e+00                  , pde-loss 5.3876e+03, initc-loss 1.2792e+04                    bc_loss 3.7444e+02, Test-Loss 1.2672e+00\n",
      "Epoch 29240, Training-Loss 2.8736e+00, Data-loss 7.0964e-01                  , pde-loss 6.3180e+03, initc-loss 1.2891e+04                    bc_loss 1.0228e+03, Test-Loss 7.0964e-01\n",
      "Epoch 29250, Training-Loss 2.6311e+00, Data-loss 9.5511e-01                  , pde-loss 5.8378e+03, initc-loss 1.2973e+04                    bc_loss 1.3428e+03, Test-Loss 9.5511e-01\n",
      "Epoch 29260, Training-Loss 2.7388e+00, Data-loss 7.5342e-01                  , pde-loss 6.1675e+03, initc-loss 1.2821e+04                    bc_loss 1.0057e+03, Test-Loss 7.5342e-01\n",
      "Epoch 29270, Training-Loss 2.1951e+00, Data-loss 1.1812e+00                  , pde-loss 5.0105e+03, initc-loss 1.3005e+04                    bc_loss 2.5280e+02, Test-Loss 1.1812e+00\n",
      "Epoch 29280, Training-Loss 3.0228e+00, Data-loss 6.6687e-01                  , pde-loss 4.8465e+03, initc-loss 1.3001e+04                    bc_loss 2.2062e+03, Test-Loss 6.6687e-01\n",
      "Epoch 29290, Training-Loss 3.2333e+00, Data-loss 5.6063e-01                  , pde-loss 7.0709e+03, initc-loss 1.2958e+04                    bc_loss 4.8074e+02, Test-Loss 5.6063e-01\n",
      "Epoch 29300, Training-Loss 2.7756e+00, Data-loss 1.1824e+00                  , pde-loss 5.8051e+03, initc-loss 1.3072e+04                    bc_loss 5.6593e+02, Test-Loss 1.1824e+00\n",
      "Epoch 29310, Training-Loss 2.7125e+00, Data-loss 9.6555e-01                  , pde-loss 6.0861e+03, initc-loss 1.2840e+04                    bc_loss 1.0173e+03, Test-Loss 9.6555e-01\n",
      "Epoch 29320, Training-Loss 3.0107e+00, Data-loss 8.1167e-01                  , pde-loss 5.8947e+03, initc-loss 1.2996e+04                    bc_loss 3.8730e+02, Test-Loss 8.1167e-01\n",
      "Epoch 29330, Training-Loss 2.6085e+00, Data-loss 2.0499e+00                  , pde-loss 5.0490e+03, initc-loss 1.2942e+04                    bc_loss 2.9944e+02, Test-Loss 2.0499e+00\n",
      "Epoch 29340, Training-Loss 2.5329e+00, Data-loss 7.7782e-01                  , pde-loss 5.5376e+03, initc-loss 1.2982e+04                    bc_loss 3.7662e+02, Test-Loss 7.7782e-01\n",
      "Epoch 29350, Training-Loss 2.7679e+00, Data-loss 5.4198e-01                  , pde-loss 6.3930e+03, initc-loss 1.2900e+04                    bc_loss 7.6768e+02, Test-Loss 5.4198e-01\n",
      "Epoch 29360, Training-Loss 2.7272e+00, Data-loss 1.8480e+00                  , pde-loss 6.3649e+03, initc-loss 1.3001e+04                    bc_loss 6.9036e+02, Test-Loss 1.8480e+00\n",
      "Epoch 29370, Training-Loss 3.3938e+00, Data-loss 6.7130e-01                  , pde-loss 4.5969e+03, initc-loss 1.2910e+04                    bc_loss 1.8926e+03, Test-Loss 6.7130e-01\n",
      "Epoch 29380, Training-Loss 3.2670e+00, Data-loss 1.1668e+00                  , pde-loss 7.1432e+03, initc-loss 1.3007e+04                    bc_loss 2.7185e+03, Test-Loss 1.1668e+00\n",
      "Epoch 29390, Training-Loss 3.6089e+00, Data-loss 5.1970e-01                  , pde-loss 6.8177e+03, initc-loss 1.2931e+04                    bc_loss 1.0909e+03, Test-Loss 5.1970e-01\n",
      "Epoch 29400, Training-Loss 2.9225e+00, Data-loss 1.2588e+00                  , pde-loss 6.4615e+03, initc-loss 1.3032e+04                    bc_loss 3.6307e+02, Test-Loss 1.2588e+00\n",
      "Epoch 29410, Training-Loss 2.6648e+00, Data-loss 6.0872e-01                  , pde-loss 5.5834e+03, initc-loss 1.2889e+04                    bc_loss 7.7977e+02, Test-Loss 6.0872e-01\n",
      "Epoch 29420, Training-Loss 2.8427e+00, Data-loss 6.2678e-01                  , pde-loss 6.3993e+03, initc-loss 1.2969e+04                    bc_loss 1.2948e+03, Test-Loss 6.2678e-01\n",
      "Epoch 29430, Training-Loss 2.9580e+00, Data-loss 1.6316e+00                  , pde-loss 5.4973e+03, initc-loss 1.2902e+04                    bc_loss 1.6136e+02, Test-Loss 1.6316e+00\n",
      "Epoch 29440, Training-Loss 2.4296e+00, Data-loss 6.4366e-01                  , pde-loss 5.7178e+03, initc-loss 1.2988e+04                    bc_loss 2.2348e+02, Test-Loss 6.4366e-01\n",
      "Epoch 29450, Training-Loss 4.5289e+00, Data-loss 6.7403e-01                  , pde-loss 5.7887e+03, initc-loss 1.2867e+04                    bc_loss 4.7430e+02, Test-Loss 6.7403e-01\n",
      "Epoch 29460, Training-Loss 2.7390e+00, Data-loss 7.3409e-01                  , pde-loss 6.6976e+03, initc-loss 1.2911e+04                    bc_loss 6.6531e+02, Test-Loss 7.3409e-01\n",
      "Epoch 29470, Training-Loss 2.9700e+00, Data-loss 7.5339e-01                  , pde-loss 6.1459e+03, initc-loss 1.2662e+04                    bc_loss 6.0808e+02, Test-Loss 7.5339e-01\n",
      "Epoch 29480, Training-Loss 2.9903e+00, Data-loss 9.1236e-01                  , pde-loss 7.5407e+03, initc-loss 1.3001e+04                    bc_loss 2.4613e+03, Test-Loss 9.1236e-01\n",
      "Epoch 29490, Training-Loss 3.0085e+00, Data-loss 9.5920e-01                  , pde-loss 4.0888e+03, initc-loss 1.2902e+04                    bc_loss 4.6677e+03, Test-Loss 9.5920e-01\n",
      "Epoch 29500, Training-Loss 2.5867e+00, Data-loss 7.0884e-01                  , pde-loss 4.0155e+03, initc-loss 1.2791e+04                    bc_loss 3.1500e+03, Test-Loss 7.0884e-01\n",
      "Epoch 29510, Training-Loss 2.6556e+00, Data-loss 6.7658e-01                  , pde-loss 5.9933e+03, initc-loss 1.3052e+04                    bc_loss 3.8528e+02, Test-Loss 6.7658e-01\n",
      "Epoch 29520, Training-Loss 2.6053e+00, Data-loss 5.2152e-01                  , pde-loss 5.8896e+03, initc-loss 1.2923e+04                    bc_loss 2.7081e+02, Test-Loss 5.2152e-01\n",
      "Epoch 29530, Training-Loss 2.8338e+00, Data-loss 2.2847e+00                  , pde-loss 4.9979e+03, initc-loss 1.2862e+04                    bc_loss 3.6471e+02, Test-Loss 2.2847e+00\n",
      "Epoch 29540, Training-Loss 2.9225e+00, Data-loss 6.1180e-01                  , pde-loss 7.3003e+03, initc-loss 1.2878e+04                    bc_loss 1.2028e+03, Test-Loss 6.1180e-01\n",
      "Epoch 29550, Training-Loss 2.7722e+00, Data-loss 1.1346e+00                  , pde-loss 7.1927e+03, initc-loss 1.2735e+04                    bc_loss 7.8913e+02, Test-Loss 1.1346e+00\n",
      "Epoch 29560, Training-Loss 3.1623e+00, Data-loss 9.0116e-01                  , pde-loss 6.2511e+03, initc-loss 1.2996e+04                    bc_loss 8.4639e+02, Test-Loss 9.0116e-01\n",
      "Epoch 29570, Training-Loss 2.1964e+00, Data-loss 6.4690e-01                  , pde-loss 4.0506e+03, initc-loss 1.2963e+04                    bc_loss 1.6850e+03, Test-Loss 6.4690e-01\n",
      "Epoch 29580, Training-Loss 2.5387e+00, Data-loss 9.5642e-01                  , pde-loss 4.9906e+03, initc-loss 1.2978e+04                    bc_loss 1.1831e+03, Test-Loss 9.5642e-01\n",
      "Epoch 29590, Training-Loss 2.2349e+00, Data-loss 6.8033e-01                  , pde-loss 4.6149e+03, initc-loss 1.2895e+04                    bc_loss 1.8966e+02, Test-Loss 6.8033e-01\n",
      "Epoch 29600, Training-Loss 3.1397e+00, Data-loss 1.2893e+00                  , pde-loss 6.5626e+03, initc-loss 1.2820e+04                    bc_loss 4.0862e+02, Test-Loss 1.2893e+00\n",
      "Epoch 29610, Training-Loss 3.5686e+00, Data-loss 7.8657e-01                  , pde-loss 7.0578e+03, initc-loss 1.3058e+04                    bc_loss 4.8188e+03, Test-Loss 7.8657e-01\n",
      "Epoch 29620, Training-Loss 2.9048e+00, Data-loss 7.4566e-01                  , pde-loss 4.7302e+03, initc-loss 1.2940e+04                    bc_loss 1.8902e+03, Test-Loss 7.4566e-01\n",
      "Epoch 29630, Training-Loss 2.7458e+00, Data-loss 6.5112e-01                  , pde-loss 5.9579e+03, initc-loss 1.2866e+04                    bc_loss 1.3030e+03, Test-Loss 6.5112e-01\n",
      "Epoch 29640, Training-Loss 2.4423e+00, Data-loss 8.1608e-01                  , pde-loss 6.6465e+03, initc-loss 1.2776e+04                    bc_loss 2.5284e+02, Test-Loss 8.1608e-01\n",
      "Epoch 29650, Training-Loss 2.4966e+00, Data-loss 6.4126e-01                  , pde-loss 5.1972e+03, initc-loss 1.2994e+04                    bc_loss 2.1175e+02, Test-Loss 6.4126e-01\n",
      "Epoch 29660, Training-Loss 2.5058e+00, Data-loss 4.7548e-01                  , pde-loss 4.7408e+03, initc-loss 1.2972e+04                    bc_loss 2.6335e+02, Test-Loss 4.7548e-01\n",
      "Epoch 29670, Training-Loss 3.0045e+00, Data-loss 6.9804e-01                  , pde-loss 6.7158e+03, initc-loss 1.2991e+04                    bc_loss 6.1614e+02, Test-Loss 6.9804e-01\n",
      "Epoch 29680, Training-Loss 2.5622e+00, Data-loss 7.0740e-01                  , pde-loss 3.8481e+03, initc-loss 1.2815e+04                    bc_loss 1.1418e+03, Test-Loss 7.0740e-01\n",
      "Epoch 29690, Training-Loss 2.5313e+00, Data-loss 1.0159e+00                  , pde-loss 4.8625e+03, initc-loss 1.3009e+04                    bc_loss 5.4298e+02, Test-Loss 1.0159e+00\n",
      "Epoch 29700, Training-Loss 2.7193e+00, Data-loss 8.2490e-01                  , pde-loss 5.9126e+03, initc-loss 1.2974e+04                    bc_loss 6.9821e+02, Test-Loss 8.2490e-01\n",
      "Epoch 29710, Training-Loss 2.4629e+00, Data-loss 6.0496e-01                  , pde-loss 5.1744e+03, initc-loss 1.2888e+04                    bc_loss 9.3995e+02, Test-Loss 6.0496e-01\n",
      "Epoch 29720, Training-Loss 4.5670e+00, Data-loss 1.4437e+00                  , pde-loss 6.4420e+03, initc-loss 1.2896e+04                    bc_loss 8.8832e+02, Test-Loss 1.4437e+00\n",
      "Epoch 29730, Training-Loss 2.8614e+00, Data-loss 8.4312e-01                  , pde-loss 6.8875e+03, initc-loss 1.3013e+04                    bc_loss 6.6720e+02, Test-Loss 8.4312e-01\n",
      "Epoch 29740, Training-Loss 2.7140e+00, Data-loss 7.7350e-01                  , pde-loss 4.7696e+03, initc-loss 1.2809e+04                    bc_loss 5.8609e+02, Test-Loss 7.7350e-01\n",
      "Epoch 29750, Training-Loss 2.3090e+00, Data-loss 8.5329e-01                  , pde-loss 5.5616e+03, initc-loss 1.2897e+04                    bc_loss 2.7919e+02, Test-Loss 8.5329e-01\n",
      "Epoch 29760, Training-Loss 3.3763e+00, Data-loss 5.5805e-01                  , pde-loss 6.2687e+03, initc-loss 1.2935e+04                    bc_loss 6.8462e+02, Test-Loss 5.5805e-01\n",
      "Epoch 29770, Training-Loss 2.3345e+00, Data-loss 6.6132e-01                  , pde-loss 4.2345e+03, initc-loss 1.2902e+04                    bc_loss 1.9539e+02, Test-Loss 6.6132e-01\n",
      "Epoch 29780, Training-Loss 2.3178e+00, Data-loss 5.7533e-01                  , pde-loss 4.1042e+03, initc-loss 1.3025e+04                    bc_loss 4.4215e+02, Test-Loss 5.7533e-01\n",
      "Epoch 29790, Training-Loss 2.5006e+00, Data-loss 7.5668e-01                  , pde-loss 4.8266e+03, initc-loss 1.2902e+04                    bc_loss 3.3057e+02, Test-Loss 7.5668e-01\n",
      "Epoch 29800, Training-Loss 2.7321e+00, Data-loss 4.6641e-01                  , pde-loss 6.4252e+03, initc-loss 1.2915e+04                    bc_loss 3.7882e+02, Test-Loss 4.6641e-01\n",
      "Epoch 29810, Training-Loss 5.4196e+00, Data-loss 9.8226e-01                  , pde-loss 5.2927e+03, initc-loss 1.2997e+04                    bc_loss 1.1105e+03, Test-Loss 9.8226e-01\n",
      "Epoch 29820, Training-Loss 2.6996e+00, Data-loss 7.2907e-01                  , pde-loss 4.2972e+03, initc-loss 1.2836e+04                    bc_loss 4.0367e+02, Test-Loss 7.2907e-01\n",
      "Epoch 29830, Training-Loss 2.7578e+00, Data-loss 7.9374e-01                  , pde-loss 6.5757e+03, initc-loss 1.2984e+04                    bc_loss 1.0224e+03, Test-Loss 7.9374e-01\n",
      "Epoch 29840, Training-Loss 2.3954e+00, Data-loss 6.1751e-01                  , pde-loss 5.1579e+03, initc-loss 1.2987e+04                    bc_loss 1.3527e+03, Test-Loss 6.1751e-01\n",
      "Epoch 29850, Training-Loss 2.3903e+00, Data-loss 1.2088e+00                  , pde-loss 4.1362e+03, initc-loss 1.3003e+04                    bc_loss 2.1716e+02, Test-Loss 1.2088e+00\n",
      "Epoch 29860, Training-Loss 2.6502e+00, Data-loss 1.0276e+00                  , pde-loss 4.9304e+03, initc-loss 1.2897e+04                    bc_loss 5.0724e+02, Test-Loss 1.0276e+00\n",
      "Epoch 29870, Training-Loss 3.7646e+00, Data-loss 5.3010e-01                  , pde-loss 5.1276e+03, initc-loss 1.2936e+04                    bc_loss 1.0078e+03, Test-Loss 5.3010e-01\n",
      "Epoch 29880, Training-Loss 2.6259e+00, Data-loss 7.7376e-01                  , pde-loss 6.3676e+03, initc-loss 1.2899e+04                    bc_loss 6.2513e+02, Test-Loss 7.7376e-01\n",
      "Epoch 29890, Training-Loss 2.2149e+00, Data-loss 6.4968e-01                  , pde-loss 3.2836e+03, initc-loss 1.2943e+04                    bc_loss 7.3871e+02, Test-Loss 6.4968e-01\n",
      "Epoch 29900, Training-Loss 2.9173e+00, Data-loss 6.0638e-01                  , pde-loss 3.9667e+03, initc-loss 1.2881e+04                    bc_loss 2.0411e+03, Test-Loss 6.0638e-01\n",
      "Epoch 29910, Training-Loss 2.8120e+00, Data-loss 2.4541e+00                  , pde-loss 5.3148e+03, initc-loss 1.2883e+04                    bc_loss 8.0063e+02, Test-Loss 2.4541e+00\n",
      "Epoch 29920, Training-Loss 2.7078e+00, Data-loss 6.5279e-01                  , pde-loss 5.7202e+03, initc-loss 1.2984e+04                    bc_loss 3.2016e+02, Test-Loss 6.5279e-01\n",
      "Epoch 29930, Training-Loss 2.6254e+00, Data-loss 3.9668e-01                  , pde-loss 5.4117e+03, initc-loss 1.3012e+04                    bc_loss 9.8306e+02, Test-Loss 3.9668e-01\n",
      "Epoch 29940, Training-Loss 2.9625e+00, Data-loss 1.5517e+00                  , pde-loss 3.3913e+03, initc-loss 1.2950e+04                    bc_loss 3.2827e+03, Test-Loss 1.5517e+00\n",
      "Epoch 29950, Training-Loss 2.7776e+00, Data-loss 9.2390e-01                  , pde-loss 5.2691e+03, initc-loss 1.2942e+04                    bc_loss 2.5239e+03, Test-Loss 9.2390e-01\n",
      "Epoch 29960, Training-Loss 2.5339e+00, Data-loss 5.8031e-01                  , pde-loss 6.1939e+03, initc-loss 1.2939e+04                    bc_loss 2.4719e+02, Test-Loss 5.8031e-01\n",
      "Epoch 29970, Training-Loss 2.9728e+00, Data-loss 8.3096e-01                  , pde-loss 7.1449e+03, initc-loss 1.2833e+04                    bc_loss 1.2932e+02, Test-Loss 8.3096e-01\n",
      "Epoch 29980, Training-Loss 3.0885e+00, Data-loss 5.5711e-01                  , pde-loss 6.7863e+03, initc-loss 1.2904e+04                    bc_loss 1.9816e+03, Test-Loss 5.5711e-01\n",
      "Epoch 29990, Training-Loss 2.5400e+00, Data-loss 6.1708e-01                  , pde-loss 4.5929e+03, initc-loss 1.2816e+04                    bc_loss 2.8138e+02, Test-Loss 6.1708e-01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses, test_losses, pde_losses, bc_losses,ic_losses, data_losses = training_loop(epochs, model, loss_fn_data, optimizer,train_loader,test_loader,train_loader_init,\\\n",
    "                  train_loader_bc_l,train_loader_bc_r)  # Train the model\n",
    " \n",
    "# test_losses = test_loop(epochs, model, loss_fn_data, optimizer, train_loader, test_loader)  # Test the model\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_nn = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).cpu().detach().numpy() # Get the predictions from the model\n",
    "\n",
    "temp_nn = temp_nn.reshape(num_steps+1, num_points) # Reshape the predictions to a 2D array\n",
    "time_ss= np.linspace(0, time_end, num_steps+1 )\n",
    "plt.figure\n",
    "plt.plot(time_ss, temp_nn[:, num_points//2], label='Predicted Temperature')\n",
    "plt.plot(time_ss, temperature_history[:,num_points//2], label='Actual Temperature')\n",
    "plt.xlabel('Time(s)')\n",
    "plt.ylabel('Temperature (K)')\n",
    "plt.title('Predicted vs Actual Temperature at x = 7.5mm')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_losses, label='Data Loss')\n",
    "plt.plot(pde_losses, label='Pde Loss')\n",
    "plt.plot(ic_losses, label='IC Loss')\n",
    "plt.plot(bc_losses, label='BC Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
