{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Three Phase Simulation of Alloys and PINN model development \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the simulation of 1D Phase change of aluminium alloy. There will be three phases (solid,liquid and mushy).   \n",
    "\n",
    "The approach used is finite difference method and the physics involved in heat conduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import csv\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "\n",
    "from pinn_loss import loss_fn_data, l1_regularization, pde_loss, boundary_loss, ic_loss, accuracy\n",
    "from Input_vec_gen import input_gen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the constants and inital geometric domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_l = 3.394878564540885e-05, alpha_s = 3.686205086349929e-05, m_eff = 6.296953764744878e-06\n",
      "dx is 0.0003061224489795918\n",
      "dt is  0.0012711033647622566\n",
      "num_steps is 31469\n",
      "cfl is 0.0012711033647622566\n",
      "stability criteria satisfied\n"
     ]
    }
   ],
   "source": [
    "# Geometry\n",
    "length = 15.0e-3             # Length of the rod\n",
    "\n",
    "# Material properties\n",
    "rho = 2300.0                     # Density of AL380 (kg/m^3)\n",
    "rho_l = 2460.0                   # Density of AL380 (kg/m^3)\n",
    "rho_s = 2710.0                    # Density of AL380 (kg/m^3)\n",
    "rho_m = (rho_l + rho_s )/2       # Desnity in mushy zone is taken as average of liquid and solid density\n",
    "\n",
    "k = 104.0                       # W/m-K\n",
    "k_l = k                       # W/m-K\n",
    "k_s = 96.2                    # W/m-K\n",
    "k_m =  (k_l+k_s)/2                     # W/m-K\n",
    "k_mo = 41.5\n",
    "\n",
    "\n",
    "cp = 1245.3                      # Specific heat of aluminum (J/kg-K)\n",
    "cp_l = cp                      # Specific heat of aluminum (J/kg-K)\n",
    "cp_s = 963.0                 # Specific heat of aluminum (J/kg-K)\n",
    "cp_m =  (cp_l+cp_s)/2                 # Specific heat of mushy zone is taken as average of liquid and solid specific heat\n",
    "# cp_m = cp\n",
    "           # Thermal diffusivity\n",
    "alpha_l = k_l / (rho_l * cp_l) \n",
    "alpha_s = k_s / (rho_s*cp_s)\n",
    "alpha_m = k_m / (rho_m * cp_m)          #`Thermal diffusivity in mushy zone is taken as average of liquid and solid thermal diffusivity`\n",
    "\n",
    "\n",
    "#L_fusion = 3.9e3                 # J/kg\n",
    "L_fusion = 389.0e3               # J/kg  # Latent heat of fusion of aluminum\n",
    "         # Thermal diffusivity\n",
    "\n",
    "\n",
    "T_L = 574.4 +273.0                       #  K -Liquidus Temperature (615 c) AL 380\n",
    "T_S = 497.3 +273.0                     # K- Solidus Temperature (550 C)\n",
    "m_eff =(k_m/(rho_m*(cp_m + (L_fusion/(T_L-T_S)))))\n",
    "print (f\"alpha_l = {alpha_l}, alpha_s = {alpha_s}, m_eff = {m_eff}\")\n",
    "\n",
    "# htc = 10.0                   # W/m^2-K\n",
    "# q = htc*(919.0-723.0)\n",
    "# q = 10000.0\n",
    "\n",
    "\n",
    "num_points = 50                        # Number of spatial points\n",
    "dx = length / (num_points - 1)         # Distance between two spatial points\n",
    "print('dx is',dx)\n",
    "\n",
    "                                                              \n",
    "# Time Discretization  \n",
    "# \n",
    "time_end = 40        # seconds                         \n",
    "\n",
    "maxi = max(alpha_s,alpha_l,alpha_m)\n",
    "dt = abs(0.5*((dx**2) /maxi)) \n",
    "\n",
    "print('dt is ',dt)\n",
    "num_steps = round(time_end/dt)\n",
    "print('num_steps is',num_steps)\n",
    "cfl = 0.5 *(dx**2/max(alpha_l,alpha_s,alpha_m))\n",
    "print('cfl is',cfl)\n",
    "\n",
    "time_steps = np.linspace(0, time_end, num_steps + 1)\n",
    "step_coeff = dt / (dx ** 2)\n",
    "\n",
    "if dt <= cfl:\n",
    "    print('stability criteria satisfied')\n",
    "else:\n",
    "    print('stability criteria not satisfied')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial and Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_init = 919.0\n",
    "# Initial temperature and phase fields\n",
    "temperature = np.full(num_points+2, 919.0)            # Initial temperature of the rod with ghost points at both ends\n",
    "phase = np.zeros(num_points+2)*0.0                    # Initial phase of the rod with ghost points at both ends\n",
    "\n",
    "# Set boundary conditions\n",
    "# temperature[-1] = 919.0 \n",
    "phase[-1] = 1.0\n",
    "\n",
    "# temperature[0] = 919.0 #(40 C)\n",
    "phase[0] = 1.0\n",
    "\n",
    "# Store initial state in history\n",
    "temperature_history = [temperature.copy()]    # List to store temperature at each time step\n",
    "phi_history = [phase.copy()]                    # List to store phase at each time step\n",
    "temp_init = temperature.copy()                 # Initial temperature of the rod\n",
    "# print(temperature_history,phi_history)\n",
    "# Array to store temperature at midpoint over time\n",
    "midpoint_index = num_points // 2                          # Index of the midpoint\n",
    "\n",
    "midpoint_temperature_history = [temperature[midpoint_index]]            # List to store temperature at midpoint over time\n",
    "dm = 60.0e-3                                                            # die thickness in m\n",
    "\n",
    "# r_m =  (k_mo / dm) + (1/htc)\n",
    "\n",
    "t_surr = 500.0                                        # Surrounding temperature in K\n",
    "# t_surr = h()\n",
    "\n",
    "def kramp(temp,v1,v2,T_L,T_s):                                      # Function to calculate thermal conductivity in Mushy Zone\n",
    "        slope = (v1-v2)/(T_L-T_S)\n",
    "        if temp > T_L:\n",
    "            k_m = k_l\n",
    "        elif temp < T_S:\n",
    "            k_m = k_s\n",
    "        else:\n",
    "            k_m = k_s + slope*(temp-T_S)\n",
    "        return k_m\n",
    "\n",
    "def cp_ramp(temp,v1,v2,T_L,T_s):                                    # Function to calculate specific heat capacity in Mushy Zone\n",
    "    slope = (v1-v2)/(T_L-T_S)\n",
    "    if temp > T_L:\n",
    "        cp_m = cp_l\n",
    "    elif temp < T_S:\n",
    "        cp_m = cp_s\n",
    "    else:\n",
    "        cp_m = cp_s + slope*(temp-T_S)\n",
    "    return cp_m\n",
    "\n",
    "def rho_ramp(temp,v1,v2,T_L,T_s):                                       # Function to calculate density in Mushy Zone\n",
    "    slope = (v1-v2)/(T_L-T_S)\n",
    "    if temp > T_L:\n",
    "        rho_m = rho_l\n",
    "    elif temp < T_S:\n",
    "        rho_m = rho_s\n",
    "    else:\n",
    "        rho_m = rho_s + slope*(temp-T_S)\n",
    "    return rho_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the HT equation and phase change numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for m in range(1, num_steps+1):                                                                            # time loop\n",
    "    htc = 10.0                   # htc of Still air in W/m^2-K\n",
    "    q1 = htc*(temp_init[0]-t_surr)   # Heat flux at the left boundary\n",
    "    \n",
    "    # print(f\"q1 is {q1}\")\n",
    "    temperature[0] = temp_init[0] + alpha_l * step_coeff * ((2.0*temp_init[1]) - (2.0 * temp_init[0])-(2.0*dx*(q1)))  # Update boundary condition temperature\n",
    "    \n",
    "    q2 = htc*(temp_init[-1]-t_surr)                   # Heat flux at the right boundary\n",
    "    temperature[-1] = temp_init[-1] + alpha_l * step_coeff * ((2.0*temp_init[-2]) - (2.0 * temp_init[-1])-(2.0*dx*(q2)))  # Update boundary condition temperature\n",
    "    \n",
    "    for n in range(1,num_points+1):              # space loop, adjusted range\n",
    "       \n",
    "        if temperature[n] >= T_L:\n",
    "            temperature[n] += ((alpha_l * step_coeff) * (temp_init[n+1] - (2.0 * temp_init[n]) + temp_init[n-1]))\n",
    "            phase[n] = 0\n",
    "            \n",
    "            # print(f\" Time-Step{m},Spatial point{n},Temperature{temperature[n]}\")\n",
    "        elif T_S < temperature[n] < T_L:\n",
    "            \n",
    "            k_m = kramp(temperature[n],k_l,k_s,T_L,T_S)\n",
    "            cp_m = cp_ramp(temperature[n],cp_l,cp_s,T_L,T_S)\n",
    "            rho_m = rho_ramp(temperature[n],rho_l,rho_s,T_L,T_S)\n",
    "            m_eff =(k_m/(rho_m*(cp_m + (L_fusion/(T_L-T_S)))))\n",
    "            \n",
    "            temperature[n] += ((m_eff * step_coeff)* (temp_init[n+1] - (2.0 * temp_init[n]) + temp_init[n-1]))\n",
    "            \n",
    "            phase[n] = (T_L - temperature[n]) / (T_L - T_S)\n",
    "            # print(m,n,temperature[n],phase[n])\n",
    "         \n",
    "        elif temperature[n]<T_S:\n",
    "            temperature[n] += ((alpha_s * step_coeff) * (temp_init[n+1] - (2.0 * temp_init[n])+ temp_init[n-1]))\n",
    "            phase[n] = 1\n",
    "                     \n",
    "        else:\n",
    "            print(\"ERROR: should not be here\")\n",
    "\n",
    "     \n",
    "          \n",
    "    temperature = temperature.copy()                                                                # Update temperature\n",
    "    phase = phase.copy()                                                                            # Update phase\n",
    "    temp_init = temperature.copy()                                                                  # Update last time step temperature\n",
    "    temperature_history.append(temperature.copy())                                                  # Append the temperature history to add ghost points\n",
    "    phi_history.append(phase.copy())                                                                # Append the phase history to add ghost points\n",
    "    midpoint_temperature_history.append(temperature[midpoint_index])                                # Store midpoint temperature\n",
    "    \n",
    "    \n",
    "    # print(f\"Step {m}, Temperature: {temperature}\")\n",
    "    \n",
    "\n",
    "\n",
    "# print(midpoint_temperature_history)\n",
    "#print(phi_history)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot temperature history for debugging\n",
    "# temperature_history_1 = np.array(temperature_history)\n",
    "# print(temperature_history_1.shape)\n",
    "# time_ss= np.linspace(0, time_end, num_steps+1)\n",
    "# # print(time_ss.shape)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(time_ss, midpoint_temperature_history, label='Midpoint Temperature')\n",
    "# plt.axhline(y=T_L, color='r', linestyle='--', label='Liquidus Temperature')\n",
    "# plt.axhline(y=T_S, color='g', linestyle='--', label='Solidus Temperature')\n",
    "# plt.xlabel('Time(s)')\n",
    "# plt.ylabel('Temperature (K)')\n",
    "# plt.title('Temperature Distribution Over Time at x = 7.5mm') \n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data into Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_history = np.array(temperature_history)\n",
    "\n",
    "phi_history = np.array(phi_history)\n",
    "\n",
    "t_hist = np.array(temperature_history[:,1:-1])\n",
    "p_hist = np.array(phi_history[:,1:-1])\n",
    "\n",
    "t_hist_init = t_hist[0,:]\n",
    "t_hist_bc_l = t_hist[:,0]\n",
    "t_hist_bc_r = t_hist[:,-1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have temperature_history and phi_history as lists of arrays\n",
    "\n",
    "\n",
    "# # Check the new shape after transposing\n",
    "# print(\"Transposed Temperature History Shape:\", temperature_history.shape)\n",
    "# print(\"Transposed Phi History Shape:\", phi_history.shape)\n",
    "\n",
    "# # Create a meshgrid for space and time coordinates\n",
    "# space_coord, time_coord = np.meshgrid(np.arange(temperature_history.shape[1]), np.arange(temperature_history.shape[0]))\n",
    "\n",
    "# time_coord = time_coord * dt \n",
    "# # Create a figure with two subplots\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# # Plot the temperature history on the left subplot\n",
    "# im1 = ax1.pcolormesh(space_coord, time_coord, temperature_history, cmap='viridis')\n",
    "# ax1.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=16)\n",
    "# ax1.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "# ax1.set_title('Temperature Variation Over Time',fontname='Times New Roman', fontsize=20)\n",
    "# fig.colorbar(im1, ax=ax1, label='Temperature')\n",
    "\n",
    "# # Plot the phase history on the right subplot\n",
    "# im2 = ax2.pcolormesh(space_coord, time_coord, phi_history, cmap='viridis')\n",
    "# ax2.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=18)\n",
    "# ax2.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "# ax2.set_title('Phase Variation Over Time',fontname='Times New Roman', fontsize=20)\n",
    "# fig.colorbar(im2, ax=ax2, label='Phase')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# #plot the main\n",
    "# fig, ax = plt.subplots(figsize=(14, 6))\n",
    "# im = ax.pcolormesh(space_coord, time_coord, Dim_ny, cmap='viridis')\n",
    "# ax.set_xlabel('Space Coordinate')\n",
    "# ax.set_ylabel('Time')\n",
    "# ax.set_title('Niyama Variation Over Time')\n",
    "# fig.colorbar(im, ax=ax, label='Main')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU/CPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check for gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (31470,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "space = np.linspace(0, length, num_points) # Spatial points\n",
    "time = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "print(space.shape,time.shape)\n",
    "\n",
    "sp_i = np.linspace(0, length, num_points) # Spatial points\n",
    "time_i = np.zeros(num_points) # Time points\n",
    "\n",
    "sp_b_l = np.zeros(num_steps+1) # Spatial points\n",
    "time_b_l = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "\n",
    "sp_b_r = np.ones(num_steps+1)*length # Spatial points\n",
    "time_b_r = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = input_gen(space,time,'mgrid')\n",
    "inputs_i = input_gen(sp_i,time_i,'scr')\n",
    "inputs_b_l = input_gen(sp_b_l,time_b_l,'scr')\n",
    "inputs_b_r = input_gen(sp_b_r,time_b_r,'scr')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1573500, 2) (50, 2) (31470, 2) (31470, 2)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape,inputs_i.shape,inputs_b_l.shape,inputs_b_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2])\n",
      "torch.Size([1573500, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "inputs = torch.tensor(inputs).float().to(device) # Convert the inputs to a tensor\n",
    "\n",
    "\n",
    "inputs_init = torch.tensor(inputs_i).float().to(device) # Convert the inputs to a tensor\n",
    "inputs_b_l = torch.tensor(inputs_b_l).float().to(device)# Convert the inputs to a tensor\n",
    "inputs_b_r = torch.tensor(inputs_b_r).float().to(device)# Convert the inputs to a tensor\n",
    "\n",
    "print(inputs_init.shape)\n",
    "# label/temp data\n",
    "temp_tr = torch.tensor(t_hist).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp = temp_tr.reshape(-1,1).float().to(device) # Reshape the temperature tensor to a column vector\n",
    "temp_inp_init = torch.tensor(t_hist_init).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp_bc_l = torch.tensor(t_hist_bc_l).float().to(device)# Convert the temperature history to a tensor\n",
    "temp_inp_bc_r = torch.tensor(t_hist_bc_r).float().to(device)# Convert the temperature history to a tensor\n",
    "print(temp_inp.shape)\n",
    "\n",
    "\n",
    "\n",
    "#Data Splitting\n",
    "\n",
    "# train_inputs, val_test_inputs, train_temp_inp, val_test_temp_inp = train_test_split(inputs, temp_inp, test_size=0.2, random_state=42)\n",
    "# val_inputs, test_inputs, val_temp_inp, test_temp_inp = train_test_split(val_test_inputs, val_test_temp_inp, test_size=0.8, random_state=42)\n",
    "\n",
    "train_inputs, test_inputs, train_temp_inp, test_temp_inp = train_test_split(inputs, temp_inp, test_size=0.2, random_state=42)\n",
    "train_inputs_init, test_inputs_init, train_temp_inp_init, test_temp_inp_init = train_test_split(inputs_init, temp_inp_init, test_size=0.2, random_state=42)\n",
    "train_inputs_bc_l, test_inputs_bc_l, train_temp_inp_bc_l, test_temp_inp_bc_l = train_test_split(inputs_b_l, temp_inp_bc_l, test_size=0.2, random_state=42)\n",
    "train_inputs_bc_r, test_inputs_bc_r, train_temp_inp_bc_r, test_temp_inp_bc_r = train_test_split(inputs_b_r, temp_inp_bc_r, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, temp_inp,transform=None, target_transform =None):\n",
    "        self.inputs = inputs\n",
    "        self.temp_inp = temp_inp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.temp_inp[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "  \n",
    "train_dataset = TensorDataset(train_inputs, train_temp_inp) # Create the training dataset\n",
    "# val_dataset = TensorDataset(val_inputs, val_temp_inp) # Create the validation dataset\n",
    "test_dataset = TensorDataset(test_inputs, test_temp_inp) # Create the test dataset\n",
    "\n",
    "train_dataset_init = TensorDataset(train_inputs_init, train_temp_inp_init) # Create the training dataset\n",
    "test_dataset_init = TensorDataset(test_inputs_init, test_temp_inp_init) # Create the test dataset\n",
    "train_dataset_bc_l = TensorDataset(train_inputs_bc_l, train_temp_inp_bc_l) # Create the training dataset\n",
    "test_dataset_bc_l = TensorDataset(test_inputs_bc_l, test_temp_inp_bc_l) # Create the test dataset\n",
    "train_dataset_bc_r = TensorDataset(train_inputs_bc_r, train_temp_inp_bc_r) # Create the training dataset\n",
    "test_dataset_bc_r = TensorDataset(test_inputs_bc_r, test_temp_inp_bc_r) # Create the test dataset\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "random_sampler_train = RandomSampler(train_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "# random_sampler_val = RandomSampler(val_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the validation dataset\n",
    "random_sampler_test = RandomSampler(test_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "\n",
    "random_sampler_train_init = RandomSampler(train_dataset_init, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_init = RandomSampler(test_dataset_init, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "random_sampler_train_bc_l = RandomSampler(train_dataset_bc_l, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_bc_l = RandomSampler(test_dataset_bc_l, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "random_sampler_train_bc_r = RandomSampler(train_dataset_bc_r, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_bc_r = RandomSampler(test_dataset_bc_r, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=random_sampler_train) # Create the training dataloader\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=random_sampler_val) # Create the validation dataloader\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, sampler=random_sampler_test) # Create the test dataloader\n",
    "\n",
    "train_loader_init = DataLoader(train_dataset_init, batch_size=batch_size, sampler=random_sampler_train_init) # Create the training dataloader\n",
    "test_loader_init = DataLoader(test_dataset_init, batch_size=batch_size, sampler=random_sampler_test_init) # Create the test dataloader\n",
    "train_loader_bc_l = DataLoader(train_dataset_bc_l, batch_size=batch_size, sampler=random_sampler_train_bc_l) # Create the training dataloader\n",
    "test_loader_bc_l = DataLoader(test_dataset_bc_l, batch_size=batch_size, sampler=random_sampler_test_bc_l) # Create the test dataloader\n",
    "train_loader_bc_r = DataLoader(train_dataset_bc_r, batch_size=batch_size, sampler=random_sampler_train_bc_r) # Create the training dataloader\n",
    "test_loader_bc_r = DataLoader(test_dataset_bc_r, batch_size=batch_size, sampler=random_sampler_test_bc_r) # Create the test dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the neural network architecture\n",
    "class Mushydata(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size): # This is the constructor\n",
    "        super(Mushydata, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t):                               # This is the forward pass\n",
    "        input_features = torch.cat([x, t], dim=1)          # Concatenate the input features\n",
    "        m = self.base(input_features)                                 # Pass through the third layer\n",
    "        return m                    # Return the output of the network\n",
    "\n",
    "\n",
    "# features = torch.rand(1, 2)\n",
    "# model = HeatPINN(2, 20, 1)\n",
    "# output = model(features[:, 0:1], features[:, 1:2])\n",
    "# print(output)\n",
    "\n",
    "\n",
    "# Loss function for data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamters Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 30\n",
    "learning_rate = 0.003\n",
    "epochs = 30000\n",
    "# alpha = 0.01  # Adjust this value based on your problem\n",
    "# boundary_value = 313.0\n",
    "# initial_value = init_temp\n",
    "# Initialize the model\n",
    "model = Mushydata(input_size=2, hidden_size=hidden_size,output_size=1).to(device)\n",
    "lambd = 0.1\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss List Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of train_loader is <class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(f\"Datatype of train_loader is {type(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_fn_data(u_pred, u_true):\n",
    "#     return nn.MSELoss()(u_pred, u_true)\n",
    "\n",
    "# def l1_regularization(model, lambd):\n",
    "#     l1_reg = sum(param.abs().sum() for param in model.parameters())\n",
    "#     return l1_reg * lambd\n",
    "\n",
    "# def pde_loss(u_pred,x,t):\n",
    "#     # u_pred.requires_grad = True\n",
    "#     x.requires_grad = True\n",
    "#     t.requires_grad = True\n",
    "    \n",
    "#     u_pred = model(x,t).requires_grad_()\n",
    "#     u_t = torch.autograd.grad(u_pred, t, \n",
    "#                                 torch.ones_like(u_pred).to(device),\n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused=True,\n",
    "#                                 )[0] # Calculate the first time derivative\n",
    "#     if u_t is None:\n",
    "#         raise RuntimeError(\"u_t is None\")\n",
    "\n",
    "#     u_x = torch.autograd.grad(u_pred, \n",
    "#                                 x, \n",
    "#                                 torch.ones_like(u_pred).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused =True)[0] # Calculate the first space derivative\n",
    "            \n",
    "#     u_xx = torch.autograd.grad(u_x, \n",
    "#                                 x, \n",
    "#                                 torch.ones_like(u_x).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused=True)[0] \n",
    "    \n",
    "#     T_S_tensor = torch.tensor(T_S, device=device)\n",
    "#     T_L_tensor = torch.tensor(T_L, device=device)\n",
    "    \n",
    "#     k_m = torch.where((u_pred >= T_S_tensor) * (u_pred <= T_L_tensor),\\\n",
    "#                        kramp(u_pred, k_l,k_s,T_L,T_S),torch.tensor(0.0,device=device))\n",
    "#     cp_m = torch.where(u_pred >= T_S_tensor * u_pred <= T_L_tensor, cp_ramp((u_pred), cp_l,cp_s,T_L,T_S))\n",
    "#     rho_m = torch.where(u_pred >= T_S_tensor * u_pred <= T_L_tensor, rho_ramp((u_pred), rho_l,rho_s,T_L,T_S))\n",
    "#     m_eff = (k_m / (rho_m * (cp_m + (L_fusion / (T_L - T_S)))))\n",
    "\n",
    "#     alpha_T = torch.where(u_pred >= T_L_tensor, alpha_l, torch.where(u_pred<=T_S_tensor,alpha_s ,m_eff))\n",
    "#     alpha_T = 1\n",
    "#     residual = u_t - alpha_T * u_xx\n",
    "\n",
    "#     return nn.MSELoss()(residual,torch.zeros_like(residual))\n",
    "\n",
    "# def boundary_loss(u_pred,x,t,t_surr):\n",
    "    \n",
    "#     u_x = torch.autograd.grad(u_pred,x, \n",
    "#                                 torch.ones_like(u_pred).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused =True)[0] # Calculate the first space derivative\n",
    "#     t_surr_t = torch.tensor(t_surr, device=device)\n",
    "#     res_l = u_x -(htc* (u_pred-t_surr_t))\n",
    "   \n",
    "\n",
    "#     return nn.MSELoss()(res_l,torch.zeros_like(res_l))\n",
    "\n",
    "# def ic_loss(u_pred):\n",
    "#     temp_init_tsr = torch.tensor(temp_init[1:-1],device=device)\n",
    "#     ic = u_pred -temp_init_tsr\n",
    "#     return nn.MSELoss()(ic,torch.zeros_like(ic))\n",
    "\n",
    "def accuracy(u_pred, u_true):\n",
    "    return torch.mean(torch.abs(u_pred - u_true) / u_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation and Testing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, model, loss_fn_data, optimizer, train_dataloader,):\n",
    "    train_losses = []  # Initialize the list to store the training losses\n",
    "    val_losses = []    # Initialize the list to store the validation losses\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()                                                                           # Set the model to training mode\n",
    "        train_loss = 0                                                                              # Initialize the training loss\n",
    "        train_accuracy = 0\n",
    "        for (batch,batch_init,batch_left,batch_right) in \\\n",
    "             zip (train_dataloader,train_loader_init,train_loader_bc_l,train_inputs_bc_r):                                                          # Loop through the training dataloader\n",
    "            inputs, temp_inp= batch                                                             # Get the inputs and the true values\n",
    "            inputs_init, temp_inp_init= batch_init                                                             # Get the inputs and the true values \n",
    "            inputs_left, temp_inp_left= batch_left                                                             # Get the inputs and the true values\n",
    "            inputs_right, temp_inp_right= batch_right                                                             # Get the inputs and the true values\n",
    "\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)                             # Move the inputs and true values to the GPU\n",
    "            inputs_init, temp_inp_init= inputs_init.to(device), temp_inp_init.to(device)                             # Move the initial condition inputs and temperature to the GPU\n",
    "            inputs_left, temp_inp_left= inputs_left.to(device), temp_inp_left.to(device)                             # Move the left boundary condition inputs and temperature values to the GPU\n",
    "            inputs_right, temp_inp_right= inputs_right.to(device), temp_inp_right.to(device)                             # Move the right boundary condition inputs and temperature values to the GPU\n",
    "\n",
    "            optimizer.zero_grad()                                                                    # Zero the gradients\n",
    "            \n",
    "            # Forward pass\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).to(device)                       # Get the predictions\n",
    "            u_initl = model(inputs_init[:,0].unsqueeze(1), inputs_init[:,1].unsqueeze(1)).to(device)                       # Get the predictions\n",
    "            \n",
    "            u_left = model(inputs_b_l[:,0].unsqueeze(1), inputs_b_l[:,1].unsqueeze(1)).to(device)               # Left boundary of the temperature\n",
    "            u_right = model(inputs_b_r[:,0].unsqueeze(1), inputs_b_r[:,1].unsqueeze(1)).to(device)             # Right boundary of the temperature\n",
    "\n",
    "            # Loss calculation\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp)                                              # Calculate the data loss\n",
    "            \n",
    "            pd_loss = pde_loss(model,inputs[:,0].unsqueeze(1),inputs[:,1].unsqueeze(1))             # Calculate the PDE loss\n",
    "            # pd_loss = 0\n",
    "            \n",
    "            initc_loss = ic_loss(u_initl) \n",
    "            # initc_loss =0                                                      # Calculate initial condition loss\n",
    "            \n",
    "            bc_loss_left = boundary_loss(model,inputs_b_l[:,0].unsqueeze(1),inputs_b_l[:,1].unsqueeze(1),t_surr) # Calculate the left boundary condition loss\n",
    "            bc_loss_right = boundary_loss(model,inputs_b_r[:,0].unsqueeze(1),inputs_b_r[:,1].unsqueeze(1),t_surr) # Calculate the right boundary condition loss\n",
    "            bc_loss = bc_loss_left + bc_loss_right\n",
    "            # l1_regularization_loss = l1_regularization(model, lambda_l1)                      # Calculate the L1 regularization loss\n",
    "            # loss = data_loss  + pd_loss + initc_loss + bc_loss                                              # Calculate the total loss\n",
    "            w1 = 0.0001\n",
    "            w2 = 0.0001\n",
    "            w3 = 0.0001\n",
    "            loss = data_loss + w1* pd_loss + w2 *initc_loss + w3* bc_loss\n",
    "            train_accuracy += accuracy(u_pred, temp_inp)                                                              # Calculate the total loss\n",
    "            # Backpropagation\n",
    "            loss.backward(retain_graph=True)                                                        # Backpropagate the gradients\n",
    "            \n",
    "            optimizer.step()                                                                           # Update the weights\n",
    "            \n",
    "            train_loss += loss.item()                                                           # Add the loss to the training set loss                 \n",
    "\n",
    "        \n",
    "\n",
    "        # model.eval()\n",
    "        # test_loss = 0\n",
    "        # test_accuracy = 0\n",
    "        # with torch.no_grad():   \n",
    "        #     for batch in test_dataloader:\n",
    "        #         inputs, temp_inp= batch\n",
    "        #         inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "        #         u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "        #         data_loss = loss_fn_data(u_pred, temp_inp)\n",
    "        #         # l1_regularization_loss = l1_regularization(model, lambd)\n",
    "        #         # loss = data_loss  + l1_regularization_loss\n",
    "        #         loss = data_loss\n",
    "        #         test_accuracy = accuracy(u_pred, temp_inp)\n",
    "        #         test_loss += loss.item()\n",
    "        #     test_losses.append(test_loss)\n",
    "\n",
    "        train_losses.append(train_loss)                                                   # Append the training loss to the list of training losses\n",
    "        \n",
    "        # if epoch % 10 == 0:\n",
    "        #     print(f\"Epoch {epoch}, Training-Loss {train_loss:.4e}\")\n",
    "        \n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Training-Loss {train_loss:.4e}, Data-loss {data_loss:.4e}\\\n",
    "                  , pde-loss {pd_loss:.4e}, initc-loss {initc_loss:.4e}\\\n",
    "                    bc_loss {bc_loss:.4e}\") \n",
    "\n",
    "    return train_losses, val_losses                                                             # Return the training and validation losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(epochs, model, loss_fn_data, optimizer, train_dataloader, test_dataloader):\n",
    "      \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    with torch.no_grad():   \n",
    "        for batch in test_dataloader:\n",
    "            inputs, temp_inp= batch\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp)\n",
    "            # l1_regularization_loss = l1_regularization(model, lambd)\n",
    "            # loss = data_loss  + l1_regularization_loss\n",
    "            loss = data_loss\n",
    "            test_accuracy = accuracy(u_pred, temp_inp)\n",
    "            test_loss += loss.item()\n",
    "        test_losses.append(test_loss)\n",
    "    if epochs % 10 == 0:\n",
    "        print(f\"Epoch {epochs}, Test-Loss {test_loss:.4e}, Test-Accuracy {test_accuracy:.4e}\")      \n",
    "    return test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Button "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training-Loss 6.5451e+05, Data-loss 6.4943e+05                  , pde-loss 2.4328e-09, initc-loss 8.4368e+05                    bc_loss 4.9905e+07\n",
      "Epoch 10, Training-Loss 6.6193e+05, Data-loss 6.5687e+05                  , pde-loss 2.6590e-07, initc-loss 8.4202e+05                    bc_loss 4.9724e+07\n",
      "Epoch 20, Training-Loss 6.6490e+05, Data-loss 6.5987e+05                  , pde-loss 3.7513e-06, initc-loss 8.4013e+05                    bc_loss 4.9518e+07\n",
      "Epoch 30, Training-Loss 6.5438e+05, Data-loss 6.4937e+05                  , pde-loss 2.9222e-06, initc-loss 8.3810e+05                    bc_loss 4.9298e+07\n",
      "Epoch 40, Training-Loss 6.5736e+05, Data-loss 6.5236e+05                  , pde-loss 8.2595e-07, initc-loss 8.3619e+05                    bc_loss 4.9092e+07\n",
      "Epoch 50, Training-Loss 6.5071e+05, Data-loss 6.4574e+05                  , pde-loss 1.4778e-07, initc-loss 8.3446e+05                    bc_loss 4.8904e+07\n",
      "Epoch 60, Training-Loss 6.4909e+05, Data-loss 6.4414e+05                  , pde-loss 6.8096e-08, initc-loss 8.3284e+05                    bc_loss 4.8728e+07\n",
      "Epoch 70, Training-Loss 6.4914e+05, Data-loss 6.4420e+05                  , pde-loss 2.4565e-08, initc-loss 8.3128e+05                    bc_loss 4.8559e+07\n",
      "Epoch 80, Training-Loss 6.4816e+05, Data-loss 6.4324e+05                  , pde-loss 1.2910e-08, initc-loss 8.2977e+05                    bc_loss 4.8397e+07\n",
      "Epoch 90, Training-Loss 6.3892e+05, Data-loss 6.3402e+05                  , pde-loss 1.2840e-08, initc-loss 8.2831e+05                    bc_loss 4.8238e+07\n",
      "Epoch 100, Training-Loss 6.5260e+05, Data-loss 6.4771e+05                  , pde-loss 9.5622e-09, initc-loss 8.2687e+05                    bc_loss 4.8083e+07\n",
      "Epoch 110, Training-Loss 6.4915e+05, Data-loss 6.4428e+05                  , pde-loss 1.0370e-08, initc-loss 8.2544e+05                    bc_loss 4.7929e+07\n",
      "Epoch 120, Training-Loss 6.5295e+05, Data-loss 6.4809e+05                  , pde-loss 2.1462e-08, initc-loss 8.2397e+05                    bc_loss 4.7771e+07\n",
      "Epoch 130, Training-Loss 6.4039e+05, Data-loss 6.3555e+05                  , pde-loss 2.6079e-08, initc-loss 8.2245e+05                    bc_loss 4.7607e+07\n",
      "Epoch 140, Training-Loss 6.4016e+05, Data-loss 6.3533e+05                  , pde-loss 1.9320e-08, initc-loss 8.2095e+05                    bc_loss 4.7446e+07\n",
      "Epoch 150, Training-Loss 6.4205e+05, Data-loss 6.3724e+05                  , pde-loss 1.4653e-08, initc-loss 8.1948e+05                    bc_loss 4.7288e+07\n",
      "Epoch 160, Training-Loss 6.3830e+05, Data-loss 6.3351e+05                  , pde-loss 1.3830e-08, initc-loss 8.1802e+05                    bc_loss 4.7132e+07\n",
      "Epoch 170, Training-Loss 6.3743e+05, Data-loss 6.3265e+05                  , pde-loss 8.6054e-09, initc-loss 8.1658e+05                    bc_loss 4.6977e+07\n",
      "Epoch 180, Training-Loss 6.3861e+05, Data-loss 6.3385e+05                  , pde-loss 6.7324e-09, initc-loss 8.1514e+05                    bc_loss 4.6823e+07\n",
      "Epoch 190, Training-Loss 6.2490e+05, Data-loss 6.2015e+05                  , pde-loss 9.4573e-09, initc-loss 8.1363e+05                    bc_loss 4.6661e+07\n",
      "Epoch 200, Training-Loss 6.3771e+05, Data-loss 6.3298e+05                  , pde-loss 8.5842e-09, initc-loss 8.1205e+05                    bc_loss 4.6492e+07\n",
      "Epoch 210, Training-Loss 6.3581e+05, Data-loss 6.3109e+05                  , pde-loss 1.4220e-08, initc-loss 8.1042e+05                    bc_loss 4.6317e+07\n",
      "Epoch 220, Training-Loss 6.3062e+05, Data-loss 6.2592e+05                  , pde-loss 2.0303e-08, initc-loss 8.0861e+05                    bc_loss 4.6124e+07\n",
      "Epoch 230, Training-Loss 6.2983e+05, Data-loss 6.2515e+05                  , pde-loss 2.9763e-08, initc-loss 8.0663e+05                    bc_loss 4.5913e+07\n",
      "Epoch 240, Training-Loss 6.2969e+05, Data-loss 6.2504e+05                  , pde-loss 1.8433e-08, initc-loss 8.0461e+05                    bc_loss 4.5697e+07\n",
      "Epoch 250, Training-Loss 6.2798e+05, Data-loss 6.2335e+05                  , pde-loss 8.4232e-09, initc-loss 8.0270e+05                    bc_loss 4.5493e+07\n",
      "Epoch 260, Training-Loss 6.2269e+05, Data-loss 6.1808e+05                  , pde-loss 5.7079e-09, initc-loss 8.0084e+05                    bc_loss 4.5296e+07\n",
      "Epoch 270, Training-Loss 6.2468e+05, Data-loss 6.2008e+05                  , pde-loss 4.2387e-09, initc-loss 7.9904e+05                    bc_loss 4.5104e+07\n",
      "Epoch 280, Training-Loss 6.1854e+05, Data-loss 6.1397e+05                  , pde-loss 3.3337e-09, initc-loss 7.9726e+05                    bc_loss 4.4915e+07\n",
      "Epoch 290, Training-Loss 6.1702e+05, Data-loss 6.1247e+05                  , pde-loss 1.6834e-09, initc-loss 7.9551e+05                    bc_loss 4.4730e+07\n",
      "Epoch 300, Training-Loss 6.2400e+05, Data-loss 6.1947e+05                  , pde-loss 3.9517e-10, initc-loss 7.9375e+05                    bc_loss 4.4543e+07\n",
      "Epoch 310, Training-Loss 6.1277e+05, Data-loss 6.0826e+05                  , pde-loss 9.4742e-10, initc-loss 7.9182e+05                    bc_loss 4.4338e+07\n",
      "Epoch 320, Training-Loss 6.0950e+05, Data-loss 6.0501e+05                  , pde-loss 2.1550e-09, initc-loss 7.8976e+05                    bc_loss 4.4121e+07\n",
      "Epoch 330, Training-Loss 6.0882e+05, Data-loss 6.0435e+05                  , pde-loss 4.4358e-09, initc-loss 7.8771e+05                    bc_loss 4.3904e+07\n",
      "Epoch 340, Training-Loss 6.0898e+05, Data-loss 6.0454e+05                  , pde-loss 3.0944e-09, initc-loss 7.8573e+05                    bc_loss 4.3696e+07\n",
      "Epoch 350, Training-Loss 6.0411e+05, Data-loss 5.9969e+05                  , pde-loss 2.5069e-09, initc-loss 7.8381e+05                    bc_loss 4.3492e+07\n",
      "Epoch 360, Training-Loss 6.0640e+05, Data-loss 6.0199e+05                  , pde-loss 2.3155e-09, initc-loss 7.8192e+05                    bc_loss 4.3294e+07\n",
      "Epoch 370, Training-Loss 6.1583e+05, Data-loss 6.1144e+05                  , pde-loss 1.6575e-09, initc-loss 7.8006e+05                    bc_loss 4.3098e+07\n",
      "Epoch 380, Training-Loss 6.0594e+05, Data-loss 6.0158e+05                  , pde-loss 1.7951e-09, initc-loss 7.7823e+05                    bc_loss 4.2906e+07\n",
      "Epoch 390, Training-Loss 6.0299e+05, Data-loss 5.9864e+05                  , pde-loss 1.8704e-09, initc-loss 7.7642e+05                    bc_loss 4.2716e+07\n",
      "Epoch 400, Training-Loss 6.0008e+05, Data-loss 5.9575e+05                  , pde-loss 1.6209e-09, initc-loss 7.7464e+05                    bc_loss 4.2529e+07\n",
      "Epoch 410, Training-Loss 5.8906e+05, Data-loss 5.8475e+05                  , pde-loss 1.6647e-09, initc-loss 7.7287e+05                    bc_loss 4.2344e+07\n",
      "Epoch 420, Training-Loss 6.0128e+05, Data-loss 5.9699e+05                  , pde-loss 1.2374e-09, initc-loss 7.7112e+05                    bc_loss 4.2161e+07\n",
      "Epoch 430, Training-Loss 5.9260e+05, Data-loss 5.8832e+05                  , pde-loss 1.0928e-09, initc-loss 7.6938e+05                    bc_loss 4.1979e+07\n",
      "Epoch 440, Training-Loss 5.9493e+05, Data-loss 5.9067e+05                  , pde-loss 1.0140e-09, initc-loss 7.6766e+05                    bc_loss 4.1799e+07\n",
      "Epoch 450, Training-Loss 5.9377e+05, Data-loss 5.8953e+05                  , pde-loss 9.0488e-10, initc-loss 7.6595e+05                    bc_loss 4.1621e+07\n",
      "Epoch 460, Training-Loss 5.9312e+05, Data-loss 5.8890e+05                  , pde-loss 7.3317e-10, initc-loss 7.6424e+05                    bc_loss 4.1443e+07\n",
      "Epoch 470, Training-Loss 5.8583e+05, Data-loss 5.8162e+05                  , pde-loss 9.1813e-10, initc-loss 7.6255e+05                    bc_loss 4.1267e+07\n",
      "Epoch 480, Training-Loss 5.8514e+05, Data-loss 5.8096e+05                  , pde-loss 8.2806e-10, initc-loss 7.6086e+05                    bc_loss 4.1092e+07\n",
      "Epoch 490, Training-Loss 5.8809e+05, Data-loss 5.8392e+05                  , pde-loss 7.8164e-10, initc-loss 7.5919e+05                    bc_loss 4.0917e+07\n",
      "Epoch 500, Training-Loss 5.8179e+05, Data-loss 5.7764e+05                  , pde-loss 7.9104e-10, initc-loss 7.5752e+05                    bc_loss 4.0744e+07\n",
      "Epoch 510, Training-Loss 5.9234e+05, Data-loss 5.8821e+05                  , pde-loss 6.3144e-10, initc-loss 7.5586e+05                    bc_loss 4.0573e+07\n",
      "Epoch 520, Training-Loss 5.8506e+05, Data-loss 5.8095e+05                  , pde-loss 6.7915e-10, initc-loss 7.5421e+05                    bc_loss 4.0401e+07\n",
      "Epoch 530, Training-Loss 5.7001e+05, Data-loss 5.6591e+05                  , pde-loss 7.4253e-10, initc-loss 7.5256e+05                    bc_loss 4.0231e+07\n",
      "Epoch 540, Training-Loss 5.6726e+05, Data-loss 5.6318e+05                  , pde-loss 6.7294e-10, initc-loss 7.5093e+05                    bc_loss 4.0062e+07\n",
      "Epoch 550, Training-Loss 5.7397e+05, Data-loss 5.6990e+05                  , pde-loss 5.8211e-10, initc-loss 7.4930e+05                    bc_loss 3.9894e+07\n",
      "Epoch 560, Training-Loss 5.6249e+05, Data-loss 5.5844e+05                  , pde-loss 6.2173e-10, initc-loss 7.4767e+05                    bc_loss 3.9726e+07\n",
      "Epoch 570, Training-Loss 5.6968e+05, Data-loss 5.6565e+05                  , pde-loss 5.2557e-10, initc-loss 7.4606e+05                    bc_loss 3.9560e+07\n",
      "Epoch 580, Training-Loss 5.6850e+05, Data-loss 5.6449e+05                  , pde-loss 5.2474e-10, initc-loss 7.4445e+05                    bc_loss 3.9394e+07\n",
      "Epoch 590, Training-Loss 5.7524e+05, Data-loss 5.7124e+05                  , pde-loss 3.7678e-10, initc-loss 7.4284e+05                    bc_loss 3.9229e+07\n",
      "Epoch 600, Training-Loss 5.6818e+05, Data-loss 5.6420e+05                  , pde-loss 3.5196e-10, initc-loss 7.4125e+05                    bc_loss 3.9065e+07\n",
      "Epoch 610, Training-Loss 5.7384e+05, Data-loss 5.6988e+05                  , pde-loss 3.0924e-10, initc-loss 7.3965e+05                    bc_loss 3.8901e+07\n",
      "Epoch 620, Training-Loss 5.7490e+05, Data-loss 5.7095e+05                  , pde-loss 3.0441e-10, initc-loss 7.3806e+05                    bc_loss 3.8738e+07\n",
      "Epoch 630, Training-Loss 5.6354e+05, Data-loss 5.5961e+05                  , pde-loss 2.7877e-10, initc-loss 7.3648e+05                    bc_loss 3.8576e+07\n",
      "Epoch 640, Training-Loss 5.6301e+05, Data-loss 5.5910e+05                  , pde-loss 3.0521e-10, initc-loss 7.3489e+05                    bc_loss 3.8414e+07\n",
      "Epoch 650, Training-Loss 5.6639e+05, Data-loss 5.6249e+05                  , pde-loss 2.6842e-10, initc-loss 7.3332e+05                    bc_loss 3.8253e+07\n",
      "Epoch 660, Training-Loss 5.6191e+05, Data-loss 5.5802e+05                  , pde-loss 2.8315e-10, initc-loss 7.3175e+05                    bc_loss 3.8093e+07\n",
      "Epoch 670, Training-Loss 5.5987e+05, Data-loss 5.5601e+05                  , pde-loss 2.4611e-10, initc-loss 7.3018e+05                    bc_loss 3.7933e+07\n",
      "Epoch 680, Training-Loss 5.5709e+05, Data-loss 5.5324e+05                  , pde-loss 2.7170e-10, initc-loss 7.2862e+05                    bc_loss 3.7774e+07\n",
      "Epoch 690, Training-Loss 5.5218e+05, Data-loss 5.4835e+05                  , pde-loss 2.4513e-10, initc-loss 7.2706e+05                    bc_loss 3.7615e+07\n",
      "Epoch 700, Training-Loss 5.5770e+05, Data-loss 5.5388e+05                  , pde-loss 2.2680e-10, initc-loss 7.2551e+05                    bc_loss 3.7457e+07\n",
      "Epoch 710, Training-Loss 5.5911e+05, Data-loss 5.5530e+05                  , pde-loss 2.2048e-10, initc-loss 7.2396e+05                    bc_loss 3.7300e+07\n",
      "Epoch 720, Training-Loss 5.4685e+05, Data-loss 5.4306e+05                  , pde-loss 2.1378e-10, initc-loss 7.2241e+05                    bc_loss 3.7143e+07\n",
      "Epoch 730, Training-Loss 5.5234e+05, Data-loss 5.4857e+05                  , pde-loss 1.8953e-10, initc-loss 7.2087e+05                    bc_loss 3.6987e+07\n",
      "Epoch 740, Training-Loss 5.4543e+05, Data-loss 5.4168e+05                  , pde-loss 1.9179e-10, initc-loss 7.1933e+05                    bc_loss 3.6832e+07\n",
      "Epoch 750, Training-Loss 5.4670e+05, Data-loss 5.4296e+05                  , pde-loss 1.8461e-10, initc-loss 7.1780e+05                    bc_loss 3.6677e+07\n",
      "Epoch 760, Training-Loss 5.4396e+05, Data-loss 5.4024e+05                  , pde-loss 1.6852e-10, initc-loss 7.1627e+05                    bc_loss 3.6522e+07\n",
      "Epoch 770, Training-Loss 5.4457e+05, Data-loss 5.4086e+05                  , pde-loss 1.6903e-10, initc-loss 7.1475e+05                    bc_loss 3.6368e+07\n",
      "Epoch 780, Training-Loss 5.4063e+05, Data-loss 5.3694e+05                  , pde-loss 1.6424e-10, initc-loss 7.1323e+05                    bc_loss 3.6215e+07\n",
      "Epoch 790, Training-Loss 5.5149e+05, Data-loss 5.4781e+05                  , pde-loss 1.4408e-10, initc-loss 7.1171e+05                    bc_loss 3.6062e+07\n",
      "Epoch 800, Training-Loss 5.4107e+05, Data-loss 5.3741e+05                  , pde-loss 1.4580e-10, initc-loss 7.1019e+05                    bc_loss 3.5909e+07\n",
      "Epoch 810, Training-Loss 5.4418e+05, Data-loss 5.4054e+05                  , pde-loss 1.3217e-10, initc-loss 7.0868e+05                    bc_loss 3.5757e+07\n",
      "Epoch 820, Training-Loss 5.3520e+05, Data-loss 5.3157e+05                  , pde-loss 1.4006e-10, initc-loss 7.0717e+05                    bc_loss 3.5606e+07\n",
      "Epoch 830, Training-Loss 5.3698e+05, Data-loss 5.3336e+05                  , pde-loss 1.2693e-10, initc-loss 7.0567e+05                    bc_loss 3.5455e+07\n",
      "Epoch 840, Training-Loss 5.3262e+05, Data-loss 5.2902e+05                  , pde-loss 1.2427e-10, initc-loss 7.0416e+05                    bc_loss 3.5304e+07\n",
      "Epoch 850, Training-Loss 5.3369e+05, Data-loss 5.3010e+05                  , pde-loss 1.2064e-10, initc-loss 7.0266e+05                    bc_loss 3.5154e+07\n",
      "Epoch 860, Training-Loss 5.2783e+05, Data-loss 5.2426e+05                  , pde-loss 1.2753e-10, initc-loss 7.0117e+05                    bc_loss 3.5005e+07\n",
      "Epoch 870, Training-Loss 5.3813e+05, Data-loss 5.3458e+05                  , pde-loss 1.0893e-10, initc-loss 6.9968e+05                    bc_loss 3.4856e+07\n",
      "Epoch 880, Training-Loss 5.2555e+05, Data-loss 5.2201e+05                  , pde-loss 1.1443e-10, initc-loss 6.9820e+05                    bc_loss 3.4708e+07\n",
      "Epoch 890, Training-Loss 5.2473e+05, Data-loss 5.2121e+05                  , pde-loss 1.0060e-10, initc-loss 6.9671e+05                    bc_loss 3.4560e+07\n",
      "Epoch 900, Training-Loss 5.2604e+05, Data-loss 5.2253e+05                  , pde-loss 8.9835e-11, initc-loss 6.9523e+05                    bc_loss 3.4413e+07\n",
      "Epoch 910, Training-Loss 5.3231e+05, Data-loss 5.2881e+05                  , pde-loss 7.7880e-11, initc-loss 6.9375e+05                    bc_loss 3.4266e+07\n",
      "Epoch 920, Training-Loss 5.1967e+05, Data-loss 5.1619e+05                  , pde-loss 8.6186e-11, initc-loss 6.9227e+05                    bc_loss 3.4119e+07\n",
      "Epoch 930, Training-Loss 5.2200e+05, Data-loss 5.1854e+05                  , pde-loss 7.5193e-11, initc-loss 6.9080e+05                    bc_loss 3.3972e+07\n",
      "Epoch 940, Training-Loss 5.3046e+05, Data-loss 5.2701e+05                  , pde-loss 6.7376e-11, initc-loss 6.8933e+05                    bc_loss 3.3827e+07\n",
      "Epoch 950, Training-Loss 5.1917e+05, Data-loss 5.1573e+05                  , pde-loss 6.4814e-11, initc-loss 6.8787e+05                    bc_loss 3.3682e+07\n",
      "Epoch 960, Training-Loss 5.2740e+05, Data-loss 5.2398e+05                  , pde-loss 4.4863e-11, initc-loss 6.8641e+05                    bc_loss 3.3537e+07\n",
      "Epoch 970, Training-Loss 5.2015e+05, Data-loss 5.1674e+05                  , pde-loss 3.1425e-11, initc-loss 6.8495e+05                    bc_loss 3.3393e+07\n",
      "Epoch 980, Training-Loss 5.3104e+05, Data-loss 5.2765e+05                  , pde-loss 3.3321e-12, initc-loss 6.8349e+05                    bc_loss 3.3249e+07\n",
      "Epoch 990, Training-Loss 5.2307e+05, Data-loss 5.1969e+05                  , pde-loss 1.4639e-10, initc-loss 6.8195e+05                    bc_loss 3.3098e+07\n",
      "Epoch 1000, Training-Loss 5.1289e+05, Data-loss 5.0953e+05                  , pde-loss 2.3103e-10, initc-loss 6.8009e+05                    bc_loss 3.2915e+07\n",
      "Epoch 1010, Training-Loss 5.2468e+05, Data-loss 5.2134e+05                  , pde-loss 7.4316e-11, initc-loss 6.7837e+05                    bc_loss 3.2745e+07\n",
      "Epoch 1020, Training-Loss 5.0155e+05, Data-loss 4.9822e+05                  , pde-loss 8.5029e-11, initc-loss 6.7668e+05                    bc_loss 3.2579e+07\n",
      "Epoch 1030, Training-Loss 5.1083e+05, Data-loss 5.0752e+05                  , pde-loss 6.8116e-11, initc-loss 6.7502e+05                    bc_loss 3.2417e+07\n",
      "Epoch 1040, Training-Loss 5.0686e+05, Data-loss 5.0357e+05                  , pde-loss 6.5609e-11, initc-loss 6.7339e+05                    bc_loss 3.2257e+07\n",
      "Epoch 1050, Training-Loss 5.0336e+05, Data-loss 5.0008e+05                  , pde-loss 7.1300e-11, initc-loss 6.7178e+05                    bc_loss 3.2099e+07\n",
      "Epoch 1060, Training-Loss 5.0286e+05, Data-loss 4.9959e+05                  , pde-loss 6.4817e-11, initc-loss 6.7018e+05                    bc_loss 3.1944e+07\n",
      "Epoch 1070, Training-Loss 5.0727e+05, Data-loss 5.0402e+05                  , pde-loss 6.7319e-11, initc-loss 6.6860e+05                    bc_loss 3.1789e+07\n",
      "Epoch 1080, Training-Loss 5.0942e+05, Data-loss 5.0619e+05                  , pde-loss 5.5800e-11, initc-loss 6.6704e+05                    bc_loss 3.1637e+07\n",
      "Epoch 1090, Training-Loss 5.0378e+05, Data-loss 5.0056e+05                  , pde-loss 6.0073e-11, initc-loss 6.6548e+05                    bc_loss 3.1485e+07\n",
      "Epoch 1100, Training-Loss 5.0318e+05, Data-loss 4.9998e+05                  , pde-loss 5.9696e-11, initc-loss 6.6393e+05                    bc_loss 3.1335e+07\n",
      "Epoch 1110, Training-Loss 5.0045e+05, Data-loss 4.9726e+05                  , pde-loss 5.8032e-11, initc-loss 6.6239e+05                    bc_loss 3.1185e+07\n",
      "Epoch 1120, Training-Loss 4.9673e+05, Data-loss 4.9356e+05                  , pde-loss 5.3129e-11, initc-loss 6.6086e+05                    bc_loss 3.1037e+07\n",
      "Epoch 1130, Training-Loss 4.8558e+05, Data-loss 4.8242e+05                  , pde-loss 6.1549e-11, initc-loss 6.5934e+05                    bc_loss 3.0889e+07\n",
      "Epoch 1140, Training-Loss 4.9682e+05, Data-loss 4.9368e+05                  , pde-loss 5.1645e-11, initc-loss 6.5782e+05                    bc_loss 3.0743e+07\n",
      "Epoch 1150, Training-Loss 4.9720e+05, Data-loss 4.9408e+05                  , pde-loss 5.0648e-11, initc-loss 6.5631e+05                    bc_loss 3.0596e+07\n",
      "Epoch 1160, Training-Loss 4.9022e+05, Data-loss 4.8711e+05                  , pde-loss 4.9033e-11, initc-loss 6.5480e+05                    bc_loss 3.0451e+07\n",
      "Epoch 1170, Training-Loss 4.9010e+05, Data-loss 4.8700e+05                  , pde-loss 4.9920e-11, initc-loss 6.5330e+05                    bc_loss 3.0307e+07\n",
      "Epoch 1180, Training-Loss 4.9159e+05, Data-loss 4.8851e+05                  , pde-loss 4.3996e-11, initc-loss 6.5181e+05                    bc_loss 3.0163e+07\n",
      "Epoch 1190, Training-Loss 4.8477e+05, Data-loss 4.8170e+05                  , pde-loss 4.5192e-11, initc-loss 6.5032e+05                    bc_loss 3.0020e+07\n",
      "Epoch 1200, Training-Loss 4.8214e+05, Data-loss 4.7908e+05                  , pde-loss 4.5270e-11, initc-loss 6.4884e+05                    bc_loss 2.9877e+07\n",
      "Epoch 1210, Training-Loss 4.8771e+05, Data-loss 4.8467e+05                  , pde-loss 3.5460e-11, initc-loss 6.4736e+05                    bc_loss 2.9736e+07\n",
      "Epoch 1220, Training-Loss 4.8386e+05, Data-loss 4.8084e+05                  , pde-loss 4.2352e-11, initc-loss 6.4589e+05                    bc_loss 2.9594e+07\n",
      "Epoch 1230, Training-Loss 4.9131e+05, Data-loss 4.8830e+05                  , pde-loss 3.5714e-11, initc-loss 6.4441e+05                    bc_loss 2.9453e+07\n",
      "Epoch 1240, Training-Loss 4.9007e+05, Data-loss 4.8708e+05                  , pde-loss 3.2119e-11, initc-loss 6.4295e+05                    bc_loss 2.9313e+07\n",
      "Epoch 1250, Training-Loss 4.8255e+05, Data-loss 4.7956e+05                  , pde-loss 3.2380e-11, initc-loss 6.4148e+05                    bc_loss 2.9174e+07\n",
      "Epoch 1260, Training-Loss 4.8511e+05, Data-loss 4.8214e+05                  , pde-loss 3.1411e-11, initc-loss 6.4002e+05                    bc_loss 2.9034e+07\n",
      "Epoch 1270, Training-Loss 4.7720e+05, Data-loss 4.7425e+05                  , pde-loss 3.2278e-11, initc-loss 6.3857e+05                    bc_loss 2.8896e+07\n",
      "Epoch 1280, Training-Loss 4.8110e+05, Data-loss 4.7816e+05                  , pde-loss 2.7410e-11, initc-loss 6.3712e+05                    bc_loss 2.8758e+07\n",
      "Epoch 1290, Training-Loss 4.7831e+05, Data-loss 4.7539e+05                  , pde-loss 2.8515e-11, initc-loss 6.3567e+05                    bc_loss 2.8620e+07\n",
      "Epoch 1300, Training-Loss 4.8204e+05, Data-loss 4.7912e+05                  , pde-loss 2.6337e-11, initc-loss 6.3422e+05                    bc_loss 2.8483e+07\n",
      "Epoch 1310, Training-Loss 4.7095e+05, Data-loss 4.6805e+05                  , pde-loss 2.8719e-11, initc-loss 6.3278e+05                    bc_loss 2.8347e+07\n",
      "Epoch 1320, Training-Loss 4.7609e+05, Data-loss 4.7320e+05                  , pde-loss 2.4295e-11, initc-loss 6.3135e+05                    bc_loss 2.8211e+07\n",
      "Epoch 1330, Training-Loss 4.7330e+05, Data-loss 4.7042e+05                  , pde-loss 2.7233e-11, initc-loss 6.2991e+05                    bc_loss 2.8075e+07\n",
      "Epoch 1340, Training-Loss 4.6993e+05, Data-loss 4.6707e+05                  , pde-loss 2.6818e-11, initc-loss 6.2848e+05                    bc_loss 2.7940e+07\n",
      "Epoch 1350, Training-Loss 4.6455e+05, Data-loss 4.6170e+05                  , pde-loss 2.6868e-11, initc-loss 6.2705e+05                    bc_loss 2.7806e+07\n",
      "Epoch 1360, Training-Loss 4.6624e+05, Data-loss 4.6341e+05                  , pde-loss 2.5554e-11, initc-loss 6.2563e+05                    bc_loss 2.7672e+07\n",
      "Epoch 1370, Training-Loss 4.6580e+05, Data-loss 4.6298e+05                  , pde-loss 2.3936e-11, initc-loss 6.2421e+05                    bc_loss 2.7538e+07\n",
      "Epoch 1380, Training-Loss 4.6868e+05, Data-loss 4.6588e+05                  , pde-loss 2.2640e-11, initc-loss 6.2279e+05                    bc_loss 2.7405e+07\n",
      "Epoch 1390, Training-Loss 4.6829e+05, Data-loss 4.6550e+05                  , pde-loss 2.0203e-11, initc-loss 6.2138e+05                    bc_loss 2.7273e+07\n",
      "Epoch 1400, Training-Loss 4.6153e+05, Data-loss 4.5875e+05                  , pde-loss 2.2584e-11, initc-loss 6.1997e+05                    bc_loss 2.7141e+07\n",
      "Epoch 1410, Training-Loss 4.6618e+05, Data-loss 4.6341e+05                  , pde-loss 1.9649e-11, initc-loss 6.1856e+05                    bc_loss 2.7009e+07\n",
      "Epoch 1420, Training-Loss 4.5512e+05, Data-loss 4.5237e+05                  , pde-loss 2.4833e-11, initc-loss 6.1715e+05                    bc_loss 2.6877e+07\n",
      "Epoch 1430, Training-Loss 4.6119e+05, Data-loss 4.5845e+05                  , pde-loss 2.1172e-11, initc-loss 6.1575e+05                    bc_loss 2.6747e+07\n",
      "Epoch 1440, Training-Loss 4.5593e+05, Data-loss 4.5321e+05                  , pde-loss 1.9898e-11, initc-loss 6.1435e+05                    bc_loss 2.6616e+07\n",
      "Epoch 1450, Training-Loss 4.6016e+05, Data-loss 4.5745e+05                  , pde-loss 1.9860e-11, initc-loss 6.1295e+05                    bc_loss 2.6486e+07\n",
      "Epoch 1460, Training-Loss 4.6042e+05, Data-loss 4.5772e+05                  , pde-loss 1.7095e-11, initc-loss 6.1156e+05                    bc_loss 2.6357e+07\n",
      "Epoch 1470, Training-Loss 4.5212e+05, Data-loss 4.4944e+05                  , pde-loss 1.9803e-11, initc-loss 6.1016e+05                    bc_loss 2.6227e+07\n",
      "Epoch 1480, Training-Loss 4.5510e+05, Data-loss 4.5243e+05                  , pde-loss 1.7872e-11, initc-loss 6.0877e+05                    bc_loss 2.6099e+07\n",
      "Epoch 1490, Training-Loss 4.5149e+05, Data-loss 4.4883e+05                  , pde-loss 1.9269e-11, initc-loss 6.0739e+05                    bc_loss 2.5971e+07\n",
      "Epoch 1500, Training-Loss 4.4378e+05, Data-loss 4.4114e+05                  , pde-loss 1.9898e-11, initc-loss 6.0601e+05                    bc_loss 2.5843e+07\n",
      "Epoch 1510, Training-Loss 4.4640e+05, Data-loss 4.4377e+05                  , pde-loss 1.7350e-11, initc-loss 6.0463e+05                    bc_loss 2.5716e+07\n",
      "Epoch 1520, Training-Loss 4.4280e+05, Data-loss 4.4018e+05                  , pde-loss 1.9095e-11, initc-loss 6.0325e+05                    bc_loss 2.5589e+07\n",
      "Epoch 1530, Training-Loss 4.4385e+05, Data-loss 4.4125e+05                  , pde-loss 1.7080e-11, initc-loss 6.0188e+05                    bc_loss 2.5463e+07\n",
      "Epoch 1540, Training-Loss 4.4861e+05, Data-loss 4.4601e+05                  , pde-loss 1.4590e-11, initc-loss 6.0051e+05                    bc_loss 2.5337e+07\n",
      "Epoch 1550, Training-Loss 4.3903e+05, Data-loss 4.3644e+05                  , pde-loss 1.7089e-11, initc-loss 5.9914e+05                    bc_loss 2.5211e+07\n",
      "Epoch 1560, Training-Loss 4.4078e+05, Data-loss 4.3821e+05                  , pde-loss 1.5162e-11, initc-loss 5.9778e+05                    bc_loss 2.5086e+07\n",
      "Epoch 1570, Training-Loss 4.3269e+05, Data-loss 4.3014e+05                  , pde-loss 1.6212e-11, initc-loss 5.9642e+05                    bc_loss 2.4961e+07\n",
      "Epoch 1580, Training-Loss 4.4443e+05, Data-loss 4.4189e+05                  , pde-loss 1.2604e-11, initc-loss 5.9505e+05                    bc_loss 2.4837e+07\n",
      "Epoch 1590, Training-Loss 4.3961e+05, Data-loss 4.3708e+05                  , pde-loss 1.4421e-11, initc-loss 5.9369e+05                    bc_loss 2.4713e+07\n",
      "Epoch 1600, Training-Loss 4.3792e+05, Data-loss 4.3540e+05                  , pde-loss 1.2731e-11, initc-loss 5.9234e+05                    bc_loss 2.4589e+07\n",
      "Epoch 1610, Training-Loss 4.3466e+05, Data-loss 4.3216e+05                  , pde-loss 1.3141e-11, initc-loss 5.9099e+05                    bc_loss 2.4466e+07\n",
      "Epoch 1620, Training-Loss 4.3750e+05, Data-loss 4.3501e+05                  , pde-loss 1.1962e-11, initc-loss 5.8964e+05                    bc_loss 2.4343e+07\n",
      "Epoch 1630, Training-Loss 4.3637e+05, Data-loss 4.3389e+05                  , pde-loss 1.2431e-11, initc-loss 5.8829e+05                    bc_loss 2.4221e+07\n",
      "Epoch 1640, Training-Loss 4.4006e+05, Data-loss 4.3759e+05                  , pde-loss 1.1035e-11, initc-loss 5.8695e+05                    bc_loss 2.4099e+07\n",
      "Epoch 1650, Training-Loss 4.2949e+05, Data-loss 4.2703e+05                  , pde-loss 1.2061e-11, initc-loss 5.8560e+05                    bc_loss 2.3977e+07\n",
      "Epoch 1660, Training-Loss 4.3229e+05, Data-loss 4.2985e+05                  , pde-loss 1.1907e-11, initc-loss 5.8426e+05                    bc_loss 2.3856e+07\n",
      "Epoch 1670, Training-Loss 4.3277e+05, Data-loss 4.3033e+05                  , pde-loss 1.0629e-11, initc-loss 5.8292e+05                    bc_loss 2.3735e+07\n",
      "Epoch 1680, Training-Loss 4.2464e+05, Data-loss 4.2222e+05                  , pde-loss 1.2625e-11, initc-loss 5.8159e+05                    bc_loss 2.3615e+07\n",
      "Epoch 1690, Training-Loss 4.3237e+05, Data-loss 4.2996e+05                  , pde-loss 9.6843e-12, initc-loss 5.8026e+05                    bc_loss 2.3495e+07\n",
      "Epoch 1700, Training-Loss 4.2244e+05, Data-loss 4.2005e+05                  , pde-loss 1.1471e-11, initc-loss 5.7892e+05                    bc_loss 2.3375e+07\n",
      "Epoch 1710, Training-Loss 4.2565e+05, Data-loss 4.2327e+05                  , pde-loss 1.0538e-11, initc-loss 5.7760e+05                    bc_loss 2.3256e+07\n",
      "Epoch 1720, Training-Loss 4.3584e+05, Data-loss 4.3347e+05                  , pde-loss 8.6239e-12, initc-loss 5.7627e+05                    bc_loss 2.3137e+07\n",
      "Epoch 1730, Training-Loss 4.2256e+05, Data-loss 4.2020e+05                  , pde-loss 1.0717e-11, initc-loss 5.7495e+05                    bc_loss 2.3019e+07\n",
      "Epoch 1740, Training-Loss 4.2199e+05, Data-loss 4.1965e+05                  , pde-loss 1.0251e-11, initc-loss 5.7363e+05                    bc_loss 2.2900e+07\n",
      "Epoch 1750, Training-Loss 4.1778e+05, Data-loss 4.1544e+05                  , pde-loss 1.0785e-11, initc-loss 5.7231e+05                    bc_loss 2.2783e+07\n",
      "Epoch 1760, Training-Loss 4.1952e+05, Data-loss 4.1720e+05                  , pde-loss 9.7811e-12, initc-loss 5.7099e+05                    bc_loss 2.2665e+07\n",
      "Epoch 1770, Training-Loss 4.1338e+05, Data-loss 4.1106e+05                  , pde-loss 1.0289e-11, initc-loss 5.6968e+05                    bc_loss 2.2548e+07\n",
      "Epoch 1780, Training-Loss 4.1394e+05, Data-loss 4.1164e+05                  , pde-loss 9.7734e-12, initc-loss 5.6837e+05                    bc_loss 2.2432e+07\n",
      "Epoch 1790, Training-Loss 4.1318e+05, Data-loss 4.1090e+05                  , pde-loss 9.0348e-12, initc-loss 5.6706e+05                    bc_loss 2.2316e+07\n",
      "Epoch 1800, Training-Loss 4.1581e+05, Data-loss 4.1354e+05                  , pde-loss 8.8431e-12, initc-loss 5.6575e+05                    bc_loss 2.2200e+07\n",
      "Epoch 1810, Training-Loss 4.1679e+05, Data-loss 4.1452e+05                  , pde-loss 8.2205e-12, initc-loss 5.6445e+05                    bc_loss 2.2084e+07\n",
      "Epoch 1820, Training-Loss 4.1307e+05, Data-loss 4.1082e+05                  , pde-loss 8.5266e-12, initc-loss 5.6314e+05                    bc_loss 2.1969e+07\n",
      "Epoch 1830, Training-Loss 4.1541e+05, Data-loss 4.1317e+05                  , pde-loss 7.8797e-12, initc-loss 5.6185e+05                    bc_loss 2.1854e+07\n",
      "Epoch 1840, Training-Loss 4.0674e+05, Data-loss 4.0451e+05                  , pde-loss 8.3828e-12, initc-loss 5.6055e+05                    bc_loss 2.1740e+07\n",
      "Epoch 1850, Training-Loss 4.1048e+05, Data-loss 4.0826e+05                  , pde-loss 7.9997e-12, initc-loss 5.5925e+05                    bc_loss 2.1626e+07\n",
      "Epoch 1860, Training-Loss 4.1121e+05, Data-loss 4.0900e+05                  , pde-loss 7.9293e-12, initc-loss 5.5796e+05                    bc_loss 2.1512e+07\n",
      "Epoch 1870, Training-Loss 4.0090e+05, Data-loss 3.9870e+05                  , pde-loss 8.5473e-12, initc-loss 5.5667e+05                    bc_loss 2.1399e+07\n",
      "Epoch 1880, Training-Loss 4.0298e+05, Data-loss 4.0080e+05                  , pde-loss 7.9127e-12, initc-loss 5.5538e+05                    bc_loss 2.1286e+07\n",
      "Epoch 1890, Training-Loss 4.0947e+05, Data-loss 4.0730e+05                  , pde-loss 6.7188e-12, initc-loss 5.5410e+05                    bc_loss 2.1174e+07\n",
      "Epoch 1900, Training-Loss 4.0705e+05, Data-loss 4.0489e+05                  , pde-loss 6.5377e-12, initc-loss 5.5281e+05                    bc_loss 2.1062e+07\n",
      "Epoch 1910, Training-Loss 4.0544e+05, Data-loss 4.0329e+05                  , pde-loss 6.8810e-12, initc-loss 5.5153e+05                    bc_loss 2.0950e+07\n",
      "Epoch 1920, Training-Loss 3.9735e+05, Data-loss 3.9521e+05                  , pde-loss 7.7843e-12, initc-loss 5.5025e+05                    bc_loss 2.0838e+07\n",
      "Epoch 1930, Training-Loss 4.0385e+05, Data-loss 4.0172e+05                  , pde-loss 6.8246e-12, initc-loss 5.4897e+05                    bc_loss 2.0727e+07\n",
      "Epoch 1940, Training-Loss 3.9770e+05, Data-loss 3.9559e+05                  , pde-loss 7.3069e-12, initc-loss 5.4770e+05                    bc_loss 2.0617e+07\n",
      "Epoch 1950, Training-Loss 3.9873e+05, Data-loss 3.9662e+05                  , pde-loss 6.5590e-12, initc-loss 5.4643e+05                    bc_loss 2.0506e+07\n",
      "Epoch 1960, Training-Loss 3.9534e+05, Data-loss 3.9325e+05                  , pde-loss 6.8792e-12, initc-loss 5.4516e+05                    bc_loss 2.0397e+07\n",
      "Epoch 1970, Training-Loss 3.9768e+05, Data-loss 3.9559e+05                  , pde-loss 5.6137e-12, initc-loss 5.4389e+05                    bc_loss 2.0287e+07\n",
      "Epoch 1980, Training-Loss 3.9837e+05, Data-loss 3.9629e+05                  , pde-loss 6.0245e-12, initc-loss 5.4262e+05                    bc_loss 2.0178e+07\n",
      "Epoch 1990, Training-Loss 3.9560e+05, Data-loss 3.9354e+05                  , pde-loss 5.5399e-12, initc-loss 5.4136e+05                    bc_loss 2.0069e+07\n",
      "Epoch 2000, Training-Loss 3.9020e+05, Data-loss 3.8815e+05                  , pde-loss 6.0786e-12, initc-loss 5.4010e+05                    bc_loss 1.9960e+07\n",
      "Epoch 2010, Training-Loss 3.8642e+05, Data-loss 3.8438e+05                  , pde-loss 6.1288e-12, initc-loss 5.3884e+05                    bc_loss 1.9852e+07\n",
      "Epoch 2020, Training-Loss 3.8936e+05, Data-loss 3.8733e+05                  , pde-loss 5.8705e-12, initc-loss 5.3758e+05                    bc_loss 1.9744e+07\n",
      "Epoch 2030, Training-Loss 3.9379e+05, Data-loss 3.9177e+05                  , pde-loss 4.9904e-12, initc-loss 5.3632e+05                    bc_loss 1.9636e+07\n",
      "Epoch 2040, Training-Loss 3.8579e+05, Data-loss 3.8378e+05                  , pde-loss 5.6061e-12, initc-loss 5.3507e+05                    bc_loss 1.9529e+07\n",
      "Epoch 2050, Training-Loss 3.9104e+05, Data-loss 3.8905e+05                  , pde-loss 5.3011e-12, initc-loss 5.3382e+05                    bc_loss 1.9422e+07\n",
      "Epoch 2060, Training-Loss 3.8468e+05, Data-loss 3.8269e+05                  , pde-loss 5.3326e-12, initc-loss 5.3257e+05                    bc_loss 1.9316e+07\n",
      "Epoch 2070, Training-Loss 3.9327e+05, Data-loss 3.9130e+05                  , pde-loss 4.4622e-12, initc-loss 5.3132e+05                    bc_loss 1.9210e+07\n",
      "Epoch 2080, Training-Loss 3.8153e+05, Data-loss 3.7957e+05                  , pde-loss 5.5096e-12, initc-loss 5.3007e+05                    bc_loss 1.9104e+07\n",
      "Epoch 2090, Training-Loss 3.8107e+05, Data-loss 3.7911e+05                  , pde-loss 5.3568e-12, initc-loss 5.2883e+05                    bc_loss 1.8998e+07\n",
      "Epoch 2100, Training-Loss 3.7902e+05, Data-loss 3.7708e+05                  , pde-loss 5.2477e-12, initc-loss 5.2759e+05                    bc_loss 1.8893e+07\n",
      "Epoch 2110, Training-Loss 3.7514e+05, Data-loss 3.7320e+05                  , pde-loss 5.3945e-12, initc-loss 5.2635e+05                    bc_loss 1.8788e+07\n",
      "Epoch 2120, Training-Loss 3.8292e+05, Data-loss 3.8100e+05                  , pde-loss 4.6199e-12, initc-loss 5.2511e+05                    bc_loss 1.8684e+07\n",
      "Epoch 2130, Training-Loss 3.7819e+05, Data-loss 3.7628e+05                  , pde-loss 4.8817e-12, initc-loss 5.2388e+05                    bc_loss 1.8580e+07\n",
      "Epoch 2140, Training-Loss 3.8210e+05, Data-loss 3.8020e+05                  , pde-loss 4.7200e-12, initc-loss 5.2264e+05                    bc_loss 1.8476e+07\n",
      "Epoch 2150, Training-Loss 3.7798e+05, Data-loss 3.7609e+05                  , pde-loss 4.5633e-12, initc-loss 5.2141e+05                    bc_loss 1.8373e+07\n",
      "Epoch 2160, Training-Loss 3.6974e+05, Data-loss 3.6786e+05                  , pde-loss 4.8187e-12, initc-loss 5.2019e+05                    bc_loss 1.8270e+07\n",
      "Epoch 2170, Training-Loss 3.8501e+05, Data-loss 3.8314e+05                  , pde-loss 3.6264e-12, initc-loss 5.1896e+05                    bc_loss 1.8167e+07\n",
      "Epoch 2180, Training-Loss 3.7311e+05, Data-loss 3.7125e+05                  , pde-loss 4.5339e-12, initc-loss 5.1774e+05                    bc_loss 1.8065e+07\n",
      "Epoch 2190, Training-Loss 3.7373e+05, Data-loss 3.7188e+05                  , pde-loss 4.1986e-12, initc-loss 5.1652e+05                    bc_loss 1.7963e+07\n",
      "Epoch 2200, Training-Loss 3.7316e+05, Data-loss 3.7133e+05                  , pde-loss 4.2118e-12, initc-loss 5.1530e+05                    bc_loss 1.7861e+07\n",
      "Epoch 2210, Training-Loss 3.6421e+05, Data-loss 3.6238e+05                  , pde-loss 4.5596e-12, initc-loss 5.1408e+05                    bc_loss 1.7760e+07\n",
      "Epoch 2220, Training-Loss 3.7438e+05, Data-loss 3.7256e+05                  , pde-loss 3.7873e-12, initc-loss 5.1286e+05                    bc_loss 1.7659e+07\n",
      "Epoch 2230, Training-Loss 3.6366e+05, Data-loss 3.6185e+05                  , pde-loss 4.4257e-12, initc-loss 5.1165e+05                    bc_loss 1.7558e+07\n",
      "Epoch 2240, Training-Loss 3.6912e+05, Data-loss 3.6732e+05                  , pde-loss 3.7688e-12, initc-loss 5.1044e+05                    bc_loss 1.7458e+07\n",
      "Epoch 2250, Training-Loss 3.6693e+05, Data-loss 3.6515e+05                  , pde-loss 3.8796e-12, initc-loss 5.0923e+05                    bc_loss 1.7358e+07\n",
      "Epoch 2260, Training-Loss 3.7281e+05, Data-loss 3.7103e+05                  , pde-loss 3.3393e-12, initc-loss 5.0802e+05                    bc_loss 1.7258e+07\n",
      "Epoch 2270, Training-Loss 3.6024e+05, Data-loss 3.5848e+05                  , pde-loss 3.8087e-12, initc-loss 5.0681e+05                    bc_loss 1.7159e+07\n",
      "Epoch 2280, Training-Loss 3.6944e+05, Data-loss 3.6769e+05                  , pde-loss 3.3422e-12, initc-loss 5.0561e+05                    bc_loss 1.7060e+07\n",
      "Epoch 2290, Training-Loss 3.6909e+05, Data-loss 3.6734e+05                  , pde-loss 3.4738e-12, initc-loss 5.0440e+05                    bc_loss 1.6961e+07\n",
      "Epoch 2300, Training-Loss 3.6117e+05, Data-loss 3.5944e+05                  , pde-loss 3.6262e-12, initc-loss 5.0320e+05                    bc_loss 1.6863e+07\n",
      "Epoch 2310, Training-Loss 3.6299e+05, Data-loss 3.6127e+05                  , pde-loss 3.2662e-12, initc-loss 5.0201e+05                    bc_loss 1.6765e+07\n",
      "Epoch 2320, Training-Loss 3.5528e+05, Data-loss 3.5356e+05                  , pde-loss 3.6989e-12, initc-loss 5.0081e+05                    bc_loss 1.6667e+07\n",
      "Epoch 2330, Training-Loss 3.6236e+05, Data-loss 3.6065e+05                  , pde-loss 3.0465e-12, initc-loss 4.9962e+05                    bc_loss 1.6570e+07\n",
      "Epoch 2340, Training-Loss 3.5874e+05, Data-loss 3.5704e+05                  , pde-loss 3.5751e-12, initc-loss 4.9842e+05                    bc_loss 1.6473e+07\n",
      "Epoch 2350, Training-Loss 3.5463e+05, Data-loss 3.5294e+05                  , pde-loss 3.3207e-12, initc-loss 4.9723e+05                    bc_loss 1.6376e+07\n",
      "Epoch 2360, Training-Loss 3.6058e+05, Data-loss 3.5890e+05                  , pde-loss 2.7097e-12, initc-loss 4.9604e+05                    bc_loss 1.6280e+07\n",
      "Epoch 2370, Training-Loss 3.5964e+05, Data-loss 3.5797e+05                  , pde-loss 2.9272e-12, initc-loss 4.9486e+05                    bc_loss 1.6184e+07\n",
      "Epoch 2380, Training-Loss 3.5228e+05, Data-loss 3.5062e+05                  , pde-loss 3.0296e-12, initc-loss 4.9367e+05                    bc_loss 1.6088e+07\n",
      "Epoch 2390, Training-Loss 3.4519e+05, Data-loss 3.4354e+05                  , pde-loss 3.4012e-12, initc-loss 4.9249e+05                    bc_loss 1.5993e+07\n",
      "Epoch 2400, Training-Loss 3.4999e+05, Data-loss 3.4835e+05                  , pde-loss 3.1153e-12, initc-loss 4.9131e+05                    bc_loss 1.5898e+07\n",
      "Epoch 2410, Training-Loss 3.5039e+05, Data-loss 3.4876e+05                  , pde-loss 2.9534e-12, initc-loss 4.9014e+05                    bc_loss 1.5803e+07\n",
      "Epoch 2420, Training-Loss 3.5346e+05, Data-loss 3.5185e+05                  , pde-loss 2.6794e-12, initc-loss 4.8896e+05                    bc_loss 1.5709e+07\n",
      "Epoch 2430, Training-Loss 3.4510e+05, Data-loss 3.4348e+05                  , pde-loss 3.0741e-12, initc-loss 4.8778e+05                    bc_loss 1.5615e+07\n",
      "Epoch 2440, Training-Loss 3.5720e+05, Data-loss 3.5560e+05                  , pde-loss 2.5878e-12, initc-loss 4.8661e+05                    bc_loss 1.5521e+07\n",
      "Epoch 2450, Training-Loss 3.4627e+05, Data-loss 3.4468e+05                  , pde-loss 2.7752e-12, initc-loss 4.8544e+05                    bc_loss 1.5427e+07\n",
      "Epoch 2460, Training-Loss 3.4224e+05, Data-loss 3.4065e+05                  , pde-loss 2.8309e-12, initc-loss 4.8427e+05                    bc_loss 1.5334e+07\n",
      "Epoch 2470, Training-Loss 3.4817e+05, Data-loss 3.4659e+05                  , pde-loss 2.5395e-12, initc-loss 4.8310e+05                    bc_loss 1.5241e+07\n",
      "Epoch 2480, Training-Loss 3.4617e+05, Data-loss 3.4461e+05                  , pde-loss 2.4659e-12, initc-loss 4.8193e+05                    bc_loss 1.5149e+07\n",
      "Epoch 2490, Training-Loss 3.4847e+05, Data-loss 3.4692e+05                  , pde-loss 2.4324e-12, initc-loss 4.8077e+05                    bc_loss 1.5056e+07\n",
      "Epoch 2500, Training-Loss 3.4071e+05, Data-loss 3.3917e+05                  , pde-loss 2.8104e-12, initc-loss 4.7960e+05                    bc_loss 1.4964e+07\n",
      "Epoch 2510, Training-Loss 3.4399e+05, Data-loss 3.4246e+05                  , pde-loss 2.4919e-12, initc-loss 4.7844e+05                    bc_loss 1.4873e+07\n",
      "Epoch 2520, Training-Loss 3.4152e+05, Data-loss 3.3999e+05                  , pde-loss 2.3357e-12, initc-loss 4.7729e+05                    bc_loss 1.4781e+07\n",
      "Epoch 2530, Training-Loss 3.3821e+05, Data-loss 3.3670e+05                  , pde-loss 2.4644e-12, initc-loss 4.7613e+05                    bc_loss 1.4690e+07\n",
      "Epoch 2540, Training-Loss 3.3450e+05, Data-loss 3.3300e+05                  , pde-loss 2.5033e-12, initc-loss 4.7497e+05                    bc_loss 1.4600e+07\n",
      "Epoch 2550, Training-Loss 3.3842e+05, Data-loss 3.3692e+05                  , pde-loss 2.5561e-12, initc-loss 4.7382e+05                    bc_loss 1.4509e+07\n",
      "Epoch 2560, Training-Loss 3.3485e+05, Data-loss 3.3336e+05                  , pde-loss 2.3428e-12, initc-loss 4.7267e+05                    bc_loss 1.4420e+07\n",
      "Epoch 2570, Training-Loss 3.3751e+05, Data-loss 3.3603e+05                  , pde-loss 2.1298e-12, initc-loss 4.7152e+05                    bc_loss 1.4330e+07\n",
      "Epoch 2580, Training-Loss 3.3264e+05, Data-loss 3.3117e+05                  , pde-loss 2.3095e-12, initc-loss 4.7038e+05                    bc_loss 1.4241e+07\n",
      "Epoch 2590, Training-Loss 3.3175e+05, Data-loss 3.3029e+05                  , pde-loss 2.3299e-12, initc-loss 4.6923e+05                    bc_loss 1.4152e+07\n",
      "Epoch 2600, Training-Loss 3.3479e+05, Data-loss 3.3334e+05                  , pde-loss 2.2790e-12, initc-loss 4.6809e+05                    bc_loss 1.4063e+07\n",
      "Epoch 2610, Training-Loss 3.3073e+05, Data-loss 3.2929e+05                  , pde-loss 2.0404e-12, initc-loss 4.6695e+05                    bc_loss 1.3974e+07\n",
      "Epoch 2620, Training-Loss 3.2282e+05, Data-loss 3.2139e+05                  , pde-loss 2.5411e-12, initc-loss 4.6581e+05                    bc_loss 1.3886e+07\n",
      "Epoch 2630, Training-Loss 3.3647e+05, Data-loss 3.3504e+05                  , pde-loss 1.9786e-12, initc-loss 4.6467e+05                    bc_loss 1.3799e+07\n",
      "Epoch 2640, Training-Loss 3.3278e+05, Data-loss 3.3137e+05                  , pde-loss 1.9655e-12, initc-loss 4.6353e+05                    bc_loss 1.3711e+07\n",
      "Epoch 2650, Training-Loss 3.3123e+05, Data-loss 3.2982e+05                  , pde-loss 1.8590e-12, initc-loss 4.6240e+05                    bc_loss 1.3624e+07\n",
      "Epoch 2660, Training-Loss 3.2523e+05, Data-loss 3.2383e+05                  , pde-loss 2.1832e-12, initc-loss 4.6126e+05                    bc_loss 1.3537e+07\n",
      "Epoch 2670, Training-Loss 3.2525e+05, Data-loss 3.2386e+05                  , pde-loss 2.1692e-12, initc-loss 4.6013e+05                    bc_loss 1.3451e+07\n",
      "Epoch 2680, Training-Loss 3.2107e+05, Data-loss 3.1969e+05                  , pde-loss 2.0442e-12, initc-loss 4.5901e+05                    bc_loss 1.3365e+07\n",
      "Epoch 2690, Training-Loss 3.1954e+05, Data-loss 3.1817e+05                  , pde-loss 2.2272e-12, initc-loss 4.5788e+05                    bc_loss 1.3279e+07\n",
      "Epoch 2700, Training-Loss 3.2396e+05, Data-loss 3.2259e+05                  , pde-loss 1.8742e-12, initc-loss 4.5676e+05                    bc_loss 1.3193e+07\n",
      "Epoch 2710, Training-Loss 3.2369e+05, Data-loss 3.2234e+05                  , pde-loss 1.8002e-12, initc-loss 4.5564e+05                    bc_loss 1.3108e+07\n",
      "Epoch 2720, Training-Loss 3.1620e+05, Data-loss 3.1485e+05                  , pde-loss 2.0358e-12, initc-loss 4.5452e+05                    bc_loss 1.3023e+07\n",
      "Epoch 2730, Training-Loss 3.2068e+05, Data-loss 3.1934e+05                  , pde-loss 1.8593e-12, initc-loss 4.5340e+05                    bc_loss 1.2939e+07\n",
      "Epoch 2740, Training-Loss 3.1722e+05, Data-loss 3.1589e+05                  , pde-loss 1.9446e-12, initc-loss 4.5228e+05                    bc_loss 1.2854e+07\n",
      "Epoch 2750, Training-Loss 3.2052e+05, Data-loss 3.1920e+05                  , pde-loss 1.7706e-12, initc-loss 4.5116e+05                    bc_loss 1.2770e+07\n",
      "Epoch 2760, Training-Loss 3.2130e+05, Data-loss 3.1998e+05                  , pde-loss 1.8053e-12, initc-loss 4.5005e+05                    bc_loss 1.2686e+07\n",
      "Epoch 2770, Training-Loss 3.1363e+05, Data-loss 3.1232e+05                  , pde-loss 1.8221e-12, initc-loss 4.4894e+05                    bc_loss 1.2603e+07\n",
      "Epoch 2780, Training-Loss 3.1910e+05, Data-loss 3.1780e+05                  , pde-loss 1.7192e-12, initc-loss 4.4783e+05                    bc_loss 1.2520e+07\n",
      "Epoch 2790, Training-Loss 3.1514e+05, Data-loss 3.1386e+05                  , pde-loss 1.7263e-12, initc-loss 4.4672e+05                    bc_loss 1.2437e+07\n",
      "Epoch 2800, Training-Loss 3.1730e+05, Data-loss 3.1602e+05                  , pde-loss 1.6257e-12, initc-loss 4.4561e+05                    bc_loss 1.2355e+07\n",
      "Epoch 2810, Training-Loss 3.0750e+05, Data-loss 3.0623e+05                  , pde-loss 1.8282e-12, initc-loss 4.4451e+05                    bc_loss 1.2273e+07\n",
      "Epoch 2820, Training-Loss 3.1228e+05, Data-loss 3.1102e+05                  , pde-loss 1.6243e-12, initc-loss 4.4341e+05                    bc_loss 1.2191e+07\n",
      "Epoch 2830, Training-Loss 3.1151e+05, Data-loss 3.1025e+05                  , pde-loss 1.7395e-12, initc-loss 4.4231e+05                    bc_loss 1.2109e+07\n",
      "Epoch 2840, Training-Loss 3.1602e+05, Data-loss 3.1477e+05                  , pde-loss 1.4592e-12, initc-loss 4.4121e+05                    bc_loss 1.2028e+07\n",
      "Epoch 2850, Training-Loss 3.0629e+05, Data-loss 3.0505e+05                  , pde-loss 1.7163e-12, initc-loss 4.4011e+05                    bc_loss 1.1947e+07\n",
      "Epoch 2860, Training-Loss 3.0606e+05, Data-loss 3.0483e+05                  , pde-loss 1.6318e-12, initc-loss 4.3902e+05                    bc_loss 1.1867e+07\n",
      "Epoch 2870, Training-Loss 3.0533e+05, Data-loss 3.0411e+05                  , pde-loss 1.6451e-12, initc-loss 4.3792e+05                    bc_loss 1.1786e+07\n",
      "Epoch 2880, Training-Loss 3.0842e+05, Data-loss 3.0721e+05                  , pde-loss 1.4760e-12, initc-loss 4.3683e+05                    bc_loss 1.1706e+07\n",
      "Epoch 2890, Training-Loss 3.0630e+05, Data-loss 3.0509e+05                  , pde-loss 1.4348e-12, initc-loss 4.3574e+05                    bc_loss 1.1627e+07\n",
      "Epoch 2900, Training-Loss 3.0379e+05, Data-loss 3.0259e+05                  , pde-loss 1.4695e-12, initc-loss 4.3466e+05                    bc_loss 1.1547e+07\n",
      "Epoch 2910, Training-Loss 3.0613e+05, Data-loss 3.0494e+05                  , pde-loss 1.4289e-12, initc-loss 4.3357e+05                    bc_loss 1.1468e+07\n",
      "Epoch 2920, Training-Loss 2.9866e+05, Data-loss 2.9748e+05                  , pde-loss 1.6071e-12, initc-loss 4.3248e+05                    bc_loss 1.1389e+07\n",
      "Epoch 2930, Training-Loss 3.0220e+05, Data-loss 3.0103e+05                  , pde-loss 1.2849e-12, initc-loss 4.3140e+05                    bc_loss 1.1311e+07\n",
      "Epoch 2940, Training-Loss 3.0685e+05, Data-loss 3.0569e+05                  , pde-loss 1.2295e-12, initc-loss 4.3032e+05                    bc_loss 1.1233e+07\n",
      "Epoch 2950, Training-Loss 2.9801e+05, Data-loss 2.9685e+05                  , pde-loss 1.4180e-12, initc-loss 4.2924e+05                    bc_loss 1.1155e+07\n",
      "Epoch 2960, Training-Loss 3.0233e+05, Data-loss 3.0118e+05                  , pde-loss 1.2658e-12, initc-loss 4.2816e+05                    bc_loss 1.1077e+07\n",
      "Epoch 2970, Training-Loss 2.9556e+05, Data-loss 2.9442e+05                  , pde-loss 1.3621e-12, initc-loss 4.2708e+05                    bc_loss 1.0999e+07\n",
      "Epoch 2980, Training-Loss 2.9614e+05, Data-loss 2.9501e+05                  , pde-loss 1.3441e-12, initc-loss 4.2601e+05                    bc_loss 1.0923e+07\n",
      "Epoch 2990, Training-Loss 2.9063e+05, Data-loss 2.8950e+05                  , pde-loss 1.3703e-12, initc-loss 4.2494e+05                    bc_loss 1.0846e+07\n",
      "Epoch 3000, Training-Loss 2.9075e+05, Data-loss 2.8963e+05                  , pde-loss 1.4032e-12, initc-loss 4.2386e+05                    bc_loss 1.0769e+07\n",
      "Epoch 3010, Training-Loss 2.9486e+05, Data-loss 2.9375e+05                  , pde-loss 1.2299e-12, initc-loss 4.2279e+05                    bc_loss 1.0693e+07\n",
      "Epoch 3020, Training-Loss 2.9070e+05, Data-loss 2.8959e+05                  , pde-loss 1.3564e-12, initc-loss 4.2173e+05                    bc_loss 1.0617e+07\n",
      "Epoch 3030, Training-Loss 2.8580e+05, Data-loss 2.8471e+05                  , pde-loss 1.3925e-12, initc-loss 4.2066e+05                    bc_loss 1.0542e+07\n",
      "Epoch 3040, Training-Loss 2.9906e+05, Data-loss 2.9797e+05                  , pde-loss 1.1192e-12, initc-loss 4.1960e+05                    bc_loss 1.0467e+07\n",
      "Epoch 3050, Training-Loss 2.9979e+05, Data-loss 2.9870e+05                  , pde-loss 1.0213e-12, initc-loss 4.1854e+05                    bc_loss 1.0392e+07\n",
      "Epoch 3060, Training-Loss 2.9492e+05, Data-loss 2.9385e+05                  , pde-loss 1.1391e-12, initc-loss 4.1748e+05                    bc_loss 1.0317e+07\n",
      "Epoch 3070, Training-Loss 2.8679e+05, Data-loss 2.8572e+05                  , pde-loss 1.2967e-12, initc-loss 4.1642e+05                    bc_loss 1.0243e+07\n",
      "Epoch 3080, Training-Loss 2.8539e+05, Data-loss 2.8433e+05                  , pde-loss 1.2957e-12, initc-loss 4.1536e+05                    bc_loss 1.0169e+07\n",
      "Epoch 3090, Training-Loss 2.9744e+05, Data-loss 2.9639e+05                  , pde-loss 9.4583e-13, initc-loss 4.1430e+05                    bc_loss 1.0095e+07\n",
      "Epoch 3100, Training-Loss 2.8098e+05, Data-loss 2.7994e+05                  , pde-loss 1.2426e-12, initc-loss 4.1325e+05                    bc_loss 1.0021e+07\n",
      "Epoch 3110, Training-Loss 2.8680e+05, Data-loss 2.8577e+05                  , pde-loss 1.1187e-12, initc-loss 4.1220e+05                    bc_loss 9.9481e+06\n",
      "Epoch 3120, Training-Loss 2.8444e+05, Data-loss 2.8342e+05                  , pde-loss 1.0883e-12, initc-loss 4.1115e+05                    bc_loss 9.8751e+06\n",
      "Epoch 3130, Training-Loss 2.8517e+05, Data-loss 2.8414e+05                  , pde-loss 1.0792e-12, initc-loss 4.1010e+05                    bc_loss 9.8026e+06\n",
      "Epoch 3140, Training-Loss 2.8402e+05, Data-loss 2.8300e+05                  , pde-loss 1.0045e-12, initc-loss 4.0905e+05                    bc_loss 9.7303e+06\n",
      "Epoch 3150, Training-Loss 2.7826e+05, Data-loss 2.7726e+05                  , pde-loss 1.1680e-12, initc-loss 4.0801e+05                    bc_loss 9.6583e+06\n",
      "Epoch 3160, Training-Loss 2.8091e+05, Data-loss 2.7992e+05                  , pde-loss 1.1279e-12, initc-loss 4.0696e+05                    bc_loss 9.5867e+06\n",
      "Epoch 3170, Training-Loss 2.7845e+05, Data-loss 2.7746e+05                  , pde-loss 1.0522e-12, initc-loss 4.0592e+05                    bc_loss 9.5152e+06\n",
      "Epoch 3180, Training-Loss 2.8009e+05, Data-loss 2.7911e+05                  , pde-loss 9.9093e-13, initc-loss 4.0488e+05                    bc_loss 9.4443e+06\n",
      "Epoch 3190, Training-Loss 2.8004e+05, Data-loss 2.7906e+05                  , pde-loss 1.0110e-12, initc-loss 4.0385e+05                    bc_loss 9.3736e+06\n",
      "Epoch 3200, Training-Loss 2.8004e+05, Data-loss 2.7907e+05                  , pde-loss 9.1758e-13, initc-loss 4.0281e+05                    bc_loss 9.3032e+06\n",
      "Epoch 3210, Training-Loss 2.7671e+05, Data-loss 2.7575e+05                  , pde-loss 1.1051e-12, initc-loss 4.0178e+05                    bc_loss 9.2330e+06\n",
      "Epoch 3220, Training-Loss 2.7519e+05, Data-loss 2.7423e+05                  , pde-loss 1.0444e-12, initc-loss 4.0075e+05                    bc_loss 9.1631e+06\n",
      "Epoch 3230, Training-Loss 2.6951e+05, Data-loss 2.6856e+05                  , pde-loss 1.1201e-12, initc-loss 3.9972e+05                    bc_loss 9.0935e+06\n",
      "Epoch 3240, Training-Loss 2.7447e+05, Data-loss 2.7353e+05                  , pde-loss 1.0080e-12, initc-loss 3.9869e+05                    bc_loss 9.0242e+06\n",
      "Epoch 3250, Training-Loss 2.7152e+05, Data-loss 2.7058e+05                  , pde-loss 9.5277e-13, initc-loss 3.9766e+05                    bc_loss 8.9553e+06\n",
      "Epoch 3260, Training-Loss 2.7093e+05, Data-loss 2.7000e+05                  , pde-loss 9.6409e-13, initc-loss 3.9664e+05                    bc_loss 8.8866e+06\n",
      "Epoch 3270, Training-Loss 2.6923e+05, Data-loss 2.6830e+05                  , pde-loss 9.6855e-13, initc-loss 3.9561e+05                    bc_loss 8.8182e+06\n",
      "Epoch 3280, Training-Loss 2.6941e+05, Data-loss 2.6850e+05                  , pde-loss 9.3239e-13, initc-loss 3.9459e+05                    bc_loss 8.7500e+06\n",
      "Epoch 3290, Training-Loss 2.7237e+05, Data-loss 2.7147e+05                  , pde-loss 8.2080e-13, initc-loss 3.9357e+05                    bc_loss 8.6821e+06\n",
      "Epoch 3300, Training-Loss 2.6984e+05, Data-loss 2.6894e+05                  , pde-loss 8.5107e-13, initc-loss 3.9255e+05                    bc_loss 8.6143e+06\n",
      "Epoch 3310, Training-Loss 2.7251e+05, Data-loss 2.7161e+05                  , pde-loss 7.7781e-13, initc-loss 3.9153e+05                    bc_loss 8.5469e+06\n",
      "Epoch 3320, Training-Loss 2.6833e+05, Data-loss 2.6745e+05                  , pde-loss 8.9190e-13, initc-loss 3.9051e+05                    bc_loss 8.4798e+06\n",
      "Epoch 3330, Training-Loss 2.6783e+05, Data-loss 2.6695e+05                  , pde-loss 8.5664e-13, initc-loss 3.8950e+05                    bc_loss 8.4130e+06\n",
      "Epoch 3340, Training-Loss 2.6604e+05, Data-loss 2.6516e+05                  , pde-loss 8.7668e-13, initc-loss 3.8848e+05                    bc_loss 8.3465e+06\n",
      "Epoch 3350, Training-Loss 2.6264e+05, Data-loss 2.6177e+05                  , pde-loss 8.9686e-13, initc-loss 3.8747e+05                    bc_loss 8.2803e+06\n",
      "Epoch 3360, Training-Loss 2.5831e+05, Data-loss 2.5745e+05                  , pde-loss 9.2663e-13, initc-loss 3.8646e+05                    bc_loss 8.2144e+06\n",
      "Epoch 3370, Training-Loss 2.6601e+05, Data-loss 2.6516e+05                  , pde-loss 8.0450e-13, initc-loss 3.8546e+05                    bc_loss 8.1488e+06\n",
      "Epoch 3380, Training-Loss 2.6529e+05, Data-loss 2.6444e+05                  , pde-loss 8.1701e-13, initc-loss 3.8445e+05                    bc_loss 8.0834e+06\n",
      "Epoch 3390, Training-Loss 2.5570e+05, Data-loss 2.5486e+05                  , pde-loss 8.7630e-13, initc-loss 3.8345e+05                    bc_loss 8.0184e+06\n",
      "Epoch 3400, Training-Loss 2.6114e+05, Data-loss 2.6031e+05                  , pde-loss 7.9820e-13, initc-loss 3.8245e+05                    bc_loss 7.9538e+06\n",
      "Epoch 3410, Training-Loss 2.5878e+05, Data-loss 2.5795e+05                  , pde-loss 8.0884e-13, initc-loss 3.8144e+05                    bc_loss 7.8894e+06\n",
      "Epoch 3420, Training-Loss 2.5556e+05, Data-loss 2.5474e+05                  , pde-loss 7.7266e-13, initc-loss 3.8044e+05                    bc_loss 7.8251e+06\n",
      "Epoch 3430, Training-Loss 2.6151e+05, Data-loss 2.6070e+05                  , pde-loss 7.2243e-13, initc-loss 3.7944e+05                    bc_loss 7.7611e+06\n",
      "Epoch 3440, Training-Loss 2.5891e+05, Data-loss 2.5810e+05                  , pde-loss 7.4845e-13, initc-loss 3.7845e+05                    bc_loss 7.6974e+06\n",
      "Epoch 3450, Training-Loss 2.5954e+05, Data-loss 2.5874e+05                  , pde-loss 6.9997e-13, initc-loss 3.7745e+05                    bc_loss 7.6340e+06\n",
      "Epoch 3460, Training-Loss 2.5481e+05, Data-loss 2.5401e+05                  , pde-loss 8.0345e-13, initc-loss 3.7646e+05                    bc_loss 7.5709e+06\n",
      "Epoch 3470, Training-Loss 2.4600e+05, Data-loss 2.4521e+05                  , pde-loss 8.8458e-13, initc-loss 3.7547e+05                    bc_loss 7.5082e+06\n",
      "Epoch 3480, Training-Loss 2.5910e+05, Data-loss 2.5832e+05                  , pde-loss 7.4647e-13, initc-loss 3.7448e+05                    bc_loss 7.4458e+06\n",
      "Epoch 3490, Training-Loss 2.5576e+05, Data-loss 2.5498e+05                  , pde-loss 6.8859e-13, initc-loss 3.7349e+05                    bc_loss 7.3835e+06\n",
      "Epoch 3500, Training-Loss 2.5567e+05, Data-loss 2.5490e+05                  , pde-loss 6.4082e-13, initc-loss 3.7250e+05                    bc_loss 7.3215e+06\n",
      "Epoch 3510, Training-Loss 2.4618e+05, Data-loss 2.4542e+05                  , pde-loss 7.7657e-13, initc-loss 3.7152e+05                    bc_loss 7.2598e+06\n",
      "Epoch 3520, Training-Loss 2.4985e+05, Data-loss 2.4909e+05                  , pde-loss 6.8887e-13, initc-loss 3.7054e+05                    bc_loss 7.1986e+06\n",
      "Epoch 3530, Training-Loss 2.5549e+05, Data-loss 2.5474e+05                  , pde-loss 6.7898e-13, initc-loss 3.6956e+05                    bc_loss 7.1376e+06\n",
      "Epoch 3540, Training-Loss 2.4541e+05, Data-loss 2.4466e+05                  , pde-loss 7.0160e-13, initc-loss 3.6858e+05                    bc_loss 7.0767e+06\n",
      "Epoch 3550, Training-Loss 2.4913e+05, Data-loss 2.4840e+05                  , pde-loss 6.7842e-13, initc-loss 3.6760e+05                    bc_loss 7.0162e+06\n",
      "Epoch 3560, Training-Loss 2.4863e+05, Data-loss 2.4790e+05                  , pde-loss 6.9382e-13, initc-loss 3.6662e+05                    bc_loss 6.9559e+06\n",
      "Epoch 3570, Training-Loss 2.4870e+05, Data-loss 2.4798e+05                  , pde-loss 6.5192e-13, initc-loss 3.6565e+05                    bc_loss 6.8959e+06\n",
      "Epoch 3580, Training-Loss 2.4658e+05, Data-loss 2.4586e+05                  , pde-loss 6.0612e-13, initc-loss 3.6467e+05                    bc_loss 6.8363e+06\n",
      "Epoch 3590, Training-Loss 2.4342e+05, Data-loss 2.4271e+05                  , pde-loss 6.4255e-13, initc-loss 3.6370e+05                    bc_loss 6.7769e+06\n",
      "Epoch 3600, Training-Loss 2.4609e+05, Data-loss 2.4539e+05                  , pde-loss 6.0660e-13, initc-loss 3.6273e+05                    bc_loss 6.7178e+06\n",
      "Epoch 3610, Training-Loss 2.4651e+05, Data-loss 2.4581e+05                  , pde-loss 5.9150e-13, initc-loss 3.6176e+05                    bc_loss 6.6589e+06\n",
      "Epoch 3620, Training-Loss 2.4497e+05, Data-loss 2.4427e+05                  , pde-loss 6.2514e-13, initc-loss 3.6080e+05                    bc_loss 6.6004e+06\n",
      "Epoch 3630, Training-Loss 2.4097e+05, Data-loss 2.4028e+05                  , pde-loss 6.4846e-13, initc-loss 3.5983e+05                    bc_loss 6.5421e+06\n",
      "Epoch 3640, Training-Loss 2.4399e+05, Data-loss 2.4331e+05                  , pde-loss 6.0042e-13, initc-loss 3.5887e+05                    bc_loss 6.4841e+06\n",
      "Epoch 3650, Training-Loss 2.4024e+05, Data-loss 2.3956e+05                  , pde-loss 5.9961e-13, initc-loss 3.5791e+05                    bc_loss 6.4264e+06\n",
      "Epoch 3660, Training-Loss 2.3793e+05, Data-loss 2.3726e+05                  , pde-loss 6.3543e-13, initc-loss 3.5695e+05                    bc_loss 6.3690e+06\n",
      "Epoch 3670, Training-Loss 2.4367e+05, Data-loss 2.4300e+05                  , pde-loss 5.1871e-13, initc-loss 3.5599e+05                    bc_loss 6.3118e+06\n",
      "Epoch 3680, Training-Loss 2.3813e+05, Data-loss 2.3747e+05                  , pde-loss 6.0516e-13, initc-loss 3.5503e+05                    bc_loss 6.2550e+06\n",
      "Epoch 3690, Training-Loss 2.3751e+05, Data-loss 2.3685e+05                  , pde-loss 5.7223e-13, initc-loss 3.5408e+05                    bc_loss 6.1983e+06\n",
      "Epoch 3700, Training-Loss 2.3519e+05, Data-loss 2.3454e+05                  , pde-loss 5.8309e-13, initc-loss 3.5312e+05                    bc_loss 6.1419e+06\n",
      "Epoch 3710, Training-Loss 2.3342e+05, Data-loss 2.3277e+05                  , pde-loss 5.5478e-13, initc-loss 3.5217e+05                    bc_loss 6.0859e+06\n",
      "Epoch 3720, Training-Loss 2.3163e+05, Data-loss 2.3100e+05                  , pde-loss 6.3764e-13, initc-loss 3.5122e+05                    bc_loss 6.0302e+06\n",
      "Epoch 3730, Training-Loss 2.3064e+05, Data-loss 2.3000e+05                  , pde-loss 6.0590e-13, initc-loss 3.5028e+05                    bc_loss 5.9748e+06\n",
      "Epoch 3740, Training-Loss 2.2761e+05, Data-loss 2.2698e+05                  , pde-loss 5.9601e-13, initc-loss 3.4933e+05                    bc_loss 5.9196e+06\n",
      "Epoch 3750, Training-Loss 2.3328e+05, Data-loss 2.3266e+05                  , pde-loss 5.6800e-13, initc-loss 3.4838e+05                    bc_loss 5.8646e+06\n",
      "Epoch 3760, Training-Loss 2.3141e+05, Data-loss 2.3079e+05                  , pde-loss 5.4520e-13, initc-loss 3.4744e+05                    bc_loss 5.8098e+06\n",
      "Epoch 3770, Training-Loss 2.3324e+05, Data-loss 2.3263e+05                  , pde-loss 5.2866e-13, initc-loss 3.4650e+05                    bc_loss 5.7555e+06\n",
      "Epoch 3780, Training-Loss 2.3262e+05, Data-loss 2.3202e+05                  , pde-loss 5.2126e-13, initc-loss 3.4556e+05                    bc_loss 5.7014e+06\n",
      "Epoch 3790, Training-Loss 2.2801e+05, Data-loss 2.2741e+05                  , pde-loss 5.7169e-13, initc-loss 3.4462e+05                    bc_loss 5.6475e+06\n",
      "Epoch 3800, Training-Loss 2.3366e+05, Data-loss 2.3307e+05                  , pde-loss 4.7306e-13, initc-loss 3.4368e+05                    bc_loss 5.5940e+06\n",
      "Epoch 3810, Training-Loss 2.3168e+05, Data-loss 2.3109e+05                  , pde-loss 5.1470e-13, initc-loss 3.4275e+05                    bc_loss 5.5408e+06\n",
      "Epoch 3820, Training-Loss 2.3211e+05, Data-loss 2.3153e+05                  , pde-loss 4.9400e-13, initc-loss 3.4181e+05                    bc_loss 5.4879e+06\n",
      "Epoch 3830, Training-Loss 2.2969e+05, Data-loss 2.2912e+05                  , pde-loss 4.6405e-13, initc-loss 3.4088e+05                    bc_loss 5.4352e+06\n",
      "Epoch 3840, Training-Loss 2.2540e+05, Data-loss 2.2483e+05                  , pde-loss 4.8626e-13, initc-loss 3.3995e+05                    bc_loss 5.3827e+06\n",
      "Epoch 3850, Training-Loss 2.2240e+05, Data-loss 2.2184e+05                  , pde-loss 5.2261e-13, initc-loss 3.3902e+05                    bc_loss 5.3305e+06\n",
      "Epoch 3860, Training-Loss 2.2489e+05, Data-loss 2.2432e+05                  , pde-loss 4.7354e-13, initc-loss 3.3809e+05                    bc_loss 5.2786e+06\n",
      "Epoch 3870, Training-Loss 2.2519e+05, Data-loss 2.2464e+05                  , pde-loss 4.5630e-13, initc-loss 3.3717e+05                    bc_loss 5.2269e+06\n",
      "Epoch 3880, Training-Loss 2.3062e+05, Data-loss 2.3007e+05                  , pde-loss 4.0735e-13, initc-loss 3.3624e+05                    bc_loss 5.1754e+06\n",
      "Epoch 3890, Training-Loss 2.1938e+05, Data-loss 2.1883e+05                  , pde-loss 4.8491e-13, initc-loss 3.3532e+05                    bc_loss 5.1243e+06\n",
      "Epoch 3900, Training-Loss 2.2031e+05, Data-loss 2.1977e+05                  , pde-loss 4.6981e-13, initc-loss 3.3440e+05                    bc_loss 5.0735e+06\n",
      "Epoch 3910, Training-Loss 2.2561e+05, Data-loss 2.2508e+05                  , pde-loss 3.9402e-13, initc-loss 3.3348e+05                    bc_loss 5.0229e+06\n",
      "Epoch 3920, Training-Loss 2.1820e+05, Data-loss 2.1767e+05                  , pde-loss 4.7828e-13, initc-loss 3.3256e+05                    bc_loss 4.9726e+06\n",
      "Epoch 3930, Training-Loss 2.1924e+05, Data-loss 2.1871e+05                  , pde-loss 4.6347e-13, initc-loss 3.3164e+05                    bc_loss 4.9225e+06\n",
      "Epoch 3940, Training-Loss 2.2280e+05, Data-loss 2.2228e+05                  , pde-loss 4.4543e-13, initc-loss 3.3073e+05                    bc_loss 4.8727e+06\n",
      "Epoch 3950, Training-Loss 2.2366e+05, Data-loss 2.2314e+05                  , pde-loss 3.9856e-13, initc-loss 3.2981e+05                    bc_loss 4.8232e+06\n",
      "Epoch 3960, Training-Loss 2.1538e+05, Data-loss 2.1487e+05                  , pde-loss 4.6657e-13, initc-loss 3.2890e+05                    bc_loss 4.7740e+06\n",
      "Epoch 3970, Training-Loss 2.1500e+05, Data-loss 2.1450e+05                  , pde-loss 4.2607e-13, initc-loss 3.2799e+05                    bc_loss 4.7250e+06\n",
      "Epoch 3980, Training-Loss 2.1502e+05, Data-loss 2.1452e+05                  , pde-loss 4.4798e-13, initc-loss 3.2708e+05                    bc_loss 4.6761e+06\n",
      "Epoch 3990, Training-Loss 2.1766e+05, Data-loss 2.1716e+05                  , pde-loss 4.0036e-13, initc-loss 3.2617e+05                    bc_loss 4.6277e+06\n",
      "Epoch 4000, Training-Loss 2.1272e+05, Data-loss 2.1223e+05                  , pde-loss 4.6078e-13, initc-loss 3.2526e+05                    bc_loss 4.5794e+06\n",
      "Epoch 4010, Training-Loss 2.2075e+05, Data-loss 2.2027e+05                  , pde-loss 3.2557e-13, initc-loss 3.2436e+05                    bc_loss 4.5316e+06\n",
      "Epoch 4020, Training-Loss 2.1282e+05, Data-loss 2.1234e+05                  , pde-loss 3.9838e-13, initc-loss 3.2345e+05                    bc_loss 4.4838e+06\n",
      "Epoch 4030, Training-Loss 2.1286e+05, Data-loss 2.1238e+05                  , pde-loss 4.1399e-13, initc-loss 3.2255e+05                    bc_loss 4.4365e+06\n",
      "Epoch 4040, Training-Loss 2.1140e+05, Data-loss 2.1092e+05                  , pde-loss 4.0089e-13, initc-loss 3.2165e+05                    bc_loss 4.3895e+06\n",
      "Epoch 4050, Training-Loss 2.0673e+05, Data-loss 2.0627e+05                  , pde-loss 4.2731e-13, initc-loss 3.2075e+05                    bc_loss 4.3425e+06\n",
      "Epoch 4060, Training-Loss 2.0882e+05, Data-loss 2.0836e+05                  , pde-loss 4.0244e-13, initc-loss 3.1986e+05                    bc_loss 4.2959e+06\n",
      "Epoch 4070, Training-Loss 2.0523e+05, Data-loss 2.0477e+05                  , pde-loss 4.0682e-13, initc-loss 3.1896e+05                    bc_loss 4.2496e+06\n",
      "Epoch 4080, Training-Loss 2.0585e+05, Data-loss 2.0539e+05                  , pde-loss 4.0358e-13, initc-loss 3.1807e+05                    bc_loss 4.2036e+06\n",
      "Epoch 4090, Training-Loss 2.0882e+05, Data-loss 2.0837e+05                  , pde-loss 3.7538e-13, initc-loss 3.1718e+05                    bc_loss 4.1578e+06\n",
      "Epoch 4100, Training-Loss 2.0795e+05, Data-loss 2.0751e+05                  , pde-loss 3.9891e-13, initc-loss 3.1628e+05                    bc_loss 4.1122e+06\n",
      "Epoch 4110, Training-Loss 2.0644e+05, Data-loss 2.0601e+05                  , pde-loss 3.9199e-13, initc-loss 3.1540e+05                    bc_loss 4.0670e+06\n",
      "Epoch 4120, Training-Loss 2.0569e+05, Data-loss 2.0525e+05                  , pde-loss 3.7359e-13, initc-loss 3.1451e+05                    bc_loss 4.0221e+06\n",
      "Epoch 4130, Training-Loss 2.0775e+05, Data-loss 2.0733e+05                  , pde-loss 3.5281e-13, initc-loss 3.1362e+05                    bc_loss 3.9774e+06\n",
      "Epoch 4140, Training-Loss 2.0690e+05, Data-loss 2.0648e+05                  , pde-loss 3.5486e-13, initc-loss 3.1274e+05                    bc_loss 3.9330e+06\n",
      "Epoch 4150, Training-Loss 2.0406e+05, Data-loss 2.0364e+05                  , pde-loss 3.6985e-13, initc-loss 3.1186e+05                    bc_loss 3.8888e+06\n",
      "Epoch 4160, Training-Loss 2.0436e+05, Data-loss 2.0395e+05                  , pde-loss 3.4248e-13, initc-loss 3.1098e+05                    bc_loss 3.8449e+06\n",
      "Epoch 4170, Training-Loss 1.9994e+05, Data-loss 1.9953e+05                  , pde-loss 3.8277e-13, initc-loss 3.1010e+05                    bc_loss 3.8013e+06\n",
      "Epoch 4180, Training-Loss 1.9836e+05, Data-loss 1.9795e+05                  , pde-loss 3.6328e-13, initc-loss 3.0922e+05                    bc_loss 3.7580e+06\n",
      "Epoch 4190, Training-Loss 2.0278e+05, Data-loss 2.0238e+05                  , pde-loss 3.3305e-13, initc-loss 3.0834e+05                    bc_loss 3.7148e+06\n",
      "Epoch 4200, Training-Loss 1.9965e+05, Data-loss 1.9925e+05                  , pde-loss 3.3871e-13, initc-loss 3.0747e+05                    bc_loss 3.6719e+06\n",
      "Epoch 4210, Training-Loss 1.9663e+05, Data-loss 1.9624e+05                  , pde-loss 3.4412e-13, initc-loss 3.0659e+05                    bc_loss 3.6292e+06\n",
      "Epoch 4220, Training-Loss 2.0069e+05, Data-loss 2.0030e+05                  , pde-loss 3.1935e-13, initc-loss 3.0572e+05                    bc_loss 3.5868e+06\n",
      "Epoch 4230, Training-Loss 1.9135e+05, Data-loss 1.9096e+05                  , pde-loss 3.7858e-13, initc-loss 3.0485e+05                    bc_loss 3.5447e+06\n",
      "Epoch 4240, Training-Loss 2.0330e+05, Data-loss 2.0292e+05                  , pde-loss 3.1281e-13, initc-loss 3.0398e+05                    bc_loss 3.5030e+06\n",
      "Epoch 4250, Training-Loss 1.9364e+05, Data-loss 1.9326e+05                  , pde-loss 3.4492e-13, initc-loss 3.0312e+05                    bc_loss 3.4616e+06\n",
      "Epoch 4260, Training-Loss 1.9579e+05, Data-loss 1.9542e+05                  , pde-loss 3.3735e-13, initc-loss 3.0225e+05                    bc_loss 3.4204e+06\n",
      "Epoch 4270, Training-Loss 1.9881e+05, Data-loss 1.9844e+05                  , pde-loss 3.1550e-13, initc-loss 3.0139e+05                    bc_loss 3.3795e+06\n",
      "Epoch 4280, Training-Loss 1.9529e+05, Data-loss 1.9493e+05                  , pde-loss 3.2486e-13, initc-loss 3.0053e+05                    bc_loss 3.3387e+06\n",
      "Epoch 4290, Training-Loss 1.9408e+05, Data-loss 1.9372e+05                  , pde-loss 3.2222e-13, initc-loss 2.9967e+05                    bc_loss 3.2983e+06\n",
      "Epoch 4300, Training-Loss 1.9329e+05, Data-loss 1.9293e+05                  , pde-loss 3.4250e-13, initc-loss 2.9881e+05                    bc_loss 3.2582e+06\n",
      "Epoch 4310, Training-Loss 1.9252e+05, Data-loss 1.9217e+05                  , pde-loss 3.1444e-13, initc-loss 2.9795e+05                    bc_loss 3.2182e+06\n",
      "Epoch 4320, Training-Loss 1.9004e+05, Data-loss 1.8969e+05                  , pde-loss 3.2852e-13, initc-loss 2.9710e+05                    bc_loss 3.1785e+06\n",
      "Epoch 4330, Training-Loss 1.8955e+05, Data-loss 1.8920e+05                  , pde-loss 3.2623e-13, initc-loss 2.9624e+05                    bc_loss 3.1391e+06\n",
      "Epoch 4340, Training-Loss 1.9408e+05, Data-loss 1.9374e+05                  , pde-loss 2.9046e-13, initc-loss 2.9539e+05                    bc_loss 3.0999e+06\n",
      "Epoch 4350, Training-Loss 1.8834e+05, Data-loss 1.8800e+05                  , pde-loss 3.0976e-13, initc-loss 2.9454e+05                    bc_loss 3.0609e+06\n",
      "Epoch 4360, Training-Loss 1.8851e+05, Data-loss 1.8818e+05                  , pde-loss 2.9364e-13, initc-loss 2.9368e+05                    bc_loss 3.0221e+06\n",
      "Epoch 4370, Training-Loss 1.9159e+05, Data-loss 1.9126e+05                  , pde-loss 2.8458e-13, initc-loss 2.9283e+05                    bc_loss 2.9837e+06\n",
      "Epoch 4380, Training-Loss 1.8886e+05, Data-loss 1.8853e+05                  , pde-loss 2.8447e-13, initc-loss 2.9199e+05                    bc_loss 2.9455e+06\n",
      "Epoch 4390, Training-Loss 1.8871e+05, Data-loss 1.8839e+05                  , pde-loss 2.9119e-13, initc-loss 2.9114e+05                    bc_loss 2.9076e+06\n",
      "Epoch 4400, Training-Loss 1.8575e+05, Data-loss 1.8544e+05                  , pde-loss 2.8381e-13, initc-loss 2.9030e+05                    bc_loss 2.8700e+06\n",
      "Epoch 4410, Training-Loss 1.8385e+05, Data-loss 1.8353e+05                  , pde-loss 3.0925e-13, initc-loss 2.8945e+05                    bc_loss 2.8327e+06\n",
      "Epoch 4420, Training-Loss 1.8287e+05, Data-loss 1.8256e+05                  , pde-loss 3.1079e-13, initc-loss 2.8861e+05                    bc_loss 2.7955e+06\n",
      "Epoch 4430, Training-Loss 1.7938e+05, Data-loss 1.7908e+05                  , pde-loss 3.2288e-13, initc-loss 2.8777e+05                    bc_loss 2.7587e+06\n",
      "Epoch 4440, Training-Loss 1.7940e+05, Data-loss 1.7910e+05                  , pde-loss 3.2228e-13, initc-loss 2.8694e+05                    bc_loss 2.7221e+06\n",
      "Epoch 4450, Training-Loss 1.8114e+05, Data-loss 1.8084e+05                  , pde-loss 3.0637e-13, initc-loss 2.8610e+05                    bc_loss 2.6857e+06\n",
      "Epoch 4460, Training-Loss 1.7898e+05, Data-loss 1.7868e+05                  , pde-loss 3.0290e-13, initc-loss 2.8526e+05                    bc_loss 2.6497e+06\n",
      "Epoch 4470, Training-Loss 1.8000e+05, Data-loss 1.7971e+05                  , pde-loss 3.0650e-13, initc-loss 2.8443e+05                    bc_loss 2.6139e+06\n",
      "Epoch 4480, Training-Loss 1.7800e+05, Data-loss 1.7771e+05                  , pde-loss 3.0613e-13, initc-loss 2.8360e+05                    bc_loss 2.5783e+06\n",
      "Epoch 4490, Training-Loss 1.8203e+05, Data-loss 1.8174e+05                  , pde-loss 2.7691e-13, initc-loss 2.8277e+05                    bc_loss 2.5430e+06\n",
      "Epoch 4500, Training-Loss 1.8078e+05, Data-loss 1.8050e+05                  , pde-loss 2.7684e-13, initc-loss 2.8194e+05                    bc_loss 2.5079e+06\n",
      "Epoch 4510, Training-Loss 1.8101e+05, Data-loss 1.8074e+05                  , pde-loss 2.6646e-13, initc-loss 2.8111e+05                    bc_loss 2.4731e+06\n",
      "Epoch 4520, Training-Loss 1.7818e+05, Data-loss 1.7791e+05                  , pde-loss 2.5790e-13, initc-loss 2.8029e+05                    bc_loss 2.4386e+06\n",
      "Epoch 4530, Training-Loss 1.7612e+05, Data-loss 1.7586e+05                  , pde-loss 2.7538e-13, initc-loss 2.7946e+05                    bc_loss 2.4044e+06\n",
      "Epoch 4540, Training-Loss 1.7515e+05, Data-loss 1.7489e+05                  , pde-loss 2.7515e-13, initc-loss 2.7864e+05                    bc_loss 2.3704e+06\n",
      "Epoch 4550, Training-Loss 1.7668e+05, Data-loss 1.7642e+05                  , pde-loss 2.6159e-13, initc-loss 2.7782e+05                    bc_loss 2.3367e+06\n",
      "Epoch 4560, Training-Loss 1.7792e+05, Data-loss 1.7766e+05                  , pde-loss 2.4569e-13, initc-loss 2.7701e+05                    bc_loss 2.3033e+06\n",
      "Epoch 4570, Training-Loss 1.7455e+05, Data-loss 1.7429e+05                  , pde-loss 2.5651e-13, initc-loss 2.7619e+05                    bc_loss 2.2700e+06\n",
      "Epoch 4580, Training-Loss 1.7498e+05, Data-loss 1.7473e+05                  , pde-loss 2.4462e-13, initc-loss 2.7537e+05                    bc_loss 2.2369e+06\n",
      "Epoch 4590, Training-Loss 1.7419e+05, Data-loss 1.7395e+05                  , pde-loss 2.5411e-13, initc-loss 2.7455e+05                    bc_loss 2.2041e+06\n",
      "Epoch 4600, Training-Loss 1.6873e+05, Data-loss 1.6848e+05                  , pde-loss 2.7016e-13, initc-loss 2.7374e+05                    bc_loss 2.1716e+06\n",
      "Epoch 4610, Training-Loss 1.6871e+05, Data-loss 1.6847e+05                  , pde-loss 2.5976e-13, initc-loss 2.7293e+05                    bc_loss 2.1394e+06\n",
      "Epoch 4620, Training-Loss 1.7204e+05, Data-loss 1.7180e+05                  , pde-loss 2.5860e-13, initc-loss 2.7212e+05                    bc_loss 2.1074e+06\n",
      "Epoch 4630, Training-Loss 1.7673e+05, Data-loss 1.7650e+05                  , pde-loss 2.1608e-13, initc-loss 2.7131e+05                    bc_loss 2.0757e+06\n",
      "Epoch 4640, Training-Loss 1.6914e+05, Data-loss 1.6891e+05                  , pde-loss 2.4530e-13, initc-loss 2.7050e+05                    bc_loss 2.0442e+06\n",
      "Epoch 4650, Training-Loss 1.6752e+05, Data-loss 1.6729e+05                  , pde-loss 2.5362e-13, initc-loss 2.6970e+05                    bc_loss 2.0129e+06\n",
      "Epoch 4660, Training-Loss 1.7033e+05, Data-loss 1.7011e+05                  , pde-loss 2.3963e-13, initc-loss 2.6889e+05                    bc_loss 1.9820e+06\n",
      "Epoch 4670, Training-Loss 1.6893e+05, Data-loss 1.6870e+05                  , pde-loss 2.4129e-13, initc-loss 2.6809e+05                    bc_loss 1.9513e+06\n",
      "Epoch 4680, Training-Loss 1.7137e+05, Data-loss 1.7116e+05                  , pde-loss 2.1599e-13, initc-loss 2.6729e+05                    bc_loss 1.9208e+06\n",
      "Epoch 4690, Training-Loss 1.6195e+05, Data-loss 1.6174e+05                  , pde-loss 2.5071e-13, initc-loss 2.6649e+05                    bc_loss 1.8906e+06\n",
      "Epoch 4700, Training-Loss 1.6335e+05, Data-loss 1.6314e+05                  , pde-loss 2.3367e-13, initc-loss 2.6569e+05                    bc_loss 1.8607e+06\n",
      "Epoch 4710, Training-Loss 1.6833e+05, Data-loss 1.6812e+05                  , pde-loss 2.0270e-13, initc-loss 2.6490e+05                    bc_loss 1.8310e+06\n",
      "Epoch 4720, Training-Loss 1.6655e+05, Data-loss 1.6634e+05                  , pde-loss 1.9477e-13, initc-loss 2.6410e+05                    bc_loss 1.8015e+06\n",
      "Epoch 4730, Training-Loss 1.6255e+05, Data-loss 1.6235e+05                  , pde-loss 2.0710e-13, initc-loss 2.6331e+05                    bc_loss 1.7723e+06\n",
      "Epoch 4740, Training-Loss 1.6077e+05, Data-loss 1.6057e+05                  , pde-loss 2.1152e-13, initc-loss 2.6252e+05                    bc_loss 1.7433e+06\n",
      "Epoch 4750, Training-Loss 1.6564e+05, Data-loss 1.6544e+05                  , pde-loss 1.8972e-13, initc-loss 2.6172e+05                    bc_loss 1.7145e+06\n",
      "Epoch 4760, Training-Loss 1.6669e+05, Data-loss 1.6650e+05                  , pde-loss 1.7083e-13, initc-loss 2.6093e+05                    bc_loss 1.6860e+06\n",
      "Epoch 4770, Training-Loss 1.6461e+05, Data-loss 1.6442e+05                  , pde-loss 1.9002e-13, initc-loss 2.6014e+05                    bc_loss 1.6577e+06\n",
      "Epoch 4780, Training-Loss 1.6151e+05, Data-loss 1.6132e+05                  , pde-loss 1.9673e-13, initc-loss 2.5935e+05                    bc_loss 1.6297e+06\n",
      "Epoch 4790, Training-Loss 1.6080e+05, Data-loss 1.6061e+05                  , pde-loss 1.9988e-13, initc-loss 2.5857e+05                    bc_loss 1.6019e+06\n",
      "Epoch 4800, Training-Loss 1.5943e+05, Data-loss 1.5925e+05                  , pde-loss 2.0453e-13, initc-loss 2.5778e+05                    bc_loss 1.5744e+06\n",
      "Epoch 4810, Training-Loss 1.5751e+05, Data-loss 1.5733e+05                  , pde-loss 2.0695e-13, initc-loss 2.5700e+05                    bc_loss 1.5471e+06\n",
      "Epoch 4820, Training-Loss 1.5237e+05, Data-loss 1.5219e+05                  , pde-loss 2.3298e-13, initc-loss 2.5622e+05                    bc_loss 1.5202e+06\n",
      "Epoch 4830, Training-Loss 1.5911e+05, Data-loss 1.5893e+05                  , pde-loss 2.0081e-13, initc-loss 2.5545e+05                    bc_loss 1.4935e+06\n",
      "Epoch 4840, Training-Loss 1.6389e+05, Data-loss 1.6372e+05                  , pde-loss 1.8648e-13, initc-loss 2.5467e+05                    bc_loss 1.4670e+06\n",
      "Epoch 4850, Training-Loss 1.5434e+05, Data-loss 1.5417e+05                  , pde-loss 1.9417e-13, initc-loss 2.5389e+05                    bc_loss 1.4407e+06\n",
      "Epoch 4860, Training-Loss 1.5292e+05, Data-loss 1.5275e+05                  , pde-loss 1.8583e-13, initc-loss 2.5312e+05                    bc_loss 1.4148e+06\n",
      "Epoch 4870, Training-Loss 1.5047e+05, Data-loss 1.5031e+05                  , pde-loss 1.9152e-13, initc-loss 2.5234e+05                    bc_loss 1.3890e+06\n",
      "Epoch 4880, Training-Loss 1.5295e+05, Data-loss 1.5278e+05                  , pde-loss 1.8464e-13, initc-loss 2.5157e+05                    bc_loss 1.3635e+06\n",
      "Epoch 4890, Training-Loss 1.5494e+05, Data-loss 1.5478e+05                  , pde-loss 1.7702e-13, initc-loss 2.5080e+05                    bc_loss 1.3383e+06\n",
      "Epoch 4900, Training-Loss 1.5296e+05, Data-loss 1.5281e+05                  , pde-loss 1.8731e-13, initc-loss 2.5003e+05                    bc_loss 1.3133e+06\n",
      "Epoch 4910, Training-Loss 1.5242e+05, Data-loss 1.5226e+05                  , pde-loss 1.9161e-13, initc-loss 2.4927e+05                    bc_loss 1.2885e+06\n",
      "Epoch 4920, Training-Loss 1.5459e+05, Data-loss 1.5444e+05                  , pde-loss 1.8071e-13, initc-loss 2.4850e+05                    bc_loss 1.2640e+06\n",
      "Epoch 4930, Training-Loss 1.5453e+05, Data-loss 1.5438e+05                  , pde-loss 1.7264e-13, initc-loss 2.4774e+05                    bc_loss 1.2397e+06\n",
      "Epoch 4940, Training-Loss 1.5243e+05, Data-loss 1.5228e+05                  , pde-loss 1.6785e-13, initc-loss 2.4697e+05                    bc_loss 1.2157e+06\n",
      "Epoch 4950, Training-Loss 1.5087e+05, Data-loss 1.5072e+05                  , pde-loss 1.9434e-13, initc-loss 2.4621e+05                    bc_loss 1.1918e+06\n",
      "Epoch 4960, Training-Loss 1.4839e+05, Data-loss 1.4825e+05                  , pde-loss 1.9777e-13, initc-loss 2.4545e+05                    bc_loss 1.1682e+06\n",
      "Epoch 4970, Training-Loss 1.4896e+05, Data-loss 1.4882e+05                  , pde-loss 1.9052e-13, initc-loss 2.4469e+05                    bc_loss 1.1449e+06\n",
      "Epoch 4980, Training-Loss 1.4555e+05, Data-loss 1.4542e+05                  , pde-loss 1.9175e-13, initc-loss 2.4393e+05                    bc_loss 1.1219e+06\n",
      "Epoch 4990, Training-Loss 1.5561e+05, Data-loss 1.5548e+05                  , pde-loss 1.5583e-13, initc-loss 2.4318e+05                    bc_loss 1.0991e+06\n",
      "Epoch 5000, Training-Loss 1.4847e+05, Data-loss 1.4834e+05                  , pde-loss 1.7609e-13, initc-loss 2.4242e+05                    bc_loss 1.0765e+06\n",
      "Epoch 5010, Training-Loss 1.4168e+05, Data-loss 1.4155e+05                  , pde-loss 1.9932e-13, initc-loss 2.4167e+05                    bc_loss 1.0542e+06\n",
      "Epoch 5020, Training-Loss 1.4919e+05, Data-loss 1.4906e+05                  , pde-loss 1.7415e-13, initc-loss 2.4092e+05                    bc_loss 1.0321e+06\n",
      "Epoch 5030, Training-Loss 1.4326e+05, Data-loss 1.4313e+05                  , pde-loss 1.8665e-13, initc-loss 2.4017e+05                    bc_loss 1.0103e+06\n",
      "Epoch 5040, Training-Loss 1.5038e+05, Data-loss 1.5025e+05                  , pde-loss 1.5186e-13, initc-loss 2.3942e+05                    bc_loss 9.8866e+05\n",
      "Epoch 5050, Training-Loss 1.4204e+05, Data-loss 1.4192e+05                  , pde-loss 1.8179e-13, initc-loss 2.3868e+05                    bc_loss 9.6728e+05\n",
      "Epoch 5060, Training-Loss 1.4323e+05, Data-loss 1.4311e+05                  , pde-loss 1.7659e-13, initc-loss 2.3793e+05                    bc_loss 9.4615e+05\n",
      "Epoch 5070, Training-Loss 1.4403e+05, Data-loss 1.4391e+05                  , pde-loss 1.7188e-13, initc-loss 2.3718e+05                    bc_loss 9.2522e+05\n",
      "Epoch 5080, Training-Loss 1.3800e+05, Data-loss 1.3789e+05                  , pde-loss 1.9583e-13, initc-loss 2.3644e+05                    bc_loss 9.0451e+05\n",
      "Epoch 5090, Training-Loss 1.4087e+05, Data-loss 1.4076e+05                  , pde-loss 1.7481e-13, initc-loss 2.3570e+05                    bc_loss 8.8414e+05\n",
      "Epoch 5100, Training-Loss 1.3910e+05, Data-loss 1.3899e+05                  , pde-loss 1.8170e-13, initc-loss 2.3496e+05                    bc_loss 8.6404e+05\n",
      "Epoch 5110, Training-Loss 1.4127e+05, Data-loss 1.4116e+05                  , pde-loss 1.6461e-13, initc-loss 2.3423e+05                    bc_loss 8.4421e+05\n",
      "Epoch 5120, Training-Loss 1.4460e+05, Data-loss 1.4450e+05                  , pde-loss 1.5935e-13, initc-loss 2.3349e+05                    bc_loss 8.2462e+05\n",
      "Epoch 5130, Training-Loss 1.3601e+05, Data-loss 1.3591e+05                  , pde-loss 1.8829e-13, initc-loss 2.3276e+05                    bc_loss 8.0524e+05\n",
      "Epoch 5140, Training-Loss 1.4285e+05, Data-loss 1.4275e+05                  , pde-loss 1.6052e-13, initc-loss 2.3203e+05                    bc_loss 7.8614e+05\n",
      "Epoch 5150, Training-Loss 1.4271e+05, Data-loss 1.4261e+05                  , pde-loss 1.5711e-13, initc-loss 2.3130e+05                    bc_loss 7.6724e+05\n",
      "Epoch 5160, Training-Loss 1.3789e+05, Data-loss 1.3780e+05                  , pde-loss 1.6836e-13, initc-loss 2.3057e+05                    bc_loss 7.4852e+05\n",
      "Epoch 5170, Training-Loss 1.3684e+05, Data-loss 1.3675e+05                  , pde-loss 1.6908e-13, initc-loss 2.2984e+05                    bc_loss 7.3009e+05\n",
      "Epoch 5180, Training-Loss 1.3643e+05, Data-loss 1.3633e+05                  , pde-loss 1.6807e-13, initc-loss 2.2911e+05                    bc_loss 7.1183e+05\n",
      "Epoch 5190, Training-Loss 1.3630e+05, Data-loss 1.3621e+05                  , pde-loss 1.7706e-13, initc-loss 2.2839e+05                    bc_loss 6.9381e+05\n",
      "Epoch 5200, Training-Loss 1.3481e+05, Data-loss 1.3472e+05                  , pde-loss 1.6383e-13, initc-loss 2.2766e+05                    bc_loss 6.7605e+05\n",
      "Epoch 5210, Training-Loss 1.3634e+05, Data-loss 1.3625e+05                  , pde-loss 1.5880e-13, initc-loss 2.2694e+05                    bc_loss 6.5854e+05\n",
      "Epoch 5220, Training-Loss 1.3941e+05, Data-loss 1.3933e+05                  , pde-loss 1.3484e-13, initc-loss 2.2622e+05                    bc_loss 6.4124e+05\n",
      "Epoch 5230, Training-Loss 1.3798e+05, Data-loss 1.3789e+05                  , pde-loss 1.3730e-13, initc-loss 2.2550e+05                    bc_loss 6.2414e+05\n",
      "Epoch 5240, Training-Loss 1.3345e+05, Data-loss 1.3337e+05                  , pde-loss 1.4375e-13, initc-loss 2.2477e+05                    bc_loss 6.0729e+05\n",
      "Epoch 5250, Training-Loss 1.3500e+05, Data-loss 1.3492e+05                  , pde-loss 1.4181e-13, initc-loss 2.2406e+05                    bc_loss 5.9072e+05\n",
      "Epoch 5260, Training-Loss 1.3174e+05, Data-loss 1.3166e+05                  , pde-loss 1.5154e-13, initc-loss 2.2334e+05                    bc_loss 5.7435e+05\n",
      "Epoch 5270, Training-Loss 1.3072e+05, Data-loss 1.3064e+05                  , pde-loss 1.5228e-13, initc-loss 2.2262e+05                    bc_loss 5.5823e+05\n",
      "Epoch 5280, Training-Loss 1.3536e+05, Data-loss 1.3528e+05                  , pde-loss 1.2465e-13, initc-loss 2.2191e+05                    bc_loss 5.4240e+05\n",
      "Epoch 5290, Training-Loss 1.2889e+05, Data-loss 1.2882e+05                  , pde-loss 1.3906e-13, initc-loss 2.2120e+05                    bc_loss 5.2676e+05\n",
      "Epoch 5300, Training-Loss 1.3072e+05, Data-loss 1.3065e+05                  , pde-loss 1.2808e-13, initc-loss 2.2049e+05                    bc_loss 5.1136e+05\n",
      "Epoch 5310, Training-Loss 1.2698e+05, Data-loss 1.2691e+05                  , pde-loss 1.4833e-13, initc-loss 2.1978e+05                    bc_loss 4.9619e+05\n",
      "Epoch 5320, Training-Loss 1.2897e+05, Data-loss 1.2890e+05                  , pde-loss 1.3686e-13, initc-loss 2.1908e+05                    bc_loss 4.8128e+05\n",
      "Epoch 5330, Training-Loss 1.3668e+05, Data-loss 1.3662e+05                  , pde-loss 1.1914e-13, initc-loss 2.1837e+05                    bc_loss 4.6658e+05\n",
      "Epoch 5340, Training-Loss 1.2943e+05, Data-loss 1.2936e+05                  , pde-loss 1.3905e-13, initc-loss 2.1766e+05                    bc_loss 4.5210e+05\n",
      "Epoch 5350, Training-Loss 1.2435e+05, Data-loss 1.2429e+05                  , pde-loss 1.4983e-13, initc-loss 2.1696e+05                    bc_loss 4.3789e+05\n",
      "Epoch 5360, Training-Loss 1.3182e+05, Data-loss 1.3175e+05                  , pde-loss 1.2218e-13, initc-loss 2.1626e+05                    bc_loss 4.2391e+05\n",
      "Epoch 5370, Training-Loss 1.2873e+05, Data-loss 1.2866e+05                  , pde-loss 1.2261e-13, initc-loss 2.1556e+05                    bc_loss 4.1013e+05\n",
      "Epoch 5380, Training-Loss 1.2239e+05, Data-loss 1.2233e+05                  , pde-loss 1.4308e-13, initc-loss 2.1486e+05                    bc_loss 3.9656e+05\n",
      "Epoch 5390, Training-Loss 1.2282e+05, Data-loss 1.2276e+05                  , pde-loss 1.3606e-13, initc-loss 2.1416e+05                    bc_loss 3.8323e+05\n",
      "Epoch 5400, Training-Loss 1.2066e+05, Data-loss 1.2061e+05                  , pde-loss 1.2332e-13, initc-loss 2.1346e+05                    bc_loss 3.7016e+05\n",
      "Epoch 5410, Training-Loss 1.2474e+05, Data-loss 1.2469e+05                  , pde-loss 1.1131e-13, initc-loss 2.1277e+05                    bc_loss 3.5734e+05\n",
      "Epoch 5420, Training-Loss 1.2773e+05, Data-loss 1.2767e+05                  , pde-loss 1.0287e-13, initc-loss 2.1208e+05                    bc_loss 3.4474e+05\n",
      "Epoch 5430, Training-Loss 1.2219e+05, Data-loss 1.2214e+05                  , pde-loss 1.1885e-13, initc-loss 2.1138e+05                    bc_loss 3.3237e+05\n",
      "Epoch 5440, Training-Loss 1.2953e+05, Data-loss 1.2948e+05                  , pde-loss 9.1531e-14, initc-loss 2.1069e+05                    bc_loss 3.2023e+05\n",
      "Epoch 5450, Training-Loss 1.1909e+05, Data-loss 1.1903e+05                  , pde-loss 1.1833e-13, initc-loss 2.1000e+05                    bc_loss 3.0831e+05\n",
      "Epoch 5460, Training-Loss 1.2234e+05, Data-loss 1.2229e+05                  , pde-loss 1.1323e-13, initc-loss 2.0932e+05                    bc_loss 2.9664e+05\n",
      "Epoch 5470, Training-Loss 1.2441e+05, Data-loss 1.2436e+05                  , pde-loss 9.4906e-14, initc-loss 2.0863e+05                    bc_loss 2.8520e+05\n",
      "Epoch 5480, Training-Loss 1.2410e+05, Data-loss 1.2405e+05                  , pde-loss 9.8781e-14, initc-loss 2.0795e+05                    bc_loss 2.7396e+05\n",
      "Epoch 5490, Training-Loss 1.1633e+05, Data-loss 1.1628e+05                  , pde-loss 1.1666e-13, initc-loss 2.0726e+05                    bc_loss 2.6298e+05\n",
      "Epoch 5500, Training-Loss 1.2009e+05, Data-loss 1.2004e+05                  , pde-loss 1.0008e-13, initc-loss 2.0658e+05                    bc_loss 2.5224e+05\n",
      "Epoch 5510, Training-Loss 1.2181e+05, Data-loss 1.2177e+05                  , pde-loss 1.0281e-13, initc-loss 2.0590e+05                    bc_loss 2.4170e+05\n",
      "Epoch 5520, Training-Loss 1.2030e+05, Data-loss 1.2026e+05                  , pde-loss 1.0682e-13, initc-loss 2.0522e+05                    bc_loss 2.3138e+05\n",
      "Epoch 5530, Training-Loss 1.1835e+05, Data-loss 1.1831e+05                  , pde-loss 1.0841e-13, initc-loss 2.0454e+05                    bc_loss 2.2129e+05\n",
      "Epoch 5540, Training-Loss 1.1940e+05, Data-loss 1.1936e+05                  , pde-loss 1.0132e-13, initc-loss 2.0386e+05                    bc_loss 2.1143e+05\n",
      "Epoch 5550, Training-Loss 1.1923e+05, Data-loss 1.1918e+05                  , pde-loss 1.0354e-13, initc-loss 2.0319e+05                    bc_loss 2.0179e+05\n",
      "Epoch 5560, Training-Loss 1.2087e+05, Data-loss 1.2083e+05                  , pde-loss 1.0811e-13, initc-loss 2.0251e+05                    bc_loss 1.9238e+05\n",
      "Epoch 5570, Training-Loss 1.1408e+05, Data-loss 1.1405e+05                  , pde-loss 1.1958e-13, initc-loss 2.0184e+05                    bc_loss 1.8321e+05\n",
      "Epoch 5580, Training-Loss 1.1751e+05, Data-loss 1.1748e+05                  , pde-loss 1.1716e-13, initc-loss 2.0117e+05                    bc_loss 1.7427e+05\n",
      "Epoch 5590, Training-Loss 1.1742e+05, Data-loss 1.1739e+05                  , pde-loss 1.0789e-13, initc-loss 2.0050e+05                    bc_loss 1.6557e+05\n",
      "Epoch 5600, Training-Loss 1.1108e+05, Data-loss 1.1105e+05                  , pde-loss 1.2630e-13, initc-loss 1.9983e+05                    bc_loss 1.5711e+05\n",
      "Epoch 5610, Training-Loss 1.1096e+05, Data-loss 1.1092e+05                  , pde-loss 1.1667e-13, initc-loss 1.9917e+05                    bc_loss 1.4891e+05\n",
      "Epoch 5620, Training-Loss 1.1382e+05, Data-loss 1.1379e+05                  , pde-loss 1.1310e-13, initc-loss 1.9851e+05                    bc_loss 1.4094e+05\n",
      "Epoch 5630, Training-Loss 1.1211e+05, Data-loss 1.1208e+05                  , pde-loss 1.1079e-13, initc-loss 1.9785e+05                    bc_loss 1.3316e+05\n",
      "Epoch 5640, Training-Loss 1.1288e+05, Data-loss 1.1285e+05                  , pde-loss 1.1045e-13, initc-loss 1.9719e+05                    bc_loss 1.2559e+05\n",
      "Epoch 5650, Training-Loss 1.1428e+05, Data-loss 1.1425e+05                  , pde-loss 1.0807e-13, initc-loss 1.9653e+05                    bc_loss 1.1823e+05\n",
      "Epoch 5660, Training-Loss 1.1324e+05, Data-loss 1.1321e+05                  , pde-loss 1.1217e-13, initc-loss 1.9587e+05                    bc_loss 1.1109e+05\n",
      "Epoch 5670, Training-Loss 1.1451e+05, Data-loss 1.1448e+05                  , pde-loss 1.0076e-13, initc-loss 1.9521e+05                    bc_loss 1.0417e+05\n",
      "Epoch 5680, Training-Loss 1.1144e+05, Data-loss 1.1141e+05                  , pde-loss 1.0468e-13, initc-loss 1.9455e+05                    bc_loss 9.7498e+04\n",
      "Epoch 5690, Training-Loss 1.1242e+05, Data-loss 1.1239e+05                  , pde-loss 1.0605e-13, initc-loss 1.9390e+05                    bc_loss 9.1064e+04\n",
      "Epoch 5700, Training-Loss 1.0827e+05, Data-loss 1.0825e+05                  , pde-loss 1.1462e-13, initc-loss 1.9324e+05                    bc_loss 8.4840e+04\n",
      "Epoch 5710, Training-Loss 1.0874e+05, Data-loss 1.0872e+05                  , pde-loss 1.1341e-13, initc-loss 1.9259e+05                    bc_loss 7.8855e+04\n",
      "Epoch 5720, Training-Loss 1.1061e+05, Data-loss 1.1058e+05                  , pde-loss 1.0939e-13, initc-loss 1.9194e+05                    bc_loss 7.3078e+04\n",
      "Epoch 5730, Training-Loss 1.0707e+05, Data-loss 1.0705e+05                  , pde-loss 1.1695e-13, initc-loss 1.9130e+05                    bc_loss 6.7518e+04\n",
      "Epoch 5740, Training-Loss 1.0818e+05, Data-loss 1.0815e+05                  , pde-loss 1.1169e-13, initc-loss 1.9065e+05                    bc_loss 6.2182e+04\n",
      "Epoch 5750, Training-Loss 1.0759e+05, Data-loss 1.0757e+05                  , pde-loss 1.0497e-13, initc-loss 1.9000e+05                    bc_loss 5.7055e+04\n",
      "Epoch 5760, Training-Loss 1.0810e+05, Data-loss 1.0808e+05                  , pde-loss 1.1369e-13, initc-loss 1.8935e+05                    bc_loss 5.2145e+04\n",
      "Epoch 5770, Training-Loss 1.0665e+05, Data-loss 1.0662e+05                  , pde-loss 1.0604e-13, initc-loss 1.8871e+05                    bc_loss 4.7468e+04\n",
      "Epoch 5780, Training-Loss 1.0637e+05, Data-loss 1.0635e+05                  , pde-loss 1.1303e-13, initc-loss 1.8806e+05                    bc_loss 4.3006e+04\n",
      "Epoch 5790, Training-Loss 1.0781e+05, Data-loss 1.0778e+05                  , pde-loss 1.1066e-13, initc-loss 1.8742e+05                    bc_loss 3.8771e+04\n",
      "Epoch 5800, Training-Loss 1.0489e+05, Data-loss 1.0486e+05                  , pde-loss 1.2023e-13, initc-loss 1.8678e+05                    bc_loss 3.4750e+04\n",
      "Epoch 5810, Training-Loss 1.0480e+05, Data-loss 1.0478e+05                  , pde-loss 1.1967e-13, initc-loss 1.8614e+05                    bc_loss 3.0950e+04\n",
      "Epoch 5820, Training-Loss 1.0533e+05, Data-loss 1.0531e+05                  , pde-loss 1.0414e-13, initc-loss 1.8550e+05                    bc_loss 2.7381e+04\n",
      "Epoch 5830, Training-Loss 1.0141e+05, Data-loss 1.0139e+05                  , pde-loss 1.0361e-13, initc-loss 1.8487e+05                    bc_loss 2.4027e+04\n",
      "Epoch 5840, Training-Loss 1.0534e+05, Data-loss 1.0532e+05                  , pde-loss 9.2822e-14, initc-loss 1.8423e+05                    bc_loss 2.0901e+04\n",
      "Epoch 5850, Training-Loss 1.0113e+05, Data-loss 1.0111e+05                  , pde-loss 1.0962e-13, initc-loss 1.8360e+05                    bc_loss 1.7989e+04\n",
      "Epoch 5860, Training-Loss 1.0118e+05, Data-loss 1.0116e+05                  , pde-loss 1.0947e-13, initc-loss 1.8297e+05                    bc_loss 1.5304e+04\n",
      "Epoch 5870, Training-Loss 1.0217e+05, Data-loss 1.0215e+05                  , pde-loss 1.0407e-13, initc-loss 1.8234e+05                    bc_loss 1.2840e+04\n",
      "Epoch 5880, Training-Loss 1.0191e+05, Data-loss 1.0189e+05                  , pde-loss 9.9752e-14, initc-loss 1.8171e+05                    bc_loss 1.0591e+04\n",
      "Epoch 5890, Training-Loss 9.9057e+04, Data-loss 9.9038e+04                  , pde-loss 1.0509e-13, initc-loss 1.8109e+05                    bc_loss 8.5567e+03\n",
      "Epoch 5900, Training-Loss 9.6893e+04, Data-loss 9.6875e+04                  , pde-loss 1.2168e-13, initc-loss 1.8046e+05                    bc_loss 6.7387e+03\n",
      "Epoch 5910, Training-Loss 1.0170e+05, Data-loss 1.0168e+05                  , pde-loss 9.7660e-14, initc-loss 1.7983e+05                    bc_loss 5.1343e+03\n",
      "Epoch 5920, Training-Loss 9.6712e+04, Data-loss 9.6693e+04                  , pde-loss 1.1262e-13, initc-loss 1.7921e+05                    bc_loss 3.7500e+03\n",
      "Epoch 5930, Training-Loss 1.0123e+05, Data-loss 1.0121e+05                  , pde-loss 9.9000e-14, initc-loss 1.7859e+05                    bc_loss 2.5845e+03\n",
      "Epoch 5940, Training-Loss 9.9936e+04, Data-loss 9.9918e+04                  , pde-loss 9.7741e-14, initc-loss 1.7797e+05                    bc_loss 1.6363e+03\n",
      "Epoch 5950, Training-Loss 9.6887e+04, Data-loss 9.6869e+04                  , pde-loss 9.8863e-14, initc-loss 1.7735e+05                    bc_loss 9.0312e+02\n",
      "Epoch 5960, Training-Loss 9.4558e+04, Data-loss 9.4540e+04                  , pde-loss 1.0052e-13, initc-loss 1.7673e+05                    bc_loss 3.8639e+02\n",
      "Epoch 5970, Training-Loss 9.6327e+04, Data-loss 9.6309e+04                  , pde-loss 9.5412e-14, initc-loss 1.7611e+05                    bc_loss 8.6454e+01\n",
      "Epoch 5980, Training-Loss 9.7564e+04, Data-loss 9.7547e+04                  , pde-loss 9.5553e-14, initc-loss 1.7550e+05                    bc_loss 1.1539e+00\n",
      "Epoch 5990, Training-Loss 9.8412e+04, Data-loss 9.8395e+04                  , pde-loss 9.0933e-14, initc-loss 1.7488e+05                    bc_loss 1.3061e+02\n",
      "Epoch 6000, Training-Loss 9.6350e+04, Data-loss 9.6332e+04                  , pde-loss 9.7453e-14, initc-loss 1.7427e+05                    bc_loss 4.7297e+02\n",
      "Epoch 6010, Training-Loss 9.5854e+04, Data-loss 9.5836e+04                  , pde-loss 1.0157e-13, initc-loss 1.7367e+05                    bc_loss 1.0276e+03\n",
      "Epoch 6020, Training-Loss 9.7141e+04, Data-loss 9.7123e+04                  , pde-loss 9.6222e-14, initc-loss 1.7306e+05                    bc_loss 1.7957e+03\n",
      "Epoch 6030, Training-Loss 9.5649e+04, Data-loss 9.5632e+04                  , pde-loss 9.9957e-14, initc-loss 1.7245e+05                    bc_loss 2.7782e+03\n",
      "Epoch 6040, Training-Loss 9.5968e+04, Data-loss 9.5951e+04                  , pde-loss 9.7706e-14, initc-loss 1.7185e+05                    bc_loss 3.9718e+03\n",
      "Epoch 6050, Training-Loss 9.7070e+04, Data-loss 9.7053e+04                  , pde-loss 9.3387e-14, initc-loss 1.7124e+05                    bc_loss 5.3781e+03\n",
      "Epoch 6060, Training-Loss 9.2350e+04, Data-loss 9.2332e+04                  , pde-loss 9.1973e-14, initc-loss 1.7064e+05                    bc_loss 7.0031e+03\n",
      "Epoch 6070, Training-Loss 9.2396e+04, Data-loss 9.2378e+04                  , pde-loss 9.6799e-14, initc-loss 1.7003e+05                    bc_loss 8.8383e+03\n",
      "Epoch 6080, Training-Loss 9.2953e+04, Data-loss 9.2935e+04                  , pde-loss 8.7221e-14, initc-loss 1.6943e+05                    bc_loss 1.0889e+04\n",
      "Epoch 6090, Training-Loss 9.0180e+04, Data-loss 9.0162e+04                  , pde-loss 8.9270e-14, initc-loss 1.6883e+05                    bc_loss 1.3153e+04\n",
      "Epoch 6100, Training-Loss 9.2302e+04, Data-loss 9.2283e+04                  , pde-loss 8.6416e-14, initc-loss 1.6823e+05                    bc_loss 1.5629e+04\n",
      "Epoch 6110, Training-Loss 8.8137e+04, Data-loss 8.8118e+04                  , pde-loss 8.6319e-14, initc-loss 1.6763e+05                    bc_loss 1.8313e+04\n",
      "Epoch 6120, Training-Loss 9.1867e+04, Data-loss 9.1849e+04                  , pde-loss 7.8547e-14, initc-loss 1.6704e+05                    bc_loss 2.1201e+04\n",
      "Epoch 6130, Training-Loss 9.0803e+04, Data-loss 9.0784e+04                  , pde-loss 7.4901e-14, initc-loss 1.6645e+05                    bc_loss 2.4294e+04\n",
      "Epoch 6140, Training-Loss 8.9805e+04, Data-loss 8.9786e+04                  , pde-loss 7.7975e-14, initc-loss 1.6585e+05                    bc_loss 2.7601e+04\n",
      "Epoch 6150, Training-Loss 8.9264e+04, Data-loss 8.9245e+04                  , pde-loss 7.6271e-14, initc-loss 1.6526e+05                    bc_loss 3.1111e+04\n",
      "Epoch 6160, Training-Loss 8.9705e+04, Data-loss 8.9685e+04                  , pde-loss 7.5007e-14, initc-loss 1.6468e+05                    bc_loss 3.4836e+04\n",
      "Epoch 6170, Training-Loss 8.5403e+04, Data-loss 8.5383e+04                  , pde-loss 8.1717e-14, initc-loss 1.6409e+05                    bc_loss 3.8776e+04\n",
      "Epoch 6180, Training-Loss 8.9924e+04, Data-loss 8.9903e+04                  , pde-loss 7.2581e-14, initc-loss 1.6350e+05                    bc_loss 4.2926e+04\n",
      "Epoch 6190, Training-Loss 8.4963e+04, Data-loss 8.4942e+04                  , pde-loss 8.0067e-14, initc-loss 1.6291e+05                    bc_loss 4.7288e+04\n",
      "Epoch 6200, Training-Loss 8.4783e+04, Data-loss 8.4762e+04                  , pde-loss 7.9555e-14, initc-loss 1.6233e+05                    bc_loss 5.1846e+04\n",
      "Epoch 6210, Training-Loss 8.5916e+04, Data-loss 8.5894e+04                  , pde-loss 7.3903e-14, initc-loss 1.6175e+05                    bc_loss 5.6588e+04\n",
      "Epoch 6220, Training-Loss 8.4592e+04, Data-loss 8.4570e+04                  , pde-loss 7.8994e-14, initc-loss 1.6117e+05                    bc_loss 6.1551e+04\n",
      "Epoch 6230, Training-Loss 8.4462e+04, Data-loss 8.4439e+04                  , pde-loss 7.3578e-14, initc-loss 1.6059e+05                    bc_loss 6.6721e+04\n",
      "Epoch 6240, Training-Loss 8.9354e+04, Data-loss 8.9331e+04                  , pde-loss 6.0939e-14, initc-loss 1.6001e+05                    bc_loss 7.2088e+04\n",
      "Epoch 6250, Training-Loss 8.4493e+04, Data-loss 8.4470e+04                  , pde-loss 7.1608e-14, initc-loss 1.5943e+05                    bc_loss 7.7689e+04\n",
      "Epoch 6260, Training-Loss 8.6041e+04, Data-loss 8.6017e+04                  , pde-loss 6.2075e-14, initc-loss 1.5886e+05                    bc_loss 8.3503e+04\n",
      "Epoch 6270, Training-Loss 8.2506e+04, Data-loss 8.2481e+04                  , pde-loss 7.0713e-14, initc-loss 1.5828e+05                    bc_loss 8.9531e+04\n",
      "Epoch 6280, Training-Loss 8.2321e+04, Data-loss 8.2296e+04                  , pde-loss 6.8958e-14, initc-loss 1.5770e+05                    bc_loss 9.5744e+04\n",
      "Epoch 6290, Training-Loss 8.2688e+04, Data-loss 8.2662e+04                  , pde-loss 6.2363e-14, initc-loss 1.5713e+05                    bc_loss 1.0216e+05\n",
      "Epoch 6300, Training-Loss 8.2009e+04, Data-loss 8.1983e+04                  , pde-loss 6.2205e-14, initc-loss 1.5656e+05                    bc_loss 1.0879e+05\n",
      "Epoch 6310, Training-Loss 7.9494e+04, Data-loss 7.9467e+04                  , pde-loss 6.1104e-14, initc-loss 1.5599e+05                    bc_loss 1.1559e+05\n",
      "Epoch 6320, Training-Loss 7.8199e+04, Data-loss 7.8171e+04                  , pde-loss 5.9934e-14, initc-loss 1.5543e+05                    bc_loss 1.2261e+05\n",
      "Epoch 6330, Training-Loss 7.9644e+04, Data-loss 7.9615e+04                  , pde-loss 5.6019e-14, initc-loss 1.5486e+05                    bc_loss 1.2983e+05\n",
      "Epoch 6340, Training-Loss 8.2650e+04, Data-loss 8.2621e+04                  , pde-loss 5.0197e-14, initc-loss 1.5429e+05                    bc_loss 1.3725e+05\n",
      "Epoch 6350, Training-Loss 8.0784e+04, Data-loss 8.0755e+04                  , pde-loss 5.2256e-14, initc-loss 1.5373e+05                    bc_loss 1.4491e+05\n",
      "Epoch 6360, Training-Loss 8.1871e+04, Data-loss 8.1841e+04                  , pde-loss 5.3354e-14, initc-loss 1.5317e+05                    bc_loss 1.5275e+05\n",
      "Epoch 6370, Training-Loss 7.9361e+04, Data-loss 7.9330e+04                  , pde-loss 5.5114e-14, initc-loss 1.5260e+05                    bc_loss 1.6078e+05\n",
      "Epoch 6380, Training-Loss 7.9247e+04, Data-loss 7.9215e+04                  , pde-loss 5.4641e-14, initc-loss 1.5205e+05                    bc_loss 1.6901e+05\n",
      "Epoch 6390, Training-Loss 8.2586e+04, Data-loss 8.2553e+04                  , pde-loss 4.5041e-14, initc-loss 1.5149e+05                    bc_loss 1.7746e+05\n",
      "Epoch 6400, Training-Loss 7.8918e+04, Data-loss 7.8884e+04                  , pde-loss 5.0763e-14, initc-loss 1.5093e+05                    bc_loss 1.8613e+05\n",
      "Epoch 6410, Training-Loss 8.0306e+04, Data-loss 8.0272e+04                  , pde-loss 4.4901e-14, initc-loss 1.5037e+05                    bc_loss 1.9497e+05\n",
      "Epoch 6420, Training-Loss 7.8834e+04, Data-loss 7.8799e+04                  , pde-loss 4.5897e-14, initc-loss 1.4982e+05                    bc_loss 2.0401e+05\n",
      "Epoch 6430, Training-Loss 7.7247e+04, Data-loss 7.7211e+04                  , pde-loss 5.0665e-14, initc-loss 1.4926e+05                    bc_loss 2.1324e+05\n",
      "Epoch 6440, Training-Loss 7.6342e+04, Data-loss 7.6305e+04                  , pde-loss 4.7725e-14, initc-loss 1.4871e+05                    bc_loss 2.2263e+05\n",
      "Epoch 6450, Training-Loss 7.5940e+04, Data-loss 7.5902e+04                  , pde-loss 4.9596e-14, initc-loss 1.4817e+05                    bc_loss 2.3226e+05\n",
      "Epoch 6460, Training-Loss 7.7096e+04, Data-loss 7.7057e+04                  , pde-loss 4.7450e-14, initc-loss 1.4762e+05                    bc_loss 2.4209e+05\n",
      "Epoch 6470, Training-Loss 7.6794e+04, Data-loss 7.6754e+04                  , pde-loss 5.1108e-14, initc-loss 1.4707e+05                    bc_loss 2.5213e+05\n",
      "Epoch 6480, Training-Loss 7.8040e+04, Data-loss 7.7999e+04                  , pde-loss 4.5414e-14, initc-loss 1.4652e+05                    bc_loss 2.6237e+05\n",
      "Epoch 6490, Training-Loss 7.7759e+04, Data-loss 7.7717e+04                  , pde-loss 4.9047e-14, initc-loss 1.4597e+05                    bc_loss 2.7286e+05\n",
      "Epoch 6500, Training-Loss 7.4465e+04, Data-loss 7.4422e+04                  , pde-loss 5.2191e-14, initc-loss 1.4543e+05                    bc_loss 2.8352e+05\n",
      "Epoch 6510, Training-Loss 7.7125e+04, Data-loss 7.7081e+04                  , pde-loss 4.7176e-14, initc-loss 1.4488e+05                    bc_loss 2.9435e+05\n",
      "Epoch 6520, Training-Loss 7.2549e+04, Data-loss 7.2504e+04                  , pde-loss 5.1040e-14, initc-loss 1.4434e+05                    bc_loss 3.0538e+05\n",
      "Epoch 6530, Training-Loss 7.3173e+04, Data-loss 7.3127e+04                  , pde-loss 4.7074e-14, initc-loss 1.4380e+05                    bc_loss 3.1659e+05\n",
      "Epoch 6540, Training-Loss 7.2503e+04, Data-loss 7.2456e+04                  , pde-loss 5.0472e-14, initc-loss 1.4326e+05                    bc_loss 3.2800e+05\n",
      "Epoch 6550, Training-Loss 7.3516e+04, Data-loss 7.3468e+04                  , pde-loss 4.8207e-14, initc-loss 1.4273e+05                    bc_loss 3.3962e+05\n",
      "Epoch 6560, Training-Loss 7.1894e+04, Data-loss 7.1844e+04                  , pde-loss 4.9868e-14, initc-loss 1.4219e+05                    bc_loss 3.5142e+05\n",
      "Epoch 6570, Training-Loss 7.0718e+04, Data-loss 7.0667e+04                  , pde-loss 5.2052e-14, initc-loss 1.4165e+05                    bc_loss 3.6347e+05\n",
      "Epoch 6580, Training-Loss 6.9804e+04, Data-loss 6.9752e+04                  , pde-loss 4.8591e-14, initc-loss 1.4112e+05                    bc_loss 3.7569e+05\n",
      "Epoch 6590, Training-Loss 7.0785e+04, Data-loss 7.0732e+04                  , pde-loss 4.8949e-14, initc-loss 1.4059e+05                    bc_loss 3.8810e+05\n",
      "Epoch 6600, Training-Loss 7.1076e+04, Data-loss 7.1022e+04                  , pde-loss 4.8101e-14, initc-loss 1.4006e+05                    bc_loss 4.0069e+05\n",
      "Epoch 6610, Training-Loss 7.0094e+04, Data-loss 7.0039e+04                  , pde-loss 5.2409e-14, initc-loss 1.3953e+05                    bc_loss 4.1348e+05\n",
      "Epoch 6620, Training-Loss 7.0143e+04, Data-loss 7.0086e+04                  , pde-loss 4.6316e-14, initc-loss 1.3900e+05                    bc_loss 4.2645e+05\n",
      "Epoch 6630, Training-Loss 6.9564e+04, Data-loss 6.9506e+04                  , pde-loss 5.2767e-14, initc-loss 1.3847e+05                    bc_loss 4.3966e+05\n",
      "Epoch 6640, Training-Loss 6.9918e+04, Data-loss 6.9858e+04                  , pde-loss 4.8888e-14, initc-loss 1.3794e+05                    bc_loss 4.5309e+05\n",
      "Epoch 6650, Training-Loss 6.8172e+04, Data-loss 6.8111e+04                  , pde-loss 5.3330e-14, initc-loss 1.3741e+05                    bc_loss 4.6670e+05\n",
      "Epoch 6660, Training-Loss 7.0435e+04, Data-loss 7.0373e+04                  , pde-loss 4.9236e-14, initc-loss 1.3689e+05                    bc_loss 4.8048e+05\n",
      "Epoch 6670, Training-Loss 7.0016e+04, Data-loss 6.9953e+04                  , pde-loss 5.1079e-14, initc-loss 1.3637e+05                    bc_loss 4.9444e+05\n",
      "Epoch 6680, Training-Loss 7.0554e+04, Data-loss 7.0490e+04                  , pde-loss 4.6185e-14, initc-loss 1.3585e+05                    bc_loss 5.0857e+05\n",
      "Epoch 6690, Training-Loss 6.5759e+04, Data-loss 6.5693e+04                  , pde-loss 5.3923e-14, initc-loss 1.3533e+05                    bc_loss 5.2290e+05\n",
      "Epoch 6700, Training-Loss 7.4345e+04, Data-loss 7.4277e+04                  , pde-loss 4.2332e-14, initc-loss 1.3481e+05                    bc_loss 5.3739e+05\n",
      "Epoch 6710, Training-Loss 6.4132e+04, Data-loss 6.4063e+04                  , pde-loss 5.5458e-14, initc-loss 1.3429e+05                    bc_loss 5.5211e+05\n",
      "Epoch 6720, Training-Loss 6.7421e+04, Data-loss 6.7351e+04                  , pde-loss 5.1751e-14, initc-loss 1.3378e+05                    bc_loss 5.6697e+05\n",
      "Epoch 6730, Training-Loss 6.2644e+04, Data-loss 6.2572e+04                  , pde-loss 5.7851e-14, initc-loss 1.3326e+05                    bc_loss 5.8206e+05\n",
      "Epoch 6740, Training-Loss 6.6521e+04, Data-loss 6.6448e+04                  , pde-loss 4.9732e-14, initc-loss 1.3275e+05                    bc_loss 5.9732e+05\n",
      "Epoch 6750, Training-Loss 6.5500e+04, Data-loss 6.5426e+04                  , pde-loss 5.4255e-14, initc-loss 1.3224e+05                    bc_loss 6.1281e+05\n",
      "Epoch 6760, Training-Loss 6.1869e+04, Data-loss 6.1793e+04                  , pde-loss 5.9585e-14, initc-loss 1.3173e+05                    bc_loss 6.2845e+05\n",
      "Epoch 6770, Training-Loss 6.5327e+04, Data-loss 6.5249e+04                  , pde-loss 5.2461e-14, initc-loss 1.3122e+05                    bc_loss 6.4428e+05\n",
      "Epoch 6780, Training-Loss 6.3025e+04, Data-loss 6.2946e+04                  , pde-loss 5.3135e-14, initc-loss 1.3071e+05                    bc_loss 6.6030e+05\n",
      "Epoch 6790, Training-Loss 6.6920e+04, Data-loss 6.6839e+04                  , pde-loss 4.4817e-14, initc-loss 1.3021e+05                    bc_loss 6.7646e+05\n",
      "Epoch 6800, Training-Loss 6.6597e+04, Data-loss 6.6515e+04                  , pde-loss 4.9071e-14, initc-loss 1.2970e+05                    bc_loss 6.9284e+05\n",
      "Epoch 6810, Training-Loss 6.3606e+04, Data-loss 6.3522e+04                  , pde-loss 4.8547e-14, initc-loss 1.2920e+05                    bc_loss 7.0937e+05\n",
      "Epoch 6820, Training-Loss 6.0899e+04, Data-loss 6.0814e+04                  , pde-loss 5.4313e-14, initc-loss 1.2870e+05                    bc_loss 7.2608e+05\n",
      "Epoch 6830, Training-Loss 6.4185e+04, Data-loss 6.4098e+04                  , pde-loss 5.1772e-14, initc-loss 1.2820e+05                    bc_loss 7.4299e+05\n",
      "Epoch 6840, Training-Loss 6.5768e+04, Data-loss 6.5679e+04                  , pde-loss 5.0561e-14, initc-loss 1.2770e+05                    bc_loss 7.6015e+05\n",
      "Epoch 6850, Training-Loss 6.1508e+04, Data-loss 6.1418e+04                  , pde-loss 5.3351e-14, initc-loss 1.2720e+05                    bc_loss 7.7750e+05\n",
      "Epoch 6860, Training-Loss 6.5399e+04, Data-loss 6.5307e+04                  , pde-loss 4.7699e-14, initc-loss 1.2670e+05                    bc_loss 7.9496e+05\n",
      "Epoch 6870, Training-Loss 6.2197e+04, Data-loss 6.2103e+04                  , pde-loss 5.0441e-14, initc-loss 1.2621e+05                    bc_loss 8.1260e+05\n",
      "Epoch 6880, Training-Loss 6.1751e+04, Data-loss 6.1655e+04                  , pde-loss 4.9907e-14, initc-loss 1.2572e+05                    bc_loss 8.3038e+05\n",
      "Epoch 6890, Training-Loss 6.2030e+04, Data-loss 6.1933e+04                  , pde-loss 4.8825e-14, initc-loss 1.2523e+05                    bc_loss 8.4831e+05\n",
      "Epoch 6900, Training-Loss 6.5129e+04, Data-loss 6.5030e+04                  , pde-loss 4.5362e-14, initc-loss 1.2473e+05                    bc_loss 8.6650e+05\n",
      "Epoch 6910, Training-Loss 5.9474e+04, Data-loss 5.9373e+04                  , pde-loss 5.0001e-14, initc-loss 1.2424e+05                    bc_loss 8.8494e+05\n",
      "Epoch 6920, Training-Loss 6.1229e+04, Data-loss 6.1126e+04                  , pde-loss 4.6988e-14, initc-loss 1.2375e+05                    bc_loss 9.0356e+05\n",
      "Epoch 6930, Training-Loss 5.7207e+04, Data-loss 5.7103e+04                  , pde-loss 5.4285e-14, initc-loss 1.2327e+05                    bc_loss 9.2230e+05\n",
      "Epoch 6940, Training-Loss 5.9896e+04, Data-loss 5.9790e+04                  , pde-loss 4.8977e-14, initc-loss 1.2278e+05                    bc_loss 9.4114e+05\n",
      "Epoch 6950, Training-Loss 5.8180e+04, Data-loss 5.8072e+04                  , pde-loss 5.0949e-14, initc-loss 1.2230e+05                    bc_loss 9.6014e+05\n",
      "Epoch 6960, Training-Loss 5.7702e+04, Data-loss 5.7592e+04                  , pde-loss 4.8503e-14, initc-loss 1.2182e+05                    bc_loss 9.7939e+05\n",
      "Epoch 6970, Training-Loss 5.8073e+04, Data-loss 5.7961e+04                  , pde-loss 5.0240e-14, initc-loss 1.2133e+05                    bc_loss 9.9885e+05\n",
      "Epoch 6980, Training-Loss 5.8083e+04, Data-loss 5.7969e+04                  , pde-loss 4.8393e-14, initc-loss 1.2085e+05                    bc_loss 1.0185e+06\n",
      "Epoch 6990, Training-Loss 5.7996e+04, Data-loss 5.7880e+04                  , pde-loss 4.6027e-14, initc-loss 1.2037e+05                    bc_loss 1.0383e+06\n",
      "Epoch 7000, Training-Loss 5.9808e+04, Data-loss 5.9690e+04                  , pde-loss 4.6604e-14, initc-loss 1.1990e+05                    bc_loss 1.0582e+06\n",
      "Epoch 7010, Training-Loss 5.3989e+04, Data-loss 5.3869e+04                  , pde-loss 5.1334e-14, initc-loss 1.1942e+05                    bc_loss 1.0782e+06\n",
      "Epoch 7020, Training-Loss 5.5961e+04, Data-loss 5.5839e+04                  , pde-loss 4.8758e-14, initc-loss 1.1895e+05                    bc_loss 1.0985e+06\n",
      "Epoch 7030, Training-Loss 5.6548e+04, Data-loss 5.6424e+04                  , pde-loss 4.7476e-14, initc-loss 1.1848e+05                    bc_loss 1.1189e+06\n",
      "Epoch 7040, Training-Loss 5.4768e+04, Data-loss 5.4642e+04                  , pde-loss 5.0861e-14, initc-loss 1.1800e+05                    bc_loss 1.1395e+06\n",
      "Epoch 7050, Training-Loss 5.5809e+04, Data-loss 5.5681e+04                  , pde-loss 4.9347e-14, initc-loss 1.1753e+05                    bc_loss 1.1604e+06\n",
      "Epoch 7060, Training-Loss 5.6823e+04, Data-loss 5.6693e+04                  , pde-loss 4.7040e-14, initc-loss 1.1706e+05                    bc_loss 1.1814e+06\n",
      "Epoch 7070, Training-Loss 5.7036e+04, Data-loss 5.6904e+04                  , pde-loss 4.8807e-14, initc-loss 1.1659e+05                    bc_loss 1.2027e+06\n",
      "Epoch 7080, Training-Loss 5.2108e+04, Data-loss 5.1974e+04                  , pde-loss 5.1619e-14, initc-loss 1.1612e+05                    bc_loss 1.2240e+06\n",
      "Epoch 7090, Training-Loss 5.3380e+04, Data-loss 5.3244e+04                  , pde-loss 5.0619e-14, initc-loss 1.1566e+05                    bc_loss 1.2455e+06\n",
      "Epoch 7100, Training-Loss 5.2892e+04, Data-loss 5.2754e+04                  , pde-loss 5.5836e-14, initc-loss 1.1519e+05                    bc_loss 1.2671e+06\n",
      "Epoch 7110, Training-Loss 5.4142e+04, Data-loss 5.4002e+04                  , pde-loss 5.0725e-14, initc-loss 1.1473e+05                    bc_loss 1.2890e+06\n",
      "Epoch 7120, Training-Loss 5.3250e+04, Data-loss 5.3108e+04                  , pde-loss 5.0744e-14, initc-loss 1.1427e+05                    bc_loss 1.3110e+06\n",
      "Epoch 7130, Training-Loss 5.2795e+04, Data-loss 5.2650e+04                  , pde-loss 4.9791e-14, initc-loss 1.1381e+05                    bc_loss 1.3331e+06\n",
      "Epoch 7140, Training-Loss 5.1254e+04, Data-loss 5.1107e+04                  , pde-loss 5.0557e-14, initc-loss 1.1335e+05                    bc_loss 1.3555e+06\n",
      "Epoch 7150, Training-Loss 5.5636e+04, Data-loss 5.5487e+04                  , pde-loss 4.3690e-14, initc-loss 1.1289e+05                    bc_loss 1.3781e+06\n",
      "Epoch 7160, Training-Loss 5.1502e+04, Data-loss 5.1351e+04                  , pde-loss 5.1136e-14, initc-loss 1.1243e+05                    bc_loss 1.4009e+06\n",
      "Epoch 7170, Training-Loss 5.1796e+04, Data-loss 5.1642e+04                  , pde-loss 4.7417e-14, initc-loss 1.1197e+05                    bc_loss 1.4238e+06\n",
      "Epoch 7180, Training-Loss 5.1724e+04, Data-loss 5.1568e+04                  , pde-loss 4.8282e-14, initc-loss 1.1152e+05                    bc_loss 1.4468e+06\n",
      "Epoch 7190, Training-Loss 5.1055e+04, Data-loss 5.0897e+04                  , pde-loss 4.9614e-14, initc-loss 1.1107e+05                    bc_loss 1.4700e+06\n",
      "Epoch 7200, Training-Loss 4.9832e+04, Data-loss 4.9671e+04                  , pde-loss 5.2764e-14, initc-loss 1.1061e+05                    bc_loss 1.4934e+06\n",
      "Epoch 7210, Training-Loss 5.0964e+04, Data-loss 5.0801e+04                  , pde-loss 4.8086e-14, initc-loss 1.1016e+05                    bc_loss 1.5170e+06\n",
      "Epoch 7220, Training-Loss 4.8541e+04, Data-loss 4.8376e+04                  , pde-loss 5.0690e-14, initc-loss 1.0971e+05                    bc_loss 1.5407e+06\n",
      "Epoch 7230, Training-Loss 4.7439e+04, Data-loss 4.7272e+04                  , pde-loss 5.2867e-14, initc-loss 1.0927e+05                    bc_loss 1.5644e+06\n",
      "Epoch 7240, Training-Loss 4.9146e+04, Data-loss 4.8976e+04                  , pde-loss 5.0742e-14, initc-loss 1.0882e+05                    bc_loss 1.5883e+06\n",
      "Epoch 7250, Training-Loss 4.6952e+04, Data-loss 4.6780e+04                  , pde-loss 5.3320e-14, initc-loss 1.0838e+05                    bc_loss 1.6124e+06\n",
      "Epoch 7260, Training-Loss 5.2570e+04, Data-loss 5.2395e+04                  , pde-loss 4.6321e-14, initc-loss 1.0794e+05                    bc_loss 1.6367e+06\n",
      "Epoch 7270, Training-Loss 4.8570e+04, Data-loss 4.8393e+04                  , pde-loss 5.1828e-14, initc-loss 1.0750e+05                    bc_loss 1.6611e+06\n",
      "Epoch 7280, Training-Loss 5.1767e+04, Data-loss 5.1587e+04                  , pde-loss 4.4702e-14, initc-loss 1.0705e+05                    bc_loss 1.6858e+06\n",
      "Epoch 7290, Training-Loss 4.9229e+04, Data-loss 4.9048e+04                  , pde-loss 4.7313e-14, initc-loss 1.0661e+05                    bc_loss 1.7107e+06\n",
      "Epoch 7300, Training-Loss 4.8377e+04, Data-loss 4.8193e+04                  , pde-loss 4.3873e-14, initc-loss 1.0617e+05                    bc_loss 1.7359e+06\n",
      "Epoch 7310, Training-Loss 4.6245e+04, Data-loss 4.6058e+04                  , pde-loss 4.9689e-14, initc-loss 1.0573e+05                    bc_loss 1.7612e+06\n",
      "Epoch 7320, Training-Loss 4.6113e+04, Data-loss 4.5924e+04                  , pde-loss 4.6728e-14, initc-loss 1.0529e+05                    bc_loss 1.7865e+06\n",
      "Epoch 7330, Training-Loss 4.7060e+04, Data-loss 4.6868e+04                  , pde-loss 4.4086e-14, initc-loss 1.0486e+05                    bc_loss 1.8119e+06\n",
      "Epoch 7340, Training-Loss 4.8224e+04, Data-loss 4.8030e+04                  , pde-loss 4.2017e-14, initc-loss 1.0443e+05                    bc_loss 1.8374e+06\n",
      "Epoch 7350, Training-Loss 4.7122e+04, Data-loss 4.6925e+04                  , pde-loss 4.2448e-14, initc-loss 1.0399e+05                    bc_loss 1.8633e+06\n",
      "Epoch 7360, Training-Loss 4.7300e+04, Data-loss 4.7100e+04                  , pde-loss 4.0933e-14, initc-loss 1.0356e+05                    bc_loss 1.8893e+06\n",
      "Epoch 7370, Training-Loss 4.8105e+04, Data-loss 4.7903e+04                  , pde-loss 3.7424e-14, initc-loss 1.0313e+05                    bc_loss 1.9154e+06\n",
      "Epoch 7380, Training-Loss 4.3906e+04, Data-loss 4.3702e+04                  , pde-loss 4.3929e-14, initc-loss 1.0270e+05                    bc_loss 1.9417e+06\n",
      "Epoch 7390, Training-Loss 4.6769e+04, Data-loss 4.6562e+04                  , pde-loss 3.8344e-14, initc-loss 1.0227e+05                    bc_loss 1.9681e+06\n",
      "Epoch 7400, Training-Loss 4.6465e+04, Data-loss 4.6255e+04                  , pde-loss 3.8781e-14, initc-loss 1.0185e+05                    bc_loss 1.9946e+06\n",
      "Epoch 7410, Training-Loss 4.4589e+04, Data-loss 4.4377e+04                  , pde-loss 4.2854e-14, initc-loss 1.0142e+05                    bc_loss 2.0213e+06\n",
      "Epoch 7420, Training-Loss 4.4526e+04, Data-loss 4.4311e+04                  , pde-loss 4.1468e-14, initc-loss 1.0100e+05                    bc_loss 2.0483e+06\n",
      "Epoch 7430, Training-Loss 4.5184e+04, Data-loss 4.4966e+04                  , pde-loss 4.0060e-14, initc-loss 1.0057e+05                    bc_loss 2.0753e+06\n",
      "Epoch 7440, Training-Loss 4.5045e+04, Data-loss 4.4825e+04                  , pde-loss 3.9907e-14, initc-loss 1.0015e+05                    bc_loss 2.1024e+06\n",
      "Epoch 7450, Training-Loss 4.3078e+04, Data-loss 4.2855e+04                  , pde-loss 4.3783e-14, initc-loss 9.9735e+04                    bc_loss 2.1297e+06\n",
      "Epoch 7460, Training-Loss 4.4011e+04, Data-loss 4.3785e+04                  , pde-loss 4.2564e-14, initc-loss 9.9315e+04                    bc_loss 2.1573e+06\n",
      "Epoch 7470, Training-Loss 4.2368e+04, Data-loss 4.2140e+04                  , pde-loss 4.4747e-14, initc-loss 9.8896e+04                    bc_loss 2.1850e+06\n",
      "Epoch 7480, Training-Loss 4.2799e+04, Data-loss 4.2568e+04                  , pde-loss 4.2388e-14, initc-loss 9.8479e+04                    bc_loss 2.2129e+06\n",
      "Epoch 7490, Training-Loss 3.7820e+04, Data-loss 3.7586e+04                  , pde-loss 5.2032e-14, initc-loss 9.8061e+04                    bc_loss 2.2410e+06\n",
      "Epoch 7500, Training-Loss 4.0323e+04, Data-loss 4.0087e+04                  , pde-loss 4.4064e-14, initc-loss 9.7648e+04                    bc_loss 2.2690e+06\n",
      "Epoch 7510, Training-Loss 4.1382e+04, Data-loss 4.1142e+04                  , pde-loss 4.3661e-14, initc-loss 9.7235e+04                    bc_loss 2.2973e+06\n",
      "Epoch 7520, Training-Loss 4.1512e+04, Data-loss 4.1270e+04                  , pde-loss 4.4273e-14, initc-loss 9.6823e+04                    bc_loss 2.3257e+06\n",
      "Epoch 7530, Training-Loss 4.0341e+04, Data-loss 4.0095e+04                  , pde-loss 4.3932e-14, initc-loss 9.6413e+04                    bc_loss 2.3543e+06\n",
      "Epoch 7540, Training-Loss 4.1780e+04, Data-loss 4.1532e+04                  , pde-loss 4.5690e-14, initc-loss 9.6003e+04                    bc_loss 2.3830e+06\n",
      "Epoch 7550, Training-Loss 4.3135e+04, Data-loss 4.2885e+04                  , pde-loss 4.1263e-14, initc-loss 9.5595e+04                    bc_loss 2.4119e+06\n",
      "Epoch 7560, Training-Loss 3.9648e+04, Data-loss 3.9394e+04                  , pde-loss 4.8819e-14, initc-loss 9.5188e+04                    bc_loss 2.4410e+06\n",
      "Epoch 7570, Training-Loss 4.2248e+04, Data-loss 4.1992e+04                  , pde-loss 4.3148e-14, initc-loss 9.4782e+04                    bc_loss 2.4701e+06\n",
      "Epoch 7580, Training-Loss 3.8675e+04, Data-loss 3.8416e+04                  , pde-loss 4.5146e-14, initc-loss 9.4378e+04                    bc_loss 2.4994e+06\n",
      "Epoch 7590, Training-Loss 3.9621e+04, Data-loss 3.9359e+04                  , pde-loss 4.5145e-14, initc-loss 9.3976e+04                    bc_loss 2.5287e+06\n",
      "Epoch 7600, Training-Loss 3.9349e+04, Data-loss 3.9084e+04                  , pde-loss 4.6208e-14, initc-loss 9.3575e+04                    bc_loss 2.5583e+06\n",
      "Epoch 7610, Training-Loss 4.1208e+04, Data-loss 4.0940e+04                  , pde-loss 4.3175e-14, initc-loss 9.3173e+04                    bc_loss 2.5881e+06\n",
      "Epoch 7620, Training-Loss 4.0995e+04, Data-loss 4.0724e+04                  , pde-loss 4.3652e-14, initc-loss 9.2772e+04                    bc_loss 2.6182e+06\n",
      "Epoch 7630, Training-Loss 3.7486e+04, Data-loss 3.7211e+04                  , pde-loss 4.7278e-14, initc-loss 9.2372e+04                    bc_loss 2.6483e+06\n",
      "Epoch 7640, Training-Loss 3.9369e+04, Data-loss 3.9092e+04                  , pde-loss 4.2105e-14, initc-loss 9.1976e+04                    bc_loss 2.6785e+06\n",
      "Epoch 7650, Training-Loss 3.8818e+04, Data-loss 3.8538e+04                  , pde-loss 4.2462e-14, initc-loss 9.1579e+04                    bc_loss 2.7088e+06\n",
      "Epoch 7660, Training-Loss 3.6204e+04, Data-loss 3.5921e+04                  , pde-loss 4.6190e-14, initc-loss 9.1185e+04                    bc_loss 2.7393e+06\n",
      "Epoch 7670, Training-Loss 3.9953e+04, Data-loss 3.9667e+04                  , pde-loss 3.9580e-14, initc-loss 9.0793e+04                    bc_loss 2.7698e+06\n",
      "Epoch 7680, Training-Loss 3.7322e+04, Data-loss 3.7033e+04                  , pde-loss 4.5663e-14, initc-loss 9.0400e+04                    bc_loss 2.8006e+06\n",
      "Epoch 7690, Training-Loss 3.9798e+04, Data-loss 3.9506e+04                  , pde-loss 3.9479e-14, initc-loss 9.0008e+04                    bc_loss 2.8316e+06\n",
      "Epoch 7700, Training-Loss 3.6535e+04, Data-loss 3.6240e+04                  , pde-loss 4.4341e-14, initc-loss 8.9617e+04                    bc_loss 2.8627e+06\n",
      "Epoch 7710, Training-Loss 3.5099e+04, Data-loss 3.4801e+04                  , pde-loss 4.7823e-14, initc-loss 8.9228e+04                    bc_loss 2.8939e+06\n",
      "Epoch 7720, Training-Loss 3.8044e+04, Data-loss 3.7743e+04                  , pde-loss 4.2503e-14, initc-loss 8.8844e+04                    bc_loss 2.9249e+06\n",
      "Epoch 7730, Training-Loss 3.5579e+04, Data-loss 3.5274e+04                  , pde-loss 4.8033e-14, initc-loss 8.8459e+04                    bc_loss 2.9563e+06\n",
      "Epoch 7740, Training-Loss 3.8427e+04, Data-loss 3.8119e+04                  , pde-loss 4.0596e-14, initc-loss 8.8074e+04                    bc_loss 2.9879e+06\n",
      "Epoch 7750, Training-Loss 3.4606e+04, Data-loss 3.4295e+04                  , pde-loss 4.6360e-14, initc-loss 8.7689e+04                    bc_loss 3.0198e+06\n",
      "Epoch 7760, Training-Loss 3.6223e+04, Data-loss 3.5909e+04                  , pde-loss 4.2879e-14, initc-loss 8.7305e+04                    bc_loss 3.0517e+06\n",
      "Epoch 7770, Training-Loss 3.6134e+04, Data-loss 3.5817e+04                  , pde-loss 4.4454e-14, initc-loss 8.6923e+04                    bc_loss 3.0838e+06\n",
      "Epoch 7780, Training-Loss 3.3219e+04, Data-loss 3.2899e+04                  , pde-loss 4.9342e-14, initc-loss 8.6543e+04                    bc_loss 3.1159e+06\n",
      "Epoch 7790, Training-Loss 3.7671e+04, Data-loss 3.7348e+04                  , pde-loss 4.3069e-14, initc-loss 8.6167e+04                    bc_loss 3.1479e+06\n",
      "Epoch 7800, Training-Loss 3.6517e+04, Data-loss 3.6190e+04                  , pde-loss 4.2851e-14, initc-loss 8.5790e+04                    bc_loss 3.1802e+06\n",
      "Epoch 7810, Training-Loss 3.6589e+04, Data-loss 3.6259e+04                  , pde-loss 4.1314e-14, initc-loss 8.5415e+04                    bc_loss 3.2127e+06\n",
      "Epoch 7820, Training-Loss 3.3378e+04, Data-loss 3.3045e+04                  , pde-loss 4.5625e-14, initc-loss 8.5041e+04                    bc_loss 3.2453e+06\n",
      "Epoch 7830, Training-Loss 3.4419e+04, Data-loss 3.4083e+04                  , pde-loss 4.6899e-14, initc-loss 8.4667e+04                    bc_loss 3.2780e+06\n",
      "Epoch 7840, Training-Loss 3.3887e+04, Data-loss 3.3548e+04                  , pde-loss 4.8418e-14, initc-loss 8.4294e+04                    bc_loss 3.3109e+06\n",
      "Epoch 7850, Training-Loss 3.5267e+04, Data-loss 3.4925e+04                  , pde-loss 4.0008e-14, initc-loss 8.3924e+04                    bc_loss 3.3439e+06\n",
      "Epoch 7860, Training-Loss 3.5032e+04, Data-loss 3.4686e+04                  , pde-loss 4.0069e-14, initc-loss 8.3553e+04                    bc_loss 3.3771e+06\n",
      "Epoch 7870, Training-Loss 3.3519e+04, Data-loss 3.3170e+04                  , pde-loss 4.1201e-14, initc-loss 8.3184e+04                    bc_loss 3.4104e+06\n",
      "Epoch 7880, Training-Loss 3.5144e+04, Data-loss 3.4791e+04                  , pde-loss 3.4037e-14, initc-loss 8.2816e+04                    bc_loss 3.4439e+06\n",
      "Epoch 7890, Training-Loss 3.2929e+04, Data-loss 3.2573e+04                  , pde-loss 3.9162e-14, initc-loss 8.2447e+04                    bc_loss 3.4776e+06\n",
      "Epoch 7900, Training-Loss 3.5058e+04, Data-loss 3.4699e+04                  , pde-loss 3.5665e-14, initc-loss 8.2081e+04                    bc_loss 3.5114e+06\n",
      "Epoch 7910, Training-Loss 3.0817e+04, Data-loss 3.0454e+04                  , pde-loss 3.8206e-14, initc-loss 8.1716e+04                    bc_loss 3.5453e+06\n",
      "Epoch 7920, Training-Loss 3.4289e+04, Data-loss 3.3923e+04                  , pde-loss 3.2075e-14, initc-loss 8.1353e+04                    bc_loss 3.5792e+06\n",
      "Epoch 7930, Training-Loss 3.2900e+04, Data-loss 3.2531e+04                  , pde-loss 3.5687e-14, initc-loss 8.0988e+04                    bc_loss 3.6136e+06\n",
      "Epoch 7940, Training-Loss 3.2073e+04, Data-loss 3.1700e+04                  , pde-loss 3.5848e-14, initc-loss 8.0624e+04                    bc_loss 3.6480e+06\n",
      "Epoch 7950, Training-Loss 3.1313e+04, Data-loss 3.0937e+04                  , pde-loss 3.8920e-14, initc-loss 8.0265e+04                    bc_loss 3.6823e+06\n",
      "Epoch 7960, Training-Loss 3.1527e+04, Data-loss 3.1148e+04                  , pde-loss 3.4767e-14, initc-loss 7.9906e+04                    bc_loss 3.7168e+06\n",
      "Epoch 7970, Training-Loss 3.1144e+04, Data-loss 3.0761e+04                  , pde-loss 3.4627e-14, initc-loss 7.9548e+04                    bc_loss 3.7514e+06\n",
      "Epoch 7980, Training-Loss 3.0454e+04, Data-loss 3.0067e+04                  , pde-loss 3.6734e-14, initc-loss 7.9194e+04                    bc_loss 3.7860e+06\n",
      "Epoch 7990, Training-Loss 3.1253e+04, Data-loss 3.0863e+04                  , pde-loss 3.6239e-14, initc-loss 7.8840e+04                    bc_loss 3.8207e+06\n",
      "Epoch 8000, Training-Loss 3.1779e+04, Data-loss 3.1385e+04                  , pde-loss 3.2840e-14, initc-loss 7.8486e+04                    bc_loss 3.8556e+06\n",
      "Epoch 8010, Training-Loss 2.9816e+04, Data-loss 2.9419e+04                  , pde-loss 3.6355e-14, initc-loss 7.8134e+04                    bc_loss 3.8907e+06\n",
      "Epoch 8020, Training-Loss 2.9559e+04, Data-loss 2.9159e+04                  , pde-loss 3.5190e-14, initc-loss 7.7782e+04                    bc_loss 3.9259e+06\n",
      "Epoch 8030, Training-Loss 3.0213e+04, Data-loss 2.9809e+04                  , pde-loss 3.3543e-14, initc-loss 7.7431e+04                    bc_loss 3.9613e+06\n",
      "Epoch 8040, Training-Loss 2.9524e+04, Data-loss 2.9116e+04                  , pde-loss 3.0356e-14, initc-loss 7.7083e+04                    bc_loss 3.9966e+06\n",
      "Epoch 8050, Training-Loss 2.9881e+04, Data-loss 2.9470e+04                  , pde-loss 3.0112e-14, initc-loss 7.6735e+04                    bc_loss 4.0322e+06\n",
      "Epoch 8060, Training-Loss 2.8793e+04, Data-loss 2.8378e+04                  , pde-loss 3.0726e-14, initc-loss 7.6388e+04                    bc_loss 4.0678e+06\n",
      "Epoch 8070, Training-Loss 2.8692e+04, Data-loss 2.8274e+04                  , pde-loss 2.8718e-14, initc-loss 7.6044e+04                    bc_loss 4.1035e+06\n",
      "Epoch 8080, Training-Loss 3.0820e+04, Data-loss 3.0398e+04                  , pde-loss 2.7475e-14, initc-loss 7.5698e+04                    bc_loss 4.1395e+06\n",
      "Epoch 8090, Training-Loss 2.8990e+04, Data-loss 2.8565e+04                  , pde-loss 3.1002e-14, initc-loss 7.5354e+04                    bc_loss 4.1756e+06\n",
      "Epoch 8100, Training-Loss 2.7470e+04, Data-loss 2.7042e+04                  , pde-loss 3.3338e-14, initc-loss 7.5011e+04                    bc_loss 4.2119e+06\n",
      "Epoch 8110, Training-Loss 2.7789e+04, Data-loss 2.7357e+04                  , pde-loss 3.1848e-14, initc-loss 7.4672e+04                    bc_loss 4.2479e+06\n",
      "Epoch 8120, Training-Loss 3.0784e+04, Data-loss 3.0348e+04                  , pde-loss 2.7581e-14, initc-loss 7.4336e+04                    bc_loss 4.2839e+06\n",
      "Epoch 8130, Training-Loss 2.7507e+04, Data-loss 2.7068e+04                  , pde-loss 2.9623e-14, initc-loss 7.3997e+04                    bc_loss 4.3204e+06\n",
      "Epoch 8140, Training-Loss 2.8331e+04, Data-loss 2.7888e+04                  , pde-loss 3.0198e-14, initc-loss 7.3660e+04                    bc_loss 4.3570e+06\n",
      "Epoch 8150, Training-Loss 2.8450e+04, Data-loss 2.8003e+04                  , pde-loss 2.9575e-14, initc-loss 7.3324e+04                    bc_loss 4.3936e+06\n",
      "Epoch 8160, Training-Loss 2.6934e+04, Data-loss 2.6484e+04                  , pde-loss 3.1132e-14, initc-loss 7.2989e+04                    bc_loss 4.4304e+06\n",
      "Epoch 8170, Training-Loss 2.7002e+04, Data-loss 2.6548e+04                  , pde-loss 3.0794e-14, initc-loss 7.2655e+04                    bc_loss 4.4673e+06\n",
      "Epoch 8180, Training-Loss 2.8499e+04, Data-loss 2.8041e+04                  , pde-loss 2.6999e-14, initc-loss 7.2324e+04                    bc_loss 4.5041e+06\n",
      "Epoch 8190, Training-Loss 2.5249e+04, Data-loss 2.4788e+04                  , pde-loss 2.8373e-14, initc-loss 7.1993e+04                    bc_loss 4.5411e+06\n",
      "Epoch 8200, Training-Loss 2.7277e+04, Data-loss 2.6812e+04                  , pde-loss 2.5347e-14, initc-loss 7.1663e+04                    bc_loss 4.5784e+06\n",
      "Epoch 8210, Training-Loss 2.7486e+04, Data-loss 2.7017e+04                  , pde-loss 2.2037e-14, initc-loss 7.1334e+04                    bc_loss 4.6157e+06\n",
      "Epoch 8220, Training-Loss 2.5293e+04, Data-loss 2.4821e+04                  , pde-loss 2.2987e-14, initc-loss 7.1005e+04                    bc_loss 4.6532e+06\n",
      "Epoch 8230, Training-Loss 2.5858e+04, Data-loss 2.5382e+04                  , pde-loss 2.1040e-14, initc-loss 7.0679e+04                    bc_loss 4.6906e+06\n",
      "Epoch 8240, Training-Loss 2.6206e+04, Data-loss 2.5726e+04                  , pde-loss 2.0517e-14, initc-loss 7.0355e+04                    bc_loss 4.7281e+06\n",
      "Epoch 8250, Training-Loss 2.5010e+04, Data-loss 2.4527e+04                  , pde-loss 1.8932e-14, initc-loss 7.0030e+04                    bc_loss 4.7659e+06\n",
      "Epoch 8260, Training-Loss 2.7966e+04, Data-loss 2.7479e+04                  , pde-loss 1.3984e-14, initc-loss 6.9708e+04                    bc_loss 4.8036e+06\n",
      "Epoch 8270, Training-Loss 2.5630e+04, Data-loss 2.5139e+04                  , pde-loss 1.4361e-14, initc-loss 6.9387e+04                    bc_loss 4.8414e+06\n",
      "Epoch 8280, Training-Loss 2.5974e+04, Data-loss 2.5480e+04                  , pde-loss 1.4251e-14, initc-loss 6.9068e+04                    bc_loss 4.8792e+06\n",
      "Epoch 8290, Training-Loss 2.4759e+04, Data-loss 2.4260e+04                  , pde-loss 1.2220e-14, initc-loss 6.8748e+04                    bc_loss 4.9173e+06\n",
      "Epoch 8300, Training-Loss 2.5461e+04, Data-loss 2.4958e+04                  , pde-loss 1.3385e-14, initc-loss 6.8430e+04                    bc_loss 4.9555e+06\n",
      "Epoch 8310, Training-Loss 2.4534e+04, Data-loss 2.4028e+04                  , pde-loss 1.2987e-14, initc-loss 6.8113e+04                    bc_loss 4.9938e+06\n",
      "Epoch 8320, Training-Loss 2.3215e+04, Data-loss 2.2705e+04                  , pde-loss 1.6546e-14, initc-loss 6.7798e+04                    bc_loss 5.0320e+06\n",
      "Epoch 8330, Training-Loss 2.4745e+04, Data-loss 2.4231e+04                  , pde-loss 1.0228e-14, initc-loss 6.7485e+04                    bc_loss 5.0703e+06\n",
      "Epoch 8340, Training-Loss 2.5798e+04, Data-loss 2.5281e+04                  , pde-loss 9.7970e-15, initc-loss 6.7173e+04                    bc_loss 5.1087e+06\n",
      "Epoch 8350, Training-Loss 2.3207e+04, Data-loss 2.2685e+04                  , pde-loss 1.0902e-14, initc-loss 6.6859e+04                    bc_loss 5.1475e+06\n",
      "Epoch 8360, Training-Loss 2.5158e+04, Data-loss 2.4633e+04                  , pde-loss 9.4020e-15, initc-loss 6.6546e+04                    bc_loss 5.1865e+06\n",
      "Epoch 8370, Training-Loss 2.3270e+04, Data-loss 2.2741e+04                  , pde-loss 1.1221e-14, initc-loss 6.6237e+04                    bc_loss 5.2252e+06\n",
      "Epoch 8380, Training-Loss 2.1714e+04, Data-loss 2.1181e+04                  , pde-loss 1.1050e-14, initc-loss 6.5928e+04                    bc_loss 5.2641e+06\n",
      "Epoch 8390, Training-Loss 2.2416e+04, Data-loss 2.1879e+04                  , pde-loss 1.0903e-14, initc-loss 6.5622e+04                    bc_loss 5.3029e+06\n",
      "Epoch 8400, Training-Loss 2.3854e+04, Data-loss 2.3313e+04                  , pde-loss 1.0823e-14, initc-loss 6.5314e+04                    bc_loss 5.3421e+06\n",
      "Epoch 8410, Training-Loss 2.2861e+04, Data-loss 2.2317e+04                  , pde-loss 1.0497e-14, initc-loss 6.5007e+04                    bc_loss 5.3815e+06\n",
      "Epoch 8420, Training-Loss 2.1221e+04, Data-loss 2.0673e+04                  , pde-loss 1.1252e-14, initc-loss 6.4700e+04                    bc_loss 5.4211e+06\n",
      "Epoch 8430, Training-Loss 2.2076e+04, Data-loss 2.1524e+04                  , pde-loss 1.0941e-14, initc-loss 6.4397e+04                    bc_loss 5.4605e+06\n",
      "Epoch 8440, Training-Loss 2.3253e+04, Data-loss 2.2696e+04                  , pde-loss 9.2497e-15, initc-loss 6.4094e+04                    bc_loss 5.5000e+06\n",
      "Epoch 8450, Training-Loss 2.2857e+04, Data-loss 2.2297e+04                  , pde-loss 9.3244e-15, initc-loss 6.3792e+04                    bc_loss 5.5398e+06\n",
      "Epoch 8460, Training-Loss 2.2969e+04, Data-loss 2.2404e+04                  , pde-loss 8.2496e-15, initc-loss 6.3489e+04                    bc_loss 5.5798e+06\n",
      "Epoch 8470, Training-Loss 2.1619e+04, Data-loss 2.1050e+04                  , pde-loss 8.4711e-15, initc-loss 6.3189e+04                    bc_loss 5.6196e+06\n",
      "Epoch 8480, Training-Loss 2.0329e+04, Data-loss 1.9756e+04                  , pde-loss 7.6865e-15, initc-loss 6.2892e+04                    bc_loss 5.6595e+06\n",
      "Epoch 8490, Training-Loss 2.1015e+04, Data-loss 2.0439e+04                  , pde-loss 7.2098e-15, initc-loss 6.2597e+04                    bc_loss 5.6991e+06\n",
      "Epoch 8500, Training-Loss 2.3775e+04, Data-loss 2.3195e+04                  , pde-loss 5.9957e-15, initc-loss 6.2302e+04                    bc_loss 5.7390e+06\n",
      "Epoch 8510, Training-Loss 2.0335e+04, Data-loss 1.9751e+04                  , pde-loss 7.0582e-15, initc-loss 6.2007e+04                    bc_loss 5.7792e+06\n",
      "Epoch 8520, Training-Loss 2.1013e+04, Data-loss 2.0425e+04                  , pde-loss 5.1455e-15, initc-loss 6.1715e+04                    bc_loss 5.8192e+06\n",
      "Epoch 8530, Training-Loss 2.0530e+04, Data-loss 1.9938e+04                  , pde-loss 3.9347e-15, initc-loss 6.1423e+04                    bc_loss 5.8594e+06\n",
      "Epoch 8540, Training-Loss 2.0617e+04, Data-loss 2.0021e+04                  , pde-loss 3.6264e-15, initc-loss 6.1134e+04                    bc_loss 5.8994e+06\n",
      "Epoch 8550, Training-Loss 2.0126e+04, Data-loss 1.9526e+04                  , pde-loss 4.1062e-15, initc-loss 6.0846e+04                    bc_loss 5.9395e+06\n",
      "Epoch 8560, Training-Loss 2.1261e+04, Data-loss 2.0657e+04                  , pde-loss 2.8841e-15, initc-loss 6.0558e+04                    bc_loss 5.9798e+06\n",
      "Epoch 8570, Training-Loss 1.9342e+04, Data-loss 1.8733e+04                  , pde-loss 2.3921e-15, initc-loss 6.0270e+04                    bc_loss 6.0204e+06\n",
      "Epoch 8580, Training-Loss 2.1241e+04, Data-loss 2.0629e+04                  , pde-loss 2.0096e-15, initc-loss 5.9983e+04                    bc_loss 6.0612e+06\n",
      "Epoch 8590, Training-Loss 1.9729e+04, Data-loss 1.9113e+04                  , pde-loss 1.7626e-15, initc-loss 5.9696e+04                    bc_loss 6.1021e+06\n",
      "Epoch 8600, Training-Loss 1.9217e+04, Data-loss 1.8596e+04                  , pde-loss 2.8868e-15, initc-loss 5.9411e+04                    bc_loss 6.1429e+06\n",
      "Epoch 8610, Training-Loss 1.9919e+04, Data-loss 1.9295e+04                  , pde-loss 2.9952e-15, initc-loss 5.9128e+04                    bc_loss 6.1838e+06\n",
      "Epoch 8620, Training-Loss 2.0220e+04, Data-loss 1.9592e+04                  , pde-loss 2.6097e-15, initc-loss 5.8847e+04                    bc_loss 6.2245e+06\n",
      "Epoch 8630, Training-Loss 2.0654e+04, Data-loss 2.0021e+04                  , pde-loss 1.3715e-15, initc-loss 5.8566e+04                    bc_loss 6.2655e+06\n",
      "Epoch 8640, Training-Loss 1.9083e+04, Data-loss 1.8446e+04                  , pde-loss 2.6119e-15, initc-loss 5.8285e+04                    bc_loss 6.3067e+06\n",
      "Epoch 8650, Training-Loss 1.9854e+04, Data-loss 1.9214e+04                  , pde-loss 2.1499e-15, initc-loss 5.8006e+04                    bc_loss 6.3479e+06\n",
      "Epoch 8660, Training-Loss 1.8902e+04, Data-loss 1.8257e+04                  , pde-loss 1.5370e-15, initc-loss 5.7726e+04                    bc_loss 6.3894e+06\n",
      "Epoch 8670, Training-Loss 1.9528e+04, Data-loss 1.8879e+04                  , pde-loss 1.3354e-15, initc-loss 5.7451e+04                    bc_loss 6.4304e+06\n",
      "Epoch 8680, Training-Loss 1.9134e+04, Data-loss 1.8481e+04                  , pde-loss 1.4405e-15, initc-loss 5.7176e+04                    bc_loss 6.4718e+06\n",
      "Epoch 8690, Training-Loss 1.9106e+04, Data-loss 1.8449e+04                  , pde-loss 1.7073e-15, initc-loss 5.6899e+04                    bc_loss 6.5135e+06\n",
      "Epoch 8700, Training-Loss 1.5955e+04, Data-loss 1.5294e+04                  , pde-loss 2.8061e-15, initc-loss 5.6626e+04                    bc_loss 6.5550e+06\n",
      "Epoch 8710, Training-Loss 1.8247e+04, Data-loss 1.7581e+04                  , pde-loss 2.0815e-15, initc-loss 5.6355e+04                    bc_loss 6.5963e+06\n",
      "Epoch 8720, Training-Loss 1.7170e+04, Data-loss 1.6500e+04                  , pde-loss 1.9603e-15, initc-loss 5.6083e+04                    bc_loss 6.6380e+06\n",
      "Epoch 8730, Training-Loss 1.8873e+04, Data-loss 1.8199e+04                  , pde-loss 2.6054e-15, initc-loss 5.5813e+04                    bc_loss 6.6797e+06\n",
      "Epoch 8740, Training-Loss 1.7939e+04, Data-loss 1.7261e+04                  , pde-loss 2.4245e-15, initc-loss 5.5544e+04                    bc_loss 6.7215e+06\n",
      "Epoch 8750, Training-Loss 1.7920e+04, Data-loss 1.7238e+04                  , pde-loss 2.4469e-15, initc-loss 5.5277e+04                    bc_loss 6.7631e+06\n",
      "Epoch 8760, Training-Loss 1.8270e+04, Data-loss 1.7584e+04                  , pde-loss 1.3826e-15, initc-loss 5.5010e+04                    bc_loss 6.8049e+06\n",
      "Epoch 8770, Training-Loss 1.7643e+04, Data-loss 1.6952e+04                  , pde-loss 2.5775e-15, initc-loss 5.4745e+04                    bc_loss 6.8468e+06\n",
      "Epoch 8780, Training-Loss 1.6881e+04, Data-loss 1.6186e+04                  , pde-loss 1.4847e-15, initc-loss 5.4480e+04                    bc_loss 6.8888e+06\n",
      "Epoch 8790, Training-Loss 1.8858e+04, Data-loss 1.8160e+04                  , pde-loss 1.3394e-15, initc-loss 5.4216e+04                    bc_loss 6.9308e+06\n",
      "Epoch 8800, Training-Loss 1.8308e+04, Data-loss 1.7606e+04                  , pde-loss 1.4561e-15, initc-loss 5.3953e+04                    bc_loss 6.9731e+06\n",
      "Epoch 8810, Training-Loss 1.7177e+04, Data-loss 1.6470e+04                  , pde-loss 1.7540e-15, initc-loss 5.3691e+04                    bc_loss 7.0153e+06\n",
      "Epoch 8820, Training-Loss 1.5415e+04, Data-loss 1.4703e+04                  , pde-loss 2.5960e-15, initc-loss 5.3430e+04                    bc_loss 7.0576e+06\n",
      "Epoch 8830, Training-Loss 1.7686e+04, Data-loss 1.6971e+04                  , pde-loss 1.3048e-15, initc-loss 5.3170e+04                    bc_loss 7.0999e+06\n",
      "Epoch 8840, Training-Loss 1.8005e+04, Data-loss 1.7285e+04                  , pde-loss 2.0678e-15, initc-loss 5.2909e+04                    bc_loss 7.1427e+06\n",
      "Epoch 8850, Training-Loss 1.7128e+04, Data-loss 1.6404e+04                  , pde-loss 1.3231e-15, initc-loss 5.2650e+04                    bc_loss 7.1854e+06\n",
      "Epoch 8860, Training-Loss 1.6071e+04, Data-loss 1.5343e+04                  , pde-loss 1.8626e-15, initc-loss 5.2393e+04                    bc_loss 7.2280e+06\n",
      "Epoch 8870, Training-Loss 1.6591e+04, Data-loss 1.5859e+04                  , pde-loss 9.9076e-16, initc-loss 5.2136e+04                    bc_loss 7.2708e+06\n",
      "Epoch 8880, Training-Loss 1.5311e+04, Data-loss 1.4574e+04                  , pde-loss 1.5587e-15, initc-loss 5.1880e+04                    bc_loss 7.3136e+06\n",
      "Epoch 8890, Training-Loss 1.4083e+04, Data-loss 1.3342e+04                  , pde-loss 1.1578e-15, initc-loss 5.1628e+04                    bc_loss 7.3560e+06\n",
      "Epoch 8900, Training-Loss 1.5056e+04, Data-loss 1.4311e+04                  , pde-loss 1.2816e-15, initc-loss 5.1380e+04                    bc_loss 7.3981e+06\n",
      "Epoch 8910, Training-Loss 1.5273e+04, Data-loss 1.4523e+04                  , pde-loss 9.2230e-16, initc-loss 5.1132e+04                    bc_loss 7.4403e+06\n",
      "Epoch 8920, Training-Loss 1.4817e+04, Data-loss 1.4064e+04                  , pde-loss 8.0191e-16, initc-loss 5.0881e+04                    bc_loss 7.4831e+06\n",
      "Epoch 8930, Training-Loss 1.5347e+04, Data-loss 1.4590e+04                  , pde-loss 1.2272e-15, initc-loss 5.0632e+04                    bc_loss 7.5261e+06\n",
      "Epoch 8940, Training-Loss 1.5011e+04, Data-loss 1.4249e+04                  , pde-loss 7.8398e-16, initc-loss 5.0382e+04                    bc_loss 7.5692e+06\n",
      "Epoch 8950, Training-Loss 1.6179e+04, Data-loss 1.5412e+04                  , pde-loss 1.5516e-15, initc-loss 5.0136e+04                    bc_loss 7.6119e+06\n",
      "Epoch 8960, Training-Loss 1.5716e+04, Data-loss 1.4946e+04                  , pde-loss 1.5920e-15, initc-loss 4.9892e+04                    bc_loss 7.6546e+06\n",
      "Epoch 8970, Training-Loss 1.4919e+04, Data-loss 1.4144e+04                  , pde-loss 7.3170e-16, initc-loss 4.9646e+04                    bc_loss 7.6978e+06\n",
      "Epoch 8980, Training-Loss 1.4834e+04, Data-loss 1.4055e+04                  , pde-loss 7.3440e-16, initc-loss 4.9400e+04                    bc_loss 7.7412e+06\n",
      "Epoch 8990, Training-Loss 1.4176e+04, Data-loss 1.3392e+04                  , pde-loss 6.9178e-16, initc-loss 4.9155e+04                    bc_loss 7.7847e+06\n",
      "Epoch 9000, Training-Loss 1.4543e+04, Data-loss 1.3755e+04                  , pde-loss 6.4201e-16, initc-loss 4.8911e+04                    bc_loss 7.8283e+06\n",
      "Epoch 9010, Training-Loss 1.4879e+04, Data-loss 1.4087e+04                  , pde-loss 7.1442e-16, initc-loss 4.8668e+04                    bc_loss 7.8719e+06\n",
      "Epoch 9020, Training-Loss 1.4775e+04, Data-loss 1.3979e+04                  , pde-loss 7.1454e-16, initc-loss 4.8429e+04                    bc_loss 7.9149e+06\n",
      "Epoch 9030, Training-Loss 1.4470e+04, Data-loss 1.3669e+04                  , pde-loss 8.5412e-16, initc-loss 4.8191e+04                    bc_loss 7.9582e+06\n",
      "Epoch 9040, Training-Loss 1.4517e+04, Data-loss 1.3712e+04                  , pde-loss 8.6285e-16, initc-loss 4.7953e+04                    bc_loss 8.0015e+06\n",
      "Epoch 9050, Training-Loss 1.4093e+04, Data-loss 1.3283e+04                  , pde-loss 1.2921e-15, initc-loss 4.7717e+04                    bc_loss 8.0447e+06\n",
      "Epoch 9060, Training-Loss 1.3649e+04, Data-loss 1.2836e+04                  , pde-loss 1.3738e-15, initc-loss 4.7483e+04                    bc_loss 8.0877e+06\n",
      "Epoch 9070, Training-Loss 1.3353e+04, Data-loss 1.2536e+04                  , pde-loss 1.6705e-15, initc-loss 4.7250e+04                    bc_loss 8.1308e+06\n",
      "Epoch 9080, Training-Loss 1.2755e+04, Data-loss 1.1933e+04                  , pde-loss 1.1043e-15, initc-loss 4.7021e+04                    bc_loss 8.1735e+06\n",
      "Epoch 9090, Training-Loss 1.4016e+04, Data-loss 1.3190e+04                  , pde-loss 1.4135e-15, initc-loss 4.6791e+04                    bc_loss 8.2165e+06\n",
      "Epoch 9100, Training-Loss 1.2740e+04, Data-loss 1.1910e+04                  , pde-loss 1.5789e-15, initc-loss 4.6560e+04                    bc_loss 8.2599e+06\n",
      "Epoch 9110, Training-Loss 1.3097e+04, Data-loss 1.2262e+04                  , pde-loss 7.2914e-16, initc-loss 4.6329e+04                    bc_loss 8.3034e+06\n",
      "Epoch 9120, Training-Loss 1.2440e+04, Data-loss 1.1600e+04                  , pde-loss 7.7201e-16, initc-loss 4.6101e+04                    bc_loss 8.3468e+06\n",
      "Epoch 9130, Training-Loss 1.4186e+04, Data-loss 1.3342e+04                  , pde-loss 6.4393e-16, initc-loss 4.5874e+04                    bc_loss 8.3901e+06\n",
      "Epoch 9140, Training-Loss 1.2648e+04, Data-loss 1.1800e+04                  , pde-loss 6.9832e-16, initc-loss 4.5646e+04                    bc_loss 8.4338e+06\n",
      "Epoch 9150, Training-Loss 1.3283e+04, Data-loss 1.2431e+04                  , pde-loss 7.2956e-16, initc-loss 4.5418e+04                    bc_loss 8.4778e+06\n",
      "Epoch 9160, Training-Loss 1.2993e+04, Data-loss 1.2136e+04                  , pde-loss 8.7476e-16, initc-loss 4.5188e+04                    bc_loss 8.5222e+06\n",
      "Epoch 9170, Training-Loss 1.2039e+04, Data-loss 1.1178e+04                  , pde-loss 7.7464e-16, initc-loss 4.4961e+04                    bc_loss 8.5664e+06\n",
      "Epoch 9180, Training-Loss 1.1583e+04, Data-loss 1.0717e+04                  , pde-loss 1.0123e-15, initc-loss 4.4737e+04                    bc_loss 8.6102e+06\n",
      "Epoch 9190, Training-Loss 1.1316e+04, Data-loss 1.0446e+04                  , pde-loss 8.6092e-16, initc-loss 4.4516e+04                    bc_loss 8.6538e+06\n",
      "Epoch 9200, Training-Loss 1.1481e+04, Data-loss 1.0607e+04                  , pde-loss 1.6256e-15, initc-loss 4.4297e+04                    bc_loss 8.6972e+06\n",
      "Epoch 9210, Training-Loss 1.3643e+04, Data-loss 1.2765e+04                  , pde-loss 6.2459e-16, initc-loss 4.4077e+04                    bc_loss 8.7407e+06\n",
      "Epoch 9220, Training-Loss 1.2086e+04, Data-loss 1.1203e+04                  , pde-loss 7.7132e-16, initc-loss 4.3859e+04                    bc_loss 8.7844e+06\n",
      "Epoch 9230, Training-Loss 1.1136e+04, Data-loss 1.0249e+04                  , pde-loss 1.2847e-15, initc-loss 4.3640e+04                    bc_loss 8.8283e+06\n",
      "Epoch 9240, Training-Loss 1.2263e+04, Data-loss 1.1371e+04                  , pde-loss 6.7711e-16, initc-loss 4.3424e+04                    bc_loss 8.8718e+06\n",
      "Epoch 9250, Training-Loss 1.1590e+04, Data-loss 1.0695e+04                  , pde-loss 8.1737e-16, initc-loss 4.3209e+04                    bc_loss 8.9154e+06\n",
      "Epoch 9260, Training-Loss 1.1952e+04, Data-loss 1.1051e+04                  , pde-loss 7.9224e-16, initc-loss 4.2995e+04                    bc_loss 8.9590e+06\n",
      "Epoch 9270, Training-Loss 1.3137e+04, Data-loss 1.2233e+04                  , pde-loss 4.2790e-16, initc-loss 4.2780e+04                    bc_loss 9.0029e+06\n",
      "Epoch 9280, Training-Loss 1.1517e+04, Data-loss 1.0608e+04                  , pde-loss 5.4270e-16, initc-loss 4.2567e+04                    bc_loss 9.0468e+06\n",
      "Epoch 9290, Training-Loss 1.0825e+04, Data-loss 9.9114e+03                  , pde-loss 4.0077e-16, initc-loss 4.2357e+04                    bc_loss 9.0902e+06\n",
      "Epoch 9300, Training-Loss 1.1640e+04, Data-loss 1.0722e+04                  , pde-loss 6.7298e-16, initc-loss 4.2148e+04                    bc_loss 9.1337e+06\n",
      "Epoch 9310, Training-Loss 1.1518e+04, Data-loss 1.0596e+04                  , pde-loss 3.1929e-16, initc-loss 4.1938e+04                    bc_loss 9.1775e+06\n",
      "Epoch 9320, Training-Loss 1.0386e+04, Data-loss 9.4600e+03                  , pde-loss 1.0542e-15, initc-loss 4.1728e+04                    bc_loss 9.2213e+06\n",
      "Epoch 9330, Training-Loss 1.1135e+04, Data-loss 1.0204e+04                  , pde-loss 6.7552e-16, initc-loss 4.1521e+04                    bc_loss 9.2651e+06\n",
      "Epoch 9340, Training-Loss 1.0818e+04, Data-loss 9.8829e+03                  , pde-loss 3.9089e-16, initc-loss 4.1313e+04                    bc_loss 9.3091e+06\n",
      "Epoch 9350, Training-Loss 1.2263e+04, Data-loss 1.1324e+04                  , pde-loss 3.9839e-16, initc-loss 4.1107e+04                    bc_loss 9.3529e+06\n",
      "Epoch 9360, Training-Loss 1.0629e+04, Data-loss 9.6855e+03                  , pde-loss 2.2179e-16, initc-loss 4.0901e+04                    bc_loss 9.3970e+06\n",
      "Epoch 9370, Training-Loss 1.1231e+04, Data-loss 1.0283e+04                  , pde-loss 3.9364e-16, initc-loss 4.0697e+04                    bc_loss 9.4408e+06\n",
      "Epoch 9380, Training-Loss 1.0526e+04, Data-loss 9.5733e+03                  , pde-loss 6.5186e-16, initc-loss 4.0494e+04                    bc_loss 9.4846e+06\n",
      "Epoch 9390, Training-Loss 9.7875e+03, Data-loss 8.8306e+03                  , pde-loss 2.9505e-16, initc-loss 4.0292e+04                    bc_loss 9.5285e+06\n",
      "Epoch 9400, Training-Loss 9.7620e+03, Data-loss 8.8008e+03                  , pde-loss 3.8874e-16, initc-loss 4.0092e+04                    bc_loss 9.5720e+06\n",
      "Epoch 9410, Training-Loss 1.0184e+04, Data-loss 9.2181e+03                  , pde-loss 2.5671e-16, initc-loss 3.9892e+04                    bc_loss 9.6160e+06\n",
      "Epoch 9420, Training-Loss 1.0495e+04, Data-loss 9.5246e+03                  , pde-loss 1.1450e-16, initc-loss 3.9690e+04                    bc_loss 9.6603e+06\n",
      "Epoch 9430, Training-Loss 1.0403e+04, Data-loss 9.4288e+03                  , pde-loss 1.1220e-16, initc-loss 3.9489e+04                    bc_loss 9.7048e+06\n",
      "Epoch 9440, Training-Loss 1.0206e+04, Data-loss 9.2270e+03                  , pde-loss 1.4399e-15, initc-loss 3.9291e+04                    bc_loss 9.7488e+06\n",
      "Epoch 9450, Training-Loss 1.0116e+04, Data-loss 9.1328e+03                  , pde-loss 9.8729e-17, initc-loss 3.9095e+04                    bc_loss 9.7926e+06\n",
      "Epoch 9460, Training-Loss 9.6338e+03, Data-loss 8.6462e+03                  , pde-loss 8.8049e-16, initc-loss 3.8899e+04                    bc_loss 9.8364e+06\n",
      "Epoch 9470, Training-Loss 8.1386e+03, Data-loss 7.1467e+03                  , pde-loss 7.5730e-17, initc-loss 3.8704e+04                    bc_loss 9.8804e+06\n",
      "Epoch 9480, Training-Loss 9.0577e+03, Data-loss 8.0615e+03                  , pde-loss 1.8505e-16, initc-loss 3.8512e+04                    bc_loss 9.9239e+06\n",
      "Epoch 9490, Training-Loss 9.3847e+03, Data-loss 8.3841e+03                  , pde-loss 1.0602e-16, initc-loss 3.8320e+04                    bc_loss 9.9676e+06\n",
      "Epoch 9500, Training-Loss 9.6971e+03, Data-loss 8.6922e+03                  , pde-loss 2.9155e-16, initc-loss 3.8128e+04                    bc_loss 1.0012e+07\n",
      "Epoch 9510, Training-Loss 1.0981e+04, Data-loss 9.9718e+03                  , pde-loss 6.8466e-16, initc-loss 3.7936e+04                    bc_loss 1.0056e+07\n",
      "Epoch 9520, Training-Loss 9.5538e+03, Data-loss 8.5401e+03                  , pde-loss 7.4226e-17, initc-loss 3.7745e+04                    bc_loss 1.0100e+07\n",
      "Epoch 9530, Training-Loss 9.6829e+03, Data-loss 8.6648e+03                  , pde-loss 7.3452e-16, initc-loss 3.7556e+04                    bc_loss 1.0144e+07\n",
      "Epoch 9540, Training-Loss 9.5580e+03, Data-loss 8.5355e+03                  , pde-loss 5.5067e-17, initc-loss 3.7367e+04                    bc_loss 1.0188e+07\n",
      "Epoch 9550, Training-Loss 8.0747e+03, Data-loss 7.0479e+03                  , pde-loss 1.3623e-16, initc-loss 3.7180e+04                    bc_loss 1.0231e+07\n",
      "Epoch 9560, Training-Loss 8.1475e+03, Data-loss 7.1163e+03                  , pde-loss 1.2575e-15, initc-loss 3.6995e+04                    bc_loss 1.0275e+07\n",
      "Epoch 9570, Training-Loss 9.2009e+03, Data-loss 8.1654e+03                  , pde-loss 8.3732e-17, initc-loss 3.6812e+04                    bc_loss 1.0318e+07\n",
      "Epoch 9580, Training-Loss 8.6623e+03, Data-loss 7.6225e+03                  , pde-loss 9.1891e-16, initc-loss 3.6628e+04                    bc_loss 1.0362e+07\n",
      "Epoch 9590, Training-Loss 9.0142e+03, Data-loss 7.9699e+03                  , pde-loss 9.2028e-17, initc-loss 3.6444e+04                    bc_loss 1.0406e+07\n",
      "Epoch 9600, Training-Loss 8.3082e+03, Data-loss 7.2597e+03                  , pde-loss 4.1881e-16, initc-loss 3.6262e+04                    bc_loss 1.0449e+07\n",
      "Epoch 9610, Training-Loss 8.8099e+03, Data-loss 7.7571e+03                  , pde-loss 7.8345e-16, initc-loss 3.6083e+04                    bc_loss 1.0492e+07\n",
      "Epoch 9620, Training-Loss 8.2135e+03, Data-loss 7.1564e+03                  , pde-loss 9.2395e-16, initc-loss 3.5903e+04                    bc_loss 1.0536e+07\n",
      "Epoch 9630, Training-Loss 8.6544e+03, Data-loss 7.5929e+03                  , pde-loss 5.0863e-17, initc-loss 3.5723e+04                    bc_loss 1.0579e+07\n",
      "Epoch 9640, Training-Loss 8.0574e+03, Data-loss 6.9915e+03                  , pde-loss 9.1667e-16, initc-loss 3.5544e+04                    bc_loss 1.0623e+07\n",
      "Epoch 9650, Training-Loss 7.8386e+03, Data-loss 6.7684e+03                  , pde-loss 7.2684e-16, initc-loss 3.5366e+04                    bc_loss 1.0667e+07\n",
      "Epoch 9660, Training-Loss 8.0994e+03, Data-loss 7.0249e+03                  , pde-loss 3.9169e-16, initc-loss 3.5191e+04                    bc_loss 1.0710e+07\n",
      "Epoch 9670, Training-Loss 8.4182e+03, Data-loss 7.3394e+03                  , pde-loss 4.3985e-17, initc-loss 3.5016e+04                    bc_loss 1.0753e+07\n",
      "Epoch 9680, Training-Loss 9.6071e+03, Data-loss 8.5240e+03                  , pde-loss 3.9044e-17, initc-loss 3.4844e+04                    bc_loss 1.0796e+07\n",
      "Epoch 9690, Training-Loss 7.6373e+03, Data-loss 6.5499e+03                  , pde-loss 6.7639e-16, initc-loss 3.4671e+04                    bc_loss 1.0839e+07\n",
      "Epoch 9700, Training-Loss 9.0399e+03, Data-loss 7.9482e+03                  , pde-loss 2.0837e-16, initc-loss 3.4501e+04                    bc_loss 1.0882e+07\n",
      "Epoch 9710, Training-Loss 7.9154e+03, Data-loss 6.8195e+03                  , pde-loss 3.3746e-17, initc-loss 3.4330e+04                    bc_loss 1.0925e+07\n",
      "Epoch 9720, Training-Loss 9.2099e+03, Data-loss 8.1097e+03                  , pde-loss 4.3710e-17, initc-loss 3.4160e+04                    bc_loss 1.0968e+07\n",
      "Epoch 9730, Training-Loss 7.7367e+03, Data-loss 6.6322e+03                  , pde-loss 2.9845e-17, initc-loss 3.3990e+04                    bc_loss 1.1011e+07\n",
      "Epoch 9740, Training-Loss 8.3998e+03, Data-loss 7.2910e+03                  , pde-loss 2.1864e-17, initc-loss 3.3821e+04                    bc_loss 1.1054e+07\n",
      "Epoch 9750, Training-Loss 6.5882e+03, Data-loss 5.4751e+03                  , pde-loss 6.3748e-16, initc-loss 3.3653e+04                    bc_loss 1.1097e+07\n",
      "Epoch 9760, Training-Loss 7.8779e+03, Data-loss 6.7606e+03                  , pde-loss 2.7911e-16, initc-loss 3.3488e+04                    bc_loss 1.1139e+07\n",
      "Epoch 9770, Training-Loss 8.2645e+03, Data-loss 7.1430e+03                  , pde-loss 2.5706e-16, initc-loss 3.3323e+04                    bc_loss 1.1182e+07\n",
      "Epoch 9780, Training-Loss 9.0823e+03, Data-loss 7.9565e+03                  , pde-loss 6.5116e-17, initc-loss 3.3157e+04                    bc_loss 1.1225e+07\n",
      "Epoch 9790, Training-Loss 8.5795e+03, Data-loss 7.4493e+03                  , pde-loss 6.4221e-16, initc-loss 3.2989e+04                    bc_loss 1.1269e+07\n",
      "Epoch 9800, Training-Loss 7.9247e+03, Data-loss 6.7901e+03                  , pde-loss 5.5205e-16, initc-loss 3.2824e+04                    bc_loss 1.1312e+07\n",
      "Epoch 9810, Training-Loss 6.8338e+03, Data-loss 5.6950e+03                  , pde-loss 9.3916e-17, initc-loss 3.2659e+04                    bc_loss 1.1356e+07\n",
      "Epoch 9820, Training-Loss 7.7522e+03, Data-loss 6.6092e+03                  , pde-loss 5.7690e-17, initc-loss 3.2498e+04                    bc_loss 1.1398e+07\n",
      "Epoch 9830, Training-Loss 8.6992e+03, Data-loss 7.5518e+03                  , pde-loss 4.0948e-17, initc-loss 3.2335e+04                    bc_loss 1.1441e+07\n",
      "Epoch 9840, Training-Loss 7.6971e+03, Data-loss 6.5455e+03                  , pde-loss 6.9524e-17, initc-loss 3.2174e+04                    bc_loss 1.1484e+07\n",
      "Epoch 9850, Training-Loss 6.2887e+03, Data-loss 5.1328e+03                  , pde-loss 1.5473e-16, initc-loss 3.2015e+04                    bc_loss 1.1527e+07\n",
      "Epoch 9860, Training-Loss 6.9615e+03, Data-loss 5.8014e+03                  , pde-loss 5.7225e-16, initc-loss 3.1859e+04                    bc_loss 1.1569e+07\n",
      "Epoch 9870, Training-Loss 6.4683e+03, Data-loss 5.3040e+03                  , pde-loss 6.4511e-17, initc-loss 3.1704e+04                    bc_loss 1.1611e+07\n",
      "Epoch 9880, Training-Loss 7.5881e+03, Data-loss 6.4197e+03                  , pde-loss 1.9792e-16, initc-loss 3.1549e+04                    bc_loss 1.1653e+07\n",
      "Epoch 9890, Training-Loss 7.5133e+03, Data-loss 6.3406e+03                  , pde-loss 4.3045e-17, initc-loss 3.1392e+04                    bc_loss 1.1696e+07\n",
      "Epoch 9900, Training-Loss 6.9005e+03, Data-loss 5.7236e+03                  , pde-loss 5.0156e-17, initc-loss 3.1237e+04                    bc_loss 1.1738e+07\n",
      "Epoch 9910, Training-Loss 6.4133e+03, Data-loss 5.2321e+03                  , pde-loss 1.5775e-17, initc-loss 3.1083e+04                    bc_loss 1.1780e+07\n",
      "Epoch 9920, Training-Loss 7.5947e+03, Data-loss 6.4094e+03                  , pde-loss 7.4156e-17, initc-loss 3.0930e+04                    bc_loss 1.1822e+07\n",
      "Epoch 9930, Training-Loss 6.9899e+03, Data-loss 5.8004e+03                  , pde-loss 2.6839e-16, initc-loss 3.0779e+04                    bc_loss 1.1864e+07\n",
      "Epoch 9940, Training-Loss 6.6319e+03, Data-loss 5.4382e+03                  , pde-loss 9.7301e-16, initc-loss 3.0627e+04                    bc_loss 1.1907e+07\n",
      "Epoch 9950, Training-Loss 7.0108e+03, Data-loss 5.8129e+03                  , pde-loss 4.2965e-17, initc-loss 3.0476e+04                    bc_loss 1.1949e+07\n",
      "Epoch 9960, Training-Loss 7.2416e+03, Data-loss 6.0395e+03                  , pde-loss 5.3664e-17, initc-loss 3.0327e+04                    bc_loss 1.1991e+07\n",
      "Epoch 9970, Training-Loss 6.3633e+03, Data-loss 5.1571e+03                  , pde-loss 4.3505e-16, initc-loss 3.0180e+04                    bc_loss 1.2032e+07\n",
      "Epoch 9980, Training-Loss 5.7532e+03, Data-loss 4.5429e+03                  , pde-loss 1.5090e-16, initc-loss 3.0035e+04                    bc_loss 1.2073e+07\n",
      "Epoch 9990, Training-Loss 6.3186e+03, Data-loss 5.1042e+03                  , pde-loss 7.0691e-17, initc-loss 2.9893e+04                    bc_loss 1.2113e+07\n",
      "Epoch 10000, Training-Loss 7.0631e+03, Data-loss 5.8447e+03                  , pde-loss 4.1406e-17, initc-loss 2.9752e+04                    bc_loss 1.2154e+07\n",
      "Epoch 10010, Training-Loss 6.3126e+03, Data-loss 5.0901e+03                  , pde-loss 4.4235e-17, initc-loss 2.9606e+04                    bc_loss 1.2196e+07\n",
      "Epoch 10020, Training-Loss 6.9654e+03, Data-loss 5.7387e+03                  , pde-loss 1.6774e-15, initc-loss 2.9461e+04                    bc_loss 1.2237e+07\n",
      "Epoch 10030, Training-Loss 6.8533e+03, Data-loss 5.6225e+03                  , pde-loss 6.3473e-17, initc-loss 2.9317e+04                    bc_loss 1.2279e+07\n",
      "Epoch 10040, Training-Loss 6.7055e+03, Data-loss 5.4705e+03                  , pde-loss 1.2231e-16, initc-loss 2.9173e+04                    bc_loss 1.2321e+07\n",
      "Epoch 10050, Training-Loss 5.6382e+03, Data-loss 4.3991e+03                  , pde-loss 3.5982e-17, initc-loss 2.9031e+04                    bc_loss 1.2362e+07\n",
      "Epoch 10060, Training-Loss 6.6538e+03, Data-loss 5.4106e+03                  , pde-loss 3.5941e-16, initc-loss 2.8889e+04                    bc_loss 1.2403e+07\n",
      "Epoch 10070, Training-Loss 6.4220e+03, Data-loss 5.1747e+03                  , pde-loss 8.1434e-16, initc-loss 2.8750e+04                    bc_loss 1.2444e+07\n",
      "Epoch 10080, Training-Loss 5.8491e+03, Data-loss 4.5978e+03                  , pde-loss 4.3094e-16, initc-loss 2.8612e+04                    bc_loss 1.2485e+07\n",
      "Epoch 10090, Training-Loss 6.1612e+03, Data-loss 4.9058e+03                  , pde-loss 1.0631e-16, initc-loss 2.8476e+04                    bc_loss 1.2525e+07\n",
      "Epoch 10100, Training-Loss 6.4828e+03, Data-loss 5.2233e+03                  , pde-loss 6.7226e-17, initc-loss 2.8336e+04                    bc_loss 1.2567e+07\n",
      "Epoch 10110, Training-Loss 5.7265e+03, Data-loss 4.4628e+03                  , pde-loss 7.1521e-17, initc-loss 2.8197e+04                    bc_loss 1.2608e+07\n",
      "Epoch 10120, Training-Loss 7.1937e+03, Data-loss 5.9260e+03                  , pde-loss 7.1721e-16, initc-loss 2.8061e+04                    bc_loss 1.2649e+07\n",
      "Epoch 10130, Training-Loss 5.6693e+03, Data-loss 4.3975e+03                  , pde-loss 1.1868e-16, initc-loss 2.7925e+04                    bc_loss 1.2690e+07\n",
      "Epoch 10140, Training-Loss 6.4443e+03, Data-loss 5.1684e+03                  , pde-loss 7.7807e-17, initc-loss 2.7789e+04                    bc_loss 1.2731e+07\n",
      "Epoch 10150, Training-Loss 6.9709e+03, Data-loss 5.6910e+03                  , pde-loss 1.5388e-15, initc-loss 2.7654e+04                    bc_loss 1.2772e+07\n",
      "Epoch 10160, Training-Loss 6.7928e+03, Data-loss 5.5087e+03                  , pde-loss 2.9959e-16, initc-loss 2.7518e+04                    bc_loss 1.2813e+07\n",
      "Epoch 10170, Training-Loss 6.1622e+03, Data-loss 4.8740e+03                  , pde-loss 1.2840e-16, initc-loss 2.7385e+04                    bc_loss 1.2854e+07\n",
      "Epoch 10180, Training-Loss 5.4935e+03, Data-loss 4.2013e+03                  , pde-loss 1.3796e-15, initc-loss 2.7254e+04                    bc_loss 1.2894e+07\n",
      "Epoch 10190, Training-Loss 5.0407e+03, Data-loss 3.7446e+03                  , pde-loss 1.8354e-16, initc-loss 2.7124e+04                    bc_loss 1.2934e+07\n",
      "Epoch 10200, Training-Loss 5.5501e+03, Data-loss 4.2500e+03                  , pde-loss 1.2712e-16, initc-loss 2.6997e+04                    bc_loss 1.2974e+07\n",
      "Epoch 10210, Training-Loss 6.0671e+03, Data-loss 4.7631e+03                  , pde-loss 8.4807e-16, initc-loss 2.6870e+04                    bc_loss 1.3013e+07\n",
      "Epoch 10220, Training-Loss 5.4958e+03, Data-loss 4.1879e+03                  , pde-loss 8.1145e-16, initc-loss 2.6744e+04                    bc_loss 1.3052e+07\n",
      "Epoch 10230, Training-Loss 5.5146e+03, Data-loss 4.2028e+03                  , pde-loss 4.2152e-16, initc-loss 2.6617e+04                    bc_loss 1.3092e+07\n",
      "Epoch 10240, Training-Loss 5.8150e+03, Data-loss 4.4992e+03                  , pde-loss 2.5813e-16, initc-loss 2.6492e+04                    bc_loss 1.3132e+07\n",
      "Epoch 10250, Training-Loss 5.4419e+03, Data-loss 4.1223e+03                  , pde-loss 4.8808e-16, initc-loss 2.6369e+04                    bc_loss 1.3170e+07\n",
      "Epoch 10260, Training-Loss 5.4583e+03, Data-loss 4.1349e+03                  , pde-loss 1.2010e-15, initc-loss 2.6251e+04                    bc_loss 1.3208e+07\n",
      "Epoch 10270, Training-Loss 4.9147e+03, Data-loss 3.5875e+03                  , pde-loss 1.1464e-15, initc-loss 2.6130e+04                    bc_loss 1.3246e+07\n",
      "Epoch 10280, Training-Loss 5.4526e+03, Data-loss 4.1215e+03                  , pde-loss 3.6035e-16, initc-loss 2.6006e+04                    bc_loss 1.3286e+07\n",
      "Epoch 10290, Training-Loss 5.4194e+03, Data-loss 4.0844e+03                  , pde-loss 1.0853e-15, initc-loss 2.5884e+04                    bc_loss 1.3325e+07\n",
      "Epoch 10300, Training-Loss 5.8934e+03, Data-loss 4.5544e+03                  , pde-loss 2.6048e-16, initc-loss 2.5763e+04                    bc_loss 1.3364e+07\n",
      "Epoch 10310, Training-Loss 5.3210e+03, Data-loss 3.9781e+03                  , pde-loss 2.2161e-16, initc-loss 2.5642e+04                    bc_loss 1.3403e+07\n",
      "Epoch 10320, Training-Loss 5.1238e+03, Data-loss 3.7771e+03                  , pde-loss 2.2350e-16, initc-loss 2.5523e+04                    bc_loss 1.3441e+07\n",
      "Epoch 10330, Training-Loss 5.2158e+03, Data-loss 3.8653e+03                  , pde-loss 3.7001e-16, initc-loss 2.5406e+04                    bc_loss 1.3479e+07\n",
      "Epoch 10340, Training-Loss 5.6499e+03, Data-loss 4.2956e+03                  , pde-loss 5.8293e-16, initc-loss 2.5287e+04                    bc_loss 1.3518e+07\n",
      "Epoch 10350, Training-Loss 5.8719e+03, Data-loss 4.5136e+03                  , pde-loss 1.7775e-16, initc-loss 2.5167e+04                    bc_loss 1.3557e+07\n",
      "Epoch 10360, Training-Loss 4.7999e+03, Data-loss 3.4378e+03                  , pde-loss 3.3221e-16, initc-loss 2.5048e+04                    bc_loss 1.3596e+07\n",
      "Epoch 10370, Training-Loss 5.5059e+03, Data-loss 4.1400e+03                  , pde-loss 1.0253e-15, initc-loss 2.4933e+04                    bc_loss 1.3634e+07\n",
      "Epoch 10380, Training-Loss 5.2625e+03, Data-loss 3.8929e+03                  , pde-loss 7.0884e-16, initc-loss 2.4820e+04                    bc_loss 1.3672e+07\n",
      "Epoch 10390, Training-Loss 4.8197e+03, Data-loss 3.4463e+03                  , pde-loss 1.2703e-15, initc-loss 2.4709e+04                    bc_loss 1.3709e+07\n",
      "Epoch 10400, Training-Loss 4.6766e+03, Data-loss 3.2994e+03                  , pde-loss 7.8903e-16, initc-loss 2.4594e+04                    bc_loss 1.3747e+07\n",
      "Epoch 10410, Training-Loss 4.7569e+03, Data-loss 3.3760e+03                  , pde-loss 2.0035e-15, initc-loss 2.4482e+04                    bc_loss 1.3785e+07\n",
      "Epoch 10420, Training-Loss 5.5034e+03, Data-loss 4.1188e+03                  , pde-loss 7.6546e-16, initc-loss 2.4372e+04                    bc_loss 1.3822e+07\n",
      "Epoch 10430, Training-Loss 4.6569e+03, Data-loss 3.2686e+03                  , pde-loss 2.3383e-15, initc-loss 2.4261e+04                    bc_loss 1.3859e+07\n",
      "Epoch 10440, Training-Loss 4.6008e+03, Data-loss 3.2087e+03                  , pde-loss 3.2182e-15, initc-loss 2.4152e+04                    bc_loss 1.3896e+07\n",
      "Epoch 10450, Training-Loss 4.7327e+03, Data-loss 3.3370e+03                  , pde-loss 2.0042e-15, initc-loss 2.4044e+04                    bc_loss 1.3933e+07\n",
      "Epoch 10460, Training-Loss 4.6542e+03, Data-loss 3.2548e+03                  , pde-loss 2.0844e-15, initc-loss 2.3935e+04                    bc_loss 1.3970e+07\n",
      "Epoch 10470, Training-Loss 4.1393e+03, Data-loss 2.7362e+03                  , pde-loss 1.5870e-15, initc-loss 2.3827e+04                    bc_loss 1.4007e+07\n",
      "Epoch 10480, Training-Loss 4.7370e+03, Data-loss 3.3302e+03                  , pde-loss 2.1122e-15, initc-loss 2.3720e+04                    bc_loss 1.4044e+07\n",
      "Epoch 10490, Training-Loss 5.5485e+03, Data-loss 4.1381e+03                  , pde-loss 1.8979e-15, initc-loss 2.3613e+04                    bc_loss 1.4080e+07\n",
      "Epoch 10500, Training-Loss 5.3696e+03, Data-loss 3.9555e+03                  , pde-loss 3.0660e-15, initc-loss 2.3507e+04                    bc_loss 1.4117e+07\n",
      "Epoch 10510, Training-Loss 4.4102e+03, Data-loss 2.9926e+03                  , pde-loss 1.2096e-15, initc-loss 2.3404e+04                    bc_loss 1.4153e+07\n",
      "Epoch 10520, Training-Loss 4.3552e+03, Data-loss 2.9340e+03                  , pde-loss 1.8373e-15, initc-loss 2.3301e+04                    bc_loss 1.4189e+07\n",
      "Epoch 10530, Training-Loss 5.1098e+03, Data-loss 3.6849e+03                  , pde-loss 4.0398e-15, initc-loss 2.3196e+04                    bc_loss 1.4225e+07\n",
      "Epoch 10540, Training-Loss 4.2635e+03, Data-loss 2.8349e+03                  , pde-loss 2.6951e-15, initc-loss 2.3090e+04                    bc_loss 1.4263e+07\n",
      "Epoch 10550, Training-Loss 4.8522e+03, Data-loss 3.4200e+03                  , pde-loss 3.2268e-15, initc-loss 2.2987e+04                    bc_loss 1.4299e+07\n",
      "Epoch 10560, Training-Loss 4.4951e+03, Data-loss 3.0593e+03                  , pde-loss 3.0960e-15, initc-loss 2.2885e+04                    bc_loss 1.4335e+07\n",
      "Epoch 10570, Training-Loss 4.5726e+03, Data-loss 3.1333e+03                  , pde-loss 2.7139e-15, initc-loss 2.2784e+04                    bc_loss 1.4371e+07\n",
      "Epoch 10580, Training-Loss 5.2076e+03, Data-loss 3.7647e+03                  , pde-loss 2.1124e-15, initc-loss 2.2684e+04                    bc_loss 1.4406e+07\n",
      "Epoch 10590, Training-Loss 4.8135e+03, Data-loss 3.3670e+03                  , pde-loss 3.7773e-15, initc-loss 2.2582e+04                    bc_loss 1.4443e+07\n",
      "Epoch 10600, Training-Loss 4.6166e+03, Data-loss 3.1665e+03                  , pde-loss 4.3764e-15, initc-loss 2.2481e+04                    bc_loss 1.4479e+07\n",
      "Epoch 10610, Training-Loss 4.3850e+03, Data-loss 2.9313e+03                  , pde-loss 5.6302e-15, initc-loss 2.2382e+04                    bc_loss 1.4514e+07\n",
      "Epoch 10620, Training-Loss 4.7554e+03, Data-loss 3.2981e+03                  , pde-loss 9.1685e-15, initc-loss 2.2284e+04                    bc_loss 1.4550e+07\n",
      "Epoch 10630, Training-Loss 4.1272e+03, Data-loss 2.6665e+03                  , pde-loss 7.2806e-15, initc-loss 2.2188e+04                    bc_loss 1.4585e+07\n",
      "Epoch 10640, Training-Loss 4.4903e+03, Data-loss 3.0262e+03                  , pde-loss 8.2450e-15, initc-loss 2.2094e+04                    bc_loss 1.4619e+07\n",
      "Epoch 10650, Training-Loss 4.0364e+03, Data-loss 2.5688e+03                  , pde-loss 9.9370e-15, initc-loss 2.1999e+04                    bc_loss 1.4653e+07\n",
      "Epoch 10660, Training-Loss 3.5259e+03, Data-loss 2.0550e+03                  , pde-loss 1.2297e-14, initc-loss 2.1905e+04                    bc_loss 1.4688e+07\n",
      "Epoch 10670, Training-Loss 4.3487e+03, Data-loss 2.8743e+03                  , pde-loss 8.0517e-15, initc-loss 2.1812e+04                    bc_loss 1.4722e+07\n",
      "Epoch 10680, Training-Loss 4.9171e+03, Data-loss 3.4393e+03                  , pde-loss 1.5743e-14, initc-loss 2.1718e+04                    bc_loss 1.4757e+07\n",
      "Epoch 10690, Training-Loss 4.6403e+03, Data-loss 3.1591e+03                  , pde-loss 9.9822e-15, initc-loss 2.1625e+04                    bc_loss 1.4791e+07\n",
      "Epoch 10700, Training-Loss 4.1567e+03, Data-loss 2.6721e+03                  , pde-loss 1.9456e-14, initc-loss 2.1535e+04                    bc_loss 1.4824e+07\n",
      "Epoch 10710, Training-Loss 4.3464e+03, Data-loss 2.8585e+03                  , pde-loss 2.3184e-14, initc-loss 2.1446e+04                    bc_loss 1.4857e+07\n",
      "Epoch 10720, Training-Loss 4.2572e+03, Data-loss 2.7660e+03                  , pde-loss 1.5620e-14, initc-loss 2.1356e+04                    bc_loss 1.4891e+07\n",
      "Epoch 10730, Training-Loss 4.3393e+03, Data-loss 2.8448e+03                  , pde-loss 2.2229e-14, initc-loss 2.1267e+04                    bc_loss 1.4924e+07\n",
      "Epoch 10740, Training-Loss 4.9135e+03, Data-loss 3.4156e+03                  , pde-loss 2.3552e-14, initc-loss 2.1179e+04                    bc_loss 1.4957e+07\n",
      "Epoch 10750, Training-Loss 4.4674e+03, Data-loss 2.9663e+03                  , pde-loss 2.5508e-14, initc-loss 2.1092e+04                    bc_loss 1.4990e+07\n",
      "Epoch 10760, Training-Loss 4.1912e+03, Data-loss 2.6868e+03                  , pde-loss 2.5743e-14, initc-loss 2.1004e+04                    bc_loss 1.5023e+07\n",
      "Epoch 10770, Training-Loss 4.6973e+03, Data-loss 3.1897e+03                  , pde-loss 2.3332e-14, initc-loss 2.0917e+04                    bc_loss 1.5056e+07\n",
      "Epoch 10780, Training-Loss 3.9269e+03, Data-loss 2.4159e+03                  , pde-loss 3.5803e-14, initc-loss 2.0831e+04                    bc_loss 1.5089e+07\n",
      "Epoch 10790, Training-Loss 3.9812e+03, Data-loss 2.4669e+03                  , pde-loss 3.6081e-14, initc-loss 2.0745e+04                    bc_loss 1.5122e+07\n",
      "Epoch 10800, Training-Loss 3.8093e+03, Data-loss 2.2918e+03                  , pde-loss 4.3484e-14, initc-loss 2.0660e+04                    bc_loss 1.5154e+07\n",
      "Epoch 10810, Training-Loss 3.6870e+03, Data-loss 2.1663e+03                  , pde-loss 4.1454e-14, initc-loss 2.0577e+04                    bc_loss 1.5186e+07\n",
      "Epoch 10820, Training-Loss 4.3159e+03, Data-loss 2.7921e+03                  , pde-loss 2.7872e-14, initc-loss 2.0493e+04                    bc_loss 1.5218e+07\n",
      "Epoch 10830, Training-Loss 4.2760e+03, Data-loss 2.7489e+03                  , pde-loss 3.9060e-14, initc-loss 2.0408e+04                    bc_loss 1.5251e+07\n",
      "Epoch 10840, Training-Loss 4.0199e+03, Data-loss 2.4895e+03                  , pde-loss 4.0245e-14, initc-loss 2.0324e+04                    bc_loss 1.5284e+07\n",
      "Epoch 10850, Training-Loss 3.8834e+03, Data-loss 2.3500e+03                  , pde-loss 4.4964e-14, initc-loss 2.0244e+04                    bc_loss 1.5315e+07\n",
      "Epoch 10860, Training-Loss 4.1116e+03, Data-loss 2.5751e+03                  , pde-loss 4.3397e-14, initc-loss 2.0165e+04                    bc_loss 1.5345e+07\n",
      "Epoch 10870, Training-Loss 4.1554e+03, Data-loss 2.6158e+03                  , pde-loss 4.4712e-14, initc-loss 2.0088e+04                    bc_loss 1.5376e+07\n",
      "Epoch 10880, Training-Loss 3.5709e+03, Data-loss 2.0284e+03                  , pde-loss 5.3506e-14, initc-loss 2.0012e+04                    bc_loss 1.5405e+07\n",
      "Epoch 10890, Training-Loss 4.0605e+03, Data-loss 2.5150e+03                  , pde-loss 5.0168e-14, initc-loss 1.9936e+04                    bc_loss 1.5435e+07\n",
      "Epoch 10900, Training-Loss 2.9895e+03, Data-loss 1.4410e+03                  , pde-loss 5.6481e-14, initc-loss 1.9858e+04                    bc_loss 1.5466e+07\n",
      "Epoch 10910, Training-Loss 4.1511e+03, Data-loss 2.5995e+03                  , pde-loss 6.1197e-14, initc-loss 1.9782e+04                    bc_loss 1.5496e+07\n",
      "Epoch 10920, Training-Loss 3.8140e+03, Data-loss 2.2594e+03                  , pde-loss 6.4047e-14, initc-loss 1.9707e+04                    bc_loss 1.5526e+07\n",
      "Epoch 10930, Training-Loss 4.6609e+03, Data-loss 3.1035e+03                  , pde-loss 5.5364e-14, initc-loss 1.9635e+04                    bc_loss 1.5554e+07\n",
      "Epoch 10940, Training-Loss 4.3361e+03, Data-loss 2.7759e+03                  , pde-loss 6.0506e-14, initc-loss 1.9562e+04                    bc_loss 1.5583e+07\n",
      "Epoch 10950, Training-Loss 4.1809e+03, Data-loss 2.6176e+03                  , pde-loss 6.4886e-14, initc-loss 1.9488e+04                    bc_loss 1.5613e+07\n",
      "Epoch 10960, Training-Loss 3.3520e+03, Data-loss 1.7858e+03                  , pde-loss 8.3338e-14, initc-loss 1.9414e+04                    bc_loss 1.5643e+07\n",
      "Epoch 10970, Training-Loss 3.8617e+03, Data-loss 2.2925e+03                  , pde-loss 7.5205e-14, initc-loss 1.9339e+04                    bc_loss 1.5673e+07\n",
      "Epoch 10980, Training-Loss 4.4730e+03, Data-loss 2.9009e+03                  , pde-loss 8.2372e-14, initc-loss 1.9268e+04                    bc_loss 1.5701e+07\n",
      "Epoch 10990, Training-Loss 3.3439e+03, Data-loss 1.7689e+03                  , pde-loss 8.2162e-14, initc-loss 1.9196e+04                    bc_loss 1.5731e+07\n",
      "Epoch 11000, Training-Loss 3.5378e+03, Data-loss 1.9600e+03                  , pde-loss 9.0606e-14, initc-loss 1.9125e+04                    bc_loss 1.5759e+07\n",
      "Epoch 11010, Training-Loss 3.6684e+03, Data-loss 2.0878e+03                  , pde-loss 8.9193e-14, initc-loss 1.9057e+04                    bc_loss 1.5787e+07\n",
      "Epoch 11020, Training-Loss 3.6871e+03, Data-loss 2.1038e+03                  , pde-loss 1.1227e-13, initc-loss 1.8990e+04                    bc_loss 1.5814e+07\n",
      "Epoch 11030, Training-Loss 3.6681e+03, Data-loss 2.0821e+03                  , pde-loss 9.4311e-14, initc-loss 1.8924e+04                    bc_loss 1.5841e+07\n",
      "Epoch 11040, Training-Loss 3.6793e+03, Data-loss 2.0905e+03                  , pde-loss 1.0705e-13, initc-loss 1.8857e+04                    bc_loss 1.5868e+07\n",
      "Epoch 11050, Training-Loss 3.7506e+03, Data-loss 2.1589e+03                  , pde-loss 1.0210e-13, initc-loss 1.8786e+04                    bc_loss 1.5898e+07\n",
      "Epoch 11060, Training-Loss 3.5812e+03, Data-loss 1.9867e+03                  , pde-loss 1.0382e-13, initc-loss 1.8718e+04                    bc_loss 1.5926e+07\n",
      "Epoch 11070, Training-Loss 3.3531e+03, Data-loss 1.7560e+03                  , pde-loss 1.1520e-13, initc-loss 1.8652e+04                    bc_loss 1.5953e+07\n",
      "Epoch 11080, Training-Loss 3.9287e+03, Data-loss 2.3288e+03                  , pde-loss 1.1768e-13, initc-loss 1.8587e+04                    bc_loss 1.5980e+07\n",
      "Epoch 11090, Training-Loss 3.8226e+03, Data-loss 2.2201e+03                  , pde-loss 1.0939e-13, initc-loss 1.8524e+04                    bc_loss 1.6006e+07\n",
      "Epoch 11100, Training-Loss 3.8413e+03, Data-loss 2.2362e+03                  , pde-loss 1.3076e-13, initc-loss 1.8459e+04                    bc_loss 1.6033e+07\n",
      "Epoch 11110, Training-Loss 3.6314e+03, Data-loss 2.0236e+03                  , pde-loss 1.1280e-13, initc-loss 1.8397e+04                    bc_loss 1.6059e+07\n",
      "Epoch 11120, Training-Loss 3.8635e+03, Data-loss 2.2531e+03                  , pde-loss 1.2165e-13, initc-loss 1.8334e+04                    bc_loss 1.6086e+07\n",
      "Epoch 11130, Training-Loss 3.9855e+03, Data-loss 2.3725e+03                  , pde-loss 1.1498e-13, initc-loss 1.8271e+04                    bc_loss 1.6112e+07\n",
      "Epoch 11140, Training-Loss 3.8254e+03, Data-loss 2.2096e+03                  , pde-loss 1.4170e-13, initc-loss 1.8206e+04                    bc_loss 1.6139e+07\n",
      "Epoch 11150, Training-Loss 3.5526e+03, Data-loss 1.9342e+03                  , pde-loss 1.3523e-13, initc-loss 1.8142e+04                    bc_loss 1.6166e+07\n",
      "Epoch 11160, Training-Loss 3.3433e+03, Data-loss 1.7222e+03                  , pde-loss 1.3414e-13, initc-loss 1.8079e+04                    bc_loss 1.6193e+07\n",
      "Epoch 11170, Training-Loss 4.0486e+03, Data-loss 2.4250e+03                  , pde-loss 1.3164e-13, initc-loss 1.8021e+04                    bc_loss 1.6217e+07\n",
      "Epoch 11180, Training-Loss 3.3720e+03, Data-loss 1.7461e+03                  , pde-loss 1.4578e-13, initc-loss 1.7966e+04                    bc_loss 1.6241e+07\n",
      "Epoch 11190, Training-Loss 3.3885e+03, Data-loss 1.7602e+03                  , pde-loss 1.5139e-13, initc-loss 1.7908e+04                    bc_loss 1.6265e+07\n",
      "Epoch 11200, Training-Loss 3.7222e+03, Data-loss 2.0914e+03                  , pde-loss 1.6529e-13, initc-loss 1.7850e+04                    bc_loss 1.6290e+07\n",
      "Epoch 11210, Training-Loss 4.3356e+03, Data-loss 2.7024e+03                  , pde-loss 1.7112e-13, initc-loss 1.7796e+04                    bc_loss 1.6313e+07\n",
      "Epoch 11220, Training-Loss 3.2803e+03, Data-loss 1.6447e+03                  , pde-loss 1.9254e-13, initc-loss 1.7738e+04                    bc_loss 1.6338e+07\n",
      "Epoch 11230, Training-Loss 3.1794e+03, Data-loss 1.5414e+03                  , pde-loss 2.0372e-13, initc-loss 1.7680e+04                    bc_loss 1.6363e+07\n",
      "Epoch 11240, Training-Loss 3.3036e+03, Data-loss 1.6633e+03                  , pde-loss 2.1185e-13, initc-loss 1.7628e+04                    bc_loss 1.6386e+07\n",
      "Epoch 11250, Training-Loss 3.2341e+03, Data-loss 1.5915e+03                  , pde-loss 2.2644e-13, initc-loss 1.7575e+04                    bc_loss 1.6408e+07\n",
      "Epoch 11260, Training-Loss 3.2720e+03, Data-loss 1.6270e+03                  , pde-loss 2.3543e-13, initc-loss 1.7521e+04                    bc_loss 1.6432e+07\n",
      "Epoch 11270, Training-Loss 3.4483e+03, Data-loss 1.8011e+03                  , pde-loss 2.2458e-13, initc-loss 1.7468e+04                    bc_loss 1.6455e+07\n",
      "Epoch 11280, Training-Loss 4.1290e+03, Data-loss 2.4795e+03                  , pde-loss 2.1847e-13, initc-loss 1.7414e+04                    bc_loss 1.6478e+07\n",
      "Epoch 11290, Training-Loss 3.4198e+03, Data-loss 1.7678e+03                  , pde-loss 2.5041e-13, initc-loss 1.7359e+04                    bc_loss 1.6502e+07\n",
      "Epoch 11300, Training-Loss 3.9927e+03, Data-loss 2.3384e+03                  , pde-loss 2.5174e-13, initc-loss 1.7305e+04                    bc_loss 1.6526e+07\n",
      "Epoch 11310, Training-Loss 3.5664e+03, Data-loss 1.9097e+03                  , pde-loss 2.8016e-13, initc-loss 1.7250e+04                    bc_loss 1.6550e+07\n",
      "Epoch 11320, Training-Loss 3.7161e+03, Data-loss 2.0571e+03                  , pde-loss 2.5606e-13, initc-loss 1.7197e+04                    bc_loss 1.6573e+07\n",
      "Epoch 11330, Training-Loss 3.3362e+03, Data-loss 1.6749e+03                  , pde-loss 3.1046e-13, initc-loss 1.7146e+04                    bc_loss 1.6595e+07\n",
      "Epoch 11340, Training-Loss 3.3611e+03, Data-loss 1.6975e+03                  , pde-loss 3.3724e-13, initc-loss 1.7094e+04                    bc_loss 1.6618e+07\n",
      "Epoch 11350, Training-Loss 3.5580e+03, Data-loss 1.8921e+03                  , pde-loss 3.7503e-13, initc-loss 1.7042e+04                    bc_loss 1.6641e+07\n",
      "Epoch 11360, Training-Loss 3.6880e+03, Data-loss 2.0199e+03                  , pde-loss 3.1301e-13, initc-loss 1.6991e+04                    bc_loss 1.6664e+07\n",
      "Epoch 11370, Training-Loss 3.4911e+03, Data-loss 1.8207e+03                  , pde-loss 3.6435e-13, initc-loss 1.6939e+04                    bc_loss 1.6687e+07\n",
      "Epoch 11380, Training-Loss 3.6418e+03, Data-loss 1.9691e+03                  , pde-loss 3.8235e-13, initc-loss 1.6888e+04                    bc_loss 1.6710e+07\n",
      "Epoch 11390, Training-Loss 3.9238e+03, Data-loss 2.2489e+03                  , pde-loss 3.6830e-13, initc-loss 1.6839e+04                    bc_loss 1.6732e+07\n",
      "Epoch 11400, Training-Loss 3.9574e+03, Data-loss 2.2805e+03                  , pde-loss 3.3081e-13, initc-loss 1.6792e+04                    bc_loss 1.6752e+07\n",
      "Epoch 11410, Training-Loss 3.6131e+03, Data-loss 1.9342e+03                  , pde-loss 3.9609e-13, initc-loss 1.6747e+04                    bc_loss 1.6772e+07\n",
      "Epoch 11420, Training-Loss 3.2641e+03, Data-loss 1.5832e+03                  , pde-loss 4.1550e-13, initc-loss 1.6703e+04                    bc_loss 1.6792e+07\n",
      "Epoch 11430, Training-Loss 3.5560e+03, Data-loss 1.8730e+03                  , pde-loss 4.5098e-13, initc-loss 1.6655e+04                    bc_loss 1.6814e+07\n",
      "Epoch 11440, Training-Loss 3.2508e+03, Data-loss 1.5655e+03                  , pde-loss 5.1862e-13, initc-loss 1.6605e+04                    bc_loss 1.6836e+07\n",
      "Epoch 11450, Training-Loss 3.3039e+03, Data-loss 1.6166e+03                  , pde-loss 4.8004e-13, initc-loss 1.6560e+04                    bc_loss 1.6857e+07\n",
      "Epoch 11460, Training-Loss 3.5537e+03, Data-loss 1.8644e+03                  , pde-loss 4.6997e-13, initc-loss 1.6516e+04                    bc_loss 1.6876e+07\n",
      "Epoch 11470, Training-Loss 3.2922e+03, Data-loss 1.6009e+03                  , pde-loss 5.6966e-13, initc-loss 1.6471e+04                    bc_loss 1.6897e+07\n",
      "Epoch 11480, Training-Loss 2.9874e+03, Data-loss 1.2941e+03                  , pde-loss 5.7673e-13, initc-loss 1.6427e+04                    bc_loss 1.6917e+07\n",
      "Epoch 11490, Training-Loss 3.5372e+03, Data-loss 1.8419e+03                  , pde-loss 5.9749e-13, initc-loss 1.6384e+04                    bc_loss 1.6936e+07\n",
      "Epoch 11500, Training-Loss 3.3482e+03, Data-loss 1.6509e+03                  , pde-loss 6.7512e-13, initc-loss 1.6339e+04                    bc_loss 1.6957e+07\n",
      "Epoch 11510, Training-Loss 3.3749e+03, Data-loss 1.6757e+03                  , pde-loss 7.2228e-13, initc-loss 1.6297e+04                    bc_loss 1.6976e+07\n",
      "Epoch 11520, Training-Loss 3.2945e+03, Data-loss 1.5934e+03                  , pde-loss 6.7078e-13, initc-loss 1.6256e+04                    bc_loss 1.6995e+07\n",
      "Epoch 11530, Training-Loss 3.9627e+03, Data-loss 2.2596e+03                  , pde-loss 7.0590e-13, initc-loss 1.6213e+04                    bc_loss 1.7014e+07\n",
      "Epoch 11540, Training-Loss 3.5848e+03, Data-loss 1.8798e+03                  , pde-loss 7.2551e-13, initc-loss 1.6171e+04                    bc_loss 1.7034e+07\n",
      "Epoch 11550, Training-Loss 3.1499e+03, Data-loss 1.4430e+03                  , pde-loss 7.6529e-13, initc-loss 1.6128e+04                    bc_loss 1.7053e+07\n",
      "Epoch 11560, Training-Loss 3.0434e+03, Data-loss 1.3347e+03                  , pde-loss 8.6949e-13, initc-loss 1.6089e+04                    bc_loss 1.7071e+07\n",
      "Epoch 11570, Training-Loss 3.6173e+03, Data-loss 1.9067e+03                  , pde-loss 7.8896e-13, initc-loss 1.6049e+04                    bc_loss 1.7090e+07\n",
      "Epoch 11580, Training-Loss 3.7505e+03, Data-loss 2.0382e+03                  , pde-loss 9.2363e-13, initc-loss 1.6010e+04                    bc_loss 1.7108e+07\n",
      "Epoch 11590, Training-Loss 3.5247e+03, Data-loss 1.8105e+03                  , pde-loss 9.0472e-13, initc-loss 1.5969e+04                    bc_loss 1.7126e+07\n",
      "Epoch 11600, Training-Loss 3.0900e+03, Data-loss 1.3738e+03                  , pde-loss 9.7133e-13, initc-loss 1.5928e+04                    bc_loss 1.7146e+07\n",
      "Epoch 11610, Training-Loss 3.9270e+03, Data-loss 2.2091e+03                  , pde-loss 9.4360e-13, initc-loss 1.5891e+04                    bc_loss 1.7163e+07\n",
      "Epoch 11620, Training-Loss 3.2061e+03, Data-loss 1.4863e+03                  , pde-loss 1.0619e-12, initc-loss 1.5851e+04                    bc_loss 1.7182e+07\n",
      "Epoch 11630, Training-Loss 3.0054e+03, Data-loss 1.2840e+03                  , pde-loss 1.0769e-12, initc-loss 1.5814e+04                    bc_loss 1.7199e+07\n",
      "Epoch 11640, Training-Loss 3.8242e+03, Data-loss 2.1010e+03                  , pde-loss 1.1051e-12, initc-loss 1.5777e+04                    bc_loss 1.7216e+07\n",
      "Epoch 11650, Training-Loss 3.6022e+03, Data-loss 1.8773e+03                  , pde-loss 1.0420e-12, initc-loss 1.5739e+04                    bc_loss 1.7234e+07\n",
      "Epoch 11660, Training-Loss 3.0644e+03, Data-loss 1.3377e+03                  , pde-loss 1.2347e-12, initc-loss 1.5702e+04                    bc_loss 1.7251e+07\n",
      "Epoch 11670, Training-Loss 3.3624e+03, Data-loss 1.6341e+03                  , pde-loss 1.3131e-12, initc-loss 1.5666e+04                    bc_loss 1.7268e+07\n",
      "Epoch 11680, Training-Loss 3.6445e+03, Data-loss 1.9146e+03                  , pde-loss 1.2320e-12, initc-loss 1.5633e+04                    bc_loss 1.7284e+07\n",
      "Epoch 11690, Training-Loss 3.5946e+03, Data-loss 1.8632e+03                  , pde-loss 1.2722e-12, initc-loss 1.5602e+04                    bc_loss 1.7298e+07\n",
      "Epoch 11700, Training-Loss 3.5350e+03, Data-loss 1.8020e+03                  , pde-loss 1.4695e-12, initc-loss 1.5567e+04                    bc_loss 1.7314e+07\n",
      "Epoch 11710, Training-Loss 3.0406e+03, Data-loss 1.3060e+03                  , pde-loss 1.5316e-12, initc-loss 1.5534e+04                    bc_loss 1.7330e+07\n",
      "Epoch 11720, Training-Loss 3.2868e+03, Data-loss 1.5508e+03                  , pde-loss 1.4819e-12, initc-loss 1.5503e+04                    bc_loss 1.7345e+07\n",
      "Epoch 11730, Training-Loss 3.5311e+03, Data-loss 1.7936e+03                  , pde-loss 1.5109e-12, initc-loss 1.5471e+04                    bc_loss 1.7360e+07\n",
      "Epoch 11740, Training-Loss 2.9666e+03, Data-loss 1.2275e+03                  , pde-loss 1.6559e-12, initc-loss 1.5439e+04                    bc_loss 1.7375e+07\n",
      "Epoch 11750, Training-Loss 3.3632e+03, Data-loss 1.6228e+03                  , pde-loss 1.5175e-12, initc-loss 1.5410e+04                    bc_loss 1.7389e+07\n",
      "Epoch 11760, Training-Loss 2.9347e+03, Data-loss 1.1926e+03                  , pde-loss 1.7303e-12, initc-loss 1.5376e+04                    bc_loss 1.7405e+07\n",
      "Epoch 11770, Training-Loss 3.7330e+03, Data-loss 1.9894e+03                  , pde-loss 1.7315e-12, initc-loss 1.5344e+04                    bc_loss 1.7420e+07\n",
      "Epoch 11780, Training-Loss 3.8674e+03, Data-loss 2.1223e+03                  , pde-loss 1.6550e-12, initc-loss 1.5312e+04                    bc_loss 1.7435e+07\n",
      "Epoch 11790, Training-Loss 3.6884e+03, Data-loss 1.9418e+03                  , pde-loss 1.9229e-12, initc-loss 1.5282e+04                    bc_loss 1.7450e+07\n",
      "Epoch 11800, Training-Loss 3.0592e+03, Data-loss 1.3113e+03                  , pde-loss 1.8346e-12, initc-loss 1.5254e+04                    bc_loss 1.7463e+07\n",
      "Epoch 11810, Training-Loss 3.5913e+03, Data-loss 1.8419e+03                  , pde-loss 1.8566e-12, initc-loss 1.5222e+04                    bc_loss 1.7479e+07\n",
      "Epoch 11820, Training-Loss 3.9723e+03, Data-loss 2.2211e+03                  , pde-loss 1.6897e-12, initc-loss 1.5185e+04                    bc_loss 1.7496e+07\n",
      "Epoch 11830, Training-Loss 3.1108e+03, Data-loss 1.3581e+03                  , pde-loss 2.5083e-12, initc-loss 1.5152e+04                    bc_loss 1.7512e+07\n",
      "Epoch 11840, Training-Loss 3.5760e+03, Data-loss 1.8220e+03                  , pde-loss 2.2274e-12, initc-loss 1.5126e+04                    bc_loss 1.7525e+07\n",
      "Epoch 11850, Training-Loss 3.3807e+03, Data-loss 1.6253e+03                  , pde-loss 2.1208e-12, initc-loss 1.5096e+04                    bc_loss 1.7539e+07\n",
      "Epoch 11860, Training-Loss 3.4059e+03, Data-loss 1.6491e+03                  , pde-loss 2.3586e-12, initc-loss 1.5066e+04                    bc_loss 1.7553e+07\n",
      "Epoch 11870, Training-Loss 3.6224e+03, Data-loss 1.8638e+03                  , pde-loss 2.2479e-12, initc-loss 1.5030e+04                    bc_loss 1.7571e+07\n",
      "Epoch 11880, Training-Loss 3.6048e+03, Data-loss 1.8446e+03                  , pde-loss 2.2032e-12, initc-loss 1.4997e+04                    bc_loss 1.7587e+07\n",
      "Epoch 11890, Training-Loss 3.5317e+03, Data-loss 1.7700e+03                  , pde-loss 2.7289e-12, initc-loss 1.4965e+04                    bc_loss 1.7602e+07\n",
      "Epoch 11900, Training-Loss 3.1371e+03, Data-loss 1.3742e+03                  , pde-loss 2.9557e-12, initc-loss 1.4940e+04                    bc_loss 1.7615e+07\n",
      "Epoch 11910, Training-Loss 2.7667e+03, Data-loss 1.0026e+03                  , pde-loss 3.0315e-12, initc-loss 1.4916e+04                    bc_loss 1.7626e+07\n",
      "Epoch 11920, Training-Loss 3.0701e+03, Data-loss 1.3047e+03                  , pde-loss 2.9901e-12, initc-loss 1.4891e+04                    bc_loss 1.7638e+07\n",
      "Epoch 11930, Training-Loss 3.4908e+03, Data-loss 1.7243e+03                  , pde-loss 2.6933e-12, initc-loss 1.4869e+04                    bc_loss 1.7649e+07\n",
      "Epoch 11940, Training-Loss 3.5800e+03, Data-loss 1.8124e+03                  , pde-loss 3.5680e-12, initc-loss 1.4845e+04                    bc_loss 1.7661e+07\n",
      "Epoch 11950, Training-Loss 3.3131e+03, Data-loss 1.5442e+03                  , pde-loss 3.2988e-12, initc-loss 1.4818e+04                    bc_loss 1.7674e+07\n",
      "Epoch 11960, Training-Loss 3.2556e+03, Data-loss 1.4854e+03                  , pde-loss 3.1669e-12, initc-loss 1.4791e+04                    bc_loss 1.7687e+07\n",
      "Epoch 11970, Training-Loss 3.3679e+03, Data-loss 1.5964e+03                  , pde-loss 3.3738e-12, initc-loss 1.4764e+04                    bc_loss 1.7700e+07\n",
      "Epoch 11980, Training-Loss 2.9593e+03, Data-loss 1.1869e+03                  , pde-loss 4.0288e-12, initc-loss 1.4745e+04                    bc_loss 1.7710e+07\n",
      "Epoch 11990, Training-Loss 3.4707e+03, Data-loss 1.6974e+03                  , pde-loss 3.6835e-12, initc-loss 1.4727e+04                    bc_loss 1.7719e+07\n",
      "Epoch 12000, Training-Loss 2.9889e+03, Data-loss 1.2144e+03                  , pde-loss 3.8461e-12, initc-loss 1.4705e+04                    bc_loss 1.7730e+07\n",
      "Epoch 12010, Training-Loss 3.3274e+03, Data-loss 1.5519e+03                  , pde-loss 4.2146e-12, initc-loss 1.4682e+04                    bc_loss 1.7741e+07\n",
      "Epoch 12020, Training-Loss 3.1092e+03, Data-loss 1.3324e+03                  , pde-loss 4.5374e-12, initc-loss 1.4657e+04                    bc_loss 1.7753e+07\n",
      "Epoch 12030, Training-Loss 3.4615e+03, Data-loss 1.6835e+03                  , pde-loss 5.2634e-12, initc-loss 1.4632e+04                    bc_loss 1.7765e+07\n",
      "Epoch 12040, Training-Loss 3.3183e+03, Data-loss 1.5393e+03                  , pde-loss 4.7068e-12, initc-loss 1.4613e+04                    bc_loss 1.7775e+07\n",
      "Epoch 12050, Training-Loss 3.5206e+03, Data-loss 1.7406e+03                  , pde-loss 5.1144e-12, initc-loss 1.4590e+04                    bc_loss 1.7786e+07\n",
      "Epoch 12060, Training-Loss 3.5198e+03, Data-loss 1.7386e+03                  , pde-loss 5.1274e-12, initc-loss 1.4568e+04                    bc_loss 1.7797e+07\n",
      "Epoch 12070, Training-Loss 3.2044e+03, Data-loss 1.4221e+03                  , pde-loss 5.4412e-12, initc-loss 1.4545e+04                    bc_loss 1.7808e+07\n",
      "Epoch 12080, Training-Loss 3.5988e+03, Data-loss 1.8155e+03                  , pde-loss 5.8208e-12, initc-loss 1.4525e+04                    bc_loss 1.7818e+07\n",
      "Epoch 12090, Training-Loss 3.1434e+03, Data-loss 1.3593e+03                  , pde-loss 6.5351e-12, initc-loss 1.4507e+04                    bc_loss 1.7827e+07\n",
      "Epoch 12100, Training-Loss 3.5100e+03, Data-loss 1.7250e+03                  , pde-loss 6.1507e-12, initc-loss 1.4490e+04                    bc_loss 1.7835e+07\n",
      "Epoch 12110, Training-Loss 3.1475e+03, Data-loss 1.3616e+03                  , pde-loss 6.0750e-12, initc-loss 1.4472e+04                    bc_loss 1.7845e+07\n",
      "Epoch 12120, Training-Loss 3.1560e+03, Data-loss 1.3692e+03                  , pde-loss 6.6082e-12, initc-loss 1.4454e+04                    bc_loss 1.7854e+07\n",
      "Epoch 12130, Training-Loss 3.2525e+03, Data-loss 1.4646e+03                  , pde-loss 6.6935e-12, initc-loss 1.4433e+04                    bc_loss 1.7864e+07\n",
      "Epoch 12140, Training-Loss 3.4241e+03, Data-loss 1.6351e+03                  , pde-loss 7.0461e-12, initc-loss 1.4410e+04                    bc_loss 1.7875e+07\n",
      "Epoch 12150, Training-Loss 3.4099e+03, Data-loss 1.6199e+03                  , pde-loss 8.5754e-12, initc-loss 1.4389e+04                    bc_loss 1.7885e+07\n",
      "Epoch 12160, Training-Loss 3.1884e+03, Data-loss 1.3975e+03                  , pde-loss 6.5809e-12, initc-loss 1.4372e+04                    bc_loss 1.7894e+07\n",
      "Epoch 12170, Training-Loss 3.8112e+03, Data-loss 2.0194e+03                  , pde-loss 7.9578e-12, initc-loss 1.4353e+04                    bc_loss 1.7904e+07\n",
      "Epoch 12180, Training-Loss 3.6695e+03, Data-loss 1.8767e+03                  , pde-loss 8.3795e-12, initc-loss 1.4334e+04                    bc_loss 1.7913e+07\n",
      "Epoch 12190, Training-Loss 4.0076e+03, Data-loss 2.2140e+03                  , pde-loss 7.9535e-12, initc-loss 1.4316e+04                    bc_loss 1.7922e+07\n",
      "Epoch 12200, Training-Loss 3.1281e+03, Data-loss 1.3336e+03                  , pde-loss 9.1105e-12, initc-loss 1.4298e+04                    bc_loss 1.7931e+07\n",
      "Epoch 12210, Training-Loss 3.3212e+03, Data-loss 1.5260e+03                  , pde-loss 1.1900e-11, initc-loss 1.4285e+04                    bc_loss 1.7938e+07\n",
      "Epoch 12220, Training-Loss 3.2702e+03, Data-loss 1.4744e+03                  , pde-loss 1.0005e-11, initc-loss 1.4274e+04                    bc_loss 1.7943e+07\n",
      "Epoch 12230, Training-Loss 3.3424e+03, Data-loss 1.5460e+03                  , pde-loss 1.0553e-11, initc-loss 1.4261e+04                    bc_loss 1.7950e+07\n",
      "Epoch 12240, Training-Loss 2.9559e+03, Data-loss 1.1586e+03                  , pde-loss 1.3610e-11, initc-loss 1.4243e+04                    bc_loss 1.7959e+07\n",
      "Epoch 12250, Training-Loss 3.3565e+03, Data-loss 1.5584e+03                  , pde-loss 1.2537e-11, initc-loss 1.4226e+04                    bc_loss 1.7967e+07\n",
      "Epoch 12260, Training-Loss 3.1408e+03, Data-loss 1.3419e+03                  , pde-loss 1.3396e-11, initc-loss 1.4211e+04                    bc_loss 1.7975e+07\n",
      "Epoch 12270, Training-Loss 3.3146e+03, Data-loss 1.5150e+03                  , pde-loss 1.1903e-11, initc-loss 1.4197e+04                    bc_loss 1.7982e+07\n",
      "Epoch 12280, Training-Loss 3.5909e+03, Data-loss 1.7902e+03                  , pde-loss 1.2929e-11, initc-loss 1.4175e+04                    bc_loss 1.7993e+07\n",
      "Epoch 12290, Training-Loss 3.1409e+03, Data-loss 1.3393e+03                  , pde-loss 1.1035e-11, initc-loss 1.4156e+04                    bc_loss 1.8002e+07\n",
      "Epoch 12300, Training-Loss 3.1383e+03, Data-loss 1.3359e+03                  , pde-loss 1.5149e-11, initc-loss 1.4142e+04                    bc_loss 1.8010e+07\n",
      "Epoch 12310, Training-Loss 3.1730e+03, Data-loss 1.3702e+03                  , pde-loss 1.4641e-11, initc-loss 1.4133e+04                    bc_loss 1.8014e+07\n",
      "Epoch 12320, Training-Loss 3.2957e+03, Data-loss 1.4923e+03                  , pde-loss 1.7054e-11, initc-loss 1.4122e+04                    bc_loss 1.8020e+07\n",
      "Epoch 12330, Training-Loss 3.1849e+03, Data-loss 1.3807e+03                  , pde-loss 1.9188e-11, initc-loss 1.4108e+04                    bc_loss 1.8027e+07\n",
      "Epoch 12340, Training-Loss 3.3635e+03, Data-loss 1.5587e+03                  , pde-loss 1.8475e-11, initc-loss 1.4093e+04                    bc_loss 1.8035e+07\n",
      "Epoch 12350, Training-Loss 3.3880e+03, Data-loss 1.5822e+03                  , pde-loss 1.9660e-11, initc-loss 1.4075e+04                    bc_loss 1.8044e+07\n",
      "Epoch 12360, Training-Loss 3.3509e+03, Data-loss 1.5443e+03                  , pde-loss 1.9301e-11, initc-loss 1.4059e+04                    bc_loss 1.8051e+07\n",
      "Epoch 12370, Training-Loss 3.3934e+03, Data-loss 1.5862e+03                  , pde-loss 2.2124e-11, initc-loss 1.4045e+04                    bc_loss 1.8059e+07\n",
      "Epoch 12380, Training-Loss 3.4105e+03, Data-loss 1.6024e+03                  , pde-loss 2.4807e-11, initc-loss 1.4028e+04                    bc_loss 1.8067e+07\n",
      "Epoch 12390, Training-Loss 2.9378e+03, Data-loss 1.1290e+03                  , pde-loss 2.3028e-11, initc-loss 1.4015e+04                    bc_loss 1.8074e+07\n",
      "Epoch 12400, Training-Loss 3.6795e+03, Data-loss 1.8701e+03                  , pde-loss 2.9022e-11, initc-loss 1.4004e+04                    bc_loss 1.8079e+07\n",
      "Epoch 12410, Training-Loss 3.1919e+03, Data-loss 1.3822e+03                  , pde-loss 2.7481e-11, initc-loss 1.3997e+04                    bc_loss 1.8083e+07\n",
      "Epoch 12420, Training-Loss 3.2590e+03, Data-loss 1.4489e+03                  , pde-loss 3.0659e-11, initc-loss 1.3989e+04                    bc_loss 1.8087e+07\n",
      "Epoch 12430, Training-Loss 3.2450e+03, Data-loss 1.4345e+03                  , pde-loss 3.4201e-11, initc-loss 1.3982e+04                    bc_loss 1.8091e+07\n",
      "Epoch 12440, Training-Loss 3.2435e+03, Data-loss 1.4326e+03                  , pde-loss 3.3710e-11, initc-loss 1.3974e+04                    bc_loss 1.8095e+07\n",
      "Epoch 12450, Training-Loss 3.1609e+03, Data-loss 1.3498e+03                  , pde-loss 3.2446e-11, initc-loss 1.3968e+04                    bc_loss 1.8098e+07\n",
      "Epoch 12460, Training-Loss 3.2362e+03, Data-loss 1.4246e+03                  , pde-loss 3.4638e-11, initc-loss 1.3960e+04                    bc_loss 1.8102e+07\n",
      "Epoch 12470, Training-Loss 3.1020e+03, Data-loss 1.2899e+03                  , pde-loss 3.7177e-11, initc-loss 1.3950e+04                    bc_loss 1.8107e+07\n",
      "Epoch 12480, Training-Loss 3.3524e+03, Data-loss 1.5399e+03                  , pde-loss 4.6435e-11, initc-loss 1.3941e+04                    bc_loss 1.8112e+07\n",
      "Epoch 12490, Training-Loss 2.9825e+03, Data-loss 1.1694e+03                  , pde-loss 4.3099e-11, initc-loss 1.3929e+04                    bc_loss 1.8118e+07\n",
      "Epoch 12500, Training-Loss 3.7764e+03, Data-loss 1.9627e+03                  , pde-loss 4.0435e-11, initc-loss 1.3920e+04                    bc_loss 1.8122e+07\n",
      "Epoch 12510, Training-Loss 3.6932e+03, Data-loss 1.8791e+03                  , pde-loss 5.0652e-11, initc-loss 1.3911e+04                    bc_loss 1.8127e+07\n",
      "Epoch 12520, Training-Loss 3.2552e+03, Data-loss 1.4406e+03                  , pde-loss 4.8164e-11, initc-loss 1.3901e+04                    bc_loss 1.8132e+07\n",
      "Epoch 12530, Training-Loss 3.4232e+03, Data-loss 1.6081e+03                  , pde-loss 5.4316e-11, initc-loss 1.3891e+04                    bc_loss 1.8137e+07\n",
      "Epoch 12540, Training-Loss 3.7525e+03, Data-loss 1.9370e+03                  , pde-loss 5.3535e-11, initc-loss 1.3883e+04                    bc_loss 1.8141e+07\n",
      "Epoch 12550, Training-Loss 3.2311e+03, Data-loss 1.4149e+03                  , pde-loss 5.6496e-11, initc-loss 1.3869e+04                    bc_loss 1.8148e+07\n",
      "Epoch 12560, Training-Loss 3.1535e+03, Data-loss 1.3367e+03                  , pde-loss 6.9867e-11, initc-loss 1.3857e+04                    bc_loss 1.8154e+07\n",
      "Epoch 12570, Training-Loss 3.4528e+03, Data-loss 1.6356e+03                  , pde-loss 6.3454e-11, initc-loss 1.3850e+04                    bc_loss 1.8158e+07\n",
      "Epoch 12580, Training-Loss 3.6688e+03, Data-loss 1.8509e+03                  , pde-loss 9.2693e-11, initc-loss 1.3837e+04                    bc_loss 1.8165e+07\n",
      "Epoch 12590, Training-Loss 3.7543e+03, Data-loss 1.9357e+03                  , pde-loss 7.8241e-11, initc-loss 1.3823e+04                    bc_loss 1.8172e+07\n",
      "Epoch 12600, Training-Loss 3.6327e+03, Data-loss 1.8132e+03                  , pde-loss 7.0010e-11, initc-loss 1.3805e+04                    bc_loss 1.8181e+07\n",
      "Epoch 12610, Training-Loss 3.2652e+03, Data-loss 1.4448e+03                  , pde-loss 1.0091e-10, initc-loss 1.3788e+04                    bc_loss 1.8190e+07\n",
      "Epoch 12620, Training-Loss 3.4304e+03, Data-loss 1.6097e+03                  , pde-loss 9.8703e-11, initc-loss 1.3781e+04                    bc_loss 1.8193e+07\n",
      "Epoch 12630, Training-Loss 3.7273e+03, Data-loss 1.9065e+03                  , pde-loss 1.0992e-10, initc-loss 1.3779e+04                    bc_loss 1.8194e+07\n",
      "Epoch 12640, Training-Loss 3.6971e+03, Data-loss 1.8763e+03                  , pde-loss 1.1329e-10, initc-loss 1.3780e+04                    bc_loss 1.8194e+07\n",
      "Epoch 12650, Training-Loss 3.5309e+03, Data-loss 1.7097e+03                  , pde-loss 1.1671e-10, initc-loss 1.3772e+04                    bc_loss 1.8198e+07\n",
      "Epoch 12660, Training-Loss 3.4132e+03, Data-loss 1.5916e+03                  , pde-loss 1.3052e-10, initc-loss 1.3764e+04                    bc_loss 1.8202e+07\n",
      "Epoch 12670, Training-Loss 3.3635e+03, Data-loss 1.5417e+03                  , pde-loss 1.5667e-10, initc-loss 1.3761e+04                    bc_loss 1.8204e+07\n",
      "Epoch 12680, Training-Loss 3.5688e+03, Data-loss 1.7467e+03                  , pde-loss 1.8226e-10, initc-loss 1.3755e+04                    bc_loss 1.8207e+07\n",
      "Epoch 12690, Training-Loss 3.1330e+03, Data-loss 1.3106e+03                  , pde-loss 2.1502e-10, initc-loss 1.3749e+04                    bc_loss 1.8210e+07\n",
      "Epoch 12700, Training-Loss 3.2486e+03, Data-loss 1.4259e+03                  , pde-loss 2.1566e-10, initc-loss 1.3743e+04                    bc_loss 1.8213e+07\n",
      "Epoch 12710, Training-Loss 3.3718e+03, Data-loss 1.5485e+03                  , pde-loss 1.9194e-10, initc-loss 1.3730e+04                    bc_loss 1.8220e+07\n",
      "Epoch 12720, Training-Loss 3.0779e+03, Data-loss 1.2542e+03                  , pde-loss 2.0315e-10, initc-loss 1.3723e+04                    bc_loss 1.8224e+07\n",
      "Epoch 12730, Training-Loss 3.1674e+03, Data-loss 1.3437e+03                  , pde-loss 3.2771e-10, initc-loss 1.3723e+04                    bc_loss 1.8223e+07\n",
      "Epoch 12740, Training-Loss 3.1352e+03, Data-loss 1.3116e+03                  , pde-loss 2.9920e-10, initc-loss 1.3725e+04                    bc_loss 1.8222e+07\n",
      "Epoch 12750, Training-Loss 3.3321e+03, Data-loss 1.5084e+03                  , pde-loss 3.1005e-10, initc-loss 1.3723e+04                    bc_loss 1.8223e+07\n",
      "Epoch 12760, Training-Loss 3.3823e+03, Data-loss 1.5583e+03                  , pde-loss 4.1623e-10, initc-loss 1.3716e+04                    bc_loss 1.8227e+07\n",
      "Epoch 12770, Training-Loss 3.3383e+03, Data-loss 1.5138e+03                  , pde-loss 5.4542e-10, initc-loss 1.3707e+04                    bc_loss 1.8231e+07\n",
      "Epoch 12780, Training-Loss 3.2548e+03, Data-loss 1.4300e+03                  , pde-loss 5.1615e-10, initc-loss 1.3700e+04                    bc_loss 1.8235e+07\n",
      "Epoch 12790, Training-Loss 3.4055e+03, Data-loss 1.5804e+03                  , pde-loss 5.8745e-10, initc-loss 1.3696e+04                    bc_loss 1.8237e+07\n",
      "Epoch 12800, Training-Loss 3.2583e+03, Data-loss 1.4331e+03                  , pde-loss 5.7665e-10, initc-loss 1.3694e+04                    bc_loss 1.8238e+07\n",
      "Epoch 12810, Training-Loss 3.2515e+03, Data-loss 1.4262e+03                  , pde-loss 5.4215e-10, initc-loss 1.3691e+04                    bc_loss 1.8240e+07\n",
      "Epoch 12820, Training-Loss 3.1601e+03, Data-loss 1.3343e+03                  , pde-loss 7.0234e-10, initc-loss 1.3681e+04                    bc_loss 1.8245e+07\n",
      "Epoch 12830, Training-Loss 3.4453e+03, Data-loss 1.6189e+03                  , pde-loss 6.8982e-10, initc-loss 1.3670e+04                    bc_loss 1.8251e+07\n",
      "Epoch 12840, Training-Loss 3.4729e+03, Data-loss 1.6459e+03                  , pde-loss 8.1283e-10, initc-loss 1.3659e+04                    bc_loss 1.8256e+07\n",
      "Epoch 12850, Training-Loss 3.2456e+03, Data-loss 1.4182e+03                  , pde-loss 1.1386e-09, initc-loss 1.3652e+04                    bc_loss 1.8260e+07\n",
      "Epoch 12860, Training-Loss 3.2581e+03, Data-loss 1.4304e+03                  , pde-loss 1.0334e-09, initc-loss 1.3647e+04                    bc_loss 1.8263e+07\n",
      "Epoch 12870, Training-Loss 3.1509e+03, Data-loss 1.3233e+03                  , pde-loss 1.3452e-09, initc-loss 1.3647e+04                    bc_loss 1.8262e+07\n",
      "Epoch 12880, Training-Loss 3.0662e+03, Data-loss 1.2388e+03                  , pde-loss 1.6493e-09, initc-loss 1.3651e+04                    bc_loss 1.8261e+07\n",
      "Epoch 12890, Training-Loss 3.4142e+03, Data-loss 1.5872e+03                  , pde-loss 2.0484e-09, initc-loss 1.3658e+04                    bc_loss 1.8257e+07\n",
      "Epoch 12900, Training-Loss 3.3428e+03, Data-loss 1.5158e+03                  , pde-loss 2.4721e-09, initc-loss 1.3659e+04                    bc_loss 1.8256e+07\n",
      "Epoch 12910, Training-Loss 3.0960e+03, Data-loss 1.2690e+03                  , pde-loss 3.2868e-09, initc-loss 1.3658e+04                    bc_loss 1.8257e+07\n",
      "Epoch 12920, Training-Loss 3.4185e+03, Data-loss 1.5918e+03                  , pde-loss 3.4868e-09, initc-loss 1.3663e+04                    bc_loss 1.8254e+07\n",
      "Epoch 12930, Training-Loss 3.3807e+03, Data-loss 1.5540e+03                  , pde-loss 7.0852e-09, initc-loss 1.3663e+04                    bc_loss 1.8254e+07\n",
      "Epoch 12940, Training-Loss 3.5601e+03, Data-loss 1.7331e+03                  , pde-loss 7.8969e-09, initc-loss 1.3658e+04                    bc_loss 1.8257e+07\n",
      "Epoch 12950, Training-Loss 3.6150e+03, Data-loss 1.7880e+03                  , pde-loss 1.5143e-08, initc-loss 1.3658e+04                    bc_loss 1.8257e+07\n",
      "Epoch 12960, Training-Loss 3.2835e+03, Data-loss 1.4566e+03                  , pde-loss 2.3686e-08, initc-loss 1.3661e+04                    bc_loss 1.8255e+07\n",
      "Epoch 12970, Training-Loss 3.3823e+03, Data-loss 1.5556e+03                  , pde-loss 3.8314e-08, initc-loss 1.3665e+04                    bc_loss 1.8253e+07\n",
      "Epoch 12980, Training-Loss 3.5379e+03, Data-loss 1.7111e+03                  , pde-loss 1.0265e-07, initc-loss 1.3663e+04                    bc_loss 1.8254e+07\n",
      "Epoch 12990, Training-Loss 3.2125e+03, Data-loss 1.3853e+03                  , pde-loss 2.1298e-07, initc-loss 1.3655e+04                    bc_loss 1.8259e+07\n",
      "Epoch 13000, Training-Loss 3.4948e+03, Data-loss 1.6674e+03                  , pde-loss 8.9886e-07, initc-loss 1.3650e+04                    bc_loss 1.8261e+07\n",
      "Epoch 13010, Training-Loss 3.4177e+03, Data-loss 1.5901e+03                  , pde-loss 6.3620e-06, initc-loss 1.3648e+04                    bc_loss 1.8262e+07\n",
      "Epoch 13020, Training-Loss 3.4149e+03, Data-loss 1.5874e+03                  , pde-loss 2.9108e-05, initc-loss 1.3649e+04                    bc_loss 1.8262e+07\n",
      "Epoch 13030, Training-Loss 3.8976e+03, Data-loss 2.0698e+03                  , pde-loss 7.5624e-04, initc-loss 1.3642e+04                    bc_loss 1.8264e+07\n",
      "Epoch 13040, Training-Loss 3.3508e+03, Data-loss 1.5230e+03                  , pde-loss 2.1726e-02, initc-loss 1.3633e+04                    bc_loss 1.8265e+07\n",
      "Epoch 13050, Training-Loss 3.8422e+03, Data-loss 2.0544e+03                  , pde-loss 6.5386e+00, initc-loss 1.4134e+04                    bc_loss 1.7864e+07\n",
      "Epoch 13060, Training-Loss 3.3307e+03, Data-loss 1.6643e+03                  , pde-loss 3.0749e+02, initc-loss 1.4247e+04                    bc_loss 1.6650e+07\n",
      "Epoch 13070, Training-Loss 2.3296e+03, Data-loss 6.4824e+02                  , pde-loss 6.4327e+02, initc-loss 1.3794e+04                    bc_loss 1.6799e+07\n",
      "Epoch 13080, Training-Loss 2.4630e+03, Data-loss 7.8722e+02                  , pde-loss 7.6990e+02, initc-loss 1.3647e+04                    bc_loss 1.6743e+07\n",
      "Epoch 13090, Training-Loss 2.7478e+03, Data-loss 1.0493e+03                  , pde-loss 6.0357e+02, initc-loss 1.3458e+04                    bc_loss 1.6971e+07\n",
      "Epoch 13100, Training-Loss 2.5675e+03, Data-loss 8.6167e+02                  , pde-loss 7.7197e+02, initc-loss 1.3346e+04                    bc_loss 1.7045e+07\n",
      "Epoch 13110, Training-Loss 2.9925e+03, Data-loss 1.3099e+03                  , pde-loss 6.1442e+02, initc-loss 1.3306e+04                    bc_loss 1.6813e+07\n",
      "Epoch 13120, Training-Loss 3.1617e+03, Data-loss 1.4669e+03                  , pde-loss 6.9330e+02, initc-loss 1.3197e+04                    bc_loss 1.6934e+07\n",
      "Epoch 13130, Training-Loss 2.8181e+03, Data-loss 1.1208e+03                  , pde-loss 7.7365e+02, initc-loss 1.3116e+04                    bc_loss 1.6959e+07\n",
      "Epoch 13140, Training-Loss 2.5565e+03, Data-loss 8.5019e+02                  , pde-loss 6.4191e+02, initc-loss 1.3029e+04                    bc_loss 1.7049e+07\n",
      "Epoch 13150, Training-Loss 2.4316e+03, Data-loss 7.4049e+02                  , pde-loss 6.7105e+02, initc-loss 1.3018e+04                    bc_loss 1.6897e+07\n",
      "Epoch 13160, Training-Loss 2.8388e+03, Data-loss 1.1390e+03                  , pde-loss 7.8012e+02, initc-loss 1.2949e+04                    bc_loss 1.6984e+07\n",
      "Epoch 13170, Training-Loss 3.1606e+03, Data-loss 1.4721e+03                  , pde-loss 4.4199e+02, initc-loss 1.2959e+04                    bc_loss 1.6872e+07\n",
      "Epoch 13180, Training-Loss 2.6620e+03, Data-loss 9.5346e+02                  , pde-loss 5.8215e+02, initc-loss 1.2848e+04                    bc_loss 1.7072e+07\n",
      "Epoch 13190, Training-Loss 2.8137e+03, Data-loss 1.1071e+03                  , pde-loss 5.6920e+02, initc-loss 1.2838e+04                    bc_loss 1.7052e+07\n",
      "Epoch 13200, Training-Loss 2.3309e+03, Data-loss 6.2477e+02                  , pde-loss 5.7524e+02, initc-loss 1.2811e+04                    bc_loss 1.7048e+07\n",
      "Epoch 13210, Training-Loss 2.4846e+03, Data-loss 7.8906e+02                  , pde-loss 7.1798e+02, initc-loss 1.2878e+04                    bc_loss 1.6942e+07\n",
      "Epoch 13220, Training-Loss 2.5156e+03, Data-loss 8.3066e+02                  , pde-loss 6.5203e+02, initc-loss 1.3039e+04                    bc_loss 1.6836e+07\n",
      "Epoch 13230, Training-Loss 2.6621e+03, Data-loss 9.6207e+02                  , pde-loss 5.9628e+02, initc-loss 1.2887e+04                    bc_loss 1.6987e+07\n",
      "Epoch 13240, Training-Loss 2.6092e+03, Data-loss 9.2122e+02                  , pde-loss 7.0312e+02, initc-loss 1.2965e+04                    bc_loss 1.6866e+07\n",
      "Epoch 13250, Training-Loss 2.6979e+03, Data-loss 1.0137e+03                  , pde-loss 6.2296e+02, initc-loss 1.2934e+04                    bc_loss 1.6828e+07\n",
      "Epoch 13260, Training-Loss 2.4227e+03, Data-loss 7.2523e+02                  , pde-loss 7.3919e+02, initc-loss 1.2764e+04                    bc_loss 1.6961e+07\n",
      "Epoch 13270, Training-Loss 2.4516e+03, Data-loss 7.7523e+02                  , pde-loss 6.7071e+02, initc-loss 1.3094e+04                    bc_loss 1.6750e+07\n",
      "Epoch 13280, Training-Loss 2.7555e+03, Data-loss 1.0494e+03                  , pde-loss 5.5880e+02, initc-loss 1.2723e+04                    bc_loss 1.7048e+07\n",
      "Epoch 13290, Training-Loss 2.2002e+03, Data-loss 4.8019e+02                  , pde-loss 5.4486e+02, initc-loss 1.2646e+04                    bc_loss 1.7187e+07\n",
      "Epoch 13300, Training-Loss 2.8024e+03, Data-loss 1.0984e+03                  , pde-loss 5.4825e+02, initc-loss 1.2911e+04                    bc_loss 1.7027e+07\n",
      "Epoch 13310, Training-Loss 2.7558e+03, Data-loss 1.0636e+03                  , pde-loss 6.1837e+02, initc-loss 1.3062e+04                    bc_loss 1.6908e+07\n",
      "Epoch 13320, Training-Loss 2.5392e+03, Data-loss 8.5399e+02                  , pde-loss 7.5558e+02, initc-loss 1.3228e+04                    bc_loss 1.6838e+07\n",
      "Epoch 13330, Training-Loss 2.4742e+03, Data-loss 7.6495e+02                  , pde-loss 5.5081e+02, initc-loss 1.2891e+04                    bc_loss 1.7079e+07\n",
      "Epoch 13340, Training-Loss 2.7701e+03, Data-loss 1.0555e+03                  , pde-loss 5.1800e+02, initc-loss 1.2926e+04                    bc_loss 1.7133e+07\n",
      "Epoch 13350, Training-Loss 2.5448e+03, Data-loss 8.3545e+02                  , pde-loss 5.1932e+02, initc-loss 1.3033e+04                    bc_loss 1.7080e+07\n",
      "Epoch 13360, Training-Loss 2.2254e+03, Data-loss 5.2697e+02                  , pde-loss 7.3019e+02, initc-loss 1.3295e+04                    bc_loss 1.6971e+07\n",
      "Epoch 13370, Training-Loss 2.4903e+03, Data-loss 7.8565e+02                  , pde-loss 4.9714e+02, initc-loss 1.3269e+04                    bc_loss 1.7033e+07\n",
      "Epoch 13380, Training-Loss 2.3813e+03, Data-loss 6.5506e+02                  , pde-loss 6.7028e+02, initc-loss 1.2843e+04                    bc_loss 1.7249e+07\n",
      "Epoch 13390, Training-Loss 2.2828e+03, Data-loss 5.7488e+02                  , pde-loss 6.7139e+02, initc-loss 1.3408e+04                    bc_loss 1.7066e+07\n",
      "Epoch 13400, Training-Loss 2.6084e+03, Data-loss 9.0891e+02                  , pde-loss 6.1149e+02, initc-loss 1.3709e+04                    bc_loss 1.6981e+07\n",
      "Epoch 13410, Training-Loss 2.1948e+03, Data-loss 4.9203e+02                  , pde-loss 6.6398e+02, initc-loss 1.3648e+04                    bc_loss 1.7013e+07\n",
      "Epoch 13420, Training-Loss 2.2758e+03, Data-loss 5.6223e+02                  , pde-loss 8.0044e+02, initc-loss 1.3330e+04                    bc_loss 1.7121e+07\n",
      "Epoch 13430, Training-Loss 2.4883e+03, Data-loss 7.8555e+02                  , pde-loss 6.2960e+02, initc-loss 1.3732e+04                    bc_loss 1.7013e+07\n",
      "Epoch 13440, Training-Loss 2.4168e+03, Data-loss 7.0695e+02                  , pde-loss 7.8259e+02, initc-loss 1.3803e+04                    bc_loss 1.7084e+07\n",
      "Epoch 13450, Training-Loss 2.6786e+03, Data-loss 9.5997e+02                  , pde-loss 6.6525e+02, initc-loss 1.3740e+04                    bc_loss 1.7172e+07\n",
      "Epoch 13460, Training-Loss 2.4312e+03, Data-loss 7.1652e+02                  , pde-loss 7.0124e+02, initc-loss 1.3996e+04                    bc_loss 1.7132e+07\n",
      "Epoch 13470, Training-Loss 2.3468e+03, Data-loss 6.3173e+02                  , pde-loss 7.3239e+02, initc-loss 1.3991e+04                    bc_loss 1.7136e+07\n",
      "Epoch 13480, Training-Loss 2.3741e+03, Data-loss 6.5447e+02                  , pde-loss 7.1428e+02, initc-loss 1.4193e+04                    bc_loss 1.7181e+07\n",
      "Epoch 13490, Training-Loss 2.3543e+03, Data-loss 6.4040e+02                  , pde-loss 6.9893e+02, initc-loss 1.4435e+04                    bc_loss 1.7124e+07\n",
      "Epoch 13500, Training-Loss 2.6660e+03, Data-loss 9.4602e+02                  , pde-loss 7.0531e+02, initc-loss 1.4029e+04                    bc_loss 1.7185e+07\n",
      "Epoch 13510, Training-Loss 2.1595e+03, Data-loss 4.5504e+02                  , pde-loss 7.4964e+02, initc-loss 1.4791e+04                    bc_loss 1.7029e+07\n",
      "Epoch 13520, Training-Loss 2.3497e+03, Data-loss 6.3068e+02                  , pde-loss 9.3818e+02, initc-loss 1.4198e+04                    bc_loss 1.7175e+07\n",
      "Epoch 13530, Training-Loss 2.2518e+03, Data-loss 5.2587e+02                  , pde-loss 7.2429e+02, initc-loss 1.4665e+04                    bc_loss 1.7244e+07\n",
      "Epoch 13540, Training-Loss 2.1172e+03, Data-loss 4.0337e+02                  , pde-loss 9.5282e+02, initc-loss 1.4981e+04                    bc_loss 1.7122e+07\n",
      "Epoch 13550, Training-Loss 2.3887e+03, Data-loss 6.6349e+02                  , pde-loss 9.1456e+02, initc-loss 1.4281e+04                    bc_loss 1.7237e+07\n",
      "Epoch 13560, Training-Loss 2.2768e+03, Data-loss 5.5299e+02                  , pde-loss 8.7880e+02, initc-loss 1.4703e+04                    bc_loss 1.7222e+07\n",
      "Epoch 13570, Training-Loss 2.7159e+03, Data-loss 9.8664e+02                  , pde-loss 8.1879e+02, initc-loss 1.4510e+04                    bc_loss 1.7278e+07\n",
      "Epoch 13580, Training-Loss 2.3069e+03, Data-loss 5.8524e+02                  , pde-loss 1.1112e+03, initc-loss 1.4881e+04                    bc_loss 1.7201e+07\n",
      "Epoch 13590, Training-Loss 2.2607e+03, Data-loss 5.2685e+02                  , pde-loss 9.7198e+02, initc-loss 1.4540e+04                    bc_loss 1.7323e+07\n",
      "Epoch 13600, Training-Loss 2.6028e+03, Data-loss 8.6828e+02                  , pde-loss 8.5114e+02, initc-loss 1.4825e+04                    bc_loss 1.7330e+07\n",
      "Epoch 13610, Training-Loss 2.1250e+03, Data-loss 3.8188e+02                  , pde-loss 9.6668e+02, initc-loss 1.4097e+04                    bc_loss 1.7416e+07\n",
      "Epoch 13620, Training-Loss 2.1804e+03, Data-loss 4.6839e+02                  , pde-loss 1.0728e+03, initc-loss 1.5342e+04                    bc_loss 1.7104e+07\n",
      "Epoch 13630, Training-Loss 2.2839e+03, Data-loss 5.5752e+02                  , pde-loss 8.8403e+02, initc-loss 1.5264e+04                    bc_loss 1.7248e+07\n",
      "Epoch 13640, Training-Loss 2.0746e+03, Data-loss 3.4337e+02                  , pde-loss 1.0112e+03, initc-loss 1.5446e+04                    bc_loss 1.7296e+07\n",
      "Epoch 13650, Training-Loss 2.3800e+03, Data-loss 6.4956e+02                  , pde-loss 9.7892e+02, initc-loss 1.4904e+04                    bc_loss 1.7288e+07\n",
      "Epoch 13660, Training-Loss 2.4278e+03, Data-loss 6.9083e+02                  , pde-loss 1.0713e+03, initc-loss 1.4739e+04                    bc_loss 1.7353e+07\n",
      "Epoch 13670, Training-Loss 2.3409e+03, Data-loss 5.9972e+02                  , pde-loss 8.1518e+02, initc-loss 1.4787e+04                    bc_loss 1.7396e+07\n",
      "Epoch 13680, Training-Loss 2.3915e+03, Data-loss 6.5684e+02                  , pde-loss 1.2797e+03, initc-loss 1.4998e+04                    bc_loss 1.7330e+07\n",
      "Epoch 13690, Training-Loss 2.2778e+03, Data-loss 5.4755e+02                  , pde-loss 1.1761e+03, initc-loss 1.4989e+04                    bc_loss 1.7286e+07\n",
      "Epoch 13700, Training-Loss 2.2929e+03, Data-loss 5.6370e+02                  , pde-loss 1.2457e+03, initc-loss 1.5289e+04                    bc_loss 1.7275e+07\n",
      "Epoch 13710, Training-Loss 2.2894e+03, Data-loss 5.6364e+02                  , pde-loss 9.7140e+02, initc-loss 1.5411e+04                    bc_loss 1.7241e+07\n",
      "Epoch 13720, Training-Loss 2.1291e+03, Data-loss 4.0921e+02                  , pde-loss 1.1640e+03, initc-loss 1.5568e+04                    bc_loss 1.7182e+07\n",
      "Epoch 13730, Training-Loss 2.4788e+03, Data-loss 7.5672e+02                  , pde-loss 1.1257e+03, initc-loss 1.5968e+04                    bc_loss 1.7204e+07\n",
      "Epoch 13740, Training-Loss 2.1879e+03, Data-loss 4.4110e+02                  , pde-loss 1.1024e+03, initc-loss 1.4601e+04                    bc_loss 1.7452e+07\n",
      "Epoch 13750, Training-Loss 2.0475e+03, Data-loss 3.0431e+02                  , pde-loss 1.2183e+03, initc-loss 1.4607e+04                    bc_loss 1.7416e+07\n",
      "Epoch 13760, Training-Loss 2.2526e+03, Data-loss 5.2159e+02                  , pde-loss 1.1274e+03, initc-loss 1.5583e+04                    bc_loss 1.7293e+07\n",
      "Epoch 13770, Training-Loss 2.0374e+03, Data-loss 3.0312e+02                  , pde-loss 1.1627e+03, initc-loss 1.5279e+04                    bc_loss 1.7326e+07\n",
      "Epoch 13780, Training-Loss 2.1608e+03, Data-loss 4.2683e+02                  , pde-loss 1.0901e+03, initc-loss 1.5605e+04                    bc_loss 1.7323e+07\n",
      "Epoch 13790, Training-Loss 2.0189e+03, Data-loss 2.6872e+02                  , pde-loss 1.1015e+03, initc-loss 1.4773e+04                    bc_loss 1.7486e+07\n",
      "Epoch 13800, Training-Loss 2.2333e+03, Data-loss 4.7412e+02                  , pde-loss 1.0913e+03, initc-loss 1.4499e+04                    bc_loss 1.7576e+07\n",
      "Epoch 13810, Training-Loss 2.3523e+03, Data-loss 5.9202e+02                  , pde-loss 9.2939e+02, initc-loss 1.4101e+04                    bc_loss 1.7588e+07\n",
      "Epoch 13820, Training-Loss 2.5143e+03, Data-loss 7.4560e+02                  , pde-loss 1.0707e+03, initc-loss 1.4368e+04                    bc_loss 1.7672e+07\n",
      "Epoch 13830, Training-Loss 2.2614e+03, Data-loss 4.9075e+02                  , pde-loss 1.0807e+03, initc-loss 1.3789e+04                    bc_loss 1.7692e+07\n",
      "Epoch 13840, Training-Loss 2.0525e+03, Data-loss 2.8562e+02                  , pde-loss 9.7839e+02, initc-loss 1.4365e+04                    bc_loss 1.7653e+07\n",
      "Epoch 13850, Training-Loss 2.0728e+03, Data-loss 3.1388e+02                  , pde-loss 1.0903e+03, initc-loss 1.4777e+04                    bc_loss 1.7573e+07\n",
      "Epoch 13860, Training-Loss 2.1461e+03, Data-loss 3.8015e+02                  , pde-loss 1.1386e+03, initc-loss 1.4248e+04                    bc_loss 1.7644e+07\n",
      "Epoch 13870, Training-Loss 2.1497e+03, Data-loss 3.9371e+02                  , pde-loss 1.1616e+03, initc-loss 1.4434e+04                    bc_loss 1.7544e+07\n",
      "Epoch 13880, Training-Loss 2.2700e+03, Data-loss 5.2385e+02                  , pde-loss 1.1405e+03, initc-loss 1.5221e+04                    bc_loss 1.7445e+07\n",
      "Epoch 13890, Training-Loss 2.1433e+03, Data-loss 3.9167e+02                  , pde-loss 1.1009e+03, initc-loss 1.4848e+04                    bc_loss 1.7501e+07\n",
      "Epoch 13900, Training-Loss 2.2794e+03, Data-loss 5.1942e+02                  , pde-loss 1.0115e+03, initc-loss 1.4739e+04                    bc_loss 1.7584e+07\n",
      "Epoch 13910, Training-Loss 2.2698e+03, Data-loss 5.1053e+02                  , pde-loss 1.2099e+03, initc-loss 1.4653e+04                    bc_loss 1.7577e+07\n",
      "Epoch 13920, Training-Loss 2.1596e+03, Data-loss 4.1323e+02                  , pde-loss 1.1114e+03, initc-loss 1.5161e+04                    bc_loss 1.7447e+07\n",
      "Epoch 13930, Training-Loss 2.1054e+03, Data-loss 3.4431e+02                  , pde-loss 1.3545e+03, initc-loss 1.4536e+04                    bc_loss 1.7595e+07\n",
      "Epoch 13940, Training-Loss 2.2062e+03, Data-loss 4.3587e+02                  , pde-loss 1.1702e+03, initc-loss 1.4506e+04                    bc_loss 1.7688e+07\n",
      "Epoch 13950, Training-Loss 2.1241e+03, Data-loss 3.4311e+02                  , pde-loss 1.2489e+03, initc-loss 1.3990e+04                    bc_loss 1.7794e+07\n",
      "Epoch 13960, Training-Loss 2.4090e+03, Data-loss 6.4573e+02                  , pde-loss 9.5255e+02, initc-loss 1.4639e+04                    bc_loss 1.7617e+07\n",
      "Epoch 13970, Training-Loss 2.0386e+03, Data-loss 2.8664e+02                  , pde-loss 1.1398e+03, initc-loss 1.4779e+04                    bc_loss 1.7504e+07\n",
      "Epoch 13980, Training-Loss 2.0521e+03, Data-loss 3.0959e+02                  , pde-loss 1.1362e+03, initc-loss 1.5341e+04                    bc_loss 1.7408e+07\n",
      "Epoch 13990, Training-Loss 2.1715e+03, Data-loss 4.1378e+02                  , pde-loss 1.1153e+03, initc-loss 1.5092e+04                    bc_loss 1.7561e+07\n",
      "Epoch 14000, Training-Loss 2.0293e+03, Data-loss 2.7495e+02                  , pde-loss 1.2965e+03, initc-loss 1.4829e+04                    bc_loss 1.7527e+07\n",
      "Epoch 14010, Training-Loss 2.2264e+03, Data-loss 4.6711e+02                  , pde-loss 1.0221e+03, initc-loss 1.4606e+04                    bc_loss 1.7577e+07\n",
      "Epoch 14020, Training-Loss 2.1050e+03, Data-loss 3.4500e+02                  , pde-loss 1.3233e+03, initc-loss 1.4768e+04                    bc_loss 1.7584e+07\n",
      "Epoch 14030, Training-Loss 2.1872e+03, Data-loss 4.3793e+02                  , pde-loss 1.2158e+03, initc-loss 1.5175e+04                    bc_loss 1.7476e+07\n",
      "Epoch 14040, Training-Loss 2.1156e+03, Data-loss 3.5970e+02                  , pde-loss 1.3001e+03, initc-loss 1.4900e+04                    bc_loss 1.7543e+07\n",
      "Epoch 14050, Training-Loss 1.9843e+03, Data-loss 2.2596e+02                  , pde-loss 1.1321e+03, initc-loss 1.4921e+04                    bc_loss 1.7568e+07\n",
      "Epoch 14060, Training-Loss 2.1671e+03, Data-loss 4.0454e+02                  , pde-loss 1.1989e+03, initc-loss 1.4580e+04                    bc_loss 1.7610e+07\n",
      "Epoch 14070, Training-Loss 2.2711e+03, Data-loss 5.1125e+02                  , pde-loss 1.3099e+03, initc-loss 1.4625e+04                    bc_loss 1.7582e+07\n",
      "Epoch 14080, Training-Loss 2.1759e+03, Data-loss 4.2020e+02                  , pde-loss 1.0778e+03, initc-loss 1.4789e+04                    bc_loss 1.7541e+07\n",
      "Epoch 14090, Training-Loss 2.1935e+03, Data-loss 4.2412e+02                  , pde-loss 1.1705e+03, initc-loss 1.4856e+04                    bc_loss 1.7678e+07\n",
      "Epoch 14100, Training-Loss 2.0939e+03, Data-loss 3.1885e+02                  , pde-loss 1.0759e+03, initc-loss 1.4230e+04                    bc_loss 1.7735e+07\n",
      "Epoch 14110, Training-Loss 2.1622e+03, Data-loss 3.9194e+02                  , pde-loss 1.2224e+03, initc-loss 1.4575e+04                    bc_loss 1.7687e+07\n",
      "Epoch 14120, Training-Loss 2.1537e+03, Data-loss 3.7532e+02                  , pde-loss 1.2372e+03, initc-loss 1.4121e+04                    bc_loss 1.7769e+07\n",
      "Epoch 14130, Training-Loss 2.2418e+03, Data-loss 4.5412e+02                  , pde-loss 1.2659e+03, initc-loss 1.3705e+04                    bc_loss 1.7862e+07\n",
      "Epoch 14140, Training-Loss 2.0616e+03, Data-loss 2.7640e+02                  , pde-loss 1.0992e+03, initc-loss 1.4225e+04                    bc_loss 1.7836e+07\n",
      "Epoch 14150, Training-Loss 2.1112e+03, Data-loss 3.4821e+02                  , pde-loss 1.1724e+03, initc-loss 1.4204e+04                    bc_loss 1.7615e+07\n",
      "Epoch 14160, Training-Loss 2.1174e+03, Data-loss 3.6617e+02                  , pde-loss 1.3784e+03, initc-loss 1.4727e+04                    bc_loss 1.7497e+07\n",
      "Epoch 14170, Training-Loss 2.0807e+03, Data-loss 3.4065e+02                  , pde-loss 1.3212e+03, initc-loss 1.5355e+04                    bc_loss 1.7383e+07\n",
      "Epoch 14180, Training-Loss 1.9879e+03, Data-loss 2.4772e+02                  , pde-loss 1.5259e+03, initc-loss 1.5246e+04                    bc_loss 1.7385e+07\n",
      "Epoch 14190, Training-Loss 2.1617e+03, Data-loss 4.0193e+02                  , pde-loss 1.2397e+03, initc-loss 1.4570e+04                    bc_loss 1.7582e+07\n",
      "Epoch 14200, Training-Loss 2.1436e+03, Data-loss 3.6735e+02                  , pde-loss 1.1608e+03, initc-loss 1.4109e+04                    bc_loss 1.7747e+07\n",
      "Epoch 14210, Training-Loss 2.1894e+03, Data-loss 4.1780e+02                  , pde-loss 1.3818e+03, initc-loss 1.4406e+04                    bc_loss 1.7701e+07\n",
      "Epoch 14220, Training-Loss 2.0355e+03, Data-loss 2.6777e+02                  , pde-loss 1.1810e+03, initc-loss 1.4549e+04                    bc_loss 1.7661e+07\n",
      "Epoch 14230, Training-Loss 2.0349e+03, Data-loss 2.5529e+02                  , pde-loss 1.3782e+03, initc-loss 1.4365e+04                    bc_loss 1.7780e+07\n",
      "Epoch 14240, Training-Loss 2.2783e+03, Data-loss 4.9450e+02                  , pde-loss 9.3806e+02, initc-loss 1.4429e+04                    bc_loss 1.7823e+07\n",
      "Epoch 14250, Training-Loss 2.1595e+03, Data-loss 3.8635e+02                  , pde-loss 1.1142e+03, initc-loss 1.4503e+04                    bc_loss 1.7716e+07\n",
      "Epoch 14260, Training-Loss 2.0386e+03, Data-loss 2.4725e+02                  , pde-loss 1.4193e+03, initc-loss 1.3915e+04                    bc_loss 1.7898e+07\n",
      "Epoch 14270, Training-Loss 2.1636e+03, Data-loss 3.7144e+02                  , pde-loss 1.1564e+03, initc-loss 1.3676e+04                    bc_loss 1.7907e+07\n",
      "Epoch 14280, Training-Loss 2.0495e+03, Data-loss 2.9387e+02                  , pde-loss 1.3789e+03, initc-loss 1.4713e+04                    bc_loss 1.7541e+07\n",
      "Epoch 14290, Training-Loss 2.1127e+03, Data-loss 3.4926e+02                  , pde-loss 1.3598e+03, initc-loss 1.4252e+04                    bc_loss 1.7619e+07\n",
      "Epoch 14300, Training-Loss 2.1746e+03, Data-loss 4.0722e+02                  , pde-loss 1.1087e+03, initc-loss 1.4617e+04                    bc_loss 1.7658e+07\n",
      "Epoch 14310, Training-Loss 2.2024e+03, Data-loss 4.2462e+02                  , pde-loss 1.1129e+03, initc-loss 1.4094e+04                    bc_loss 1.7763e+07\n",
      "Epoch 14320, Training-Loss 2.0197e+03, Data-loss 2.3808e+02                  , pde-loss 1.2009e+03, initc-loss 1.4216e+04                    bc_loss 1.7801e+07\n",
      "Epoch 14330, Training-Loss 2.0550e+03, Data-loss 2.8293e+02                  , pde-loss 1.3394e+03, initc-loss 1.4361e+04                    bc_loss 1.7705e+07\n",
      "Epoch 14340, Training-Loss 2.0542e+03, Data-loss 2.7813e+02                  , pde-loss 1.2689e+03, initc-loss 1.4233e+04                    bc_loss 1.7745e+07\n",
      "Epoch 14350, Training-Loss 2.0338e+03, Data-loss 2.7328e+02                  , pde-loss 1.4235e+03, initc-loss 1.4654e+04                    bc_loss 1.7589e+07\n",
      "Epoch 14360, Training-Loss 2.0049e+03, Data-loss 2.4285e+02                  , pde-loss 1.1547e+03, initc-loss 1.4486e+04                    bc_loss 1.7604e+07\n",
      "Epoch 14370, Training-Loss 2.1447e+03, Data-loss 3.8188e+02                  , pde-loss 1.3304e+03, initc-loss 1.4527e+04                    bc_loss 1.7612e+07\n",
      "Epoch 14380, Training-Loss 2.0710e+03, Data-loss 3.1191e+02                  , pde-loss 1.4607e+03, initc-loss 1.4742e+04                    bc_loss 1.7574e+07\n",
      "Epoch 14390, Training-Loss 2.1307e+03, Data-loss 3.6029e+02                  , pde-loss 1.2696e+03, initc-loss 1.4099e+04                    bc_loss 1.7689e+07\n",
      "Epoch 14400, Training-Loss 2.0305e+03, Data-loss 2.5770e+02                  , pde-loss 1.1374e+03, initc-loss 1.4725e+04                    bc_loss 1.7712e+07\n",
      "Epoch 14410, Training-Loss 2.1311e+03, Data-loss 3.5809e+02                  , pde-loss 1.1423e+03, initc-loss 1.4414e+04                    bc_loss 1.7714e+07\n",
      "Epoch 14420, Training-Loss 2.0407e+03, Data-loss 2.4588e+02                  , pde-loss 1.3251e+03, initc-loss 1.3823e+04                    bc_loss 1.7933e+07\n",
      "Epoch 14430, Training-Loss 2.1820e+03, Data-loss 3.9388e+02                  , pde-loss 1.3165e+03, initc-loss 1.3656e+04                    bc_loss 1.7866e+07\n",
      "Epoch 14440, Training-Loss 1.9864e+03, Data-loss 2.0897e+02                  , pde-loss 1.0139e+03, initc-loss 1.4340e+04                    bc_loss 1.7759e+07\n",
      "Epoch 14450, Training-Loss 2.1581e+03, Data-loss 3.7652e+02                  , pde-loss 1.3751e+03, initc-loss 1.3930e+04                    bc_loss 1.7801e+07\n",
      "Epoch 14460, Training-Loss 2.0592e+03, Data-loss 2.9120e+02                  , pde-loss 1.2476e+03, initc-loss 1.4352e+04                    bc_loss 1.7664e+07\n",
      "Epoch 14470, Training-Loss 2.1096e+03, Data-loss 3.3940e+02                  , pde-loss 1.1495e+03, initc-loss 1.4426e+04                    bc_loss 1.7686e+07\n",
      "Epoch 14480, Training-Loss 2.1661e+03, Data-loss 3.8003e+02                  , pde-loss 1.0755e+03, initc-loss 1.3902e+04                    bc_loss 1.7846e+07\n",
      "Epoch 14490, Training-Loss 2.0749e+03, Data-loss 2.7826e+02                  , pde-loss 1.1746e+03, initc-loss 1.3517e+04                    bc_loss 1.7952e+07\n",
      "Epoch 14500, Training-Loss 2.2026e+03, Data-loss 4.1109e+02                  , pde-loss 1.3164e+03, initc-loss 1.3880e+04                    bc_loss 1.7900e+07\n",
      "Epoch 14510, Training-Loss 2.1215e+03, Data-loss 3.4988e+02                  , pde-loss 1.1033e+03, initc-loss 1.4596e+04                    bc_loss 1.7700e+07\n",
      "Epoch 14520, Training-Loss 2.0995e+03, Data-loss 3.2406e+02                  , pde-loss 1.2480e+03, initc-loss 1.4267e+04                    bc_loss 1.7738e+07\n",
      "Epoch 14530, Training-Loss 2.0329e+03, Data-loss 2.3777e+02                  , pde-loss 1.3851e+03, initc-loss 1.3815e+04                    bc_loss 1.7936e+07\n",
      "Epoch 14540, Training-Loss 2.0732e+03, Data-loss 3.0662e+02                  , pde-loss 1.3462e+03, initc-loss 1.4668e+04                    bc_loss 1.7650e+07\n",
      "Epoch 14550, Training-Loss 1.9728e+03, Data-loss 2.1135e+02                  , pde-loss 1.5727e+03, initc-loss 1.4375e+04                    bc_loss 1.7599e+07\n",
      "Epoch 14560, Training-Loss 2.0405e+03, Data-loss 2.8374e+02                  , pde-loss 1.4207e+03, initc-loss 1.4919e+04                    bc_loss 1.7551e+07\n",
      "Epoch 14570, Training-Loss 2.1265e+03, Data-loss 3.4911e+02                  , pde-loss 1.3776e+03, initc-loss 1.4096e+04                    bc_loss 1.7758e+07\n",
      "Epoch 14580, Training-Loss 2.1087e+03, Data-loss 3.3123e+02                  , pde-loss 1.3278e+03, initc-loss 1.4138e+04                    bc_loss 1.7760e+07\n",
      "Epoch 14590, Training-Loss 2.0859e+03, Data-loss 3.1232e+02                  , pde-loss 1.1616e+03, initc-loss 1.4244e+04                    bc_loss 1.7720e+07\n",
      "Epoch 14600, Training-Loss 2.1039e+03, Data-loss 3.2659e+02                  , pde-loss 1.4814e+03, initc-loss 1.4158e+04                    bc_loss 1.7757e+07\n",
      "Epoch 14610, Training-Loss 2.1284e+03, Data-loss 3.5645e+02                  , pde-loss 1.6800e+03, initc-loss 1.4311e+04                    bc_loss 1.7703e+07\n",
      "Epoch 14620, Training-Loss 2.0897e+03, Data-loss 3.3420e+02                  , pde-loss 1.3663e+03, initc-loss 1.4956e+04                    bc_loss 1.7539e+07\n",
      "Epoch 14630, Training-Loss 2.0978e+03, Data-loss 3.3032e+02                  , pde-loss 1.3237e+03, initc-loss 1.4397e+04                    bc_loss 1.7659e+07\n",
      "Epoch 14640, Training-Loss 2.0754e+03, Data-loss 3.0815e+02                  , pde-loss 1.3038e+03, initc-loss 1.4651e+04                    bc_loss 1.7657e+07\n",
      "Epoch 14650, Training-Loss 1.9865e+03, Data-loss 2.1950e+02                  , pde-loss 1.3108e+03, initc-loss 1.4364e+04                    bc_loss 1.7654e+07\n",
      "Epoch 14660, Training-Loss 2.1362e+03, Data-loss 3.6508e+02                  , pde-loss 1.2655e+03, initc-loss 1.4213e+04                    bc_loss 1.7696e+07\n",
      "Epoch 14670, Training-Loss 2.0664e+03, Data-loss 2.9386e+02                  , pde-loss 1.5221e+03, initc-loss 1.4116e+04                    bc_loss 1.7710e+07\n",
      "Epoch 14680, Training-Loss 2.0968e+03, Data-loss 3.3206e+02                  , pde-loss 1.2934e+03, initc-loss 1.4648e+04                    bc_loss 1.7631e+07\n",
      "Epoch 14690, Training-Loss 1.9146e+03, Data-loss 1.4966e+02                  , pde-loss 1.4827e+03, initc-loss 1.4275e+04                    bc_loss 1.7634e+07\n",
      "Epoch 14700, Training-Loss 2.0649e+03, Data-loss 3.0800e+02                  , pde-loss 1.4320e+03, initc-loss 1.5084e+04                    bc_loss 1.7552e+07\n",
      "Epoch 14710, Training-Loss 1.9947e+03, Data-loss 2.3366e+02                  , pde-loss 1.2537e+03, initc-loss 1.4744e+04                    bc_loss 1.7595e+07\n",
      "Epoch 14720, Training-Loss 2.1478e+03, Data-loss 3.9352e+02                  , pde-loss 1.4150e+03, initc-loss 1.4670e+04                    bc_loss 1.7527e+07\n",
      "Epoch 14730, Training-Loss 2.0324e+03, Data-loss 2.7102e+02                  , pde-loss 1.4080e+03, initc-loss 1.4699e+04                    bc_loss 1.7598e+07\n",
      "Epoch 14740, Training-Loss 2.1648e+03, Data-loss 3.9529e+02                  , pde-loss 1.2637e+03, initc-loss 1.4402e+04                    bc_loss 1.7679e+07\n",
      "Epoch 14750, Training-Loss 2.1217e+03, Data-loss 3.5530e+02                  , pde-loss 1.5209e+03, initc-loss 1.4547e+04                    bc_loss 1.7648e+07\n",
      "Epoch 14760, Training-Loss 1.9420e+03, Data-loss 1.7401e+02                  , pde-loss 1.5308e+03, initc-loss 1.4352e+04                    bc_loss 1.7664e+07\n",
      "Epoch 14770, Training-Loss 1.9261e+03, Data-loss 1.4930e+02                  , pde-loss 1.3274e+03, initc-loss 1.4079e+04                    bc_loss 1.7753e+07\n",
      "Epoch 14780, Training-Loss 2.1018e+03, Data-loss 3.2695e+02                  , pde-loss 1.4898e+03, initc-loss 1.4272e+04                    bc_loss 1.7733e+07\n",
      "Epoch 14790, Training-Loss 2.0681e+03, Data-loss 2.8576e+02                  , pde-loss 1.3504e+03, initc-loss 1.4028e+04                    bc_loss 1.7808e+07\n",
      "Epoch 14800, Training-Loss 2.0001e+03, Data-loss 2.2795e+02                  , pde-loss 1.4368e+03, initc-loss 1.4457e+04                    bc_loss 1.7705e+07\n",
      "Epoch 14810, Training-Loss 2.0813e+03, Data-loss 3.0970e+02                  , pde-loss 1.4615e+03, initc-loss 1.4465e+04                    bc_loss 1.7700e+07\n",
      "Epoch 14820, Training-Loss 2.0852e+03, Data-loss 2.9820e+02                  , pde-loss 1.5700e+03, initc-loss 1.3869e+04                    bc_loss 1.7855e+07\n",
      "Epoch 14830, Training-Loss 2.0145e+03, Data-loss 2.2869e+02                  , pde-loss 1.3977e+03, initc-loss 1.3938e+04                    bc_loss 1.7843e+07\n",
      "Epoch 14840, Training-Loss 2.0293e+03, Data-loss 2.3751e+02                  , pde-loss 1.3562e+03, initc-loss 1.3763e+04                    bc_loss 1.7903e+07\n",
      "Epoch 14850, Training-Loss 2.1748e+03, Data-loss 3.8465e+02                  , pde-loss 1.3616e+03, initc-loss 1.3845e+04                    bc_loss 1.7887e+07\n",
      "Epoch 14860, Training-Loss 2.1596e+03, Data-loss 3.7771e+02                  , pde-loss 1.5599e+03, initc-loss 1.4018e+04                    bc_loss 1.7803e+07\n",
      "Epoch 14870, Training-Loss 2.1325e+03, Data-loss 3.3736e+02                  , pde-loss 1.4406e+03, initc-loss 1.3751e+04                    bc_loss 1.7936e+07\n",
      "Epoch 14880, Training-Loss 1.9541e+03, Data-loss 1.6562e+02                  , pde-loss 1.3164e+03, initc-loss 1.3514e+04                    bc_loss 1.7870e+07\n",
      "Epoch 14890, Training-Loss 2.0013e+03, Data-loss 2.2123e+02                  , pde-loss 1.6649e+03, initc-loss 1.4071e+04                    bc_loss 1.7785e+07\n",
      "Epoch 14900, Training-Loss 2.0974e+03, Data-loss 3.0670e+02                  , pde-loss 1.4399e+03, initc-loss 1.3521e+04                    bc_loss 1.7892e+07\n",
      "Epoch 14910, Training-Loss 2.0737e+03, Data-loss 2.7987e+02                  , pde-loss 1.3332e+03, initc-loss 1.3564e+04                    bc_loss 1.7924e+07\n",
      "Epoch 14920, Training-Loss 2.1058e+03, Data-loss 3.2678e+02                  , pde-loss 1.4172e+03, initc-loss 1.4231e+04                    bc_loss 1.7775e+07\n",
      "Epoch 14930, Training-Loss 2.0098e+03, Data-loss 2.2524e+02                  , pde-loss 1.4725e+03, initc-loss 1.4068e+04                    bc_loss 1.7830e+07\n",
      "Epoch 14940, Training-Loss 2.0612e+03, Data-loss 2.9041e+02                  , pde-loss 1.3731e+03, initc-loss 1.4444e+04                    bc_loss 1.7692e+07\n",
      "Epoch 14950, Training-Loss 1.9556e+03, Data-loss 1.7986e+02                  , pde-loss 1.6869e+03, initc-loss 1.4071e+04                    bc_loss 1.7741e+07\n",
      "Epoch 14960, Training-Loss 2.0373e+03, Data-loss 2.8001e+02                  , pde-loss 1.5728e+03, initc-loss 1.4561e+04                    bc_loss 1.7557e+07\n",
      "Epoch 14970, Training-Loss 1.9244e+03, Data-loss 1.4520e+02                  , pde-loss 1.5981e+03, initc-loss 1.3840e+04                    bc_loss 1.7776e+07\n",
      "Epoch 14980, Training-Loss 2.0621e+03, Data-loss 2.7773e+02                  , pde-loss 1.3243e+03, initc-loss 1.3914e+04                    bc_loss 1.7828e+07\n",
      "Epoch 14990, Training-Loss 2.0836e+03, Data-loss 2.9583e+02                  , pde-loss 1.6243e+03, initc-loss 1.3601e+04                    bc_loss 1.7863e+07\n",
      "Epoch 15000, Training-Loss 1.9666e+03, Data-loss 2.1123e+02                  , pde-loss 1.4024e+03, initc-loss 1.4466e+04                    bc_loss 1.7538e+07\n",
      "Epoch 15010, Training-Loss 2.0458e+03, Data-loss 2.7642e+02                  , pde-loss 1.4385e+03, initc-loss 1.3756e+04                    bc_loss 1.7679e+07\n",
      "Epoch 15020, Training-Loss 1.9535e+03, Data-loss 1.9414e+02                  , pde-loss 1.5602e+03, initc-loss 1.4122e+04                    bc_loss 1.7578e+07\n",
      "Epoch 15030, Training-Loss 2.1357e+03, Data-loss 3.5840e+02                  , pde-loss 1.3396e+03, initc-loss 1.3761e+04                    bc_loss 1.7758e+07\n",
      "Epoch 15040, Training-Loss 1.9796e+03, Data-loss 1.8677e+02                  , pde-loss 1.5025e+03, initc-loss 1.3797e+04                    bc_loss 1.7913e+07\n",
      "Epoch 15050, Training-Loss 1.9561e+03, Data-loss 1.5628e+02                  , pde-loss 1.4072e+03, initc-loss 1.3522e+04                    bc_loss 1.7984e+07\n",
      "Epoch 15060, Training-Loss 2.0188e+03, Data-loss 2.4789e+02                  , pde-loss 1.6379e+03, initc-loss 1.4040e+04                    bc_loss 1.7694e+07\n",
      "Epoch 15070, Training-Loss 1.9880e+03, Data-loss 2.1242e+02                  , pde-loss 1.5832e+03, initc-loss 1.3948e+04                    bc_loss 1.7741e+07\n",
      "Epoch 15080, Training-Loss 1.9920e+03, Data-loss 2.1339e+02                  , pde-loss 1.4758e+03, initc-loss 1.3825e+04                    bc_loss 1.7771e+07\n",
      "Epoch 15090, Training-Loss 2.0927e+03, Data-loss 3.2111e+02                  , pde-loss 1.5910e+03, initc-loss 1.3888e+04                    bc_loss 1.7701e+07\n",
      "Epoch 15100, Training-Loss 1.9329e+03, Data-loss 1.7118e+02                  , pde-loss 1.4380e+03, initc-loss 1.4271e+04                    bc_loss 1.7601e+07\n",
      "Epoch 15110, Training-Loss 1.9933e+03, Data-loss 2.1734e+02                  , pde-loss 1.6590e+03, initc-loss 1.3670e+04                    bc_loss 1.7745e+07\n",
      "Epoch 15120, Training-Loss 2.0544e+03, Data-loss 2.9785e+02                  , pde-loss 1.3977e+03, initc-loss 1.4293e+04                    bc_loss 1.7550e+07\n",
      "Epoch 15130, Training-Loss 2.0887e+03, Data-loss 3.1563e+02                  , pde-loss 1.5952e+03, initc-loss 1.3939e+04                    bc_loss 1.7715e+07\n",
      "Epoch 15140, Training-Loss 1.9379e+03, Data-loss 1.7026e+02                  , pde-loss 1.3885e+03, initc-loss 1.3825e+04                    bc_loss 1.7661e+07\n",
      "Epoch 15150, Training-Loss 1.9759e+03, Data-loss 2.0851e+02                  , pde-loss 1.4495e+03, initc-loss 1.4002e+04                    bc_loss 1.7658e+07\n",
      "Epoch 15160, Training-Loss 2.0385e+03, Data-loss 2.6342e+02                  , pde-loss 1.4804e+03, initc-loss 1.3813e+04                    bc_loss 1.7735e+07\n",
      "Epoch 15170, Training-Loss 2.0077e+03, Data-loss 2.4951e+02                  , pde-loss 1.5200e+03, initc-loss 1.4028e+04                    bc_loss 1.7566e+07\n",
      "Epoch 15180, Training-Loss 2.0369e+03, Data-loss 2.8194e+02                  , pde-loss 1.3438e+03, initc-loss 1.3956e+04                    bc_loss 1.7534e+07\n",
      "Epoch 15190, Training-Loss 2.0390e+03, Data-loss 2.7513e+02                  , pde-loss 1.2927e+03, initc-loss 1.3840e+04                    bc_loss 1.7624e+07\n",
      "Epoch 15200, Training-Loss 2.0590e+03, Data-loss 3.0007e+02                  , pde-loss 1.7923e+03, initc-loss 1.4198e+04                    bc_loss 1.7573e+07\n",
      "Epoch 15210, Training-Loss 1.9969e+03, Data-loss 2.4638e+02                  , pde-loss 1.4628e+03, initc-loss 1.4390e+04                    bc_loss 1.7489e+07\n",
      "Epoch 15220, Training-Loss 1.8941e+03, Data-loss 1.3944e+02                  , pde-loss 1.5778e+03, initc-loss 1.4288e+04                    bc_loss 1.7531e+07\n",
      "Epoch 15230, Training-Loss 1.9998e+03, Data-loss 2.4080e+02                  , pde-loss 1.6038e+03, initc-loss 1.3785e+04                    bc_loss 1.7574e+07\n",
      "Epoch 15240, Training-Loss 1.9209e+03, Data-loss 1.5520e+02                  , pde-loss 1.6148e+03, initc-loss 1.3821e+04                    bc_loss 1.7642e+07\n",
      "Epoch 15250, Training-Loss 2.0179e+03, Data-loss 2.6033e+02                  , pde-loss 1.4196e+03, initc-loss 1.3898e+04                    bc_loss 1.7560e+07\n",
      "Epoch 15260, Training-Loss 1.9432e+03, Data-loss 1.6803e+02                  , pde-loss 1.6452e+03, initc-loss 1.3814e+04                    bc_loss 1.7736e+07\n",
      "Epoch 15270, Training-Loss 1.9441e+03, Data-loss 2.0713e+02                  , pde-loss 1.8422e+03, initc-loss 1.4656e+04                    bc_loss 1.7353e+07\n",
      "Epoch 15280, Training-Loss 1.9910e+03, Data-loss 2.4823e+02                  , pde-loss 2.0423e+03, initc-loss 1.4141e+04                    bc_loss 1.7412e+07\n",
      "Epoch 15290, Training-Loss 1.9192e+03, Data-loss 1.7553e+02                  , pde-loss 1.6675e+03, initc-loss 1.3837e+04                    bc_loss 1.7421e+07\n",
      "Epoch 15300, Training-Loss 1.9931e+03, Data-loss 2.5760e+02                  , pde-loss 1.5987e+03, initc-loss 1.4529e+04                    bc_loss 1.7339e+07\n",
      "Epoch 15310, Training-Loss 2.0874e+03, Data-loss 3.6004e+02                  , pde-loss 1.4837e+03, initc-loss 1.4641e+04                    bc_loss 1.7258e+07\n",
      "Epoch 15320, Training-Loss 2.0779e+03, Data-loss 3.5355e+02                  , pde-loss 1.7570e+03, initc-loss 1.4282e+04                    bc_loss 1.7228e+07\n",
      "Epoch 15330, Training-Loss 1.9088e+03, Data-loss 1.9064e+02                  , pde-loss 1.6315e+03, initc-loss 1.4509e+04                    bc_loss 1.7165e+07\n",
      "Epoch 15340, Training-Loss 2.0045e+03, Data-loss 2.5296e+02                  , pde-loss 1.8139e+03, initc-loss 1.3665e+04                    bc_loss 1.7500e+07\n",
      "Epoch 15350, Training-Loss 1.9560e+03, Data-loss 2.2125e+02                  , pde-loss 1.5821e+03, initc-loss 1.3988e+04                    bc_loss 1.7332e+07\n",
      "Epoch 15360, Training-Loss 2.0127e+03, Data-loss 2.7865e+02                  , pde-loss 1.6232e+03, initc-loss 1.3861e+04                    bc_loss 1.7325e+07\n",
      "Epoch 15370, Training-Loss 2.0745e+03, Data-loss 3.5699e+02                  , pde-loss 1.4667e+03, initc-loss 1.4266e+04                    bc_loss 1.7160e+07\n",
      "Epoch 15380, Training-Loss 2.0392e+03, Data-loss 3.0984e+02                  , pde-loss 1.5802e+03, initc-loss 1.4265e+04                    bc_loss 1.7277e+07\n",
      "Epoch 15390, Training-Loss 1.9016e+03, Data-loss 1.9042e+02                  , pde-loss 1.7202e+03, initc-loss 1.4274e+04                    bc_loss 1.7096e+07\n",
      "Epoch 15400, Training-Loss 1.9512e+03, Data-loss 2.3281e+02                  , pde-loss 1.6412e+03, initc-loss 1.4340e+04                    bc_loss 1.7168e+07\n",
      "Epoch 15410, Training-Loss 1.9276e+03, Data-loss 2.0250e+02                  , pde-loss 1.4053e+03, initc-loss 1.4249e+04                    bc_loss 1.7236e+07\n",
      "Epoch 15420, Training-Loss 1.9577e+03, Data-loss 2.2369e+02                  , pde-loss 1.9453e+03, initc-loss 1.4125e+04                    bc_loss 1.7324e+07\n",
      "Epoch 15430, Training-Loss 1.9989e+03, Data-loss 2.4540e+02                  , pde-loss 1.5079e+03, initc-loss 1.3218e+04                    bc_loss 1.7520e+07\n",
      "Epoch 15440, Training-Loss 1.9916e+03, Data-loss 2.5474e+02                  , pde-loss 1.7802e+03, initc-loss 1.4045e+04                    bc_loss 1.7353e+07\n",
      "Epoch 15450, Training-Loss 1.9920e+03, Data-loss 2.5996e+02                  , pde-loss 1.7801e+03, initc-loss 1.3657e+04                    bc_loss 1.7305e+07\n",
      "Epoch 15460, Training-Loss 1.9509e+03, Data-loss 1.9019e+02                  , pde-loss 1.4988e+03, initc-loss 1.3633e+04                    bc_loss 1.7592e+07\n",
      "Epoch 15470, Training-Loss 1.8827e+03, Data-loss 1.5774e+02                  , pde-loss 1.8823e+03, initc-loss 1.4101e+04                    bc_loss 1.7234e+07\n",
      "Epoch 15480, Training-Loss 1.9867e+03, Data-loss 2.6187e+02                  , pde-loss 1.6021e+03, initc-loss 1.3764e+04                    bc_loss 1.7233e+07\n",
      "Epoch 15490, Training-Loss 1.9290e+03, Data-loss 2.0594e+02                  , pde-loss 1.5972e+03, initc-loss 1.3734e+04                    bc_loss 1.7216e+07\n",
      "Epoch 15500, Training-Loss 1.9298e+03, Data-loss 2.3088e+02                  , pde-loss 1.6504e+03, initc-loss 1.4473e+04                    bc_loss 1.6973e+07\n",
      "Epoch 15510, Training-Loss 1.8870e+03, Data-loss 1.8333e+02                  , pde-loss 1.7189e+03, initc-loss 1.4314e+04                    bc_loss 1.7021e+07\n",
      "Epoch 15520, Training-Loss 1.9242e+03, Data-loss 2.1913e+02                  , pde-loss 1.7885e+03, initc-loss 1.4229e+04                    bc_loss 1.7035e+07\n",
      "Epoch 15530, Training-Loss 1.9555e+03, Data-loss 2.4572e+02                  , pde-loss 1.5863e+03, initc-loss 1.3753e+04                    bc_loss 1.7083e+07\n",
      "Epoch 15540, Training-Loss 1.9308e+03, Data-loss 2.4342e+02                  , pde-loss 1.8282e+03, initc-loss 1.4440e+04                    bc_loss 1.6858e+07\n",
      "Epoch 15550, Training-Loss 1.9480e+03, Data-loss 2.5589e+02                  , pde-loss 1.6163e+03, initc-loss 1.4091e+04                    bc_loss 1.6906e+07\n",
      "Epoch 15560, Training-Loss 1.9247e+03, Data-loss 2.1678e+02                  , pde-loss 1.8812e+03, initc-loss 1.3436e+04                    bc_loss 1.7064e+07\n",
      "Epoch 15570, Training-Loss 1.8850e+03, Data-loss 1.7597e+02                  , pde-loss 1.6029e+03, initc-loss 1.3544e+04                    bc_loss 1.7075e+07\n",
      "Epoch 15580, Training-Loss 1.9517e+03, Data-loss 2.5487e+02                  , pde-loss 1.8942e+03, initc-loss 1.3776e+04                    bc_loss 1.6952e+07\n",
      "Epoch 15590, Training-Loss 1.9113e+03, Data-loss 2.0237e+02                  , pde-loss 1.7686e+03, initc-loss 1.3736e+04                    bc_loss 1.7074e+07\n",
      "Epoch 15600, Training-Loss 1.9205e+03, Data-loss 2.3195e+02                  , pde-loss 1.6620e+03, initc-loss 1.4268e+04                    bc_loss 1.6869e+07\n",
      "Epoch 15610, Training-Loss 1.8988e+03, Data-loss 2.1231e+02                  , pde-loss 1.5280e+03, initc-loss 1.4197e+04                    bc_loss 1.6849e+07\n",
      "Epoch 15620, Training-Loss 1.8820e+03, Data-loss 2.2853e+02                  , pde-loss 1.9326e+03, initc-loss 1.5045e+04                    bc_loss 1.6517e+07\n",
      "Epoch 15630, Training-Loss 1.9832e+03, Data-loss 3.3298e+02                  , pde-loss 1.5039e+03, initc-loss 1.4674e+04                    bc_loss 1.6487e+07\n",
      "Epoch 15640, Training-Loss 1.9072e+03, Data-loss 2.4813e+02                  , pde-loss 1.7511e+03, initc-loss 1.4104e+04                    bc_loss 1.6575e+07\n",
      "Epoch 15650, Training-Loss 1.8608e+03, Data-loss 2.1740e+02                  , pde-loss 2.0436e+03, initc-loss 1.4419e+04                    bc_loss 1.6418e+07\n",
      "Epoch 15660, Training-Loss 1.8890e+03, Data-loss 2.7157e+02                  , pde-loss 1.7286e+03, initc-loss 1.4712e+04                    bc_loss 1.6158e+07\n",
      "Epoch 15670, Training-Loss 1.8959e+03, Data-loss 2.5684e+02                  , pde-loss 1.7129e+03, initc-loss 1.4590e+04                    bc_loss 1.6374e+07\n",
      "Epoch 15680, Training-Loss 1.9582e+03, Data-loss 3.3559e+02                  , pde-loss 1.6578e+03, initc-loss 1.5418e+04                    bc_loss 1.6209e+07\n",
      "Epoch 15690, Training-Loss 1.8798e+03, Data-loss 2.3635e+02                  , pde-loss 2.0192e+03, initc-loss 1.4640e+04                    bc_loss 1.6417e+07\n",
      "Epoch 15700, Training-Loss 1.9808e+03, Data-loss 3.7210e+02                  , pde-loss 1.7330e+03, initc-loss 1.4413e+04                    bc_loss 1.6071e+07\n",
      "Epoch 15710, Training-Loss 1.8917e+03, Data-loss 2.8479e+02                  , pde-loss 2.1631e+03, initc-loss 1.4720e+04                    bc_loss 1.6052e+07\n",
      "Epoch 15720, Training-Loss 1.8830e+03, Data-loss 2.4983e+02                  , pde-loss 2.1081e+03, initc-loss 1.4776e+04                    bc_loss 1.6315e+07\n",
      "Epoch 15730, Training-Loss 1.8348e+03, Data-loss 1.7514e+02                  , pde-loss 1.7379e+03, initc-loss 1.3807e+04                    bc_loss 1.6581e+07\n",
      "Epoch 15740, Training-Loss 1.8808e+03, Data-loss 2.4849e+02                  , pde-loss 2.0107e+03, initc-loss 1.4211e+04                    bc_loss 1.6307e+07\n",
      "Epoch 15750, Training-Loss 1.8490e+03, Data-loss 2.3897e+02                  , pde-loss 1.7044e+03, initc-loss 1.4476e+04                    bc_loss 1.6084e+07\n",
      "Epoch 15760, Training-Loss 1.9641e+03, Data-loss 3.6315e+02                  , pde-loss 1.5808e+03, initc-loss 1.4185e+04                    bc_loss 1.5994e+07\n",
      "Epoch 15770, Training-Loss 1.8792e+03, Data-loss 2.7513e+02                  , pde-loss 1.7375e+03, initc-loss 1.4335e+04                    bc_loss 1.6025e+07\n",
      "Epoch 15780, Training-Loss 1.8472e+03, Data-loss 2.3999e+02                  , pde-loss 1.9238e+03, initc-loss 1.4750e+04                    bc_loss 1.6056e+07\n",
      "Epoch 15790, Training-Loss 1.8370e+03, Data-loss 2.1143e+02                  , pde-loss 1.8484e+03, initc-loss 1.3572e+04                    bc_loss 1.6241e+07\n",
      "Epoch 15800, Training-Loss 1.8268e+03, Data-loss 2.4877e+02                  , pde-loss 1.7386e+03, initc-loss 1.4662e+04                    bc_loss 1.5764e+07\n",
      "Epoch 15810, Training-Loss 1.8379e+03, Data-loss 2.5705e+02                  , pde-loss 2.0048e+03, initc-loss 1.4093e+04                    bc_loss 1.5793e+07\n",
      "Epoch 15820, Training-Loss 1.8462e+03, Data-loss 2.7831e+02                  , pde-loss 1.9655e+03, initc-loss 1.4589e+04                    bc_loss 1.5662e+07\n",
      "Epoch 15830, Training-Loss 1.8230e+03, Data-loss 2.2411e+02                  , pde-loss 1.8785e+03, initc-loss 1.4149e+04                    bc_loss 1.5973e+07\n",
      "Epoch 15840, Training-Loss 1.8019e+03, Data-loss 2.3533e+02                  , pde-loss 1.9605e+03, initc-loss 1.4428e+04                    bc_loss 1.5649e+07\n",
      "Epoch 15850, Training-Loss 1.8052e+03, Data-loss 2.6797e+02                  , pde-loss 1.9529e+03, initc-loss 1.4857e+04                    bc_loss 1.5355e+07\n",
      "Epoch 15860, Training-Loss 1.8478e+03, Data-loss 3.4091e+02                  , pde-loss 1.7556e+03, initc-loss 1.5168e+04                    bc_loss 1.5052e+07\n",
      "Epoch 15870, Training-Loss 1.7887e+03, Data-loss 2.1611e+02                  , pde-loss 2.0512e+03, initc-loss 1.3804e+04                    bc_loss 1.5711e+07\n",
      "Epoch 15880, Training-Loss 1.8492e+03, Data-loss 2.8028e+02                  , pde-loss 1.8528e+03, initc-loss 1.3900e+04                    bc_loss 1.5674e+07\n",
      "Epoch 15890, Training-Loss 1.7960e+03, Data-loss 2.2314e+02                  , pde-loss 1.6413e+03, initc-loss 1.3471e+04                    bc_loss 1.5714e+07\n",
      "Epoch 15900, Training-Loss 1.8354e+03, Data-loss 2.9389e+02                  , pde-loss 1.5772e+03, initc-loss 1.3901e+04                    bc_loss 1.5400e+07\n",
      "Epoch 15910, Training-Loss 1.8092e+03, Data-loss 2.7181e+02                  , pde-loss 1.9188e+03, initc-loss 1.4672e+04                    bc_loss 1.5357e+07\n",
      "Epoch 15920, Training-Loss 1.8129e+03, Data-loss 2.9675e+02                  , pde-loss 2.2777e+03, initc-loss 1.4655e+04                    bc_loss 1.5145e+07\n",
      "Epoch 15930, Training-Loss 1.8286e+03, Data-loss 3.4192e+02                  , pde-loss 1.6560e+03, initc-loss 1.4928e+04                    bc_loss 1.4850e+07\n",
      "Epoch 15940, Training-Loss 1.8044e+03, Data-loss 2.9885e+02                  , pde-loss 1.8251e+03, initc-loss 1.4878e+04                    bc_loss 1.5039e+07\n",
      "Epoch 15950, Training-Loss 1.8461e+03, Data-loss 3.3078e+02                  , pde-loss 1.5870e+03, initc-loss 1.4144e+04                    bc_loss 1.5138e+07\n",
      "Epoch 15960, Training-Loss 1.9029e+03, Data-loss 3.7869e+02                  , pde-loss 1.8850e+03, initc-loss 1.4406e+04                    bc_loss 1.5226e+07\n",
      "Epoch 15970, Training-Loss 1.8152e+03, Data-loss 3.1092e+02                  , pde-loss 2.2988e+03, initc-loss 1.5119e+04                    bc_loss 1.5025e+07\n",
      "Epoch 15980, Training-Loss 1.7872e+03, Data-loss 2.9448e+02                  , pde-loss 2.0104e+03, initc-loss 1.4267e+04                    bc_loss 1.4911e+07\n",
      "Epoch 15990, Training-Loss 1.8247e+03, Data-loss 3.4320e+02                  , pde-loss 1.9816e+03, initc-loss 1.4564e+04                    bc_loss 1.4798e+07\n",
      "Epoch 16000, Training-Loss 1.6992e+03, Data-loss 1.9007e+02                  , pde-loss 2.1343e+03, initc-loss 1.3738e+04                    bc_loss 1.5075e+07\n",
      "Epoch 16010, Training-Loss 1.7210e+03, Data-loss 2.3803e+02                  , pde-loss 1.9196e+03, initc-loss 1.4029e+04                    bc_loss 1.4814e+07\n",
      "Epoch 16020, Training-Loss 1.7728e+03, Data-loss 3.1136e+02                  , pde-loss 2.1606e+03, initc-loss 1.5147e+04                    bc_loss 1.4597e+07\n",
      "Epoch 16030, Training-Loss 1.8821e+03, Data-loss 4.2616e+02                  , pde-loss 2.1213e+03, initc-loss 1.4484e+04                    bc_loss 1.4543e+07\n",
      "Epoch 16040, Training-Loss 1.6953e+03, Data-loss 2.5034e+02                  , pde-loss 1.8377e+03, initc-loss 1.4881e+04                    bc_loss 1.4433e+07\n",
      "Epoch 16050, Training-Loss 1.8368e+03, Data-loss 3.9493e+02                  , pde-loss 2.1427e+03, initc-loss 1.4650e+04                    bc_loss 1.4402e+07\n",
      "Epoch 16060, Training-Loss 1.8001e+03, Data-loss 3.0958e+02                  , pde-loss 1.5866e+03, initc-loss 1.3765e+04                    bc_loss 1.4890e+07\n",
      "Epoch 16070, Training-Loss 1.6611e+03, Data-loss 2.1149e+02                  , pde-loss 2.0761e+03, initc-loss 1.3913e+04                    bc_loss 1.4480e+07\n",
      "Epoch 16080, Training-Loss 1.6679e+03, Data-loss 2.4592e+02                  , pde-loss 1.8419e+03, initc-loss 1.4457e+04                    bc_loss 1.4204e+07\n",
      "Epoch 16090, Training-Loss 1.6716e+03, Data-loss 2.2142e+02                  , pde-loss 2.0077e+03, initc-loss 1.3669e+04                    bc_loss 1.4486e+07\n",
      "Epoch 16100, Training-Loss 1.7331e+03, Data-loss 2.8393e+02                  , pde-loss 1.7941e+03, initc-loss 1.4098e+04                    bc_loss 1.4476e+07\n",
      "Epoch 16110, Training-Loss 1.7220e+03, Data-loss 2.7858e+02                  , pde-loss 1.9635e+03, initc-loss 1.4629e+04                    bc_loss 1.4418e+07\n",
      "Epoch 16120, Training-Loss 1.6982e+03, Data-loss 3.1920e+02                  , pde-loss 1.9688e+03, initc-loss 1.4795e+04                    bc_loss 1.3773e+07\n",
      "Epoch 16130, Training-Loss 1.7438e+03, Data-loss 3.2614e+02                  , pde-loss 2.1212e+03, initc-loss 1.3459e+04                    bc_loss 1.4161e+07\n",
      "Epoch 16140, Training-Loss 1.7100e+03, Data-loss 2.7355e+02                  , pde-loss 1.7719e+03, initc-loss 1.3702e+04                    bc_loss 1.4349e+07\n",
      "Epoch 16150, Training-Loss 1.7716e+03, Data-loss 3.2948e+02                  , pde-loss 2.0170e+03, initc-loss 1.3813e+04                    bc_loss 1.4405e+07\n",
      "Epoch 16160, Training-Loss 1.7078e+03, Data-loss 2.8669e+02                  , pde-loss 2.3212e+03, initc-loss 1.3630e+04                    bc_loss 1.4195e+07\n",
      "Epoch 16170, Training-Loss 1.6590e+03, Data-loss 3.0142e+02                  , pde-loss 2.1626e+03, initc-loss 1.4860e+04                    bc_loss 1.3559e+07\n",
      "Epoch 16180, Training-Loss 1.7849e+03, Data-loss 4.8950e+02                  , pde-loss 2.2423e+03, initc-loss 1.6161e+04                    bc_loss 1.2936e+07\n",
      "Epoch 16190, Training-Loss 1.7354e+03, Data-loss 4.1725e+02                  , pde-loss 3.0916e+03, initc-loss 1.5178e+04                    bc_loss 1.3163e+07\n",
      "Epoch 16200, Training-Loss 1.6633e+03, Data-loss 3.4465e+02                  , pde-loss 2.3665e+03, initc-loss 1.5007e+04                    bc_loss 1.3169e+07\n",
      "Epoch 16210, Training-Loss 1.6982e+03, Data-loss 3.8210e+02                  , pde-loss 2.3882e+03, initc-loss 1.5692e+04                    bc_loss 1.3143e+07\n",
      "Epoch 16220, Training-Loss 1.5589e+03, Data-loss 2.5660e+02                  , pde-loss 1.8784e+03, initc-loss 1.5055e+04                    bc_loss 1.3006e+07\n",
      "Epoch 16230, Training-Loss 1.7030e+03, Data-loss 3.9704e+02                  , pde-loss 1.8140e+03, initc-loss 1.4928e+04                    bc_loss 1.3043e+07\n",
      "Epoch 16240, Training-Loss 1.6181e+03, Data-loss 3.2767e+02                  , pde-loss 2.1393e+03, initc-loss 1.4906e+04                    bc_loss 1.2887e+07\n",
      "Epoch 16250, Training-Loss 1.6407e+03, Data-loss 3.6399e+02                  , pde-loss 2.3067e+03, initc-loss 1.4906e+04                    bc_loss 1.2750e+07\n",
      "Epoch 16260, Training-Loss 1.6324e+03, Data-loss 2.7805e+02                  , pde-loss 2.1960e+03, initc-loss 1.4380e+04                    bc_loss 1.3526e+07\n",
      "Epoch 16270, Training-Loss 1.7572e+03, Data-loss 4.3145e+02                  , pde-loss 2.3162e+03, initc-loss 1.4473e+04                    bc_loss 1.3241e+07\n",
      "Epoch 16280, Training-Loss 1.5884e+03, Data-loss 3.2694e+02                  , pde-loss 1.9527e+03, initc-loss 1.5733e+04                    bc_loss 1.2596e+07\n",
      "Epoch 16290, Training-Loss 1.6609e+03, Data-loss 3.5665e+02                  , pde-loss 2.0962e+03, initc-loss 1.3986e+04                    bc_loss 1.3026e+07\n",
      "Epoch 16300, Training-Loss 1.8006e+03, Data-loss 5.2475e+02                  , pde-loss 2.4566e+03, initc-loss 1.4674e+04                    bc_loss 1.2742e+07\n",
      "Epoch 16310, Training-Loss 1.5893e+03, Data-loss 2.7989e+02                  , pde-loss 2.1363e+03, initc-loss 1.4001e+04                    bc_loss 1.3078e+07\n",
      "Epoch 16320, Training-Loss 1.6126e+03, Data-loss 2.8793e+02                  , pde-loss 2.0513e+03, initc-loss 1.3863e+04                    bc_loss 1.3231e+07\n",
      "Epoch 16330, Training-Loss 1.6449e+03, Data-loss 3.3054e+02                  , pde-loss 1.7963e+03, initc-loss 1.3302e+04                    bc_loss 1.3129e+07\n",
      "Epoch 16340, Training-Loss 1.6399e+03, Data-loss 3.2661e+02                  , pde-loss 1.8200e+03, initc-loss 1.3793e+04                    bc_loss 1.3118e+07\n",
      "Epoch 16350, Training-Loss 1.6086e+03, Data-loss 2.8418e+02                  , pde-loss 2.7279e+03, initc-loss 1.3386e+04                    bc_loss 1.3228e+07\n",
      "Epoch 16360, Training-Loss 1.5915e+03, Data-loss 2.6784e+02                  , pde-loss 2.0200e+03, initc-loss 1.2852e+04                    bc_loss 1.3221e+07\n",
      "Epoch 16370, Training-Loss 1.6068e+03, Data-loss 3.1927e+02                  , pde-loss 2.4882e+03, initc-loss 1.3814e+04                    bc_loss 1.2859e+07\n",
      "Epoch 16380, Training-Loss 1.6553e+03, Data-loss 3.7045e+02                  , pde-loss 2.0314e+03, initc-loss 1.3408e+04                    bc_loss 1.2833e+07\n",
      "Epoch 16390, Training-Loss 1.6476e+03, Data-loss 3.4399e+02                  , pde-loss 2.1449e+03, initc-loss 1.3599e+04                    bc_loss 1.3020e+07\n",
      "Epoch 16400, Training-Loss 1.5889e+03, Data-loss 3.7866e+02                  , pde-loss 2.0731e+03, initc-loss 1.4343e+04                    bc_loss 1.2086e+07\n",
      "Epoch 16410, Training-Loss 1.5747e+03, Data-loss 3.8756e+02                  , pde-loss 2.2254e+03, initc-loss 1.5942e+04                    bc_loss 1.1854e+07\n",
      "Epoch 16420, Training-Loss 1.6683e+03, Data-loss 4.7835e+02                  , pde-loss 2.2846e+03, initc-loss 1.4935e+04                    bc_loss 1.1882e+07\n",
      "Epoch 16430, Training-Loss 1.7139e+03, Data-loss 4.9692e+02                  , pde-loss 3.0258e+03, initc-loss 1.5090e+04                    bc_loss 1.2152e+07\n",
      "Epoch 16440, Training-Loss 1.7378e+03, Data-loss 5.6789e+02                  , pde-loss 2.2263e+03, initc-loss 1.6754e+04                    bc_loss 1.1680e+07\n",
      "Epoch 16450, Training-Loss 1.5284e+03, Data-loss 3.6823e+02                  , pde-loss 1.9901e+03, initc-loss 1.4849e+04                    bc_loss 1.1585e+07\n",
      "Epoch 16460, Training-Loss 1.6291e+03, Data-loss 4.8761e+02                  , pde-loss 2.2616e+03, initc-loss 1.4968e+04                    bc_loss 1.1397e+07\n",
      "Epoch 16470, Training-Loss 1.5617e+03, Data-loss 4.0012e+02                  , pde-loss 2.3365e+03, initc-loss 1.5772e+04                    bc_loss 1.1598e+07\n",
      "Epoch 16480, Training-Loss 1.5928e+03, Data-loss 3.9986e+02                  , pde-loss 2.4849e+03, initc-loss 1.4219e+04                    bc_loss 1.1913e+07\n",
      "Epoch 16490, Training-Loss 1.6612e+03, Data-loss 5.1489e+02                  , pde-loss 2.4544e+03, initc-loss 1.6575e+04                    bc_loss 1.1444e+07\n",
      "Epoch 16500, Training-Loss 1.6358e+03, Data-loss 4.7923e+02                  , pde-loss 3.3425e+03, initc-loss 1.6370e+04                    bc_loss 1.1546e+07\n",
      "Epoch 16510, Training-Loss 1.6305e+03, Data-loss 4.4090e+02                  , pde-loss 2.3921e+03, initc-loss 1.4912e+04                    bc_loss 1.1878e+07\n",
      "Epoch 16520, Training-Loss 1.5304e+03, Data-loss 3.8288e+02                  , pde-loss 2.3910e+03, initc-loss 1.5229e+04                    bc_loss 1.1457e+07\n",
      "Epoch 16530, Training-Loss 1.4613e+03, Data-loss 3.2494e+02                  , pde-loss 2.3195e+03, initc-loss 1.5403e+04                    bc_loss 1.1345e+07\n",
      "Epoch 16540, Training-Loss 1.5088e+03, Data-loss 3.7021e+02                  , pde-loss 2.3026e+03, initc-loss 1.5609e+04                    bc_loss 1.1368e+07\n",
      "Epoch 16550, Training-Loss 1.5548e+03, Data-loss 4.2369e+02                  , pde-loss 2.3334e+03, initc-loss 1.4542e+04                    bc_loss 1.1294e+07\n",
      "Epoch 16560, Training-Loss 1.4682e+03, Data-loss 3.1857e+02                  , pde-loss 2.7396e+03, initc-loss 1.4293e+04                    bc_loss 1.1479e+07\n",
      "Epoch 16570, Training-Loss 1.5138e+03, Data-loss 3.7477e+02                  , pde-loss 2.0873e+03, initc-loss 1.4781e+04                    bc_loss 1.1374e+07\n",
      "Epoch 16580, Training-Loss 1.5799e+03, Data-loss 5.0900e+02                  , pde-loss 2.2668e+03, initc-loss 1.6257e+04                    bc_loss 1.0691e+07\n",
      "Epoch 16590, Training-Loss 1.5489e+03, Data-loss 4.6534e+02                  , pde-loss 2.7322e+03, initc-loss 1.6325e+04                    bc_loss 1.0816e+07\n",
      "Epoch 16600, Training-Loss 1.4752e+03, Data-loss 3.6364e+02                  , pde-loss 2.9639e+03, initc-loss 1.4586e+04                    bc_loss 1.1098e+07\n",
      "Epoch 16610, Training-Loss 1.4418e+03, Data-loss 2.5639e+02                  , pde-loss 2.1112e+03, initc-loss 1.3542e+04                    bc_loss 1.1839e+07\n",
      "Epoch 16620, Training-Loss 1.5517e+03, Data-loss 4.2477e+02                  , pde-loss 2.6015e+03, initc-loss 1.4943e+04                    bc_loss 1.1252e+07\n",
      "Epoch 16630, Training-Loss 1.7557e+03, Data-loss 6.1022e+02                  , pde-loss 2.7792e+03, initc-loss 1.4012e+04                    bc_loss 1.1438e+07\n",
      "Epoch 16640, Training-Loss 1.4461e+03, Data-loss 2.5332e+02                  , pde-loss 1.9955e+03, initc-loss 1.3456e+04                    bc_loss 1.1912e+07\n",
      "Epoch 16650, Training-Loss 1.5803e+03, Data-loss 4.8078e+02                  , pde-loss 2.6971e+03, initc-loss 1.4378e+04                    bc_loss 1.0978e+07\n",
      "Epoch 16660, Training-Loss 1.6094e+03, Data-loss 5.8640e+02                  , pde-loss 2.2434e+03, initc-loss 1.5858e+04                    bc_loss 1.0212e+07\n",
      "Epoch 16670, Training-Loss 1.4469e+03, Data-loss 4.2577e+02                  , pde-loss 2.6068e+03, initc-loss 1.4528e+04                    bc_loss 1.0194e+07\n",
      "Epoch 16680, Training-Loss 1.5449e+03, Data-loss 4.7519e+02                  , pde-loss 2.5627e+03, initc-loss 1.4679e+04                    bc_loss 1.0680e+07\n",
      "Epoch 16690, Training-Loss 1.4858e+03, Data-loss 3.8538e+02                  , pde-loss 2.2500e+03, initc-loss 1.5078e+04                    bc_loss 1.0987e+07\n",
      "Epoch 16700, Training-Loss 1.5356e+03, Data-loss 4.7180e+02                  , pde-loss 2.5471e+03, initc-loss 1.4549e+04                    bc_loss 1.0621e+07\n",
      "Epoch 16710, Training-Loss 1.6009e+03, Data-loss 4.5571e+02                  , pde-loss 2.3496e+03, initc-loss 1.3722e+04                    bc_loss 1.1436e+07\n",
      "Epoch 16720, Training-Loss 1.6404e+03, Data-loss 5.0795e+02                  , pde-loss 2.2283e+03, initc-loss 1.3544e+04                    bc_loss 1.1308e+07\n",
      "Epoch 16730, Training-Loss 1.4294e+03, Data-loss 3.7613e+02                  , pde-loss 2.7285e+03, initc-loss 1.4839e+04                    bc_loss 1.0515e+07\n",
      "Epoch 16740, Training-Loss 1.4091e+03, Data-loss 3.5342e+02                  , pde-loss 2.0711e+03, initc-loss 1.5539e+04                    bc_loss 1.0539e+07\n",
      "Epoch 16750, Training-Loss 1.2991e+03, Data-loss 1.9409e+02                  , pde-loss 2.2202e+03, initc-loss 1.4102e+04                    bc_loss 1.1034e+07\n",
      "Epoch 16760, Training-Loss 1.4410e+03, Data-loss 3.4544e+02                  , pde-loss 2.3908e+03, initc-loss 1.3148e+04                    bc_loss 1.0940e+07\n",
      "Epoch 16770, Training-Loss 1.5269e+03, Data-loss 4.2809e+02                  , pde-loss 2.7299e+03, initc-loss 1.3680e+04                    bc_loss 1.0972e+07\n",
      "Epoch 16780, Training-Loss 1.3225e+03, Data-loss 2.8638e+02                  , pde-loss 2.6343e+03, initc-loss 1.4322e+04                    bc_loss 1.0344e+07\n",
      "Epoch 16790, Training-Loss 1.4730e+03, Data-loss 4.3576e+02                  , pde-loss 2.3520e+03, initc-loss 1.4074e+04                    bc_loss 1.0356e+07\n",
      "Epoch 16800, Training-Loss 1.4639e+03, Data-loss 3.2074e+02                  , pde-loss 2.1979e+03, initc-loss 1.2755e+04                    bc_loss 1.1417e+07\n",
      "Epoch 16810, Training-Loss 1.3964e+03, Data-loss 3.7073e+02                  , pde-loss 2.5109e+03, initc-loss 1.4519e+04                    bc_loss 1.0240e+07\n",
      "Epoch 16820, Training-Loss 1.5667e+03, Data-loss 5.6902e+02                  , pde-loss 2.6647e+03, initc-loss 1.5613e+04                    bc_loss 9.9583e+06\n",
      "Epoch 16830, Training-Loss 1.4982e+03, Data-loss 4.1389e+02                  , pde-loss 2.6167e+03, initc-loss 1.3302e+04                    bc_loss 1.0827e+07\n",
      "Epoch 16840, Training-Loss 1.4257e+03, Data-loss 3.5554e+02                  , pde-loss 2.2245e+03, initc-loss 1.4285e+04                    bc_loss 1.0686e+07\n",
      "Epoch 16850, Training-Loss 1.2990e+03, Data-loss 2.2788e+02                  , pde-loss 2.1996e+03, initc-loss 1.5239e+04                    bc_loss 1.0694e+07\n",
      "Epoch 16860, Training-Loss 1.4357e+03, Data-loss 4.2798e+02                  , pde-loss 2.7309e+03, initc-loss 1.5511e+04                    bc_loss 1.0059e+07\n",
      "Epoch 16870, Training-Loss 1.2849e+03, Data-loss 3.0009e+02                  , pde-loss 2.0664e+03, initc-loss 1.5419e+04                    bc_loss 9.8303e+06\n",
      "Epoch 16880, Training-Loss 1.3478e+03, Data-loss 3.9190e+02                  , pde-loss 2.5139e+03, initc-loss 1.5513e+04                    bc_loss 9.5412e+06\n",
      "Epoch 16890, Training-Loss 1.4140e+03, Data-loss 4.0904e+02                  , pde-loss 2.2781e+03, initc-loss 1.4178e+04                    bc_loss 1.0033e+07\n",
      "Epoch 16900, Training-Loss 1.5868e+03, Data-loss 5.5675e+02                  , pde-loss 2.5156e+03, initc-loss 1.2300e+04                    bc_loss 1.0286e+07\n",
      "Epoch 16910, Training-Loss 1.5793e+03, Data-loss 5.7702e+02                  , pde-loss 2.2493e+03, initc-loss 1.1655e+04                    bc_loss 1.0008e+07\n",
      "Epoch 16920, Training-Loss 1.4114e+03, Data-loss 5.1768e+02                  , pde-loss 2.5968e+03, initc-loss 1.5378e+04                    bc_loss 8.9189e+06\n",
      "Epoch 16930, Training-Loss 1.3281e+03, Data-loss 3.9157e+02                  , pde-loss 2.5042e+03, initc-loss 1.4500e+04                    bc_loss 9.3486e+06\n",
      "Epoch 16940, Training-Loss 1.3422e+03, Data-loss 3.9789e+02                  , pde-loss 2.8667e+03, initc-loss 1.5635e+04                    bc_loss 9.4242e+06\n",
      "Epoch 16950, Training-Loss 1.3915e+03, Data-loss 4.4505e+02                  , pde-loss 2.0441e+03, initc-loss 1.4557e+04                    bc_loss 9.4476e+06\n",
      "Epoch 16960, Training-Loss 1.4588e+03, Data-loss 4.1744e+02                  , pde-loss 2.3793e+03, initc-loss 1.3160e+04                    bc_loss 1.0398e+07\n",
      "Epoch 16970, Training-Loss 1.2672e+03, Data-loss 3.7328e+02                  , pde-loss 2.1042e+03, initc-loss 1.4543e+04                    bc_loss 8.9227e+06\n",
      "Epoch 16980, Training-Loss 1.3035e+03, Data-loss 4.6561e+02                  , pde-loss 2.5720e+03, initc-loss 1.6276e+04                    bc_loss 8.3603e+06\n",
      "Epoch 16990, Training-Loss 1.4914e+03, Data-loss 6.2593e+02                  , pde-loss 2.6507e+03, initc-loss 1.5170e+04                    bc_loss 8.6369e+06\n",
      "Epoch 17000, Training-Loss 1.4308e+03, Data-loss 5.5822e+02                  , pde-loss 2.2902e+03, initc-loss 1.4469e+04                    bc_loss 8.7087e+06\n",
      "Epoch 17010, Training-Loss 1.3907e+03, Data-loss 5.2560e+02                  , pde-loss 2.3811e+03, initc-loss 1.4952e+04                    bc_loss 8.6333e+06\n",
      "Epoch 17020, Training-Loss 1.5061e+03, Data-loss 6.5466e+02                  , pde-loss 2.5481e+03, initc-loss 1.6481e+04                    bc_loss 8.4959e+06\n",
      "Epoch 17030, Training-Loss 1.2677e+03, Data-loss 3.3300e+02                  , pde-loss 3.0029e+03, initc-loss 1.4287e+04                    bc_loss 9.3299e+06\n",
      "Epoch 17040, Training-Loss 1.3441e+03, Data-loss 3.5274e+02                  , pde-loss 2.4577e+03, initc-loss 1.3532e+04                    bc_loss 9.8973e+06\n",
      "Epoch 17050, Training-Loss 1.4763e+03, Data-loss 6.1926e+02                  , pde-loss 2.0680e+03, initc-loss 1.5973e+04                    bc_loss 8.5522e+06\n",
      "Epoch 17060, Training-Loss 1.2757e+03, Data-loss 4.0765e+02                  , pde-loss 2.6746e+03, initc-loss 1.4912e+04                    bc_loss 8.6627e+06\n",
      "Epoch 17070, Training-Loss 1.3182e+03, Data-loss 3.5958e+02                  , pde-loss 2.4410e+03, initc-loss 1.3583e+04                    bc_loss 9.5698e+06\n",
      "Epoch 17080, Training-Loss 1.3425e+03, Data-loss 4.5978e+02                  , pde-loss 2.7328e+03, initc-loss 1.5269e+04                    bc_loss 8.8092e+06\n",
      "Epoch 17090, Training-Loss 1.3624e+03, Data-loss 5.2587e+02                  , pde-loss 2.6661e+03, initc-loss 1.5134e+04                    bc_loss 8.3470e+06\n",
      "Epoch 17100, Training-Loss 1.4249e+03, Data-loss 4.9705e+02                  , pde-loss 2.5336e+03, initc-loss 1.4658e+04                    bc_loss 9.2613e+06\n",
      "Epoch 17110, Training-Loss 1.2446e+03, Data-loss 3.7684e+02                  , pde-loss 2.5915e+03, initc-loss 1.4165e+04                    bc_loss 8.6606e+06\n",
      "Epoch 17120, Training-Loss 1.5254e+03, Data-loss 6.5467e+02                  , pde-loss 2.6565e+03, initc-loss 1.4195e+04                    bc_loss 8.6908e+06\n",
      "Epoch 17130, Training-Loss 1.2600e+03, Data-loss 4.0587e+02                  , pde-loss 2.1573e+03, initc-loss 1.4648e+04                    bc_loss 8.5241e+06\n",
      "Epoch 17140, Training-Loss 1.3358e+03, Data-loss 3.8052e+02                  , pde-loss 2.1068e+03, initc-loss 1.2876e+04                    bc_loss 9.5379e+06\n",
      "Epoch 17150, Training-Loss 1.3042e+03, Data-loss 4.5649e+02                  , pde-loss 2.8103e+03, initc-loss 1.4934e+04                    bc_loss 8.4590e+06\n",
      "Epoch 17160, Training-Loss 1.1352e+03, Data-loss 4.0062e+02                  , pde-loss 2.5636e+03, initc-loss 1.6128e+04                    bc_loss 7.3272e+06\n",
      "Epoch 17170, Training-Loss 1.3337e+03, Data-loss 5.3324e+02                  , pde-loss 2.6571e+03, initc-loss 1.4569e+04                    bc_loss 7.9877e+06\n",
      "Epoch 17180, Training-Loss 1.0824e+03, Data-loss 3.3356e+02                  , pde-loss 3.1104e+03, initc-loss 1.4943e+04                    bc_loss 7.4705e+06\n",
      "Epoch 17190, Training-Loss 1.1156e+03, Data-loss 3.0974e+02                  , pde-loss 2.7741e+03, initc-loss 1.4371e+04                    bc_loss 8.0415e+06\n",
      "Epoch 17200, Training-Loss 1.2273e+03, Data-loss 3.4202e+02                  , pde-loss 2.0000e+03, initc-loss 1.3237e+04                    bc_loss 8.8376e+06\n",
      "Epoch 17210, Training-Loss 1.3725e+03, Data-loss 4.5696e+02                  , pde-loss 2.3255e+03, initc-loss 1.3457e+04                    bc_loss 9.1396e+06\n",
      "Epoch 17220, Training-Loss 1.2189e+03, Data-loss 3.9135e+02                  , pde-loss 2.5340e+03, initc-loss 1.3643e+04                    bc_loss 8.2591e+06\n",
      "Epoch 17230, Training-Loss 1.0963e+03, Data-loss 2.8004e+02                  , pde-loss 2.6891e+03, initc-loss 1.4753e+04                    bc_loss 8.1455e+06\n",
      "Epoch 17240, Training-Loss 1.3947e+03, Data-loss 6.2793e+02                  , pde-loss 2.4834e+03, initc-loss 1.5640e+04                    bc_loss 7.6491e+06\n",
      "Epoch 17250, Training-Loss 1.1442e+03, Data-loss 3.7041e+02                  , pde-loss 2.3431e+03, initc-loss 1.5106e+04                    bc_loss 7.7206e+06\n",
      "Epoch 17260, Training-Loss 1.0817e+03, Data-loss 3.3991e+02                  , pde-loss 2.6088e+03, initc-loss 1.4484e+04                    bc_loss 7.4008e+06\n",
      "Epoch 17270, Training-Loss 1.1461e+03, Data-loss 3.9823e+02                  , pde-loss 2.4694e+03, initc-loss 1.4753e+04                    bc_loss 7.4613e+06\n",
      "Epoch 17280, Training-Loss 1.3413e+03, Data-loss 5.6309e+02                  , pde-loss 2.1363e+03, initc-loss 1.3660e+04                    bc_loss 7.7661e+06\n",
      "Epoch 17290, Training-Loss 1.3405e+03, Data-loss 5.6503e+02                  , pde-loss 2.4486e+03, initc-loss 1.3678e+04                    bc_loss 7.7386e+06\n",
      "Epoch 17300, Training-Loss 1.0895e+03, Data-loss 4.3697e+02                  , pde-loss 1.8061e+03, initc-loss 1.5574e+04                    bc_loss 6.5082e+06\n",
      "Epoch 17310, Training-Loss 1.1200e+03, Data-loss 4.2979e+02                  , pde-loss 2.0910e+03, initc-loss 1.5341e+04                    bc_loss 6.8847e+06\n",
      "Epoch 17320, Training-Loss 1.0763e+03, Data-loss 3.2781e+02                  , pde-loss 2.1000e+03, initc-loss 1.2932e+04                    bc_loss 7.4703e+06\n",
      "Epoch 17330, Training-Loss 1.0814e+03, Data-loss 3.7506e+02                  , pde-loss 2.2231e+03, initc-loss 1.3829e+04                    bc_loss 7.0474e+06\n",
      "Epoch 17340, Training-Loss 1.3952e+03, Data-loss 7.2583e+02                  , pde-loss 2.6532e+03, initc-loss 1.4598e+04                    bc_loss 6.6761e+06\n",
      "Epoch 17350, Training-Loss 1.3352e+03, Data-loss 7.3347e+02                  , pde-loss 2.6635e+03, initc-loss 1.6327e+04                    bc_loss 5.9981e+06\n",
      "Epoch 17360, Training-Loss 1.1897e+03, Data-loss 5.3885e+02                  , pde-loss 2.3726e+03, initc-loss 1.5146e+04                    bc_loss 6.4914e+06\n",
      "Epoch 17370, Training-Loss 1.0631e+03, Data-loss 3.2432e+02                  , pde-loss 1.9302e+03, initc-loss 1.3789e+04                    bc_loss 7.3719e+06\n",
      "Epoch 17380, Training-Loss 1.2175e+03, Data-loss 4.3628e+02                  , pde-loss 2.2562e+03, initc-loss 1.2449e+04                    bc_loss 7.7974e+06\n",
      "Epoch 17390, Training-Loss 1.4531e+03, Data-loss 9.0192e+02                  , pde-loss 2.6281e+03, initc-loss 1.6338e+04                    bc_loss 5.4925e+06\n",
      "Epoch 17400, Training-Loss 9.4535e+02, Data-loss 3.3608e+02                  , pde-loss 2.4839e+03, initc-loss 1.5109e+04                    bc_loss 6.0751e+06\n",
      "Epoch 17410, Training-Loss 9.5657e+02, Data-loss 2.8807e+02                  , pde-loss 2.2453e+03, initc-loss 1.3619e+04                    bc_loss 6.6691e+06\n",
      "Epoch 17420, Training-Loss 1.3224e+03, Data-loss 7.0654e+02                  , pde-loss 2.5760e+03, initc-loss 1.3987e+04                    bc_loss 6.1424e+06\n",
      "Epoch 17430, Training-Loss 1.0064e+03, Data-loss 4.6811e+02                  , pde-loss 2.6089e+03, initc-loss 1.6225e+04                    bc_loss 5.3643e+06\n",
      "Epoch 17440, Training-Loss 9.5369e+02, Data-loss 4.5005e+02                  , pde-loss 2.2306e+03, initc-loss 1.6136e+04                    bc_loss 5.0180e+06\n",
      "Epoch 17450, Training-Loss 1.0301e+03, Data-loss 3.6734e+02                  , pde-loss 2.0500e+03, initc-loss 1.2857e+04                    bc_loss 6.6127e+06\n",
      "Epoch 17460, Training-Loss 1.1774e+03, Data-loss 5.0974e+02                  , pde-loss 2.4457e+03, initc-loss 1.3185e+04                    bc_loss 6.6613e+06\n",
      "Epoch 17470, Training-Loss 1.2038e+03, Data-loss 6.2431e+02                  , pde-loss 2.4935e+03, initc-loss 1.4976e+04                    bc_loss 5.7775e+06\n",
      "Epoch 17480, Training-Loss 1.1750e+03, Data-loss 5.2964e+02                  , pde-loss 2.0382e+03, initc-loss 1.4401e+04                    bc_loss 6.4370e+06\n",
      "Epoch 17490, Training-Loss 1.0886e+03, Data-loss 4.3799e+02                  , pde-loss 2.1327e+03, initc-loss 1.4197e+04                    bc_loss 6.4895e+06\n",
      "Epoch 17500, Training-Loss 1.1710e+03, Data-loss 6.0851e+02                  , pde-loss 2.4741e+03, initc-loss 1.5511e+04                    bc_loss 5.6073e+06\n",
      "Epoch 17510, Training-Loss 1.0614e+03, Data-loss 5.3998e+02                  , pde-loss 2.5788e+03, initc-loss 1.6552e+04                    bc_loss 5.1949e+06\n",
      "Epoch 17520, Training-Loss 1.1170e+03, Data-loss 5.1507e+02                  , pde-loss 1.6396e+03, initc-loss 1.3792e+04                    bc_loss 6.0037e+06\n",
      "Epoch 17530, Training-Loss 9.9477e+02, Data-loss 5.1631e+02                  , pde-loss 1.9871e+03, initc-loss 1.4638e+04                    bc_loss 4.7681e+06\n",
      "Epoch 17540, Training-Loss 8.4676e+02, Data-loss 4.1094e+02                  , pde-loss 2.4581e+03, initc-loss 1.5974e+04                    bc_loss 4.3397e+06\n",
      "Epoch 17550, Training-Loss 9.3092e+02, Data-loss 3.0454e+02                  , pde-loss 1.9654e+03, initc-loss 1.3205e+04                    bc_loss 6.2486e+06\n",
      "Epoch 17560, Training-Loss 1.0037e+03, Data-loss 5.1455e+02                  , pde-loss 2.9177e+03, initc-loss 1.5769e+04                    bc_loss 4.8728e+06\n",
      "Epoch 17570, Training-Loss 1.0066e+03, Data-loss 5.2804e+02                  , pde-loss 2.4400e+03, initc-loss 1.4799e+04                    bc_loss 4.7682e+06\n",
      "Epoch 17580, Training-Loss 1.0377e+03, Data-loss 5.6860e+02                  , pde-loss 2.3540e+03, initc-loss 1.4306e+04                    bc_loss 4.6748e+06\n",
      "Epoch 17590, Training-Loss 9.7196e+02, Data-loss 4.7404e+02                  , pde-loss 2.6718e+03, initc-loss 1.4295e+04                    bc_loss 4.9622e+06\n",
      "Epoch 17600, Training-Loss 8.5043e+02, Data-loss 3.7965e+02                  , pde-loss 2.3633e+03, initc-loss 1.3775e+04                    bc_loss 4.6917e+06\n",
      "Epoch 17610, Training-Loss 9.0601e+02, Data-loss 4.6841e+02                  , pde-loss 2.9451e+03, initc-loss 1.5014e+04                    bc_loss 4.3580e+06\n",
      "Epoch 17620, Training-Loss 9.9425e+02, Data-loss 5.1368e+02                  , pde-loss 2.9515e+03, initc-loss 1.5109e+04                    bc_loss 4.7876e+06\n",
      "Epoch 17630, Training-Loss 7.6070e+02, Data-loss 2.7203e+02                  , pde-loss 1.8200e+03, initc-loss 1.3198e+04                    bc_loss 4.8717e+06\n",
      "Epoch 17640, Training-Loss 8.4467e+02, Data-loss 3.8542e+02                  , pde-loss 2.5405e+03, initc-loss 1.3290e+04                    bc_loss 4.5766e+06\n",
      "Epoch 17650, Training-Loss 1.0286e+03, Data-loss 6.4614e+02                  , pde-loss 2.2932e+03, initc-loss 1.4114e+04                    bc_loss 3.8083e+06\n",
      "Epoch 17660, Training-Loss 8.1717e+02, Data-loss 3.6855e+02                  , pde-loss 2.2055e+03, initc-loss 1.4560e+04                    bc_loss 4.4694e+06\n",
      "Epoch 17670, Training-Loss 6.8924e+02, Data-loss 2.8004e+02                  , pde-loss 2.5042e+03, initc-loss 1.4195e+04                    bc_loss 4.0753e+06\n",
      "Epoch 17680, Training-Loss 1.0369e+03, Data-loss 5.2651e+02                  , pde-loss 2.7729e+03, initc-loss 1.3852e+04                    bc_loss 5.0869e+06\n",
      "Epoch 17690, Training-Loss 6.8435e+02, Data-loss 2.6789e+02                  , pde-loss 2.3616e+03, initc-loss 1.4794e+04                    bc_loss 4.1474e+06\n",
      "Epoch 17700, Training-Loss 9.1335e+02, Data-loss 5.5221e+02                  , pde-loss 2.3898e+03, initc-loss 1.6585e+04                    bc_loss 3.5925e+06\n",
      "Epoch 17710, Training-Loss 8.1770e+02, Data-loss 3.6597e+02                  , pde-loss 2.4670e+03, initc-loss 1.3355e+04                    bc_loss 4.5015e+06\n",
      "Epoch 17720, Training-Loss 9.2964e+02, Data-loss 4.8069e+02                  , pde-loss 3.0674e+03, initc-loss 1.3573e+04                    bc_loss 4.4729e+06\n",
      "Epoch 17730, Training-Loss 7.8976e+02, Data-loss 4.2636e+02                  , pde-loss 2.2567e+03, initc-loss 1.4998e+04                    bc_loss 3.6167e+06\n",
      "Epoch 17740, Training-Loss 6.6460e+02, Data-loss 3.0396e+02                  , pde-loss 2.5044e+03, initc-loss 1.4779e+04                    bc_loss 3.5891e+06\n",
      "Epoch 17750, Training-Loss 7.6191e+02, Data-loss 3.3635e+02                  , pde-loss 2.2121e+03, initc-loss 1.2376e+04                    bc_loss 4.2411e+06\n",
      "Epoch 17760, Training-Loss 8.2989e+02, Data-loss 4.2293e+02                  , pde-loss 2.7800e+03, initc-loss 1.3854e+04                    bc_loss 4.0530e+06\n",
      "Epoch 17770, Training-Loss 7.0983e+02, Data-loss 3.3736e+02                  , pde-loss 3.1701e+03, initc-loss 1.4572e+04                    bc_loss 3.7069e+06\n",
      "Epoch 17780, Training-Loss 6.8725e+02, Data-loss 3.1411e+02                  , pde-loss 2.2633e+03, initc-loss 1.4282e+04                    bc_loss 3.7149e+06\n",
      "Epoch 17790, Training-Loss 5.5268e+02, Data-loss 2.3965e+02                  , pde-loss 2.6717e+03, initc-loss 1.4966e+04                    bc_loss 3.1127e+06\n",
      "Epoch 17800, Training-Loss 9.1218e+02, Data-loss 6.1105e+02                  , pde-loss 3.3081e+03, initc-loss 1.4716e+04                    bc_loss 2.9933e+06\n",
      "Epoch 17810, Training-Loss 8.0619e+02, Data-loss 4.2646e+02                  , pde-loss 2.0705e+03, initc-loss 1.4456e+04                    bc_loss 3.7808e+06\n",
      "Epoch 17820, Training-Loss 7.2870e+02, Data-loss 3.4673e+02                  , pde-loss 2.0507e+03, initc-loss 1.4629e+04                    bc_loss 3.8030e+06\n",
      "Epoch 17830, Training-Loss 7.5791e+02, Data-loss 4.7498e+02                  , pde-loss 2.3348e+03, initc-loss 1.4428e+04                    bc_loss 2.8126e+06\n",
      "Epoch 17840, Training-Loss 8.6621e+02, Data-loss 5.8943e+02                  , pde-loss 2.4552e+03, initc-loss 1.5443e+04                    bc_loss 2.7500e+06\n",
      "Epoch 17850, Training-Loss 5.6903e+02, Data-loss 2.8946e+02                  , pde-loss 2.3909e+03, initc-loss 1.4308e+04                    bc_loss 2.7790e+06\n",
      "Epoch 17860, Training-Loss 5.9233e+02, Data-loss 3.1091e+02                  , pde-loss 2.3475e+03, initc-loss 1.4591e+04                    bc_loss 2.7973e+06\n",
      "Epoch 17870, Training-Loss 5.8254e+02, Data-loss 3.4239e+02                  , pde-loss 2.0534e+03, initc-loss 1.4321e+04                    bc_loss 2.3851e+06\n",
      "Epoch 17880, Training-Loss 9.7169e+02, Data-loss 7.8161e+02                  , pde-loss 2.3120e+03, initc-loss 1.5349e+04                    bc_loss 1.8831e+06\n",
      "Epoch 17890, Training-Loss 6.7745e+02, Data-loss 3.9845e+02                  , pde-loss 2.2177e+03, initc-loss 1.3657e+04                    bc_loss 2.7741e+06\n",
      "Epoch 17900, Training-Loss 6.0018e+02, Data-loss 2.4272e+02                  , pde-loss 1.6155e+03, initc-loss 1.3931e+04                    bc_loss 3.5591e+06\n",
      "Epoch 17910, Training-Loss 5.8651e+02, Data-loss 3.3661e+02                  , pde-loss 2.5378e+03, initc-loss 1.4914e+04                    bc_loss 2.4816e+06\n",
      "Epoch 17920, Training-Loss 7.7434e+02, Data-loss 5.0545e+02                  , pde-loss 2.7632e+03, initc-loss 1.3853e+04                    bc_loss 2.6723e+06\n",
      "Epoch 17930, Training-Loss 5.7729e+02, Data-loss 2.9731e+02                  , pde-loss 2.2899e+03, initc-loss 1.4351e+04                    bc_loss 2.7832e+06\n",
      "Epoch 17940, Training-Loss 4.9197e+02, Data-loss 3.0188e+02                  , pde-loss 2.3192e+03, initc-loss 1.6005e+04                    bc_loss 1.8826e+06\n",
      "Epoch 17950, Training-Loss 4.8488e+02, Data-loss 1.6401e+02                  , pde-loss 2.3679e+03, initc-loss 1.4695e+04                    bc_loss 3.1917e+06\n",
      "Epoch 17960, Training-Loss 7.1230e+02, Data-loss 4.1135e+02                  , pde-loss 2.8833e+03, initc-loss 1.3226e+04                    bc_loss 2.9934e+06\n",
      "Epoch 17970, Training-Loss 8.4298e+02, Data-loss 6.3156e+02                  , pde-loss 2.5500e+03, initc-loss 1.4371e+04                    bc_loss 2.0973e+06\n",
      "Epoch 17980, Training-Loss 3.8074e+02, Data-loss 2.0259e+02                  , pde-loss 2.3443e+03, initc-loss 1.5737e+04                    bc_loss 1.7635e+06\n",
      "Epoch 17990, Training-Loss 8.3646e+02, Data-loss 5.8985e+02                  , pde-loss 2.1880e+03, initc-loss 1.5648e+04                    bc_loss 2.4483e+06\n",
      "Epoch 18000, Training-Loss 6.4733e+02, Data-loss 3.7717e+02                  , pde-loss 1.8825e+03, initc-loss 1.3524e+04                    bc_loss 2.6862e+06\n",
      "Epoch 18010, Training-Loss 4.3945e+02, Data-loss 2.2202e+02                  , pde-loss 2.1136e+03, initc-loss 1.4357e+04                    bc_loss 2.1578e+06\n",
      "Epoch 18020, Training-Loss 6.5926e+02, Data-loss 4.2738e+02                  , pde-loss 2.0213e+03, initc-loss 1.4818e+04                    bc_loss 2.3019e+06\n",
      "Epoch 18030, Training-Loss 7.2504e+02, Data-loss 5.4497e+02                  , pde-loss 2.1615e+03, initc-loss 1.5130e+04                    bc_loss 1.7834e+06\n",
      "Epoch 18040, Training-Loss 5.4643e+02, Data-loss 3.5713e+02                  , pde-loss 2.2272e+03, initc-loss 1.4754e+04                    bc_loss 1.8760e+06\n",
      "Epoch 18050, Training-Loss 4.9179e+02, Data-loss 2.2235e+02                  , pde-loss 2.1219e+03, initc-loss 1.3435e+04                    bc_loss 2.6789e+06\n",
      "Epoch 18060, Training-Loss 3.6185e+02, Data-loss 1.6184e+02                  , pde-loss 1.9457e+03, initc-loss 1.4377e+04                    bc_loss 1.9839e+06\n",
      "Epoch 18070, Training-Loss 1.1155e+03, Data-loss 9.2212e+02                  , pde-loss 2.5365e+03, initc-loss 1.3846e+04                    bc_loss 1.9171e+06\n",
      "Epoch 18080, Training-Loss 5.0958e+02, Data-loss 2.6891e+02                  , pde-loss 2.0111e+03, initc-loss 1.3857e+04                    bc_loss 2.3909e+06\n",
      "Epoch 18090, Training-Loss 5.2595e+02, Data-loss 2.6985e+02                  , pde-loss 1.9238e+03, initc-loss 1.2952e+04                    bc_loss 2.5462e+06\n",
      "Epoch 18100, Training-Loss 7.0242e+02, Data-loss 4.7024e+02                  , pde-loss 2.4763e+03, initc-loss 1.5180e+04                    bc_loss 2.3041e+06\n",
      "Epoch 18110, Training-Loss 6.4158e+02, Data-loss 4.4823e+02                  , pde-loss 2.1984e+03, initc-loss 1.5548e+04                    bc_loss 1.9157e+06\n",
      "Epoch 18120, Training-Loss 6.1216e+02, Data-loss 4.6090e+02                  , pde-loss 2.6457e+03, initc-loss 1.5037e+04                    bc_loss 1.4948e+06\n",
      "Epoch 18130, Training-Loss 6.7209e+02, Data-loss 4.4775e+02                  , pde-loss 2.2790e+03, initc-loss 1.3484e+04                    bc_loss 2.2276e+06\n",
      "Epoch 18140, Training-Loss 6.9051e+02, Data-loss 4.8263e+02                  , pde-loss 2.2012e+03, initc-loss 1.3375e+04                    bc_loss 2.0632e+06\n",
      "Epoch 18150, Training-Loss 4.4706e+02, Data-loss 2.6916e+02                  , pde-loss 2.6727e+03, initc-loss 1.4803e+04                    bc_loss 1.7615e+06\n",
      "Epoch 18160, Training-Loss 5.0720e+02, Data-loss 2.6363e+02                  , pde-loss 2.2086e+03, initc-loss 1.3865e+04                    bc_loss 2.4196e+06\n",
      "Epoch 18170, Training-Loss 7.1705e+02, Data-loss 4.1076e+02                  , pde-loss 2.5812e+03, initc-loss 1.3760e+04                    bc_loss 3.0466e+06\n",
      "Epoch 18180, Training-Loss 6.1206e+02, Data-loss 4.9305e+02                  , pde-loss 2.1657e+03, initc-loss 1.5630e+04                    bc_loss 1.1724e+06\n",
      "Epoch 18190, Training-Loss 6.3654e+02, Data-loss 5.0636e+02                  , pde-loss 1.9277e+03, initc-loss 1.5708e+04                    bc_loss 1.2842e+06\n",
      "Epoch 18200, Training-Loss 6.2032e+02, Data-loss 3.2315e+02                  , pde-loss 2.1039e+03, initc-loss 1.2567e+04                    bc_loss 2.9570e+06\n",
      "Epoch 18210, Training-Loss 4.5439e+02, Data-loss 2.9117e+02                  , pde-loss 2.8586e+03, initc-loss 1.5832e+04                    bc_loss 1.6135e+06\n",
      "Epoch 18220, Training-Loss 9.4678e+02, Data-loss 8.5185e+02                  , pde-loss 2.9289e+03, initc-loss 1.5587e+04                    bc_loss 9.3084e+05\n",
      "Epoch 18230, Training-Loss 7.5826e+02, Data-loss 6.0399e+02                  , pde-loss 2.0123e+03, initc-loss 1.4332e+04                    bc_loss 1.5263e+06\n",
      "Epoch 18240, Training-Loss 5.6451e+02, Data-loss 4.3113e+02                  , pde-loss 2.2341e+03, initc-loss 1.5470e+04                    bc_loss 1.3161e+06\n",
      "Epoch 18250, Training-Loss 6.4570e+02, Data-loss 4.2806e+02                  , pde-loss 2.1861e+03, initc-loss 1.4182e+04                    bc_loss 2.1600e+06\n",
      "Epoch 18260, Training-Loss 5.8794e+02, Data-loss 4.0268e+02                  , pde-loss 1.6725e+03, initc-loss 1.3629e+04                    bc_loss 1.8373e+06\n",
      "Epoch 18270, Training-Loss 5.8827e+02, Data-loss 4.4273e+02                  , pde-loss 2.2008e+03, initc-loss 1.4484e+04                    bc_loss 1.4388e+06\n",
      "Epoch 18280, Training-Loss 6.3291e+02, Data-loss 4.2878e+02                  , pde-loss 3.2583e+03, initc-loss 1.4231e+04                    bc_loss 2.0238e+06\n",
      "Epoch 18290, Training-Loss 4.1305e+02, Data-loss 2.1443e+02                  , pde-loss 2.1026e+03, initc-loss 1.4196e+04                    bc_loss 1.9700e+06\n",
      "Epoch 18300, Training-Loss 6.2397e+02, Data-loss 4.5046e+02                  , pde-loss 2.2947e+03, initc-loss 1.3982e+04                    bc_loss 1.7189e+06\n",
      "Epoch 18310, Training-Loss 5.2701e+02, Data-loss 2.4137e+02                  , pde-loss 2.9218e+03, initc-loss 1.3647e+04                    bc_loss 2.8398e+06\n",
      "Epoch 18320, Training-Loss 7.5128e+02, Data-loss 6.2106e+02                  , pde-loss 2.4406e+03, initc-loss 1.5081e+04                    bc_loss 1.2846e+06\n",
      "Epoch 18330, Training-Loss 1.0325e+03, Data-loss 9.0265e+02                  , pde-loss 2.6421e+03, initc-loss 1.4495e+04                    bc_loss 1.2809e+06\n",
      "Epoch 18340, Training-Loss 5.0498e+02, Data-loss 3.0398e+02                  , pde-loss 2.6515e+03, initc-loss 1.4826e+04                    bc_loss 1.9925e+06\n",
      "Epoch 18350, Training-Loss 2.4752e+02, Data-loss 9.2857e+01                  , pde-loss 2.2004e+03, initc-loss 1.3850e+04                    bc_loss 1.5306e+06\n",
      "Epoch 18360, Training-Loss 6.8928e+02, Data-loss 5.9706e+02                  , pde-loss 2.5008e+03, initc-loss 1.5477e+04                    bc_loss 9.0420e+05\n",
      "Epoch 18370, Training-Loss 8.8820e+02, Data-loss 7.7600e+02                  , pde-loss 2.7010e+03, initc-loss 1.5388e+04                    bc_loss 1.1040e+06\n",
      "Epoch 18380, Training-Loss 5.4836e+02, Data-loss 3.4924e+02                  , pde-loss 2.2190e+03, initc-loss 1.3064e+04                    bc_loss 1.9759e+06\n",
      "Epoch 18390, Training-Loss 2.9546e+02, Data-loss 9.5968e+01                  , pde-loss 2.0067e+03, initc-loss 1.2964e+04                    bc_loss 1.9799e+06\n",
      "Epoch 18400, Training-Loss 3.5460e+02, Data-loss 2.2346e+02                  , pde-loss 2.2738e+03, initc-loss 1.4468e+04                    bc_loss 1.2946e+06\n",
      "Epoch 18410, Training-Loss 3.2522e+02, Data-loss 1.6145e+02                  , pde-loss 2.2729e+03, initc-loss 1.3649e+04                    bc_loss 1.6218e+06\n",
      "Epoch 18420, Training-Loss 8.3499e+02, Data-loss 7.0345e+02                  , pde-loss 2.5193e+03, initc-loss 1.4512e+04                    bc_loss 1.2984e+06\n",
      "Epoch 18430, Training-Loss 5.6935e+02, Data-loss 4.3754e+02                  , pde-loss 2.3142e+03, initc-loss 1.4857e+04                    bc_loss 1.3010e+06\n",
      "Epoch 18440, Training-Loss 8.2888e+02, Data-loss 6.5229e+02                  , pde-loss 2.2848e+03, initc-loss 1.3502e+04                    bc_loss 1.7501e+06\n",
      "Epoch 18450, Training-Loss 5.0814e+02, Data-loss 3.4912e+02                  , pde-loss 2.0021e+03, initc-loss 1.3359e+04                    bc_loss 1.5749e+06\n",
      "Epoch 18460, Training-Loss 4.3360e+02, Data-loss 2.7842e+02                  , pde-loss 2.5326e+03, initc-loss 1.4347e+04                    bc_loss 1.5350e+06\n",
      "Epoch 18470, Training-Loss 7.5203e+02, Data-loss 5.7248e+02                  , pde-loss 2.3238e+03, initc-loss 1.3543e+04                    bc_loss 1.7796e+06\n",
      "Epoch 18480, Training-Loss 6.6468e+02, Data-loss 5.1695e+02                  , pde-loss 2.4632e+03, initc-loss 1.5314e+04                    bc_loss 1.4596e+06\n",
      "Epoch 18490, Training-Loss 5.6838e+02, Data-loss 3.4085e+02                  , pde-loss 2.2820e+03, initc-loss 1.3903e+04                    bc_loss 2.2592e+06\n",
      "Epoch 18500, Training-Loss 4.0594e+02, Data-loss 1.9980e+02                  , pde-loss 2.2151e+03, initc-loss 1.3428e+04                    bc_loss 2.0458e+06\n",
      "Epoch 18510, Training-Loss 5.7155e+02, Data-loss 5.1208e+02                  , pde-loss 2.2479e+03, initc-loss 1.6147e+04                    bc_loss 5.7635e+05\n",
      "Epoch 18520, Training-Loss 5.6937e+02, Data-loss 4.3309e+02                  , pde-loss 2.7962e+03, initc-loss 1.5438e+04                    bc_loss 1.3445e+06\n",
      "Epoch 18530, Training-Loss 5.4819e+02, Data-loss 3.6352e+02                  , pde-loss 2.7711e+03, initc-loss 1.2391e+04                    bc_loss 1.8315e+06\n",
      "Epoch 18540, Training-Loss 6.3903e+02, Data-loss 5.3852e+02                  , pde-loss 2.4713e+03, initc-loss 1.4361e+04                    bc_loss 9.8822e+05\n",
      "Epoch 18550, Training-Loss 4.7460e+02, Data-loss 3.5785e+02                  , pde-loss 2.1804e+03, initc-loss 1.3855e+04                    bc_loss 1.1514e+06\n",
      "Epoch 18560, Training-Loss 4.3448e+02, Data-loss 2.5524e+02                  , pde-loss 2.2297e+03, initc-loss 1.3946e+04                    bc_loss 1.7762e+06\n",
      "Epoch 18570, Training-Loss 4.1129e+02, Data-loss 2.2846e+02                  , pde-loss 2.3748e+03, initc-loss 1.3240e+04                    bc_loss 1.8127e+06\n",
      "Epoch 18580, Training-Loss 6.5168e+02, Data-loss 5.5686e+02                  , pde-loss 2.8478e+03, initc-loss 1.4618e+04                    bc_loss 9.3078e+05\n",
      "Epoch 18590, Training-Loss 3.2068e+02, Data-loss 1.9607e+02                  , pde-loss 2.3568e+03, initc-loss 1.4355e+04                    bc_loss 1.2293e+06\n",
      "Epoch 18600, Training-Loss 4.0410e+02, Data-loss 1.8819e+02                  , pde-loss 2.2695e+03, initc-loss 1.3522e+04                    bc_loss 2.1433e+06\n",
      "Epoch 18610, Training-Loss 5.1972e+02, Data-loss 4.0919e+02                  , pde-loss 2.7908e+03, initc-loss 1.4559e+04                    bc_loss 1.0879e+06\n",
      "Epoch 18620, Training-Loss 3.1434e+02, Data-loss 1.3110e+02                  , pde-loss 2.0068e+03, initc-loss 1.2912e+04                    bc_loss 1.8175e+06\n",
      "Epoch 18630, Training-Loss 4.0841e+02, Data-loss 2.8452e+02                  , pde-loss 2.6449e+03, initc-loss 1.4587e+04                    bc_loss 1.2216e+06\n",
      "Epoch 18640, Training-Loss 4.7239e+02, Data-loss 3.9065e+02                  , pde-loss 1.8814e+03, initc-loss 1.4358e+04                    bc_loss 8.0119e+05\n",
      "Epoch 18650, Training-Loss 3.7154e+02, Data-loss 1.9369e+02                  , pde-loss 2.1796e+03, initc-loss 1.3600e+04                    bc_loss 1.7628e+06\n",
      "Epoch 18660, Training-Loss 4.1649e+02, Data-loss 2.6318e+02                  , pde-loss 2.4821e+03, initc-loss 1.3839e+04                    bc_loss 1.5168e+06\n",
      "Epoch 18670, Training-Loss 3.6365e+02, Data-loss 2.3080e+02                  , pde-loss 1.7417e+03, initc-loss 1.4805e+04                    bc_loss 1.3119e+06\n",
      "Epoch 18680, Training-Loss 6.1885e+02, Data-loss 4.7249e+02                  , pde-loss 2.8765e+03, initc-loss 1.3882e+04                    bc_loss 1.4468e+06\n",
      "Epoch 18690, Training-Loss 4.3518e+02, Data-loss 2.7059e+02                  , pde-loss 2.0685e+03, initc-loss 1.3000e+04                    bc_loss 1.6308e+06\n",
      "Epoch 18700, Training-Loss 3.9171e+02, Data-loss 2.6140e+02                  , pde-loss 2.4409e+03, initc-loss 1.4073e+04                    bc_loss 1.2866e+06\n",
      "Epoch 18710, Training-Loss 4.3490e+02, Data-loss 2.4297e+02                  , pde-loss 2.2062e+03, initc-loss 1.3643e+04                    bc_loss 1.9034e+06\n",
      "Epoch 18720, Training-Loss 3.4817e+02, Data-loss 2.0370e+02                  , pde-loss 2.4825e+03, initc-loss 1.4076e+04                    bc_loss 1.4281e+06\n",
      "Epoch 18730, Training-Loss 4.7946e+02, Data-loss 3.2000e+02                  , pde-loss 2.5153e+03, initc-loss 1.2647e+04                    bc_loss 1.5795e+06\n",
      "Epoch 18740, Training-Loss 7.3511e+02, Data-loss 6.6797e+02                  , pde-loss 3.0307e+03, initc-loss 1.4946e+04                    bc_loss 6.5351e+05\n",
      "Epoch 18750, Training-Loss 4.0108e+02, Data-loss 3.0590e+02                  , pde-loss 1.9543e+03, initc-loss 1.4576e+04                    bc_loss 9.3529e+05\n",
      "Epoch 18760, Training-Loss 2.3039e+02, Data-loss 1.3719e+02                  , pde-loss 2.2640e+03, initc-loss 1.3053e+04                    bc_loss 9.1664e+05\n",
      "Epoch 18770, Training-Loss 7.8072e+02, Data-loss 5.9964e+02                  , pde-loss 2.1667e+03, initc-loss 1.2410e+04                    bc_loss 1.7963e+06\n",
      "Epoch 18780, Training-Loss 4.1057e+02, Data-loss 2.8707e+02                  , pde-loss 2.7434e+03, initc-loss 1.4677e+04                    bc_loss 1.2176e+06\n",
      "Epoch 18790, Training-Loss 5.1815e+02, Data-loss 4.4881e+02                  , pde-loss 2.4264e+03, initc-loss 1.3893e+04                    bc_loss 6.7709e+05\n",
      "Epoch 18800, Training-Loss 5.2027e+02, Data-loss 4.0895e+02                  , pde-loss 2.5595e+03, initc-loss 1.3358e+04                    bc_loss 1.0973e+06\n",
      "Epoch 18810, Training-Loss 5.0582e+02, Data-loss 3.7990e+02                  , pde-loss 2.2438e+03, initc-loss 1.3961e+04                    bc_loss 1.2430e+06\n",
      "Epoch 18820, Training-Loss 4.5324e+02, Data-loss 3.3281e+02                  , pde-loss 2.4849e+03, initc-loss 1.3864e+04                    bc_loss 1.1879e+06\n",
      "Epoch 18830, Training-Loss 3.5251e+02, Data-loss 1.8708e+02                  , pde-loss 2.5953e+03, initc-loss 1.3351e+04                    bc_loss 1.6383e+06\n",
      "Epoch 18840, Training-Loss 2.7778e+02, Data-loss 1.7588e+02                  , pde-loss 2.3845e+03, initc-loss 1.3613e+04                    bc_loss 1.0031e+06\n",
      "Epoch 18850, Training-Loss 8.4133e+02, Data-loss 7.3631e+02                  , pde-loss 2.5072e+03, initc-loss 1.3687e+04                    bc_loss 1.0340e+06\n",
      "Epoch 18860, Training-Loss 6.7697e+02, Data-loss 5.9093e+02                  , pde-loss 3.4027e+03, initc-loss 1.5690e+04                    bc_loss 8.4139e+05\n",
      "Epoch 18870, Training-Loss 4.1637e+02, Data-loss 3.0252e+02                  , pde-loss 2.1923e+03, initc-loss 1.3009e+04                    bc_loss 1.1232e+06\n",
      "Epoch 18880, Training-Loss 5.2684e+02, Data-loss 3.9792e+02                  , pde-loss 2.3818e+03, initc-loss 1.3177e+04                    bc_loss 1.2736e+06\n",
      "Epoch 18890, Training-Loss 3.6924e+02, Data-loss 2.5897e+02                  , pde-loss 3.0502e+03, initc-loss 1.5959e+04                    bc_loss 1.0838e+06\n",
      "Epoch 18900, Training-Loss 4.4295e+02, Data-loss 3.2542e+02                  , pde-loss 2.1074e+03, initc-loss 1.4139e+04                    bc_loss 1.1591e+06\n",
      "Epoch 18910, Training-Loss 4.4353e+02, Data-loss 3.2449e+02                  , pde-loss 2.8093e+03, initc-loss 1.3137e+04                    bc_loss 1.1744e+06\n",
      "Epoch 18920, Training-Loss 5.4439e+02, Data-loss 4.5866e+02                  , pde-loss 2.4388e+03, initc-loss 1.5180e+04                    bc_loss 8.3967e+05\n",
      "Epoch 18930, Training-Loss 5.7783e+02, Data-loss 4.8158e+02                  , pde-loss 2.1499e+03, initc-loss 1.3679e+04                    bc_loss 9.4663e+05\n",
      "Epoch 18940, Training-Loss 2.8373e+02, Data-loss 1.8125e+02                  , pde-loss 2.5456e+03, initc-loss 1.4473e+04                    bc_loss 1.0078e+06\n",
      "Epoch 18950, Training-Loss 3.5584e+02, Data-loss 2.7922e+02                  , pde-loss 2.4150e+03, initc-loss 1.3758e+04                    bc_loss 7.5004e+05\n",
      "Epoch 18960, Training-Loss 3.5152e+02, Data-loss 1.7328e+02                  , pde-loss 2.5673e+03, initc-loss 1.3091e+04                    bc_loss 1.7667e+06\n",
      "Epoch 18970, Training-Loss 3.5505e+02, Data-loss 2.3269e+02                  , pde-loss 2.2744e+03, initc-loss 1.3848e+04                    bc_loss 1.2074e+06\n",
      "Epoch 18980, Training-Loss 5.0160e+02, Data-loss 4.3247e+02                  , pde-loss 2.7468e+03, initc-loss 1.3829e+04                    bc_loss 6.7467e+05\n",
      "Epoch 18990, Training-Loss 3.0657e+02, Data-loss 2.1487e+02                  , pde-loss 2.4488e+03, initc-loss 1.3780e+04                    bc_loss 9.0073e+05\n",
      "Epoch 19000, Training-Loss 5.3380e+02, Data-loss 4.0962e+02                  , pde-loss 2.5066e+03, initc-loss 1.2949e+04                    bc_loss 1.2263e+06\n",
      "Epoch 19010, Training-Loss 3.8537e+02, Data-loss 2.8646e+02                  , pde-loss 2.4869e+03, initc-loss 1.4158e+04                    bc_loss 9.7238e+05\n",
      "Epoch 19020, Training-Loss 5.1255e+02, Data-loss 4.4829e+02                  , pde-loss 3.1942e+03, initc-loss 1.4155e+04                    bc_loss 6.2524e+05\n",
      "Epoch 19030, Training-Loss 6.0339e+02, Data-loss 5.0629e+02                  , pde-loss 2.7821e+03, initc-loss 1.4165e+04                    bc_loss 9.5408e+05\n",
      "Epoch 19040, Training-Loss 3.0167e+02, Data-loss 1.9189e+02                  , pde-loss 2.6978e+03, initc-loss 1.5366e+04                    bc_loss 1.0798e+06\n",
      "Epoch 19050, Training-Loss 3.7487e+02, Data-loss 2.5600e+02                  , pde-loss 2.3179e+03, initc-loss 1.4436e+04                    bc_loss 1.1720e+06\n",
      "Epoch 19060, Training-Loss 3.0394e+02, Data-loss 2.2483e+02                  , pde-loss 1.7237e+03, initc-loss 1.3553e+04                    bc_loss 7.7585e+05\n",
      "Epoch 19070, Training-Loss 4.4534e+02, Data-loss 3.8391e+02                  , pde-loss 2.5619e+03, initc-loss 1.3910e+04                    bc_loss 5.9778e+05\n",
      "Epoch 19080, Training-Loss 2.0287e+02, Data-loss 1.2238e+02                  , pde-loss 2.4215e+03, initc-loss 1.4010e+04                    bc_loss 7.8850e+05\n",
      "Epoch 19090, Training-Loss 3.9684e+02, Data-loss 2.8364e+02                  , pde-loss 2.8444e+03, initc-loss 1.3316e+04                    bc_loss 1.1158e+06\n",
      "Epoch 19100, Training-Loss 2.7919e+02, Data-loss 1.8963e+02                  , pde-loss 3.5927e+03, initc-loss 1.5316e+04                    bc_loss 8.7668e+05\n",
      "Epoch 19110, Training-Loss 2.5356e+02, Data-loss 1.5652e+02                  , pde-loss 2.4081e+03, initc-loss 1.5385e+04                    bc_loss 9.5263e+05\n",
      "Epoch 19120, Training-Loss 2.9657e+02, Data-loss 1.5566e+02                  , pde-loss 2.2904e+03, initc-loss 1.3337e+04                    bc_loss 1.3934e+06\n",
      "Epoch 19130, Training-Loss 2.9681e+02, Data-loss 2.0292e+02                  , pde-loss 2.0746e+03, initc-loss 1.3656e+04                    bc_loss 9.2315e+05\n",
      "Epoch 19140, Training-Loss 4.2218e+02, Data-loss 3.0997e+02                  , pde-loss 2.5587e+03, initc-loss 1.3787e+04                    bc_loss 1.1058e+06\n",
      "Epoch 19150, Training-Loss 4.6667e+02, Data-loss 3.8530e+02                  , pde-loss 2.2769e+03, initc-loss 1.5105e+04                    bc_loss 7.9633e+05\n",
      "Epoch 19160, Training-Loss 4.5539e+02, Data-loss 4.0090e+02                  , pde-loss 2.3319e+03, initc-loss 1.3821e+04                    bc_loss 5.2871e+05\n",
      "Epoch 19170, Training-Loss 3.6543e+02, Data-loss 2.2909e+02                  , pde-loss 2.3004e+03, initc-loss 1.2628e+04                    bc_loss 1.3484e+06\n",
      "Epoch 19180, Training-Loss 2.3761e+02, Data-loss 1.4107e+02                  , pde-loss 2.2063e+03, initc-loss 1.5142e+04                    bc_loss 9.4803e+05\n",
      "Epoch 19190, Training-Loss 2.4214e+02, Data-loss 1.8003e+02                  , pde-loss 2.3684e+03, initc-loss 1.3767e+04                    bc_loss 6.0498e+05\n",
      "Epoch 19200, Training-Loss 4.1762e+02, Data-loss 3.3432e+02                  , pde-loss 2.5054e+03, initc-loss 1.3999e+04                    bc_loss 8.1651e+05\n",
      "Epoch 19210, Training-Loss 6.6584e+02, Data-loss 5.7812e+02                  , pde-loss 2.7258e+03, initc-loss 1.4843e+04                    bc_loss 8.5972e+05\n",
      "Epoch 19220, Training-Loss 2.7479e+02, Data-loss 2.1192e+02                  , pde-loss 1.9588e+03, initc-loss 1.4158e+04                    bc_loss 6.1252e+05\n",
      "Epoch 19230, Training-Loss 1.8201e+02, Data-loss 1.1476e+02                  , pde-loss 2.4283e+03, initc-loss 1.3427e+04                    bc_loss 6.5663e+05\n",
      "Epoch 19240, Training-Loss 3.2466e+02, Data-loss 2.5910e+02                  , pde-loss 2.2949e+03, initc-loss 1.4164e+04                    bc_loss 6.3911e+05\n",
      "Epoch 19250, Training-Loss 4.6516e+02, Data-loss 3.9848e+02                  , pde-loss 2.8646e+03, initc-loss 1.3466e+04                    bc_loss 6.5042e+05\n",
      "Epoch 19260, Training-Loss 4.4314e+02, Data-loss 3.7901e+02                  , pde-loss 3.4415e+03, initc-loss 1.4389e+04                    bc_loss 6.2349e+05\n",
      "Epoch 19270, Training-Loss 3.3457e+02, Data-loss 2.5101e+02                  , pde-loss 2.7875e+03, initc-loss 1.4074e+04                    bc_loss 8.1876e+05\n",
      "Epoch 19280, Training-Loss 5.5187e+02, Data-loss 4.4947e+02                  , pde-loss 3.9455e+03, initc-loss 1.3109e+04                    bc_loss 1.0070e+06\n",
      "Epoch 19290, Training-Loss 3.2784e+02, Data-loss 2.4251e+02                  , pde-loss 2.5372e+03, initc-loss 1.4115e+04                    bc_loss 8.3668e+05\n",
      "Epoch 19300, Training-Loss 6.3543e+02, Data-loss 5.7191e+02                  , pde-loss 3.4301e+03, initc-loss 1.3521e+04                    bc_loss 6.1826e+05\n",
      "Epoch 19310, Training-Loss 4.2969e+02, Data-loss 3.7175e+02                  , pde-loss 2.7255e+03, initc-loss 1.4034e+04                    bc_loss 5.6264e+05\n",
      "Epoch 19320, Training-Loss 4.2358e+02, Data-loss 3.2330e+02                  , pde-loss 2.3915e+03, initc-loss 1.2934e+04                    bc_loss 9.8748e+05\n",
      "Epoch 19330, Training-Loss 3.3243e+02, Data-loss 2.6312e+02                  , pde-loss 2.7824e+03, initc-loss 1.4732e+04                    bc_loss 6.7549e+05\n",
      "Epoch 19340, Training-Loss 2.9294e+02, Data-loss 2.1635e+02                  , pde-loss 2.3296e+03, initc-loss 1.3314e+04                    bc_loss 7.5018e+05\n",
      "Epoch 19350, Training-Loss 3.6464e+02, Data-loss 2.6410e+02                  , pde-loss 2.1600e+03, initc-loss 1.3149e+04                    bc_loss 9.9011e+05\n",
      "Epoch 19360, Training-Loss 2.9256e+02, Data-loss 2.4805e+02                  , pde-loss 3.0951e+03, initc-loss 1.4384e+04                    bc_loss 4.2761e+05\n",
      "Epoch 19370, Training-Loss 2.9526e+02, Data-loss 2.4449e+02                  , pde-loss 1.9817e+03, initc-loss 1.3929e+04                    bc_loss 4.9174e+05\n",
      "Epoch 19380, Training-Loss 2.7326e+02, Data-loss 1.9882e+02                  , pde-loss 2.4772e+03, initc-loss 1.3971e+04                    bc_loss 7.2789e+05\n",
      "Epoch 19390, Training-Loss 2.5043e+02, Data-loss 1.6280e+02                  , pde-loss 2.4632e+03, initc-loss 1.4046e+04                    bc_loss 8.5978e+05\n",
      "Epoch 19400, Training-Loss 3.3726e+02, Data-loss 2.8147e+02                  , pde-loss 1.9380e+03, initc-loss 1.3217e+04                    bc_loss 5.4277e+05\n",
      "Epoch 19410, Training-Loss 2.2771e+02, Data-loss 1.5877e+02                  , pde-loss 2.5162e+03, initc-loss 1.4351e+04                    bc_loss 6.7247e+05\n",
      "Epoch 19420, Training-Loss 4.1139e+02, Data-loss 3.3934e+02                  , pde-loss 2.9966e+03, initc-loss 1.3159e+04                    bc_loss 7.0440e+05\n",
      "Epoch 19430, Training-Loss 5.1129e+02, Data-loss 4.6451e+02                  , pde-loss 1.8686e+03, initc-loss 1.4071e+04                    bc_loss 4.5184e+05\n",
      "Epoch 19440, Training-Loss 1.5534e+02, Data-loss 9.5988e+01                  , pde-loss 2.2978e+03, initc-loss 1.4514e+04                    bc_loss 5.7672e+05\n",
      "Epoch 19450, Training-Loss 3.0885e+02, Data-loss 2.5114e+02                  , pde-loss 2.7381e+03, initc-loss 1.3035e+04                    bc_loss 5.6133e+05\n",
      "Epoch 19460, Training-Loss 2.6847e+02, Data-loss 2.0999e+02                  , pde-loss 2.2093e+03, initc-loss 1.4836e+04                    bc_loss 5.6771e+05\n",
      "Epoch 19470, Training-Loss 3.1575e+02, Data-loss 2.6904e+02                  , pde-loss 2.4264e+03, initc-loss 1.3878e+04                    bc_loss 4.5079e+05\n",
      "Epoch 19480, Training-Loss 4.6419e+02, Data-loss 4.1535e+02                  , pde-loss 2.4551e+03, initc-loss 1.5443e+04                    bc_loss 4.7048e+05\n",
      "Epoch 19490, Training-Loss 4.6504e+02, Data-loss 3.7923e+02                  , pde-loss 2.5372e+03, initc-loss 1.3262e+04                    bc_loss 8.4223e+05\n",
      "Epoch 19500, Training-Loss 2.1234e+02, Data-loss 1.0762e+02                  , pde-loss 2.4672e+03, initc-loss 1.3517e+04                    bc_loss 1.0313e+06\n",
      "Epoch 19510, Training-Loss 4.2636e+02, Data-loss 3.5245e+02                  , pde-loss 2.3171e+03, initc-loss 1.3748e+04                    bc_loss 7.2304e+05\n",
      "Epoch 19520, Training-Loss 2.0345e+02, Data-loss 1.3622e+02                  , pde-loss 2.3876e+03, initc-loss 1.4310e+04                    bc_loss 6.5558e+05\n",
      "Epoch 19530, Training-Loss 2.0069e+02, Data-loss 1.4665e+02                  , pde-loss 2.9506e+03, initc-loss 1.3169e+04                    bc_loss 5.2424e+05\n",
      "Epoch 19540, Training-Loss 4.3158e+02, Data-loss 3.6730e+02                  , pde-loss 3.0241e+03, initc-loss 1.2858e+04                    bc_loss 6.2690e+05\n",
      "Epoch 19550, Training-Loss 1.9070e+02, Data-loss 1.3277e+02                  , pde-loss 2.5080e+03, initc-loss 1.4982e+04                    bc_loss 5.6182e+05\n",
      "Epoch 19560, Training-Loss 3.6816e+02, Data-loss 2.8830e+02                  , pde-loss 2.5444e+03, initc-loss 1.3315e+04                    bc_loss 7.8276e+05\n",
      "Epoch 19570, Training-Loss 1.3638e+02, Data-loss 8.2858e+01                  , pde-loss 2.8754e+03, initc-loss 1.3937e+04                    bc_loss 5.1842e+05\n",
      "Epoch 19580, Training-Loss 2.0918e+02, Data-loss 1.8373e+02                  , pde-loss 2.4921e+03, initc-loss 1.4496e+04                    bc_loss 2.3758e+05\n",
      "Epoch 19590, Training-Loss 3.2891e+02, Data-loss 2.6648e+02                  , pde-loss 3.0035e+03, initc-loss 1.4090e+04                    bc_loss 6.0721e+05\n",
      "Epoch 19600, Training-Loss 4.4292e+02, Data-loss 3.6312e+02                  , pde-loss 2.4081e+03, initc-loss 1.3293e+04                    bc_loss 7.8222e+05\n",
      "Epoch 19610, Training-Loss 3.6697e+02, Data-loss 3.1128e+02                  , pde-loss 2.6893e+03, initc-loss 1.3095e+04                    bc_loss 5.4105e+05\n",
      "Epoch 19620, Training-Loss 2.1370e+02, Data-loss 1.6078e+02                  , pde-loss 2.6929e+03, initc-loss 1.4358e+04                    bc_loss 5.1216e+05\n",
      "Epoch 19630, Training-Loss 4.2920e+02, Data-loss 3.8233e+02                  , pde-loss 2.2921e+03, initc-loss 1.3733e+04                    bc_loss 4.5270e+05\n",
      "Epoch 19640, Training-Loss 2.3388e+02, Data-loss 1.5701e+02                  , pde-loss 2.2150e+03, initc-loss 1.3722e+04                    bc_loss 7.5273e+05\n",
      "Epoch 19650, Training-Loss 5.8831e+02, Data-loss 5.5154e+02                  , pde-loss 3.5312e+03, initc-loss 1.4106e+04                    bc_loss 3.5015e+05\n",
      "Epoch 19660, Training-Loss 2.1438e+02, Data-loss 1.6551e+02                  , pde-loss 2.3808e+03, initc-loss 1.3596e+04                    bc_loss 4.7274e+05\n",
      "Epoch 19670, Training-Loss 4.6841e+02, Data-loss 4.3556e+02                  , pde-loss 2.5562e+03, initc-loss 1.4097e+04                    bc_loss 3.1183e+05\n",
      "Epoch 19680, Training-Loss 2.7046e+02, Data-loss 2.0728e+02                  , pde-loss 2.8542e+03, initc-loss 1.4551e+04                    bc_loss 6.1443e+05\n",
      "Epoch 19690, Training-Loss 2.9950e+02, Data-loss 2.4915e+02                  , pde-loss 2.5851e+03, initc-loss 1.3497e+04                    bc_loss 4.8744e+05\n",
      "Epoch 19700, Training-Loss 3.5761e+02, Data-loss 2.8756e+02                  , pde-loss 2.7375e+03, initc-loss 1.3017e+04                    bc_loss 6.8473e+05\n",
      "Epoch 19710, Training-Loss 2.8838e+02, Data-loss 2.4268e+02                  , pde-loss 2.7729e+03, initc-loss 1.3889e+04                    bc_loss 4.4030e+05\n",
      "Epoch 19720, Training-Loss 2.7880e+02, Data-loss 2.2439e+02                  , pde-loss 2.0909e+03, initc-loss 1.3047e+04                    bc_loss 5.2904e+05\n",
      "Epoch 19730, Training-Loss 2.3761e+02, Data-loss 1.8226e+02                  , pde-loss 2.1628e+03, initc-loss 1.3761e+04                    bc_loss 5.3750e+05\n",
      "Epoch 19740, Training-Loss 2.9689e+02, Data-loss 2.5942e+02                  , pde-loss 2.2669e+03, initc-loss 1.3562e+04                    bc_loss 3.5887e+05\n",
      "Epoch 19750, Training-Loss 2.0754e+02, Data-loss 1.6152e+02                  , pde-loss 2.8823e+03, initc-loss 1.4331e+04                    bc_loss 4.4289e+05\n",
      "Epoch 19760, Training-Loss 2.9845e+02, Data-loss 2.5841e+02                  , pde-loss 2.2975e+03, initc-loss 1.4103e+04                    bc_loss 3.8406e+05\n",
      "Epoch 19770, Training-Loss 2.9309e+02, Data-loss 2.3497e+02                  , pde-loss 1.9032e+03, initc-loss 1.3634e+04                    bc_loss 5.6564e+05\n",
      "Epoch 19780, Training-Loss 2.7334e+02, Data-loss 2.0550e+02                  , pde-loss 2.0928e+03, initc-loss 1.3147e+04                    bc_loss 6.6321e+05\n",
      "Epoch 19790, Training-Loss 3.0455e+02, Data-loss 2.4871e+02                  , pde-loss 2.3424e+03, initc-loss 1.3206e+04                    bc_loss 5.4289e+05\n",
      "Epoch 19800, Training-Loss 1.6893e+02, Data-loss 1.3152e+02                  , pde-loss 2.6546e+03, initc-loss 1.3454e+04                    bc_loss 3.5800e+05\n",
      "Epoch 19810, Training-Loss 1.6817e+02, Data-loss 1.2669e+02                  , pde-loss 2.3147e+03, initc-loss 1.4109e+04                    bc_loss 3.9838e+05\n",
      "Epoch 19820, Training-Loss 2.6365e+02, Data-loss 2.0673e+02                  , pde-loss 2.6904e+03, initc-loss 1.3831e+04                    bc_loss 5.5264e+05\n",
      "Epoch 19830, Training-Loss 2.4233e+02, Data-loss 1.9403e+02                  , pde-loss 2.0105e+03, initc-loss 1.3402e+04                    bc_loss 4.6762e+05\n",
      "Epoch 19840, Training-Loss 2.6991e+02, Data-loss 2.2905e+02                  , pde-loss 2.8658e+03, initc-loss 1.3783e+04                    bc_loss 3.9195e+05\n",
      "Epoch 19850, Training-Loss 2.2454e+02, Data-loss 1.8961e+02                  , pde-loss 2.7179e+03, initc-loss 1.3395e+04                    bc_loss 3.3318e+05\n",
      "Epoch 19860, Training-Loss 1.7517e+02, Data-loss 1.2400e+02                  , pde-loss 2.2150e+03, initc-loss 1.3400e+04                    bc_loss 4.9610e+05\n",
      "Epoch 19870, Training-Loss 3.2750e+02, Data-loss 2.5772e+02                  , pde-loss 2.6286e+03, initc-loss 1.3008e+04                    bc_loss 6.8221e+05\n",
      "Epoch 19880, Training-Loss 4.6445e+02, Data-loss 4.2780e+02                  , pde-loss 3.0089e+03, initc-loss 1.4355e+04                    bc_loss 3.4907e+05\n",
      "Epoch 19890, Training-Loss 2.2591e+02, Data-loss 1.8522e+02                  , pde-loss 2.6720e+03, initc-loss 1.4322e+04                    bc_loss 3.8989e+05\n",
      "Epoch 19900, Training-Loss 3.9327e+02, Data-loss 3.6856e+02                  , pde-loss 3.2620e+03, initc-loss 1.4879e+04                    bc_loss 2.2894e+05\n",
      "Epoch 19910, Training-Loss 2.3701e+02, Data-loss 1.7326e+02                  , pde-loss 2.5133e+03, initc-loss 1.3401e+04                    bc_loss 6.2155e+05\n",
      "Epoch 19920, Training-Loss 2.4487e+02, Data-loss 2.0127e+02                  , pde-loss 2.4111e+03, initc-loss 1.3474e+04                    bc_loss 4.2003e+05\n",
      "Epoch 19930, Training-Loss 2.7351e+02, Data-loss 2.4424e+02                  , pde-loss 2.8257e+03, initc-loss 1.4433e+04                    bc_loss 2.7547e+05\n",
      "Epoch 19940, Training-Loss 2.2039e+02, Data-loss 1.8253e+02                  , pde-loss 2.5177e+03, initc-loss 1.3012e+04                    bc_loss 3.6307e+05\n",
      "Epoch 19950, Training-Loss 2.8438e+02, Data-loss 2.2539e+02                  , pde-loss 2.2081e+03, initc-loss 1.3720e+04                    bc_loss 5.7393e+05\n",
      "Epoch 19960, Training-Loss 2.0162e+02, Data-loss 1.4453e+02                  , pde-loss 3.1027e+03, initc-loss 1.3474e+04                    bc_loss 5.5432e+05\n",
      "Epoch 19970, Training-Loss 2.3767e+02, Data-loss 1.9090e+02                  , pde-loss 3.1305e+03, initc-loss 1.3186e+04                    bc_loss 4.5135e+05\n",
      "Epoch 19980, Training-Loss 2.0711e+02, Data-loss 1.7782e+02                  , pde-loss 2.3726e+03, initc-loss 1.3449e+04                    bc_loss 2.7714e+05\n",
      "Epoch 19990, Training-Loss 2.8282e+02, Data-loss 2.5128e+02                  , pde-loss 2.7665e+03, initc-loss 1.3070e+04                    bc_loss 2.9952e+05\n",
      "Epoch 20000, Training-Loss 2.1922e+02, Data-loss 1.8429e+02                  , pde-loss 2.5940e+03, initc-loss 1.3751e+04                    bc_loss 3.3303e+05\n",
      "Epoch 20010, Training-Loss 1.9500e+02, Data-loss 1.5729e+02                  , pde-loss 2.6713e+03, initc-loss 1.3049e+04                    bc_loss 3.6146e+05\n",
      "Epoch 20020, Training-Loss 2.2340e+02, Data-loss 1.8367e+02                  , pde-loss 2.5475e+03, initc-loss 1.3590e+04                    bc_loss 3.8113e+05\n",
      "Epoch 20030, Training-Loss 1.3101e+02, Data-loss 9.7611e+01                  , pde-loss 2.6365e+03, initc-loss 1.3461e+04                    bc_loss 3.1787e+05\n",
      "Epoch 20040, Training-Loss 1.2107e+02, Data-loss 9.2077e+01                  , pde-loss 2.7493e+03, initc-loss 1.3383e+04                    bc_loss 2.7381e+05\n",
      "Epoch 20050, Training-Loss 2.5354e+02, Data-loss 2.1534e+02                  , pde-loss 3.2625e+03, initc-loss 1.2937e+04                    bc_loss 3.6575e+05\n",
      "Epoch 20060, Training-Loss 1.5415e+02, Data-loss 1.0102e+02                  , pde-loss 2.4591e+03, initc-loss 1.3354e+04                    bc_loss 5.1543e+05\n",
      "Epoch 20070, Training-Loss 1.8846e+02, Data-loss 1.5026e+02                  , pde-loss 2.7154e+03, initc-loss 1.2781e+04                    bc_loss 3.6646e+05\n",
      "Epoch 20080, Training-Loss 1.7070e+02, Data-loss 1.3517e+02                  , pde-loss 2.4879e+03, initc-loss 1.3100e+04                    bc_loss 3.3974e+05\n",
      "Epoch 20090, Training-Loss 2.9019e+02, Data-loss 2.5001e+02                  , pde-loss 3.1606e+03, initc-loss 1.3959e+04                    bc_loss 3.8475e+05\n",
      "Epoch 20100, Training-Loss 2.4306e+02, Data-loss 2.0772e+02                  , pde-loss 2.5664e+03, initc-loss 1.3096e+04                    bc_loss 3.3769e+05\n",
      "Epoch 20110, Training-Loss 2.0696e+02, Data-loss 1.8266e+02                  , pde-loss 2.3310e+03, initc-loss 1.3314e+04                    bc_loss 2.2735e+05\n",
      "Epoch 20120, Training-Loss 2.4564e+02, Data-loss 2.0465e+02                  , pde-loss 2.5436e+03, initc-loss 1.3521e+04                    bc_loss 3.9388e+05\n",
      "Epoch 20130, Training-Loss 1.6163e+02, Data-loss 1.2738e+02                  , pde-loss 2.3893e+03, initc-loss 1.3010e+04                    bc_loss 3.2707e+05\n",
      "Epoch 20140, Training-Loss 1.7393e+02, Data-loss 1.4277e+02                  , pde-loss 2.9982e+03, initc-loss 1.3179e+04                    bc_loss 2.9542e+05\n",
      "Epoch 20150, Training-Loss 1.9898e+02, Data-loss 1.5616e+02                  , pde-loss 2.3700e+03, initc-loss 1.2892e+04                    bc_loss 4.1294e+05\n",
      "Epoch 20160, Training-Loss 1.7228e+02, Data-loss 1.1403e+02                  , pde-loss 2.3273e+03, initc-loss 1.3457e+04                    bc_loss 5.6664e+05\n",
      "Epoch 20170, Training-Loss 1.3703e+02, Data-loss 1.0278e+02                  , pde-loss 2.1206e+03, initc-loss 1.3471e+04                    bc_loss 3.2693e+05\n",
      "Epoch 20180, Training-Loss 9.7027e+01, Data-loss 5.4768e+01                  , pde-loss 2.9597e+03, initc-loss 1.3429e+04                    bc_loss 4.0621e+05\n",
      "Epoch 20190, Training-Loss 1.7634e+02, Data-loss 1.5286e+02                  , pde-loss 3.1127e+03, initc-loss 1.3912e+04                    bc_loss 2.1775e+05\n",
      "Epoch 20200, Training-Loss 2.0051e+02, Data-loss 1.6516e+02                  , pde-loss 2.9783e+03, initc-loss 1.2734e+04                    bc_loss 3.3777e+05\n",
      "Epoch 20210, Training-Loss 1.6694e+02, Data-loss 1.0866e+02                  , pde-loss 2.5428e+03, initc-loss 1.3559e+04                    bc_loss 5.6675e+05\n",
      "Epoch 20220, Training-Loss 2.3214e+02, Data-loss 2.0380e+02                  , pde-loss 2.1740e+03, initc-loss 1.2945e+04                    bc_loss 2.6829e+05\n",
      "Epoch 20230, Training-Loss 1.7638e+02, Data-loss 1.5259e+02                  , pde-loss 3.1041e+03, initc-loss 1.3626e+04                    bc_loss 2.2113e+05\n",
      "Epoch 20240, Training-Loss 8.0567e+01, Data-loss 4.6957e+01                  , pde-loss 2.8554e+03, initc-loss 1.4140e+04                    bc_loss 3.1910e+05\n",
      "Epoch 20250, Training-Loss 1.6942e+02, Data-loss 1.3316e+02                  , pde-loss 2.6117e+03, initc-loss 1.3130e+04                    bc_loss 3.4685e+05\n",
      "Epoch 20260, Training-Loss 1.0767e+02, Data-loss 7.3322e+01                  , pde-loss 2.6372e+03, initc-loss 1.2872e+04                    bc_loss 3.2800e+05\n",
      "Epoch 20270, Training-Loss 1.5709e+02, Data-loss 1.2175e+02                  , pde-loss 2.8781e+03, initc-loss 1.3233e+04                    bc_loss 3.3730e+05\n",
      "Epoch 20280, Training-Loss 2.4255e+02, Data-loss 2.2072e+02                  , pde-loss 2.6883e+03, initc-loss 1.3255e+04                    bc_loss 2.0231e+05\n",
      "Epoch 20290, Training-Loss 1.3700e+02, Data-loss 1.0918e+02                  , pde-loss 2.3542e+03, initc-loss 1.3963e+04                    bc_loss 2.6194e+05\n",
      "Epoch 20300, Training-Loss 1.8757e+02, Data-loss 1.2773e+02                  , pde-loss 2.5230e+03, initc-loss 1.2519e+04                    bc_loss 5.8343e+05\n",
      "Epoch 20310, Training-Loss 1.9289e+02, Data-loss 1.4974e+02                  , pde-loss 2.6973e+03, initc-loss 1.2259e+04                    bc_loss 4.1651e+05\n",
      "Epoch 20320, Training-Loss 1.3613e+02, Data-loss 1.0579e+02                  , pde-loss 2.9857e+03, initc-loss 1.3328e+04                    bc_loss 2.8715e+05\n",
      "Epoch 20330, Training-Loss 2.0701e+02, Data-loss 1.8401e+02                  , pde-loss 3.4239e+03, initc-loss 1.3093e+04                    bc_loss 2.1346e+05\n",
      "Epoch 20340, Training-Loss 9.8293e+01, Data-loss 7.5443e+01                  , pde-loss 3.0006e+03, initc-loss 1.2793e+04                    bc_loss 2.1270e+05\n",
      "Epoch 20350, Training-Loss 1.7659e+02, Data-loss 1.5243e+02                  , pde-loss 2.4334e+03, initc-loss 1.4083e+04                    bc_loss 2.2500e+05\n",
      "Epoch 20360, Training-Loss 2.0977e+02, Data-loss 1.8436e+02                  , pde-loss 2.8816e+03, initc-loss 1.3657e+04                    bc_loss 2.3758e+05\n",
      "Epoch 20370, Training-Loss 1.1640e+02, Data-loss 9.8636e+01                  , pde-loss 2.8363e+03, initc-loss 1.3524e+04                    bc_loss 1.6131e+05\n",
      "Epoch 20380, Training-Loss 1.5918e+02, Data-loss 1.3528e+02                  , pde-loss 2.8451e+03, initc-loss 1.3074e+04                    bc_loss 2.2307e+05\n",
      "Epoch 20390, Training-Loss 1.1253e+02, Data-loss 9.2901e+01                  , pde-loss 3.0198e+03, initc-loss 1.3325e+04                    bc_loss 1.7991e+05\n",
      "Epoch 20400, Training-Loss 9.0006e+01, Data-loss 6.2913e+01                  , pde-loss 3.1490e+03, initc-loss 1.3388e+04                    bc_loss 2.5439e+05\n",
      "Epoch 20410, Training-Loss 1.6120e+02, Data-loss 1.3216e+02                  , pde-loss 2.5405e+03, initc-loss 1.3267e+04                    bc_loss 2.7467e+05\n",
      "Epoch 20420, Training-Loss 2.4004e+02, Data-loss 2.0335e+02                  , pde-loss 3.3006e+03, initc-loss 1.2544e+04                    bc_loss 3.5102e+05\n",
      "Epoch 20430, Training-Loss 1.5518e+02, Data-loss 1.1524e+02                  , pde-loss 2.0870e+03, initc-loss 1.2587e+04                    bc_loss 3.8469e+05\n",
      "Epoch 20440, Training-Loss 1.3510e+02, Data-loss 9.7709e+01                  , pde-loss 2.7285e+03, initc-loss 1.2799e+04                    bc_loss 3.5843e+05\n",
      "Epoch 20450, Training-Loss 1.8164e+02, Data-loss 1.5934e+02                  , pde-loss 3.1876e+03, initc-loss 1.2404e+04                    bc_loss 2.0746e+05\n",
      "Epoch 20460, Training-Loss 8.5441e+01, Data-loss 6.0577e+01                  , pde-loss 3.1206e+03, initc-loss 1.3493e+04                    bc_loss 2.3203e+05\n",
      "Epoch 20470, Training-Loss 1.0305e+02, Data-loss 8.6425e+01                  , pde-loss 2.9223e+03, initc-loss 1.3459e+04                    bc_loss 1.4982e+05\n",
      "Epoch 20480, Training-Loss 1.5542e+02, Data-loss 1.1472e+02                  , pde-loss 2.7021e+03, initc-loss 1.2919e+04                    bc_loss 3.9136e+05\n",
      "Epoch 20490, Training-Loss 1.3469e+02, Data-loss 1.0998e+02                  , pde-loss 2.7287e+03, initc-loss 1.3129e+04                    bc_loss 2.3119e+05\n",
      "Epoch 20500, Training-Loss 1.0070e+02, Data-loss 8.0990e+01                  , pde-loss 2.6503e+03, initc-loss 1.3254e+04                    bc_loss 1.8123e+05\n",
      "Epoch 20510, Training-Loss 1.7426e+02, Data-loss 1.5646e+02                  , pde-loss 2.0804e+03, initc-loss 1.3461e+04                    bc_loss 1.6245e+05\n",
      "Epoch 20520, Training-Loss 8.5054e+01, Data-loss 6.2500e+01                  , pde-loss 2.8521e+03, initc-loss 1.3339e+04                    bc_loss 2.0935e+05\n",
      "Epoch 20530, Training-Loss 1.1209e+02, Data-loss 8.9182e+01                  , pde-loss 2.9587e+03, initc-loss 1.2759e+04                    bc_loss 2.1332e+05\n",
      "Epoch 20540, Training-Loss 1.3997e+02, Data-loss 1.1803e+02                  , pde-loss 2.9477e+03, initc-loss 1.3660e+04                    bc_loss 2.0283e+05\n",
      "Epoch 20550, Training-Loss 1.5526e+02, Data-loss 1.2931e+02                  , pde-loss 2.3565e+03, initc-loss 1.2794e+04                    bc_loss 2.4434e+05\n",
      "Epoch 20560, Training-Loss 1.3016e+02, Data-loss 9.4998e+01                  , pde-loss 3.1932e+03, initc-loss 1.2961e+04                    bc_loss 3.3548e+05\n",
      "Epoch 20570, Training-Loss 1.3515e+02, Data-loss 1.1768e+02                  , pde-loss 2.7149e+03, initc-loss 1.3071e+04                    bc_loss 1.5893e+05\n",
      "Epoch 20580, Training-Loss 1.8307e+02, Data-loss 1.6343e+02                  , pde-loss 3.0176e+03, initc-loss 1.2984e+04                    bc_loss 1.8034e+05\n",
      "Epoch 20590, Training-Loss 1.2297e+02, Data-loss 9.8184e+01                  , pde-loss 3.4940e+03, initc-loss 1.3600e+04                    bc_loss 2.3073e+05\n",
      "Epoch 20600, Training-Loss 2.2786e+02, Data-loss 2.1374e+02                  , pde-loss 3.2092e+03, initc-loss 1.3483e+04                    bc_loss 1.2451e+05\n",
      "Epoch 20610, Training-Loss 1.2593e+02, Data-loss 1.0719e+02                  , pde-loss 2.4844e+03, initc-loss 1.3490e+04                    bc_loss 1.7139e+05\n",
      "Epoch 20620, Training-Loss 1.1640e+02, Data-loss 9.8397e+01                  , pde-loss 2.5410e+03, initc-loss 1.2975e+04                    bc_loss 1.6452e+05\n",
      "Epoch 20630, Training-Loss 8.4633e+01, Data-loss 6.5058e+01                  , pde-loss 3.4936e+03, initc-loss 1.2941e+04                    bc_loss 1.7931e+05\n",
      "Epoch 20640, Training-Loss 2.0057e+02, Data-loss 1.7487e+02                  , pde-loss 3.0337e+03, initc-loss 1.3864e+04                    bc_loss 2.4011e+05\n",
      "Epoch 20650, Training-Loss 8.1319e+01, Data-loss 6.6547e+01                  , pde-loss 2.6012e+03, initc-loss 1.3410e+04                    bc_loss 1.3171e+05\n",
      "Epoch 20660, Training-Loss 1.3347e+02, Data-loss 1.1263e+02                  , pde-loss 2.8717e+03, initc-loss 1.3624e+04                    bc_loss 1.9184e+05\n",
      "Epoch 20670, Training-Loss 8.5097e+01, Data-loss 6.5266e+01                  , pde-loss 2.7717e+03, initc-loss 1.3029e+04                    bc_loss 1.8251e+05\n",
      "Epoch 20680, Training-Loss 1.0124e+02, Data-loss 7.8853e+01                  , pde-loss 2.7117e+03, initc-loss 1.2966e+04                    bc_loss 2.0819e+05\n",
      "Epoch 20690, Training-Loss 1.3102e+02, Data-loss 1.0956e+02                  , pde-loss 2.4621e+03, initc-loss 1.2731e+04                    bc_loss 1.9941e+05\n",
      "Epoch 20700, Training-Loss 1.5203e+02, Data-loss 1.2325e+02                  , pde-loss 2.4165e+03, initc-loss 1.3060e+04                    bc_loss 2.7241e+05\n",
      "Epoch 20710, Training-Loss 7.9346e+01, Data-loss 5.6254e+01                  , pde-loss 2.9864e+03, initc-loss 1.2792e+04                    bc_loss 2.1514e+05\n",
      "Epoch 20720, Training-Loss 1.2939e+02, Data-loss 1.1302e+02                  , pde-loss 3.0576e+03, initc-loss 1.3606e+04                    bc_loss 1.4707e+05\n",
      "Epoch 20730, Training-Loss 8.7279e+01, Data-loss 6.8805e+01                  , pde-loss 2.7603e+03, initc-loss 1.2756e+04                    bc_loss 1.6922e+05\n",
      "Epoch 20740, Training-Loss 1.1444e+02, Data-loss 9.8684e+01                  , pde-loss 2.8422e+03, initc-loss 1.3066e+04                    bc_loss 1.4169e+05\n",
      "Epoch 20750, Training-Loss 1.3118e+02, Data-loss 1.1234e+02                  , pde-loss 4.0550e+03, initc-loss 1.3308e+04                    bc_loss 1.7108e+05\n",
      "Epoch 20760, Training-Loss 5.9505e+01, Data-loss 3.7245e+01                  , pde-loss 2.3416e+03, initc-loss 1.2931e+04                    bc_loss 2.0733e+05\n",
      "Epoch 20770, Training-Loss 8.2576e+01, Data-loss 6.6915e+01                  , pde-loss 2.8966e+03, initc-loss 1.3251e+04                    bc_loss 1.4046e+05\n",
      "Epoch 20780, Training-Loss 1.1224e+02, Data-loss 9.4602e+01                  , pde-loss 2.6470e+03, initc-loss 1.3346e+04                    bc_loss 1.6042e+05\n",
      "Epoch 20790, Training-Loss 1.3946e+02, Data-loss 1.2313e+02                  , pde-loss 3.1541e+03, initc-loss 1.3157e+04                    bc_loss 1.4702e+05\n",
      "Epoch 20800, Training-Loss 1.0031e+02, Data-loss 7.9510e+01                  , pde-loss 2.7679e+03, initc-loss 1.2771e+04                    bc_loss 1.9242e+05\n",
      "Epoch 20810, Training-Loss 1.2452e+02, Data-loss 1.0783e+02                  , pde-loss 3.0790e+03, initc-loss 1.2738e+04                    bc_loss 1.5105e+05\n",
      "Epoch 20820, Training-Loss 1.0382e+02, Data-loss 8.6702e+01                  , pde-loss 2.8259e+03, initc-loss 1.3692e+04                    bc_loss 1.5471e+05\n",
      "Epoch 20830, Training-Loss 1.0126e+02, Data-loss 8.8630e+01                  , pde-loss 2.5519e+03, initc-loss 1.3277e+04                    bc_loss 1.1050e+05\n",
      "Epoch 20840, Training-Loss 1.0693e+02, Data-loss 7.9061e+01                  , pde-loss 2.9562e+03, initc-loss 1.2412e+04                    bc_loss 2.6332e+05\n",
      "Epoch 20850, Training-Loss 1.4551e+02, Data-loss 1.1962e+02                  , pde-loss 2.5192e+03, initc-loss 1.2600e+04                    bc_loss 2.4372e+05\n",
      "Epoch 20860, Training-Loss 1.2654e+02, Data-loss 8.7350e+01                  , pde-loss 2.9352e+03, initc-loss 1.2713e+04                    bc_loss 3.7622e+05\n",
      "Epoch 20870, Training-Loss 1.2709e+02, Data-loss 1.0927e+02                  , pde-loss 2.7729e+03, initc-loss 1.2821e+04                    bc_loss 1.6263e+05\n",
      "Epoch 20880, Training-Loss 1.1162e+02, Data-loss 9.2735e+01                  , pde-loss 2.7032e+03, initc-loss 1.3265e+04                    bc_loss 1.7288e+05\n",
      "Epoch 20890, Training-Loss 9.0783e+01, Data-loss 6.8508e+01                  , pde-loss 3.1049e+03, initc-loss 1.2472e+04                    bc_loss 2.0717e+05\n",
      "Epoch 20900, Training-Loss 6.7306e+01, Data-loss 5.1055e+01                  , pde-loss 2.5382e+03, initc-loss 1.3380e+04                    bc_loss 1.4659e+05\n",
      "Epoch 20910, Training-Loss 6.8851e+01, Data-loss 4.5644e+01                  , pde-loss 2.3055e+03, initc-loss 1.2426e+04                    bc_loss 2.1734e+05\n",
      "Epoch 20920, Training-Loss 1.2143e+02, Data-loss 9.8897e+01                  , pde-loss 2.6123e+03, initc-loss 1.2668e+04                    bc_loss 2.1009e+05\n",
      "Epoch 20930, Training-Loss 1.8357e+02, Data-loss 1.6008e+02                  , pde-loss 3.4734e+03, initc-loss 1.2620e+04                    bc_loss 2.1879e+05\n",
      "Epoch 20940, Training-Loss 1.0279e+02, Data-loss 8.7684e+01                  , pde-loss 2.5687e+03, initc-loss 1.2929e+04                    bc_loss 1.3553e+05\n",
      "Epoch 20950, Training-Loss 1.1935e+02, Data-loss 1.0253e+02                  , pde-loss 3.1399e+03, initc-loss 1.3097e+04                    bc_loss 1.5195e+05\n",
      "Epoch 20960, Training-Loss 8.5747e+01, Data-loss 6.3919e+01                  , pde-loss 2.6353e+03, initc-loss 1.2682e+04                    bc_loss 2.0296e+05\n",
      "Epoch 20970, Training-Loss 1.0084e+02, Data-loss 7.7952e+01                  , pde-loss 2.3374e+03, initc-loss 1.2484e+04                    bc_loss 2.1408e+05\n",
      "Epoch 20980, Training-Loss 1.0267e+02, Data-loss 6.9618e+01                  , pde-loss 2.9147e+03, initc-loss 1.2871e+04                    bc_loss 3.1472e+05\n",
      "Epoch 20990, Training-Loss 1.0076e+02, Data-loss 8.5245e+01                  , pde-loss 3.9110e+03, initc-loss 1.2998e+04                    bc_loss 1.3826e+05\n",
      "Epoch 21000, Training-Loss 7.5876e+01, Data-loss 6.3241e+01                  , pde-loss 2.6561e+03, initc-loss 1.3463e+04                    bc_loss 1.1022e+05\n",
      "Epoch 21010, Training-Loss 8.3208e+01, Data-loss 6.8615e+01                  , pde-loss 2.7057e+03, initc-loss 1.3429e+04                    bc_loss 1.2980e+05\n",
      "Epoch 21020, Training-Loss 1.0129e+02, Data-loss 8.5056e+01                  , pde-loss 3.1898e+03, initc-loss 1.3134e+04                    bc_loss 1.4601e+05\n",
      "Epoch 21030, Training-Loss 6.9980e+01, Data-loss 5.3214e+01                  , pde-loss 2.4833e+03, initc-loss 1.2904e+04                    bc_loss 1.5227e+05\n",
      "Epoch 21040, Training-Loss 9.4548e+01, Data-loss 7.3712e+01                  , pde-loss 3.7286e+03, initc-loss 1.2989e+04                    bc_loss 1.9165e+05\n",
      "Epoch 21050, Training-Loss 1.2988e+02, Data-loss 1.1213e+02                  , pde-loss 3.2415e+03, initc-loss 1.2390e+04                    bc_loss 1.6185e+05\n",
      "Epoch 21060, Training-Loss 7.3556e+01, Data-loss 5.9216e+01                  , pde-loss 2.9415e+03, initc-loss 1.2829e+04                    bc_loss 1.2763e+05\n",
      "Epoch 21070, Training-Loss 7.7954e+01, Data-loss 6.0055e+01                  , pde-loss 2.5782e+03, initc-loss 1.2716e+04                    bc_loss 1.6370e+05\n",
      "Epoch 21080, Training-Loss 9.2755e+01, Data-loss 7.4096e+01                  , pde-loss 2.8937e+03, initc-loss 1.2576e+04                    bc_loss 1.7112e+05\n",
      "Epoch 21090, Training-Loss 1.3819e+02, Data-loss 1.2189e+02                  , pde-loss 3.5302e+03, initc-loss 1.2726e+04                    bc_loss 1.4677e+05\n",
      "Epoch 21100, Training-Loss 1.0104e+02, Data-loss 8.8471e+01                  , pde-loss 3.5118e+03, initc-loss 1.2919e+04                    bc_loss 1.0924e+05\n",
      "Epoch 21110, Training-Loss 1.1589e+02, Data-loss 1.0010e+02                  , pde-loss 3.0243e+03, initc-loss 1.3284e+04                    bc_loss 1.4158e+05\n",
      "Epoch 21120, Training-Loss 7.5547e+01, Data-loss 5.8809e+01                  , pde-loss 2.8221e+03, initc-loss 1.2835e+04                    bc_loss 1.5173e+05\n",
      "Epoch 21130, Training-Loss 7.0719e+01, Data-loss 5.6921e+01                  , pde-loss 2.6866e+03, initc-loss 1.3468e+04                    bc_loss 1.2183e+05\n",
      "Epoch 21140, Training-Loss 6.7875e+01, Data-loss 5.2860e+01                  , pde-loss 3.2119e+03, initc-loss 1.3058e+04                    bc_loss 1.3388e+05\n",
      "Epoch 21150, Training-Loss 1.2106e+02, Data-loss 1.0383e+02                  , pde-loss 2.8260e+03, initc-loss 1.2946e+04                    bc_loss 1.5653e+05\n",
      "Epoch 21160, Training-Loss 1.2283e+02, Data-loss 1.0490e+02                  , pde-loss 3.0679e+03, initc-loss 1.2801e+04                    bc_loss 1.6342e+05\n",
      "Epoch 21170, Training-Loss 7.2418e+01, Data-loss 5.8835e+01                  , pde-loss 3.0978e+03, initc-loss 1.2997e+04                    bc_loss 1.1973e+05\n",
      "Epoch 21180, Training-Loss 1.3500e+02, Data-loss 1.2310e+02                  , pde-loss 3.1167e+03, initc-loss 1.3414e+04                    bc_loss 1.0248e+05\n",
      "Epoch 21190, Training-Loss 6.9260e+01, Data-loss 5.4038e+01                  , pde-loss 2.9703e+03, initc-loss 1.3171e+04                    bc_loss 1.3608e+05\n",
      "Epoch 21200, Training-Loss 4.6372e+01, Data-loss 3.4418e+01                  , pde-loss 3.2043e+03, initc-loss 1.3104e+04                    bc_loss 1.0323e+05\n",
      "Epoch 21210, Training-Loss 5.2484e+01, Data-loss 4.0677e+01                  , pde-loss 2.5528e+03, initc-loss 1.3072e+04                    bc_loss 1.0244e+05\n",
      "Epoch 21220, Training-Loss 9.7856e+01, Data-loss 7.7342e+01                  , pde-loss 3.7219e+03, initc-loss 1.3110e+04                    bc_loss 1.8830e+05\n",
      "Epoch 21230, Training-Loss 7.0482e+01, Data-loss 5.6941e+01                  , pde-loss 2.5153e+03, initc-loss 1.2663e+04                    bc_loss 1.2023e+05\n",
      "Epoch 21240, Training-Loss 1.1807e+02, Data-loss 9.8577e+01                  , pde-loss 2.6566e+03, initc-loss 1.2842e+04                    bc_loss 1.7945e+05\n",
      "Epoch 21250, Training-Loss 6.1163e+01, Data-loss 4.7692e+01                  , pde-loss 4.1238e+03, initc-loss 1.3157e+04                    bc_loss 1.1742e+05\n",
      "Epoch 21260, Training-Loss 1.0338e+02, Data-loss 9.2518e+01                  , pde-loss 3.1961e+03, initc-loss 1.2915e+04                    bc_loss 9.2538e+04\n",
      "Epoch 21270, Training-Loss 1.0016e+02, Data-loss 8.8799e+01                  , pde-loss 3.3654e+03, initc-loss 1.3252e+04                    bc_loss 9.7037e+04\n",
      "Epoch 21280, Training-Loss 6.7623e+01, Data-loss 5.1676e+01                  , pde-loss 3.3140e+03, initc-loss 1.2674e+04                    bc_loss 1.4348e+05\n",
      "Epoch 21290, Training-Loss 8.1569e+01, Data-loss 6.9988e+01                  , pde-loss 3.7605e+03, initc-loss 1.2977e+04                    bc_loss 9.9070e+04\n",
      "Epoch 21300, Training-Loss 6.6481e+01, Data-loss 5.5602e+01                  , pde-loss 3.1172e+03, initc-loss 1.3067e+04                    bc_loss 9.2612e+04\n",
      "Epoch 21310, Training-Loss 6.8013e+01, Data-loss 5.5876e+01                  , pde-loss 2.9491e+03, initc-loss 1.3107e+04                    bc_loss 1.0532e+05\n",
      "Epoch 21320, Training-Loss 5.6883e+01, Data-loss 4.6452e+01                  , pde-loss 2.9900e+03, initc-loss 1.3103e+04                    bc_loss 8.8208e+04\n",
      "Epoch 21330, Training-Loss 6.5876e+01, Data-loss 5.2307e+01                  , pde-loss 2.8935e+03, initc-loss 1.2837e+04                    bc_loss 1.1996e+05\n",
      "Epoch 21340, Training-Loss 6.7499e+01, Data-loss 5.6401e+01                  , pde-loss 3.6042e+03, initc-loss 1.3144e+04                    bc_loss 9.4230e+04\n",
      "Epoch 21350, Training-Loss 6.0985e+01, Data-loss 5.0051e+01                  , pde-loss 2.8797e+03, initc-loss 1.3099e+04                    bc_loss 9.3367e+04\n",
      "Epoch 21360, Training-Loss 8.6242e+01, Data-loss 7.5641e+01                  , pde-loss 2.7190e+03, initc-loss 1.3397e+04                    bc_loss 8.9891e+04\n",
      "Epoch 21370, Training-Loss 8.2054e+01, Data-loss 6.9385e+01                  , pde-loss 2.5657e+03, initc-loss 1.2915e+04                    bc_loss 1.1121e+05\n",
      "Epoch 21380, Training-Loss 5.4879e+01, Data-loss 4.2186e+01                  , pde-loss 2.7780e+03, initc-loss 1.3269e+04                    bc_loss 1.1088e+05\n",
      "Epoch 21390, Training-Loss 6.8848e+01, Data-loss 5.8685e+01                  , pde-loss 3.5847e+03, initc-loss 1.2980e+04                    bc_loss 8.5069e+04\n",
      "Epoch 21400, Training-Loss 8.0326e+01, Data-loss 6.9173e+01                  , pde-loss 2.3526e+03, initc-loss 1.2804e+04                    bc_loss 9.6372e+04\n",
      "Epoch 21410, Training-Loss 6.0166e+01, Data-loss 4.8833e+01                  , pde-loss 3.1095e+03, initc-loss 1.2949e+04                    bc_loss 9.7274e+04\n",
      "Epoch 21420, Training-Loss 1.0642e+02, Data-loss 9.5675e+01                  , pde-loss 3.3687e+03, initc-loss 1.3125e+04                    bc_loss 9.0943e+04\n",
      "Epoch 21430, Training-Loss 7.5537e+01, Data-loss 6.5332e+01                  , pde-loss 2.9702e+03, initc-loss 1.3362e+04                    bc_loss 8.5711e+04\n",
      "Epoch 21440, Training-Loss 6.2884e+01, Data-loss 4.6561e+01                  , pde-loss 3.0685e+03, initc-loss 1.2966e+04                    bc_loss 1.4720e+05\n",
      "Epoch 21450, Training-Loss 5.3804e+01, Data-loss 4.0853e+01                  , pde-loss 2.8506e+03, initc-loss 1.2572e+04                    bc_loss 1.1409e+05\n",
      "Epoch 21460, Training-Loss 9.8251e+01, Data-loss 8.0399e+01                  , pde-loss 3.0533e+03, initc-loss 1.2576e+04                    bc_loss 1.6289e+05\n",
      "Epoch 21470, Training-Loss 6.7162e+01, Data-loss 5.2250e+01                  , pde-loss 3.1553e+03, initc-loss 1.2423e+04                    bc_loss 1.3353e+05\n",
      "Epoch 21480, Training-Loss 8.3744e+01, Data-loss 6.3980e+01                  , pde-loss 3.9659e+03, initc-loss 1.2639e+04                    bc_loss 1.8103e+05\n",
      "Epoch 21490, Training-Loss 6.0703e+01, Data-loss 4.8825e+01                  , pde-loss 3.2884e+03, initc-loss 1.2612e+04                    bc_loss 1.0288e+05\n",
      "Epoch 21500, Training-Loss 7.7455e+01, Data-loss 6.4073e+01                  , pde-loss 3.0458e+03, initc-loss 1.3079e+04                    bc_loss 1.1769e+05\n",
      "Epoch 21510, Training-Loss 9.4035e+01, Data-loss 8.3714e+01                  , pde-loss 2.9424e+03, initc-loss 1.2798e+04                    bc_loss 8.7469e+04\n",
      "Epoch 21520, Training-Loss 9.5415e+01, Data-loss 8.5244e+01                  , pde-loss 3.0219e+03, initc-loss 1.3322e+04                    bc_loss 8.5373e+04\n",
      "Epoch 21530, Training-Loss 1.2251e+02, Data-loss 1.0997e+02                  , pde-loss 3.3002e+03, initc-loss 1.2850e+04                    bc_loss 1.0924e+05\n",
      "Epoch 21540, Training-Loss 4.0926e+01, Data-loss 2.9520e+01                  , pde-loss 3.4052e+03, initc-loss 1.2521e+04                    bc_loss 9.8142e+04\n",
      "Epoch 21550, Training-Loss 7.2227e+01, Data-loss 4.7889e+01                  , pde-loss 3.1358e+03, initc-loss 1.2700e+04                    bc_loss 2.2754e+05\n",
      "Epoch 21560, Training-Loss 8.1490e+01, Data-loss 7.0753e+01                  , pde-loss 3.6573e+03, initc-loss 1.2504e+04                    bc_loss 9.1203e+04\n",
      "Epoch 21570, Training-Loss 4.6589e+01, Data-loss 3.4189e+01                  , pde-loss 3.1105e+03, initc-loss 1.3377e+04                    bc_loss 1.0751e+05\n",
      "Epoch 21580, Training-Loss 4.8526e+01, Data-loss 3.8608e+01                  , pde-loss 2.8387e+03, initc-loss 1.2913e+04                    bc_loss 8.3426e+04\n",
      "Epoch 21590, Training-Loss 8.1164e+01, Data-loss 6.9908e+01                  , pde-loss 3.5172e+03, initc-loss 1.2990e+04                    bc_loss 9.6059e+04\n",
      "Epoch 21600, Training-Loss 5.6270e+01, Data-loss 4.6226e+01                  , pde-loss 3.4692e+03, initc-loss 1.2803e+04                    bc_loss 8.4167e+04\n",
      "Epoch 21610, Training-Loss 5.3929e+01, Data-loss 4.0603e+01                  , pde-loss 3.4865e+03, initc-loss 1.2700e+04                    bc_loss 1.1708e+05\n",
      "Epoch 21620, Training-Loss 4.6647e+01, Data-loss 3.1458e+01                  , pde-loss 3.4033e+03, initc-loss 1.2819e+04                    bc_loss 1.3566e+05\n",
      "Epoch 21630, Training-Loss 6.5162e+01, Data-loss 5.4352e+01                  , pde-loss 3.7133e+03, initc-loss 1.3000e+04                    bc_loss 9.1381e+04\n",
      "Epoch 21640, Training-Loss 6.9521e+01, Data-loss 5.9283e+01                  , pde-loss 2.5662e+03, initc-loss 1.2765e+04                    bc_loss 8.7047e+04\n",
      "Epoch 21650, Training-Loss 9.4299e+01, Data-loss 7.6911e+01                  , pde-loss 3.6774e+03, initc-loss 1.2916e+04                    bc_loss 1.5729e+05\n",
      "Epoch 21660, Training-Loss 5.7665e+01, Data-loss 4.6003e+01                  , pde-loss 3.1021e+03, initc-loss 1.2564e+04                    bc_loss 1.0095e+05\n",
      "Epoch 21670, Training-Loss 7.4543e+01, Data-loss 5.5999e+01                  , pde-loss 3.2603e+03, initc-loss 1.2771e+04                    bc_loss 1.6941e+05\n",
      "Epoch 21680, Training-Loss 4.5652e+01, Data-loss 3.5821e+01                  , pde-loss 2.8067e+03, initc-loss 1.2753e+04                    bc_loss 8.2755e+04\n",
      "Epoch 21690, Training-Loss 7.0078e+01, Data-loss 5.9961e+01                  , pde-loss 3.5439e+03, initc-loss 1.2909e+04                    bc_loss 8.4722e+04\n",
      "Epoch 21700, Training-Loss 8.8207e+01, Data-loss 7.7673e+01                  , pde-loss 4.2559e+03, initc-loss 1.2995e+04                    bc_loss 8.8088e+04\n",
      "Epoch 21710, Training-Loss 5.4815e+01, Data-loss 4.4197e+01                  , pde-loss 3.5648e+03, initc-loss 1.2630e+04                    bc_loss 8.9992e+04\n",
      "Epoch 21720, Training-Loss 5.0938e+01, Data-loss 4.0824e+01                  , pde-loss 2.2105e+03, initc-loss 1.3294e+04                    bc_loss 8.5630e+04\n",
      "Epoch 21730, Training-Loss 4.4563e+01, Data-loss 3.4164e+01                  , pde-loss 3.5057e+03, initc-loss 1.3391e+04                    bc_loss 8.7092e+04\n",
      "Epoch 21740, Training-Loss 5.5924e+01, Data-loss 4.6294e+01                  , pde-loss 3.1477e+03, initc-loss 1.3097e+04                    bc_loss 8.0048e+04\n",
      "Epoch 21750, Training-Loss 8.4990e+01, Data-loss 7.2994e+01                  , pde-loss 3.7340e+03, initc-loss 1.2859e+04                    bc_loss 1.0337e+05\n",
      "Epoch 21760, Training-Loss 5.3390e+01, Data-loss 4.2264e+01                  , pde-loss 3.6942e+03, initc-loss 1.3012e+04                    bc_loss 9.4552e+04\n",
      "Epoch 21770, Training-Loss 5.2047e+01, Data-loss 3.6710e+01                  , pde-loss 3.4616e+03, initc-loss 1.2558e+04                    bc_loss 1.3736e+05\n",
      "Epoch 21780, Training-Loss 8.3215e+01, Data-loss 7.0838e+01                  , pde-loss 3.1652e+03, initc-loss 1.2734e+04                    bc_loss 1.0788e+05\n",
      "Epoch 21790, Training-Loss 7.8761e+01, Data-loss 6.8954e+01                  , pde-loss 3.0373e+03, initc-loss 1.2839e+04                    bc_loss 8.2197e+04\n",
      "Epoch 21800, Training-Loss 4.9678e+01, Data-loss 4.0269e+01                  , pde-loss 3.1156e+03, initc-loss 1.3067e+04                    bc_loss 7.7901e+04\n",
      "Epoch 21810, Training-Loss 4.0483e+01, Data-loss 3.1329e+01                  , pde-loss 3.8966e+03, initc-loss 1.3225e+04                    bc_loss 7.4414e+04\n",
      "Epoch 21820, Training-Loss 7.2960e+01, Data-loss 6.2036e+01                  , pde-loss 3.5467e+03, initc-loss 1.2778e+04                    bc_loss 9.2912e+04\n",
      "Epoch 21830, Training-Loss 5.2689e+01, Data-loss 4.1989e+01                  , pde-loss 3.7807e+03, initc-loss 1.2563e+04                    bc_loss 9.0649e+04\n",
      "Epoch 21840, Training-Loss 9.0011e+01, Data-loss 7.4676e+01                  , pde-loss 3.1827e+03, initc-loss 1.2544e+04                    bc_loss 1.3763e+05\n",
      "Epoch 21850, Training-Loss 5.3023e+01, Data-loss 4.2043e+01                  , pde-loss 3.4124e+03, initc-loss 1.2933e+04                    bc_loss 9.3455e+04\n",
      "Epoch 21860, Training-Loss 6.9879e+01, Data-loss 6.0873e+01                  , pde-loss 3.4504e+03, initc-loss 1.2971e+04                    bc_loss 7.3634e+04\n",
      "Epoch 21870, Training-Loss 5.8107e+01, Data-loss 4.9071e+01                  , pde-loss 3.7565e+03, initc-loss 1.2850e+04                    bc_loss 7.3748e+04\n",
      "Epoch 21880, Training-Loss 7.7898e+01, Data-loss 6.8051e+01                  , pde-loss 3.5270e+03, initc-loss 1.2927e+04                    bc_loss 8.2012e+04\n",
      "Epoch 21890, Training-Loss 5.2192e+01, Data-loss 4.3700e+01                  , pde-loss 2.9954e+03, initc-loss 1.3004e+04                    bc_loss 6.8917e+04\n",
      "Epoch 21900, Training-Loss 5.7557e+01, Data-loss 4.8767e+01                  , pde-loss 3.0045e+03, initc-loss 1.3065e+04                    bc_loss 7.1829e+04\n",
      "Epoch 21910, Training-Loss 4.9217e+01, Data-loss 4.0053e+01                  , pde-loss 3.1316e+03, initc-loss 1.2867e+04                    bc_loss 7.5636e+04\n",
      "Epoch 21920, Training-Loss 4.1259e+01, Data-loss 3.2647e+01                  , pde-loss 3.3318e+03, initc-loss 1.2925e+04                    bc_loss 6.9862e+04\n",
      "Epoch 21930, Training-Loss 6.0234e+01, Data-loss 5.0592e+01                  , pde-loss 3.5497e+03, initc-loss 1.2999e+04                    bc_loss 7.9869e+04\n",
      "Epoch 21940, Training-Loss 6.6287e+01, Data-loss 5.1912e+01                  , pde-loss 3.0555e+03, initc-loss 1.2397e+04                    bc_loss 1.2830e+05\n",
      "Epoch 21950, Training-Loss 6.6671e+01, Data-loss 5.0773e+01                  , pde-loss 3.3429e+03, initc-loss 1.2554e+04                    bc_loss 1.4309e+05\n",
      "Epoch 21960, Training-Loss 5.8039e+01, Data-loss 4.9072e+01                  , pde-loss 3.4015e+03, initc-loss 1.3104e+04                    bc_loss 7.3160e+04\n",
      "Epoch 21970, Training-Loss 7.8959e+01, Data-loss 6.9167e+01                  , pde-loss 3.3684e+03, initc-loss 1.3274e+04                    bc_loss 8.1277e+04\n",
      "Epoch 21980, Training-Loss 5.8211e+01, Data-loss 4.8334e+01                  , pde-loss 3.2971e+03, initc-loss 1.2521e+04                    bc_loss 8.2953e+04\n",
      "Epoch 21990, Training-Loss 5.3622e+01, Data-loss 4.4269e+01                  , pde-loss 3.5938e+03, initc-loss 1.2947e+04                    bc_loss 7.6980e+04\n",
      "Epoch 22000, Training-Loss 6.3319e+01, Data-loss 5.2734e+01                  , pde-loss 3.3216e+03, initc-loss 1.2736e+04                    bc_loss 8.9787e+04\n",
      "Epoch 22010, Training-Loss 4.1944e+01, Data-loss 3.1494e+01                  , pde-loss 3.2660e+03, initc-loss 1.2650e+04                    bc_loss 8.8576e+04\n",
      "Epoch 22020, Training-Loss 5.6735e+01, Data-loss 4.4088e+01                  , pde-loss 3.3740e+03, initc-loss 1.2834e+04                    bc_loss 1.1026e+05\n",
      "Epoch 22030, Training-Loss 4.8564e+01, Data-loss 4.0463e+01                  , pde-loss 2.8544e+03, initc-loss 1.3110e+04                    bc_loss 6.5042e+04\n",
      "Epoch 22040, Training-Loss 5.0570e+01, Data-loss 4.0988e+01                  , pde-loss 3.2903e+03, initc-loss 1.2887e+04                    bc_loss 7.9642e+04\n",
      "Epoch 22050, Training-Loss 5.1127e+01, Data-loss 4.1304e+01                  , pde-loss 2.5744e+03, initc-loss 1.2538e+04                    bc_loss 8.3118e+04\n",
      "Epoch 22060, Training-Loss 6.5834e+01, Data-loss 5.5755e+01                  , pde-loss 3.0903e+03, initc-loss 1.2991e+04                    bc_loss 8.4709e+04\n",
      "Epoch 22070, Training-Loss 7.6035e+01, Data-loss 6.7683e+01                  , pde-loss 3.2303e+03, initc-loss 1.3147e+04                    bc_loss 6.7137e+04\n",
      "Epoch 22080, Training-Loss 5.1553e+01, Data-loss 4.3444e+01                  , pde-loss 3.6138e+03, initc-loss 1.3105e+04                    bc_loss 6.4370e+04\n",
      "Epoch 22090, Training-Loss 5.1364e+01, Data-loss 4.2614e+01                  , pde-loss 3.5125e+03, initc-loss 1.3149e+04                    bc_loss 7.0839e+04\n",
      "Epoch 22100, Training-Loss 7.7694e+01, Data-loss 6.9739e+01                  , pde-loss 3.7718e+03, initc-loss 1.3126e+04                    bc_loss 6.2652e+04\n",
      "Epoch 22110, Training-Loss 4.5319e+01, Data-loss 3.7055e+01                  , pde-loss 4.1574e+03, initc-loss 1.2930e+04                    bc_loss 6.5552e+04\n",
      "Epoch 22120, Training-Loss 4.2648e+01, Data-loss 3.3570e+01                  , pde-loss 3.6832e+03, initc-loss 1.2763e+04                    bc_loss 7.4330e+04\n",
      "Epoch 22130, Training-Loss 4.0879e+01, Data-loss 3.0075e+01                  , pde-loss 3.8920e+03, initc-loss 1.2790e+04                    bc_loss 9.1365e+04\n",
      "Epoch 22140, Training-Loss 7.6790e+01, Data-loss 6.5668e+01                  , pde-loss 2.7329e+03, initc-loss 1.2844e+04                    bc_loss 9.5644e+04\n",
      "Epoch 22150, Training-Loss 7.4866e+01, Data-loss 6.7020e+01                  , pde-loss 3.4295e+03, initc-loss 1.3017e+04                    bc_loss 6.2012e+04\n",
      "Epoch 22160, Training-Loss 4.5636e+01, Data-loss 3.6386e+01                  , pde-loss 3.4614e+03, initc-loss 1.2745e+04                    bc_loss 7.6294e+04\n",
      "Epoch 22170, Training-Loss 3.7381e+01, Data-loss 2.7567e+01                  , pde-loss 3.2634e+03, initc-loss 1.3066e+04                    bc_loss 8.1808e+04\n",
      "Epoch 22180, Training-Loss 3.2428e+01, Data-loss 2.4466e+01                  , pde-loss 3.9475e+03, initc-loss 1.3179e+04                    bc_loss 6.2501e+04\n",
      "Epoch 22190, Training-Loss 5.3617e+01, Data-loss 4.5497e+01                  , pde-loss 4.2307e+03, initc-loss 1.3000e+04                    bc_loss 6.3968e+04\n",
      "Epoch 22200, Training-Loss 5.2164e+01, Data-loss 4.3727e+01                  , pde-loss 3.5540e+03, initc-loss 1.2814e+04                    bc_loss 6.7997e+04\n",
      "Epoch 22210, Training-Loss 3.9252e+01, Data-loss 3.0716e+01                  , pde-loss 4.1922e+03, initc-loss 1.2922e+04                    bc_loss 6.8253e+04\n",
      "Epoch 22220, Training-Loss 4.9058e+01, Data-loss 4.1145e+01                  , pde-loss 3.3562e+03, initc-loss 1.3116e+04                    bc_loss 6.2658e+04\n",
      "Epoch 22230, Training-Loss 4.6091e+01, Data-loss 3.8027e+01                  , pde-loss 3.0064e+03, initc-loss 1.3016e+04                    bc_loss 6.4613e+04\n",
      "Epoch 22240, Training-Loss 4.1577e+01, Data-loss 3.3394e+01                  , pde-loss 3.0507e+03, initc-loss 1.2908e+04                    bc_loss 6.5875e+04\n",
      "Epoch 22250, Training-Loss 3.1918e+01, Data-loss 2.2977e+01                  , pde-loss 3.1150e+03, initc-loss 1.2966e+04                    bc_loss 7.3328e+04\n",
      "Epoch 22260, Training-Loss 4.9496e+01, Data-loss 4.1903e+01                  , pde-loss 3.6671e+03, initc-loss 1.2736e+04                    bc_loss 5.9527e+04\n",
      "Epoch 22270, Training-Loss 4.3677e+01, Data-loss 3.4154e+01                  , pde-loss 3.2204e+03, initc-loss 1.2709e+04                    bc_loss 7.9300e+04\n",
      "Epoch 22280, Training-Loss 3.9870e+01, Data-loss 3.2160e+01                  , pde-loss 3.6505e+03, initc-loss 1.3365e+04                    bc_loss 6.0083e+04\n",
      "Epoch 22290, Training-Loss 5.0585e+01, Data-loss 4.2531e+01                  , pde-loss 3.3345e+03, initc-loss 1.3116e+04                    bc_loss 6.4091e+04\n",
      "Epoch 22300, Training-Loss 5.4157e+01, Data-loss 4.5783e+01                  , pde-loss 4.1872e+03, initc-loss 1.3023e+04                    bc_loss 6.6528e+04\n",
      "Epoch 22310, Training-Loss 3.4219e+01, Data-loss 2.6762e+01                  , pde-loss 3.6991e+03, initc-loss 1.2953e+04                    bc_loss 5.7912e+04\n",
      "Epoch 22320, Training-Loss 4.2663e+01, Data-loss 3.4038e+01                  , pde-loss 3.7445e+03, initc-loss 1.3138e+04                    bc_loss 6.9363e+04\n",
      "Epoch 22330, Training-Loss 5.2653e+01, Data-loss 4.3910e+01                  , pde-loss 4.3198e+03, initc-loss 1.2821e+04                    bc_loss 7.0284e+04\n",
      "Epoch 22340, Training-Loss 4.9196e+01, Data-loss 4.1695e+01                  , pde-loss 3.3202e+03, initc-loss 1.3262e+04                    bc_loss 5.8429e+04\n",
      "Epoch 22350, Training-Loss 3.5367e+01, Data-loss 2.6620e+01                  , pde-loss 3.6794e+03, initc-loss 1.3010e+04                    bc_loss 7.0776e+04\n",
      "Epoch 22360, Training-Loss 5.4452e+01, Data-loss 4.5342e+01                  , pde-loss 4.1622e+03, initc-loss 1.2785e+04                    bc_loss 7.4153e+04\n",
      "Epoch 22370, Training-Loss 4.0171e+01, Data-loss 3.2498e+01                  , pde-loss 3.3514e+03, initc-loss 1.2834e+04                    bc_loss 6.0546e+04\n",
      "Epoch 22380, Training-Loss 7.4250e+01, Data-loss 6.5687e+01                  , pde-loss 4.5063e+03, initc-loss 1.3227e+04                    bc_loss 6.7897e+04\n",
      "Epoch 22390, Training-Loss 4.8719e+01, Data-loss 4.1256e+01                  , pde-loss 3.2907e+03, initc-loss 1.3071e+04                    bc_loss 5.8269e+04\n",
      "Epoch 22400, Training-Loss 4.4715e+01, Data-loss 3.4202e+01                  , pde-loss 3.6403e+03, initc-loss 1.2937e+04                    bc_loss 8.8548e+04\n",
      "Epoch 22410, Training-Loss 6.3230e+01, Data-loss 5.5480e+01                  , pde-loss 3.5441e+03, initc-loss 1.2852e+04                    bc_loss 6.1105e+04\n",
      "Epoch 22420, Training-Loss 4.3739e+01, Data-loss 3.5624e+01                  , pde-loss 3.8489e+03, initc-loss 1.3274e+04                    bc_loss 6.4019e+04\n",
      "Epoch 22430, Training-Loss 6.7089e+01, Data-loss 5.9452e+01                  , pde-loss 4.1479e+03, initc-loss 1.3361e+04                    bc_loss 5.8862e+04\n",
      "Epoch 22440, Training-Loss 5.1472e+01, Data-loss 4.3914e+01                  , pde-loss 3.7681e+03, initc-loss 1.2533e+04                    bc_loss 5.9275e+04\n",
      "Epoch 22450, Training-Loss 4.4198e+01, Data-loss 3.4918e+01                  , pde-loss 3.9560e+03, initc-loss 1.2930e+04                    bc_loss 7.5922e+04\n",
      "Epoch 22460, Training-Loss 5.5869e+01, Data-loss 4.8624e+01                  , pde-loss 3.1288e+03, initc-loss 1.3030e+04                    bc_loss 5.6297e+04\n",
      "Epoch 22470, Training-Loss 5.9899e+01, Data-loss 5.1086e+01                  , pde-loss 3.5159e+03, initc-loss 1.2795e+04                    bc_loss 7.1817e+04\n",
      "Epoch 22480, Training-Loss 5.4078e+01, Data-loss 4.6028e+01                  , pde-loss 4.8254e+03, initc-loss 1.3344e+04                    bc_loss 6.2326e+04\n",
      "Epoch 22490, Training-Loss 5.2633e+01, Data-loss 4.4260e+01                  , pde-loss 2.9528e+03, initc-loss 1.3026e+04                    bc_loss 6.7756e+04\n",
      "Epoch 22500, Training-Loss 2.9475e+01, Data-loss 2.2232e+01                  , pde-loss 2.8184e+03, initc-loss 1.2906e+04                    bc_loss 5.6702e+04\n",
      "Epoch 22510, Training-Loss 4.7879e+01, Data-loss 3.9742e+01                  , pde-loss 2.9750e+03, initc-loss 1.2964e+04                    bc_loss 6.5434e+04\n",
      "Epoch 22520, Training-Loss 4.7093e+01, Data-loss 3.9717e+01                  , pde-loss 3.2819e+03, initc-loss 1.2891e+04                    bc_loss 5.7585e+04\n",
      "Epoch 22530, Training-Loss 3.4984e+01, Data-loss 2.7669e+01                  , pde-loss 3.2396e+03, initc-loss 1.2978e+04                    bc_loss 5.6929e+04\n",
      "Epoch 22540, Training-Loss 4.4975e+01, Data-loss 3.6860e+01                  , pde-loss 3.7098e+03, initc-loss 1.3296e+04                    bc_loss 6.4140e+04\n",
      "Epoch 22550, Training-Loss 6.2124e+01, Data-loss 5.4747e+01                  , pde-loss 3.5208e+03, initc-loss 1.3010e+04                    bc_loss 5.7238e+04\n",
      "Epoch 22560, Training-Loss 5.4892e+01, Data-loss 4.5690e+01                  , pde-loss 3.3922e+03, initc-loss 1.2551e+04                    bc_loss 7.6078e+04\n",
      "Epoch 22570, Training-Loss 3.7067e+01, Data-loss 2.8569e+01                  , pde-loss 3.4079e+03, initc-loss 1.2769e+04                    bc_loss 6.8809e+04\n",
      "Epoch 22580, Training-Loss 4.4015e+01, Data-loss 3.6853e+01                  , pde-loss 3.0403e+03, initc-loss 1.3188e+04                    bc_loss 5.5382e+04\n",
      "Epoch 22590, Training-Loss 3.5895e+01, Data-loss 2.6861e+01                  , pde-loss 3.2114e+03, initc-loss 1.2854e+04                    bc_loss 7.4283e+04\n",
      "Epoch 22600, Training-Loss 4.7156e+01, Data-loss 3.7659e+01                  , pde-loss 3.6884e+03, initc-loss 1.3053e+04                    bc_loss 7.8222e+04\n",
      "Epoch 22610, Training-Loss 4.0584e+01, Data-loss 3.3541e+01                  , pde-loss 2.5453e+03, initc-loss 1.2872e+04                    bc_loss 5.5013e+04\n",
      "Epoch 22620, Training-Loss 4.3610e+01, Data-loss 3.6254e+01                  , pde-loss 4.0843e+03, initc-loss 1.3114e+04                    bc_loss 5.6360e+04\n",
      "Epoch 22630, Training-Loss 3.1171e+01, Data-loss 2.3614e+01                  , pde-loss 3.7444e+03, initc-loss 1.3273e+04                    bc_loss 5.8559e+04\n",
      "Epoch 22640, Training-Loss 4.5642e+01, Data-loss 3.8837e+01                  , pde-loss 3.3141e+03, initc-loss 1.3085e+04                    bc_loss 5.1657e+04\n",
      "Epoch 22650, Training-Loss 4.1231e+01, Data-loss 3.2548e+01                  , pde-loss 3.6014e+03, initc-loss 1.2784e+04                    bc_loss 7.0442e+04\n",
      "Epoch 22660, Training-Loss 4.1747e+01, Data-loss 3.4237e+01                  , pde-loss 4.3716e+03, initc-loss 1.2870e+04                    bc_loss 5.7857e+04\n",
      "Epoch 22670, Training-Loss 3.7097e+01, Data-loss 2.7290e+01                  , pde-loss 4.4055e+03, initc-loss 1.3301e+04                    bc_loss 8.0368e+04\n",
      "Epoch 22680, Training-Loss 4.3162e+01, Data-loss 3.6208e+01                  , pde-loss 3.5693e+03, initc-loss 1.3096e+04                    bc_loss 5.2865e+04\n",
      "Epoch 22690, Training-Loss 5.4008e+01, Data-loss 4.6800e+01                  , pde-loss 4.3015e+03, initc-loss 1.2886e+04                    bc_loss 5.4893e+04\n",
      "Epoch 22700, Training-Loss 3.5262e+01, Data-loss 2.6130e+01                  , pde-loss 4.0459e+03, initc-loss 1.2802e+04                    bc_loss 7.4468e+04\n",
      "Epoch 22710, Training-Loss 4.0514e+01, Data-loss 3.2282e+01                  , pde-loss 3.5770e+03, initc-loss 1.3314e+04                    bc_loss 6.5437e+04\n",
      "Epoch 22720, Training-Loss 4.7592e+01, Data-loss 4.0697e+01                  , pde-loss 4.8881e+03, initc-loss 1.3127e+04                    bc_loss 5.0928e+04\n",
      "Epoch 22730, Training-Loss 3.1122e+01, Data-loss 2.4112e+01                  , pde-loss 4.3919e+03, initc-loss 1.3063e+04                    bc_loss 5.2644e+04\n",
      "Epoch 22740, Training-Loss 3.2422e+01, Data-loss 2.4343e+01                  , pde-loss 3.9053e+03, initc-loss 1.3225e+04                    bc_loss 6.3667e+04\n",
      "Epoch 22750, Training-Loss 4.8271e+01, Data-loss 4.0765e+01                  , pde-loss 4.6719e+03, initc-loss 1.2881e+04                    bc_loss 5.7503e+04\n",
      "Epoch 22760, Training-Loss 4.1244e+01, Data-loss 3.4505e+01                  , pde-loss 4.2280e+03, initc-loss 1.2777e+04                    bc_loss 5.0388e+04\n",
      "Epoch 22770, Training-Loss 3.0214e+01, Data-loss 2.3692e+01                  , pde-loss 3.3038e+03, initc-loss 1.3012e+04                    bc_loss 4.8905e+04\n",
      "Epoch 22780, Training-Loss 5.9567e+01, Data-loss 5.3288e+01                  , pde-loss 3.0805e+03, initc-loss 1.2880e+04                    bc_loss 4.6833e+04\n",
      "Epoch 22790, Training-Loss 4.4322e+01, Data-loss 3.4074e+01                  , pde-loss 4.6602e+03, initc-loss 1.2647e+04                    bc_loss 8.5172e+04\n",
      "Epoch 22800, Training-Loss 3.9726e+01, Data-loss 3.2888e+01                  , pde-loss 3.7771e+03, initc-loss 1.2844e+04                    bc_loss 5.1758e+04\n",
      "Epoch 22810, Training-Loss 4.7391e+01, Data-loss 4.0760e+01                  , pde-loss 4.2165e+03, initc-loss 1.3488e+04                    bc_loss 4.8607e+04\n",
      "Epoch 22820, Training-Loss 3.6571e+01, Data-loss 2.8633e+01                  , pde-loss 3.9233e+03, initc-loss 1.3247e+04                    bc_loss 6.2204e+04\n",
      "Epoch 22830, Training-Loss 4.3155e+01, Data-loss 3.6263e+01                  , pde-loss 3.4013e+03, initc-loss 1.3140e+04                    bc_loss 5.2373e+04\n",
      "Epoch 22840, Training-Loss 3.8908e+01, Data-loss 3.1926e+01                  , pde-loss 3.2424e+03, initc-loss 1.2947e+04                    bc_loss 5.3632e+04\n",
      "Epoch 22850, Training-Loss 3.6830e+01, Data-loss 2.9043e+01                  , pde-loss 3.4986e+03, initc-loss 1.2811e+04                    bc_loss 6.1561e+04\n",
      "Epoch 22860, Training-Loss 2.8013e+01, Data-loss 2.1340e+01                  , pde-loss 3.5041e+03, initc-loss 1.3069e+04                    bc_loss 5.0157e+04\n",
      "Epoch 22870, Training-Loss 3.6885e+01, Data-loss 3.0397e+01                  , pde-loss 4.1289e+03, initc-loss 1.2820e+04                    bc_loss 4.7929e+04\n",
      "Epoch 22880, Training-Loss 3.8755e+01, Data-loss 2.9410e+01                  , pde-loss 4.2256e+03, initc-loss 1.2908e+04                    bc_loss 7.6320e+04\n",
      "Epoch 22890, Training-Loss 3.2113e+01, Data-loss 2.5372e+01                  , pde-loss 4.0541e+03, initc-loss 1.3056e+04                    bc_loss 5.0299e+04\n",
      "Epoch 22900, Training-Loss 4.4519e+01, Data-loss 3.8156e+01                  , pde-loss 3.7468e+03, initc-loss 1.2834e+04                    bc_loss 4.7053e+04\n",
      "Epoch 22910, Training-Loss 3.2673e+01, Data-loss 2.3384e+01                  , pde-loss 3.5757e+03, initc-loss 1.2895e+04                    bc_loss 7.6419e+04\n",
      "Epoch 22920, Training-Loss 3.5325e+01, Data-loss 2.8773e+01                  , pde-loss 3.2173e+03, initc-loss 1.3112e+04                    bc_loss 4.9191e+04\n",
      "Epoch 22930, Training-Loss 3.1010e+01, Data-loss 2.4877e+01                  , pde-loss 3.6124e+03, initc-loss 1.2981e+04                    bc_loss 4.4741e+04\n",
      "Epoch 22940, Training-Loss 5.6461e+01, Data-loss 4.7630e+01                  , pde-loss 3.9343e+03, initc-loss 1.2892e+04                    bc_loss 7.1476e+04\n",
      "Epoch 22950, Training-Loss 4.5578e+01, Data-loss 3.9166e+01                  , pde-loss 4.2169e+03, initc-loss 1.2861e+04                    bc_loss 4.7039e+04\n",
      "Epoch 22960, Training-Loss 3.0545e+01, Data-loss 2.4141e+01                  , pde-loss 5.5233e+03, initc-loss 1.3152e+04                    bc_loss 4.5365e+04\n",
      "Epoch 22970, Training-Loss 3.4175e+01, Data-loss 2.7771e+01                  , pde-loss 4.3504e+03, initc-loss 1.2990e+04                    bc_loss 4.6697e+04\n",
      "Epoch 22980, Training-Loss 2.6516e+01, Data-loss 2.0101e+01                  , pde-loss 3.4067e+03, initc-loss 1.3279e+04                    bc_loss 4.7467e+04\n",
      "Epoch 22990, Training-Loss 3.5207e+01, Data-loss 2.8110e+01                  , pde-loss 4.2783e+03, initc-loss 1.3187e+04                    bc_loss 5.3496e+04\n",
      "Epoch 23000, Training-Loss 2.5796e+01, Data-loss 1.9878e+01                  , pde-loss 3.8000e+03, initc-loss 1.3028e+04                    bc_loss 4.2357e+04\n",
      "Epoch 23010, Training-Loss 4.4870e+01, Data-loss 3.8402e+01                  , pde-loss 4.6183e+03, initc-loss 1.3020e+04                    bc_loss 4.7042e+04\n",
      "Epoch 23020, Training-Loss 3.8480e+01, Data-loss 3.2129e+01                  , pde-loss 3.7339e+03, initc-loss 1.2892e+04                    bc_loss 4.6890e+04\n",
      "Epoch 23030, Training-Loss 2.4312e+01, Data-loss 1.7590e+01                  , pde-loss 4.3100e+03, initc-loss 1.3128e+04                    bc_loss 4.9787e+04\n",
      "Epoch 23040, Training-Loss 3.8115e+01, Data-loss 2.9379e+01                  , pde-loss 3.8661e+03, initc-loss 1.2706e+04                    bc_loss 7.0789e+04\n",
      "Epoch 23050, Training-Loss 2.9716e+01, Data-loss 2.3791e+01                  , pde-loss 3.5786e+03, initc-loss 1.3150e+04                    bc_loss 4.2522e+04\n",
      "Epoch 23060, Training-Loss 2.0089e+01, Data-loss 1.4123e+01                  , pde-loss 3.5407e+03, initc-loss 1.3028e+04                    bc_loss 4.3094e+04\n",
      "Epoch 23070, Training-Loss 2.7207e+01, Data-loss 2.1495e+01                  , pde-loss 3.1201e+03, initc-loss 1.3070e+04                    bc_loss 4.0930e+04\n",
      "Epoch 23080, Training-Loss 3.7629e+01, Data-loss 3.1463e+01                  , pde-loss 4.3474e+03, initc-loss 1.3066e+04                    bc_loss 4.4253e+04\n",
      "Epoch 23090, Training-Loss 2.5919e+01, Data-loss 1.9994e+01                  , pde-loss 2.8773e+03, initc-loss 1.3184e+04                    bc_loss 4.3192e+04\n",
      "Epoch 23100, Training-Loss 2.3298e+01, Data-loss 1.7397e+01                  , pde-loss 3.6218e+03, initc-loss 1.3069e+04                    bc_loss 4.2322e+04\n",
      "Epoch 23110, Training-Loss 3.5746e+01, Data-loss 2.8993e+01                  , pde-loss 3.2320e+03, initc-loss 1.2712e+04                    bc_loss 5.1591e+04\n",
      "Epoch 23120, Training-Loss 2.5510e+01, Data-loss 1.9512e+01                  , pde-loss 3.9929e+03, initc-loss 1.3137e+04                    bc_loss 4.2858e+04\n",
      "Epoch 23130, Training-Loss 2.5042e+01, Data-loss 1.9251e+01                  , pde-loss 4.1672e+03, initc-loss 1.3175e+04                    bc_loss 4.0565e+04\n",
      "Epoch 23140, Training-Loss 3.1573e+01, Data-loss 2.5325e+01                  , pde-loss 3.5488e+03, initc-loss 1.2888e+04                    bc_loss 4.6045e+04\n",
      "Epoch 23150, Training-Loss 4.2467e+01, Data-loss 3.4802e+01                  , pde-loss 4.7317e+03, initc-loss 1.3300e+04                    bc_loss 5.8622e+04\n",
      "Epoch 23160, Training-Loss 3.4422e+01, Data-loss 2.8280e+01                  , pde-loss 4.1967e+03, initc-loss 1.3028e+04                    bc_loss 4.4197e+04\n",
      "Epoch 23170, Training-Loss 3.9671e+01, Data-loss 3.2980e+01                  , pde-loss 4.0846e+03, initc-loss 1.3110e+04                    bc_loss 4.9718e+04\n",
      "Epoch 23180, Training-Loss 3.4670e+01, Data-loss 2.9041e+01                  , pde-loss 3.6035e+03, initc-loss 1.3031e+04                    bc_loss 3.9652e+04\n",
      "Epoch 23190, Training-Loss 3.0313e+01, Data-loss 2.4380e+01                  , pde-loss 4.4138e+03, initc-loss 1.3071e+04                    bc_loss 4.1848e+04\n",
      "Epoch 23200, Training-Loss 2.7463e+01, Data-loss 2.0781e+01                  , pde-loss 4.6806e+03, initc-loss 1.2960e+04                    bc_loss 4.9174e+04\n",
      "Epoch 23210, Training-Loss 1.8477e+01, Data-loss 1.2235e+01                  , pde-loss 3.4519e+03, initc-loss 1.3195e+04                    bc_loss 4.5775e+04\n",
      "Epoch 23220, Training-Loss 4.5289e+01, Data-loss 3.9446e+01                  , pde-loss 3.9373e+03, initc-loss 1.3111e+04                    bc_loss 4.1380e+04\n",
      "Epoch 23230, Training-Loss 3.2737e+01, Data-loss 2.6002e+01                  , pde-loss 3.3552e+03, initc-loss 1.2668e+04                    bc_loss 5.1319e+04\n",
      "Epoch 23240, Training-Loss 3.7762e+01, Data-loss 3.2310e+01                  , pde-loss 3.3536e+03, initc-loss 1.3196e+04                    bc_loss 3.7980e+04\n",
      "Epoch 23250, Training-Loss 2.6989e+01, Data-loss 2.0826e+01                  , pde-loss 4.5827e+03, initc-loss 1.3212e+04                    bc_loss 4.3842e+04\n",
      "Epoch 23260, Training-Loss 3.4677e+01, Data-loss 2.8713e+01                  , pde-loss 3.7545e+03, initc-loss 1.2836e+04                    bc_loss 4.3051e+04\n",
      "Epoch 23270, Training-Loss 3.2350e+01, Data-loss 2.6404e+01                  , pde-loss 3.8524e+03, initc-loss 1.2963e+04                    bc_loss 4.2643e+04\n",
      "Epoch 23280, Training-Loss 2.8962e+01, Data-loss 2.2935e+01                  , pde-loss 3.3875e+03, initc-loss 1.3327e+04                    bc_loss 4.3550e+04\n",
      "Epoch 23290, Training-Loss 3.1548e+01, Data-loss 2.5833e+01                  , pde-loss 3.3812e+03, initc-loss 1.3153e+04                    bc_loss 4.0617e+04\n",
      "Epoch 23300, Training-Loss 3.7489e+01, Data-loss 3.0619e+01                  , pde-loss 4.5547e+03, initc-loss 1.2683e+04                    bc_loss 5.1459e+04\n",
      "Epoch 23310, Training-Loss 4.0509e+01, Data-loss 3.4694e+01                  , pde-loss 4.1556e+03, initc-loss 1.3405e+04                    bc_loss 4.0582e+04\n",
      "Epoch 23320, Training-Loss 2.7315e+01, Data-loss 2.0652e+01                  , pde-loss 3.7308e+03, initc-loss 1.2759e+04                    bc_loss 5.0138e+04\n",
      "Epoch 23330, Training-Loss 3.1490e+01, Data-loss 2.5925e+01                  , pde-loss 4.1064e+03, initc-loss 1.2958e+04                    bc_loss 3.8586e+04\n",
      "Epoch 23340, Training-Loss 2.1059e+01, Data-loss 1.5722e+01                  , pde-loss 3.0060e+03, initc-loss 1.3015e+04                    bc_loss 3.7353e+04\n",
      "Epoch 23350, Training-Loss 1.8235e+01, Data-loss 1.2811e+01                  , pde-loss 4.7688e+03, initc-loss 1.3371e+04                    bc_loss 3.6096e+04\n",
      "Epoch 23360, Training-Loss 2.5654e+01, Data-loss 1.8319e+01                  , pde-loss 4.1272e+03, initc-loss 1.2757e+04                    bc_loss 5.6467e+04\n",
      "Epoch 23370, Training-Loss 2.1778e+01, Data-loss 1.6467e+01                  , pde-loss 3.5985e+03, initc-loss 1.2922e+04                    bc_loss 3.6587e+04\n",
      "Epoch 23380, Training-Loss 2.2330e+01, Data-loss 1.6616e+01                  , pde-loss 4.5879e+03, initc-loss 1.2919e+04                    bc_loss 3.9629e+04\n",
      "Epoch 23390, Training-Loss 2.5922e+01, Data-loss 2.0633e+01                  , pde-loss 4.5255e+03, initc-loss 1.3124e+04                    bc_loss 3.5236e+04\n",
      "Epoch 23400, Training-Loss 4.0280e+01, Data-loss 3.3303e+01                  , pde-loss 4.5730e+03, initc-loss 1.2945e+04                    bc_loss 5.2251e+04\n",
      "Epoch 23410, Training-Loss 2.2768e+01, Data-loss 1.7521e+01                  , pde-loss 3.5923e+03, initc-loss 1.3084e+04                    bc_loss 3.5793e+04\n",
      "Epoch 23420, Training-Loss 2.5309e+01, Data-loss 1.9653e+01                  , pde-loss 3.9829e+03, initc-loss 1.2959e+04                    bc_loss 3.9614e+04\n",
      "Epoch 23430, Training-Loss 2.8292e+01, Data-loss 2.2872e+01                  , pde-loss 4.2972e+03, initc-loss 1.3037e+04                    bc_loss 3.6863e+04\n",
      "Epoch 23440, Training-Loss 2.3491e+01, Data-loss 1.8192e+01                  , pde-loss 3.5428e+03, initc-loss 1.3028e+04                    bc_loss 3.6419e+04\n",
      "Epoch 23450, Training-Loss 3.8574e+01, Data-loss 3.3651e+01                  , pde-loss 3.8810e+03, initc-loss 1.2972e+04                    bc_loss 3.2373e+04\n",
      "Epoch 23460, Training-Loss 2.3694e+01, Data-loss 1.7633e+01                  , pde-loss 4.2774e+03, initc-loss 1.3353e+04                    bc_loss 4.2983e+04\n",
      "Epoch 23470, Training-Loss 2.3368e+01, Data-loss 1.8027e+01                  , pde-loss 3.9284e+03, initc-loss 1.2807e+04                    bc_loss 3.6677e+04\n",
      "Epoch 23480, Training-Loss 3.4140e+01, Data-loss 2.8895e+01                  , pde-loss 3.6356e+03, initc-loss 1.2991e+04                    bc_loss 3.5817e+04\n",
      "Epoch 23490, Training-Loss 2.6265e+01, Data-loss 2.0445e+01                  , pde-loss 4.7650e+03, initc-loss 1.3030e+04                    bc_loss 4.0407e+04\n",
      "Epoch 23500, Training-Loss 2.1963e+01, Data-loss 1.6786e+01                  , pde-loss 4.0869e+03, initc-loss 1.2950e+04                    bc_loss 3.4732e+04\n",
      "Epoch 23510, Training-Loss 3.1413e+01, Data-loss 2.5580e+01                  , pde-loss 3.4171e+03, initc-loss 1.2862e+04                    bc_loss 4.2057e+04\n",
      "Epoch 23520, Training-Loss 3.2138e+01, Data-loss 2.6355e+01                  , pde-loss 5.0176e+03, initc-loss 1.3163e+04                    bc_loss 3.9652e+04\n",
      "Epoch 23530, Training-Loss 2.5768e+01, Data-loss 1.9935e+01                  , pde-loss 4.2270e+03, initc-loss 1.3068e+04                    bc_loss 4.1032e+04\n",
      "Epoch 23540, Training-Loss 1.9110e+01, Data-loss 1.4043e+01                  , pde-loss 4.2885e+03, initc-loss 1.3119e+04                    bc_loss 3.3270e+04\n",
      "Epoch 23550, Training-Loss 2.3993e+01, Data-loss 1.8628e+01                  , pde-loss 3.7062e+03, initc-loss 1.3093e+04                    bc_loss 3.6843e+04\n",
      "Epoch 23560, Training-Loss 2.1637e+01, Data-loss 1.6477e+01                  , pde-loss 4.7389e+03, initc-loss 1.3171e+04                    bc_loss 3.3687e+04\n",
      "Epoch 23570, Training-Loss 2.6101e+01, Data-loss 2.1255e+01                  , pde-loss 3.4559e+03, initc-loss 1.2927e+04                    bc_loss 3.2071e+04\n",
      "Epoch 23580, Training-Loss 2.1012e+01, Data-loss 1.5510e+01                  , pde-loss 4.6488e+03, initc-loss 1.3362e+04                    bc_loss 3.7013e+04\n",
      "Epoch 23590, Training-Loss 2.1679e+01, Data-loss 1.6564e+01                  , pde-loss 4.0311e+03, initc-loss 1.2791e+04                    bc_loss 3.4334e+04\n",
      "Epoch 23600, Training-Loss 1.6677e+01, Data-loss 1.1313e+01                  , pde-loss 4.9660e+03, initc-loss 1.3099e+04                    bc_loss 3.5575e+04\n",
      "Epoch 23610, Training-Loss 2.5482e+01, Data-loss 2.0545e+01                  , pde-loss 4.0398e+03, initc-loss 1.3157e+04                    bc_loss 3.2170e+04\n",
      "Epoch 23620, Training-Loss 2.0533e+01, Data-loss 1.5775e+01                  , pde-loss 3.4899e+03, initc-loss 1.3058e+04                    bc_loss 3.1032e+04\n",
      "Epoch 23630, Training-Loss 2.9758e+01, Data-loss 2.4582e+01                  , pde-loss 3.6245e+03, initc-loss 1.3126e+04                    bc_loss 3.5007e+04\n",
      "Epoch 23640, Training-Loss 2.3259e+01, Data-loss 1.7681e+01                  , pde-loss 3.8078e+03, initc-loss 1.3175e+04                    bc_loss 3.8801e+04\n",
      "Epoch 23650, Training-Loss 2.6339e+01, Data-loss 2.0423e+01                  , pde-loss 4.8681e+03, initc-loss 1.3077e+04                    bc_loss 4.1223e+04\n",
      "Epoch 23660, Training-Loss 2.5311e+01, Data-loss 2.0220e+01                  , pde-loss 3.4967e+03, initc-loss 1.2862e+04                    bc_loss 3.4552e+04\n",
      "Epoch 23670, Training-Loss 2.4589e+01, Data-loss 1.9213e+01                  , pde-loss 4.1269e+03, initc-loss 1.2665e+04                    bc_loss 3.6968e+04\n",
      "Epoch 23680, Training-Loss 2.1496e+01, Data-loss 1.5872e+01                  , pde-loss 4.0531e+03, initc-loss 1.3345e+04                    bc_loss 3.8846e+04\n",
      "Epoch 23690, Training-Loss 2.0994e+01, Data-loss 1.5007e+01                  , pde-loss 2.7584e+03, initc-loss 1.3051e+04                    bc_loss 4.4058e+04\n",
      "Epoch 23700, Training-Loss 4.0149e+01, Data-loss 3.5490e+01                  , pde-loss 4.3382e+03, initc-loss 1.3042e+04                    bc_loss 2.9209e+04\n",
      "Epoch 23710, Training-Loss 1.5358e+01, Data-loss 1.0664e+01                  , pde-loss 3.7344e+03, initc-loss 1.3219e+04                    bc_loss 2.9981e+04\n",
      "Epoch 23720, Training-Loss 2.6083e+01, Data-loss 2.0703e+01                  , pde-loss 4.3036e+03, initc-loss 1.2957e+04                    bc_loss 3.6537e+04\n",
      "Epoch 23730, Training-Loss 2.2826e+01, Data-loss 1.8045e+01                  , pde-loss 4.2118e+03, initc-loss 1.3091e+04                    bc_loss 3.0503e+04\n",
      "Epoch 23740, Training-Loss 2.2244e+01, Data-loss 1.5998e+01                  , pde-loss 4.7202e+03, initc-loss 1.2955e+04                    bc_loss 4.4788e+04\n",
      "Epoch 23750, Training-Loss 1.7785e+01, Data-loss 1.2908e+01                  , pde-loss 3.3357e+03, initc-loss 1.3234e+04                    bc_loss 3.2198e+04\n",
      "Epoch 23760, Training-Loss 3.3997e+01, Data-loss 2.9037e+01                  , pde-loss 3.9320e+03, initc-loss 1.3124e+04                    bc_loss 3.2542e+04\n",
      "Epoch 23770, Training-Loss 2.6860e+01, Data-loss 2.2133e+01                  , pde-loss 4.7986e+03, initc-loss 1.3223e+04                    bc_loss 2.9252e+04\n",
      "Epoch 23780, Training-Loss 2.1753e+01, Data-loss 1.6455e+01                  , pde-loss 4.2228e+03, initc-loss 1.3113e+04                    bc_loss 3.5642e+04\n",
      "Epoch 23790, Training-Loss 2.5385e+01, Data-loss 1.9188e+01                  , pde-loss 3.6763e+03, initc-loss 1.3272e+04                    bc_loss 4.5027e+04\n",
      "Epoch 23800, Training-Loss 2.1067e+01, Data-loss 1.5947e+01                  , pde-loss 4.6972e+03, initc-loss 1.2588e+04                    bc_loss 3.3916e+04\n",
      "Epoch 23810, Training-Loss 2.2556e+01, Data-loss 1.7959e+01                  , pde-loss 4.5449e+03, initc-loss 1.3222e+04                    bc_loss 2.8195e+04\n",
      "Epoch 23820, Training-Loss 3.5172e+01, Data-loss 2.8344e+01                  , pde-loss 4.9358e+03, initc-loss 1.3008e+04                    bc_loss 5.0336e+04\n",
      "Epoch 23830, Training-Loss 2.2304e+01, Data-loss 1.7381e+01                  , pde-loss 3.6320e+03, initc-loss 1.3251e+04                    bc_loss 3.2354e+04\n",
      "Epoch 23840, Training-Loss 1.8099e+01, Data-loss 1.3539e+01                  , pde-loss 3.7097e+03, initc-loss 1.3072e+04                    bc_loss 2.8826e+04\n",
      "Epoch 23850, Training-Loss 3.0804e+01, Data-loss 2.5993e+01                  , pde-loss 3.2495e+03, initc-loss 1.3090e+04                    bc_loss 3.1776e+04\n",
      "Epoch 23860, Training-Loss 2.0984e+01, Data-loss 1.6242e+01                  , pde-loss 4.0344e+03, initc-loss 1.3151e+04                    bc_loss 3.0233e+04\n",
      "Epoch 23870, Training-Loss 1.5059e+01, Data-loss 1.0465e+01                  , pde-loss 5.4110e+03, initc-loss 1.3015e+04                    bc_loss 2.7512e+04\n",
      "Epoch 23880, Training-Loss 1.7209e+01, Data-loss 1.2848e+01                  , pde-loss 3.1320e+03, initc-loss 1.2998e+04                    bc_loss 2.7475e+04\n",
      "Epoch 23890, Training-Loss 1.7397e+01, Data-loss 1.2915e+01                  , pde-loss 4.3160e+03, initc-loss 1.3061e+04                    bc_loss 2.7445e+04\n",
      "Epoch 23900, Training-Loss 1.9963e+01, Data-loss 1.3812e+01                  , pde-loss 3.6012e+03, initc-loss 1.3129e+04                    bc_loss 4.4782e+04\n",
      "Epoch 23910, Training-Loss 2.7831e+01, Data-loss 2.3312e+01                  , pde-loss 4.8128e+03, initc-loss 1.3055e+04                    bc_loss 2.7326e+04\n",
      "Epoch 23920, Training-Loss 2.0059e+01, Data-loss 1.5529e+01                  , pde-loss 5.0932e+03, initc-loss 1.2983e+04                    bc_loss 2.7222e+04\n",
      "Epoch 23930, Training-Loss 2.7309e+01, Data-loss 2.3072e+01                  , pde-loss 4.3673e+03, initc-loss 1.2990e+04                    bc_loss 2.5013e+04\n",
      "Epoch 23940, Training-Loss 2.6947e+01, Data-loss 2.2210e+01                  , pde-loss 5.4854e+03, initc-loss 1.2981e+04                    bc_loss 2.8906e+04\n",
      "Epoch 23950, Training-Loss 2.4204e+01, Data-loss 1.9529e+01                  , pde-loss 4.5168e+03, initc-loss 1.3026e+04                    bc_loss 2.9214e+04\n",
      "Epoch 23960, Training-Loss 3.2715e+01, Data-loss 2.8156e+01                  , pde-loss 5.4394e+03, initc-loss 1.3179e+04                    bc_loss 2.6973e+04\n",
      "Epoch 23970, Training-Loss 2.8198e+01, Data-loss 2.3689e+01                  , pde-loss 4.9354e+03, initc-loss 1.3086e+04                    bc_loss 2.7065e+04\n",
      "Epoch 23980, Training-Loss 1.5623e+01, Data-loss 1.1354e+01                  , pde-loss 3.0277e+03, initc-loss 1.3105e+04                    bc_loss 2.6564e+04\n",
      "Epoch 23990, Training-Loss 2.1896e+01, Data-loss 1.7662e+01                  , pde-loss 4.7256e+03, initc-loss 1.3062e+04                    bc_loss 2.4546e+04\n",
      "Epoch 24000, Training-Loss 2.8213e+01, Data-loss 2.3196e+01                  , pde-loss 4.8634e+03, initc-loss 1.3158e+04                    bc_loss 3.2154e+04\n",
      "Epoch 24010, Training-Loss 1.6682e+01, Data-loss 1.1308e+01                  , pde-loss 3.6964e+03, initc-loss 1.2957e+04                    bc_loss 3.7085e+04\n",
      "Epoch 24020, Training-Loss 1.8334e+01, Data-loss 1.3888e+01                  , pde-loss 4.5120e+03, initc-loss 1.3118e+04                    bc_loss 2.6840e+04\n",
      "Epoch 24030, Training-Loss 1.5121e+01, Data-loss 1.0753e+01                  , pde-loss 4.7385e+03, initc-loss 1.2955e+04                    bc_loss 2.5985e+04\n",
      "Epoch 24040, Training-Loss 1.9047e+01, Data-loss 1.4683e+01                  , pde-loss 3.7034e+03, initc-loss 1.3260e+04                    bc_loss 2.6683e+04\n",
      "Epoch 24050, Training-Loss 2.2554e+01, Data-loss 1.7291e+01                  , pde-loss 4.3814e+03, initc-loss 1.2739e+04                    bc_loss 3.5517e+04\n",
      "Epoch 24060, Training-Loss 2.1895e+01, Data-loss 1.7420e+01                  , pde-loss 4.1815e+03, initc-loss 1.3189e+04                    bc_loss 2.7379e+04\n",
      "Epoch 24070, Training-Loss 1.4108e+01, Data-loss 9.5879e+00                  , pde-loss 4.9105e+03, initc-loss 1.2931e+04                    bc_loss 2.7362e+04\n",
      "Epoch 24080, Training-Loss 1.9311e+01, Data-loss 1.4821e+01                  , pde-loss 3.8491e+03, initc-loss 1.3174e+04                    bc_loss 2.7880e+04\n",
      "Epoch 24090, Training-Loss 2.5359e+01, Data-loss 1.9547e+01                  , pde-loss 5.1710e+03, initc-loss 1.2965e+04                    bc_loss 3.9981e+04\n",
      "Epoch 24100, Training-Loss 1.8705e+01, Data-loss 1.4245e+01                  , pde-loss 3.1770e+03, initc-loss 1.3144e+04                    bc_loss 2.8277e+04\n",
      "Epoch 24110, Training-Loss 1.7852e+01, Data-loss 1.3507e+01                  , pde-loss 3.8707e+03, initc-loss 1.2782e+04                    bc_loss 2.6791e+04\n",
      "Epoch 24120, Training-Loss 1.8916e+01, Data-loss 1.4819e+01                  , pde-loss 3.9274e+03, initc-loss 1.3312e+04                    bc_loss 2.3729e+04\n",
      "Epoch 24130, Training-Loss 1.9139e+01, Data-loss 1.3112e+01                  , pde-loss 4.1676e+03, initc-loss 1.3073e+04                    bc_loss 4.3029e+04\n",
      "Epoch 24140, Training-Loss 2.1123e+01, Data-loss 1.6792e+01                  , pde-loss 4.0976e+03, initc-loss 1.2993e+04                    bc_loss 2.6218e+04\n",
      "Epoch 24150, Training-Loss 1.5014e+01, Data-loss 1.0519e+01                  , pde-loss 4.1450e+03, initc-loss 1.3043e+04                    bc_loss 2.7766e+04\n",
      "Epoch 24160, Training-Loss 1.4033e+01, Data-loss 9.3986e+00                  , pde-loss 4.0473e+03, initc-loss 1.2845e+04                    bc_loss 2.9455e+04\n",
      "Epoch 24170, Training-Loss 1.7356e+01, Data-loss 1.2405e+01                  , pde-loss 4.5827e+03, initc-loss 1.3148e+04                    bc_loss 3.1785e+04\n",
      "Epoch 24180, Training-Loss 2.1966e+01, Data-loss 1.7125e+01                  , pde-loss 5.7191e+03, initc-loss 1.3042e+04                    bc_loss 2.9652e+04\n",
      "Epoch 24190, Training-Loss 2.5279e+01, Data-loss 2.0686e+01                  , pde-loss 5.5529e+03, initc-loss 1.3017e+04                    bc_loss 2.7353e+04\n",
      "Epoch 24200, Training-Loss 1.9280e+01, Data-loss 1.4937e+01                  , pde-loss 5.1322e+03, initc-loss 1.3007e+04                    bc_loss 2.5284e+04\n",
      "Epoch 24210, Training-Loss 1.5244e+01, Data-loss 1.0186e+01                  , pde-loss 3.5665e+03, initc-loss 1.3259e+04                    bc_loss 3.3751e+04\n",
      "Epoch 24220, Training-Loss 1.2873e+01, Data-loss 8.4443e+00                  , pde-loss 3.9472e+03, initc-loss 1.2912e+04                    bc_loss 2.7428e+04\n",
      "Epoch 24230, Training-Loss 1.3499e+01, Data-loss 9.6326e+00                  , pde-loss 3.3631e+03, initc-loss 1.3162e+04                    bc_loss 2.2136e+04\n",
      "Epoch 24240, Training-Loss 1.8904e+01, Data-loss 1.3801e+01                  , pde-loss 4.5794e+03, initc-loss 1.3357e+04                    bc_loss 3.3086e+04\n",
      "Epoch 24250, Training-Loss 1.8392e+01, Data-loss 1.3047e+01                  , pde-loss 5.1167e+03, initc-loss 1.2899e+04                    bc_loss 3.5437e+04\n",
      "Epoch 24260, Training-Loss 2.1202e+01, Data-loss 1.6645e+01                  , pde-loss 4.5895e+03, initc-loss 1.3241e+04                    bc_loss 2.7739e+04\n",
      "Epoch 24270, Training-Loss 2.2107e+01, Data-loss 1.7443e+01                  , pde-loss 5.2792e+03, initc-loss 1.3041e+04                    bc_loss 2.8322e+04\n",
      "Epoch 24280, Training-Loss 2.6670e+01, Data-loss 2.2385e+01                  , pde-loss 4.7921e+03, initc-loss 1.3113e+04                    bc_loss 2.4944e+04\n",
      "Epoch 24290, Training-Loss 1.7579e+01, Data-loss 1.3631e+01                  , pde-loss 4.2890e+03, initc-loss 1.3007e+04                    bc_loss 2.2188e+04\n",
      "Epoch 24300, Training-Loss 1.6408e+01, Data-loss 1.0925e+01                  , pde-loss 3.4575e+03, initc-loss 1.3139e+04                    bc_loss 3.8235e+04\n",
      "Epoch 24310, Training-Loss 2.4183e+01, Data-loss 1.9808e+01                  , pde-loss 4.9973e+03, initc-loss 1.3272e+04                    bc_loss 2.5473e+04\n",
      "Epoch 24320, Training-Loss 2.1270e+01, Data-loss 1.6524e+01                  , pde-loss 3.9266e+03, initc-loss 1.3035e+04                    bc_loss 3.0497e+04\n",
      "Epoch 24330, Training-Loss 2.1932e+01, Data-loss 1.6370e+01                  , pde-loss 4.4236e+03, initc-loss 1.3253e+04                    bc_loss 3.7941e+04\n",
      "Epoch 24340, Training-Loss 1.9765e+01, Data-loss 1.4244e+01                  , pde-loss 4.5608e+03, initc-loss 1.3054e+04                    bc_loss 3.7593e+04\n",
      "Epoch 24350, Training-Loss 2.3363e+01, Data-loss 1.9122e+01                  , pde-loss 5.6670e+03, initc-loss 1.3089e+04                    bc_loss 2.3651e+04\n",
      "Epoch 24360, Training-Loss 1.6941e+01, Data-loss 1.2587e+01                  , pde-loss 5.6640e+03, initc-loss 1.3351e+04                    bc_loss 2.4526e+04\n",
      "Epoch 24370, Training-Loss 1.8051e+01, Data-loss 1.3608e+01                  , pde-loss 4.7775e+03, initc-loss 1.2896e+04                    bc_loss 2.6763e+04\n",
      "Epoch 24380, Training-Loss 1.2006e+01, Data-loss 7.5471e+00                  , pde-loss 4.8134e+03, initc-loss 1.3093e+04                    bc_loss 2.6683e+04\n",
      "Epoch 24390, Training-Loss 1.5610e+01, Data-loss 1.1291e+01                  , pde-loss 3.3041e+03, initc-loss 1.2834e+04                    bc_loss 2.7051e+04\n",
      "Epoch 24400, Training-Loss 1.5088e+01, Data-loss 1.0661e+01                  , pde-loss 4.8552e+03, initc-loss 1.3223e+04                    bc_loss 2.6189e+04\n",
      "Epoch 24410, Training-Loss 1.7382e+01, Data-loss 1.2835e+01                  , pde-loss 5.4831e+03, initc-loss 1.3035e+04                    bc_loss 2.6944e+04\n",
      "Epoch 24420, Training-Loss 1.5361e+01, Data-loss 1.1000e+01                  , pde-loss 5.0041e+03, initc-loss 1.3100e+04                    bc_loss 2.5506e+04\n",
      "Epoch 24430, Training-Loss 1.4911e+01, Data-loss 1.0977e+01                  , pde-loss 4.5003e+03, initc-loss 1.2970e+04                    bc_loss 2.1867e+04\n",
      "Epoch 24440, Training-Loss 1.4803e+01, Data-loss 1.0703e+01                  , pde-loss 3.9152e+03, initc-loss 1.3054e+04                    bc_loss 2.4034e+04\n",
      "Epoch 24450, Training-Loss 1.4128e+01, Data-loss 1.0111e+01                  , pde-loss 4.8705e+03, initc-loss 1.2896e+04                    bc_loss 2.2397e+04\n",
      "Epoch 24460, Training-Loss 1.3996e+01, Data-loss 1.0034e+01                  , pde-loss 4.0442e+03, initc-loss 1.3021e+04                    bc_loss 2.2553e+04\n",
      "Epoch 24470, Training-Loss 1.6552e+01, Data-loss 1.2584e+01                  , pde-loss 3.9632e+03, initc-loss 1.3143e+04                    bc_loss 2.2570e+04\n",
      "Epoch 24480, Training-Loss 1.8055e+01, Data-loss 1.4021e+01                  , pde-loss 5.1062e+03, initc-loss 1.3200e+04                    bc_loss 2.2039e+04\n",
      "Epoch 24490, Training-Loss 1.5208e+01, Data-loss 1.0831e+01                  , pde-loss 4.2174e+03, initc-loss 1.3099e+04                    bc_loss 2.6451e+04\n",
      "Epoch 24500, Training-Loss 1.7270e+01, Data-loss 1.2484e+01                  , pde-loss 4.8239e+03, initc-loss 1.2796e+04                    bc_loss 3.0243e+04\n",
      "Epoch 24510, Training-Loss 1.5549e+01, Data-loss 1.1174e+01                  , pde-loss 4.3890e+03, initc-loss 1.3152e+04                    bc_loss 2.6213e+04\n",
      "Epoch 24520, Training-Loss 1.5396e+01, Data-loss 1.0710e+01                  , pde-loss 5.3625e+03, initc-loss 1.2812e+04                    bc_loss 2.8689e+04\n",
      "Epoch 24530, Training-Loss 2.1880e+01, Data-loss 1.8027e+01                  , pde-loss 5.4418e+03, initc-loss 1.3162e+04                    bc_loss 1.9929e+04\n",
      "Epoch 24540, Training-Loss 1.8537e+01, Data-loss 1.4729e+01                  , pde-loss 4.7232e+03, initc-loss 1.3233e+04                    bc_loss 2.0125e+04\n",
      "Epoch 24550, Training-Loss 1.3294e+01, Data-loss 9.4761e+00                  , pde-loss 4.0741e+03, initc-loss 1.2770e+04                    bc_loss 2.1334e+04\n",
      "Epoch 24560, Training-Loss 2.1548e+01, Data-loss 1.7624e+01                  , pde-loss 6.3357e+03, initc-loss 1.3253e+04                    bc_loss 1.9650e+04\n",
      "Epoch 24570, Training-Loss 1.2535e+01, Data-loss 8.6061e+00                  , pde-loss 5.1103e+03, initc-loss 1.3144e+04                    bc_loss 2.1034e+04\n",
      "Epoch 24580, Training-Loss 2.0417e+01, Data-loss 1.6362e+01                  , pde-loss 4.0852e+03, initc-loss 1.2941e+04                    bc_loss 2.3529e+04\n",
      "Epoch 24590, Training-Loss 2.3699e+01, Data-loss 1.9310e+01                  , pde-loss 4.9075e+03, initc-loss 1.3153e+04                    bc_loss 2.5833e+04\n",
      "Epoch 24600, Training-Loss 1.4620e+01, Data-loss 1.0279e+01                  , pde-loss 4.3289e+03, initc-loss 1.2866e+04                    bc_loss 2.6224e+04\n",
      "Epoch 24610, Training-Loss 1.4451e+01, Data-loss 1.0063e+01                  , pde-loss 4.4975e+03, initc-loss 1.3020e+04                    bc_loss 2.6371e+04\n",
      "Epoch 24620, Training-Loss 1.4896e+01, Data-loss 1.0943e+01                  , pde-loss 6.3878e+03, initc-loss 1.2941e+04                    bc_loss 2.0208e+04\n",
      "Epoch 24630, Training-Loss 1.2359e+01, Data-loss 8.6569e+00                  , pde-loss 3.9640e+03, initc-loss 1.2980e+04                    bc_loss 2.0073e+04\n",
      "Epoch 24640, Training-Loss 1.3641e+01, Data-loss 1.0018e+01                  , pde-loss 4.0873e+03, initc-loss 1.3058e+04                    bc_loss 1.9084e+04\n",
      "Epoch 24650, Training-Loss 1.2503e+01, Data-loss 8.8901e+00                  , pde-loss 3.6741e+03, initc-loss 1.3083e+04                    bc_loss 1.9373e+04\n",
      "Epoch 24660, Training-Loss 1.4550e+01, Data-loss 1.0723e+01                  , pde-loss 4.3376e+03, initc-loss 1.2817e+04                    bc_loss 2.1108e+04\n",
      "Epoch 24670, Training-Loss 1.1892e+01, Data-loss 7.5884e+00                  , pde-loss 4.9256e+03, initc-loss 1.3331e+04                    bc_loss 2.4776e+04\n",
      "Epoch 24680, Training-Loss 2.6361e+01, Data-loss 2.1263e+01                  , pde-loss 3.8995e+03, initc-loss 1.2640e+04                    bc_loss 3.4439e+04\n",
      "Epoch 24690, Training-Loss 1.5671e+01, Data-loss 1.1935e+01                  , pde-loss 5.1932e+03, initc-loss 1.3180e+04                    bc_loss 1.8990e+04\n",
      "Epoch 24700, Training-Loss 1.5249e+01, Data-loss 1.1272e+01                  , pde-loss 4.6876e+03, initc-loss 1.3014e+04                    bc_loss 2.2068e+04\n",
      "Epoch 24710, Training-Loss 1.6246e+01, Data-loss 1.2109e+01                  , pde-loss 4.0793e+03, initc-loss 1.3060e+04                    bc_loss 2.4234e+04\n",
      "Epoch 24720, Training-Loss 2.2435e+01, Data-loss 1.8643e+01                  , pde-loss 5.5065e+03, initc-loss 1.3207e+04                    bc_loss 1.9202e+04\n",
      "Epoch 24730, Training-Loss 1.3365e+01, Data-loss 9.6536e+00                  , pde-loss 5.1951e+03, initc-loss 1.2963e+04                    bc_loss 1.8954e+04\n",
      "Epoch 24740, Training-Loss 1.1836e+01, Data-loss 8.0755e+00                  , pde-loss 5.3323e+03, initc-loss 1.3098e+04                    bc_loss 1.9174e+04\n",
      "Epoch 24750, Training-Loss 1.7150e+01, Data-loss 1.3609e+01                  , pde-loss 3.3520e+03, initc-loss 1.3225e+04                    bc_loss 1.8831e+04\n",
      "Epoch 24760, Training-Loss 1.2701e+01, Data-loss 9.1146e+00                  , pde-loss 4.8105e+03, initc-loss 1.3108e+04                    bc_loss 1.7942e+04\n",
      "Epoch 24770, Training-Loss 1.8300e+01, Data-loss 1.4255e+01                  , pde-loss 4.9568e+03, initc-loss 1.3102e+04                    bc_loss 2.2397e+04\n",
      "Epoch 24780, Training-Loss 1.3432e+01, Data-loss 9.6304e+00                  , pde-loss 4.5804e+03, initc-loss 1.3229e+04                    bc_loss 2.0202e+04\n",
      "Epoch 24790, Training-Loss 1.2963e+01, Data-loss 8.3948e+00                  , pde-loss 4.7419e+03, initc-loss 1.2703e+04                    bc_loss 2.8235e+04\n",
      "Epoch 24800, Training-Loss 1.5882e+01, Data-loss 1.1981e+01                  , pde-loss 4.6617e+03, initc-loss 1.3242e+04                    bc_loss 2.1110e+04\n",
      "Epoch 24810, Training-Loss 1.4626e+01, Data-loss 1.0742e+01                  , pde-loss 4.4912e+03, initc-loss 1.2999e+04                    bc_loss 2.1355e+04\n",
      "Epoch 24820, Training-Loss 1.3207e+01, Data-loss 9.2549e+00                  , pde-loss 5.0958e+03, initc-loss 1.3021e+04                    bc_loss 2.1404e+04\n",
      "Epoch 24830, Training-Loss 1.5034e+01, Data-loss 1.0988e+01                  , pde-loss 4.0990e+03, initc-loss 1.3235e+04                    bc_loss 2.3129e+04\n",
      "Epoch 24840, Training-Loss 1.3759e+01, Data-loss 9.9648e+00                  , pde-loss 5.3003e+03, initc-loss 1.2900e+04                    bc_loss 1.9742e+04\n",
      "Epoch 24850, Training-Loss 1.5764e+01, Data-loss 1.1907e+01                  , pde-loss 5.1848e+03, initc-loss 1.3016e+04                    bc_loss 2.0367e+04\n",
      "Epoch 24860, Training-Loss 1.1423e+01, Data-loss 7.7722e+00                  , pde-loss 4.6709e+03, initc-loss 1.2976e+04                    bc_loss 1.8856e+04\n",
      "Epoch 24870, Training-Loss 1.6266e+01, Data-loss 1.2176e+01                  , pde-loss 5.8334e+03, initc-loss 1.2747e+04                    bc_loss 2.2324e+04\n",
      "Epoch 24880, Training-Loss 1.4929e+01, Data-loss 1.1240e+01                  , pde-loss 3.6313e+03, initc-loss 1.3164e+04                    bc_loss 2.0088e+04\n",
      "Epoch 24890, Training-Loss 1.4569e+01, Data-loss 1.0789e+01                  , pde-loss 3.4664e+03, initc-loss 1.3148e+04                    bc_loss 2.1181e+04\n",
      "Epoch 24900, Training-Loss 1.7839e+01, Data-loss 1.2612e+01                  , pde-loss 6.1556e+03, initc-loss 1.3287e+04                    bc_loss 3.2834e+04\n",
      "Epoch 24910, Training-Loss 2.0724e+01, Data-loss 1.6790e+01                  , pde-loss 5.2889e+03, initc-loss 1.3091e+04                    bc_loss 2.0960e+04\n",
      "Epoch 24920, Training-Loss 2.0426e+01, Data-loss 1.6972e+01                  , pde-loss 4.1753e+03, initc-loss 1.2998e+04                    bc_loss 1.7360e+04\n",
      "Epoch 24930, Training-Loss 1.8405e+01, Data-loss 1.4076e+01                  , pde-loss 6.3423e+03, initc-loss 1.3136e+04                    bc_loss 2.3811e+04\n",
      "Epoch 24940, Training-Loss 1.6392e+01, Data-loss 1.2119e+01                  , pde-loss 5.0086e+03, initc-loss 1.3222e+04                    bc_loss 2.4490e+04\n",
      "Epoch 24950, Training-Loss 1.3179e+01, Data-loss 9.7386e+00                  , pde-loss 4.2171e+03, initc-loss 1.3060e+04                    bc_loss 1.7123e+04\n",
      "Epoch 24960, Training-Loss 1.3447e+01, Data-loss 8.6373e+00                  , pde-loss 5.2334e+03, initc-loss 1.3028e+04                    bc_loss 2.9836e+04\n",
      "Epoch 24970, Training-Loss 1.1928e+01, Data-loss 8.2755e+00                  , pde-loss 3.5736e+03, initc-loss 1.3277e+04                    bc_loss 1.9673e+04\n",
      "Epoch 24980, Training-Loss 1.3517e+01, Data-loss 9.8196e+00                  , pde-loss 6.1308e+03, initc-loss 1.2768e+04                    bc_loss 1.8079e+04\n",
      "Epoch 24990, Training-Loss 1.1402e+01, Data-loss 6.7713e+00                  , pde-loss 6.2234e+03, initc-loss 1.3366e+04                    bc_loss 2.6715e+04\n",
      "Epoch 25000, Training-Loss 1.6456e+01, Data-loss 1.2348e+01                  , pde-loss 5.5689e+03, initc-loss 1.3332e+04                    bc_loss 2.2182e+04\n",
      "Epoch 25010, Training-Loss 1.2945e+01, Data-loss 9.0498e+00                  , pde-loss 5.0391e+03, initc-loss 1.2965e+04                    bc_loss 2.0951e+04\n",
      "Epoch 25020, Training-Loss 1.8310e+01, Data-loss 1.4912e+01                  , pde-loss 4.5171e+03, initc-loss 1.3059e+04                    bc_loss 1.6407e+04\n",
      "Epoch 25030, Training-Loss 1.0424e+01, Data-loss 6.9272e+00                  , pde-loss 3.9956e+03, initc-loss 1.3111e+04                    bc_loss 1.7865e+04\n",
      "Epoch 25040, Training-Loss 1.2518e+01, Data-loss 8.8373e+00                  , pde-loss 5.0712e+03, initc-loss 1.2993e+04                    bc_loss 1.8741e+04\n",
      "Epoch 25050, Training-Loss 1.1396e+01, Data-loss 7.4773e+00                  , pde-loss 4.7067e+03, initc-loss 1.3025e+04                    bc_loss 2.1459e+04\n",
      "Epoch 25060, Training-Loss 1.5098e+01, Data-loss 1.1547e+01                  , pde-loss 5.6865e+03, initc-loss 1.2988e+04                    bc_loss 1.6836e+04\n",
      "Epoch 25070, Training-Loss 1.6149e+01, Data-loss 1.2556e+01                  , pde-loss 4.9987e+03, initc-loss 1.2952e+04                    bc_loss 1.7981e+04\n",
      "Epoch 25080, Training-Loss 1.7089e+01, Data-loss 1.3640e+01                  , pde-loss 4.1865e+03, initc-loss 1.3060e+04                    bc_loss 1.7249e+04\n",
      "Epoch 25090, Training-Loss 1.4596e+01, Data-loss 1.1111e+01                  , pde-loss 5.1025e+03, initc-loss 1.2989e+04                    bc_loss 1.6755e+04\n",
      "Epoch 25100, Training-Loss 1.5643e+01, Data-loss 1.1513e+01                  , pde-loss 5.8582e+03, initc-loss 1.2889e+04                    bc_loss 2.2554e+04\n",
      "Epoch 25110, Training-Loss 1.2186e+01, Data-loss 8.6453e+00                  , pde-loss 4.8770e+03, initc-loss 1.3023e+04                    bc_loss 1.7509e+04\n",
      "Epoch 25120, Training-Loss 1.4536e+01, Data-loss 1.0984e+01                  , pde-loss 6.3816e+03, initc-loss 1.3060e+04                    bc_loss 1.6076e+04\n",
      "Epoch 25130, Training-Loss 2.5069e+01, Data-loss 2.1752e+01                  , pde-loss 5.3234e+03, initc-loss 1.2949e+04                    bc_loss 1.4899e+04\n",
      "Epoch 25140, Training-Loss 1.2758e+01, Data-loss 9.0151e+00                  , pde-loss 4.2137e+03, initc-loss 1.3143e+04                    bc_loss 2.0074e+04\n",
      "Epoch 25150, Training-Loss 1.3169e+01, Data-loss 9.7261e+00                  , pde-loss 4.6887e+03, initc-loss 1.2976e+04                    bc_loss 1.6765e+04\n",
      "Epoch 25160, Training-Loss 2.1497e+01, Data-loss 1.8112e+01                  , pde-loss 5.4742e+03, initc-loss 1.3027e+04                    bc_loss 1.5351e+04\n",
      "Epoch 25170, Training-Loss 9.8954e+00, Data-loss 6.4734e+00                  , pde-loss 5.5968e+03, initc-loss 1.3203e+04                    bc_loss 1.5419e+04\n",
      "Epoch 25180, Training-Loss 1.4162e+01, Data-loss 1.0232e+01                  , pde-loss 4.7114e+03, initc-loss 1.2944e+04                    bc_loss 2.1641e+04\n",
      "Epoch 25190, Training-Loss 1.0655e+01, Data-loss 7.0516e+00                  , pde-loss 4.4571e+03, initc-loss 1.2979e+04                    bc_loss 1.8597e+04\n",
      "Epoch 25200, Training-Loss 1.3595e+01, Data-loss 9.2846e+00                  , pde-loss 5.1986e+03, initc-loss 1.3199e+04                    bc_loss 2.4710e+04\n",
      "Epoch 25210, Training-Loss 1.7044e+01, Data-loss 1.1247e+01                  , pde-loss 4.1909e+03, initc-loss 1.2807e+04                    bc_loss 4.0973e+04\n",
      "Epoch 25220, Training-Loss 2.1466e+01, Data-loss 1.7120e+01                  , pde-loss 4.9506e+03, initc-loss 1.3152e+04                    bc_loss 2.5356e+04\n",
      "Epoch 25230, Training-Loss 1.4953e+01, Data-loss 1.1390e+01                  , pde-loss 5.8313e+03, initc-loss 1.2995e+04                    bc_loss 1.6811e+04\n",
      "Epoch 25240, Training-Loss 1.9382e+01, Data-loss 1.5811e+01                  , pde-loss 5.7225e+03, initc-loss 1.2881e+04                    bc_loss 1.7101e+04\n",
      "Epoch 25250, Training-Loss 1.2734e+01, Data-loss 8.7618e+00                  , pde-loss 5.7885e+03, initc-loss 1.3142e+04                    bc_loss 2.0795e+04\n",
      "Epoch 25260, Training-Loss 9.0036e+00, Data-loss 5.4815e+00                  , pde-loss 5.4270e+03, initc-loss 1.2986e+04                    bc_loss 1.6808e+04\n",
      "Epoch 25270, Training-Loss 9.8470e+00, Data-loss 6.4098e+00                  , pde-loss 5.1251e+03, initc-loss 1.2941e+04                    bc_loss 1.6306e+04\n",
      "Epoch 25280, Training-Loss 1.3045e+01, Data-loss 9.6382e+00                  , pde-loss 5.2581e+03, initc-loss 1.3159e+04                    bc_loss 1.5655e+04\n",
      "Epoch 25290, Training-Loss 1.1651e+01, Data-loss 8.3800e+00                  , pde-loss 4.2555e+03, initc-loss 1.3074e+04                    bc_loss 1.5384e+04\n",
      "Epoch 25300, Training-Loss 1.2460e+01, Data-loss 8.9255e+00                  , pde-loss 5.9395e+03, initc-loss 1.2897e+04                    bc_loss 1.6511e+04\n",
      "Epoch 25310, Training-Loss 2.1424e+01, Data-loss 1.8010e+01                  , pde-loss 5.1242e+03, initc-loss 1.3078e+04                    bc_loss 1.5938e+04\n",
      "Epoch 25320, Training-Loss 1.1295e+01, Data-loss 7.8959e+00                  , pde-loss 4.7583e+03, initc-loss 1.3086e+04                    bc_loss 1.6146e+04\n",
      "Epoch 25330, Training-Loss 1.1046e+01, Data-loss 7.8230e+00                  , pde-loss 4.2293e+03, initc-loss 1.2765e+04                    bc_loss 1.5231e+04\n",
      "Epoch 25340, Training-Loss 1.0362e+01, Data-loss 6.7046e+00                  , pde-loss 6.3065e+03, initc-loss 1.2985e+04                    bc_loss 1.7284e+04\n",
      "Epoch 25350, Training-Loss 1.1442e+01, Data-loss 7.8436e+00                  , pde-loss 4.6293e+03, initc-loss 1.3052e+04                    bc_loss 1.8307e+04\n",
      "Epoch 25360, Training-Loss 1.6168e+01, Data-loss 1.2517e+01                  , pde-loss 5.3165e+03, initc-loss 1.3256e+04                    bc_loss 1.7937e+04\n",
      "Epoch 25370, Training-Loss 1.0300e+01, Data-loss 6.8359e+00                  , pde-loss 4.6929e+03, initc-loss 1.3011e+04                    bc_loss 1.6942e+04\n",
      "Epoch 25380, Training-Loss 1.0995e+01, Data-loss 7.8059e+00                  , pde-loss 3.8084e+03, initc-loss 1.2943e+04                    bc_loss 1.5136e+04\n",
      "Epoch 25390, Training-Loss 1.2486e+01, Data-loss 8.5583e+00                  , pde-loss 4.4139e+03, initc-loss 1.2734e+04                    bc_loss 2.2129e+04\n",
      "Epoch 25400, Training-Loss 1.0575e+01, Data-loss 6.9179e+00                  , pde-loss 5.9534e+03, initc-loss 1.3137e+04                    bc_loss 1.7485e+04\n",
      "Epoch 25410, Training-Loss 1.1412e+01, Data-loss 8.0980e+00                  , pde-loss 5.1455e+03, initc-loss 1.3188e+04                    bc_loss 1.4806e+04\n",
      "Epoch 25420, Training-Loss 1.1000e+01, Data-loss 7.6951e+00                  , pde-loss 5.1846e+03, initc-loss 1.3293e+04                    bc_loss 1.4575e+04\n",
      "Epoch 25430, Training-Loss 1.0084e+01, Data-loss 6.8082e+00                  , pde-loss 4.5553e+03, initc-loss 1.3019e+04                    bc_loss 1.5188e+04\n",
      "Epoch 25440, Training-Loss 9.0159e+00, Data-loss 5.8291e+00                  , pde-loss 4.8081e+03, initc-loss 1.3068e+04                    bc_loss 1.3992e+04\n",
      "Epoch 25450, Training-Loss 1.9823e+01, Data-loss 1.5661e+01                  , pde-loss 3.7970e+03, initc-loss 1.2751e+04                    bc_loss 2.5076e+04\n",
      "Epoch 25460, Training-Loss 1.5585e+01, Data-loss 1.2297e+01                  , pde-loss 4.1327e+03, initc-loss 1.2931e+04                    bc_loss 1.5813e+04\n",
      "Epoch 25470, Training-Loss 1.9534e+01, Data-loss 1.6209e+01                  , pde-loss 5.3366e+03, initc-loss 1.2949e+04                    bc_loss 1.4964e+04\n",
      "Epoch 25480, Training-Loss 1.1300e+01, Data-loss 8.1613e+00                  , pde-loss 4.7896e+03, initc-loss 1.2934e+04                    bc_loss 1.3661e+04\n",
      "Epoch 25490, Training-Loss 7.7711e+00, Data-loss 4.5334e+00                  , pde-loss 5.3219e+03, initc-loss 1.2876e+04                    bc_loss 1.4179e+04\n",
      "Epoch 25500, Training-Loss 9.4022e+00, Data-loss 6.2651e+00                  , pde-loss 4.4959e+03, initc-loss 1.3057e+04                    bc_loss 1.3818e+04\n",
      "Epoch 25510, Training-Loss 9.2668e+00, Data-loss 5.8086e+00                  , pde-loss 6.0082e+03, initc-loss 1.2882e+04                    bc_loss 1.5692e+04\n",
      "Epoch 25520, Training-Loss 1.1196e+01, Data-loss 7.7227e+00                  , pde-loss 3.6207e+03, initc-loss 1.3056e+04                    bc_loss 1.8056e+04\n",
      "Epoch 25530, Training-Loss 1.0637e+01, Data-loss 7.1510e+00                  , pde-loss 4.7290e+03, initc-loss 1.3093e+04                    bc_loss 1.7041e+04\n",
      "Epoch 25540, Training-Loss 1.1484e+01, Data-loss 8.0994e+00                  , pde-loss 4.2394e+03, initc-loss 1.2855e+04                    bc_loss 1.6749e+04\n",
      "Epoch 25550, Training-Loss 8.4641e+00, Data-loss 5.2095e+00                  , pde-loss 5.4905e+03, initc-loss 1.2945e+04                    bc_loss 1.4111e+04\n",
      "Epoch 25560, Training-Loss 1.3835e+01, Data-loss 1.0470e+01                  , pde-loss 4.8474e+03, initc-loss 1.3025e+04                    bc_loss 1.5782e+04\n",
      "Epoch 25570, Training-Loss 1.1884e+01, Data-loss 8.6277e+00                  , pde-loss 4.5287e+03, initc-loss 1.2836e+04                    bc_loss 1.5195e+04\n",
      "Epoch 25580, Training-Loss 8.0430e+00, Data-loss 4.8859e+00                  , pde-loss 5.0200e+03, initc-loss 1.3035e+04                    bc_loss 1.3516e+04\n",
      "Epoch 25590, Training-Loss 1.0148e+01, Data-loss 6.8680e+00                  , pde-loss 4.9774e+03, initc-loss 1.2939e+04                    bc_loss 1.4880e+04\n",
      "Epoch 25600, Training-Loss 1.1097e+01, Data-loss 7.8454e+00                  , pde-loss 5.3922e+03, initc-loss 1.2984e+04                    bc_loss 1.4137e+04\n",
      "Epoch 25610, Training-Loss 9.0703e+00, Data-loss 5.8084e+00                  , pde-loss 5.5875e+03, initc-loss 1.3020e+04                    bc_loss 1.4011e+04\n",
      "Epoch 25620, Training-Loss 1.1672e+01, Data-loss 8.3531e+00                  , pde-loss 4.1945e+03, initc-loss 1.3009e+04                    bc_loss 1.5983e+04\n",
      "Epoch 25630, Training-Loss 1.7539e+01, Data-loss 1.4224e+01                  , pde-loss 5.1509e+03, initc-loss 1.2786e+04                    bc_loss 1.5211e+04\n",
      "Epoch 25640, Training-Loss 1.3677e+01, Data-loss 1.0281e+01                  , pde-loss 4.7158e+03, initc-loss 1.3192e+04                    bc_loss 1.6054e+04\n",
      "Epoch 25650, Training-Loss 9.4490e+00, Data-loss 5.2120e+00                  , pde-loss 4.6460e+03, initc-loss 1.2711e+04                    bc_loss 2.5013e+04\n",
      "Epoch 25660, Training-Loss 1.1942e+01, Data-loss 8.5532e+00                  , pde-loss 4.3846e+03, initc-loss 1.3032e+04                    bc_loss 1.6471e+04\n",
      "Epoch 25670, Training-Loss 1.3667e+01, Data-loss 1.0356e+01                  , pde-loss 5.2603e+03, initc-loss 1.3057e+04                    bc_loss 1.4791e+04\n",
      "Epoch 25680, Training-Loss 1.0023e+01, Data-loss 6.8163e+00                  , pde-loss 4.1588e+03, initc-loss 1.3104e+04                    bc_loss 1.4803e+04\n",
      "Epoch 25690, Training-Loss 1.7366e+01, Data-loss 1.4135e+01                  , pde-loss 4.8147e+03, initc-loss 1.2948e+04                    bc_loss 1.4543e+04\n",
      "Epoch 25700, Training-Loss 1.2388e+01, Data-loss 8.8915e+00                  , pde-loss 7.0990e+03, initc-loss 1.3036e+04                    bc_loss 1.4832e+04\n",
      "Epoch 25710, Training-Loss 8.8121e+00, Data-loss 5.6409e+00                  , pde-loss 5.7246e+03, initc-loss 1.3164e+04                    bc_loss 1.2824e+04\n",
      "Epoch 25720, Training-Loss 8.6925e+00, Data-loss 5.5311e+00                  , pde-loss 4.9351e+03, initc-loss 1.3128e+04                    bc_loss 1.3551e+04\n",
      "Epoch 25730, Training-Loss 9.3411e+00, Data-loss 6.1349e+00                  , pde-loss 5.2734e+03, initc-loss 1.3045e+04                    bc_loss 1.3743e+04\n",
      "Epoch 25740, Training-Loss 1.5690e+01, Data-loss 1.2511e+01                  , pde-loss 5.7225e+03, initc-loss 1.3028e+04                    bc_loss 1.3036e+04\n",
      "Epoch 25750, Training-Loss 1.3432e+01, Data-loss 1.0282e+01                  , pde-loss 5.6152e+03, initc-loss 1.3168e+04                    bc_loss 1.2718e+04\n",
      "Epoch 25760, Training-Loss 1.1269e+01, Data-loss 8.2185e+00                  , pde-loss 5.2802e+03, initc-loss 1.3018e+04                    bc_loss 1.2206e+04\n",
      "Epoch 25770, Training-Loss 1.0746e+01, Data-loss 7.5417e+00                  , pde-loss 5.7547e+03, initc-loss 1.2972e+04                    bc_loss 1.3313e+04\n",
      "Epoch 25780, Training-Loss 6.4041e+00, Data-loss 3.3896e+00                  , pde-loss 4.1613e+03, initc-loss 1.3023e+04                    bc_loss 1.2961e+04\n",
      "Epoch 25790, Training-Loss 1.1066e+01, Data-loss 7.3122e+00                  , pde-loss 5.0153e+03, initc-loss 1.3016e+04                    bc_loss 1.9507e+04\n",
      "Epoch 25800, Training-Loss 1.1139e+01, Data-loss 7.6631e+00                  , pde-loss 6.0218e+03, initc-loss 1.3028e+04                    bc_loss 1.5707e+04\n",
      "Epoch 25810, Training-Loss 1.1977e+01, Data-loss 9.0208e+00                  , pde-loss 4.2789e+03, initc-loss 1.2845e+04                    bc_loss 1.2434e+04\n",
      "Epoch 25820, Training-Loss 1.1487e+01, Data-loss 8.2658e+00                  , pde-loss 5.3180e+03, initc-loss 1.2906e+04                    bc_loss 1.3991e+04\n",
      "Epoch 25830, Training-Loss 1.4103e+01, Data-loss 1.0620e+01                  , pde-loss 5.0818e+03, initc-loss 1.3158e+04                    bc_loss 1.6586e+04\n",
      "Epoch 25840, Training-Loss 1.2200e+01, Data-loss 8.6495e+00                  , pde-loss 5.1122e+03, initc-loss 1.3240e+04                    bc_loss 1.7151e+04\n",
      "Epoch 25850, Training-Loss 1.0304e+01, Data-loss 7.3705e+00                  , pde-loss 3.4989e+03, initc-loss 1.2930e+04                    bc_loss 1.2905e+04\n",
      "Epoch 25860, Training-Loss 1.4180e+01, Data-loss 1.1167e+01                  , pde-loss 5.0197e+03, initc-loss 1.3070e+04                    bc_loss 1.2041e+04\n",
      "Epoch 25870, Training-Loss 1.0602e+01, Data-loss 7.5883e+00                  , pde-loss 4.5905e+03, initc-loss 1.2812e+04                    bc_loss 1.2735e+04\n",
      "Epoch 25880, Training-Loss 1.1355e+01, Data-loss 8.2675e+00                  , pde-loss 5.2039e+03, initc-loss 1.2891e+04                    bc_loss 1.2776e+04\n",
      "Epoch 25890, Training-Loss 8.7593e+00, Data-loss 5.3951e+00                  , pde-loss 6.4384e+03, initc-loss 1.2842e+04                    bc_loss 1.4361e+04\n",
      "Epoch 25900, Training-Loss 1.1927e+01, Data-loss 8.9125e+00                  , pde-loss 5.2288e+03, initc-loss 1.2955e+04                    bc_loss 1.1965e+04\n",
      "Epoch 25910, Training-Loss 8.6135e+00, Data-loss 5.3472e+00                  , pde-loss 5.4837e+03, initc-loss 1.3261e+04                    bc_loss 1.3919e+04\n",
      "Epoch 25920, Training-Loss 1.1628e+01, Data-loss 8.2521e+00                  , pde-loss 5.4836e+03, initc-loss 1.3004e+04                    bc_loss 1.5276e+04\n",
      "Epoch 25930, Training-Loss 8.4478e+00, Data-loss 5.0801e+00                  , pde-loss 4.4357e+03, initc-loss 1.3048e+04                    bc_loss 1.6193e+04\n",
      "Epoch 25940, Training-Loss 1.0039e+01, Data-loss 7.0324e+00                  , pde-loss 4.9612e+03, initc-loss 1.3000e+04                    bc_loss 1.2100e+04\n",
      "Epoch 25950, Training-Loss 9.2110e+00, Data-loss 5.8269e+00                  , pde-loss 4.6969e+03, initc-loss 1.2931e+04                    bc_loss 1.6213e+04\n",
      "Epoch 25960, Training-Loss 1.0621e+01, Data-loss 7.6870e+00                  , pde-loss 4.7989e+03, initc-loss 1.3098e+04                    bc_loss 1.1438e+04\n",
      "Epoch 25970, Training-Loss 8.2622e+00, Data-loss 5.1838e+00                  , pde-loss 5.7058e+03, initc-loss 1.2993e+04                    bc_loss 1.2086e+04\n",
      "Epoch 25980, Training-Loss 1.0621e+01, Data-loss 7.5441e+00                  , pde-loss 5.0385e+03, initc-loss 1.3006e+04                    bc_loss 1.2728e+04\n",
      "Epoch 25990, Training-Loss 9.2722e+00, Data-loss 5.9346e+00                  , pde-loss 5.2593e+03, initc-loss 1.2906e+04                    bc_loss 1.5210e+04\n",
      "Epoch 26000, Training-Loss 9.3268e+00, Data-loss 6.3397e+00                  , pde-loss 5.3749e+03, initc-loss 1.3095e+04                    bc_loss 1.1400e+04\n",
      "Epoch 26010, Training-Loss 1.4400e+01, Data-loss 1.1335e+01                  , pde-loss 5.3792e+03, initc-loss 1.3318e+04                    bc_loss 1.1956e+04\n",
      "Epoch 26020, Training-Loss 1.0892e+01, Data-loss 7.5714e+00                  , pde-loss 5.8764e+03, initc-loss 1.3313e+04                    bc_loss 1.4017e+04\n",
      "Epoch 26030, Training-Loss 1.5292e+01, Data-loss 1.2374e+01                  , pde-loss 4.8937e+03, initc-loss 1.2945e+04                    bc_loss 1.1340e+04\n",
      "Epoch 26040, Training-Loss 1.0705e+01, Data-loss 7.5631e+00                  , pde-loss 6.3933e+03, initc-loss 1.3229e+04                    bc_loss 1.1795e+04\n",
      "Epoch 26050, Training-Loss 9.8152e+00, Data-loss 6.3288e+00                  , pde-loss 6.0488e+03, initc-loss 1.2715e+04                    bc_loss 1.6100e+04\n",
      "Epoch 26060, Training-Loss 7.7672e+00, Data-loss 3.9882e+00                  , pde-loss 4.8944e+03, initc-loss 1.3013e+04                    bc_loss 1.9882e+04\n",
      "Epoch 26070, Training-Loss 1.2286e+01, Data-loss 9.2117e+00                  , pde-loss 5.0607e+03, initc-loss 1.3107e+04                    bc_loss 1.2573e+04\n",
      "Epoch 26080, Training-Loss 9.9254e+00, Data-loss 6.5561e+00                  , pde-loss 5.8516e+03, initc-loss 1.3028e+04                    bc_loss 1.4813e+04\n",
      "Epoch 26090, Training-Loss 1.5752e+01, Data-loss 1.2489e+01                  , pde-loss 6.2869e+03, initc-loss 1.2957e+04                    bc_loss 1.3394e+04\n",
      "Epoch 26100, Training-Loss 1.0522e+01, Data-loss 7.2217e+00                  , pde-loss 4.6815e+03, initc-loss 1.3017e+04                    bc_loss 1.5302e+04\n",
      "Epoch 26110, Training-Loss 1.1924e+01, Data-loss 8.4178e+00                  , pde-loss 6.6071e+03, initc-loss 1.3218e+04                    bc_loss 1.5232e+04\n",
      "Epoch 26120, Training-Loss 1.3999e+01, Data-loss 1.0534e+01                  , pde-loss 5.8421e+03, initc-loss 1.3172e+04                    bc_loss 1.5640e+04\n",
      "Epoch 26130, Training-Loss 1.0957e+01, Data-loss 7.8887e+00                  , pde-loss 4.7078e+03, initc-loss 1.2959e+04                    bc_loss 1.3014e+04\n",
      "Epoch 26140, Training-Loss 1.1005e+01, Data-loss 8.0163e+00                  , pde-loss 4.5978e+03, initc-loss 1.2815e+04                    bc_loss 1.2474e+04\n",
      "Epoch 26150, Training-Loss 1.3535e+01, Data-loss 1.0495e+01                  , pde-loss 6.1386e+03, initc-loss 1.2978e+04                    bc_loss 1.1286e+04\n",
      "Epoch 26160, Training-Loss 8.8153e+00, Data-loss 5.8835e+00                  , pde-loss 5.6061e+03, initc-loss 1.2733e+04                    bc_loss 1.0979e+04\n",
      "Epoch 26170, Training-Loss 8.1308e+00, Data-loss 5.2454e+00                  , pde-loss 5.1176e+03, initc-loss 1.2991e+04                    bc_loss 1.0746e+04\n",
      "Epoch 26180, Training-Loss 9.6928e+00, Data-loss 6.7359e+00                  , pde-loss 5.1989e+03, initc-loss 1.2979e+04                    bc_loss 1.1391e+04\n",
      "Epoch 26190, Training-Loss 8.4583e+00, Data-loss 5.2663e+00                  , pde-loss 5.8218e+03, initc-loss 1.2912e+04                    bc_loss 1.3187e+04\n",
      "Epoch 26200, Training-Loss 9.8643e+00, Data-loss 6.7622e+00                  , pde-loss 5.3598e+03, initc-loss 1.3060e+04                    bc_loss 1.2600e+04\n",
      "Epoch 26210, Training-Loss 8.7629e+00, Data-loss 5.4927e+00                  , pde-loss 5.6077e+03, initc-loss 1.2970e+04                    bc_loss 1.4125e+04\n",
      "Epoch 26220, Training-Loss 8.3189e+00, Data-loss 4.9863e+00                  , pde-loss 5.1687e+03, initc-loss 1.2942e+04                    bc_loss 1.5215e+04\n",
      "Epoch 26230, Training-Loss 1.1281e+01, Data-loss 8.1879e+00                  , pde-loss 5.8186e+03, initc-loss 1.3090e+04                    bc_loss 1.2026e+04\n",
      "Epoch 26240, Training-Loss 1.2888e+01, Data-loss 9.6132e+00                  , pde-loss 4.9587e+03, initc-loss 1.3224e+04                    bc_loss 1.4561e+04\n",
      "Epoch 26250, Training-Loss 9.4614e+00, Data-loss 6.4875e+00                  , pde-loss 5.7431e+03, initc-loss 1.3080e+04                    bc_loss 1.0915e+04\n",
      "Epoch 26260, Training-Loss 1.5059e+01, Data-loss 1.0913e+01                  , pde-loss 5.9084e+03, initc-loss 1.2970e+04                    bc_loss 2.2582e+04\n",
      "Epoch 26270, Training-Loss 1.3336e+01, Data-loss 9.8799e+00                  , pde-loss 4.8206e+03, initc-loss 1.2837e+04                    bc_loss 1.6904e+04\n",
      "Epoch 26280, Training-Loss 1.7596e+01, Data-loss 1.4552e+01                  , pde-loss 5.9421e+03, initc-loss 1.3096e+04                    bc_loss 1.1401e+04\n",
      "Epoch 26290, Training-Loss 1.3503e+01, Data-loss 1.0100e+01                  , pde-loss 5.4047e+03, initc-loss 1.2916e+04                    bc_loss 1.5716e+04\n",
      "Epoch 26300, Training-Loss 2.0493e+01, Data-loss 1.7344e+01                  , pde-loss 3.0463e+03, initc-loss 1.2873e+04                    bc_loss 1.5575e+04\n",
      "Epoch 26310, Training-Loss 1.3617e+01, Data-loss 1.0449e+01                  , pde-loss 4.3050e+03, initc-loss 1.2802e+04                    bc_loss 1.4573e+04\n",
      "Epoch 26320, Training-Loss 1.4698e+01, Data-loss 1.1693e+01                  , pde-loss 4.7067e+03, initc-loss 1.2938e+04                    bc_loss 1.2409e+04\n",
      "Epoch 26330, Training-Loss 1.6555e+01, Data-loss 1.3192e+01                  , pde-loss 5.5307e+03, initc-loss 1.3094e+04                    bc_loss 1.5005e+04\n",
      "Epoch 26340, Training-Loss 1.1574e+01, Data-loss 8.3622e+00                  , pde-loss 6.8304e+03, initc-loss 1.2877e+04                    bc_loss 1.2415e+04\n",
      "Epoch 26350, Training-Loss 1.5346e+01, Data-loss 1.2447e+01                  , pde-loss 5.0126e+03, initc-loss 1.2793e+04                    bc_loss 1.1183e+04\n",
      "Epoch 26360, Training-Loss 7.7085e+00, Data-loss 4.7941e+00                  , pde-loss 4.9288e+03, initc-loss 1.2881e+04                    bc_loss 1.1335e+04\n",
      "Epoch 26370, Training-Loss 1.1262e+01, Data-loss 8.1416e+00                  , pde-loss 6.3548e+03, initc-loss 1.2891e+04                    bc_loss 1.1955e+04\n",
      "Epoch 26380, Training-Loss 1.0584e+01, Data-loss 7.5254e+00                  , pde-loss 5.2291e+03, initc-loss 1.3005e+04                    bc_loss 1.2353e+04\n",
      "Epoch 26390, Training-Loss 1.0924e+01, Data-loss 7.4363e+00                  , pde-loss 6.6270e+03, initc-loss 1.2776e+04                    bc_loss 1.5478e+04\n",
      "Epoch 26400, Training-Loss 1.3731e+01, Data-loss 1.0522e+01                  , pde-loss 5.6706e+03, initc-loss 1.2874e+04                    bc_loss 1.3542e+04\n",
      "Epoch 26410, Training-Loss 9.5480e+00, Data-loss 6.3466e+00                  , pde-loss 6.1724e+03, initc-loss 1.2909e+04                    bc_loss 1.2932e+04\n",
      "Epoch 26420, Training-Loss 9.7602e+00, Data-loss 6.4808e+00                  , pde-loss 5.4157e+03, initc-loss 1.3174e+04                    bc_loss 1.4204e+04\n",
      "Epoch 26430, Training-Loss 1.5002e+01, Data-loss 1.1109e+01                  , pde-loss 4.3808e+03, initc-loss 1.2675e+04                    bc_loss 2.1876e+04\n",
      "Epoch 26440, Training-Loss 1.3983e+01, Data-loss 1.0383e+01                  , pde-loss 5.8438e+03, initc-loss 1.3011e+04                    bc_loss 1.7145e+04\n",
      "Epoch 26450, Training-Loss 7.2145e+00, Data-loss 3.7852e+00                  , pde-loss 5.7212e+03, initc-loss 1.2803e+04                    bc_loss 1.5769e+04\n",
      "Epoch 26460, Training-Loss 1.4357e+01, Data-loss 1.1325e+01                  , pde-loss 6.4823e+03, initc-loss 1.3083e+04                    bc_loss 1.0753e+04\n",
      "Epoch 26470, Training-Loss 9.3394e+00, Data-loss 5.9209e+00                  , pde-loss 5.6965e+03, initc-loss 1.3172e+04                    bc_loss 1.5316e+04\n",
      "Epoch 26480, Training-Loss 1.0520e+01, Data-loss 7.3421e+00                  , pde-loss 5.6548e+03, initc-loss 1.2815e+04                    bc_loss 1.3312e+04\n",
      "Epoch 26490, Training-Loss 9.1566e+00, Data-loss 6.1101e+00                  , pde-loss 3.4109e+03, initc-loss 1.2851e+04                    bc_loss 1.4203e+04\n",
      "Epoch 26500, Training-Loss 9.9652e+00, Data-loss 7.2335e+00                  , pde-loss 4.3957e+03, initc-loss 1.2834e+04                    bc_loss 1.0087e+04\n",
      "Epoch 26510, Training-Loss 1.3151e+01, Data-loss 1.0276e+01                  , pde-loss 4.8716e+03, initc-loss 1.2965e+04                    bc_loss 1.0912e+04\n",
      "Epoch 26520, Training-Loss 8.3887e+00, Data-loss 5.3719e+00                  , pde-loss 4.2218e+03, initc-loss 1.3021e+04                    bc_loss 1.2926e+04\n",
      "Epoch 26530, Training-Loss 1.0199e+01, Data-loss 6.1059e+00                  , pde-loss 4.6999e+03, initc-loss 1.3061e+04                    bc_loss 2.3167e+04\n",
      "Epoch 26540, Training-Loss 1.3176e+01, Data-loss 7.9553e+00                  , pde-loss 5.1305e+03, initc-loss 1.2709e+04                    bc_loss 3.4368e+04\n",
      "Epoch 26550, Training-Loss 1.3081e+01, Data-loss 9.3134e+00                  , pde-loss 4.1185e+03, initc-loss 1.2940e+04                    bc_loss 2.0613e+04\n",
      "Epoch 26560, Training-Loss 8.7585e+00, Data-loss 5.9146e+00                  , pde-loss 4.6226e+03, initc-loss 1.3070e+04                    bc_loss 1.0746e+04\n",
      "Epoch 26570, Training-Loss 8.2800e+00, Data-loss 5.1572e+00                  , pde-loss 4.9872e+03, initc-loss 1.3010e+04                    bc_loss 1.3231e+04\n",
      "Epoch 26580, Training-Loss 8.3946e+00, Data-loss 5.3213e+00                  , pde-loss 4.6390e+03, initc-loss 1.3179e+04                    bc_loss 1.2916e+04\n",
      "Epoch 26590, Training-Loss 1.2143e+01, Data-loss 8.9793e+00                  , pde-loss 4.5179e+03, initc-loss 1.2922e+04                    bc_loss 1.4201e+04\n",
      "Epoch 26600, Training-Loss 9.4750e+00, Data-loss 6.2881e+00                  , pde-loss 6.2612e+03, initc-loss 1.2763e+04                    bc_loss 1.2845e+04\n",
      "Epoch 26610, Training-Loss 8.7941e+00, Data-loss 5.8076e+00                  , pde-loss 6.8045e+03, initc-loss 1.2904e+04                    bc_loss 1.0156e+04\n",
      "Epoch 26620, Training-Loss 8.8220e+00, Data-loss 5.7367e+00                  , pde-loss 6.7919e+03, initc-loss 1.2911e+04                    bc_loss 1.1150e+04\n",
      "Epoch 26630, Training-Loss 1.0129e+01, Data-loss 7.2792e+00                  , pde-loss 3.3068e+03, initc-loss 1.2687e+04                    bc_loss 1.2500e+04\n",
      "Epoch 26640, Training-Loss 6.9187e+00, Data-loss 4.0247e+00                  , pde-loss 5.8910e+03, initc-loss 1.2916e+04                    bc_loss 1.0133e+04\n",
      "Epoch 26650, Training-Loss 9.8757e+00, Data-loss 7.1082e+00                  , pde-loss 3.8584e+03, initc-loss 1.3048e+04                    bc_loss 1.0769e+04\n",
      "Epoch 26660, Training-Loss 7.2473e+00, Data-loss 4.3037e+00                  , pde-loss 5.2963e+03, initc-loss 1.3002e+04                    bc_loss 1.1138e+04\n",
      "Epoch 26670, Training-Loss 8.1432e+00, Data-loss 5.2620e+00                  , pde-loss 6.2637e+03, initc-loss 1.3065e+04                    bc_loss 9.4829e+03\n",
      "Epoch 26680, Training-Loss 7.7593e+00, Data-loss 4.6581e+00                  , pde-loss 5.1992e+03, initc-loss 1.2909e+04                    bc_loss 1.2905e+04\n",
      "Epoch 26690, Training-Loss 7.1203e+00, Data-loss 4.2779e+00                  , pde-loss 6.2187e+03, initc-loss 1.3026e+04                    bc_loss 9.1791e+03\n",
      "Epoch 26700, Training-Loss 1.7031e+01, Data-loss 1.4280e+01                  , pde-loss 4.6019e+03, initc-loss 1.3047e+04                    bc_loss 9.8617e+03\n",
      "Epoch 26710, Training-Loss 6.5288e+00, Data-loss 3.6652e+00                  , pde-loss 5.5030e+03, initc-loss 1.2950e+04                    bc_loss 1.0183e+04\n",
      "Epoch 26720, Training-Loss 9.3631e+00, Data-loss 6.3622e+00                  , pde-loss 5.3536e+03, initc-loss 1.3047e+04                    bc_loss 1.1609e+04\n",
      "Epoch 26730, Training-Loss 8.3560e+00, Data-loss 5.1643e+00                  , pde-loss 4.9057e+03, initc-loss 1.2900e+04                    bc_loss 1.4112e+04\n",
      "Epoch 26740, Training-Loss 9.7548e+00, Data-loss 5.6776e+00                  , pde-loss 5.9644e+03, initc-loss 1.3286e+04                    bc_loss 2.1522e+04\n",
      "Epoch 26750, Training-Loss 7.3510e+00, Data-loss 4.6119e+00                  , pde-loss 3.4517e+03, initc-loss 1.3100e+04                    bc_loss 1.0840e+04\n",
      "Epoch 26760, Training-Loss 9.1804e+00, Data-loss 4.9268e+00                  , pde-loss 4.9876e+03, initc-loss 1.2815e+04                    bc_loss 2.4733e+04\n",
      "Epoch 26770, Training-Loss 8.2138e+00, Data-loss 5.4516e+00                  , pde-loss 4.7962e+03, initc-loss 1.2978e+04                    bc_loss 9.8476e+03\n",
      "Epoch 26780, Training-Loss 1.0115e+01, Data-loss 7.1550e+00                  , pde-loss 6.1708e+03, initc-loss 1.3061e+04                    bc_loss 1.0368e+04\n",
      "Epoch 26790, Training-Loss 8.1165e+00, Data-loss 4.9325e+00                  , pde-loss 6.5056e+03, initc-loss 1.3015e+04                    bc_loss 1.2320e+04\n",
      "Epoch 26800, Training-Loss 1.0270e+01, Data-loss 6.9025e+00                  , pde-loss 6.8485e+03, initc-loss 1.2870e+04                    bc_loss 1.3954e+04\n",
      "Epoch 26810, Training-Loss 9.1283e+00, Data-loss 6.1710e+00                  , pde-loss 5.0158e+03, initc-loss 1.2918e+04                    bc_loss 1.1639e+04\n",
      "Epoch 26820, Training-Loss 7.3221e+00, Data-loss 4.4361e+00                  , pde-loss 5.1012e+03, initc-loss 1.3050e+04                    bc_loss 1.0709e+04\n",
      "Epoch 26830, Training-Loss 8.7039e+00, Data-loss 5.5387e+00                  , pde-loss 5.5506e+03, initc-loss 1.2953e+04                    bc_loss 1.3148e+04\n",
      "Epoch 26840, Training-Loss 1.0326e+01, Data-loss 7.5122e+00                  , pde-loss 5.1999e+03, initc-loss 1.2952e+04                    bc_loss 9.9826e+03\n",
      "Epoch 26850, Training-Loss 1.4046e+01, Data-loss 1.1490e+01                  , pde-loss 3.4941e+03, initc-loss 1.2989e+04                    bc_loss 9.0716e+03\n",
      "Epoch 26860, Training-Loss 9.0886e+00, Data-loss 5.9662e+00                  , pde-loss 6.3715e+03, initc-loss 1.2920e+04                    bc_loss 1.1932e+04\n",
      "Epoch 26870, Training-Loss 1.1082e+01, Data-loss 7.9985e+00                  , pde-loss 5.9825e+03, initc-loss 1.2734e+04                    bc_loss 1.2118e+04\n",
      "Epoch 26880, Training-Loss 8.1569e+00, Data-loss 5.1571e+00                  , pde-loss 5.8905e+03, initc-loss 1.2998e+04                    bc_loss 1.1109e+04\n",
      "Epoch 26890, Training-Loss 9.5418e+00, Data-loss 6.1763e+00                  , pde-loss 5.9429e+03, initc-loss 1.3029e+04                    bc_loss 1.4684e+04\n",
      "Epoch 26900, Training-Loss 9.2971e+00, Data-loss 6.0989e+00                  , pde-loss 5.6604e+03, initc-loss 1.3150e+04                    bc_loss 1.3172e+04\n",
      "Epoch 26910, Training-Loss 8.7751e+00, Data-loss 6.0604e+00                  , pde-loss 4.1550e+03, initc-loss 1.3000e+04                    bc_loss 9.9917e+03\n",
      "Epoch 26920, Training-Loss 9.7865e+00, Data-loss 6.5239e+00                  , pde-loss 5.1256e+03, initc-loss 1.2954e+04                    bc_loss 1.4547e+04\n",
      "Epoch 26930, Training-Loss 1.6992e+01, Data-loss 1.4192e+01                  , pde-loss 6.0025e+03, initc-loss 1.2800e+04                    bc_loss 9.1910e+03\n",
      "Epoch 26940, Training-Loss 1.0924e+01, Data-loss 8.0290e+00                  , pde-loss 4.8265e+03, initc-loss 1.2974e+04                    bc_loss 1.1145e+04\n",
      "Epoch 26950, Training-Loss 6.1510e+00, Data-loss 3.4805e+00                  , pde-loss 4.0776e+03, initc-loss 1.3002e+04                    bc_loss 9.6255e+03\n",
      "Epoch 26960, Training-Loss 1.1854e+01, Data-loss 9.0320e+00                  , pde-loss 5.2687e+03, initc-loss 1.3200e+04                    bc_loss 9.7530e+03\n",
      "Epoch 26970, Training-Loss 8.0484e+00, Data-loss 5.2492e+00                  , pde-loss 5.6462e+03, initc-loss 1.2800e+04                    bc_loss 9.5466e+03\n",
      "Epoch 26980, Training-Loss 8.3240e+00, Data-loss 5.5820e+00                  , pde-loss 5.6789e+03, initc-loss 1.3005e+04                    bc_loss 8.7370e+03\n",
      "Epoch 26990, Training-Loss 8.1028e+00, Data-loss 5.3279e+00                  , pde-loss 5.5500e+03, initc-loss 1.3230e+04                    bc_loss 8.9694e+03\n",
      "Epoch 27000, Training-Loss 1.0693e+01, Data-loss 7.8210e+00                  , pde-loss 5.9676e+03, initc-loss 1.3020e+04                    bc_loss 9.7366e+03\n",
      "Epoch 27010, Training-Loss 9.3989e+00, Data-loss 6.2138e+00                  , pde-loss 7.0830e+03, initc-loss 1.2992e+04                    bc_loss 1.1776e+04\n",
      "Epoch 27020, Training-Loss 8.6112e+00, Data-loss 5.6888e+00                  , pde-loss 5.8254e+03, initc-loss 1.3046e+04                    bc_loss 1.0353e+04\n",
      "Epoch 27030, Training-Loss 8.3457e+00, Data-loss 5.6491e+00                  , pde-loss 5.3172e+03, initc-loss 1.3076e+04                    bc_loss 8.5725e+03\n",
      "Epoch 27040, Training-Loss 9.0806e+00, Data-loss 5.9904e+00                  , pde-loss 6.0450e+03, initc-loss 1.3068e+04                    bc_loss 1.1789e+04\n",
      "Epoch 27050, Training-Loss 7.2368e+00, Data-loss 4.0251e+00                  , pde-loss 6.2004e+03, initc-loss 1.2932e+04                    bc_loss 1.2985e+04\n",
      "Epoch 27060, Training-Loss 8.5632e+00, Data-loss 5.6468e+00                  , pde-loss 5.9600e+03, initc-loss 1.3085e+04                    bc_loss 1.0119e+04\n",
      "Epoch 27070, Training-Loss 6.7148e+00, Data-loss 3.8566e+00                  , pde-loss 6.2658e+03, initc-loss 1.2902e+04                    bc_loss 9.4144e+03\n",
      "Epoch 27080, Training-Loss 1.4614e+01, Data-loss 1.1905e+01                  , pde-loss 5.5084e+03, initc-loss 1.3079e+04                    bc_loss 8.5047e+03\n",
      "Epoch 27090, Training-Loss 1.3351e+01, Data-loss 1.0620e+01                  , pde-loss 5.5682e+03, initc-loss 1.3195e+04                    bc_loss 8.5499e+03\n",
      "Epoch 27100, Training-Loss 9.1921e+00, Data-loss 6.4077e+00                  , pde-loss 5.8622e+03, initc-loss 1.3064e+04                    bc_loss 8.9183e+03\n",
      "Epoch 27110, Training-Loss 5.7355e+00, Data-loss 2.9702e+00                  , pde-loss 6.2262e+03, initc-loss 1.3106e+04                    bc_loss 8.3203e+03\n",
      "Epoch 27120, Training-Loss 1.0767e+01, Data-loss 7.8998e+00                  , pde-loss 6.7885e+03, initc-loss 1.3083e+04                    bc_loss 8.8034e+03\n",
      "Epoch 27130, Training-Loss 9.2014e+00, Data-loss 6.3075e+00                  , pde-loss 5.9213e+03, initc-loss 1.2972e+04                    bc_loss 1.0046e+04\n",
      "Epoch 27140, Training-Loss 6.6004e+00, Data-loss 3.9660e+00                  , pde-loss 4.4389e+03, initc-loss 1.2919e+04                    bc_loss 8.9863e+03\n",
      "Epoch 27150, Training-Loss 1.1001e+01, Data-loss 8.0521e+00                  , pde-loss 5.7299e+03, initc-loss 1.2934e+04                    bc_loss 1.0827e+04\n",
      "Epoch 27160, Training-Loss 9.1446e+00, Data-loss 6.1925e+00                  , pde-loss 6.2605e+03, initc-loss 1.3075e+04                    bc_loss 1.0186e+04\n",
      "Epoch 27170, Training-Loss 1.0495e+01, Data-loss 7.6904e+00                  , pde-loss 4.8891e+03, initc-loss 1.2849e+04                    bc_loss 1.0313e+04\n",
      "Epoch 27180, Training-Loss 9.8487e+00, Data-loss 6.5962e+00                  , pde-loss 5.3394e+03, initc-loss 1.2758e+04                    bc_loss 1.4427e+04\n",
      "Epoch 27190, Training-Loss 9.1570e+00, Data-loss 6.1850e+00                  , pde-loss 4.7943e+03, initc-loss 1.2953e+04                    bc_loss 1.1973e+04\n",
      "Epoch 27200, Training-Loss 1.2672e+01, Data-loss 9.0738e+00                  , pde-loss 5.7568e+03, initc-loss 1.3004e+04                    bc_loss 1.7223e+04\n",
      "Epoch 27210, Training-Loss 1.0021e+01, Data-loss 7.3846e+00                  , pde-loss 5.2577e+03, initc-loss 1.2923e+04                    bc_loss 8.1871e+03\n",
      "Epoch 27220, Training-Loss 1.0733e+01, Data-loss 8.0631e+00                  , pde-loss 4.8151e+03, initc-loss 1.2929e+04                    bc_loss 8.9509e+03\n",
      "Epoch 27230, Training-Loss 8.0991e+00, Data-loss 4.9264e+00                  , pde-loss 6.8051e+03, initc-loss 1.2909e+04                    bc_loss 1.2013e+04\n",
      "Epoch 27240, Training-Loss 7.0299e+00, Data-loss 4.3694e+00                  , pde-loss 5.6455e+03, initc-loss 1.2859e+04                    bc_loss 8.1008e+03\n",
      "Epoch 27250, Training-Loss 7.2367e+00, Data-loss 4.5296e+00                  , pde-loss 5.8731e+03, initc-loss 1.2997e+04                    bc_loss 8.2011e+03\n",
      "Epoch 27260, Training-Loss 9.9285e+00, Data-loss 7.1512e+00                  , pde-loss 5.9069e+03, initc-loss 1.2979e+04                    bc_loss 8.8866e+03\n",
      "Epoch 27270, Training-Loss 9.0213e+00, Data-loss 6.3332e+00                  , pde-loss 5.8557e+03, initc-loss 1.2748e+04                    bc_loss 8.2767e+03\n",
      "Epoch 27280, Training-Loss 7.1001e+00, Data-loss 4.5490e+00                  , pde-loss 5.0825e+03, initc-loss 1.2947e+04                    bc_loss 7.4817e+03\n",
      "Epoch 27290, Training-Loss 6.7659e+00, Data-loss 3.4799e+00                  , pde-loss 6.1186e+03, initc-loss 1.2916e+04                    bc_loss 1.3825e+04\n",
      "Epoch 27300, Training-Loss 6.5842e+00, Data-loss 3.8117e+00                  , pde-loss 4.9722e+03, initc-loss 1.2826e+04                    bc_loss 9.9264e+03\n",
      "Epoch 27310, Training-Loss 1.2586e+01, Data-loss 9.5025e+00                  , pde-loss 4.6448e+03, initc-loss 1.2883e+04                    bc_loss 1.3310e+04\n",
      "Epoch 27320, Training-Loss 7.5306e+00, Data-loss 4.6679e+00                  , pde-loss 6.0257e+03, initc-loss 1.3015e+04                    bc_loss 9.5863e+03\n",
      "Epoch 27330, Training-Loss 9.4058e+00, Data-loss 5.8954e+00                  , pde-loss 6.6238e+03, initc-loss 1.3257e+04                    bc_loss 1.5222e+04\n",
      "Epoch 27340, Training-Loss 8.1045e+00, Data-loss 5.6683e+00                  , pde-loss 3.7668e+03, initc-loss 1.2916e+04                    bc_loss 7.6791e+03\n",
      "Epoch 27350, Training-Loss 8.7199e+00, Data-loss 6.0062e+00                  , pde-loss 6.4261e+03, initc-loss 1.2865e+04                    bc_loss 7.8458e+03\n",
      "Epoch 27360, Training-Loss 1.0003e+01, Data-loss 7.0585e+00                  , pde-loss 5.2388e+03, initc-loss 1.3111e+04                    bc_loss 1.1097e+04\n",
      "Epoch 27370, Training-Loss 6.7946e+00, Data-loss 4.0668e+00                  , pde-loss 5.4749e+03, initc-loss 1.3047e+04                    bc_loss 8.7554e+03\n",
      "Epoch 27380, Training-Loss 5.5709e+00, Data-loss 2.8155e+00                  , pde-loss 5.9208e+03, initc-loss 1.3034e+04                    bc_loss 8.5994e+03\n",
      "Epoch 27390, Training-Loss 7.6893e+00, Data-loss 5.3162e+00                  , pde-loss 3.3725e+03, initc-loss 1.2858e+04                    bc_loss 7.5001e+03\n",
      "Epoch 27400, Training-Loss 8.3393e+00, Data-loss 5.4365e+00                  , pde-loss 5.7116e+03, initc-loss 1.2958e+04                    bc_loss 1.0359e+04\n",
      "Epoch 27410, Training-Loss 1.3388e+01, Data-loss 8.9334e+00                  , pde-loss 5.2282e+03, initc-loss 1.3241e+04                    bc_loss 2.6081e+04\n",
      "Epoch 27420, Training-Loss 7.8865e+00, Data-loss 4.8044e+00                  , pde-loss 4.8288e+03, initc-loss 1.2961e+04                    bc_loss 1.3032e+04\n",
      "Epoch 27430, Training-Loss 7.0670e+00, Data-loss 4.0870e+00                  , pde-loss 6.0940e+03, initc-loss 1.3016e+04                    bc_loss 1.0690e+04\n",
      "Epoch 27440, Training-Loss 7.1938e+00, Data-loss 4.4603e+00                  , pde-loss 5.2005e+03, initc-loss 1.3061e+04                    bc_loss 9.0732e+03\n",
      "Epoch 27450, Training-Loss 8.4789e+00, Data-loss 5.4285e+00                  , pde-loss 5.3084e+03, initc-loss 1.2987e+04                    bc_loss 1.2209e+04\n",
      "Epoch 27460, Training-Loss 8.4151e+00, Data-loss 5.5595e+00                  , pde-loss 6.2666e+03, initc-loss 1.2961e+04                    bc_loss 9.3288e+03\n",
      "Epoch 27470, Training-Loss 7.5915e+00, Data-loss 4.9926e+00                  , pde-loss 5.4332e+03, initc-loss 1.3177e+04                    bc_loss 7.3790e+03\n",
      "Epoch 27480, Training-Loss 7.1832e+00, Data-loss 4.2241e+00                  , pde-loss 6.7814e+03, initc-loss 1.3114e+04                    bc_loss 9.6957e+03\n",
      "Epoch 27490, Training-Loss 7.1785e+00, Data-loss 4.0739e+00                  , pde-loss 6.7813e+03, initc-loss 1.2885e+04                    bc_loss 1.1381e+04\n",
      "Epoch 27500, Training-Loss 9.1327e+00, Data-loss 6.5131e+00                  , pde-loss 5.8310e+03, initc-loss 1.3132e+04                    bc_loss 7.2333e+03\n",
      "Epoch 27510, Training-Loss 9.7449e+00, Data-loss 7.1749e+00                  , pde-loss 5.1807e+03, initc-loss 1.3046e+04                    bc_loss 7.4726e+03\n",
      "Epoch 27520, Training-Loss 7.9242e+00, Data-loss 5.0175e+00                  , pde-loss 7.1429e+03, initc-loss 1.2941e+04                    bc_loss 8.9833e+03\n",
      "Epoch 27530, Training-Loss 7.1918e+00, Data-loss 4.3516e+00                  , pde-loss 4.8934e+03, initc-loss 1.2887e+04                    bc_loss 1.0621e+04\n",
      "Epoch 27540, Training-Loss 6.3334e+00, Data-loss 3.5518e+00                  , pde-loss 5.5098e+03, initc-loss 1.2955e+04                    bc_loss 9.3516e+03\n",
      "Epoch 27550, Training-Loss 9.7520e+00, Data-loss 5.8453e+00                  , pde-loss 6.1935e+03, initc-loss 1.2587e+04                    bc_loss 2.0286e+04\n",
      "Epoch 27560, Training-Loss 1.1075e+01, Data-loss 6.6901e+00                  , pde-loss 5.2265e+03, initc-loss 1.2629e+04                    bc_loss 2.5998e+04\n",
      "Epoch 27570, Training-Loss 9.2201e+00, Data-loss 6.3812e+00                  , pde-loss 4.7515e+03, initc-loss 1.2835e+04                    bc_loss 1.0803e+04\n",
      "Epoch 27580, Training-Loss 7.9699e+00, Data-loss 5.1648e+00                  , pde-loss 5.8074e+03, initc-loss 1.3011e+04                    bc_loss 9.2327e+03\n",
      "Epoch 27590, Training-Loss 6.4741e+00, Data-loss 3.5822e+00                  , pde-loss 5.3352e+03, initc-loss 1.2804e+04                    bc_loss 1.0780e+04\n",
      "Epoch 27600, Training-Loss 1.0269e+01, Data-loss 7.2131e+00                  , pde-loss 5.8126e+03, initc-loss 1.3174e+04                    bc_loss 1.1568e+04\n",
      "Epoch 27610, Training-Loss 9.2553e+00, Data-loss 6.5578e+00                  , pde-loss 6.6553e+03, initc-loss 1.3144e+04                    bc_loss 7.1759e+03\n",
      "Epoch 27620, Training-Loss 9.3494e+00, Data-loss 6.6473e+00                  , pde-loss 6.1137e+03, initc-loss 1.2990e+04                    bc_loss 7.9168e+03\n",
      "Epoch 27630, Training-Loss 7.0775e+00, Data-loss 3.9725e+00                  , pde-loss 4.9694e+03, initc-loss 1.2862e+04                    bc_loss 1.3219e+04\n",
      "Epoch 27640, Training-Loss 6.4080e+00, Data-loss 3.6527e+00                  , pde-loss 4.1418e+03, initc-loss 1.2942e+04                    bc_loss 1.0469e+04\n",
      "Epoch 27650, Training-Loss 1.0677e+01, Data-loss 7.6559e+00                  , pde-loss 7.2212e+03, initc-loss 1.3053e+04                    bc_loss 9.9391e+03\n",
      "Epoch 27660, Training-Loss 8.6725e+00, Data-loss 5.3118e+00                  , pde-loss 6.2048e+03, initc-loss 1.2821e+04                    bc_loss 1.4581e+04\n",
      "Epoch 27670, Training-Loss 7.8118e+00, Data-loss 5.1127e+00                  , pde-loss 6.6543e+03, initc-loss 1.2956e+04                    bc_loss 7.3811e+03\n",
      "Epoch 27680, Training-Loss 8.0940e+00, Data-loss 5.5243e+00                  , pde-loss 5.0028e+03, initc-loss 1.2993e+04                    bc_loss 7.7007e+03\n",
      "Epoch 27690, Training-Loss 7.2452e+00, Data-loss 4.4226e+00                  , pde-loss 6.4236e+03, initc-loss 1.2890e+04                    bc_loss 8.9125e+03\n",
      "Epoch 27700, Training-Loss 7.2236e+00, Data-loss 3.9071e+00                  , pde-loss 5.8606e+03, initc-loss 1.2677e+04                    bc_loss 1.4627e+04\n",
      "Epoch 27710, Training-Loss 8.0226e+00, Data-loss 5.0775e+00                  , pde-loss 4.1014e+03, initc-loss 1.2918e+04                    bc_loss 1.2432e+04\n",
      "Epoch 27720, Training-Loss 8.0834e+00, Data-loss 5.3257e+00                  , pde-loss 6.1233e+03, initc-loss 1.2879e+04                    bc_loss 8.5744e+03\n",
      "Epoch 27730, Training-Loss 8.1305e+00, Data-loss 5.0829e+00                  , pde-loss 7.7667e+03, initc-loss 1.3013e+04                    bc_loss 9.6965e+03\n",
      "Epoch 27740, Training-Loss 7.4507e+00, Data-loss 4.6178e+00                  , pde-loss 6.6886e+03, initc-loss 1.2926e+04                    bc_loss 8.7146e+03\n",
      "Epoch 27750, Training-Loss 5.9721e+00, Data-loss 2.9301e+00                  , pde-loss 5.9950e+03, initc-loss 1.2947e+04                    bc_loss 1.1478e+04\n",
      "Epoch 27760, Training-Loss 8.5226e+00, Data-loss 5.6046e+00                  , pde-loss 5.0270e+03, initc-loss 1.2867e+04                    bc_loss 1.1286e+04\n",
      "Epoch 27770, Training-Loss 5.3334e+00, Data-loss 2.7618e+00                  , pde-loss 5.1598e+03, initc-loss 1.2948e+04                    bc_loss 7.6077e+03\n",
      "Epoch 27780, Training-Loss 8.4831e+00, Data-loss 5.1142e+00                  , pde-loss 8.8363e+03, initc-loss 1.3093e+04                    bc_loss 1.1759e+04\n",
      "Epoch 27790, Training-Loss 9.9199e+00, Data-loss 7.3594e+00                  , pde-loss 5.3992e+03, initc-loss 1.2950e+04                    bc_loss 7.2564e+03\n",
      "Epoch 27800, Training-Loss 7.2346e+00, Data-loss 4.6828e+00                  , pde-loss 5.6937e+03, initc-loss 1.3036e+04                    bc_loss 6.7883e+03\n",
      "Epoch 27810, Training-Loss 6.4368e+00, Data-loss 3.7237e+00                  , pde-loss 5.1254e+03, initc-loss 1.3032e+04                    bc_loss 8.9747e+03\n",
      "Epoch 27820, Training-Loss 6.0520e+00, Data-loss 3.3708e+00                  , pde-loss 4.1682e+03, initc-loss 1.3000e+04                    bc_loss 9.6440e+03\n",
      "Epoch 27830, Training-Loss 5.5235e+00, Data-loss 2.9424e+00                  , pde-loss 6.0242e+03, initc-loss 1.2901e+04                    bc_loss 6.8855e+03\n",
      "Epoch 27840, Training-Loss 6.2358e+00, Data-loss 3.8206e+00                  , pde-loss 4.1993e+03, initc-loss 1.2989e+04                    bc_loss 6.9644e+03\n",
      "Epoch 27850, Training-Loss 6.9445e+00, Data-loss 4.0677e+00                  , pde-loss 4.9367e+03, initc-loss 1.2777e+04                    bc_loss 1.1055e+04\n",
      "Epoch 27860, Training-Loss 6.5907e+00, Data-loss 4.0981e+00                  , pde-loss 4.7881e+03, initc-loss 1.2938e+04                    bc_loss 7.1997e+03\n",
      "Epoch 27870, Training-Loss 6.6462e+00, Data-loss 3.9787e+00                  , pde-loss 6.0356e+03, initc-loss 1.2961e+04                    bc_loss 7.6786e+03\n",
      "Epoch 27880, Training-Loss 5.3691e+00, Data-loss 2.7851e+00                  , pde-loss 5.5084e+03, initc-loss 1.2956e+04                    bc_loss 7.3754e+03\n",
      "Epoch 27890, Training-Loss 8.4794e+00, Data-loss 5.8856e+00                  , pde-loss 4.7392e+03, initc-loss 1.3003e+04                    bc_loss 8.1954e+03\n",
      "Epoch 27900, Training-Loss 7.3547e+00, Data-loss 4.7677e+00                  , pde-loss 6.0808e+03, initc-loss 1.2898e+04                    bc_loss 6.8903e+03\n",
      "Epoch 27910, Training-Loss 6.9616e+00, Data-loss 4.0757e+00                  , pde-loss 8.2190e+03, initc-loss 1.2905e+04                    bc_loss 7.7361e+03\n",
      "Epoch 27920, Training-Loss 5.5614e+00, Data-loss 3.0977e+00                  , pde-loss 4.1714e+03, initc-loss 1.2780e+04                    bc_loss 7.6850e+03\n",
      "Epoch 27930, Training-Loss 7.9304e+00, Data-loss 5.5644e+00                  , pde-loss 3.6160e+03, initc-loss 1.2817e+04                    bc_loss 7.2273e+03\n",
      "Epoch 27940, Training-Loss 1.2560e+01, Data-loss 9.8035e+00                  , pde-loss 6.5627e+03, initc-loss 1.2957e+04                    bc_loss 8.0483e+03\n",
      "Epoch 27950, Training-Loss 6.5822e+00, Data-loss 3.8303e+00                  , pde-loss 5.1229e+03, initc-loss 1.3213e+04                    bc_loss 9.1833e+03\n",
      "Epoch 27960, Training-Loss 6.2401e+00, Data-loss 3.5807e+00                  , pde-loss 5.6593e+03, initc-loss 1.3035e+04                    bc_loss 7.8993e+03\n",
      "Epoch 27970, Training-Loss 8.4591e+00, Data-loss 5.8848e+00                  , pde-loss 6.1826e+03, initc-loss 1.3001e+04                    bc_loss 6.5596e+03\n",
      "Epoch 27980, Training-Loss 8.1993e+00, Data-loss 5.3339e+00                  , pde-loss 6.7598e+03, initc-loss 1.2991e+04                    bc_loss 8.9039e+03\n",
      "Epoch 27990, Training-Loss 7.1918e+00, Data-loss 4.1855e+00                  , pde-loss 5.6736e+03, initc-loss 1.2821e+04                    bc_loss 1.1569e+04\n",
      "Epoch 28000, Training-Loss 8.4921e+00, Data-loss 5.5046e+00                  , pde-loss 6.3244e+03, initc-loss 1.2995e+04                    bc_loss 1.0556e+04\n",
      "Epoch 28010, Training-Loss 6.5042e+00, Data-loss 3.7016e+00                  , pde-loss 7.1585e+03, initc-loss 1.2870e+04                    bc_loss 7.9977e+03\n",
      "Epoch 28020, Training-Loss 8.3841e+00, Data-loss 5.8774e+00                  , pde-loss 5.8247e+03, initc-loss 1.2756e+04                    bc_loss 6.4862e+03\n",
      "Epoch 28030, Training-Loss 6.0062e+00, Data-loss 3.0112e+00                  , pde-loss 5.8687e+03, initc-loss 1.2972e+04                    bc_loss 1.1109e+04\n",
      "Epoch 28040, Training-Loss 6.7854e+00, Data-loss 4.3058e+00                  , pde-loss 5.3890e+03, initc-loss 1.3079e+04                    bc_loss 6.3283e+03\n",
      "Epoch 28050, Training-Loss 1.1984e+01, Data-loss 9.3256e+00                  , pde-loss 5.9719e+03, initc-loss 1.3140e+04                    bc_loss 7.4737e+03\n",
      "Epoch 28060, Training-Loss 1.1375e+01, Data-loss 8.1978e+00                  , pde-loss 5.8857e+03, initc-loss 1.2847e+04                    bc_loss 1.3041e+04\n",
      "Epoch 28070, Training-Loss 6.8360e+00, Data-loss 4.2619e+00                  , pde-loss 3.8400e+03, initc-loss 1.3231e+04                    bc_loss 8.6696e+03\n",
      "Epoch 28080, Training-Loss 7.3129e+00, Data-loss 4.3431e+00                  , pde-loss 4.3484e+03, initc-loss 1.3059e+04                    bc_loss 1.2291e+04\n",
      "Epoch 28090, Training-Loss 7.9958e+00, Data-loss 5.4426e+00                  , pde-loss 5.0657e+03, initc-loss 1.2960e+04                    bc_loss 7.5061e+03\n",
      "Epoch 28100, Training-Loss 5.2526e+00, Data-loss 2.6524e+00                  , pde-loss 4.7467e+03, initc-loss 1.2910e+04                    bc_loss 8.3453e+03\n",
      "Epoch 28110, Training-Loss 9.0200e+00, Data-loss 6.5066e+00                  , pde-loss 5.4072e+03, initc-loss 1.3002e+04                    bc_loss 6.7254e+03\n",
      "Epoch 28120, Training-Loss 7.2077e+00, Data-loss 4.6802e+00                  , pde-loss 5.2190e+03, initc-loss 1.2695e+04                    bc_loss 7.3614e+03\n",
      "Epoch 28130, Training-Loss 8.2888e+00, Data-loss 5.7588e+00                  , pde-loss 4.5623e+03, initc-loss 1.2822e+04                    bc_loss 7.9160e+03\n",
      "Epoch 28140, Training-Loss 7.4363e+00, Data-loss 4.6890e+00                  , pde-loss 7.6452e+03, initc-loss 1.2987e+04                    bc_loss 6.8403e+03\n",
      "Epoch 28150, Training-Loss 6.1180e+00, Data-loss 3.4281e+00                  , pde-loss 5.4159e+03, initc-loss 1.3043e+04                    bc_loss 8.4404e+03\n",
      "Epoch 28160, Training-Loss 5.5617e+00, Data-loss 2.9914e+00                  , pde-loss 5.2829e+03, initc-loss 1.3070e+04                    bc_loss 7.3502e+03\n",
      "Epoch 28170, Training-Loss 5.1754e+00, Data-loss 2.6337e+00                  , pde-loss 4.8577e+03, initc-loss 1.3114e+04                    bc_loss 7.4458e+03\n",
      "Epoch 28180, Training-Loss 7.1151e+00, Data-loss 4.4403e+00                  , pde-loss 6.3585e+03, initc-loss 1.3050e+04                    bc_loss 7.3400e+03\n",
      "Epoch 28190, Training-Loss 7.7034e+00, Data-loss 5.1586e+00                  , pde-loss 6.5310e+03, initc-loss 1.3106e+04                    bc_loss 5.8111e+03\n",
      "Epoch 28200, Training-Loss 8.7178e+00, Data-loss 6.2024e+00                  , pde-loss 5.6544e+03, initc-loss 1.2983e+04                    bc_loss 6.5172e+03\n",
      "Epoch 28210, Training-Loss 6.2057e+00, Data-loss 3.8396e+00                  , pde-loss 4.8466e+03, initc-loss 1.2893e+04                    bc_loss 5.9214e+03\n",
      "Epoch 28220, Training-Loss 7.0438e+00, Data-loss 4.6105e+00                  , pde-loss 5.3272e+03, initc-loss 1.2880e+04                    bc_loss 6.1255e+03\n",
      "Epoch 28230, Training-Loss 5.7332e+00, Data-loss 3.1437e+00                  , pde-loss 5.2016e+03, initc-loss 1.3067e+04                    bc_loss 7.6265e+03\n",
      "Epoch 28240, Training-Loss 9.7192e+00, Data-loss 6.7254e+00                  , pde-loss 4.6261e+03, initc-loss 1.2872e+04                    bc_loss 1.2441e+04\n",
      "Epoch 28250, Training-Loss 5.4058e+00, Data-loss 2.9415e+00                  , pde-loss 4.7937e+03, initc-loss 1.2965e+04                    bc_loss 6.8838e+03\n",
      "Epoch 28260, Training-Loss 7.4171e+00, Data-loss 4.8493e+00                  , pde-loss 5.6282e+03, initc-loss 1.3060e+04                    bc_loss 6.9898e+03\n",
      "Epoch 28270, Training-Loss 6.5551e+00, Data-loss 3.9841e+00                  , pde-loss 5.3024e+03, initc-loss 1.2851e+04                    bc_loss 7.5564e+03\n",
      "Epoch 28280, Training-Loss 8.7169e+00, Data-loss 5.4225e+00                  , pde-loss 6.3018e+03, initc-loss 1.2818e+04                    bc_loss 1.3824e+04\n",
      "Epoch 28290, Training-Loss 7.1719e+00, Data-loss 4.6749e+00                  , pde-loss 5.4209e+03, initc-loss 1.2997e+04                    bc_loss 6.5524e+03\n",
      "Epoch 28300, Training-Loss 5.8802e+00, Data-loss 3.3573e+00                  , pde-loss 5.8961e+03, initc-loss 1.3049e+04                    bc_loss 6.2843e+03\n",
      "Epoch 28310, Training-Loss 7.1108e+00, Data-loss 4.7752e+00                  , pde-loss 4.3535e+03, initc-loss 1.2922e+04                    bc_loss 6.0803e+03\n",
      "Epoch 28320, Training-Loss 6.3326e+00, Data-loss 3.4971e+00                  , pde-loss 6.2658e+03, initc-loss 1.3048e+04                    bc_loss 9.0407e+03\n",
      "Epoch 28330, Training-Loss 5.6589e+00, Data-loss 2.8104e+00                  , pde-loss 6.5955e+03, initc-loss 1.3039e+04                    bc_loss 8.8509e+03\n",
      "Epoch 28340, Training-Loss 6.9009e+00, Data-loss 4.4354e+00                  , pde-loss 4.8936e+03, initc-loss 1.3082e+04                    bc_loss 6.6801e+03\n",
      "Epoch 28350, Training-Loss 6.0440e+00, Data-loss 3.6343e+00                  , pde-loss 5.5036e+03, initc-loss 1.2992e+04                    bc_loss 5.6010e+03\n",
      "Epoch 28360, Training-Loss 8.6169e+00, Data-loss 5.8075e+00                  , pde-loss 6.1556e+03, initc-loss 1.2807e+04                    bc_loss 9.1317e+03\n",
      "Epoch 28370, Training-Loss 6.3454e+00, Data-loss 3.5155e+00                  , pde-loss 5.2742e+03, initc-loss 1.2950e+04                    bc_loss 1.0075e+04\n",
      "Epoch 28380, Training-Loss 5.3926e+00, Data-loss 2.7894e+00                  , pde-loss 4.3126e+03, initc-loss 1.3049e+04                    bc_loss 8.6705e+03\n",
      "Epoch 28390, Training-Loss 5.4447e+00, Data-loss 2.9655e+00                  , pde-loss 5.2764e+03, initc-loss 1.2968e+04                    bc_loss 6.5481e+03\n",
      "Epoch 28400, Training-Loss 5.8028e+00, Data-loss 3.1440e+00                  , pde-loss 4.1431e+03, initc-loss 1.3020e+04                    bc_loss 9.4249e+03\n",
      "Epoch 28410, Training-Loss 6.9315e+00, Data-loss 4.0385e+00                  , pde-loss 5.6498e+03, initc-loss 1.3068e+04                    bc_loss 1.0212e+04\n",
      "Epoch 28420, Training-Loss 6.2205e+00, Data-loss 3.7176e+00                  , pde-loss 6.7291e+03, initc-loss 1.2795e+04                    bc_loss 5.5050e+03\n",
      "Epoch 28430, Training-Loss 8.5135e+00, Data-loss 5.8812e+00                  , pde-loss 6.0528e+03, initc-loss 1.2998e+04                    bc_loss 7.2720e+03\n",
      "Epoch 28440, Training-Loss 5.7864e+00, Data-loss 3.3707e+00                  , pde-loss 4.5958e+03, initc-loss 1.3080e+04                    bc_loss 6.4801e+03\n",
      "Epoch 28450, Training-Loss 8.7497e+00, Data-loss 6.2251e+00                  , pde-loss 6.0080e+03, initc-loss 1.2946e+04                    bc_loss 6.2925e+03\n",
      "Epoch 28460, Training-Loss 7.2992e+00, Data-loss 4.7677e+00                  , pde-loss 5.8636e+03, initc-loss 1.2982e+04                    bc_loss 6.4691e+03\n",
      "Epoch 28470, Training-Loss 6.9830e+00, Data-loss 3.9934e+00                  , pde-loss 6.3445e+03, initc-loss 1.3168e+04                    bc_loss 1.0384e+04\n",
      "Epoch 28480, Training-Loss 5.5688e+00, Data-loss 3.0730e+00                  , pde-loss 5.6665e+03, initc-loss 1.3006e+04                    bc_loss 6.2853e+03\n",
      "Epoch 28490, Training-Loss 1.0522e+01, Data-loss 7.5464e+00                  , pde-loss 7.7609e+03, initc-loss 1.2981e+04                    bc_loss 9.0144e+03\n",
      "Epoch 28500, Training-Loss 7.1198e+00, Data-loss 4.1981e+00                  , pde-loss 6.5972e+03, initc-loss 1.2954e+04                    bc_loss 9.6671e+03\n",
      "Epoch 28510, Training-Loss 1.1133e+01, Data-loss 8.2091e+00                  , pde-loss 6.6935e+03, initc-loss 1.3130e+04                    bc_loss 9.4165e+03\n",
      "Epoch 28520, Training-Loss 6.3194e+00, Data-loss 3.5014e+00                  , pde-loss 6.0128e+03, initc-loss 1.3069e+04                    bc_loss 9.0987e+03\n",
      "Epoch 28530, Training-Loss 6.6575e+00, Data-loss 3.6638e+00                  , pde-loss 5.8713e+03, initc-loss 1.2980e+04                    bc_loss 1.1086e+04\n",
      "Epoch 28540, Training-Loss 5.6365e+00, Data-loss 3.1888e+00                  , pde-loss 3.9341e+03, initc-loss 1.2877e+04                    bc_loss 7.6664e+03\n",
      "Epoch 28550, Training-Loss 8.1642e+00, Data-loss 5.2147e+00                  , pde-loss 5.9954e+03, initc-loss 1.2845e+04                    bc_loss 1.0655e+04\n",
      "Epoch 28560, Training-Loss 5.9107e+00, Data-loss 3.3872e+00                  , pde-loss 3.9231e+03, initc-loss 1.2658e+04                    bc_loss 8.6541e+03\n",
      "Epoch 28570, Training-Loss 6.0524e+00, Data-loss 3.4804e+00                  , pde-loss 6.0593e+03, initc-loss 1.2870e+04                    bc_loss 6.7908e+03\n",
      "Epoch 28580, Training-Loss 7.9753e+00, Data-loss 5.4293e+00                  , pde-loss 6.5952e+03, initc-loss 1.2877e+04                    bc_loss 5.9873e+03\n",
      "Epoch 28590, Training-Loss 6.3037e+00, Data-loss 3.7388e+00                  , pde-loss 5.1711e+03, initc-loss 1.2971e+04                    bc_loss 7.5072e+03\n",
      "Epoch 28600, Training-Loss 8.4593e+00, Data-loss 5.7122e+00                  , pde-loss 6.6721e+03, initc-loss 1.2794e+04                    bc_loss 8.0049e+03\n",
      "Epoch 28610, Training-Loss 6.0435e+00, Data-loss 3.6469e+00                  , pde-loss 5.1688e+03, initc-loss 1.2994e+04                    bc_loss 5.8029e+03\n",
      "Epoch 28620, Training-Loss 6.3307e+00, Data-loss 3.9127e+00                  , pde-loss 5.0482e+03, initc-loss 1.2890e+04                    bc_loss 6.2420e+03\n",
      "Epoch 28630, Training-Loss 6.7521e+00, Data-loss 4.3578e+00                  , pde-loss 5.3304e+03, initc-loss 1.3008e+04                    bc_loss 5.6046e+03\n",
      "Epoch 28640, Training-Loss 6.3715e+00, Data-loss 3.9698e+00                  , pde-loss 5.3753e+03, initc-loss 1.2854e+04                    bc_loss 5.7879e+03\n",
      "Epoch 28650, Training-Loss 6.3350e+00, Data-loss 3.3125e+00                  , pde-loss 4.5619e+03, initc-loss 1.2766e+04                    bc_loss 1.2897e+04\n",
      "Epoch 28660, Training-Loss 6.1509e+00, Data-loss 3.2815e+00                  , pde-loss 5.3135e+03, initc-loss 1.2789e+04                    bc_loss 1.0592e+04\n",
      "Epoch 28670, Training-Loss 6.0355e+00, Data-loss 3.3050e+00                  , pde-loss 5.2124e+03, initc-loss 1.2886e+04                    bc_loss 9.2058e+03\n",
      "Epoch 28680, Training-Loss 6.7043e+00, Data-loss 3.8923e+00                  , pde-loss 6.3076e+03, initc-loss 1.2855e+04                    bc_loss 8.9571e+03\n",
      "Epoch 28690, Training-Loss 6.5774e+00, Data-loss 4.0282e+00                  , pde-loss 4.4316e+03, initc-loss 1.3198e+04                    bc_loss 7.8618e+03\n",
      "Epoch 28700, Training-Loss 7.7122e+00, Data-loss 5.1060e+00                  , pde-loss 6.5400e+03, initc-loss 1.3082e+04                    bc_loss 6.4393e+03\n",
      "Epoch 28710, Training-Loss 6.8163e+00, Data-loss 3.4674e+00                  , pde-loss 6.6606e+03, initc-loss 1.3039e+04                    bc_loss 1.3789e+04\n",
      "Epoch 28720, Training-Loss 6.0706e+00, Data-loss 3.4829e+00                  , pde-loss 4.8565e+03, initc-loss 1.2967e+04                    bc_loss 8.0540e+03\n",
      "Epoch 28730, Training-Loss 5.3336e+00, Data-loss 2.9827e+00                  , pde-loss 4.1600e+03, initc-loss 1.2928e+04                    bc_loss 6.4212e+03\n",
      "Epoch 28740, Training-Loss 7.1571e+00, Data-loss 4.1441e+00                  , pde-loss 4.9626e+03, initc-loss 1.2969e+04                    bc_loss 1.2199e+04\n",
      "Epoch 28750, Training-Loss 5.6547e+00, Data-loss 3.0369e+00                  , pde-loss 5.6762e+03, initc-loss 1.2895e+04                    bc_loss 7.6073e+03\n",
      "Epoch 28760, Training-Loss 7.0263e+00, Data-loss 4.5257e+00                  , pde-loss 6.8757e+03, initc-loss 1.2958e+04                    bc_loss 5.1726e+03\n",
      "Epoch 28770, Training-Loss 5.8612e+00, Data-loss 3.3588e+00                  , pde-loss 6.4228e+03, initc-loss 1.2859e+04                    bc_loss 5.7421e+03\n",
      "Epoch 28780, Training-Loss 5.6249e+00, Data-loss 3.0335e+00                  , pde-loss 5.9645e+03, initc-loss 1.2987e+04                    bc_loss 6.9624e+03\n",
      "Epoch 28790, Training-Loss 4.6703e+00, Data-loss 2.0938e+00                  , pde-loss 6.5161e+03, initc-loss 1.3099e+04                    bc_loss 6.1501e+03\n",
      "Epoch 28800, Training-Loss 7.6183e+00, Data-loss 4.9339e+00                  , pde-loss 7.1747e+03, initc-loss 1.2843e+04                    bc_loss 6.8267e+03\n",
      "Epoch 28810, Training-Loss 6.3574e+00, Data-loss 3.5441e+00                  , pde-loss 5.2270e+03, initc-loss 1.3035e+04                    bc_loss 9.8703e+03\n",
      "Epoch 28820, Training-Loss 1.0561e+01, Data-loss 7.6116e+00                  , pde-loss 7.7867e+03, initc-loss 1.2786e+04                    bc_loss 8.9220e+03\n",
      "Epoch 28830, Training-Loss 5.7102e+00, Data-loss 3.1129e+00                  , pde-loss 6.2965e+03, initc-loss 1.2898e+04                    bc_loss 6.7784e+03\n",
      "Epoch 28840, Training-Loss 6.3617e+00, Data-loss 3.9628e+00                  , pde-loss 4.9489e+03, initc-loss 1.2912e+04                    bc_loss 6.1276e+03\n",
      "Epoch 28850, Training-Loss 7.7176e+00, Data-loss 4.4658e+00                  , pde-loss 6.5712e+03, initc-loss 1.3027e+04                    bc_loss 1.2920e+04\n",
      "Epoch 28860, Training-Loss 5.5621e+00, Data-loss 3.0288e+00                  , pde-loss 5.1203e+03, initc-loss 1.2983e+04                    bc_loss 7.2299e+03\n",
      "Epoch 28870, Training-Loss 7.4164e+00, Data-loss 4.9719e+00                  , pde-loss 5.7516e+03, initc-loss 1.2997e+04                    bc_loss 5.6975e+03\n",
      "Epoch 28880, Training-Loss 6.6998e+00, Data-loss 4.3313e+00                  , pde-loss 4.7795e+03, initc-loss 1.2780e+04                    bc_loss 6.1250e+03\n",
      "Epoch 28890, Training-Loss 8.5021e+00, Data-loss 5.9058e+00                  , pde-loss 6.0737e+03, initc-loss 1.3059e+04                    bc_loss 6.8304e+03\n",
      "Epoch 28900, Training-Loss 1.0639e+01, Data-loss 8.1566e+00                  , pde-loss 5.5138e+03, initc-loss 1.3228e+04                    bc_loss 6.0799e+03\n",
      "Epoch 28910, Training-Loss 7.7661e+00, Data-loss 5.3423e+00                  , pde-loss 6.1725e+03, initc-loss 1.3010e+04                    bc_loss 5.0551e+03\n",
      "Epoch 28920, Training-Loss 6.2212e+00, Data-loss 3.7028e+00                  , pde-loss 6.1695e+03, initc-loss 1.3127e+04                    bc_loss 5.8873e+03\n",
      "Epoch 28930, Training-Loss 4.8936e+00, Data-loss 2.6080e+00                  , pde-loss 4.9040e+03, initc-loss 1.3023e+04                    bc_loss 4.9286e+03\n",
      "Epoch 28940, Training-Loss 7.9435e+00, Data-loss 5.2683e+00                  , pde-loss 5.9578e+03, initc-loss 1.3020e+04                    bc_loss 7.7740e+03\n",
      "Epoch 28950, Training-Loss 5.9463e+00, Data-loss 3.4096e+00                  , pde-loss 7.0246e+03, initc-loss 1.3010e+04                    bc_loss 5.3331e+03\n",
      "Epoch 28960, Training-Loss 9.5580e+00, Data-loss 7.0298e+00                  , pde-loss 4.5051e+03, initc-loss 1.3025e+04                    bc_loss 7.7522e+03\n",
      "Epoch 28970, Training-Loss 5.6697e+00, Data-loss 2.8181e+00                  , pde-loss 6.4796e+03, initc-loss 1.3009e+04                    bc_loss 9.0283e+03\n",
      "Epoch 28980, Training-Loss 5.9111e+00, Data-loss 3.2228e+00                  , pde-loss 5.2581e+03, initc-loss 1.2949e+04                    bc_loss 8.6758e+03\n",
      "Epoch 28990, Training-Loss 5.8476e+00, Data-loss 3.0806e+00                  , pde-loss 6.0068e+03, initc-loss 1.2943e+04                    bc_loss 8.7207e+03\n",
      "Epoch 29000, Training-Loss 6.7885e+00, Data-loss 4.1959e+00                  , pde-loss 5.0763e+03, initc-loss 1.2809e+04                    bc_loss 8.0410e+03\n",
      "Epoch 29010, Training-Loss 6.9184e+00, Data-loss 4.4008e+00                  , pde-loss 6.2863e+03, initc-loss 1.2930e+04                    bc_loss 5.9597e+03\n",
      "Epoch 29020, Training-Loss 8.5983e+00, Data-loss 5.6620e+00                  , pde-loss 8.0501e+03, initc-loss 1.2844e+04                    bc_loss 8.4685e+03\n",
      "Epoch 29030, Training-Loss 4.7861e+00, Data-loss 2.3079e+00                  , pde-loss 5.2314e+03, initc-loss 1.2890e+04                    bc_loss 6.6607e+03\n",
      "Epoch 29040, Training-Loss 6.2737e+00, Data-loss 3.9241e+00                  , pde-loss 4.6440e+03, initc-loss 1.2949e+04                    bc_loss 5.9035e+03\n",
      "Epoch 29050, Training-Loss 7.0581e+00, Data-loss 4.3180e+00                  , pde-loss 6.7628e+03, initc-loss 1.3142e+04                    bc_loss 7.4962e+03\n",
      "Epoch 29060, Training-Loss 6.7251e+00, Data-loss 4.0331e+00                  , pde-loss 6.7106e+03, initc-loss 1.3059e+04                    bc_loss 7.1508e+03\n",
      "Epoch 29070, Training-Loss 6.3426e+00, Data-loss 3.4915e+00                  , pde-loss 5.7189e+03, initc-loss 1.3039e+04                    bc_loss 9.7521e+03\n",
      "Epoch 29080, Training-Loss 6.8789e+00, Data-loss 4.3755e+00                  , pde-loss 5.2995e+03, initc-loss 1.3008e+04                    bc_loss 6.7262e+03\n",
      "Epoch 29090, Training-Loss 7.2489e+00, Data-loss 4.7762e+00                  , pde-loss 4.5841e+03, initc-loss 1.3043e+04                    bc_loss 7.0992e+03\n",
      "Epoch 29100, Training-Loss 4.7316e+00, Data-loss 2.4053e+00                  , pde-loss 5.0886e+03, initc-loss 1.2911e+04                    bc_loss 5.2640e+03\n",
      "Epoch 29110, Training-Loss 9.5061e+00, Data-loss 6.4295e+00                  , pde-loss 8.3972e+03, initc-loss 1.2827e+04                    bc_loss 9.5422e+03\n",
      "Epoch 29120, Training-Loss 6.5557e+00, Data-loss 4.1804e+00                  , pde-loss 5.7882e+03, initc-loss 1.2968e+04                    bc_loss 4.9968e+03\n",
      "Epoch 29130, Training-Loss 6.8374e+00, Data-loss 3.9883e+00                  , pde-loss 6.1357e+03, initc-loss 1.2806e+04                    bc_loss 9.5498e+03\n",
      "Epoch 29140, Training-Loss 3.8062e+00, Data-loss 1.5567e+00                  , pde-loss 4.8889e+03, initc-loss 1.2906e+04                    bc_loss 4.7007e+03\n",
      "Epoch 29150, Training-Loss 1.1530e+01, Data-loss 8.8092e+00                  , pde-loss 8.0706e+03, initc-loss 1.2951e+04                    bc_loss 6.1815e+03\n",
      "Epoch 29160, Training-Loss 6.1111e+00, Data-loss 3.2803e+00                  , pde-loss 7.2984e+03, initc-loss 1.3139e+04                    bc_loss 7.8698e+03\n",
      "Epoch 29170, Training-Loss 8.3957e+00, Data-loss 5.7149e+00                  , pde-loss 6.4460e+03, initc-loss 1.2899e+04                    bc_loss 7.4629e+03\n",
      "Epoch 29180, Training-Loss 6.3919e+00, Data-loss 3.5477e+00                  , pde-loss 6.2897e+03, initc-loss 1.3095e+04                    bc_loss 9.0576e+03\n",
      "Epoch 29190, Training-Loss 5.7268e+00, Data-loss 2.9372e+00                  , pde-loss 5.1099e+03, initc-loss 1.3148e+04                    bc_loss 9.6378e+03\n",
      "Epoch 29200, Training-Loss 5.1902e+00, Data-loss 3.0071e+00                  , pde-loss 4.1356e+03, initc-loss 1.3091e+04                    bc_loss 4.6038e+03\n",
      "Epoch 29210, Training-Loss 7.1852e+00, Data-loss 4.5072e+00                  , pde-loss 6.0392e+03, initc-loss 1.3191e+04                    bc_loss 7.5504e+03\n",
      "Epoch 29220, Training-Loss 6.2504e+00, Data-loss 3.8261e+00                  , pde-loss 5.7794e+03, initc-loss 1.3061e+04                    bc_loss 5.4022e+03\n",
      "Epoch 29230, Training-Loss 8.6745e+00, Data-loss 6.0809e+00                  , pde-loss 7.9986e+03, initc-loss 1.2995e+04                    bc_loss 4.9418e+03\n",
      "Epoch 29240, Training-Loss 6.3537e+00, Data-loss 3.9760e+00                  , pde-loss 5.0739e+03, initc-loss 1.2883e+04                    bc_loss 5.8194e+03\n",
      "Epoch 29250, Training-Loss 5.7606e+00, Data-loss 3.2235e+00                  , pde-loss 5.4473e+03, initc-loss 1.3104e+04                    bc_loss 6.8191e+03\n",
      "Epoch 29260, Training-Loss 7.4272e+00, Data-loss 4.8430e+00                  , pde-loss 7.4420e+03, initc-loss 1.2927e+04                    bc_loss 5.4733e+03\n",
      "Epoch 29270, Training-Loss 6.3227e+00, Data-loss 3.7002e+00                  , pde-loss 5.4072e+03, initc-loss 1.3035e+04                    bc_loss 7.7827e+03\n",
      "Epoch 29280, Training-Loss 4.9628e+00, Data-loss 2.5784e+00                  , pde-loss 4.9480e+03, initc-loss 1.2907e+04                    bc_loss 5.9892e+03\n",
      "Epoch 29290, Training-Loss 6.0688e+00, Data-loss 3.2731e+00                  , pde-loss 5.7514e+03, initc-loss 1.2990e+04                    bc_loss 9.2153e+03\n",
      "Epoch 29300, Training-Loss 5.6596e+00, Data-loss 3.3803e+00                  , pde-loss 4.1953e+03, initc-loss 1.3006e+04                    bc_loss 5.5913e+03\n",
      "Epoch 29310, Training-Loss 5.4047e+00, Data-loss 2.6770e+00                  , pde-loss 5.0180e+03, initc-loss 1.2843e+04                    bc_loss 9.4165e+03\n",
      "Epoch 29320, Training-Loss 5.2883e+00, Data-loss 2.8185e+00                  , pde-loss 6.3351e+03, initc-loss 1.2831e+04                    bc_loss 5.5325e+03\n",
      "Epoch 29330, Training-Loss 4.9314e+00, Data-loss 2.5272e+00                  , pde-loss 6.3563e+03, initc-loss 1.2993e+04                    bc_loss 4.6924e+03\n",
      "Epoch 29340, Training-Loss 5.4397e+00, Data-loss 2.9477e+00                  , pde-loss 6.5067e+03, initc-loss 1.2935e+04                    bc_loss 5.4779e+03\n",
      "Epoch 29350, Training-Loss 6.6116e+00, Data-loss 4.1100e+00                  , pde-loss 5.8246e+03, initc-loss 1.2943e+04                    bc_loss 6.2476e+03\n",
      "Epoch 29360, Training-Loss 5.0243e+00, Data-loss 2.1983e+00                  , pde-loss 7.1788e+03, initc-loss 1.2932e+04                    bc_loss 8.1489e+03\n",
      "Epoch 29370, Training-Loss 7.5806e+00, Data-loss 5.1605e+00                  , pde-loss 4.4928e+03, initc-loss 1.3098e+04                    bc_loss 6.6110e+03\n",
      "Epoch 29380, Training-Loss 1.1591e+01, Data-loss 8.3870e+00                  , pde-loss 6.3357e+03, initc-loss 1.2885e+04                    bc_loss 1.2815e+04\n",
      "Epoch 29390, Training-Loss 5.2142e+00, Data-loss 2.8470e+00                  , pde-loss 5.2133e+03, initc-loss 1.2795e+04                    bc_loss 5.6644e+03\n",
      "Epoch 29400, Training-Loss 1.0877e+01, Data-loss 8.3079e+00                  , pde-loss 5.3696e+03, initc-loss 1.3014e+04                    bc_loss 7.3044e+03\n",
      "Epoch 29410, Training-Loss 5.6502e+00, Data-loss 3.3555e+00                  , pde-loss 5.3121e+03, initc-loss 1.2902e+04                    bc_loss 4.7327e+03\n",
      "Epoch 29420, Training-Loss 5.4826e+00, Data-loss 2.9959e+00                  , pde-loss 6.0983e+03, initc-loss 1.2902e+04                    bc_loss 5.8665e+03\n",
      "Epoch 29430, Training-Loss 4.9610e+00, Data-loss 2.4074e+00                  , pde-loss 4.0791e+03, initc-loss 1.3009e+04                    bc_loss 8.4476e+03\n",
      "Epoch 29440, Training-Loss 5.2763e+00, Data-loss 2.9922e+00                  , pde-loss 5.0203e+03, initc-loss 1.2932e+04                    bc_loss 4.8894e+03\n",
      "Epoch 29450, Training-Loss 7.5446e+00, Data-loss 5.2925e+00                  , pde-loss 5.6663e+03, initc-loss 1.2920e+04                    bc_loss 3.9356e+03\n",
      "Epoch 29460, Training-Loss 4.6610e+00, Data-loss 2.3109e+00                  , pde-loss 5.1038e+03, initc-loss 1.2946e+04                    bc_loss 5.4507e+03\n",
      "Epoch 29470, Training-Loss 6.5489e+00, Data-loss 4.0977e+00                  , pde-loss 6.6574e+03, initc-loss 1.2993e+04                    bc_loss 4.8621e+03\n",
      "Epoch 29480, Training-Loss 5.1734e+00, Data-loss 2.1712e+00                  , pde-loss 5.2129e+03, initc-loss 1.2730e+04                    bc_loss 1.2079e+04\n",
      "Epoch 29490, Training-Loss 4.5735e+00, Data-loss 2.1150e+00                  , pde-loss 5.7757e+03, initc-loss 1.2935e+04                    bc_loss 5.8739e+03\n",
      "Epoch 29500, Training-Loss 5.5902e+00, Data-loss 3.0517e+00                  , pde-loss 5.1747e+03, initc-loss 1.2900e+04                    bc_loss 7.3113e+03\n",
      "Epoch 29510, Training-Loss 4.3957e+00, Data-loss 1.9321e+00                  , pde-loss 6.6627e+03, initc-loss 1.2809e+04                    bc_loss 5.1633e+03\n",
      "Epoch 29520, Training-Loss 5.8876e+00, Data-loss 3.2616e+00                  , pde-loss 6.4717e+03, initc-loss 1.2811e+04                    bc_loss 6.9771e+03\n",
      "Epoch 29530, Training-Loss 4.7928e+00, Data-loss 2.4123e+00                  , pde-loss 4.7738e+03, initc-loss 1.2885e+04                    bc_loss 6.1460e+03\n",
      "Epoch 29540, Training-Loss 6.0545e+00, Data-loss 3.4983e+00                  , pde-loss 5.7547e+03, initc-loss 1.2926e+04                    bc_loss 6.8808e+03\n",
      "Epoch 29550, Training-Loss 4.8279e+00, Data-loss 2.0965e+00                  , pde-loss 7.4412e+03, initc-loss 1.2908e+04                    bc_loss 6.9646e+03\n",
      "Epoch 29560, Training-Loss 4.6276e+00, Data-loss 2.3503e+00                  , pde-loss 5.5692e+03, initc-loss 1.2853e+04                    bc_loss 4.3514e+03\n",
      "Epoch 29570, Training-Loss 6.3001e+00, Data-loss 3.8177e+00                  , pde-loss 7.2529e+03, initc-loss 1.3112e+04                    bc_loss 4.4597e+03\n",
      "Epoch 29580, Training-Loss 6.4457e+00, Data-loss 3.8752e+00                  , pde-loss 6.5477e+03, initc-loss 1.2950e+04                    bc_loss 6.2073e+03\n",
      "Epoch 29590, Training-Loss 6.3070e+00, Data-loss 3.8950e+00                  , pde-loss 5.5065e+03, initc-loss 1.2930e+04                    bc_loss 5.6834e+03\n",
      "Epoch 29600, Training-Loss 1.0912e+01, Data-loss 8.4947e+00                  , pde-loss 5.5952e+03, initc-loss 1.3044e+04                    bc_loss 5.5336e+03\n",
      "Epoch 29610, Training-Loss 6.4816e+00, Data-loss 4.0384e+00                  , pde-loss 3.2165e+03, initc-loss 1.2918e+04                    bc_loss 8.2970e+03\n",
      "Epoch 29620, Training-Loss 5.3310e+00, Data-loss 2.8195e+00                  , pde-loss 5.7969e+03, initc-loss 1.3039e+04                    bc_loss 6.2782e+03\n",
      "Epoch 29630, Training-Loss 6.1528e+00, Data-loss 3.7008e+00                  , pde-loss 5.0577e+03, initc-loss 1.2980e+04                    bc_loss 6.4827e+03\n",
      "Epoch 29640, Training-Loss 5.2998e+00, Data-loss 2.9998e+00                  , pde-loss 5.1659e+03, initc-loss 1.2783e+04                    bc_loss 5.0502e+03\n",
      "Epoch 29650, Training-Loss 7.4358e+00, Data-loss 4.9184e+00                  , pde-loss 7.1806e+03, initc-loss 1.2853e+04                    bc_loss 5.1408e+03\n",
      "Epoch 29660, Training-Loss 8.7323e+00, Data-loss 6.3009e+00                  , pde-loss 5.5450e+03, initc-loss 1.2757e+04                    bc_loss 6.0124e+03\n",
      "Epoch 29670, Training-Loss 6.5014e+00, Data-loss 3.7405e+00                  , pde-loss 6.1997e+03, initc-loss 1.2798e+04                    bc_loss 8.6107e+03\n",
      "Epoch 29680, Training-Loss 8.0888e+00, Data-loss 5.5721e+00                  , pde-loss 5.0722e+03, initc-loss 1.3020e+04                    bc_loss 7.0753e+03\n",
      "Epoch 29690, Training-Loss 4.9459e+00, Data-loss 2.4015e+00                  , pde-loss 5.4064e+03, initc-loss 1.2756e+04                    bc_loss 7.2813e+03\n",
      "Epoch 29700, Training-Loss 5.4211e+00, Data-loss 2.9160e+00                  , pde-loss 5.7430e+03, initc-loss 1.2921e+04                    bc_loss 6.3871e+03\n",
      "Epoch 29710, Training-Loss 5.0575e+00, Data-loss 2.7682e+00                  , pde-loss 5.5168e+03, initc-loss 1.3065e+04                    bc_loss 4.3118e+03\n",
      "Epoch 29720, Training-Loss 6.0650e+00, Data-loss 3.6366e+00                  , pde-loss 7.1699e+03, initc-loss 1.2843e+04                    bc_loss 4.2712e+03\n",
      "Epoch 29730, Training-Loss 7.2534e+00, Data-loss 4.5378e+00                  , pde-loss 5.2923e+03, initc-loss 1.2852e+04                    bc_loss 9.0112e+03\n",
      "Epoch 29740, Training-Loss 6.4772e+00, Data-loss 3.7893e+00                  , pde-loss 6.8345e+03, initc-loss 1.2636e+04                    bc_loss 7.4091e+03\n",
      "Epoch 29750, Training-Loss 6.8546e+00, Data-loss 4.1820e+00                  , pde-loss 6.5296e+03, initc-loss 1.2773e+04                    bc_loss 7.4234e+03\n",
      "Epoch 29760, Training-Loss 4.6762e+00, Data-loss 2.2512e+00                  , pde-loss 6.7911e+03, initc-loss 1.3018e+04                    bc_loss 4.4415e+03\n",
      "Epoch 29770, Training-Loss 7.1957e+00, Data-loss 4.3050e+00                  , pde-loss 6.0769e+03, initc-loss 1.3161e+04                    bc_loss 9.6689e+03\n",
      "Epoch 29780, Training-Loss 5.3209e+00, Data-loss 2.9673e+00                  , pde-loss 5.8856e+03, initc-loss 1.2853e+04                    bc_loss 4.7976e+03\n",
      "Epoch 29790, Training-Loss 5.7934e+00, Data-loss 3.4876e+00                  , pde-loss 4.3514e+03, initc-loss 1.2780e+04                    bc_loss 5.9260e+03\n",
      "Epoch 29800, Training-Loss 6.4403e+00, Data-loss 4.0997e+00                  , pde-loss 6.0788e+03, initc-loss 1.3045e+04                    bc_loss 4.2828e+03\n",
      "Epoch 29810, Training-Loss 5.7609e+00, Data-loss 3.0904e+00                  , pde-loss 6.1876e+03, initc-loss 1.2715e+04                    bc_loss 7.8024e+03\n",
      "Epoch 29820, Training-Loss 5.0000e+00, Data-loss 2.4066e+00                  , pde-loss 6.8904e+03, initc-loss 1.2747e+04                    bc_loss 6.2965e+03\n",
      "Epoch 29830, Training-Loss 4.6147e+00, Data-loss 2.0473e+00                  , pde-loss 4.3136e+03, initc-loss 1.2881e+04                    bc_loss 8.4790e+03\n",
      "Epoch 29840, Training-Loss 5.3679e+00, Data-loss 2.7653e+00                  , pde-loss 4.7326e+03, initc-loss 1.2888e+04                    bc_loss 8.4047e+03\n",
      "Epoch 29850, Training-Loss 5.0382e+00, Data-loss 2.0308e+00                  , pde-loss 4.6186e+03, initc-loss 1.2657e+04                    bc_loss 1.2799e+04\n",
      "Epoch 29860, Training-Loss 4.8051e+00, Data-loss 2.4588e+00                  , pde-loss 5.0153e+03, initc-loss 1.2867e+04                    bc_loss 5.5797e+03\n",
      "Epoch 29870, Training-Loss 4.3555e+00, Data-loss 2.0056e+00                  , pde-loss 6.2011e+03, initc-loss 1.3084e+04                    bc_loss 4.2131e+03\n",
      "Epoch 29880, Training-Loss 7.0135e+00, Data-loss 4.4994e+00                  , pde-loss 6.6931e+03, initc-loss 1.2726e+04                    bc_loss 5.7219e+03\n",
      "Epoch 29890, Training-Loss 1.0159e+01, Data-loss 7.6758e+00                  , pde-loss 6.4038e+03, initc-loss 1.3039e+04                    bc_loss 5.3927e+03\n",
      "Epoch 29900, Training-Loss 5.4602e+00, Data-loss 3.0396e+00                  , pde-loss 6.2080e+03, initc-loss 1.2925e+04                    bc_loss 5.0730e+03\n",
      "Epoch 29910, Training-Loss 5.9156e+00, Data-loss 3.4292e+00                  , pde-loss 3.6041e+03, initc-loss 1.3087e+04                    bc_loss 8.1726e+03\n",
      "Epoch 29920, Training-Loss 5.8154e+00, Data-loss 3.4380e+00                  , pde-loss 4.1820e+03, initc-loss 1.3017e+04                    bc_loss 6.5758e+03\n",
      "Epoch 29930, Training-Loss 4.9050e+00, Data-loss 2.6699e+00                  , pde-loss 3.0516e+03, initc-loss 1.2973e+04                    bc_loss 6.3265e+03\n",
      "Epoch 29940, Training-Loss 6.6990e+00, Data-loss 3.4781e+00                  , pde-loss 7.4139e+03, initc-loss 1.3142e+04                    bc_loss 1.1652e+04\n",
      "Epoch 29950, Training-Loss 4.7907e+00, Data-loss 2.4673e+00                  , pde-loss 5.9156e+03, initc-loss 1.2885e+04                    bc_loss 4.4342e+03\n",
      "Epoch 29960, Training-Loss 6.1970e+00, Data-loss 3.4404e+00                  , pde-loss 5.7798e+03, initc-loss 1.2825e+04                    bc_loss 8.9612e+03\n",
      "Epoch 29970, Training-Loss 6.3337e+00, Data-loss 3.6170e+00                  , pde-loss 6.0902e+03, initc-loss 1.2767e+04                    bc_loss 8.3098e+03\n",
      "Epoch 29980, Training-Loss 7.1163e+00, Data-loss 4.6285e+00                  , pde-loss 5.6420e+03, initc-loss 1.2864e+04                    bc_loss 6.3730e+03\n",
      "Epoch 29990, Training-Loss 8.0695e+00, Data-loss 5.3953e+00                  , pde-loss 8.0425e+03, initc-loss 1.3018e+04                    bc_loss 5.6817e+03\n",
      "Epoch 30000, Test-Loss 2.6409e+00, Test-Accuracy 1.4847e-03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses, val_losses = training_loop(epochs, model, loss_fn_data, optimizer,train_loader)  # Train the model\n",
    " \n",
    "test_losses = test_loop(epochs, model, loss_fn_data, optimizer, train_loader, test_loader)  # Test the model\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_nn = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).cpu().detach().numpy() # Get the predictions from the model\n",
    "\n",
    "temp_nn = temp_nn.reshape(num_steps+1, num_points) # Reshape the predictions to a 2D array\n",
    "time_ss= np.linspace(0, time_end, num_steps+1 )\n",
    "plt.figure\n",
    "plt.plot(time_ss, temp_nn[:, num_points//2], label='Predicted Temperature')\n",
    "plt.plot(time_ss, temperature_history[:,num_points//2], label='Actual Temperature')\n",
    "plt.xlabel('Time(s)')\n",
    "plt.ylabel('Temperature (K)')\n",
    "plt.title('Predicted vs Actual Temperature at x = 7.5mm')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
