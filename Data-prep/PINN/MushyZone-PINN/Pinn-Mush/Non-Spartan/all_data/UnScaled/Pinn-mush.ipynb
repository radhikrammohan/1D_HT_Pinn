{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Three Phase Simulation of Alloys and PINN model development \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the simulation of 1D Phase change of aluminium alloy. There will be three phases (solid,liquid and mushy).   \n",
    "\n",
    "The approach used is finite difference method and the physics involved in heat conduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import csv\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "import torch.optim as optim\n",
    "\n",
    "from pinn_loss import loss_fn_data, l1_regularization, pde_loss, boundary_loss, ic_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the constants and inital geometric domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Material :- AL 380\n",
    "\n",
    "| Sr.No | Properties  | Symbol | Value  | Unit |Range(source) |\n",
    "|:---:|:---:|:---:|:---:|:---:|:--:|\n",
    "| 1  | Liquidus Density | $\\rho_{l}$  | 2300 | $kg/m^3$  |  2200-2400 (ASM handbook) |\n",
    "|  2 |  Solidus Density  |  $\\rho_{s}$  | 2500  |  $kg/m^3$  | 2400-2600 (ASM handbook) |\n",
    "|  3 |  Mushy Desnity |  $\\rho_{m}$  |  2400 | $kg/m^3$   |Increase linearly from liquid to solid (ASM handbook) |\n",
    "|  4 |  Liquidus Thermal Conductivity| $k_l$  |  70 | $W/m-K$  |60-80 (ASM handbook) |\n",
    "|  5 |  Solidus Thermal Conductivity | $k_s$  | 180  |  $W/m-K$ | 150-210(ASM handbook) |\n",
    "|  6 | Mushy Zone Thermal Conductivity | $k_m$  | 125  |  $W/m-K$ |Decrease linearly from liquid to solid (ASM handbook) |\n",
    "|  7 | Liquidus Specific Heat | $c_{pl}$  | 1190  | $J/kg-K$  | 1100 -1200 (ASM handbook)|\n",
    "|  8 | Solidus Specific Heat | $c_{ps}$  |  1100 |  $J/kg-K$  | 1100-1200 (ASM handbook)|\n",
    "|  9 | Mushy Zone Specific Heat |  $c_{pm}$ | 1175 | $J/kg-K$   |decrease lineraly from liquid to solid (ASM handbook)|\n",
    "|  10 | Latent Heat of Fusion | $L_{fusion}$  | 450e3  | $J/kg$ | (400-500)e3 (ASM handbook) |\n",
    "| 11 | Left Boundary Temperature |$BCT_{l}$|623 |$K$| (623-723) Nissan Data |\n",
    "|12 | Right Boundary Temperature | $BCT_{r}$|623 |$K$| (623-723) Nissan Data |\n",
    "|13| Freezing time | |60 |sec|||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_l = 3.394878564540885e-05, alpha_s = 3.686205086349929e-05, m_eff = 6.296953764744878e-06\n",
      "dx is 0.0003061224489795918\n",
      "dt is  0.0012711033647622566\n",
      "num_steps is 31469\n",
      "cfl is 0.0012711033647622566\n",
      "stability criteria satisfied\n"
     ]
    }
   ],
   "source": [
    "# Geometry\n",
    "length = 15.0e-3             # Length of the rod\n",
    "\n",
    "# Material properties\n",
    "rho = 2300.0                     # Density of AL380 (kg/m^3)\n",
    "rho_l = 2460.0                   # Density of AL380 (kg/m^3)\n",
    "rho_s = 2710.0                    # Density of AL380 (kg/m^3)\n",
    "rho_m = (rho_l + rho_s )/2       # Desnity in mushy zone is taken as average of liquid and solid density\n",
    "\n",
    "k = 104.0                       # W/m-K\n",
    "k_l = k                       # W/m-K\n",
    "k_s = 96.2                    # W/m-K\n",
    "k_m =  (k_l+k_s)/2                     # W/m-K\n",
    "k_mo = 41.5\n",
    "\n",
    "\n",
    "cp = 1245.3                      # Specific heat of aluminum (J/kg-K)\n",
    "cp_l = cp                      # Specific heat of aluminum (J/kg-K)\n",
    "cp_s = 963.0                 # Specific heat of aluminum (J/kg-K)\n",
    "cp_m =  (cp_l+cp_s)/2                 # Specific heat of mushy zone is taken as average of liquid and solid specific heat\n",
    "# cp_m = cp\n",
    "           # Thermal diffusivity\n",
    "alpha_l = k_l / (rho_l * cp_l) \n",
    "alpha_s = k_s / (rho_s*cp_s)\n",
    "alpha_m = k_m / (rho_m * cp_m)          #`Thermal diffusivity in mushy zone is taken as average of liquid and solid thermal diffusivity`\n",
    "\n",
    "\n",
    "#L_fusion = 3.9e3                 # J/kg\n",
    "L_fusion = 389.0e3               # J/kg  # Latent heat of fusion of aluminum\n",
    "         # Thermal diffusivity\n",
    "\n",
    "\n",
    "T_L = 574.4 +273.0                       #  K -Liquidus Temperature (615 c) AL 380\n",
    "T_S = 497.3 +273.0                     # K- Solidus Temperature (550 C)\n",
    "m_eff =(k_m/(rho_m*(cp_m + (L_fusion/(T_L-T_S)))))\n",
    "print (f\"alpha_l = {alpha_l}, alpha_s = {alpha_s}, m_eff = {m_eff}\")\n",
    "\n",
    "# htc = 10.0                   # W/m^2-K\n",
    "# q = htc*(919.0-723.0)\n",
    "# q = 10000.0\n",
    "\n",
    "\n",
    "num_points = 50                        # Number of spatial points\n",
    "dx = length / (num_points - 1)         # Distance between two spatial points\n",
    "print('dx is',dx)\n",
    "\n",
    "                                                              \n",
    "# Time Discretization  \n",
    "# \n",
    "time_end = 40        # seconds                         \n",
    "\n",
    "maxi = max(alpha_s,alpha_l,alpha_m)\n",
    "dt = abs(0.5*((dx**2) /maxi)) \n",
    "\n",
    "print('dt is ',dt)\n",
    "num_steps = round(time_end/dt)\n",
    "print('num_steps is',num_steps)\n",
    "cfl = 0.5 *(dx**2/max(alpha_l,alpha_s,alpha_m))\n",
    "print('cfl is',cfl)\n",
    "\n",
    "time_steps = np.linspace(0, time_end, num_steps + 1)\n",
    "step_coeff = dt / (dx ** 2)\n",
    "\n",
    "if dt <= cfl:\n",
    "    print('stability criteria satisfied')\n",
    "else:\n",
    "    print('stability criteria not satisfied')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial and Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_init = 919.0\n",
    "# Initial temperature and phase fields\n",
    "temperature = np.full(num_points+2, 919.0)            # Initial temperature of the rod with ghost points at both ends\n",
    "phase = np.zeros(num_points+2)*0.0                    # Initial phase of the rod with ghost points at both ends\n",
    "\n",
    "# Set boundary conditions\n",
    "# temperature[-1] = 919.0 \n",
    "phase[-1] = 1.0\n",
    "\n",
    "# temperature[0] = 919.0 #(40 C)\n",
    "phase[0] = 1.0\n",
    "\n",
    "# Store initial state in history\n",
    "temperature_history = [temperature.copy()]    # List to store temperature at each time step\n",
    "phi_history = [phase.copy()]                    # List to store phase at each time step\n",
    "temp_init = temperature.copy()                 # Initial temperature of the rod\n",
    "# print(temperature_history,phi_history)\n",
    "# Array to store temperature at midpoint over time\n",
    "midpoint_index = num_points // 2                          # Index of the midpoint\n",
    "\n",
    "midpoint_temperature_history = [temperature[midpoint_index]]            # List to store temperature at midpoint over time\n",
    "dm = 60.0e-3                                                            # die thickness in m\n",
    "\n",
    "# r_m =  (k_mo / dm) + (1/htc)\n",
    "\n",
    "t_surr = 500.0                                        # Surrounding temperature in K\n",
    "# t_surr = h()\n",
    "\n",
    "def kramp(temp,v1,v2,T_L,T_s):                                      # Function to calculate thermal conductivity in Mushy Zone\n",
    "        slope = (v1-v2)/(T_L-T_S)\n",
    "        if temp > T_L:\n",
    "            k_m = k_l\n",
    "        elif temp < T_S:\n",
    "            k_m = k_s\n",
    "        else:\n",
    "            k_m = k_s + slope*(temp-T_S)\n",
    "        return k_m\n",
    "\n",
    "def cp_ramp(temp,v1,v2,T_L,T_s):                                    # Function to calculate specific heat capacity in Mushy Zone\n",
    "    slope = (v1-v2)/(T_L-T_S)\n",
    "    if temp > T_L:\n",
    "        cp_m = cp_l\n",
    "    elif temp < T_S:\n",
    "        cp_m = cp_s\n",
    "    else:\n",
    "        cp_m = cp_s + slope*(temp-T_S)\n",
    "    return cp_m\n",
    "\n",
    "def rho_ramp(temp,v1,v2,T_L,T_s):                                       # Function to calculate density in Mushy Zone\n",
    "    slope = (v1-v2)/(T_L-T_S)\n",
    "    if temp > T_L:\n",
    "        rho_m = rho_l\n",
    "    elif temp < T_S:\n",
    "        rho_m = rho_s\n",
    "    else:\n",
    "        rho_m = rho_s + slope*(temp-T_S)\n",
    "    return rho_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the HT equation and phase change numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for m in range(1, num_steps+1):                                                                            # time loop\n",
    "    htc = 10.0                   # htc of Still air in W/m^2-K\n",
    "    q1 = htc*(temp_init[0]-t_surr)   # Heat flux at the left boundary\n",
    "    \n",
    "    # print(f\"q1 is {q1}\")\n",
    "    temperature[0] = temp_init[0] + alpha_l * step_coeff * ((2.0*temp_init[1]) - (2.0 * temp_init[0])-(2.0*dx*(q1)))  # Update boundary condition temperature\n",
    "    \n",
    "    q2 = htc*(temp_init[-1]-t_surr)                   # Heat flux at the right boundary\n",
    "    temperature[-1] = temp_init[-1] + alpha_l * step_coeff * ((2.0*temp_init[-2]) - (2.0 * temp_init[-1])-(2.0*dx*(q2)))  # Update boundary condition temperature\n",
    "    \n",
    "    for n in range(1,num_points+1):              # space loop, adjusted range\n",
    "       \n",
    "        if temperature[n] >= T_L:\n",
    "            temperature[n] += ((alpha_l * step_coeff) * (temp_init[n+1] - (2.0 * temp_init[n]) + temp_init[n-1]))\n",
    "            phase[n] = 0\n",
    "            \n",
    "            # print(f\" Time-Step{m},Spatial point{n},Temperature{temperature[n]}\")\n",
    "        elif T_S < temperature[n] < T_L:\n",
    "            \n",
    "            k_m = kramp(temperature[n],k_l,k_s,T_L,T_S)\n",
    "            cp_m = cp_ramp(temperature[n],cp_l,cp_s,T_L,T_S)\n",
    "            rho_m = rho_ramp(temperature[n],rho_l,rho_s,T_L,T_S)\n",
    "            m_eff =(k_m/(rho_m*(cp_m + (L_fusion/(T_L-T_S)))))\n",
    "            \n",
    "            temperature[n] += ((m_eff * step_coeff)* (temp_init[n+1] - (2.0 * temp_init[n]) + temp_init[n-1]))\n",
    "            \n",
    "            phase[n] = (T_L - temperature[n]) / (T_L - T_S)\n",
    "            # print(m,n,temperature[n],phase[n])\n",
    "         \n",
    "        elif temperature[n]<T_S:\n",
    "            temperature[n] += ((alpha_s * step_coeff) * (temp_init[n+1] - (2.0 * temp_init[n])+ temp_init[n-1]))\n",
    "            phase[n] = 1\n",
    "                     \n",
    "        else:\n",
    "            print(\"ERROR: should not be here\")\n",
    "\n",
    "     \n",
    "          \n",
    "    temperature = temperature.copy()                                                                # Update temperature\n",
    "    phase = phase.copy()                                                                            # Update phase\n",
    "    temp_init = temperature.copy()                                                                  # Update last time step temperature\n",
    "    temperature_history.append(temperature.copy())                                                  # Append the temperature history to add ghost points\n",
    "    phi_history.append(phase.copy())                                                                # Append the phase history to add ghost points\n",
    "    midpoint_temperature_history.append(temperature[midpoint_index])                                # Store midpoint temperature\n",
    "    \n",
    "    \n",
    "    # print(f\"Step {m}, Temperature: {temperature}\")\n",
    "    \n",
    "\n",
    "\n",
    "# print(midpoint_temperature_history)\n",
    "#print(phi_history)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot temperature history for debugging\n",
    "# temperature_history_1 = np.array(temperature_history)\n",
    "# print(temperature_history_1.shape)\n",
    "# time_ss= np.linspace(0, time_end, num_steps+1)\n",
    "# # print(time_ss.shape)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(time_ss, midpoint_temperature_history, label='Midpoint Temperature')\n",
    "# plt.axhline(y=T_L, color='r', linestyle='--', label='Liquidus Temperature')\n",
    "# plt.axhline(y=T_S, color='g', linestyle='--', label='Solidus Temperature')\n",
    "# plt.xlabel('Time(s)')\n",
    "# plt.ylabel('Temperature (K)')\n",
    "# plt.title('Temperature Distribution Over Time at x = 7.5mm') \n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data into Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31470, 50)\n",
      "(31470, 50)\n"
     ]
    }
   ],
   "source": [
    "temperature_history = np.array(temperature_history)\n",
    "\n",
    "phi_history = np.array(phi_history)\n",
    "\n",
    "t_hist = np.array(temperature_history[:,1:-1])\n",
    "p_hist = np.array(phi_history[:,1:-1])\n",
    "print(t_hist.shape)\n",
    "print(p_hist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have temperature_history and phi_history as lists of arrays\n",
    "\n",
    "\n",
    "# # Check the new shape after transposing\n",
    "# print(\"Transposed Temperature History Shape:\", temperature_history.shape)\n",
    "# print(\"Transposed Phi History Shape:\", phi_history.shape)\n",
    "\n",
    "# # Create a meshgrid for space and time coordinates\n",
    "# space_coord, time_coord = np.meshgrid(np.arange(temperature_history.shape[1]), np.arange(temperature_history.shape[0]))\n",
    "\n",
    "# time_coord = time_coord * dt \n",
    "# # Create a figure with two subplots\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# # Plot the temperature history on the left subplot\n",
    "# im1 = ax1.pcolormesh(space_coord, time_coord, temperature_history, cmap='viridis')\n",
    "# ax1.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=16)\n",
    "# ax1.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "# ax1.set_title('Temperature Variation Over Time',fontname='Times New Roman', fontsize=20)\n",
    "# fig.colorbar(im1, ax=ax1, label='Temperature')\n",
    "\n",
    "# # Plot the phase history on the right subplot\n",
    "# im2 = ax2.pcolormesh(space_coord, time_coord, phi_history, cmap='viridis')\n",
    "# ax2.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=18)\n",
    "# ax2.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "# ax2.set_title('Phase Variation Over Time',fontname='Times New Roman', fontsize=20)\n",
    "# fig.colorbar(im2, ax=ax2, label='Phase')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# #plot the main\n",
    "# fig, ax = plt.subplots(figsize=(14, 6))\n",
    "# im = ax.pcolormesh(space_coord, time_coord, Dim_ny, cmap='viridis')\n",
    "# ax.set_xlabel('Space Coordinate')\n",
    "# ax.set_ylabel('Time')\n",
    "# ax.set_title('Niyama Variation Over Time')\n",
    "# fig.colorbar(im, ax=ax, label='Main')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU/CPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# check for gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.4205658 ]\n",
      " [ 1.4898617 ]\n",
      " [ 1.55915759]\n",
      " [ 1.62845348]\n",
      " [ 1.69774938]\n",
      " [-1.69774938]\n",
      " [-1.62845348]\n",
      " [-1.55915759]\n",
      " [-1.4898617 ]\n",
      " [-1.4205658 ]]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "space = np.linspace(0, length, num_points)\n",
    "time = np.linspace(0, time_end, num_steps+1)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "space_tr = scaler.fit_transform(space.reshape(-1,1))\n",
    "time_tr = scaler.fit_transform(time.reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create mesh grid of space and time\n",
    "\n",
    "space_tr, time_tr = np.meshgrid(space_tr, time_tr)\n",
    "space, time = np.meshgrid(space, time)\n",
    "space_tr = space_tr.flatten().reshape(-1,1)\n",
    "print(space_tr[45:55,])\n",
    "\n",
    "time_tr = time_tr.flatten().reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_points(pdepoints,t_hist):\n",
    "\n",
    "    x_pts = 10\n",
    "    y_pts = num_points//x_pts\n",
    "    x = np.linspace(0, t_hist.shape[0], x_pts)\n",
    "    y = np.linspace(0, t_hist.shape[1], y_pts)\n",
    "\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    x = x.flatten().reshape(-1,1)\n",
    "    y = y.flatten().reshape(-1,1)\n",
    "\n",
    "    pde_points = np.hstack((x,y))\n",
    "\n",
    "    pde_temp = t_hist[pde_points[:,0].astype(int),pde_points[:,1].astype(int)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = np.hstack([space_tr,time_tr]) # Concatenate the spatial and temporal inputs\n",
    "# print(inputs.shape)\n",
    "inputs = torch.tensor(inputs).float().to(device) # Convert the inputs to a tensor\n",
    "# print(inputs.shape)\n",
    "\n",
    "# label/temp data\n",
    "temp_tr = torch.tensor(t_hist).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp = temp_tr.reshape(-1,1) # Reshape the temperature tensor to a column vector\n",
    "# print(temp_inp.shape)\n",
    "\n",
    "\n",
    "\n",
    "#Data Splitting\n",
    "\n",
    "# train_inputs, val_test_inputs, train_temp_inp, val_test_temp_inp = train_test_split(inputs, temp_inp, test_size=0.2, random_state=42)\n",
    "# val_inputs, test_inputs, val_temp_inp, test_temp_inp = train_test_split(val_test_inputs, val_test_temp_inp, test_size=0.8, random_state=42)\n",
    "\n",
    "train_inputs, test_inputs, train_temp_inp, test_temp_inp = train_test_split(inputs, temp_inp, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, temp_inp,transform=None, target_transform =None):\n",
    "        self.inputs = inputs\n",
    "        self.temp_inp = temp_inp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.temp_inp[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    \n",
    "train_dataset = TensorDataset(train_inputs, train_temp_inp) # Create the training dataset\n",
    "# val_dataset = TensorDataset(val_inputs, val_temp_inp) # Create the validation dataset\n",
    "test_dataset = TensorDataset(test_inputs, test_temp_inp) # Create the test dataset\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "random_sampler_train = RandomSampler(train_dataset, replacement=False, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "# random_sampler_val = RandomSampler(val_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the validation dataset\n",
    "random_sampler_test = RandomSampler(test_dataset, replacement=False, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=random_sampler_train) # Create the training dataloader\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=random_sampler_val) # Create the validation dataloader\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, sampler=random_sampler_test) # Create the test dataloader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the neural network architecture\n",
    "class Mushydata(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size): # This is the constructor\n",
    "        super(Mushydata, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.Tanh(), \n",
    "             \n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.Tanh(), \n",
    "\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.Tanh(),\n",
    "                    \n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.Tanh(),\n",
    "            \n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t):                               # This is the forward pass\n",
    "        input_features = torch.cat([x, t], dim=1)          # Concatenate the input features\n",
    "        # print(input_features.shape)\n",
    "        m = self.base(input_features)                                 # Pass through the third layer\n",
    "        return m                    # Return the output of the network\n",
    "\n",
    "\n",
    "# features = torch.rand(1, 2)\n",
    "# model = HeatPINN(2, 20, 1)\n",
    "# output = model(features[:, 0:1], features[:, 1:2])\n",
    "# print(output)\n",
    "\n",
    "\n",
    "# Loss function for data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamters Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 20 \n",
    "learning_rate = 0.009\n",
    "# learning_rate2 = 0.0001\n",
    "epochs = 2\n",
    "# alpha = 0.01  # Adjust this value based on your problem\n",
    "# boundary_value = 313.0\n",
    "# initial_value = init_temp\n",
    "# Initialize the model\n",
    "model = Mushydata(input_size=2, hidden_size=hidden_size,output_size=1).to(device)\n",
    "lambd = 0.9\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer2 = torch.optim.LBFGS(model.parameters(), lr=learning_rate2,\\\n",
    "                            #    max_iter = 20, \\\n",
    "                            #    max_eval = None, \\\n",
    "                            #     tolerance_grad = 1e-7, \\\n",
    "                            #         tolerance_change = 1e-9, \\\n",
    "                            #             history_size = 100, \\\n",
    "                            #                 line_search_fn = 'strong_wolfe')\n",
    "# Initialize the ReduceLROnPlateau scheduler\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.09, patience=100, verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss List Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of train_loader is <class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(f\"Datatype of train_loader is {type(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation and Testing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, model, loss_fn_data, optimizer, train_dataloader, test_dataloader):\n",
    "    train_losses = []  # Initialize the list to store the training losses\n",
    "    val_losses = []    # Initialize the list to store the validation losses\n",
    "    pd_losses = []\n",
    "    initc_losses = []\n",
    "    bc_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()                                                                           # Set the model to training mode\n",
    "        train_loss = 0                                                                              # Initialize the training loss\n",
    "        train_accuracy = 0\n",
    "        for batch in train_dataloader:                                                          # Loop through the training dataloader\n",
    "            inputs, temp_inp= batch                                                             # Get the inputs and the true values\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)                             # Move the inputs and true values to the GPU\n",
    "            optimizer.zero_grad()                                                                    # Zero the gradients\n",
    "            \n",
    "            # Forward pass\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).to(device)                       # Get the predictions\n",
    "            u_initl = model(inputs[:,0].unsqueeze(1), torch.zeros_like(inputs[:,1].unsqueeze(1))).to(device)\n",
    "            # u_left = model(inputs[0,:].unsqueeze(0), inputs[:,1].unsqueeze(1)).to(device)               # Left boundary of the temperature\n",
    "            # u_right = model(inputs[-1,:].unsqueeze(0), inputs[:,1].unsqueeze(1)).to(device)             # Right boundary of the temperature\n",
    "\n",
    "            # Loss calculation\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp)                                              # Calculate the data loss\n",
    "            pd_loss = pde_loss(model,inputs[:,0].unsqueeze(1),inputs[:,1].unsqueeze(1))             # Calculate the PDE loss\n",
    "            # pd_loss = 0\n",
    "            # initc_loss = ic_loss(u_initl) \n",
    "            initc_loss =0                                                      # Calculate initial condition loss\n",
    "            # bc_loss_left = boundary_loss(u_left,inputs[0,:].unsqueeze(0),inputs[:,1].unsqueeze(1),t_surr) # Calculate the left boundary condition loss\n",
    "            # bc_loss_right = boundary_loss(u_right,inputs[-1,:].unsqueeze(0),inputs[:,1].unsqueeze(1),t_surr) # Calculate the right boundary condition loss\n",
    "            bc_loss = 0\n",
    "            l1_regularization_loss = l1_regularization(model, lambd)                      # Calculate the L1 regularization loss\n",
    "            # loss = data_loss  + pd_loss + initc_loss + bc_loss                                              # Calculate the total loss\n",
    "            w1 = 0\n",
    "            w2 = 0\n",
    "            w3 = 0\n",
    "            loss =  pd_loss \n",
    "            \n",
    "            train_accuracy += accuracy(u_pred, temp_inp)                                                              # Calculate the total loss\n",
    "            # Backpropagation\n",
    "            loss.backward(retain_graph=True)                                                        # Backpropagate the gradients\n",
    "            \n",
    "            optimizer.step()                                                                           # Update the weights\n",
    "            \n",
    "            train_loss += loss.item()                                                           # Add the loss to the training set loss                 \n",
    "            pd_losses.append(pd_loss)\n",
    "            initc_losses.append(initc_loss)\n",
    "            bc_losses.append(bc_loss)                           \n",
    "        train_losses.append(train_loss)                                                   # Append the training loss to the list of training losses\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_accuracy = 0\n",
    "        \n",
    "        for batch in test_dataloader:\n",
    "            inputs, temp_inp= batch\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "            u_initl = model(inputs[:,0].unsqueeze(1), torch.zeros_like(inputs[:,1].unsqueeze(1))).to(device)\n",
    "            # u_left = model(inputs[0,:].unsqueeze(0), inputs[:,1].unsqueeze(1)).to(device)               # Left boundary of the temperature\n",
    "            # u_right = model(inputs[-1,:].unsqueeze(0), inputs[:,1].unsqueeze(1)).to(device)             # Right boundary of the temperature\n",
    "\n",
    "            # Loss calculation\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp)                                              # Calculate the data loss\n",
    "            pd_loss = pde_loss(model,inputs[:,0].unsqueeze(1),inputs[:,1].unsqueeze(1))             # Calculate the PDE loss\n",
    "            # pd_loss = 0\n",
    "            # initc_loss = ic_loss(u_initl) \n",
    "            initc_loss =0                                                      # Calculate initial condition loss\n",
    "            # bc_loss_left = boundary_loss(u_left,inputs[0,:].unsqueeze(0),inputs[:,1].unsqueeze(1),t_surr) # Calculate the left boundary condition loss\n",
    "            # bc_loss_right = boundary_loss(u_right,inputs[-1,:].unsqueeze(0),inputs[:,1].unsqueeze(1),t_surr) # Calculate the right boundary condition loss\n",
    "            bc_loss = 0\n",
    "            l1_regularization_loss = l1_regularization(model, lambd)                      # Calculate the L1 regularization loss\n",
    "            # loss = data_loss  + pd_loss + initc_loss + bc_loss                                              # Calculate the total loss\n",
    "            loss = data_loss + pd_loss + initc_loss + bc_loss + l1_regularization_loss\n",
    "            test_accuracy = accuracy(u_pred, temp_inp)\n",
    "            test_loss += loss.item()\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Training-Loss {train_loss:.4e},Test-Loss {test_loss:.4e},\")\n",
    "            # print(f\"Epoch {epoch},Training-Accuracy {train_accuracy:.4e} , Test-Accuracy {test_accuracy:.4e}\")\n",
    "            print(f\"Epoch {epoch},Residual_data_loss {data_loss:.4e}, ,pde_loss {pd_loss:.4e}, ,init_loss {initc_loss:.4e}, ,bc_loss {bc_loss:.4e}\")\n",
    "            print('--')\n",
    "        # scheduler.step(train_loss)                                                            # Adjust the learning rate based on the training loss\n",
    "        \n",
    "    # for epoch in range(5001,epochs):\n",
    "    #     model.train()                                                                           # Set the model to training mode\n",
    "    #     train_loss = 0                                                                              # Initialize the training loss\n",
    "    #     train_accuracy = 0\n",
    "    #     for batch in train_dataloader:                                                          # Loop through the training dataloader\n",
    "    #         inputs, temp_inp= batch                                                             # Get the inputs and the true values\n",
    "    #         inputs, temp_inp= inputs.to(device), temp_inp.to(device)                             # Move the inputs and true values to the GPU\n",
    "    #         optimizer.zero_grad()                                                                    # Zero the gradients\n",
    "            \n",
    "    #         # Forward pass\n",
    "    #         u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).to(device)                       # Get the predictions\n",
    "    #         u_initl = model(inputs[:,0].unsqueeze(1), torch.zeros_like(inputs[:,1].unsqueeze(1))).to(device)\n",
    "    #         # u_left = model(inputs[0,:].unsqueeze(0), inputs[:,1].unsqueeze(1)).to(device)               # Left boundary of the temperature\n",
    "    #         # u_right = model(inputs[-1,:].unsqueeze(0), inputs[:,1].unsqueeze(1)).to(device)             # Right boundary of the temperature\n",
    "\n",
    "    #         # Loss calculation\n",
    "    #         data_loss = loss_fn_data(u_pred, temp_inp)                                              # Calculate the data loss\n",
    "    #         pd_loss = pde_loss(model,inputs[:,0].unsqueeze(1),inputs[:,1].unsqueeze(1))             # Calculate the PDE loss\n",
    "    #         # pd_loss = 0\n",
    "    #         # initc_loss = ic_loss(u_initl) \n",
    "    #         initc_loss =0                                                      # Calculate initial condition loss\n",
    "    #         # bc_loss_left = boundary_loss(u_left,inputs[0,:].unsqueeze(0),inputs[:,1].unsqueeze(1),t_surr) # Calculate the left boundary condition loss\n",
    "    #         # bc_loss_right = boundary_loss(u_right,inputs[-1,:].unsqueeze(0),inputs[:,1].unsqueeze(1),t_surr) # Calculate the right boundary condition loss\n",
    "    #         bc_loss = 0\n",
    "    #         l1_regularization_loss = l1_regularization(model, lambd)                      # Calculate the L1 regularization loss\n",
    "    #         # loss = data_loss  + pd_loss + initc_loss + bc_loss                                              # Calculate the total loss\n",
    "    #         loss = data_loss + pd_loss + initc_loss + bc_loss + l1_regularization_loss\n",
    "    #         train_accuracy += accuracy(u_pred, temp_inp)                                                              # Calculate the total loss\n",
    "    #         # Backpropagation\n",
    "    #         loss.backward(retain_graph=True)                                                        # Backpropagate the gradients\n",
    "            \n",
    "    #         optimizer.step()                                                                           # Update the weights\n",
    "            \n",
    "    #         train_loss += loss.item()                                                           # Add the loss to the training set loss                 \n",
    "                                        \n",
    "    #     train_losses.append(train_loss)                                                   # Append the training loss to the list of training losses\n",
    "        \n",
    "    #     model.eval()\n",
    "    #     test_loss = 0\n",
    "    #     test_accuracy = 0\n",
    "        \n",
    "    #     for batch in test_dataloader:\n",
    "    #         inputs, temp_inp= batch\n",
    "    #         inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "    #         u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "    #         u_initl = model(inputs[:,0].unsqueeze(1), torch.zeros_like(inputs[:,1].unsqueeze(1))).to(device)\n",
    "    #         # u_left = model(inputs[0,:].unsqueeze(0), inputs[:,1].unsqueeze(1)).to(device)               # Left boundary of the temperature\n",
    "    #         # u_right = model(inputs[-1,:].unsqueeze(0), inputs[:,1].unsqueeze(1)).to(device)             # Right boundary of the temperature\n",
    "\n",
    "    #         # Loss calculation\n",
    "    #         data_loss = loss_fn_data(u_pred, temp_inp)                                              # Calculate the data loss\n",
    "    #         pd_loss = pde_loss(model,inputs[:,0].unsqueeze(1),inputs[:,1].unsqueeze(1))             # Calculate the PDE loss\n",
    "    #         # pd_loss = 0\n",
    "    #         # initc_loss = ic_loss(u_initl) \n",
    "    #         initc_loss =0                                                      # Calculate initial condition loss\n",
    "    #         # bc_loss_left = boundary_loss(u_left,inputs[0,:].unsqueeze(0),inputs[:,1].unsqueeze(1),t_surr) # Calculate the left boundary condition loss\n",
    "    #         # bc_loss_right = boundary_loss(u_right,inputs[-1,:].unsqueeze(0),inputs[:,1].unsqueeze(1),t_surr) # Calculate the right boundary condition loss\n",
    "    #         bc_loss = 0\n",
    "    #         l1_regularization_loss = l1_regularization(model, lambd)                      # Calculate the L1 regularization loss\n",
    "    #         # loss = data_loss  + pd_loss + initc_loss + bc_loss                                              # Calculate the total loss\n",
    "            \n",
    "    #         w1 = 0.01\n",
    "    #         w2 = 0.001\n",
    "    #         w3 = 0.0001\n",
    "    #         loss = data_loss + w1* pd_loss + w2*initc_loss + w3* bc_loss + l1_regularization_loss\n",
    "    #         test_accuracy = accuracy(u_pred, temp_inp)\n",
    "    #         test_loss += loss.item()\n",
    "    #     test_losses.append(test_loss)\n",
    "        \n",
    "\n",
    "        # if epoch % 10 == 0:\n",
    "            # print(f\"Epoch {epoch}, Training-Loss {train_loss:.4e},Test-Loss {test_loss:.4e},\")\n",
    "            # print(f\"Epoch {epoch},Training-Accuracy {train_accuracy:.4e} , Test-Accuracy {test_accuracy:.4e}\")\n",
    "            # print(f\"Epoch {epoch},Residual_data_loss {data_loss:.4e}, ,pde_loss {pd_loss:.4e}, ,init_loss {initc_loss:.4e}, ,bc_loss {bc_loss:.4e}\")\n",
    "            \n",
    "        # scheduler.step(train_loss)   \n",
    "    return train_losses, val_losses                                                             # Return the training and validation losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(epochs, model, loss_fn_data, optimizer, train_dataloader, test_dataloader):\n",
    "      \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    with torch.no_grad():   \n",
    "        for batch in test_dataloader:\n",
    "            inputs, temp_inp= batch\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "            u_initl = model(inputs[:,0].unsqueeze(1), torch.zeros_like(inputs[:,1].unsqueeze(1))).to(device)\n",
    "            # u_left = model(inputs[0,:].unsqueeze(0), inputs[:,1].unsqueeze(1)).to(device)               # Left boundary of the temperature\n",
    "            # u_right = model(inputs[-1,:].unsqueeze(0), inputs[:,1].unsqueeze(1)).to(device)             # Right boundary of the temperature\n",
    "\n",
    "            # Loss calculation\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp)                                              # Calculate the data loss\n",
    "            pd_loss = pde_loss(model,inputs[:,0].unsqueeze(1),inputs[:,1].unsqueeze(1))             # Calculate the PDE loss\n",
    "            # pd_loss = 0\n",
    "            # initc_loss = ic_loss(u_initl) \n",
    "            initc_loss =0                                                      # Calculate initial condition loss\n",
    "            # bc_loss_left = boundary_loss(u_left,inputs[0,:].unsqueeze(0),inputs[:,1].unsqueeze(1),t_surr) # Calculate the left boundary condition loss\n",
    "            # bc_loss_right = boundary_loss(u_right,inputs[-1,:].unsqueeze(0),inputs[:,1].unsqueeze(1),t_surr) # Calculate the right boundary condition loss\n",
    "            bc_loss = 0\n",
    "            l1_regularization_loss = l1_regularization(model, lambd)                      # Calculate the L1 regularization loss\n",
    "            # loss = data_loss  + pd_loss + initc_loss + bc_loss                                              # Calculate the total loss\n",
    "            w1 =1\n",
    "            w2 = 0\n",
    "            w3 = 0\n",
    "            loss = data_loss + w1*pd_loss + w2*initc_loss + w3*bc_loss\n",
    "            test_accuracy = accuracy(u_pred, temp_inp)\n",
    "            test_loss += loss.item()\n",
    "        test_losses.append(test_loss)\n",
    "    if epochs % 10 == 0:\n",
    "        print(f\"Epoch {epochs}, Test-Loss {test_loss:.4e}, Test-Accuracy {test_accuracy:.4e}\")      \n",
    "    return test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Button "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0230],\n",
      "        [ 0.0216],\n",
      "        [ 0.0018],\n",
      "        [ 0.0164],\n",
      "        [ 0.0384],\n",
      "        [ 0.0303],\n",
      "        [ 0.0388],\n",
      "        [ 0.0393],\n",
      "        [-0.0015],\n",
      "        [ 0.0392],\n",
      "        [ 0.0018],\n",
      "        [-0.0112],\n",
      "        [ 0.0124],\n",
      "        [ 0.0058],\n",
      "        [-0.0037],\n",
      "        [ 0.0383],\n",
      "        [ 0.0046],\n",
      "        [ 0.0023],\n",
      "        [-0.0138],\n",
      "        [ 0.0168],\n",
      "        [ 0.0292],\n",
      "        [-0.0233],\n",
      "        [-0.0089],\n",
      "        [ 0.0290],\n",
      "        [ 0.0342],\n",
      "        [ 0.0337],\n",
      "        [ 0.0268],\n",
      "        [-0.0130],\n",
      "        [-0.0156],\n",
      "        [-0.0116],\n",
      "        [-0.0021],\n",
      "        [ 0.0181],\n",
      "        [ 0.0404],\n",
      "        [ 0.0276],\n",
      "        [ 0.0428],\n",
      "        [ 0.0378],\n",
      "        [-0.0156],\n",
      "        [-0.0346],\n",
      "        [ 0.0096],\n",
      "        [-0.0108],\n",
      "        [ 0.0341],\n",
      "        [-0.0044],\n",
      "        [ 0.0399],\n",
      "        [ 0.0084],\n",
      "        [ 0.0376],\n",
      "        [ 0.0112],\n",
      "        [ 0.0263],\n",
      "        [ 0.0336],\n",
      "        [-0.0120],\n",
      "        [-0.0097],\n",
      "        [ 0.0058],\n",
      "        [-0.0021],\n",
      "        [ 0.0024],\n",
      "        [-0.0045],\n",
      "        [-0.0041],\n",
      "        [ 0.0144],\n",
      "        [-0.0150],\n",
      "        [-0.0019],\n",
      "        [-0.0193],\n",
      "        [ 0.0081],\n",
      "        [ 0.0316],\n",
      "        [-0.0123],\n",
      "        [ 0.0111],\n",
      "        [ 0.0006],\n",
      "        [-0.0098],\n",
      "        [ 0.0199],\n",
      "        [ 0.0198],\n",
      "        [ 0.0098],\n",
      "        [ 0.0227],\n",
      "        [ 0.0231],\n",
      "        [-0.0118],\n",
      "        [ 0.0392],\n",
      "        [-0.0219],\n",
      "        [ 0.0427],\n",
      "        [ 0.0251],\n",
      "        [-0.0173],\n",
      "        [ 0.0052],\n",
      "        [ 0.0388],\n",
      "        [ 0.0102],\n",
      "        [ 0.0176],\n",
      "        [-0.0101],\n",
      "        [ 0.0276],\n",
      "        [ 0.0313],\n",
      "        [ 0.0266],\n",
      "        [ 0.0141],\n",
      "        [ 0.0133],\n",
      "        [ 0.0102],\n",
      "        [ 0.0068],\n",
      "        [-0.0139],\n",
      "        [ 0.0119],\n",
      "        [-0.0075],\n",
      "        [ 0.0086],\n",
      "        [ 0.0007],\n",
      "        [ 0.0208],\n",
      "        [-0.0092],\n",
      "        [-0.0466],\n",
      "        [-0.0403],\n",
      "        [ 0.0169],\n",
      "        [-0.0425],\n",
      "        [ 0.0058],\n",
      "        [ 0.0072],\n",
      "        [-0.0236],\n",
      "        [ 0.0083],\n",
      "        [ 0.0310],\n",
      "        [-0.0083],\n",
      "        [-0.0446],\n",
      "        [ 0.0147],\n",
      "        [-0.0091],\n",
      "        [ 0.0312],\n",
      "        [ 0.0203],\n",
      "        [-0.0211],\n",
      "        [ 0.0062],\n",
      "        [ 0.0332],\n",
      "        [ 0.0079],\n",
      "        [ 0.0072],\n",
      "        [ 0.0045],\n",
      "        [ 0.0310],\n",
      "        [-0.0074],\n",
      "        [-0.0164],\n",
      "        [ 0.0272],\n",
      "        [ 0.0111],\n",
      "        [ 0.0043],\n",
      "        [-0.0152],\n",
      "        [ 0.0152],\n",
      "        [ 0.0035],\n",
      "        [ 0.0131],\n",
      "        [-0.0381],\n",
      "        [ 0.0430]], grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0426],\n",
      "        [0.0691],\n",
      "        [0.0303],\n",
      "        [0.0775],\n",
      "        [0.0581],\n",
      "        [0.0493],\n",
      "        [0.0465],\n",
      "        [0.0338],\n",
      "        [0.0726],\n",
      "        [0.0557],\n",
      "        [0.0490],\n",
      "        [0.0469],\n",
      "        [0.0576],\n",
      "        [0.0684],\n",
      "        [0.0371],\n",
      "        [0.0347],\n",
      "        [0.0656],\n",
      "        [0.0528],\n",
      "        [0.0505],\n",
      "        [0.0787],\n",
      "        [0.0511],\n",
      "        [0.0459],\n",
      "        [0.0521],\n",
      "        [0.0755],\n",
      "        [0.0387],\n",
      "        [0.0297],\n",
      "        [0.0747],\n",
      "        [0.0383],\n",
      "        [0.0604],\n",
      "        [0.0094],\n",
      "        [0.0562],\n",
      "        [0.0786],\n",
      "        [0.0362],\n",
      "        [0.0543],\n",
      "        [0.0483],\n",
      "        [0.0578],\n",
      "        [0.0153],\n",
      "        [0.0405],\n",
      "        [0.0468],\n",
      "        [0.0490],\n",
      "        [0.0717],\n",
      "        [0.0497],\n",
      "        [0.0390],\n",
      "        [0.0747],\n",
      "        [0.0699],\n",
      "        [0.0600],\n",
      "        [0.0601],\n",
      "        [0.0366],\n",
      "        [0.0323],\n",
      "        [0.0156],\n",
      "        [0.0534],\n",
      "        [0.0578],\n",
      "        [0.0621],\n",
      "        [0.0543],\n",
      "        [0.0590],\n",
      "        [0.0788],\n",
      "        [0.0277],\n",
      "        [0.0198],\n",
      "        [0.0503],\n",
      "        [0.0777],\n",
      "        [0.0684],\n",
      "        [0.0147],\n",
      "        [0.0779],\n",
      "        [0.0269],\n",
      "        [0.0204],\n",
      "        [0.0499],\n",
      "        [0.0785],\n",
      "        [0.0712],\n",
      "        [0.0531],\n",
      "        [0.0629],\n",
      "        [0.0582],\n",
      "        [0.0674],\n",
      "        [0.0553],\n",
      "        [0.0432],\n",
      "        [0.0499],\n",
      "        [0.0476],\n",
      "        [0.0307],\n",
      "        [0.0535],\n",
      "        [0.0770],\n",
      "        [0.0768],\n",
      "        [0.0296],\n",
      "        [0.0766],\n",
      "        [0.0323],\n",
      "        [0.0574],\n",
      "        [0.0360],\n",
      "        [0.0394],\n",
      "        [0.0769],\n",
      "        [0.0716],\n",
      "        [0.0367],\n",
      "        [0.0683],\n",
      "        [0.0673],\n",
      "        [0.0721],\n",
      "        [0.0711],\n",
      "        [0.0585],\n",
      "        [0.0464],\n",
      "        [0.0298],\n",
      "        [0.0360],\n",
      "        [0.0709],\n",
      "        [0.0348],\n",
      "        [0.0656],\n",
      "        [0.0739],\n",
      "        [0.0466],\n",
      "        [0.0735],\n",
      "        [0.0569],\n",
      "        [0.0184],\n",
      "        [0.0315],\n",
      "        [0.0654],\n",
      "        [0.0470],\n",
      "        [0.0750],\n",
      "        [0.0503],\n",
      "        [0.0435],\n",
      "        [0.0512],\n",
      "        [0.0451],\n",
      "        [0.0761],\n",
      "        [0.0619],\n",
      "        [0.0507],\n",
      "        [0.0289],\n",
      "        [0.0488],\n",
      "        [0.0423],\n",
      "        [0.0765],\n",
      "        [0.0625],\n",
      "        [0.0632],\n",
      "        [0.0141],\n",
      "        [0.0614],\n",
      "        [0.0754],\n",
      "        [0.0787],\n",
      "        [0.0331],\n",
      "        [0.0484]], grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.0116],\n",
      "        [ 0.0293],\n",
      "        [ 0.0347],\n",
      "        [ 0.0123],\n",
      "        [-0.0340],\n",
      "        [-0.0363],\n",
      "        [-0.0339],\n",
      "        [-0.0250],\n",
      "        [-0.0124],\n",
      "        [-0.0101],\n",
      "        [ 0.0398],\n",
      "        [-0.0305],\n",
      "        [ 0.0279],\n",
      "        [ 0.0290],\n",
      "        [ 0.0355],\n",
      "        [-0.0265],\n",
      "        [-0.0052],\n",
      "        [ 0.0396],\n",
      "        [-0.0295],\n",
      "        [ 0.0030],\n",
      "        [ 0.0104],\n",
      "        [-0.0128],\n",
      "        [-0.0102],\n",
      "        [-0.0111],\n",
      "        [-0.0310],\n",
      "        [-0.0234],\n",
      "        [-0.0178],\n",
      "        [ 0.0324],\n",
      "        [-0.0164],\n",
      "        [ 0.0124],\n",
      "        [ 0.0360],\n",
      "        [-0.0042],\n",
      "        [-0.0261],\n",
      "        [ 0.0205],\n",
      "        [-0.0290],\n",
      "        [-0.0047],\n",
      "        [ 0.0153],\n",
      "        [-0.0217],\n",
      "        [-0.0343],\n",
      "        [-0.0306],\n",
      "        [-0.0189],\n",
      "        [-0.0091],\n",
      "        [-0.0291],\n",
      "        [-0.0190],\n",
      "        [-0.0106],\n",
      "        [ 0.0389],\n",
      "        [ 0.0306],\n",
      "        [-0.0295],\n",
      "        [ 0.0298],\n",
      "        [ 0.0191],\n",
      "        [-0.0344],\n",
      "        [-0.0091],\n",
      "        [-0.0073],\n",
      "        [-0.0095],\n",
      "        [-0.0097],\n",
      "        [ 0.0040],\n",
      "        [-0.0233],\n",
      "        [ 0.0264],\n",
      "        [-0.0128],\n",
      "        [ 0.0020],\n",
      "        [-0.0285],\n",
      "        [ 0.0167],\n",
      "        [-0.0096],\n",
      "        [ 0.0324],\n",
      "        [ 0.0229],\n",
      "        [ 0.0358],\n",
      "        [ 0.0023],\n",
      "        [ 0.0094],\n",
      "        [-0.0367],\n",
      "        [ 0.0340],\n",
      "        [-0.0276],\n",
      "        [-0.0180],\n",
      "        [-0.0179],\n",
      "        [-0.0251],\n",
      "        [ 0.0196],\n",
      "        [-0.0114],\n",
      "        [ 0.0350],\n",
      "        [-0.0349],\n",
      "        [-0.0130],\n",
      "        [ 0.0148],\n",
      "        [ 0.0291],\n",
      "        [-0.0022],\n",
      "        [-0.0264],\n",
      "        [ 0.0126],\n",
      "        [-0.0301],\n",
      "        [ 0.0325],\n",
      "        [ 0.0125],\n",
      "        [ 0.0010],\n",
      "        [-0.0278],\n",
      "        [ 0.0155],\n",
      "        [-0.0206],\n",
      "        [-0.0237],\n",
      "        [-0.0216],\n",
      "        [ 0.0203],\n",
      "        [ 0.0348],\n",
      "        [-0.0129],\n",
      "        [-0.0187],\n",
      "        [ 0.0285],\n",
      "        [-0.0159],\n",
      "        [ 0.0286],\n",
      "        [ 0.0049],\n",
      "        [-0.0263],\n",
      "        [ 0.0149],\n",
      "        [-0.0365],\n",
      "        [ 0.0222],\n",
      "        [-0.0133],\n",
      "        [ 0.0041],\n",
      "        [ 0.0356],\n",
      "        [-0.0080],\n",
      "        [-0.0362],\n",
      "        [-0.0113],\n",
      "        [ 0.0408],\n",
      "        [-0.0347],\n",
      "        [ 0.0085],\n",
      "        [ 0.0373],\n",
      "        [-0.0081],\n",
      "        [-0.0234],\n",
      "        [ 0.0355],\n",
      "        [-0.0287],\n",
      "        [-0.0083],\n",
      "        [ 0.0255],\n",
      "        [ 0.0310],\n",
      "        [ 0.0144],\n",
      "        [ 0.0227],\n",
      "        [-0.0053],\n",
      "        [-0.0050],\n",
      "        [-0.0201],\n",
      "        [-0.0268]], grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.0849],\n",
      "        [-0.0827],\n",
      "        [-0.0636],\n",
      "        [-0.0786],\n",
      "        [-0.0819],\n",
      "        [-0.0923],\n",
      "        [-0.0849],\n",
      "        [-0.0723],\n",
      "        [-0.0886],\n",
      "        [-0.0829],\n",
      "        [-0.0695],\n",
      "        [-0.0695],\n",
      "        [-0.0610],\n",
      "        [-0.0751],\n",
      "        [-0.0871],\n",
      "        [-0.0768],\n",
      "        [-0.0918],\n",
      "        [-0.0720],\n",
      "        [-0.0657],\n",
      "        [-0.0819],\n",
      "        [-0.0942],\n",
      "        [-0.0471],\n",
      "        [-0.0891],\n",
      "        [-0.0713],\n",
      "        [-0.0913],\n",
      "        [-0.0911],\n",
      "        [-0.0794],\n",
      "        [-0.0821],\n",
      "        [-0.0836],\n",
      "        [-0.0713],\n",
      "        [-0.0803],\n",
      "        [-0.0714],\n",
      "        [-0.0658],\n",
      "        [-0.0725],\n",
      "        [-0.0705],\n",
      "        [-0.0669],\n",
      "        [-0.0748],\n",
      "        [-0.0841],\n",
      "        [-0.0824],\n",
      "        [-0.0791],\n",
      "        [-0.0809],\n",
      "        [-0.0872],\n",
      "        [-0.0769],\n",
      "        [-0.0727],\n",
      "        [-0.0808],\n",
      "        [-0.0812],\n",
      "        [-0.0843],\n",
      "        [-0.0903],\n",
      "        [-0.0768],\n",
      "        [-0.0757],\n",
      "        [-0.0887],\n",
      "        [-0.0847],\n",
      "        [-0.0675],\n",
      "        [-0.0806],\n",
      "        [-0.0716],\n",
      "        [-0.0873],\n",
      "        [-0.0866],\n",
      "        [-0.0853],\n",
      "        [-0.0877],\n",
      "        [-0.0671],\n",
      "        [-0.0781],\n",
      "        [-0.0873],\n",
      "        [-0.0636],\n",
      "        [-0.0771],\n",
      "        [-0.0928],\n",
      "        [-0.0843],\n",
      "        [-0.0822],\n",
      "        [-0.0574],\n",
      "        [-0.0782],\n",
      "        [-0.0861],\n",
      "        [-0.0836],\n",
      "        [-0.0658],\n",
      "        [-0.0569],\n",
      "        [-0.0771],\n",
      "        [-0.0714],\n",
      "        [-0.0889],\n",
      "        [-0.0698],\n",
      "        [-0.0940],\n",
      "        [-0.0472],\n",
      "        [-0.0765],\n",
      "        [-0.0420],\n",
      "        [-0.0816],\n",
      "        [-0.0932],\n",
      "        [-0.0848],\n",
      "        [-0.0880],\n",
      "        [-0.0803],\n",
      "        [-0.0843],\n",
      "        [-0.0763],\n",
      "        [-0.0885],\n",
      "        [-0.0597],\n",
      "        [-0.0724],\n",
      "        [-0.0904],\n",
      "        [-0.0913],\n",
      "        [-0.0886],\n",
      "        [-0.0872],\n",
      "        [-0.0727],\n",
      "        [-0.0871],\n",
      "        [-0.0729],\n",
      "        [-0.0808],\n",
      "        [-0.0882],\n",
      "        [-0.0938],\n",
      "        [-0.0780],\n",
      "        [-0.0840],\n",
      "        [-0.0816],\n",
      "        [-0.0854],\n",
      "        [-0.0641],\n",
      "        [-0.0843],\n",
      "        [-0.0759],\n",
      "        [-0.0882],\n",
      "        [-0.0824],\n",
      "        [-0.0772],\n",
      "        [-0.0637],\n",
      "        [-0.0886],\n",
      "        [-0.0859],\n",
      "        [-0.0852],\n",
      "        [-0.0900],\n",
      "        [-0.0770],\n",
      "        [-0.0551],\n",
      "        [-0.0795],\n",
      "        [-0.0692],\n",
      "        [-0.0782],\n",
      "        [-0.0745],\n",
      "        [-0.0643],\n",
      "        [-0.0899],\n",
      "        [-0.0887],\n",
      "        [-0.0858],\n",
      "        [-0.0814],\n",
      "        [-0.0877]], grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0066],\n",
      "        [0.0439],\n",
      "        [0.0247],\n",
      "        [0.0176],\n",
      "        [0.0499],\n",
      "        [0.0434],\n",
      "        [0.0451],\n",
      "        [0.0265],\n",
      "        [0.0516],\n",
      "        [0.0198],\n",
      "        [0.0323],\n",
      "        [0.0230],\n",
      "        [0.0334],\n",
      "        [0.0472],\n",
      "        [0.0194],\n",
      "        [0.0477],\n",
      "        [0.0486],\n",
      "        [0.0125],\n",
      "        [0.0339],\n",
      "        [0.0233],\n",
      "        [0.0508],\n",
      "        [0.0184],\n",
      "        [0.0474],\n",
      "        [0.0131],\n",
      "        [0.0489],\n",
      "        [0.0472],\n",
      "        [0.0044],\n",
      "        [0.0439],\n",
      "        [0.0216],\n",
      "        [0.0120],\n",
      "        [0.0116],\n",
      "        [0.0428],\n",
      "        [0.0363],\n",
      "        [0.0394],\n",
      "        [0.0104],\n",
      "        [0.0358],\n",
      "        [0.0462],\n",
      "        [0.0285],\n",
      "        [0.0269],\n",
      "        [0.0347],\n",
      "        [0.0400],\n",
      "        [0.0313],\n",
      "        [0.0275],\n",
      "        [0.0186],\n",
      "        [0.0424],\n",
      "        [0.0147],\n",
      "        [0.0335],\n",
      "        [0.0482],\n",
      "        [0.0475],\n",
      "        [0.0444],\n",
      "        [0.0221],\n",
      "        [0.0452],\n",
      "        [0.0295],\n",
      "        [0.0314],\n",
      "        [0.0341],\n",
      "        [0.0479],\n",
      "        [0.0183],\n",
      "        [0.0193],\n",
      "        [0.0277],\n",
      "        [0.0270],\n",
      "        [0.0331],\n",
      "        [0.0465],\n",
      "        [0.0168],\n",
      "        [0.0241],\n",
      "        [0.0501],\n",
      "        [0.0451],\n",
      "        [0.0239],\n",
      "        [0.0304],\n",
      "        [0.0459],\n",
      "        [0.0455],\n",
      "        [0.0306],\n",
      "        [0.0111],\n",
      "        [0.0302],\n",
      "        [0.0387],\n",
      "        [0.0203],\n",
      "        [0.0459],\n",
      "        [0.0383],\n",
      "        [0.0497],\n",
      "        [0.0223],\n",
      "        [0.0416],\n",
      "        [0.0133],\n",
      "        [0.0215],\n",
      "        [0.0452],\n",
      "        [0.0170],\n",
      "        [0.0442],\n",
      "        [0.0424],\n",
      "        [0.0448],\n",
      "        [0.0473],\n",
      "        [0.0176],\n",
      "        [0.0127],\n",
      "        [0.0190],\n",
      "        [0.0515],\n",
      "        [0.0514],\n",
      "        [0.0441],\n",
      "        [0.0308],\n",
      "        [0.0195],\n",
      "        [0.0463],\n",
      "        [0.0205],\n",
      "        [0.0243],\n",
      "        [0.0401],\n",
      "        [0.0478],\n",
      "        [0.0334],\n",
      "        [0.0064],\n",
      "        [0.0394],\n",
      "        [0.0442],\n",
      "        [0.0206],\n",
      "        [0.0437],\n",
      "        [0.0202],\n",
      "        [0.0455],\n",
      "        [0.0441],\n",
      "        [0.0424],\n",
      "        [0.0149],\n",
      "        [0.0347],\n",
      "        [0.0380],\n",
      "        [0.0350],\n",
      "        [0.0461],\n",
      "        [0.0242],\n",
      "        [0.0290],\n",
      "        [0.0423],\n",
      "        [0.0094],\n",
      "        [0.0386],\n",
      "        [0.0192],\n",
      "        [0.0346],\n",
      "        [0.0437],\n",
      "        [0.0210],\n",
      "        [0.0420],\n",
      "        [0.0498],\n",
      "        [0.0142]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.0170],\n",
      "        [ 0.0096],\n",
      "        [ 0.0215],\n",
      "        [ 0.0176],\n",
      "        [-0.0047],\n",
      "        [-0.0180],\n",
      "        [ 0.0019],\n",
      "        [-0.0349],\n",
      "        [ 0.0031],\n",
      "        [ 0.0227],\n",
      "        [ 0.0184],\n",
      "        [ 0.0136],\n",
      "        [ 0.0110],\n",
      "        [-0.0005],\n",
      "        [ 0.0339],\n",
      "        [-0.0104],\n",
      "        [-0.0181],\n",
      "        [-0.0253],\n",
      "        [-0.0321],\n",
      "        [ 0.0230],\n",
      "        [-0.0049],\n",
      "        [ 0.0162],\n",
      "        [-0.0214],\n",
      "        [-0.0262],\n",
      "        [ 0.0065],\n",
      "        [-0.0044],\n",
      "        [ 0.0271],\n",
      "        [ 0.0032],\n",
      "        [ 0.0241],\n",
      "        [-0.0251],\n",
      "        [ 0.0153],\n",
      "        [-0.0220],\n",
      "        [ 0.0090],\n",
      "        [ 0.0089],\n",
      "        [-0.0239],\n",
      "        [ 0.0120],\n",
      "        [-0.0146],\n",
      "        [ 0.0266],\n",
      "        [-0.0296],\n",
      "        [ 0.0235],\n",
      "        [ 0.0177],\n",
      "        [ 0.0334],\n",
      "        [ 0.0283],\n",
      "        [ 0.0142],\n",
      "        [ 0.0117],\n",
      "        [ 0.0182],\n",
      "        [-0.0204],\n",
      "        [ 0.0059],\n",
      "        [ 0.0034],\n",
      "        [ 0.0112],\n",
      "        [ 0.0344],\n",
      "        [ 0.0072],\n",
      "        [ 0.0199],\n",
      "        [ 0.0229],\n",
      "        [ 0.0180],\n",
      "        [-0.0204],\n",
      "        [ 0.0266],\n",
      "        [ 0.0339],\n",
      "        [ 0.0310],\n",
      "        [ 0.0220],\n",
      "        [ 0.0202],\n",
      "        [ 0.0042],\n",
      "        [ 0.0262],\n",
      "        [ 0.0187],\n",
      "        [ 0.0121],\n",
      "        [ 0.0053],\n",
      "        [ 0.0329],\n",
      "        [ 0.0128],\n",
      "        [ 0.0118],\n",
      "        [ 0.0008],\n",
      "        [ 0.0310],\n",
      "        [ 0.0282],\n",
      "        [ 0.0128],\n",
      "        [ 0.0157],\n",
      "        [-0.0323],\n",
      "        [-0.0236],\n",
      "        [ 0.0087],\n",
      "        [-0.0063],\n",
      "        [ 0.0137],\n",
      "        [ 0.0058],\n",
      "        [ 0.0166],\n",
      "        [ 0.0330],\n",
      "        [-0.0172],\n",
      "        [ 0.0332],\n",
      "        [-0.0080],\n",
      "        [ 0.0109],\n",
      "        [ 0.0019],\n",
      "        [ 0.0031],\n",
      "        [ 0.0318],\n",
      "        [-0.0310],\n",
      "        [ 0.0142],\n",
      "        [-0.0077],\n",
      "        [ 0.0095],\n",
      "        [ 0.0200],\n",
      "        [ 0.0306],\n",
      "        [-0.0311],\n",
      "        [ 0.0029],\n",
      "        [ 0.0149],\n",
      "        [-0.0292],\n",
      "        [-0.0164],\n",
      "        [-0.0156],\n",
      "        [-0.0340],\n",
      "        [ 0.0268],\n",
      "        [ 0.0195],\n",
      "        [-0.0036],\n",
      "        [-0.0347],\n",
      "        [-0.0271],\n",
      "        [-0.0299],\n",
      "        [ 0.0152],\n",
      "        [ 0.0037],\n",
      "        [-0.0275],\n",
      "        [ 0.0268],\n",
      "        [ 0.0319],\n",
      "        [-0.0302],\n",
      "        [ 0.0291],\n",
      "        [-0.0057],\n",
      "        [ 0.0186],\n",
      "        [ 0.0129],\n",
      "        [ 0.0103],\n",
      "        [-0.0236],\n",
      "        [ 0.0171],\n",
      "        [-0.0299],\n",
      "        [ 0.0120],\n",
      "        [ 0.0234],\n",
      "        [ 0.0314],\n",
      "        [-0.0106],\n",
      "        [-0.0010],\n",
      "        [ 0.0272]], grad_fn=<SliceBackward0>)\n",
      "Epoch 0, Training-Loss 5.0638e-04,Test-Loss 6.5623e+05,\n",
      "Epoch 0,Residual_data_loss 6.5608e+05, ,pde_loss 6.3244e-03, ,init_loss 0.0000e+00, ,bc_loss 0.0000e+00\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rrammohan\\OneDrive - The University of Melbourne\\github\\Gen-2\\1D_HT_Pinn\\Data-prep\\PINN\\MushyZone-PINN\\Pinn-Mush\\Non-Spartan\\all_data\\UnScaled\\pinn_loss.py:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(v1,device=temp.device),\n",
      "c:\\Users\\rrammohan\\OneDrive - The University of Melbourne\\github\\Gen-2\\1D_HT_Pinn\\Data-prep\\PINN\\MushyZone-PINN\\Pinn-Mush\\Non-Spartan\\all_data\\UnScaled\\pinn_loss.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(v2,device=temp.device),\n",
      "c:\\Users\\rrammohan\\OneDrive - The University of Melbourne\\github\\Gen-2\\1D_HT_Pinn\\Data-prep\\PINN\\MushyZone-PINN\\Pinn-Mush\\Non-Spartan\\all_data\\UnScaled\\pinn_loss.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(v2,device=temp.device) + slope*(temp-T_S),\n",
      "c:\\Users\\rrammohan\\OneDrive - The University of Melbourne\\github\\Gen-2\\1D_HT_Pinn\\Data-prep\\PINN\\MushyZone-PINN\\Pinn-Mush\\Non-Spartan\\all_data\\UnScaled\\pinn_loss.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  k_m_t = torch.tensor(k_m,device=temp.device)\n",
      "c:\\Users\\rrammohan\\OneDrive - The University of Melbourne\\github\\Gen-2\\1D_HT_Pinn\\Data-prep\\PINN\\MushyZone-PINN\\Pinn-Mush\\Non-Spartan\\all_data\\UnScaled\\pinn_loss.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(v1,device=temp.device),\n",
      "c:\\Users\\rrammohan\\OneDrive - The University of Melbourne\\github\\Gen-2\\1D_HT_Pinn\\Data-prep\\PINN\\MushyZone-PINN\\Pinn-Mush\\Non-Spartan\\all_data\\UnScaled\\pinn_loss.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(v2,device=temp.device),\n",
      "c:\\Users\\rrammohan\\OneDrive - The University of Melbourne\\github\\Gen-2\\1D_HT_Pinn\\Data-prep\\PINN\\MushyZone-PINN\\Pinn-Mush\\Non-Spartan\\all_data\\UnScaled\\pinn_loss.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(v2,device=temp.device) + slope*(temp-T_S),\n",
      "c:\\Users\\rrammohan\\OneDrive - The University of Melbourne\\github\\Gen-2\\1D_HT_Pinn\\Data-prep\\PINN\\MushyZone-PINN\\Pinn-Mush\\Non-Spartan\\all_data\\UnScaled\\pinn_loss.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cp_m_t = torch.tensor(cp_m,device=temp.device)\n",
      "c:\\Users\\rrammohan\\OneDrive - The University of Melbourne\\github\\Gen-2\\1D_HT_Pinn\\Data-prep\\PINN\\MushyZone-PINN\\Pinn-Mush\\Non-Spartan\\all_data\\UnScaled\\pinn_loss.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(v1,device=temp.device),\n",
      "c:\\Users\\rrammohan\\OneDrive - The University of Melbourne\\github\\Gen-2\\1D_HT_Pinn\\Data-prep\\PINN\\MushyZone-PINN\\Pinn-Mush\\Non-Spartan\\all_data\\UnScaled\\pinn_loss.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(v2,device=temp.device),\n",
      "c:\\Users\\rrammohan\\OneDrive - The University of Melbourne\\github\\Gen-2\\1D_HT_Pinn\\Data-prep\\PINN\\MushyZone-PINN\\Pinn-Mush\\Non-Spartan\\all_data\\UnScaled\\pinn_loss.py:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(v2,device=temp.device) + slope*(temp-T_S),\n",
      "c:\\Users\\rrammohan\\OneDrive - The University of Melbourne\\github\\Gen-2\\1D_HT_Pinn\\Data-prep\\PINN\\MushyZone-PINN\\Pinn-Mush\\Non-Spartan\\all_data\\UnScaled\\pinn_loss.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rho_m_t = torch.tensor(rho_m,device=temp.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0792],\n",
      "        [-0.0823],\n",
      "        [-0.0935],\n",
      "        [-0.0723],\n",
      "        [-0.0938],\n",
      "        [-0.0860],\n",
      "        [-0.0841],\n",
      "        [-0.0878],\n",
      "        [-0.0907],\n",
      "        [-0.0542],\n",
      "        [-0.0758],\n",
      "        [-0.0888],\n",
      "        [-0.0888],\n",
      "        [-0.0808],\n",
      "        [-0.0751],\n",
      "        [-0.0451],\n",
      "        [-0.0793],\n",
      "        [-0.0744],\n",
      "        [-0.0711],\n",
      "        [-0.0885],\n",
      "        [-0.0876],\n",
      "        [-0.0883],\n",
      "        [-0.0908],\n",
      "        [-0.0896],\n",
      "        [-0.0934],\n",
      "        [-0.0773],\n",
      "        [-0.0808],\n",
      "        [-0.0482],\n",
      "        [-0.0847],\n",
      "        [-0.0812],\n",
      "        [-0.0910],\n",
      "        [-0.0826],\n",
      "        [-0.0888],\n",
      "        [-0.0624],\n",
      "        [-0.0864],\n",
      "        [-0.0398],\n",
      "        [-0.0722],\n",
      "        [-0.0778],\n",
      "        [-0.0826],\n",
      "        [-0.0862],\n",
      "        [-0.0726],\n",
      "        [-0.0639],\n",
      "        [-0.0757],\n",
      "        [-0.0904],\n",
      "        [-0.0921],\n",
      "        [-0.0770],\n",
      "        [-0.0857],\n",
      "        [-0.0921],\n",
      "        [-0.0841],\n",
      "        [-0.0833],\n",
      "        [-0.0649],\n",
      "        [-0.0820],\n",
      "        [-0.0717],\n",
      "        [-0.0873],\n",
      "        [-0.0779],\n",
      "        [-0.0825],\n",
      "        [-0.0804],\n",
      "        [-0.0845],\n",
      "        [-0.0938],\n",
      "        [-0.0833],\n",
      "        [-0.0856],\n",
      "        [-0.0781],\n",
      "        [-0.0705],\n",
      "        [-0.0890],\n",
      "        [-0.0617],\n",
      "        [-0.0921],\n",
      "        [-0.0520],\n",
      "        [-0.0892],\n",
      "        [-0.0922],\n",
      "        [-0.0855],\n",
      "        [-0.0777],\n",
      "        [-0.0674],\n",
      "        [-0.0791],\n",
      "        [-0.0640],\n",
      "        [-0.0691],\n",
      "        [-0.0874],\n",
      "        [-0.0798],\n",
      "        [-0.0846],\n",
      "        [-0.0847],\n",
      "        [-0.0804],\n",
      "        [-0.0725],\n",
      "        [-0.0792],\n",
      "        [-0.0838],\n",
      "        [-0.0909],\n",
      "        [-0.0412],\n",
      "        [-0.0441],\n",
      "        [-0.0560],\n",
      "        [-0.0888],\n",
      "        [-0.0649],\n",
      "        [-0.0926],\n",
      "        [-0.0923],\n",
      "        [-0.0854],\n",
      "        [-0.0882],\n",
      "        [-0.0934],\n",
      "        [-0.0800],\n",
      "        [-0.0881],\n",
      "        [-0.0854],\n",
      "        [-0.0864],\n",
      "        [-0.0908],\n",
      "        [-0.0884],\n",
      "        [-0.0799],\n",
      "        [-0.0876],\n",
      "        [-0.0500],\n",
      "        [-0.0769],\n",
      "        [-0.0764],\n",
      "        [-0.0802],\n",
      "        [-0.0939],\n",
      "        [-0.0839],\n",
      "        [-0.0700],\n",
      "        [-0.0801],\n",
      "        [-0.0928],\n",
      "        [-0.0908],\n",
      "        [-0.0712],\n",
      "        [-0.0744],\n",
      "        [-0.0825],\n",
      "        [-0.0877],\n",
      "        [-0.0936],\n",
      "        [-0.0912],\n",
      "        [-0.0688],\n",
      "        [-0.0691],\n",
      "        [-0.0839],\n",
      "        [-0.0638],\n",
      "        [-0.0800],\n",
      "        [-0.0861],\n",
      "        [-0.0791],\n",
      "        [-0.0942],\n",
      "        [-0.0902],\n",
      "        [-0.0871]], grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0408],\n",
      "        [0.0205],\n",
      "        [0.0467],\n",
      "        [0.0191],\n",
      "        [0.0479],\n",
      "        [0.0140],\n",
      "        [0.0185],\n",
      "        [0.0467],\n",
      "        [0.0405],\n",
      "        [0.0293],\n",
      "        [0.0295],\n",
      "        [0.0506],\n",
      "        [0.0436],\n",
      "        [0.0338],\n",
      "        [0.0395],\n",
      "        [0.0149],\n",
      "        [0.0452],\n",
      "        [0.0178],\n",
      "        [0.0368],\n",
      "        [0.0365],\n",
      "        [0.0485],\n",
      "        [0.0219],\n",
      "        [0.0409],\n",
      "        [0.0472],\n",
      "        [0.0490],\n",
      "        [0.0440],\n",
      "        [0.0494],\n",
      "        [0.0213],\n",
      "        [0.0451],\n",
      "        [0.0434],\n",
      "        [0.0412],\n",
      "        [0.0283],\n",
      "        [0.0368],\n",
      "        [0.0076],\n",
      "        [0.0288],\n",
      "        [0.0045],\n",
      "        [0.0306],\n",
      "        [0.0170],\n",
      "        [0.0441],\n",
      "        [0.0288],\n",
      "        [0.0328],\n",
      "        [0.0234],\n",
      "        [0.0433],\n",
      "        [0.0326],\n",
      "        [0.0472],\n",
      "        [0.0438],\n",
      "        [0.0401],\n",
      "        [0.0430],\n",
      "        [0.0470],\n",
      "        [0.0289],\n",
      "        [0.0078],\n",
      "        [0.0262],\n",
      "        [0.0248],\n",
      "        [0.0463],\n",
      "        [0.0421],\n",
      "        [0.0479],\n",
      "        [0.0236],\n",
      "        [0.0092],\n",
      "        [0.0480],\n",
      "        [0.0014],\n",
      "        [0.0147],\n",
      "        [0.0170],\n",
      "        [0.0129],\n",
      "        [0.0469],\n",
      "        [0.0338],\n",
      "        [0.0514],\n",
      "        [0.0253],\n",
      "        [0.0431],\n",
      "        [0.0454],\n",
      "        [0.0344],\n",
      "        [0.0332],\n",
      "        [0.0169],\n",
      "        [0.0486],\n",
      "        [0.0349],\n",
      "        [0.0380],\n",
      "        [0.0456],\n",
      "        [0.0492],\n",
      "        [0.0329],\n",
      "        [0.0448],\n",
      "        [0.0227],\n",
      "        [0.0344],\n",
      "        [0.0375],\n",
      "        [0.0318],\n",
      "        [0.0411],\n",
      "        [0.0176],\n",
      "        [0.0123],\n",
      "        [0.0177],\n",
      "        [0.0443],\n",
      "        [0.0335],\n",
      "        [0.0510],\n",
      "        [0.0489],\n",
      "        [0.0455],\n",
      "        [0.0468],\n",
      "        [0.0520],\n",
      "        [0.0475],\n",
      "        [0.0299],\n",
      "        [0.0124],\n",
      "        [0.0354],\n",
      "        [0.0371],\n",
      "        [0.0503],\n",
      "        [0.0430],\n",
      "        [0.0436],\n",
      "        [0.0245],\n",
      "        [0.0481],\n",
      "        [0.0390],\n",
      "        [0.0402],\n",
      "        [0.0504],\n",
      "        [0.0445],\n",
      "        [0.0334],\n",
      "        [0.0377],\n",
      "        [0.0516],\n",
      "        [0.0427],\n",
      "        [0.0365],\n",
      "        [0.0270],\n",
      "        [0.0270],\n",
      "        [0.0444],\n",
      "        [0.0516],\n",
      "        [0.0445],\n",
      "        [0.0013],\n",
      "        [0.0427],\n",
      "        [0.0016],\n",
      "        [0.0353],\n",
      "        [0.0319],\n",
      "        [0.0115],\n",
      "        [0.0416],\n",
      "        [0.0510],\n",
      "        [0.0402],\n",
      "        [0.0099]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.0137],\n",
      "        [ 0.0223],\n",
      "        [-0.0173],\n",
      "        [ 0.0295],\n",
      "        [-0.0108],\n",
      "        [ 0.0235],\n",
      "        [ 0.0234],\n",
      "        [ 0.0065],\n",
      "        [ 0.0312],\n",
      "        [ 0.0121],\n",
      "        [ 0.0182],\n",
      "        [ 0.0115],\n",
      "        [ 0.0269],\n",
      "        [ 0.0262],\n",
      "        [ 0.0123],\n",
      "        [ 0.0174],\n",
      "        [ 0.0148],\n",
      "        [-0.0288],\n",
      "        [ 0.0137],\n",
      "        [-0.0271],\n",
      "        [ 0.0177],\n",
      "        [ 0.0345],\n",
      "        [-0.0247],\n",
      "        [-0.0002],\n",
      "        [-0.0051],\n",
      "        [-0.0247],\n",
      "        [ 0.0025],\n",
      "        [ 0.0149],\n",
      "        [ 0.0080],\n",
      "        [ 0.0009],\n",
      "        [-0.0241],\n",
      "        [ 0.0316],\n",
      "        [-0.0268],\n",
      "        [-0.0247],\n",
      "        [ 0.0338],\n",
      "        [ 0.0195],\n",
      "        [-0.0353],\n",
      "        [ 0.0319],\n",
      "        [ 0.0081],\n",
      "        [ 0.0337],\n",
      "        [-0.0348],\n",
      "        [ 0.0227],\n",
      "        [-0.0249],\n",
      "        [ 0.0349],\n",
      "        [ 0.0219],\n",
      "        [ 0.0139],\n",
      "        [ 0.0232],\n",
      "        [-0.0190],\n",
      "        [ 0.0174],\n",
      "        [-0.0300],\n",
      "        [-0.0238],\n",
      "        [-0.0240],\n",
      "        [ 0.0266],\n",
      "        [ 0.0014],\n",
      "        [ 0.0057],\n",
      "        [ 0.0133],\n",
      "        [-0.0238],\n",
      "        [ 0.0180],\n",
      "        [-0.0102],\n",
      "        [ 0.0211],\n",
      "        [ 0.0322],\n",
      "        [ 0.0320],\n",
      "        [ 0.0297],\n",
      "        [-0.0003],\n",
      "        [ 0.0110],\n",
      "        [-0.0092],\n",
      "        [ 0.0141],\n",
      "        [-0.0123],\n",
      "        [-0.0214],\n",
      "        [ 0.0283],\n",
      "        [-0.0341],\n",
      "        [ 0.0279],\n",
      "        [-0.0097],\n",
      "        [ 0.0111],\n",
      "        [ 0.0082],\n",
      "        [-0.0019],\n",
      "        [-0.0017],\n",
      "        [ 0.0303],\n",
      "        [ 0.0099],\n",
      "        [ 0.0212],\n",
      "        [ 0.0182],\n",
      "        [ 0.0206],\n",
      "        [-0.0214],\n",
      "        [ 0.0296],\n",
      "        [ 0.0134],\n",
      "        [ 0.0183],\n",
      "        [ 0.0218],\n",
      "        [-0.0089],\n",
      "        [ 0.0139],\n",
      "        [ 0.0110],\n",
      "        [ 0.0185],\n",
      "        [ 0.0077],\n",
      "        [ 0.0085],\n",
      "        [ 0.0005],\n",
      "        [-0.0172],\n",
      "        [ 0.0318],\n",
      "        [ 0.0216],\n",
      "        [-0.0206],\n",
      "        [ 0.0334],\n",
      "        [-0.0131],\n",
      "        [ 0.0022],\n",
      "        [-0.0089],\n",
      "        [ 0.0137],\n",
      "        [-0.0030],\n",
      "        [ 0.0147],\n",
      "        [ 0.0206],\n",
      "        [-0.0106],\n",
      "        [ 0.0014],\n",
      "        [ 0.0176],\n",
      "        [ 0.0206],\n",
      "        [ 0.0073],\n",
      "        [ 0.0293],\n",
      "        [ 0.0144],\n",
      "        [ 0.0269],\n",
      "        [-0.0295],\n",
      "        [-0.0069],\n",
      "        [ 0.0018],\n",
      "        [ 0.0273],\n",
      "        [ 0.0262],\n",
      "        [-0.0188],\n",
      "        [ 0.0204],\n",
      "        [ 0.0093],\n",
      "        [ 0.0222],\n",
      "        [ 0.0223],\n",
      "        [ 0.0184],\n",
      "        [-0.0063],\n",
      "        [-0.0194],\n",
      "        [ 0.0242]], grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.0214],\n",
      "        [-0.0259],\n",
      "        [-0.0087],\n",
      "        [-0.0299],\n",
      "        [-0.0248],\n",
      "        [-0.0196],\n",
      "        [-0.0238],\n",
      "        [-0.0231],\n",
      "        [-0.0288],\n",
      "        [-0.0239],\n",
      "        [-0.0301],\n",
      "        [-0.0260],\n",
      "        [-0.0318],\n",
      "        [-0.0102],\n",
      "        [-0.0207],\n",
      "        [-0.0315],\n",
      "        [-0.0125],\n",
      "        [-0.0318],\n",
      "        [-0.0246],\n",
      "        [-0.0220],\n",
      "        [-0.0222],\n",
      "        [-0.0299],\n",
      "        [-0.0265],\n",
      "        [-0.0183],\n",
      "        [-0.0231],\n",
      "        [-0.0324],\n",
      "        [-0.0304],\n",
      "        [-0.0261],\n",
      "        [-0.0299],\n",
      "        [-0.0184],\n",
      "        [-0.0260],\n",
      "        [-0.0291],\n",
      "        [-0.0268],\n",
      "        [-0.0268],\n",
      "        [-0.0210],\n",
      "        [-0.0264],\n",
      "        [-0.0261],\n",
      "        [-0.0296],\n",
      "        [-0.0284],\n",
      "        [-0.0246],\n",
      "        [-0.0287],\n",
      "        [-0.0196],\n",
      "        [-0.0230],\n",
      "        [-0.0322],\n",
      "        [-0.0279],\n",
      "        [-0.0138],\n",
      "        [-0.0256],\n",
      "        [-0.0297],\n",
      "        [-0.0283],\n",
      "        [-0.0249],\n",
      "        [-0.0262],\n",
      "        [-0.0317],\n",
      "        [-0.0315],\n",
      "        [-0.0194],\n",
      "        [-0.0295],\n",
      "        [-0.0311],\n",
      "        [-0.0292],\n",
      "        [-0.0287],\n",
      "        [-0.0291],\n",
      "        [-0.0258],\n",
      "        [-0.0168],\n",
      "        [-0.0311],\n",
      "        [-0.0254],\n",
      "        [-0.0229],\n",
      "        [-0.0237],\n",
      "        [-0.0209],\n",
      "        [-0.0281],\n",
      "        [-0.0314],\n",
      "        [-0.0173],\n",
      "        [-0.0303],\n",
      "        [-0.0159],\n",
      "        [-0.0299],\n",
      "        [-0.0226],\n",
      "        [-0.0295],\n",
      "        [-0.0172],\n",
      "        [-0.0286],\n",
      "        [-0.0157],\n",
      "        [-0.0197],\n",
      "        [-0.0199],\n",
      "        [-0.0301],\n",
      "        [-0.0127],\n",
      "        [-0.0309],\n",
      "        [-0.0320],\n",
      "        [-0.0204],\n",
      "        [-0.0125],\n",
      "        [-0.0298],\n",
      "        [-0.0270],\n",
      "        [-0.0188],\n",
      "        [-0.0300],\n",
      "        [-0.0326],\n",
      "        [-0.0256],\n",
      "        [-0.0198],\n",
      "        [-0.0319],\n",
      "        [-0.0256],\n",
      "        [-0.0234],\n",
      "        [-0.0106],\n",
      "        [-0.0017],\n",
      "        [-0.0057],\n",
      "        [-0.0207],\n",
      "        [-0.0261],\n",
      "        [-0.0232],\n",
      "        [-0.0331],\n",
      "        [-0.0093],\n",
      "        [-0.0304],\n",
      "        [-0.0305],\n",
      "        [-0.0298],\n",
      "        [-0.0216],\n",
      "        [-0.0270],\n",
      "        [-0.0267],\n",
      "        [-0.0313],\n",
      "        [-0.0289],\n",
      "        [-0.0179],\n",
      "        [-0.0266],\n",
      "        [-0.0195],\n",
      "        [-0.0235],\n",
      "        [-0.0181],\n",
      "        [-0.0286],\n",
      "        [-0.0228],\n",
      "        [-0.0270],\n",
      "        [-0.0074],\n",
      "        [-0.0312],\n",
      "        [-0.0305],\n",
      "        [-0.0301],\n",
      "        [-0.0289],\n",
      "        [-0.0302],\n",
      "        [-0.0222],\n",
      "        [-0.0300],\n",
      "        [-0.0169]], grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0359],\n",
      "        [0.0323],\n",
      "        [0.0261],\n",
      "        [0.0352],\n",
      "        [0.0480],\n",
      "        [0.0306],\n",
      "        [0.0309],\n",
      "        [0.0311],\n",
      "        [0.0378],\n",
      "        [0.0190],\n",
      "        [0.0246],\n",
      "        [0.0493],\n",
      "        [0.0181],\n",
      "        [0.0275],\n",
      "        [0.0389],\n",
      "        [0.0326],\n",
      "        [0.0246],\n",
      "        [0.0179],\n",
      "        [0.0309],\n",
      "        [0.0412],\n",
      "        [0.0427],\n",
      "        [0.0158],\n",
      "        [0.0446],\n",
      "        [0.0334],\n",
      "        [0.0333],\n",
      "        [0.0310],\n",
      "        [0.0392],\n",
      "        [0.0488],\n",
      "        [0.0411],\n",
      "        [0.0243],\n",
      "        [0.0242],\n",
      "        [0.0258],\n",
      "        [0.0280],\n",
      "        [0.0482],\n",
      "        [0.0231],\n",
      "        [0.0284],\n",
      "        [0.0398],\n",
      "        [0.0310],\n",
      "        [0.0409],\n",
      "        [0.0479],\n",
      "        [0.0442],\n",
      "        [0.0306],\n",
      "        [0.0307],\n",
      "        [0.0265],\n",
      "        [0.0185],\n",
      "        [0.0313],\n",
      "        [0.0461],\n",
      "        [0.0407],\n",
      "        [0.0414],\n",
      "        [0.0483],\n",
      "        [0.0424],\n",
      "        [0.0175],\n",
      "        [0.0351],\n",
      "        [0.0356],\n",
      "        [0.0222],\n",
      "        [0.0256],\n",
      "        [0.0285],\n",
      "        [0.0385],\n",
      "        [0.0390],\n",
      "        [0.0384],\n",
      "        [0.0239],\n",
      "        [0.0202],\n",
      "        [0.0111],\n",
      "        [0.0424],\n",
      "        [0.0365],\n",
      "        [0.0321],\n",
      "        [0.0414],\n",
      "        [0.0324],\n",
      "        [0.0354],\n",
      "        [0.0239],\n",
      "        [0.0333],\n",
      "        [0.0224],\n",
      "        [0.0108],\n",
      "        [0.0106],\n",
      "        [0.0224],\n",
      "        [0.0364],\n",
      "        [0.0175],\n",
      "        [0.0273],\n",
      "        [0.0174],\n",
      "        [0.0321],\n",
      "        [0.0303],\n",
      "        [0.0323],\n",
      "        [0.0205],\n",
      "        [0.0389],\n",
      "        [0.0233],\n",
      "        [0.0292],\n",
      "        [0.0452],\n",
      "        [0.0366],\n",
      "        [0.0129],\n",
      "        [0.0268],\n",
      "        [0.0478],\n",
      "        [0.0351],\n",
      "        [0.0292],\n",
      "        [0.0371],\n",
      "        [0.0431],\n",
      "        [0.0268],\n",
      "        [0.0175],\n",
      "        [0.0229],\n",
      "        [0.0230],\n",
      "        [0.0423],\n",
      "        [0.0451],\n",
      "        [0.0268],\n",
      "        [0.0263],\n",
      "        [0.0111],\n",
      "        [0.0386],\n",
      "        [0.0277],\n",
      "        [0.0355],\n",
      "        [0.0208],\n",
      "        [0.0415],\n",
      "        [0.0159],\n",
      "        [0.0389],\n",
      "        [0.0316],\n",
      "        [0.0373],\n",
      "        [0.0369],\n",
      "        [0.0457],\n",
      "        [0.0295],\n",
      "        [0.0427],\n",
      "        [0.0406],\n",
      "        [0.0319],\n",
      "        [0.0227],\n",
      "        [0.0140],\n",
      "        [0.0336],\n",
      "        [0.0400],\n",
      "        [0.0334],\n",
      "        [0.0379],\n",
      "        [0.0392],\n",
      "        [0.0236],\n",
      "        [0.0274]], grad_fn=<SliceBackward0>)\n",
      "tensor([[-2.7068e-02],\n",
      "        [-2.7734e-03],\n",
      "        [ 1.1272e-02],\n",
      "        [ 2.1734e-02],\n",
      "        [-9.9596e-03],\n",
      "        [ 2.3451e-02],\n",
      "        [-1.4817e-03],\n",
      "        [-8.7168e-04],\n",
      "        [ 1.9277e-02],\n",
      "        [-2.1513e-02],\n",
      "        [-1.8325e-02],\n",
      "        [ 3.6561e-03],\n",
      "        [ 1.6040e-02],\n",
      "        [ 7.6191e-03],\n",
      "        [ 9.8533e-03],\n",
      "        [-8.9152e-03],\n",
      "        [ 1.8581e-02],\n",
      "        [ 1.6773e-02],\n",
      "        [-2.7272e-02],\n",
      "        [-2.3158e-02],\n",
      "        [-2.0884e-02],\n",
      "        [ 2.2351e-02],\n",
      "        [ 2.1865e-02],\n",
      "        [ 1.8941e-02],\n",
      "        [ 4.0827e-05],\n",
      "        [-1.1626e-02],\n",
      "        [-1.4171e-02],\n",
      "        [ 2.0662e-03],\n",
      "        [-1.5069e-02],\n",
      "        [-2.5252e-02],\n",
      "        [-2.4065e-02],\n",
      "        [-2.1710e-02],\n",
      "        [-3.2911e-03],\n",
      "        [-8.0851e-03],\n",
      "        [-2.4697e-02],\n",
      "        [ 3.0491e-02],\n",
      "        [-1.5109e-03],\n",
      "        [-5.5530e-03],\n",
      "        [ 2.2403e-02],\n",
      "        [-9.6848e-03],\n",
      "        [-1.4161e-02],\n",
      "        [ 2.3422e-02],\n",
      "        [-2.7573e-02],\n",
      "        [-1.3551e-02],\n",
      "        [ 2.6080e-02],\n",
      "        [ 1.1484e-02],\n",
      "        [ 2.9167e-03],\n",
      "        [-1.1120e-02],\n",
      "        [ 2.2735e-02],\n",
      "        [-1.1951e-03],\n",
      "        [-1.1450e-03],\n",
      "        [ 1.8122e-02],\n",
      "        [-1.2909e-02],\n",
      "        [ 5.7742e-03],\n",
      "        [-1.7526e-02],\n",
      "        [-3.6238e-03],\n",
      "        [ 3.0412e-02],\n",
      "        [-6.2113e-03],\n",
      "        [ 2.3769e-02],\n",
      "        [ 2.8182e-02],\n",
      "        [-2.4770e-02],\n",
      "        [ 2.3643e-02],\n",
      "        [ 2.0517e-02],\n",
      "        [ 1.0860e-02],\n",
      "        [-2.7325e-02],\n",
      "        [-2.7677e-02],\n",
      "        [-5.7145e-03],\n",
      "        [-8.5809e-03],\n",
      "        [-2.2598e-02],\n",
      "        [-1.7124e-02],\n",
      "        [ 9.0498e-03],\n",
      "        [ 2.7280e-02],\n",
      "        [ 2.0550e-02],\n",
      "        [ 1.7635e-02],\n",
      "        [-2.4032e-02],\n",
      "        [ 2.9845e-02],\n",
      "        [-2.0454e-02],\n",
      "        [ 2.4718e-02],\n",
      "        [ 2.3913e-02],\n",
      "        [-2.1774e-02],\n",
      "        [ 1.0398e-02],\n",
      "        [-1.9580e-02],\n",
      "        [ 1.7521e-02],\n",
      "        [-2.3988e-02],\n",
      "        [ 1.9220e-02],\n",
      "        [-5.0300e-03],\n",
      "        [ 2.0255e-02],\n",
      "        [ 9.8857e-03],\n",
      "        [ 1.9306e-02],\n",
      "        [-1.2303e-02],\n",
      "        [ 8.4832e-03],\n",
      "        [ 1.9814e-02],\n",
      "        [-1.5546e-02],\n",
      "        [-1.4230e-03],\n",
      "        [ 1.5579e-03],\n",
      "        [ 6.5082e-03],\n",
      "        [ 1.1493e-02],\n",
      "        [ 1.1149e-02],\n",
      "        [-2.4672e-02],\n",
      "        [-1.1125e-03],\n",
      "        [-2.6921e-03],\n",
      "        [-8.7814e-03],\n",
      "        [ 7.1032e-03],\n",
      "        [ 1.2112e-02],\n",
      "        [-1.6357e-02],\n",
      "        [-2.1108e-02],\n",
      "        [ 2.3093e-02],\n",
      "        [ 2.7605e-02],\n",
      "        [ 1.3581e-02],\n",
      "        [ 1.8353e-02],\n",
      "        [ 2.6773e-02],\n",
      "        [ 4.0441e-03],\n",
      "        [-2.6712e-03],\n",
      "        [-2.4971e-02],\n",
      "        [-1.5957e-02],\n",
      "        [-2.6694e-02],\n",
      "        [-1.9257e-02],\n",
      "        [ 5.3832e-03],\n",
      "        [ 3.1071e-02],\n",
      "        [ 1.3959e-02],\n",
      "        [ 1.5027e-02],\n",
      "        [ 2.5904e-02],\n",
      "        [-1.2707e-02],\n",
      "        [-2.4184e-02],\n",
      "        [-1.9719e-02],\n",
      "        [ 5.1336e-03],\n",
      "        [-1.7576e-02],\n",
      "        [-2.5913e-02]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "train_losses, val_losses = training_loop(epochs, model, loss_fn_data, optimizer,train_loader,test_loader)  # Train the model\n",
    " \n",
    "# test_losses = test_loop(epochs, model, loss_fn_data, optimizer, train_loader, test_loader)  # Test the model\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model.cpu()\n",
    "inputs = inputs.cpu()\n",
    "temp_inp = temp_inp.cpu()\n",
    "temp_nn = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).cpu().detach().numpy() # Get the predictions from the model\n",
    "\n",
    "temp_nn = temp_nn.reshape(num_steps+1, num_points) # Reshape the predictions to a 2D array\n",
    "time_ss= np.linspace(0, time_end, num_steps+1)\n",
    "plt.figure\n",
    "plt.plot(time_ss, temp_nn[:,num_points//2], label='Predicted Temperature')\n",
    "plt.plot(time_ss, temperature_history[:,num_points//2], label='Actual Temperature')\n",
    "plt.xlabel('Time(s)')\n",
    "plt.ylabel('Temperature (K)')\n",
    "plt.title('Predicted vs Actual Temperature at x = 7.5mm')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,) (2,)\n"
     ]
    }
   ],
   "source": [
    "train_losses = np.array(train_losses)\n",
    "test_losses = np.array(test_losses)\n",
    "\n",
    "print(train_losses.shape, test_losses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mpd_losses\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPde Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(initc_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(bc_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBC Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd_losses' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pd_losses, label='Pde Loss')\n",
    "plt.plot(initc_losses, label='Initial Loss')\n",
    "plt.plot(bc_losses, label='BC Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
