{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Three Phase Simulation of Alloys and PINN model development \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the simulation of 1D Phase change of aluminium alloy. There will be three phases (solid,liquid and mushy).   \n",
    "\n",
    "The approach used is finite difference method and the physics involved in heat conduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import csv\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "\n",
    "from pinn_loss import loss_fn_data, l1_regularization, pde_loss, boundary_loss, ic_loss, accuracy\n",
    "from Input_vec_gen import input_gen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the constants and inital geometric domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_l = 3.394878564540885e-05, alpha_s = 3.686205086349929e-05, m_eff = 6.296953764744878e-06\n",
      "dx is 0.0003061224489795918\n",
      "dt is  0.0012711033647622566\n",
      "num_steps is 31469\n",
      "cfl is 0.0012711033647622566\n",
      "stability criteria satisfied\n"
     ]
    }
   ],
   "source": [
    "# Geometry\n",
    "length = 15.0e-3             # Length of the rod\n",
    "\n",
    "# Material properties\n",
    "rho = 2300.0                     # Density of AL380 (kg/m^3)\n",
    "rho_l = 2460.0                   # Density of AL380 (kg/m^3)\n",
    "rho_s = 2710.0                    # Density of AL380 (kg/m^3)\n",
    "rho_m = (rho_l + rho_s )/2       # Desnity in mushy zone is taken as average of liquid and solid density\n",
    "\n",
    "k = 104.0                       # W/m-K\n",
    "k_l = k                       # W/m-K\n",
    "k_s = 96.2                    # W/m-K\n",
    "k_m =  (k_l+k_s)/2                     # W/m-K\n",
    "k_mo = 41.5\n",
    "\n",
    "\n",
    "cp = 1245.3                      # Specific heat of aluminum (J/kg-K)\n",
    "cp_l = cp                      # Specific heat of aluminum (J/kg-K)\n",
    "cp_s = 963.0                 # Specific heat of aluminum (J/kg-K)\n",
    "cp_m =  (cp_l+cp_s)/2                 # Specific heat of mushy zone is taken as average of liquid and solid specific heat\n",
    "# cp_m = cp\n",
    "           # Thermal diffusivity\n",
    "alpha_l = k_l / (rho_l * cp_l) \n",
    "alpha_s = k_s / (rho_s*cp_s)\n",
    "alpha_m = k_m / (rho_m * cp_m)          #`Thermal diffusivity in mushy zone is taken as average of liquid and solid thermal diffusivity`\n",
    "\n",
    "\n",
    "#L_fusion = 3.9e3                 # J/kg\n",
    "L_fusion = 389.0e3               # J/kg  # Latent heat of fusion of aluminum\n",
    "         # Thermal diffusivity\n",
    "\n",
    "\n",
    "T_L = 574.4 +273.0                       #  K -Liquidus Temperature (615 c) AL 380\n",
    "T_S = 497.3 +273.0                     # K- Solidus Temperature (550 C)\n",
    "m_eff =(k_m/(rho_m*(cp_m + (L_fusion/(T_L-T_S)))))\n",
    "print (f\"alpha_l = {alpha_l}, alpha_s = {alpha_s}, m_eff = {m_eff}\")\n",
    "\n",
    "# htc = 10.0                   # W/m^2-K\n",
    "# q = htc*(919.0-723.0)\n",
    "# q = 10000.0\n",
    "\n",
    "\n",
    "num_points = 50                        # Number of spatial points\n",
    "dx = length / (num_points - 1)         # Distance between two spatial points\n",
    "print('dx is',dx)\n",
    "\n",
    "                                                              \n",
    "# Time Discretization  \n",
    "# \n",
    "time_end = 40        # seconds                         \n",
    "\n",
    "maxi = max(alpha_s,alpha_l,alpha_m)\n",
    "dt = abs(0.5*((dx**2) /maxi)) \n",
    "\n",
    "print('dt is ',dt)\n",
    "num_steps = round(time_end/dt)\n",
    "print('num_steps is',num_steps)\n",
    "cfl = 0.5 *(dx**2/max(alpha_l,alpha_s,alpha_m))\n",
    "print('cfl is',cfl)\n",
    "\n",
    "time_steps = np.linspace(0, time_end, num_steps + 1)\n",
    "step_coeff = dt / (dx ** 2)\n",
    "\n",
    "if dt <= cfl:\n",
    "    print('stability criteria satisfied')\n",
    "else:\n",
    "    print('stability criteria not satisfied')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial and Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_init = 919.0\n",
    "# Initial temperature and phase fields\n",
    "temperature = np.full(num_points+2, 919.0)            # Initial temperature of the rod with ghost points at both ends\n",
    "phase = np.zeros(num_points+2)*0.0                    # Initial phase of the rod with ghost points at both ends\n",
    "\n",
    "# Set boundary conditions\n",
    "# temperature[-1] = 919.0 \n",
    "phase[-1] = 1.0\n",
    "\n",
    "# temperature[0] = 919.0 #(40 C)\n",
    "phase[0] = 1.0\n",
    "\n",
    "# Store initial state in history\n",
    "temperature_history = [temperature.copy()]    # List to store temperature at each time step\n",
    "phi_history = [phase.copy()]                    # List to store phase at each time step\n",
    "temp_init = temperature.copy()                 # Initial temperature of the rod\n",
    "# print(temperature_history,phi_history)\n",
    "# Array to store temperature at midpoint over time\n",
    "midpoint_index = num_points // 2                          # Index of the midpoint\n",
    "\n",
    "midpoint_temperature_history = [temperature[midpoint_index]]            # List to store temperature at midpoint over time\n",
    "dm = 60.0e-3                                                            # die thickness in m\n",
    "\n",
    "# r_m =  (k_mo / dm) + (1/htc)\n",
    "\n",
    "t_surr = 500.0                                        # Surrounding temperature in K\n",
    "# t_surr = h()\n",
    "\n",
    "def kramp(temp,v1,v2,T_L,T_s):                                      # Function to calculate thermal conductivity in Mushy Zone\n",
    "        slope = (v1-v2)/(T_L-T_S)\n",
    "        if temp > T_L:\n",
    "            k_m = k_l\n",
    "        elif temp < T_S:\n",
    "            k_m = k_s\n",
    "        else:\n",
    "            k_m = k_s + slope*(temp-T_S)\n",
    "        return k_m\n",
    "\n",
    "def cp_ramp(temp,v1,v2,T_L,T_s):                                    # Function to calculate specific heat capacity in Mushy Zone\n",
    "    slope = (v1-v2)/(T_L-T_S)\n",
    "    if temp > T_L:\n",
    "        cp_m = cp_l\n",
    "    elif temp < T_S:\n",
    "        cp_m = cp_s\n",
    "    else:\n",
    "        cp_m = cp_s + slope*(temp-T_S)\n",
    "    return cp_m\n",
    "\n",
    "def rho_ramp(temp,v1,v2,T_L,T_s):                                       # Function to calculate density in Mushy Zone\n",
    "    slope = (v1-v2)/(T_L-T_S)\n",
    "    if temp > T_L:\n",
    "        rho_m = rho_l\n",
    "    elif temp < T_S:\n",
    "        rho_m = rho_s\n",
    "    else:\n",
    "        rho_m = rho_s + slope*(temp-T_S)\n",
    "    return rho_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the HT equation and phase change numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for m in range(1, num_steps+1):                                                                            # time loop\n",
    "    htc = 10.0                   # htc of Still air in W/m^2-K\n",
    "    q1 = htc*(temp_init[0]-t_surr)   # Heat flux at the left boundary\n",
    "    \n",
    "    # print(f\"q1 is {q1}\")\n",
    "    temperature[0] = temp_init[0] + alpha_l * step_coeff * ((2.0*temp_init[1]) - (2.0 * temp_init[0])-(2.0*dx*(q1)))  # Update boundary condition temperature\n",
    "    \n",
    "    q2 = htc*(temp_init[-1]-t_surr)                   # Heat flux at the right boundary\n",
    "    temperature[-1] = temp_init[-1] + alpha_l * step_coeff * ((2.0*temp_init[-2]) - (2.0 * temp_init[-1])-(2.0*dx*(q2)))  # Update boundary condition temperature\n",
    "    \n",
    "    for n in range(1,num_points+1):              # space loop, adjusted range\n",
    "       \n",
    "        if temperature[n] >= T_L:\n",
    "            temperature[n] += ((alpha_l * step_coeff) * (temp_init[n+1] - (2.0 * temp_init[n]) + temp_init[n-1]))\n",
    "            phase[n] = 0\n",
    "            \n",
    "            # print(f\" Time-Step{m},Spatial point{n},Temperature{temperature[n]}\")\n",
    "        elif T_S < temperature[n] < T_L:\n",
    "            \n",
    "            k_m = kramp(temperature[n],k_l,k_s,T_L,T_S)\n",
    "            cp_m = cp_ramp(temperature[n],cp_l,cp_s,T_L,T_S)\n",
    "            rho_m = rho_ramp(temperature[n],rho_l,rho_s,T_L,T_S)\n",
    "            m_eff =(k_m/(rho_m*(cp_m + (L_fusion/(T_L-T_S)))))\n",
    "            \n",
    "            temperature[n] += ((m_eff * step_coeff)* (temp_init[n+1] - (2.0 * temp_init[n]) + temp_init[n-1]))\n",
    "            \n",
    "            phase[n] = (T_L - temperature[n]) / (T_L - T_S)\n",
    "            # print(m,n,temperature[n],phase[n])\n",
    "         \n",
    "        elif temperature[n]<T_S:\n",
    "            temperature[n] += ((alpha_s * step_coeff) * (temp_init[n+1] - (2.0 * temp_init[n])+ temp_init[n-1]))\n",
    "            phase[n] = 1\n",
    "                     \n",
    "        else:\n",
    "            print(\"ERROR: should not be here\")\n",
    "\n",
    "     \n",
    "          \n",
    "    temperature = temperature.copy()                                                                # Update temperature\n",
    "    phase = phase.copy()                                                                            # Update phase\n",
    "    temp_init = temperature.copy()                                                                  # Update last time step temperature\n",
    "    temperature_history.append(temperature.copy())                                                  # Append the temperature history to add ghost points\n",
    "    phi_history.append(phase.copy())                                                                # Append the phase history to add ghost points\n",
    "    midpoint_temperature_history.append(temperature[midpoint_index])                                # Store midpoint temperature\n",
    "    \n",
    "    \n",
    "    # print(f\"Step {m}, Temperature: {temperature}\")\n",
    "    \n",
    "\n",
    "\n",
    "# print(midpoint_temperature_history)\n",
    "#print(phi_history)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot temperature history for debugging\n",
    "# temperature_history_1 = np.array(temperature_history)\n",
    "# print(temperature_history_1.shape)\n",
    "# time_ss= np.linspace(0, time_end, num_steps+1)\n",
    "# # print(time_ss.shape)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(time_ss, midpoint_temperature_history, label='Midpoint Temperature')\n",
    "# plt.axhline(y=T_L, color='r', linestyle='--', label='Liquidus Temperature')\n",
    "# plt.axhline(y=T_S, color='g', linestyle='--', label='Solidus Temperature')\n",
    "# plt.xlabel('Time(s)')\n",
    "# plt.ylabel('Temperature (K)')\n",
    "# plt.title('Temperature Distribution Over Time at x = 7.5mm') \n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data into Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_history = np.array(temperature_history)\n",
    "\n",
    "phi_history = np.array(phi_history)\n",
    "\n",
    "t_hist = np.array(temperature_history[:,1:-1])\n",
    "p_hist = np.array(phi_history[:,1:-1])\n",
    "\n",
    "t_hist_init = t_hist[0,:]\n",
    "t_hist_bc_l = t_hist[:,0]\n",
    "t_hist_bc_r = t_hist[:,-1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have temperature_history and phi_history as lists of arrays\n",
    "\n",
    "\n",
    "# # Check the new shape after transposing\n",
    "# print(\"Transposed Temperature History Shape:\", temperature_history.shape)\n",
    "# print(\"Transposed Phi History Shape:\", phi_history.shape)\n",
    "\n",
    "# # Create a meshgrid for space and time coordinates\n",
    "# space_coord, time_coord = np.meshgrid(np.arange(temperature_history.shape[1]), np.arange(temperature_history.shape[0]))\n",
    "\n",
    "# time_coord = time_coord * dt \n",
    "# # Create a figure with two subplots\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# # Plot the temperature history on the left subplot\n",
    "# im1 = ax1.pcolormesh(space_coord, time_coord, temperature_history, cmap='viridis')\n",
    "# ax1.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=16)\n",
    "# ax1.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "# ax1.set_title('Temperature Variation Over Time',fontname='Times New Roman', fontsize=20)\n",
    "# fig.colorbar(im1, ax=ax1, label='Temperature')\n",
    "\n",
    "# # Plot the phase history on the right subplot\n",
    "# im2 = ax2.pcolormesh(space_coord, time_coord, phi_history, cmap='viridis')\n",
    "# ax2.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=18)\n",
    "# ax2.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "# ax2.set_title('Phase Variation Over Time',fontname='Times New Roman', fontsize=20)\n",
    "# fig.colorbar(im2, ax=ax2, label='Phase')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# #plot the main\n",
    "# fig, ax = plt.subplots(figsize=(14, 6))\n",
    "# im = ax.pcolormesh(space_coord, time_coord, Dim_ny, cmap='viridis')\n",
    "# ax.set_xlabel('Space Coordinate')\n",
    "# ax.set_ylabel('Time')\n",
    "# ax.set_title('Niyama Variation Over Time')\n",
    "# fig.colorbar(im, ax=ax, label='Main')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU/CPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# check for gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (31470,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "space = np.linspace(0, length, num_points) # Spatial points\n",
    "time = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "print(space.shape,time.shape)\n",
    "\n",
    "sp_i = np.linspace(0, length, num_points) # Spatial points\n",
    "time_i = np.zeros(num_points) # Time points\n",
    "\n",
    "sp_b_l = np.zeros(num_steps+1) # Spatial points\n",
    "time_b_l = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "\n",
    "sp_b_r = np.ones(num_steps+1)*length # Spatial points\n",
    "time_b_r = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = input_gen(space,time,'mgrid')\n",
    "inputs_i = input_gen(sp_i,time_i,'scr')\n",
    "inputs_b_l = input_gen(sp_b_l,time_b_l,'scr')\n",
    "inputs_b_r = input_gen(sp_b_r,time_b_r,'scr')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1573500, 2) (50, 2) (31470, 2) (31470, 2)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape,inputs_i.shape,inputs_b_l.shape,inputs_b_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2])\n",
      "torch.Size([1573500, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "inputs = torch.tensor(inputs).float().to(device) # Convert the inputs to a tensor\n",
    "\n",
    "\n",
    "inputs_init = torch.tensor(inputs_i).float().to(device) # Convert the inputs to a tensor\n",
    "inputs_b_l = torch.tensor(inputs_b_l).float().to(device) # Convert the inputs to a tensor\n",
    "inputs_b_r = torch.tensor(inputs_b_r).float().to(device) # Convert the inputs to a tensor\n",
    "\n",
    "print(inputs_init.shape)\n",
    "# label/temp data\n",
    "temp_tr = torch.tensor(t_hist).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp = temp_tr.reshape(-1,1) # Reshape the temperature tensor to a column vector\n",
    "temp_inp_init = torch.tensor(t_hist_init).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp_bc_l = torch.tensor(t_hist_bc_l).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp_bc_r = torch.tensor(t_hist_bc_r).float().to(device) # Convert the temperature history to a tensor\n",
    "print(temp_inp.shape)\n",
    "\n",
    "\n",
    "\n",
    "#Data Splitting\n",
    "\n",
    "# train_inputs, val_test_inputs, train_temp_inp, val_test_temp_inp = train_test_split(inputs, temp_inp, test_size=0.2, random_state=42)\n",
    "# val_inputs, test_inputs, val_temp_inp, test_temp_inp = train_test_split(val_test_inputs, val_test_temp_inp, test_size=0.8, random_state=42)\n",
    "\n",
    "train_inputs, test_inputs, train_temp_inp, test_temp_inp = train_test_split(inputs, temp_inp, test_size=0.2, random_state=42)\n",
    "train_inputs_init, test_inputs_init, train_temp_inp_init, test_temp_inp_init = train_test_split(inputs_init, temp_inp_init, test_size=0.2, random_state=42)\n",
    "train_inputs_bc_l, test_inputs_bc_l, train_temp_inp_bc_l, test_temp_inp_bc_l = train_test_split(inputs_b_l, temp_inp_bc_l, test_size=0.2, random_state=42)\n",
    "train_inputs_bc_r, test_inputs_bc_r, train_temp_inp_bc_r, test_temp_inp_bc_r = train_test_split(inputs_b_r, temp_inp_bc_r, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, temp_inp,transform=None, target_transform =None):\n",
    "        self.inputs = inputs\n",
    "        self.temp_inp = temp_inp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.temp_inp[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "  \n",
    "train_dataset = TensorDataset(train_inputs, train_temp_inp) # Create the training dataset\n",
    "# val_dataset = TensorDataset(val_inputs, val_temp_inp) # Create the validation dataset\n",
    "test_dataset = TensorDataset(test_inputs, test_temp_inp) # Create the test dataset\n",
    "\n",
    "train_dataset_init = TensorDataset(train_inputs_init, train_temp_inp_init) # Create the training dataset\n",
    "test_dataset_init = TensorDataset(test_inputs_init, test_temp_inp_init) # Create the test dataset\n",
    "train_dataset_bc_l = TensorDataset(train_inputs_bc_l, train_temp_inp_bc_l) # Create the training dataset\n",
    "test_dataset_bc_l = TensorDataset(test_inputs_bc_l, test_temp_inp_bc_l) # Create the test dataset\n",
    "train_dataset_bc_r = TensorDataset(train_inputs_bc_r, train_temp_inp_bc_r) # Create the training dataset\n",
    "test_dataset_bc_r = TensorDataset(test_inputs_bc_r, test_temp_inp_bc_r) # Create the test dataset\n",
    "\n",
    "\n",
    "batch_size =512\n",
    "\n",
    "random_sampler_train = RandomSampler(train_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "# random_sampler_val = RandomSampler(val_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the validation dataset\n",
    "random_sampler_test = RandomSampler(test_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "\n",
    "random_sampler_train_init = RandomSampler(train_dataset_init, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_init = RandomSampler(test_dataset_init, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "random_sampler_train_bc_l = RandomSampler(train_dataset_bc_l, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_bc_l = RandomSampler(test_dataset_bc_l, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "random_sampler_train_bc_r = RandomSampler(train_dataset_bc_r, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_bc_r = RandomSampler(test_dataset_bc_r, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=random_sampler_train) # Create the training dataloader\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=random_sampler_val) # Create the validation dataloader\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, sampler=random_sampler_test) # Create the test dataloader\n",
    "\n",
    "train_loader_init = DataLoader(train_dataset_init, batch_size=batch_size, sampler=random_sampler_train_init) # Create the training dataloader\n",
    "test_loader_init = DataLoader(test_dataset_init, batch_size=batch_size, sampler=random_sampler_test_init) # Create the test dataloader\n",
    "train_loader_bc_l = DataLoader(train_dataset_bc_l, batch_size=batch_size, sampler=random_sampler_train_bc_l) # Create the training dataloader\n",
    "test_loader_bc_l = DataLoader(test_dataset_bc_l, batch_size=batch_size, sampler=random_sampler_test_bc_l) # Create the test dataloader\n",
    "train_loader_bc_r = DataLoader(train_dataset_bc_r, batch_size=batch_size, sampler=random_sampler_train_bc_r) # Create the training dataloader\n",
    "test_loader_bc_r = DataLoader(test_dataset_bc_r, batch_size=batch_size, sampler=random_sampler_test_bc_r) # Create the test dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the neural network architecture\n",
    "class Mushydata(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size): # This is the constructor\n",
    "        super(Mushydata, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t):                               # This is the forward pass\n",
    "        input_features = torch.cat([x, t], dim=1)          # Concatenate the input features\n",
    "        m = self.base(input_features)                                 # Pass through the third layer\n",
    "        return m                    # Return the output of the network\n",
    "\n",
    "\n",
    "# features = torch.rand(1, 2)\n",
    "# model = HeatPINN(2, 20, 1)\n",
    "# output = model(features[:, 0:1], features[:, 1:2])\n",
    "# print(output)\n",
    "\n",
    "\n",
    "# Loss function for data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamters Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 35\n",
    "learning_rate = 0.009\n",
    "epochs = 50000\n",
    "# alpha = 0.01  # Adjust this value based on your problem\n",
    "# boundary_value = 313.0\n",
    "# initial_value = init_temp\n",
    "# Initialize the model\n",
    "model = Mushydata(input_size=2, hidden_size=hidden_size,output_size=1).to(device)\n",
    "lambd = 0.1\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss List Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of train_loader is <class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(f\"Datatype of train_loader is {type(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_fn_data(u_pred, u_true):\n",
    "#     return nn.MSELoss()(u_pred, u_true)\n",
    "\n",
    "# def l1_regularization(model, lambd):\n",
    "#     l1_reg = sum(param.abs().sum() for param in model.parameters())\n",
    "#     return l1_reg * lambd\n",
    "\n",
    "# def pde_loss(u_pred,x,t):\n",
    "#     # u_pred.requires_grad = True\n",
    "#     x.requires_grad = True\n",
    "#     t.requires_grad = True\n",
    "    \n",
    "#     u_pred = model(x,t).requires_grad_()\n",
    "#     u_t = torch.autograd.grad(u_pred, t, \n",
    "#                                 torch.ones_like(u_pred).to(device),\n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused=True,\n",
    "#                                 )[0] # Calculate the first time derivative\n",
    "#     if u_t is None:\n",
    "#         raise RuntimeError(\"u_t is None\")\n",
    "\n",
    "#     u_x = torch.autograd.grad(u_pred, \n",
    "#                                 x, \n",
    "#                                 torch.ones_like(u_pred).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused =True)[0] # Calculate the first space derivative\n",
    "            \n",
    "#     u_xx = torch.autograd.grad(u_x, \n",
    "#                                 x, \n",
    "#                                 torch.ones_like(u_x).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused=True)[0] \n",
    "    \n",
    "#     T_S_tensor = torch.tensor(T_S, device=device)\n",
    "#     T_L_tensor = torch.tensor(T_L, device=device)\n",
    "    \n",
    "#     k_m = torch.where((u_pred >= T_S_tensor) * (u_pred <= T_L_tensor),\\\n",
    "#                        kramp(u_pred, k_l,k_s,T_L,T_S),torch.tensor(0.0,device=device))\n",
    "#     cp_m = torch.where(u_pred >= T_S_tensor * u_pred <= T_L_tensor, cp_ramp((u_pred), cp_l,cp_s,T_L,T_S))\n",
    "#     rho_m = torch.where(u_pred >= T_S_tensor * u_pred <= T_L_tensor, rho_ramp((u_pred), rho_l,rho_s,T_L,T_S))\n",
    "#     m_eff = (k_m / (rho_m * (cp_m + (L_fusion / (T_L - T_S)))))\n",
    "\n",
    "#     alpha_T = torch.where(u_pred >= T_L_tensor, alpha_l, torch.where(u_pred<=T_S_tensor,alpha_s ,m_eff))\n",
    "#     alpha_T = 1\n",
    "#     residual = u_t - alpha_T * u_xx\n",
    "\n",
    "#     return nn.MSELoss()(residual,torch.zeros_like(residual))\n",
    "\n",
    "# def boundary_loss(u_pred,x,t,t_surr):\n",
    "    \n",
    "#     u_x = torch.autograd.grad(u_pred,x, \n",
    "#                                 torch.ones_like(u_pred).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused =True)[0] # Calculate the first space derivative\n",
    "#     t_surr_t = torch.tensor(t_surr, device=device)\n",
    "#     res_l = u_x -(htc* (u_pred-t_surr_t))\n",
    "   \n",
    "\n",
    "#     return nn.MSELoss()(res_l,torch.zeros_like(res_l))\n",
    "\n",
    "# def ic_loss(u_pred):\n",
    "#     temp_init_tsr = torch.tensor(temp_init[1:-1],device=device)\n",
    "#     ic = u_pred -temp_init_tsr\n",
    "#     return nn.MSELoss()(ic,torch.zeros_like(ic))\n",
    "\n",
    "def accuracy(u_pred, u_true):\n",
    "    return torch.mean(torch.abs(u_pred - u_true) / u_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation and Testing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, model, loss_fn_data, optimizer, train_dataloader,):\n",
    "    train_losses = []  # Initialize the list to store the training losses\n",
    "    val_losses = []    # Initialize the list to store the validation losses\n",
    "    test_losses =[] \n",
    "    for epoch in range(epochs):\n",
    "        model.train()                                                                           # Set the model to training mode\n",
    "        train_loss = 0                                                                              # Initialize the training loss\n",
    "        train_accuracy = 0\n",
    "        for (batch,batch_init,batch_left,batch_right) in \\\n",
    "             zip (train_dataloader,train_loader_init,train_loader_bc_l,train_inputs_bc_r):                                                          # Loop through the training dataloader\n",
    "            inputs, temp_inp= batch                                                             # Get the inputs and the true values\n",
    "            inputs_init, temp_inp_init= batch_init                                                             # Get the inputs and the true values \n",
    "            inputs_left, temp_inp_left= batch_left                                                             # Get the inputs and the true values\n",
    "            inputs_right, temp_inp_right= batch_right                                                             # Get the inputs and the true values\n",
    "\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)                             # Move the inputs and true values to the GPU\n",
    "            inputs_init, temp_inp_init= inputs_init.to(device), temp_inp_init.to(device)                             # Move the initial condition inputs and temperature to the GPU\n",
    "            inputs_left, temp_inp_left= inputs_left.to(device), temp_inp_left.to(device)                             # Move the left boundary condition inputs and temperature values to the GPU\n",
    "            inputs_right, temp_inp_right= inputs_right.to(device), temp_inp_right.to(device)                             # Move the right boundary condition inputs and temperature values to the GPU\n",
    "\n",
    "            optimizer.zero_grad()                                                                    # Zero the gradients\n",
    "            \n",
    "            # Forward pass\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).to(device)                       # Get the predictions\n",
    "            u_initl = model(inputs_init[:,0].unsqueeze(1), inputs_init[:,1].unsqueeze(1)).to(device)                       # Get the predictions\n",
    "            \n",
    "            u_left = model(inputs_b_l[:,0].unsqueeze(1), inputs_b_l[:,1].unsqueeze(1)).to(device)               # Left boundary of the temperature\n",
    "            u_right = model(inputs_b_r[:,0].unsqueeze(1), inputs_b_r[:,1].unsqueeze(1)).to(device)             # Right boundary of the temperature\n",
    "\n",
    "            # Loss calculation\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp)                                              # Calculate the data loss\n",
    "            \n",
    "            pd_loss = pde_loss(model,inputs[:,0].unsqueeze(1),inputs[:,1].unsqueeze(1))             # Calculate the PDE loss\n",
    "            # pd_loss = 0\n",
    "            \n",
    "            initc_loss = ic_loss(u_initl) \n",
    "            # initc_loss =0                                                      # Calculate initial condition loss\n",
    "            \n",
    "            bc_loss_left = boundary_loss(model,inputs_b_l[:,0].unsqueeze(1),inputs_b_l[:,1].unsqueeze(1),t_surr) # Calculate the left boundary condition loss\n",
    "            bc_loss_right = boundary_loss(model,inputs_b_r[:,0].unsqueeze(1),inputs_b_r[:,1].unsqueeze(1),t_surr) # Calculate the right boundary condition loss\n",
    "            bc_loss = bc_loss_left + bc_loss_right\n",
    "            # l1_regularization_loss = l1_regularization(model, lambda_l1)                      # Calculate the L1 regularization loss\n",
    "            # loss = data_loss  + pd_loss + initc_loss + bc_loss                                              # Calculate the total loss\n",
    "            w1 = 0.0001\n",
    "            w2 = 0.0001\n",
    "            w3 = 0.0001\n",
    "            loss = data_loss + w1* pd_loss + w2 *initc_loss + w3* bc_loss\n",
    "            train_accuracy += accuracy(u_pred, temp_inp)                                                              # Calculate the total loss\n",
    "            # Backpropagation\n",
    "            loss.backward(retain_graph=True)                                                        # Backpropagate the gradients\n",
    "            \n",
    "            optimizer.step()                                                                           # Update the weights\n",
    "            \n",
    "            train_loss += loss.item()                                                           # Add the loss to the training set loss                 \n",
    "\n",
    "        \n",
    "\n",
    "        # model.eval()\n",
    "        # test_loss = 0\n",
    "        # test_accuracy = 0\n",
    "        # with torch.no_grad():   \n",
    "        #     for batch in test_dataloader:\n",
    "        #         inputs, temp_inp= batch\n",
    "        #         inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "        #         u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "        #         data_loss = loss_fn_data(u_pred, temp_inp)\n",
    "        #         # l1_regularization_loss = l1_regularization(model, lambd)\n",
    "        #         # loss = data_loss  + l1_regularization_loss\n",
    "        #         loss = data_loss\n",
    "        #         test_accuracy = accuracy(u_pred, temp_inp)\n",
    "        #         test_loss += loss.item()\n",
    "        #     test_losses.append(test_loss)\n",
    "\n",
    "        train_losses.append(train_loss)                                                   # Append the training loss to the list of training losses\n",
    "        \n",
    "        # if epoch % 10 == 0:\n",
    "        #     print(f\"Epoch {epoch}, Training-Loss {train_loss:.4e}\")\n",
    "        \n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Training-Loss {train_loss:.4e}, Data-loss {data_loss:.4e}\\\n",
    "                  , pde-loss {pd_loss:.4e}, initc-loss {initc_loss:.4e}\\\n",
    "                    bc_loss {bc_loss:.4e}\") \n",
    "\n",
    "    return train_losses, val_losses                                                             # Return the training and validation losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(epochs, model, loss_fn_data, optimizer, train_dataloader, test_dataloader):\n",
    "      \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    with torch.no_grad():   \n",
    "        for batch in test_dataloader:\n",
    "            inputs, temp_inp= batch\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp)\n",
    "            # l1_regularization_loss = l1_regularization(model, lambd)\n",
    "            # loss = data_loss  + l1_regularization_loss\n",
    "            loss = data_loss\n",
    "            test_accuracy = accuracy(u_pred, temp_inp)\n",
    "            test_loss += loss.item()\n",
    "        test_losses.append(test_loss)\n",
    "    if epochs % 10 == 0:\n",
    "        print(f\"Epoch {epochs}, Test-Loss {test_loss:.4e}, Test-Accuracy {test_accuracy:.4e}\")      \n",
    "    return test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Button "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training-Loss 6.6097e+05, Data-loss 6.5588e+05                  , pde-loss 2.0731e-06, initc-loss 8.4498e+05                    bc_loss 5.0046e+07\n",
      "Epoch 10, Training-Loss 6.5111e+05, Data-loss 6.4608e+05                  , pde-loss 6.9239e-07, initc-loss 8.3952e+05                    bc_loss 4.9452e+07\n",
      "Epoch 20, Training-Loss 6.5064e+05, Data-loss 6.4565e+05                  , pde-loss 1.8079e-07, initc-loss 8.3511e+05                    bc_loss 4.8974e+07\n",
      "Epoch 30, Training-Loss 6.4490e+05, Data-loss 6.3997e+05                  , pde-loss 6.6576e-08, initc-loss 8.3069e+05                    bc_loss 4.8496e+07\n",
      "Epoch 40, Training-Loss 6.4834e+05, Data-loss 6.4346e+05                  , pde-loss 4.6810e-08, initc-loss 8.2585e+05                    bc_loss 4.7973e+07\n",
      "Epoch 50, Training-Loss 6.4350e+05, Data-loss 6.3867e+05                  , pde-loss 1.9938e-09, initc-loss 8.2098e+05                    bc_loss 4.7449e+07\n",
      "Epoch 60, Training-Loss 6.3638e+05, Data-loss 6.3161e+05                  , pde-loss 3.3744e-11, initc-loss 8.1624e+05                    bc_loss 4.6941e+07\n",
      "Epoch 70, Training-Loss 6.2899e+05, Data-loss 6.2426e+05                  , pde-loss 1.5346e-09, initc-loss 8.1132e+05                    bc_loss 4.6413e+07\n",
      "Epoch 80, Training-Loss 6.2789e+05, Data-loss 6.2323e+05                  , pde-loss 1.3811e-09, initc-loss 8.0613e+05                    bc_loss 4.5859e+07\n",
      "Epoch 90, Training-Loss 6.2076e+05, Data-loss 6.1615e+05                  , pde-loss 3.0619e-09, initc-loss 8.0096e+05                    bc_loss 4.5308e+07\n",
      "Epoch 100, Training-Loss 6.1610e+05, Data-loss 6.1155e+05                  , pde-loss 9.9945e-10, initc-loss 7.9518e+05                    bc_loss 4.4695e+07\n",
      "Epoch 110, Training-Loss 6.0657e+05, Data-loss 6.0208e+05                  , pde-loss 2.9048e-10, initc-loss 7.8962e+05                    bc_loss 4.4105e+07\n",
      "Epoch 120, Training-Loss 6.0818e+05, Data-loss 6.0375e+05                  , pde-loss 1.9235e-10, initc-loss 7.8417e+05                    bc_loss 4.3531e+07\n",
      "Epoch 130, Training-Loss 6.0254e+05, Data-loss 5.9817e+05                  , pde-loss 1.1297e-10, initc-loss 7.7885e+05                    bc_loss 4.2972e+07\n",
      "Epoch 140, Training-Loss 5.9789e+05, Data-loss 5.9357e+05                  , pde-loss 1.7688e-11, initc-loss 7.7360e+05                    bc_loss 4.2420e+07\n",
      "Epoch 150, Training-Loss 5.9374e+05, Data-loss 5.8947e+05                  , pde-loss 2.8335e-10, initc-loss 7.6802e+05                    bc_loss 4.1837e+07\n",
      "Epoch 160, Training-Loss 5.8582e+05, Data-loss 5.8162e+05                  , pde-loss 1.7090e-10, initc-loss 7.6258e+05                    bc_loss 4.1270e+07\n",
      "Epoch 170, Training-Loss 5.8165e+05, Data-loss 5.7750e+05                  , pde-loss 1.2184e-10, initc-loss 7.5724e+05                    bc_loss 4.0715e+07\n",
      "Epoch 180, Training-Loss 5.7799e+05, Data-loss 5.7390e+05                  , pde-loss 7.1063e-11, initc-loss 7.5199e+05                    bc_loss 4.0172e+07\n",
      "Epoch 190, Training-Loss 5.7120e+05, Data-loss 5.6716e+05                  , pde-loss 1.4387e-09, initc-loss 7.4658e+05                    bc_loss 3.9613e+07\n",
      "Epoch 200, Training-Loss 5.7070e+05, Data-loss 5.6672e+05                  , pde-loss 8.0341e-11, initc-loss 7.4103e+05                    bc_loss 3.9043e+07\n",
      "Epoch 210, Training-Loss 5.6016e+05, Data-loss 5.5624e+05                  , pde-loss 4.2030e-11, initc-loss 7.3557e+05                    bc_loss 3.8483e+07\n",
      "Epoch 220, Training-Loss 5.5861e+05, Data-loss 5.5474e+05                  , pde-loss 7.0228e-12, initc-loss 7.3017e+05                    bc_loss 3.7932e+07\n",
      "Epoch 230, Training-Loss 5.5276e+05, Data-loss 5.4895e+05                  , pde-loss 6.1716e-11, initc-loss 7.2440e+05                    bc_loss 3.7345e+07\n",
      "Epoch 240, Training-Loss 5.4845e+05, Data-loss 5.4470e+05                  , pde-loss 5.4275e-12, initc-loss 7.1874e+05                    bc_loss 3.6772e+07\n",
      "Epoch 250, Training-Loss 5.4566e+05, Data-loss 5.4198e+05                  , pde-loss 5.0739e-10, initc-loss 7.1264e+05                    bc_loss 3.6156e+07\n",
      "Epoch 260, Training-Loss 5.3899e+05, Data-loss 5.3537e+05                  , pde-loss 4.1408e-11, initc-loss 7.0620e+05                    bc_loss 3.5508e+07\n",
      "Epoch 270, Training-Loss 5.3085e+05, Data-loss 5.2729e+05                  , pde-loss 1.1588e-09, initc-loss 6.9977e+05                    bc_loss 3.4865e+07\n",
      "Epoch 280, Training-Loss 5.2585e+05, Data-loss 5.2236e+05                  , pde-loss 5.4023e-11, initc-loss 6.9315e+05                    bc_loss 3.4205e+07\n",
      "Epoch 290, Training-Loss 5.2049e+05, Data-loss 5.1707e+05                  , pde-loss 4.2128e-11, initc-loss 6.8675e+05                    bc_loss 3.3571e+07\n",
      "Epoch 300, Training-Loss 5.1038e+05, Data-loss 5.0702e+05                  , pde-loss 4.1699e-11, initc-loss 6.8054e+05                    bc_loss 3.2958e+07\n",
      "Epoch 310, Training-Loss 5.1020e+05, Data-loss 5.0689e+05                  , pde-loss 3.5021e-11, initc-loss 6.7450e+05                    bc_loss 3.2365e+07\n",
      "Epoch 320, Training-Loss 5.0838e+05, Data-loss 5.0513e+05                  , pde-loss 3.0530e-11, initc-loss 6.6860e+05                    bc_loss 3.1789e+07\n",
      "Epoch 330, Training-Loss 5.0181e+05, Data-loss 4.9862e+05                  , pde-loss 2.8432e-11, initc-loss 6.6281e+05                    bc_loss 3.1226e+07\n",
      "Epoch 340, Training-Loss 4.9555e+05, Data-loss 4.9242e+05                  , pde-loss 3.0311e-11, initc-loss 6.5713e+05                    bc_loss 3.0676e+07\n",
      "Epoch 350, Training-Loss 4.9078e+05, Data-loss 4.8770e+05                  , pde-loss 3.3479e-11, initc-loss 6.5154e+05                    bc_loss 3.0137e+07\n",
      "Epoch 360, Training-Loss 4.8694e+05, Data-loss 4.8391e+05                  , pde-loss 3.0949e-11, initc-loss 6.4604e+05                    bc_loss 2.9609e+07\n",
      "Epoch 370, Training-Loss 4.8169e+05, Data-loss 4.7872e+05                  , pde-loss 2.4999e-11, initc-loss 6.4061e+05                    bc_loss 2.9091e+07\n",
      "Epoch 380, Training-Loss 4.7913e+05, Data-loss 4.7621e+05                  , pde-loss 2.6019e-11, initc-loss 6.3526e+05                    bc_loss 2.8581e+07\n",
      "Epoch 390, Training-Loss 4.7109e+05, Data-loss 4.6822e+05                  , pde-loss 2.4830e-11, initc-loss 6.2997e+05                    bc_loss 2.8081e+07\n",
      "Epoch 400, Training-Loss 4.6475e+05, Data-loss 4.6193e+05                  , pde-loss 2.2844e-11, initc-loss 6.2473e+05                    bc_loss 2.7588e+07\n",
      "Epoch 410, Training-Loss 4.6442e+05, Data-loss 4.6164e+05                  , pde-loss 2.0415e-11, initc-loss 6.1956e+05                    bc_loss 2.7103e+07\n",
      "Epoch 420, Training-Loss 4.6278e+05, Data-loss 4.6005e+05                  , pde-loss 1.7849e-11, initc-loss 6.1444e+05                    bc_loss 2.6625e+07\n",
      "Epoch 430, Training-Loss 4.5385e+05, Data-loss 4.5117e+05                  , pde-loss 1.7855e-11, initc-loss 6.0937e+05                    bc_loss 2.6154e+07\n",
      "Epoch 440, Training-Loss 4.5070e+05, Data-loss 4.4807e+05                  , pde-loss 1.7213e-11, initc-loss 6.0435e+05                    bc_loss 2.5690e+07\n",
      "Epoch 450, Training-Loss 4.4395e+05, Data-loss 4.4136e+05                  , pde-loss 1.6436e-11, initc-loss 5.9938e+05                    bc_loss 2.5233e+07\n",
      "Epoch 460, Training-Loss 4.3882e+05, Data-loss 4.3628e+05                  , pde-loss 1.5515e-11, initc-loss 5.9446e+05                    bc_loss 2.4783e+07\n",
      "Epoch 470, Training-Loss 4.3762e+05, Data-loss 4.3513e+05                  , pde-loss 1.5187e-11, initc-loss 5.8959e+05                    bc_loss 2.4339e+07\n",
      "Epoch 480, Training-Loss 4.2905e+05, Data-loss 4.2661e+05                  , pde-loss 1.4388e-11, initc-loss 5.8475e+05                    bc_loss 2.3900e+07\n",
      "Epoch 490, Training-Loss 4.3045e+05, Data-loss 4.2804e+05                  , pde-loss 1.2671e-11, initc-loss 5.7996e+05                    bc_loss 2.3468e+07\n",
      "Epoch 500, Training-Loss 4.2631e+05, Data-loss 4.2395e+05                  , pde-loss 1.2821e-11, initc-loss 5.7521e+05                    bc_loss 2.3042e+07\n",
      "Epoch 510, Training-Loss 4.1657e+05, Data-loss 4.1425e+05                  , pde-loss 1.2962e-11, initc-loss 5.7050e+05                    bc_loss 2.2621e+07\n",
      "Epoch 520, Training-Loss 4.1260e+05, Data-loss 4.1033e+05                  , pde-loss 1.1494e-11, initc-loss 5.6582e+05                    bc_loss 2.2206e+07\n",
      "Epoch 530, Training-Loss 4.1370e+05, Data-loss 4.1147e+05                  , pde-loss 1.0975e-11, initc-loss 5.6119e+05                    bc_loss 2.1797e+07\n",
      "Epoch 540, Training-Loss 4.1289e+05, Data-loss 4.1069e+05                  , pde-loss 9.7496e-12, initc-loss 5.5660e+05                    bc_loss 2.1393e+07\n",
      "Epoch 550, Training-Loss 3.9947e+05, Data-loss 3.9731e+05                  , pde-loss 1.0686e-11, initc-loss 5.5204e+05                    bc_loss 2.0994e+07\n",
      "Epoch 560, Training-Loss 3.9366e+05, Data-loss 3.9154e+05                  , pde-loss 1.0318e-11, initc-loss 5.4752e+05                    bc_loss 2.0601e+07\n",
      "Epoch 570, Training-Loss 3.9959e+05, Data-loss 3.9752e+05                  , pde-loss 7.8014e-12, initc-loss 5.4303e+05                    bc_loss 2.0213e+07\n",
      "Epoch 580, Training-Loss 3.8831e+05, Data-loss 3.8627e+05                  , pde-loss 9.3715e-12, initc-loss 5.3857e+05                    bc_loss 1.9829e+07\n",
      "Epoch 590, Training-Loss 3.9052e+05, Data-loss 3.8853e+05                  , pde-loss 8.2814e-12, initc-loss 5.3415e+05                    bc_loss 1.9451e+07\n",
      "Epoch 600, Training-Loss 3.8677e+05, Data-loss 3.8481e+05                  , pde-loss 8.0999e-12, initc-loss 5.2977e+05                    bc_loss 1.9078e+07\n",
      "Epoch 610, Training-Loss 3.7969e+05, Data-loss 3.7777e+05                  , pde-loss 7.3405e-12, initc-loss 5.2541e+05                    bc_loss 1.8709e+07\n",
      "Epoch 620, Training-Loss 3.8059e+05, Data-loss 3.7870e+05                  , pde-loss 7.6758e-12, initc-loss 5.2109e+05                    bc_loss 1.8345e+07\n",
      "Epoch 630, Training-Loss 3.7417e+05, Data-loss 3.7232e+05                  , pde-loss 7.8731e-12, initc-loss 5.1680e+05                    bc_loss 1.7986e+07\n",
      "Epoch 640, Training-Loss 3.7278e+05, Data-loss 3.7096e+05                  , pde-loss 6.5046e-12, initc-loss 5.1254e+05                    bc_loss 1.7632e+07\n",
      "Epoch 650, Training-Loss 3.6629e+05, Data-loss 3.6451e+05                  , pde-loss 7.3485e-12, initc-loss 5.0831e+05                    bc_loss 1.7283e+07\n",
      "Epoch 660, Training-Loss 3.6565e+05, Data-loss 3.6391e+05                  , pde-loss 6.4059e-12, initc-loss 5.0412e+05                    bc_loss 1.6938e+07\n",
      "Epoch 670, Training-Loss 3.5975e+05, Data-loss 3.5804e+05                  , pde-loss 6.1203e-12, initc-loss 4.9995e+05                    bc_loss 1.6597e+07\n",
      "Epoch 680, Training-Loss 3.5613e+05, Data-loss 3.5445e+05                  , pde-loss 6.0662e-12, initc-loss 4.9582e+05                    bc_loss 1.6262e+07\n",
      "Epoch 690, Training-Loss 3.5217e+05, Data-loss 3.5053e+05                  , pde-loss 6.0974e-12, initc-loss 4.9172e+05                    bc_loss 1.5930e+07\n",
      "Epoch 700, Training-Loss 3.5143e+05, Data-loss 3.4982e+05                  , pde-loss 5.8041e-12, initc-loss 4.8764e+05                    bc_loss 1.5603e+07\n",
      "Epoch 710, Training-Loss 3.4225e+05, Data-loss 3.4067e+05                  , pde-loss 6.4219e-12, initc-loss 4.8360e+05                    bc_loss 1.5281e+07\n",
      "Epoch 720, Training-Loss 3.3943e+05, Data-loss 3.3789e+05                  , pde-loss 5.7639e-12, initc-loss 4.7959e+05                    bc_loss 1.4963e+07\n",
      "Epoch 730, Training-Loss 3.3589e+05, Data-loss 3.3437e+05                  , pde-loss 5.4836e-12, initc-loss 4.7561e+05                    bc_loss 1.4650e+07\n",
      "Epoch 740, Training-Loss 3.3211e+05, Data-loss 3.3063e+05                  , pde-loss 5.4032e-12, initc-loss 4.7165e+05                    bc_loss 1.4340e+07\n",
      "Epoch 750, Training-Loss 3.3220e+05, Data-loss 3.3075e+05                  , pde-loss 5.1258e-12, initc-loss 4.6772e+05                    bc_loss 1.4035e+07\n",
      "Epoch 760, Training-Loss 3.2753e+05, Data-loss 3.2611e+05                  , pde-loss 5.0240e-12, initc-loss 4.6382e+05                    bc_loss 1.3733e+07\n",
      "Epoch 770, Training-Loss 3.2562e+05, Data-loss 3.2423e+05                  , pde-loss 4.8563e-12, initc-loss 4.5995e+05                    bc_loss 1.3436e+07\n",
      "Epoch 780, Training-Loss 3.2282e+05, Data-loss 3.2146e+05                  , pde-loss 4.8389e-12, initc-loss 4.5610e+05                    bc_loss 1.3144e+07\n",
      "Epoch 790, Training-Loss 3.1774e+05, Data-loss 3.1641e+05                  , pde-loss 4.7608e-12, initc-loss 4.5228e+05                    bc_loss 1.2855e+07\n",
      "Epoch 800, Training-Loss 3.1623e+05, Data-loss 3.1493e+05                  , pde-loss 4.1842e-12, initc-loss 4.4849e+05                    bc_loss 1.2570e+07\n",
      "Epoch 810, Training-Loss 3.1066e+05, Data-loss 3.0939e+05                  , pde-loss 4.4640e-12, initc-loss 4.4473e+05                    bc_loss 1.2289e+07\n",
      "Epoch 820, Training-Loss 3.0875e+05, Data-loss 3.0750e+05                  , pde-loss 4.0074e-12, initc-loss 4.4099e+05                    bc_loss 1.2012e+07\n",
      "Epoch 830, Training-Loss 3.0732e+05, Data-loss 3.0610e+05                  , pde-loss 4.0355e-12, initc-loss 4.3728e+05                    bc_loss 1.1739e+07\n",
      "Epoch 840, Training-Loss 3.0233e+05, Data-loss 3.0114e+05                  , pde-loss 3.9303e-12, initc-loss 4.3360e+05                    bc_loss 1.1470e+07\n",
      "Epoch 850, Training-Loss 3.0138e+05, Data-loss 3.0022e+05                  , pde-loss 3.8964e-12, initc-loss 4.2994e+05                    bc_loss 1.1205e+07\n",
      "Epoch 860, Training-Loss 2.9764e+05, Data-loss 2.9650e+05                  , pde-loss 3.4335e-12, initc-loss 4.2631e+05                    bc_loss 1.0944e+07\n",
      "Epoch 870, Training-Loss 2.9134e+05, Data-loss 2.9023e+05                  , pde-loss 3.6248e-12, initc-loss 4.2270e+05                    bc_loss 1.0687e+07\n",
      "Epoch 880, Training-Loss 2.8911e+05, Data-loss 2.8802e+05                  , pde-loss 3.7821e-12, initc-loss 4.1912e+05                    bc_loss 1.0433e+07\n",
      "Epoch 890, Training-Loss 2.8760e+05, Data-loss 2.8654e+05                  , pde-loss 3.5089e-12, initc-loss 4.1557e+05                    bc_loss 1.0183e+07\n",
      "Epoch 900, Training-Loss 2.8458e+05, Data-loss 2.8355e+05                  , pde-loss 3.4103e-12, initc-loss 4.1204e+05                    bc_loss 9.9372e+06\n",
      "Epoch 910, Training-Loss 2.8293e+05, Data-loss 2.8192e+05                  , pde-loss 2.8572e-12, initc-loss 4.0854e+05                    bc_loss 9.6950e+06\n",
      "Epoch 920, Training-Loss 2.8062e+05, Data-loss 2.7964e+05                  , pde-loss 2.8551e-12, initc-loss 4.0506e+05                    bc_loss 9.4563e+06\n",
      "Epoch 930, Training-Loss 2.7781e+05, Data-loss 2.7685e+05                  , pde-loss 2.8962e-12, initc-loss 4.0160e+05                    bc_loss 9.2210e+06\n",
      "Epoch 940, Training-Loss 2.7429e+05, Data-loss 2.7335e+05                  , pde-loss 2.8552e-12, initc-loss 3.9817e+05                    bc_loss 8.9892e+06\n",
      "Epoch 950, Training-Loss 2.7699e+05, Data-loss 2.7607e+05                  , pde-loss 2.5686e-12, initc-loss 3.9476e+05                    bc_loss 8.7609e+06\n",
      "Epoch 960, Training-Loss 2.6655e+05, Data-loss 2.6566e+05                  , pde-loss 2.7999e-12, initc-loss 3.9137e+05                    bc_loss 8.5362e+06\n",
      "Epoch 970, Training-Loss 2.6224e+05, Data-loss 2.6137e+05                  , pde-loss 2.8962e-12, initc-loss 3.8800e+05                    bc_loss 8.3150e+06\n",
      "Epoch 980, Training-Loss 2.6458e+05, Data-loss 2.6373e+05                  , pde-loss 2.4059e-12, initc-loss 3.8467e+05                    bc_loss 8.0974e+06\n",
      "Epoch 990, Training-Loss 2.6405e+05, Data-loss 2.6322e+05                  , pde-loss 2.4757e-12, initc-loss 3.8135e+05                    bc_loss 7.8834e+06\n",
      "Epoch 1000, Training-Loss 2.6004e+05, Data-loss 2.5924e+05                  , pde-loss 2.6142e-12, initc-loss 3.7806e+05                    bc_loss 7.6727e+06\n",
      "Epoch 1010, Training-Loss 2.5433e+05, Data-loss 2.5355e+05                  , pde-loss 2.4381e-12, initc-loss 3.7479e+05                    bc_loss 7.4654e+06\n",
      "Epoch 1020, Training-Loss 2.5187e+05, Data-loss 2.5110e+05                  , pde-loss 2.4344e-12, initc-loss 3.7155e+05                    bc_loss 7.2619e+06\n",
      "Epoch 1030, Training-Loss 2.5039e+05, Data-loss 2.4965e+05                  , pde-loss 2.2405e-12, initc-loss 3.6834e+05                    bc_loss 7.0618e+06\n",
      "Epoch 1040, Training-Loss 2.4863e+05, Data-loss 2.4791e+05                  , pde-loss 2.2336e-12, initc-loss 3.6514e+05                    bc_loss 6.8648e+06\n",
      "Epoch 1050, Training-Loss 2.4294e+05, Data-loss 2.4224e+05                  , pde-loss 2.2539e-12, initc-loss 3.6196e+05                    bc_loss 6.6709e+06\n",
      "Epoch 1060, Training-Loss 2.4024e+05, Data-loss 2.3956e+05                  , pde-loss 2.1622e-12, initc-loss 3.5881e+05                    bc_loss 6.4805e+06\n",
      "Epoch 1070, Training-Loss 2.3862e+05, Data-loss 2.3796e+05                  , pde-loss 2.1074e-12, initc-loss 3.5568e+05                    bc_loss 6.2934e+06\n",
      "Epoch 1080, Training-Loss 2.3796e+05, Data-loss 2.3731e+05                  , pde-loss 2.0549e-12, initc-loss 3.5258e+05                    bc_loss 6.1097e+06\n",
      "Epoch 1090, Training-Loss 2.3396e+05, Data-loss 2.3333e+05                  , pde-loss 1.8640e-12, initc-loss 3.4949e+05                    bc_loss 5.9289e+06\n",
      "Epoch 1100, Training-Loss 2.3018e+05, Data-loss 2.2957e+05                  , pde-loss 1.9344e-12, initc-loss 3.4643e+05                    bc_loss 5.7515e+06\n",
      "Epoch 1110, Training-Loss 2.2774e+05, Data-loss 2.2715e+05                  , pde-loss 2.1016e-12, initc-loss 3.4338e+05                    bc_loss 5.5771e+06\n",
      "Epoch 1120, Training-Loss 2.2856e+05, Data-loss 2.2798e+05                  , pde-loss 1.9434e-12, initc-loss 3.4036e+05                    bc_loss 5.4060e+06\n",
      "Epoch 1130, Training-Loss 2.2589e+05, Data-loss 2.2534e+05                  , pde-loss 1.7868e-12, initc-loss 3.3736e+05                    bc_loss 5.2379e+06\n",
      "Epoch 1140, Training-Loss 2.2195e+05, Data-loss 2.2141e+05                  , pde-loss 1.8137e-12, initc-loss 3.3439e+05                    bc_loss 5.0729e+06\n",
      "Epoch 1150, Training-Loss 2.1638e+05, Data-loss 2.1586e+05                  , pde-loss 1.9122e-12, initc-loss 3.3143e+05                    bc_loss 4.9110e+06\n",
      "Epoch 1160, Training-Loss 2.1763e+05, Data-loss 2.1713e+05                  , pde-loss 1.7754e-12, initc-loss 3.2850e+05                    bc_loss 4.7521e+06\n",
      "Epoch 1170, Training-Loss 2.1565e+05, Data-loss 2.1515e+05                  , pde-loss 1.8141e-12, initc-loss 3.2558e+05                    bc_loss 4.5963e+06\n",
      "Epoch 1180, Training-Loss 2.1063e+05, Data-loss 2.1015e+05                  , pde-loss 1.7840e-12, initc-loss 3.2269e+05                    bc_loss 4.4437e+06\n",
      "Epoch 1190, Training-Loss 2.1065e+05, Data-loss 2.1019e+05                  , pde-loss 1.6001e-12, initc-loss 3.1982e+05                    bc_loss 4.2940e+06\n",
      "Epoch 1200, Training-Loss 2.0939e+05, Data-loss 2.0895e+05                  , pde-loss 1.7274e-12, initc-loss 3.1697e+05                    bc_loss 4.1474e+06\n",
      "Epoch 1210, Training-Loss 2.0398e+05, Data-loss 2.0355e+05                  , pde-loss 1.5799e-12, initc-loss 3.1414e+05                    bc_loss 4.0035e+06\n",
      "Epoch 1220, Training-Loss 2.0576e+05, Data-loss 2.0534e+05                  , pde-loss 1.5769e-12, initc-loss 3.1133e+05                    bc_loss 3.8626e+06\n",
      "Epoch 1230, Training-Loss 2.0043e+05, Data-loss 2.0003e+05                  , pde-loss 1.5143e-12, initc-loss 3.0854e+05                    bc_loss 3.7245e+06\n",
      "Epoch 1240, Training-Loss 1.9845e+05, Data-loss 1.9806e+05                  , pde-loss 1.5218e-12, initc-loss 3.0577e+05                    bc_loss 3.5894e+06\n",
      "Epoch 1250, Training-Loss 1.9344e+05, Data-loss 1.9306e+05                  , pde-loss 1.5474e-12, initc-loss 3.0303e+05                    bc_loss 3.4573e+06\n",
      "Epoch 1260, Training-Loss 1.9358e+05, Data-loss 1.9322e+05                  , pde-loss 1.4010e-12, initc-loss 3.0030e+05                    bc_loss 3.3280e+06\n",
      "Epoch 1270, Training-Loss 1.8961e+05, Data-loss 1.8926e+05                  , pde-loss 1.5593e-12, initc-loss 2.9759e+05                    bc_loss 3.2014e+06\n",
      "Epoch 1280, Training-Loss 1.8867e+05, Data-loss 1.8833e+05                  , pde-loss 1.4167e-12, initc-loss 2.9490e+05                    bc_loss 3.0777e+06\n",
      "Epoch 1290, Training-Loss 1.8766e+05, Data-loss 1.8734e+05                  , pde-loss 1.4256e-12, initc-loss 2.9223e+05                    bc_loss 2.9567e+06\n",
      "Epoch 1300, Training-Loss 1.8498e+05, Data-loss 1.8466e+05                  , pde-loss 1.3180e-12, initc-loss 2.8958e+05                    bc_loss 2.8384e+06\n",
      "Epoch 1310, Training-Loss 1.8230e+05, Data-loss 1.8200e+05                  , pde-loss 1.3703e-12, initc-loss 2.8695e+05                    bc_loss 2.7228e+06\n",
      "Epoch 1320, Training-Loss 1.7991e+05, Data-loss 1.7962e+05                  , pde-loss 1.4043e-12, initc-loss 2.8434e+05                    bc_loss 2.6099e+06\n",
      "Epoch 1330, Training-Loss 1.7801e+05, Data-loss 1.7773e+05                  , pde-loss 1.3032e-12, initc-loss 2.8175e+05                    bc_loss 2.4999e+06\n",
      "Epoch 1340, Training-Loss 1.7478e+05, Data-loss 1.7451e+05                  , pde-loss 1.3379e-12, initc-loss 2.7918e+05                    bc_loss 2.3925e+06\n",
      "Epoch 1350, Training-Loss 1.7417e+05, Data-loss 1.7391e+05                  , pde-loss 1.2488e-12, initc-loss 2.7663e+05                    bc_loss 2.2878e+06\n",
      "Epoch 1360, Training-Loss 1.7339e+05, Data-loss 1.7315e+05                  , pde-loss 1.2353e-12, initc-loss 2.7409e+05                    bc_loss 2.1857e+06\n",
      "Epoch 1370, Training-Loss 1.7266e+05, Data-loss 1.7242e+05                  , pde-loss 1.1886e-12, initc-loss 2.7158e+05                    bc_loss 2.0862e+06\n",
      "Epoch 1380, Training-Loss 1.6822e+05, Data-loss 1.6800e+05                  , pde-loss 1.1872e-12, initc-loss 2.6908e+05                    bc_loss 1.9893e+06\n",
      "Epoch 1390, Training-Loss 1.6689e+05, Data-loss 1.6667e+05                  , pde-loss 1.1758e-12, initc-loss 2.6661e+05                    bc_loss 1.8950e+06\n",
      "Epoch 1400, Training-Loss 1.6496e+05, Data-loss 1.6476e+05                  , pde-loss 1.2465e-12, initc-loss 2.6415e+05                    bc_loss 1.8033e+06\n",
      "Epoch 1410, Training-Loss 1.6127e+05, Data-loss 1.6107e+05                  , pde-loss 1.1989e-12, initc-loss 2.6171e+05                    bc_loss 1.7141e+06\n",
      "Epoch 1420, Training-Loss 1.6083e+05, Data-loss 1.6064e+05                  , pde-loss 1.1002e-12, initc-loss 2.5929e+05                    bc_loss 1.6273e+06\n",
      "Epoch 1430, Training-Loss 1.5784e+05, Data-loss 1.5766e+05                  , pde-loss 1.1423e-12, initc-loss 2.5688e+05                    bc_loss 1.5430e+06\n",
      "Epoch 1440, Training-Loss 1.5712e+05, Data-loss 1.5695e+05                  , pde-loss 1.1257e-12, initc-loss 2.5450e+05                    bc_loss 1.4613e+06\n",
      "Epoch 1450, Training-Loss 1.5633e+05, Data-loss 1.5617e+05                  , pde-loss 1.1126e-12, initc-loss 2.5213e+05                    bc_loss 1.3821e+06\n",
      "Epoch 1460, Training-Loss 1.5412e+05, Data-loss 1.5396e+05                  , pde-loss 1.0627e-12, initc-loss 2.4978e+05                    bc_loss 1.3052e+06\n",
      "Epoch 1470, Training-Loss 1.5105e+05, Data-loss 1.5090e+05                  , pde-loss 1.0251e-12, initc-loss 2.4745e+05                    bc_loss 1.2308e+06\n",
      "Epoch 1480, Training-Loss 1.4823e+05, Data-loss 1.4809e+05                  , pde-loss 1.0049e-12, initc-loss 2.4514e+05                    bc_loss 1.1587e+06\n",
      "Epoch 1490, Training-Loss 1.4785e+05, Data-loss 1.4772e+05                  , pde-loss 1.0124e-12, initc-loss 2.4284e+05                    bc_loss 1.0890e+06\n",
      "Epoch 1500, Training-Loss 1.4514e+05, Data-loss 1.4501e+05                  , pde-loss 1.0173e-12, initc-loss 2.4056e+05                    bc_loss 1.0217e+06\n",
      "Epoch 1510, Training-Loss 1.4426e+05, Data-loss 1.4414e+05                  , pde-loss 1.0105e-12, initc-loss 2.3831e+05                    bc_loss 9.5679e+05\n",
      "Epoch 1520, Training-Loss 1.4059e+05, Data-loss 1.4048e+05                  , pde-loss 1.0020e-12, initc-loss 2.3606e+05                    bc_loss 8.9417e+05\n",
      "Epoch 1530, Training-Loss 1.4028e+05, Data-loss 1.4018e+05                  , pde-loss 9.5986e-13, initc-loss 2.3384e+05                    bc_loss 8.3383e+05\n",
      "Epoch 1540, Training-Loss 1.3862e+05, Data-loss 1.3851e+05                  , pde-loss 9.6534e-13, initc-loss 2.3163e+05                    bc_loss 7.7575e+05\n",
      "Epoch 1550, Training-Loss 1.3641e+05, Data-loss 1.3631e+05                  , pde-loss 9.5310e-13, initc-loss 2.2944e+05                    bc_loss 7.1996e+05\n",
      "Epoch 1560, Training-Loss 1.3428e+05, Data-loss 1.3419e+05                  , pde-loss 9.3152e-13, initc-loss 2.2727e+05                    bc_loss 6.6641e+05\n",
      "Epoch 1570, Training-Loss 1.3344e+05, Data-loss 1.3336e+05                  , pde-loss 9.4605e-13, initc-loss 2.2511e+05                    bc_loss 6.1507e+05\n",
      "Epoch 1580, Training-Loss 1.3211e+05, Data-loss 1.3203e+05                  , pde-loss 9.1805e-13, initc-loss 2.2297e+05                    bc_loss 5.6591e+05\n",
      "Epoch 1590, Training-Loss 1.2968e+05, Data-loss 1.2960e+05                  , pde-loss 9.4856e-13, initc-loss 2.2084e+05                    bc_loss 5.1895e+05\n",
      "Epoch 1600, Training-Loss 1.2956e+05, Data-loss 1.2949e+05                  , pde-loss 9.4670e-13, initc-loss 2.1873e+05                    bc_loss 4.7415e+05\n",
      "Epoch 1610, Training-Loss 1.3026e+05, Data-loss 1.3020e+05                  , pde-loss 7.7423e-13, initc-loss 2.1664e+05                    bc_loss 4.3149e+05\n",
      "Epoch 1620, Training-Loss 1.2733e+05, Data-loss 1.2726e+05                  , pde-loss 8.5529e-13, initc-loss 2.1456e+05                    bc_loss 3.9092e+05\n",
      "Epoch 1630, Training-Loss 1.2418e+05, Data-loss 1.2412e+05                  , pde-loss 8.5028e-13, initc-loss 2.1250e+05                    bc_loss 3.5250e+05\n",
      "Epoch 1640, Training-Loss 1.2364e+05, Data-loss 1.2359e+05                  , pde-loss 8.2133e-13, initc-loss 2.1046e+05                    bc_loss 3.1620e+05\n",
      "Epoch 1650, Training-Loss 1.1962e+05, Data-loss 1.1957e+05                  , pde-loss 9.0297e-13, initc-loss 2.0844e+05                    bc_loss 2.8201e+05\n",
      "Epoch 1660, Training-Loss 1.2062e+05, Data-loss 1.2058e+05                  , pde-loss 8.4192e-13, initc-loss 2.0643e+05                    bc_loss 2.4986e+05\n",
      "Epoch 1670, Training-Loss 1.1784e+05, Data-loss 1.1780e+05                  , pde-loss 8.2932e-13, initc-loss 2.0444e+05                    bc_loss 2.1974e+05\n",
      "Epoch 1680, Training-Loss 1.1772e+05, Data-loss 1.1768e+05                  , pde-loss 8.1420e-13, initc-loss 2.0246e+05                    bc_loss 1.9166e+05\n",
      "Epoch 1690, Training-Loss 1.1568e+05, Data-loss 1.1564e+05                  , pde-loss 8.0094e-13, initc-loss 2.0050e+05                    bc_loss 1.6559e+05\n",
      "Epoch 1700, Training-Loss 1.1325e+05, Data-loss 1.1321e+05                  , pde-loss 7.6463e-13, initc-loss 1.9856e+05                    bc_loss 1.4148e+05\n",
      "Epoch 1710, Training-Loss 1.1381e+05, Data-loss 1.1378e+05                  , pde-loss 7.5084e-13, initc-loss 1.9662e+05                    bc_loss 1.1931e+05\n",
      "Epoch 1720, Training-Loss 1.1094e+05, Data-loss 1.1091e+05                  , pde-loss 7.6054e-13, initc-loss 1.9471e+05                    bc_loss 9.9055e+04\n",
      "Epoch 1730, Training-Loss 1.0910e+05, Data-loss 1.0907e+05                  , pde-loss 7.7860e-13, initc-loss 1.9280e+05                    bc_loss 8.0763e+04\n",
      "Epoch 1740, Training-Loss 1.1081e+05, Data-loss 1.1079e+05                  , pde-loss 7.5021e-13, initc-loss 1.9092e+05                    bc_loss 6.4402e+04\n",
      "Epoch 1750, Training-Loss 1.0687e+05, Data-loss 1.0684e+05                  , pde-loss 7.4769e-13, initc-loss 1.8905e+05                    bc_loss 4.9934e+04\n",
      "Epoch 1760, Training-Loss 1.0629e+05, Data-loss 1.0627e+05                  , pde-loss 7.4825e-13, initc-loss 1.8720e+05                    bc_loss 3.7331e+04\n",
      "Epoch 1770, Training-Loss 1.0451e+05, Data-loss 1.0449e+05                  , pde-loss 7.1880e-13, initc-loss 1.8535e+05                    bc_loss 2.6576e+04\n",
      "Epoch 1780, Training-Loss 1.0270e+05, Data-loss 1.0268e+05                  , pde-loss 7.2395e-13, initc-loss 1.8353e+05                    bc_loss 1.7679e+04\n",
      "Epoch 1790, Training-Loss 1.0140e+05, Data-loss 1.0138e+05                  , pde-loss 7.3121e-13, initc-loss 1.8172e+05                    bc_loss 1.0616e+04\n",
      "Epoch 1800, Training-Loss 9.9430e+04, Data-loss 9.9412e+04                  , pde-loss 7.5770e-13, initc-loss 1.7993e+05                    bc_loss 5.3581e+03\n",
      "Epoch 1810, Training-Loss 9.9286e+04, Data-loss 9.9268e+04                  , pde-loss 7.4098e-13, initc-loss 1.7815e+05                    bc_loss 1.8879e+03\n",
      "Epoch 1820, Training-Loss 9.6939e+04, Data-loss 9.6921e+04                  , pde-loss 7.5685e-13, initc-loss 1.7638e+05                    bc_loss 1.9095e+02\n",
      "Epoch 1830, Training-Loss 9.5372e+04, Data-loss 9.5354e+04                  , pde-loss 7.5148e-13, initc-loss 1.7463e+05                    bc_loss 2.4663e+02\n",
      "Epoch 1840, Training-Loss 9.5351e+04, Data-loss 9.5334e+04                  , pde-loss 7.3143e-13, initc-loss 1.7290e+05                    bc_loss 2.0358e+03\n",
      "Epoch 1850, Training-Loss 9.3820e+04, Data-loss 9.3802e+04                  , pde-loss 7.2031e-13, initc-loss 1.7118e+05                    bc_loss 5.5425e+03\n",
      "Epoch 1860, Training-Loss 9.1154e+04, Data-loss 9.1136e+04                  , pde-loss 7.1962e-13, initc-loss 1.6947e+05                    bc_loss 1.0750e+04\n",
      "Epoch 1870, Training-Loss 9.0680e+04, Data-loss 9.0662e+04                  , pde-loss 6.9875e-13, initc-loss 1.6778e+05                    bc_loss 1.7631e+04\n",
      "Epoch 1880, Training-Loss 8.7498e+04, Data-loss 8.7478e+04                  , pde-loss 7.2556e-13, initc-loss 1.6610e+05                    bc_loss 2.6183e+04\n",
      "Epoch 1890, Training-Loss 8.9686e+04, Data-loss 8.9666e+04                  , pde-loss 6.5223e-13, initc-loss 1.6444e+05                    bc_loss 3.6375e+04\n",
      "Epoch 1900, Training-Loss 8.7112e+04, Data-loss 8.7090e+04                  , pde-loss 6.7071e-13, initc-loss 1.6279e+05                    bc_loss 4.8186e+04\n",
      "Epoch 1910, Training-Loss 8.6393e+04, Data-loss 8.6371e+04                  , pde-loss 6.2660e-13, initc-loss 1.6116e+05                    bc_loss 6.1624e+04\n",
      "Epoch 1920, Training-Loss 8.5427e+04, Data-loss 8.5403e+04                  , pde-loss 6.4273e-13, initc-loss 1.5953e+05                    bc_loss 7.6691e+04\n",
      "Epoch 1930, Training-Loss 8.4816e+04, Data-loss 8.4790e+04                  , pde-loss 6.2333e-13, initc-loss 1.5792e+05                    bc_loss 9.3361e+04\n",
      "Epoch 1940, Training-Loss 8.2410e+04, Data-loss 8.2383e+04                  , pde-loss 6.7464e-13, initc-loss 1.5633e+05                    bc_loss 1.1156e+05\n",
      "Epoch 1950, Training-Loss 8.2157e+04, Data-loss 8.2129e+04                  , pde-loss 6.4832e-13, initc-loss 1.5475e+05                    bc_loss 1.3128e+05\n",
      "Epoch 1960, Training-Loss 8.1339e+04, Data-loss 8.1309e+04                  , pde-loss 6.4858e-13, initc-loss 1.5318e+05                    bc_loss 1.5253e+05\n",
      "Epoch 1970, Training-Loss 7.8676e+04, Data-loss 7.8643e+04                  , pde-loss 6.8117e-13, initc-loss 1.5163e+05                    bc_loss 1.7531e+05\n",
      "Epoch 1980, Training-Loss 7.8559e+04, Data-loss 7.8524e+04                  , pde-loss 6.8345e-13, initc-loss 1.5008e+05                    bc_loss 1.9962e+05\n",
      "Epoch 1990, Training-Loss 7.6464e+04, Data-loss 7.6426e+04                  , pde-loss 6.9160e-13, initc-loss 1.4856e+05                    bc_loss 2.2539e+05\n",
      "Epoch 2000, Training-Loss 7.6967e+04, Data-loss 7.6927e+04                  , pde-loss 6.7469e-13, initc-loss 1.4704e+05                    bc_loss 2.5262e+05\n",
      "Epoch 2010, Training-Loss 7.4434e+04, Data-loss 7.4392e+04                  , pde-loss 6.9044e-13, initc-loss 1.4554e+05                    bc_loss 2.8128e+05\n",
      "Epoch 2020, Training-Loss 7.3676e+04, Data-loss 7.3631e+04                  , pde-loss 6.5574e-13, initc-loss 1.4405e+05                    bc_loss 3.1133e+05\n",
      "Epoch 2030, Training-Loss 7.3673e+04, Data-loss 7.3625e+04                  , pde-loss 6.3651e-13, initc-loss 1.4258e+05                    bc_loss 3.4277e+05\n",
      "Epoch 2040, Training-Loss 7.2889e+04, Data-loss 7.2838e+04                  , pde-loss 6.2713e-13, initc-loss 1.4112e+05                    bc_loss 3.7568e+05\n",
      "Epoch 2050, Training-Loss 7.0483e+04, Data-loss 7.0428e+04                  , pde-loss 6.1516e-13, initc-loss 1.3967e+05                    bc_loss 4.0988e+05\n",
      "Epoch 2060, Training-Loss 6.8986e+04, Data-loss 6.8927e+04                  , pde-loss 6.4300e-13, initc-loss 1.3824e+05                    bc_loss 4.4548e+05\n",
      "Epoch 2070, Training-Loss 6.8518e+04, Data-loss 6.8457e+04                  , pde-loss 6.5381e-13, initc-loss 1.3682e+05                    bc_loss 4.8239e+05\n",
      "Epoch 2080, Training-Loss 6.5735e+04, Data-loss 6.5669e+04                  , pde-loss 6.5744e-13, initc-loss 1.3541e+05                    bc_loss 5.2058e+05\n",
      "Epoch 2090, Training-Loss 6.7388e+04, Data-loss 6.7318e+04                  , pde-loss 5.9482e-13, initc-loss 1.3402e+05                    bc_loss 5.6003e+05\n",
      "Epoch 2100, Training-Loss 6.7219e+04, Data-loss 6.7146e+04                  , pde-loss 5.5824e-13, initc-loss 1.3264e+05                    bc_loss 6.0078e+05\n",
      "Epoch 2110, Training-Loss 6.6308e+04, Data-loss 6.6230e+04                  , pde-loss 5.2839e-13, initc-loss 1.3127e+05                    bc_loss 6.4279e+05\n",
      "Epoch 2120, Training-Loss 6.3822e+04, Data-loss 6.3741e+04                  , pde-loss 6.1450e-13, initc-loss 1.2991e+05                    bc_loss 6.8617e+05\n",
      "Epoch 2130, Training-Loss 6.0181e+04, Data-loss 6.0095e+04                  , pde-loss 6.2312e-13, initc-loss 1.2856e+05                    bc_loss 7.3077e+05\n",
      "Epoch 2140, Training-Loss 6.1244e+04, Data-loss 6.1154e+04                  , pde-loss 6.0236e-13, initc-loss 1.2723e+05                    bc_loss 7.7657e+05\n",
      "Epoch 2150, Training-Loss 6.1363e+04, Data-loss 6.1268e+04                  , pde-loss 5.9013e-13, initc-loss 1.2590e+05                    bc_loss 8.2359e+05\n",
      "Epoch 2160, Training-Loss 6.0083e+04, Data-loss 5.9983e+04                  , pde-loss 5.8789e-13, initc-loss 1.2459e+05                    bc_loss 8.7189e+05\n",
      "Epoch 2170, Training-Loss 5.9900e+04, Data-loss 5.9796e+04                  , pde-loss 5.5262e-13, initc-loss 1.2329e+05                    bc_loss 9.2126e+05\n",
      "Epoch 2180, Training-Loss 5.7861e+04, Data-loss 5.7751e+04                  , pde-loss 5.9644e-13, initc-loss 1.2201e+05                    bc_loss 9.7179e+05\n",
      "Epoch 2190, Training-Loss 5.9195e+04, Data-loss 5.9081e+04                  , pde-loss 5.6438e-13, initc-loss 1.2073e+05                    bc_loss 1.0235e+06\n",
      "Epoch 2200, Training-Loss 5.6857e+04, Data-loss 5.6737e+04                  , pde-loss 5.5747e-13, initc-loss 1.1947e+05                    bc_loss 1.0763e+06\n",
      "Epoch 2210, Training-Loss 5.6928e+04, Data-loss 5.6803e+04                  , pde-loss 5.7784e-13, initc-loss 1.1822e+05                    bc_loss 1.1303e+06\n",
      "Epoch 2220, Training-Loss 5.5999e+04, Data-loss 5.5869e+04                  , pde-loss 5.6387e-13, initc-loss 1.1697e+05                    bc_loss 1.1854e+06\n",
      "Epoch 2230, Training-Loss 5.3627e+04, Data-loss 5.3491e+04                  , pde-loss 5.9046e-13, initc-loss 1.1574e+05                    bc_loss 1.2416e+06\n",
      "Epoch 2240, Training-Loss 5.4384e+04, Data-loss 5.4242e+04                  , pde-loss 5.8716e-13, initc-loss 1.1453e+05                    bc_loss 1.2988e+06\n",
      "Epoch 2250, Training-Loss 5.3553e+04, Data-loss 5.3406e+04                  , pde-loss 6.1616e-13, initc-loss 1.1332e+05                    bc_loss 1.3571e+06\n",
      "Epoch 2260, Training-Loss 5.2034e+04, Data-loss 5.1881e+04                  , pde-loss 6.2753e-13, initc-loss 1.1212e+05                    bc_loss 1.4165e+06\n",
      "Epoch 2270, Training-Loss 5.1729e+04, Data-loss 5.1570e+04                  , pde-loss 6.3302e-13, initc-loss 1.1094e+05                    bc_loss 1.4767e+06\n",
      "Epoch 2280, Training-Loss 5.0923e+04, Data-loss 5.0758e+04                  , pde-loss 6.1283e-13, initc-loss 1.0976e+05                    bc_loss 1.5380e+06\n",
      "Epoch 2290, Training-Loss 4.8871e+04, Data-loss 4.8700e+04                  , pde-loss 6.3356e-13, initc-loss 1.0860e+05                    bc_loss 1.6003e+06\n",
      "Epoch 2300, Training-Loss 5.0341e+04, Data-loss 5.0164e+04                  , pde-loss 5.9473e-13, initc-loss 1.0745e+05                    bc_loss 1.6635e+06\n",
      "Epoch 2310, Training-Loss 4.7571e+04, Data-loss 4.7387e+04                  , pde-loss 5.8386e-13, initc-loss 1.0631e+05                    bc_loss 1.7278e+06\n",
      "Epoch 2320, Training-Loss 4.6770e+04, Data-loss 4.6580e+04                  , pde-loss 5.9699e-13, initc-loss 1.0518e+05                    bc_loss 1.7931e+06\n",
      "Epoch 2330, Training-Loss 4.5544e+04, Data-loss 4.5348e+04                  , pde-loss 6.2451e-13, initc-loss 1.0406e+05                    bc_loss 1.8590e+06\n",
      "Epoch 2340, Training-Loss 4.5956e+04, Data-loss 4.5753e+04                  , pde-loss 5.8524e-13, initc-loss 1.0296e+05                    bc_loss 1.9259e+06\n",
      "Epoch 2350, Training-Loss 4.5341e+04, Data-loss 4.5131e+04                  , pde-loss 5.8153e-13, initc-loss 1.0186e+05                    bc_loss 1.9936e+06\n",
      "Epoch 2360, Training-Loss 4.3586e+04, Data-loss 4.3369e+04                  , pde-loss 5.9513e-13, initc-loss 1.0078e+05                    bc_loss 2.0620e+06\n",
      "Epoch 2370, Training-Loss 4.3478e+04, Data-loss 4.3255e+04                  , pde-loss 5.8590e-13, initc-loss 9.9708e+04                    bc_loss 2.1314e+06\n",
      "Epoch 2380, Training-Loss 4.2585e+04, Data-loss 4.2355e+04                  , pde-loss 6.0056e-13, initc-loss 9.8643e+04                    bc_loss 2.2018e+06\n",
      "Epoch 2390, Training-Loss 4.2022e+04, Data-loss 4.1784e+04                  , pde-loss 5.8846e-13, initc-loss 9.7591e+04                    bc_loss 2.2729e+06\n",
      "Epoch 2400, Training-Loss 4.1200e+04, Data-loss 4.0956e+04                  , pde-loss 5.7823e-13, initc-loss 9.6549e+04                    bc_loss 2.3448e+06\n",
      "Epoch 2410, Training-Loss 4.2217e+04, Data-loss 4.1966e+04                  , pde-loss 5.5831e-13, initc-loss 9.5518e+04                    bc_loss 2.4174e+06\n",
      "Epoch 2420, Training-Loss 4.0596e+04, Data-loss 4.0338e+04                  , pde-loss 5.4381e-13, initc-loss 9.4497e+04                    bc_loss 2.4907e+06\n",
      "Epoch 2430, Training-Loss 3.8809e+04, Data-loss 3.8543e+04                  , pde-loss 5.7137e-13, initc-loss 9.3484e+04                    bc_loss 2.5651e+06\n",
      "Epoch 2440, Training-Loss 3.9864e+04, Data-loss 3.9590e+04                  , pde-loss 5.5460e-13, initc-loss 9.2481e+04                    bc_loss 2.6401e+06\n",
      "Epoch 2450, Training-Loss 3.9064e+04, Data-loss 3.8783e+04                  , pde-loss 5.4897e-13, initc-loss 9.1486e+04                    bc_loss 2.7160e+06\n",
      "Epoch 2460, Training-Loss 3.7404e+04, Data-loss 3.7115e+04                  , pde-loss 5.7325e-13, initc-loss 9.0501e+04                    bc_loss 2.7927e+06\n",
      "Epoch 2470, Training-Loss 3.7352e+04, Data-loss 3.7056e+04                  , pde-loss 5.4284e-13, initc-loss 8.9527e+04                    bc_loss 2.8699e+06\n",
      "Epoch 2480, Training-Loss 3.6770e+04, Data-loss 3.6466e+04                  , pde-loss 5.5540e-13, initc-loss 8.8562e+04                    bc_loss 2.9479e+06\n",
      "Epoch 2490, Training-Loss 3.6515e+04, Data-loss 3.6203e+04                  , pde-loss 5.4421e-13, initc-loss 8.7609e+04                    bc_loss 3.0264e+06\n",
      "Epoch 2500, Training-Loss 3.5871e+04, Data-loss 3.5552e+04                  , pde-loss 5.2951e-13, initc-loss 8.6667e+04                    bc_loss 3.1054e+06\n",
      "Epoch 2510, Training-Loss 3.5036e+04, Data-loss 3.4709e+04                  , pde-loss 5.3584e-13, initc-loss 8.5735e+04                    bc_loss 3.1850e+06\n",
      "Epoch 2520, Training-Loss 3.5008e+04, Data-loss 3.4673e+04                  , pde-loss 5.1698e-13, initc-loss 8.4812e+04                    bc_loss 3.2653e+06\n",
      "Epoch 2530, Training-Loss 3.4015e+04, Data-loss 3.3672e+04                  , pde-loss 5.3052e-13, initc-loss 8.3897e+04                    bc_loss 3.3463e+06\n",
      "Epoch 2540, Training-Loss 3.3352e+04, Data-loss 3.3001e+04                  , pde-loss 5.1529e-13, initc-loss 8.2991e+04                    bc_loss 3.4279e+06\n",
      "Epoch 2550, Training-Loss 3.3246e+04, Data-loss 3.2887e+04                  , pde-loss 5.0068e-13, initc-loss 8.2092e+04                    bc_loss 3.5104e+06\n",
      "Epoch 2560, Training-Loss 3.1654e+04, Data-loss 3.1287e+04                  , pde-loss 5.4727e-13, initc-loss 8.1203e+04                    bc_loss 3.5933e+06\n",
      "Epoch 2570, Training-Loss 3.1819e+04, Data-loss 3.1444e+04                  , pde-loss 5.4066e-13, initc-loss 8.0326e+04                    bc_loss 3.6765e+06\n",
      "Epoch 2580, Training-Loss 3.1506e+04, Data-loss 3.1122e+04                  , pde-loss 5.3044e-13, initc-loss 7.9456e+04                    bc_loss 3.7604e+06\n",
      "Epoch 2590, Training-Loss 3.0884e+04, Data-loss 3.0491e+04                  , pde-loss 5.6951e-13, initc-loss 7.8597e+04                    bc_loss 3.8447e+06\n",
      "Epoch 2600, Training-Loss 2.9781e+04, Data-loss 2.9380e+04                  , pde-loss 5.4069e-13, initc-loss 7.7745e+04                    bc_loss 3.9297e+06\n",
      "Epoch 2610, Training-Loss 2.9064e+04, Data-loss 2.8655e+04                  , pde-loss 5.7382e-13, initc-loss 7.6902e+04                    bc_loss 4.0151e+06\n",
      "Epoch 2620, Training-Loss 2.8563e+04, Data-loss 2.8146e+04                  , pde-loss 5.7475e-13, initc-loss 7.6070e+04                    bc_loss 4.1008e+06\n",
      "Epoch 2630, Training-Loss 2.9646e+04, Data-loss 2.9220e+04                  , pde-loss 5.4940e-13, initc-loss 7.5246e+04                    bc_loss 4.1871e+06\n",
      "Epoch 2640, Training-Loss 2.8727e+04, Data-loss 2.8292e+04                  , pde-loss 5.7099e-13, initc-loss 7.4429e+04                    bc_loss 4.2739e+06\n",
      "Epoch 2650, Training-Loss 2.8383e+04, Data-loss 2.7940e+04                  , pde-loss 5.6212e-13, initc-loss 7.3622e+04                    bc_loss 4.3611e+06\n",
      "Epoch 2660, Training-Loss 2.7541e+04, Data-loss 2.7089e+04                  , pde-loss 5.4038e-13, initc-loss 7.2822e+04                    bc_loss 4.4488e+06\n",
      "Epoch 2670, Training-Loss 2.5856e+04, Data-loss 2.5396e+04                  , pde-loss 5.8980e-13, initc-loss 7.2031e+04                    bc_loss 4.5369e+06\n",
      "Epoch 2680, Training-Loss 2.6775e+04, Data-loss 2.6306e+04                  , pde-loss 5.7542e-13, initc-loss 7.1251e+04                    bc_loss 4.6251e+06\n",
      "Epoch 2690, Training-Loss 2.5342e+04, Data-loss 2.4864e+04                  , pde-loss 5.7628e-13, initc-loss 7.0478e+04                    bc_loss 4.7139e+06\n",
      "Epoch 2700, Training-Loss 2.4703e+04, Data-loss 2.4216e+04                  , pde-loss 5.8931e-13, initc-loss 6.9714e+04                    bc_loss 4.8029e+06\n",
      "Epoch 2710, Training-Loss 2.4946e+04, Data-loss 2.4450e+04                  , pde-loss 5.7849e-13, initc-loss 6.8958e+04                    bc_loss 4.8923e+06\n",
      "Epoch 2720, Training-Loss 2.4055e+04, Data-loss 2.3550e+04                  , pde-loss 5.9314e-13, initc-loss 6.8209e+04                    bc_loss 4.9821e+06\n",
      "Epoch 2730, Training-Loss 2.3899e+04, Data-loss 2.3385e+04                  , pde-loss 5.7277e-13, initc-loss 6.7471e+04                    bc_loss 5.0720e+06\n",
      "Epoch 2740, Training-Loss 2.3242e+04, Data-loss 2.2719e+04                  , pde-loss 5.8835e-13, initc-loss 6.6738e+04                    bc_loss 5.1625e+06\n",
      "Epoch 2750, Training-Loss 2.4699e+04, Data-loss 2.4167e+04                  , pde-loss 5.5943e-13, initc-loss 6.6015e+04                    bc_loss 5.2530e+06\n",
      "Epoch 2760, Training-Loss 2.3216e+04, Data-loss 2.2675e+04                  , pde-loss 5.9148e-13, initc-loss 6.5299e+04                    bc_loss 5.3441e+06\n",
      "Epoch 2770, Training-Loss 2.2640e+04, Data-loss 2.2090e+04                  , pde-loss 6.1340e-13, initc-loss 6.4590e+04                    bc_loss 5.4353e+06\n",
      "Epoch 2780, Training-Loss 2.2124e+04, Data-loss 2.1565e+04                  , pde-loss 6.2206e-13, initc-loss 6.3890e+04                    bc_loss 5.5268e+06\n",
      "Epoch 2790, Training-Loss 2.1948e+04, Data-loss 2.1380e+04                  , pde-loss 6.1559e-13, initc-loss 6.3199e+04                    bc_loss 5.6183e+06\n",
      "Epoch 2800, Training-Loss 2.2170e+04, Data-loss 2.1592e+04                  , pde-loss 6.1753e-13, initc-loss 6.2514e+04                    bc_loss 5.7104e+06\n",
      "Epoch 2810, Training-Loss 2.1267e+04, Data-loss 2.0681e+04                  , pde-loss 6.4014e-13, initc-loss 6.1833e+04                    bc_loss 5.8030e+06\n",
      "Epoch 2820, Training-Loss 2.1162e+04, Data-loss 2.0566e+04                  , pde-loss 6.3352e-13, initc-loss 6.1161e+04                    bc_loss 5.8957e+06\n",
      "Epoch 2830, Training-Loss 2.0661e+04, Data-loss 2.0056e+04                  , pde-loss 6.4638e-13, initc-loss 6.0499e+04                    bc_loss 5.9882e+06\n",
      "Epoch 2840, Training-Loss 2.1060e+04, Data-loss 2.0446e+04                  , pde-loss 6.2862e-13, initc-loss 5.9845e+04                    bc_loss 6.0808e+06\n",
      "Epoch 2850, Training-Loss 1.9860e+04, Data-loss 1.9237e+04                  , pde-loss 6.7859e-13, initc-loss 5.9196e+04                    bc_loss 6.1739e+06\n",
      "Epoch 2860, Training-Loss 2.0361e+04, Data-loss 1.9728e+04                  , pde-loss 6.5429e-13, initc-loss 5.8557e+04                    bc_loss 6.2669e+06\n",
      "Epoch 2870, Training-Loss 1.8947e+04, Data-loss 1.8306e+04                  , pde-loss 6.5982e-13, initc-loss 5.7924e+04                    bc_loss 6.3601e+06\n",
      "Epoch 2880, Training-Loss 1.8261e+04, Data-loss 1.7610e+04                  , pde-loss 7.1345e-13, initc-loss 5.7299e+04                    bc_loss 6.4533e+06\n",
      "Epoch 2890, Training-Loss 1.7863e+04, Data-loss 1.7202e+04                  , pde-loss 6.8788e-13, initc-loss 5.6680e+04                    bc_loss 6.5467e+06\n",
      "Epoch 2900, Training-Loss 1.7845e+04, Data-loss 1.7175e+04                  , pde-loss 6.8571e-13, initc-loss 5.6067e+04                    bc_loss 6.6405e+06\n",
      "Epoch 2910, Training-Loss 1.8231e+04, Data-loss 1.7552e+04                  , pde-loss 6.2776e-13, initc-loss 5.5459e+04                    bc_loss 6.7347e+06\n",
      "Epoch 2920, Training-Loss 1.6898e+04, Data-loss 1.6209e+04                  , pde-loss 6.8513e-13, initc-loss 5.4857e+04                    bc_loss 6.8290e+06\n",
      "Epoch 2930, Training-Loss 1.7285e+04, Data-loss 1.6588e+04                  , pde-loss 6.6752e-13, initc-loss 5.4264e+04                    bc_loss 6.9232e+06\n",
      "Epoch 2940, Training-Loss 1.7567e+04, Data-loss 1.6860e+04                  , pde-loss 6.4926e-13, initc-loss 5.3679e+04                    bc_loss 7.0173e+06\n",
      "Epoch 2950, Training-Loss 1.6039e+04, Data-loss 1.5323e+04                  , pde-loss 6.9372e-13, initc-loss 5.3101e+04                    bc_loss 7.1112e+06\n",
      "Epoch 2960, Training-Loss 1.5849e+04, Data-loss 1.5123e+04                  , pde-loss 7.1110e-13, initc-loss 5.2528e+04                    bc_loss 7.2055e+06\n",
      "Epoch 2970, Training-Loss 1.5987e+04, Data-loss 1.5252e+04                  , pde-loss 7.0078e-13, initc-loss 5.1964e+04                    bc_loss 7.2996e+06\n",
      "Epoch 2980, Training-Loss 1.5341e+04, Data-loss 1.4597e+04                  , pde-loss 6.7718e-13, initc-loss 5.1407e+04                    bc_loss 7.3935e+06\n",
      "Epoch 2990, Training-Loss 1.6165e+04, Data-loss 1.5411e+04                  , pde-loss 6.0934e-13, initc-loss 5.0859e+04                    bc_loss 7.4869e+06\n",
      "Epoch 3000, Training-Loss 1.5248e+04, Data-loss 1.4485e+04                  , pde-loss 6.3323e-13, initc-loss 5.0314e+04                    bc_loss 7.5810e+06\n",
      "Epoch 3010, Training-Loss 1.5291e+04, Data-loss 1.4518e+04                  , pde-loss 5.9151e-13, initc-loss 4.9775e+04                    bc_loss 7.6752e+06\n",
      "Epoch 3020, Training-Loss 1.5322e+04, Data-loss 1.4540e+04                  , pde-loss 5.9700e-13, initc-loss 4.9242e+04                    bc_loss 7.7693e+06\n",
      "Epoch 3030, Training-Loss 1.4836e+04, Data-loss 1.4045e+04                  , pde-loss 6.0345e-13, initc-loss 4.8717e+04                    bc_loss 7.8631e+06\n",
      "Epoch 3040, Training-Loss 1.3761e+04, Data-loss 1.2961e+04                  , pde-loss 6.2395e-13, initc-loss 4.8198e+04                    bc_loss 7.9569e+06\n",
      "Epoch 3050, Training-Loss 1.3926e+04, Data-loss 1.3116e+04                  , pde-loss 6.1640e-13, initc-loss 4.7685e+04                    bc_loss 8.0506e+06\n",
      "Epoch 3060, Training-Loss 1.3191e+04, Data-loss 1.2372e+04                  , pde-loss 6.3939e-13, initc-loss 4.7178e+04                    bc_loss 8.1443e+06\n",
      "Epoch 3070, Training-Loss 1.3247e+04, Data-loss 1.2419e+04                  , pde-loss 6.4074e-13, initc-loss 4.6677e+04                    bc_loss 8.2378e+06\n",
      "Epoch 3080, Training-Loss 1.2808e+04, Data-loss 1.1970e+04                  , pde-loss 6.2242e-13, initc-loss 4.6183e+04                    bc_loss 8.3311e+06\n",
      "Epoch 3090, Training-Loss 1.2881e+04, Data-loss 1.2034e+04                  , pde-loss 6.3279e-13, initc-loss 4.5693e+04                    bc_loss 8.4247e+06\n",
      "Epoch 3100, Training-Loss 1.2249e+04, Data-loss 1.1393e+04                  , pde-loss 6.4125e-13, initc-loss 4.5208e+04                    bc_loss 8.5184e+06\n",
      "Epoch 3110, Training-Loss 1.2747e+04, Data-loss 1.1881e+04                  , pde-loss 6.1756e-13, initc-loss 4.4730e+04                    bc_loss 8.6117e+06\n",
      "Epoch 3120, Training-Loss 1.2693e+04, Data-loss 1.1819e+04                  , pde-loss 6.2192e-13, initc-loss 4.4259e+04                    bc_loss 8.7046e+06\n",
      "Epoch 3130, Training-Loss 1.2567e+04, Data-loss 1.1683e+04                  , pde-loss 6.3203e-13, initc-loss 4.3794e+04                    bc_loss 8.7973e+06\n",
      "Epoch 3140, Training-Loss 1.1776e+04, Data-loss 1.0882e+04                  , pde-loss 6.3120e-13, initc-loss 4.3336e+04                    bc_loss 8.8896e+06\n",
      "Epoch 3150, Training-Loss 1.1367e+04, Data-loss 1.0465e+04                  , pde-loss 6.2006e-13, initc-loss 4.2884e+04                    bc_loss 8.9817e+06\n",
      "Epoch 3160, Training-Loss 1.1236e+04, Data-loss 1.0324e+04                  , pde-loss 6.2463e-13, initc-loss 4.2437e+04                    bc_loss 9.0735e+06\n",
      "Epoch 3170, Training-Loss 1.0974e+04, Data-loss 1.0053e+04                  , pde-loss 6.3206e-13, initc-loss 4.1997e+04                    bc_loss 9.1650e+06\n",
      "Epoch 3180, Training-Loss 1.0895e+04, Data-loss 9.9655e+03                  , pde-loss 6.5916e-13, initc-loss 4.1562e+04                    bc_loss 9.2564e+06\n",
      "Epoch 3190, Training-Loss 1.0729e+04, Data-loss 9.7904e+03                  , pde-loss 6.4789e-13, initc-loss 4.1131e+04                    bc_loss 9.3478e+06\n",
      "Epoch 3200, Training-Loss 1.0816e+04, Data-loss 9.8677e+03                  , pde-loss 6.4161e-13, initc-loss 4.0706e+04                    bc_loss 9.4389e+06\n",
      "Epoch 3210, Training-Loss 1.0581e+04, Data-loss 9.6244e+03                  , pde-loss 6.6816e-13, initc-loss 4.0288e+04                    bc_loss 9.5294e+06\n",
      "Epoch 3220, Training-Loss 1.0754e+04, Data-loss 9.7880e+03                  , pde-loss 6.5340e-13, initc-loss 3.9874e+04                    bc_loss 9.6199e+06\n",
      "Epoch 3230, Training-Loss 1.0438e+04, Data-loss 9.4628e+03                  , pde-loss 6.7180e-13, initc-loss 3.9462e+04                    bc_loss 9.7107e+06\n",
      "Epoch 3240, Training-Loss 9.6747e+03, Data-loss 8.6906e+03                  , pde-loss 6.8358e-13, initc-loss 3.9057e+04                    bc_loss 9.8011e+06\n",
      "Epoch 3250, Training-Loss 9.8846e+03, Data-loss 8.8916e+03                  , pde-loss 6.5705e-13, initc-loss 3.8658e+04                    bc_loss 9.8908e+06\n",
      "Epoch 3260, Training-Loss 9.7085e+03, Data-loss 8.7066e+03                  , pde-loss 6.7298e-13, initc-loss 3.8262e+04                    bc_loss 9.9808e+06\n",
      "Epoch 3270, Training-Loss 9.0996e+03, Data-loss 8.0887e+03                  , pde-loss 7.0343e-13, initc-loss 3.7869e+04                    bc_loss 1.0071e+07\n",
      "Epoch 3280, Training-Loss 9.1905e+03, Data-loss 8.1708e+03                  , pde-loss 6.9950e-13, initc-loss 3.7485e+04                    bc_loss 1.0160e+07\n",
      "Epoch 3290, Training-Loss 9.4739e+03, Data-loss 8.4454e+03                  , pde-loss 6.9697e-13, initc-loss 3.7107e+04                    bc_loss 1.0248e+07\n",
      "Epoch 3300, Training-Loss 8.5021e+03, Data-loss 7.4647e+03                  , pde-loss 7.3007e-13, initc-loss 3.6733e+04                    bc_loss 1.0337e+07\n",
      "Epoch 3310, Training-Loss 8.8219e+03, Data-loss 7.7758e+03                  , pde-loss 7.0780e-13, initc-loss 3.6365e+04                    bc_loss 1.0425e+07\n",
      "Epoch 3320, Training-Loss 8.6190e+03, Data-loss 7.5642e+03                  , pde-loss 7.2285e-13, initc-loss 3.6001e+04                    bc_loss 1.0512e+07\n",
      "Epoch 3330, Training-Loss 8.6066e+03, Data-loss 7.5432e+03                  , pde-loss 7.3375e-13, initc-loss 3.5643e+04                    bc_loss 1.0599e+07\n",
      "Epoch 3340, Training-Loss 8.4999e+03, Data-loss 7.4278e+03                  , pde-loss 7.5230e-13, initc-loss 3.5290e+04                    bc_loss 1.0685e+07\n",
      "Epoch 3350, Training-Loss 8.0170e+03, Data-loss 6.9364e+03                  , pde-loss 7.5628e-13, initc-loss 3.4942e+04                    bc_loss 1.0772e+07\n",
      "Epoch 3360, Training-Loss 8.6523e+03, Data-loss 7.5631e+03                  , pde-loss 7.4429e-13, initc-loss 3.4599e+04                    bc_loss 1.0857e+07\n",
      "Epoch 3370, Training-Loss 8.7634e+03, Data-loss 7.6657e+03                  , pde-loss 7.3022e-13, initc-loss 3.4259e+04                    bc_loss 1.0943e+07\n",
      "Epoch 3380, Training-Loss 8.3483e+03, Data-loss 7.2421e+03                  , pde-loss 7.6205e-13, initc-loss 3.3922e+04                    bc_loss 1.1028e+07\n",
      "Epoch 3390, Training-Loss 7.3757e+03, Data-loss 6.2610e+03                  , pde-loss 8.0665e-13, initc-loss 3.3590e+04                    bc_loss 1.1113e+07\n",
      "Epoch 3400, Training-Loss 7.6200e+03, Data-loss 6.4969e+03                  , pde-loss 7.9667e-13, initc-loss 3.3263e+04                    bc_loss 1.1198e+07\n",
      "Epoch 3410, Training-Loss 7.5810e+03, Data-loss 6.4495e+03                  , pde-loss 8.2523e-13, initc-loss 3.2938e+04                    bc_loss 1.1282e+07\n",
      "Epoch 3420, Training-Loss 7.8396e+03, Data-loss 6.6997e+03                  , pde-loss 7.7458e-13, initc-loss 3.2619e+04                    bc_loss 1.1366e+07\n",
      "Epoch 3430, Training-Loss 7.7953e+03, Data-loss 6.6471e+03                  , pde-loss 7.8239e-13, initc-loss 3.2305e+04                    bc_loss 1.1449e+07\n",
      "Epoch 3440, Training-Loss 7.7550e+03, Data-loss 6.5985e+03                  , pde-loss 7.8207e-13, initc-loss 3.1993e+04                    bc_loss 1.1533e+07\n",
      "Epoch 3450, Training-Loss 7.2847e+03, Data-loss 6.1200e+03                  , pde-loss 8.0249e-13, initc-loss 3.1686e+04                    bc_loss 1.1616e+07\n",
      "Epoch 3460, Training-Loss 7.0640e+03, Data-loss 5.8912e+03                  , pde-loss 8.4647e-13, initc-loss 3.1386e+04                    bc_loss 1.1697e+07\n",
      "Epoch 3470, Training-Loss 7.2520e+03, Data-loss 6.0710e+03                  , pde-loss 8.2608e-13, initc-loss 3.1090e+04                    bc_loss 1.1778e+07\n",
      "Epoch 3480, Training-Loss 6.7814e+03, Data-loss 5.5923e+03                  , pde-loss 8.2989e-13, initc-loss 3.0794e+04                    bc_loss 1.1860e+07\n",
      "Epoch 3490, Training-Loss 7.0113e+03, Data-loss 5.8141e+03                  , pde-loss 8.0960e-13, initc-loss 3.0502e+04                    bc_loss 1.1941e+07\n",
      "Epoch 3500, Training-Loss 6.5771e+03, Data-loss 5.3719e+03                  , pde-loss 8.4978e-13, initc-loss 3.0215e+04                    bc_loss 1.2022e+07\n",
      "Epoch 3510, Training-Loss 6.4811e+03, Data-loss 5.2680e+03                  , pde-loss 8.6489e-13, initc-loss 2.9934e+04                    bc_loss 1.2102e+07\n",
      "Epoch 3520, Training-Loss 6.7990e+03, Data-loss 5.5779e+03                  , pde-loss 8.4648e-13, initc-loss 2.9657e+04                    bc_loss 1.2181e+07\n",
      "Epoch 3530, Training-Loss 6.2654e+03, Data-loss 5.0366e+03                  , pde-loss 9.2676e-13, initc-loss 2.9384e+04                    bc_loss 1.2259e+07\n",
      "Epoch 3540, Training-Loss 6.4227e+03, Data-loss 5.1861e+03                  , pde-loss 8.8223e-13, initc-loss 2.9118e+04                    bc_loss 1.2337e+07\n",
      "Epoch 3550, Training-Loss 6.3889e+03, Data-loss 5.1446e+03                  , pde-loss 8.3578e-13, initc-loss 2.8853e+04                    bc_loss 1.2414e+07\n",
      "Epoch 3560, Training-Loss 6.3504e+03, Data-loss 5.0984e+03                  , pde-loss 8.9150e-13, initc-loss 2.8590e+04                    bc_loss 1.2491e+07\n",
      "Epoch 3570, Training-Loss 6.1764e+03, Data-loss 4.9167e+03                  , pde-loss 9.5813e-13, initc-loss 2.8332e+04                    bc_loss 1.2568e+07\n",
      "Epoch 3580, Training-Loss 5.8883e+03, Data-loss 4.6212e+03                  , pde-loss 9.0378e-13, initc-loss 2.8080e+04                    bc_loss 1.2643e+07\n",
      "Epoch 3590, Training-Loss 5.9967e+03, Data-loss 4.7221e+03                  , pde-loss 9.4409e-13, initc-loss 2.7830e+04                    bc_loss 1.2719e+07\n",
      "Epoch 3600, Training-Loss 5.8193e+03, Data-loss 4.5372e+03                  , pde-loss 9.5522e-13, initc-loss 2.7583e+04                    bc_loss 1.2794e+07\n",
      "Epoch 3610, Training-Loss 6.0135e+03, Data-loss 4.7240e+03                  , pde-loss 9.3173e-13, initc-loss 2.7340e+04                    bc_loss 1.2868e+07\n",
      "Epoch 3620, Training-Loss 5.3805e+03, Data-loss 4.0836e+03                  , pde-loss 9.8411e-13, initc-loss 2.7099e+04                    bc_loss 1.2942e+07\n",
      "Epoch 3630, Training-Loss 5.0611e+03, Data-loss 3.7570e+03                  , pde-loss 1.0400e-12, initc-loss 2.6864e+04                    bc_loss 1.3015e+07\n",
      "Epoch 3640, Training-Loss 5.6171e+03, Data-loss 4.3057e+03                  , pde-loss 9.6857e-13, initc-loss 2.6631e+04                    bc_loss 1.3088e+07\n",
      "Epoch 3650, Training-Loss 5.3198e+03, Data-loss 4.0010e+03                  , pde-loss 1.0158e-12, initc-loss 2.6398e+04                    bc_loss 1.3161e+07\n",
      "Epoch 3660, Training-Loss 5.6255e+03, Data-loss 4.2995e+03                  , pde-loss 9.5133e-13, initc-loss 2.6170e+04                    bc_loss 1.3233e+07\n",
      "Epoch 3670, Training-Loss 5.4638e+03, Data-loss 4.1307e+03                  , pde-loss 1.0296e-12, initc-loss 2.5944e+04                    bc_loss 1.3306e+07\n",
      "Epoch 3680, Training-Loss 4.7634e+03, Data-loss 3.4231e+03                  , pde-loss 1.0697e-12, initc-loss 2.5721e+04                    bc_loss 1.3377e+07\n",
      "Epoch 3690, Training-Loss 5.6285e+03, Data-loss 4.2812e+03                  , pde-loss 1.0599e-12, initc-loss 2.5503e+04                    bc_loss 1.3448e+07\n",
      "Epoch 3700, Training-Loss 5.4134e+03, Data-loss 4.0591e+03                  , pde-loss 1.0547e-12, initc-loss 2.5289e+04                    bc_loss 1.3518e+07\n",
      "Epoch 3710, Training-Loss 5.2993e+03, Data-loss 3.9381e+03                  , pde-loss 1.0524e-12, initc-loss 2.5077e+04                    bc_loss 1.3587e+07\n",
      "Epoch 3720, Training-Loss 5.2831e+03, Data-loss 3.9150e+03                  , pde-loss 1.1116e-12, initc-loss 2.4869e+04                    bc_loss 1.3656e+07\n",
      "Epoch 3730, Training-Loss 5.1413e+03, Data-loss 3.7664e+03                  , pde-loss 1.0900e-12, initc-loss 2.4663e+04                    bc_loss 1.3724e+07\n",
      "Epoch 3740, Training-Loss 4.8866e+03, Data-loss 3.5049e+03                  , pde-loss 1.1546e-12, initc-loss 2.4458e+04                    bc_loss 1.3793e+07\n",
      "Epoch 3750, Training-Loss 5.1581e+03, Data-loss 3.7697e+03                  , pde-loss 1.1361e-12, initc-loss 2.4258e+04                    bc_loss 1.3860e+07\n",
      "Epoch 3760, Training-Loss 4.7811e+03, Data-loss 3.3860e+03                  , pde-loss 1.2291e-12, initc-loss 2.4061e+04                    bc_loss 1.3927e+07\n",
      "Epoch 3770, Training-Loss 5.1224e+03, Data-loss 3.7208e+03                  , pde-loss 1.1173e-12, initc-loss 2.3868e+04                    bc_loss 1.3993e+07\n",
      "Epoch 3780, Training-Loss 4.6366e+03, Data-loss 3.2284e+03                  , pde-loss 1.2125e-12, initc-loss 2.3676e+04                    bc_loss 1.4059e+07\n",
      "Epoch 3790, Training-Loss 4.9034e+03, Data-loss 3.4887e+03                  , pde-loss 1.2207e-12, initc-loss 2.3489e+04                    bc_loss 1.4123e+07\n",
      "Epoch 3800, Training-Loss 4.8286e+03, Data-loss 3.4075e+03                  , pde-loss 1.2045e-12, initc-loss 2.3306e+04                    bc_loss 1.4187e+07\n",
      "Epoch 3810, Training-Loss 4.3386e+03, Data-loss 2.9113e+03                  , pde-loss 1.2938e-12, initc-loss 2.3126e+04                    bc_loss 1.4250e+07\n",
      "Epoch 3820, Training-Loss 4.3479e+03, Data-loss 2.9144e+03                  , pde-loss 1.2851e-12, initc-loss 2.2951e+04                    bc_loss 1.4312e+07\n",
      "Epoch 3830, Training-Loss 4.5784e+03, Data-loss 3.1388e+03                  , pde-loss 1.2463e-12, initc-loss 2.2777e+04                    bc_loss 1.4373e+07\n",
      "Epoch 3840, Training-Loss 4.5960e+03, Data-loss 3.1503e+03                  , pde-loss 1.2807e-12, initc-loss 2.2606e+04                    bc_loss 1.4434e+07\n",
      "Epoch 3850, Training-Loss 4.7588e+03, Data-loss 3.3070e+03                  , pde-loss 1.3093e-12, initc-loss 2.2435e+04                    bc_loss 1.4496e+07\n",
      "Epoch 3860, Training-Loss 4.5266e+03, Data-loss 3.0687e+03                  , pde-loss 1.3295e-12, initc-loss 2.2267e+04                    bc_loss 1.4556e+07\n",
      "Epoch 3870, Training-Loss 4.5094e+03, Data-loss 3.0456e+03                  , pde-loss 1.3813e-12, initc-loss 2.2102e+04                    bc_loss 1.4616e+07\n",
      "Epoch 3880, Training-Loss 4.4037e+03, Data-loss 2.9340e+03                  , pde-loss 1.4060e-12, initc-loss 2.1939e+04                    bc_loss 1.4675e+07\n",
      "Epoch 3890, Training-Loss 4.3697e+03, Data-loss 2.8940e+03                  , pde-loss 1.3545e-12, initc-loss 2.1777e+04                    bc_loss 1.4735e+07\n",
      "Epoch 3900, Training-Loss 4.2315e+03, Data-loss 2.7500e+03                  , pde-loss 1.4756e-12, initc-loss 2.1617e+04                    bc_loss 1.4794e+07\n",
      "Epoch 3910, Training-Loss 4.3781e+03, Data-loss 2.8908e+03                  , pde-loss 1.4178e-12, initc-loss 2.1460e+04                    bc_loss 1.4852e+07\n",
      "Epoch 3920, Training-Loss 4.2451e+03, Data-loss 2.7520e+03                  , pde-loss 1.3915e-12, initc-loss 2.1307e+04                    bc_loss 1.4909e+07\n",
      "Epoch 3930, Training-Loss 4.4993e+03, Data-loss 3.0005e+03                  , pde-loss 1.3858e-12, initc-loss 2.1154e+04                    bc_loss 1.4966e+07\n",
      "Epoch 3940, Training-Loss 4.2897e+03, Data-loss 2.7853e+03                  , pde-loss 1.4131e-12, initc-loss 2.1004e+04                    bc_loss 1.5023e+07\n",
      "Epoch 3950, Training-Loss 4.3038e+03, Data-loss 2.7938e+03                  , pde-loss 1.5605e-12, initc-loss 2.0856e+04                    bc_loss 1.5079e+07\n",
      "Epoch 3960, Training-Loss 3.9775e+03, Data-loss 2.4620e+03                  , pde-loss 1.6075e-12, initc-loss 2.0712e+04                    bc_loss 1.5134e+07\n",
      "Epoch 3970, Training-Loss 3.8712e+03, Data-loss 2.3504e+03                  , pde-loss 1.6036e-12, initc-loss 2.0573e+04                    bc_loss 1.5187e+07\n",
      "Epoch 3980, Training-Loss 4.3051e+03, Data-loss 2.7791e+03                  , pde-loss 1.4918e-12, initc-loss 2.0436e+04                    bc_loss 1.5240e+07\n",
      "Epoch 3990, Training-Loss 4.0051e+03, Data-loss 2.4739e+03                  , pde-loss 1.5580e-12, initc-loss 2.0301e+04                    bc_loss 1.5293e+07\n",
      "Epoch 4000, Training-Loss 4.2543e+03, Data-loss 2.7177e+03                  , pde-loss 1.6879e-12, initc-loss 2.0165e+04                    bc_loss 1.5345e+07\n",
      "Epoch 4010, Training-Loss 4.1677e+03, Data-loss 2.6260e+03                  , pde-loss 1.5973e-12, initc-loss 2.0032e+04                    bc_loss 1.5397e+07\n",
      "Epoch 4020, Training-Loss 4.0735e+03, Data-loss 2.5266e+03                  , pde-loss 1.6971e-12, initc-loss 1.9900e+04                    bc_loss 1.5449e+07\n",
      "Epoch 4030, Training-Loss 3.8408e+03, Data-loss 2.2888e+03                  , pde-loss 1.7632e-12, initc-loss 1.9773e+04                    bc_loss 1.5499e+07\n",
      "Epoch 4040, Training-Loss 4.0931e+03, Data-loss 2.5363e+03                  , pde-loss 1.6769e-12, initc-loss 1.9650e+04                    bc_loss 1.5548e+07\n",
      "Epoch 4050, Training-Loss 4.0454e+03, Data-loss 2.4838e+03                  , pde-loss 1.7584e-12, initc-loss 1.9529e+04                    bc_loss 1.5597e+07\n",
      "Epoch 4060, Training-Loss 4.0429e+03, Data-loss 2.4765e+03                  , pde-loss 1.7658e-12, initc-loss 1.9410e+04                    bc_loss 1.5644e+07\n",
      "Epoch 4070, Training-Loss 3.9723e+03, Data-loss 2.4012e+03                  , pde-loss 1.8602e-12, initc-loss 1.9290e+04                    bc_loss 1.5692e+07\n",
      "Epoch 4080, Training-Loss 3.7868e+03, Data-loss 2.2109e+03                  , pde-loss 1.9192e-12, initc-loss 1.9173e+04                    bc_loss 1.5740e+07\n",
      "Epoch 4090, Training-Loss 3.6956e+03, Data-loss 2.1150e+03                  , pde-loss 1.8092e-12, initc-loss 1.9058e+04                    bc_loss 1.5786e+07\n",
      "Epoch 4100, Training-Loss 3.8511e+03, Data-loss 2.2659e+03                  , pde-loss 1.8831e-12, initc-loss 1.8943e+04                    bc_loss 1.5833e+07\n",
      "Epoch 4110, Training-Loss 3.7643e+03, Data-loss 2.1745e+03                  , pde-loss 1.9085e-12, initc-loss 1.8832e+04                    bc_loss 1.5879e+07\n",
      "Epoch 4120, Training-Loss 3.7444e+03, Data-loss 2.1502e+03                  , pde-loss 2.0311e-12, initc-loss 1.8723e+04                    bc_loss 1.5924e+07\n",
      "Epoch 4130, Training-Loss 3.8994e+03, Data-loss 2.3007e+03                  , pde-loss 2.0336e-12, initc-loss 1.8616e+04                    bc_loss 1.5968e+07\n",
      "Epoch 4140, Training-Loss 3.8405e+03, Data-loss 2.2374e+03                  , pde-loss 2.0026e-12, initc-loss 1.8510e+04                    bc_loss 1.6012e+07\n",
      "Epoch 4150, Training-Loss 3.9256e+03, Data-loss 2.3182e+03                  , pde-loss 1.9358e-12, initc-loss 1.8407e+04                    bc_loss 1.6055e+07\n",
      "Epoch 4160, Training-Loss 3.8689e+03, Data-loss 2.2572e+03                  , pde-loss 2.1232e-12, initc-loss 1.8303e+04                    bc_loss 1.6098e+07\n",
      "Epoch 4170, Training-Loss 3.5637e+03, Data-loss 1.9478e+03                  , pde-loss 2.2059e-12, initc-loss 1.8203e+04                    bc_loss 1.6140e+07\n",
      "Epoch 4180, Training-Loss 3.9620e+03, Data-loss 2.3421e+03                  , pde-loss 2.0684e-12, initc-loss 1.8107e+04                    bc_loss 1.6181e+07\n",
      "Epoch 4190, Training-Loss 3.2805e+03, Data-loss 1.6565e+03                  , pde-loss 2.2284e-12, initc-loss 1.8010e+04                    bc_loss 1.6222e+07\n",
      "Epoch 4200, Training-Loss 3.8095e+03, Data-loss 2.1815e+03                  , pde-loss 2.2136e-12, initc-loss 1.7915e+04                    bc_loss 1.6262e+07\n",
      "Epoch 4210, Training-Loss 3.7532e+03, Data-loss 2.1212e+03                  , pde-loss 2.2228e-12, initc-loss 1.7823e+04                    bc_loss 1.6302e+07\n",
      "Epoch 4220, Training-Loss 3.8454e+03, Data-loss 2.2095e+03                  , pde-loss 2.1998e-12, initc-loss 1.7730e+04                    bc_loss 1.6341e+07\n",
      "Epoch 4230, Training-Loss 3.5972e+03, Data-loss 1.9573e+03                  , pde-loss 2.3094e-12, initc-loss 1.7637e+04                    bc_loss 1.6381e+07\n",
      "Epoch 4240, Training-Loss 3.3398e+03, Data-loss 1.6958e+03                  , pde-loss 2.4540e-12, initc-loss 1.7544e+04                    bc_loss 1.6422e+07\n",
      "Epoch 4250, Training-Loss 3.6301e+03, Data-loss 1.9823e+03                  , pde-loss 2.3859e-12, initc-loss 1.7453e+04                    bc_loss 1.6461e+07\n",
      "Epoch 4260, Training-Loss 3.5470e+03, Data-loss 1.8952e+03                  , pde-loss 2.4684e-12, initc-loss 1.7363e+04                    bc_loss 1.6500e+07\n",
      "Epoch 4270, Training-Loss 3.4289e+03, Data-loss 1.7735e+03                  , pde-loss 2.4383e-12, initc-loss 1.7278e+04                    bc_loss 1.6537e+07\n",
      "Epoch 4280, Training-Loss 3.6841e+03, Data-loss 2.0252e+03                  , pde-loss 2.5350e-12, initc-loss 1.7198e+04                    bc_loss 1.6573e+07\n",
      "Epoch 4290, Training-Loss 3.5052e+03, Data-loss 1.8427e+03                  , pde-loss 2.6376e-12, initc-loss 1.7119e+04                    bc_loss 1.6607e+07\n",
      "Epoch 4300, Training-Loss 3.4264e+03, Data-loss 1.7605e+03                  , pde-loss 2.6003e-12, initc-loss 1.7041e+04                    bc_loss 1.6642e+07\n",
      "Epoch 4310, Training-Loss 3.7036e+03, Data-loss 2.0343e+03                  , pde-loss 2.5990e-12, initc-loss 1.6963e+04                    bc_loss 1.6676e+07\n",
      "Epoch 4320, Training-Loss 3.5078e+03, Data-loss 1.8350e+03                  , pde-loss 2.5796e-12, initc-loss 1.6885e+04                    bc_loss 1.6711e+07\n",
      "Epoch 4330, Training-Loss 3.6822e+03, Data-loss 2.0060e+03                  , pde-loss 2.7394e-12, initc-loss 1.6806e+04                    bc_loss 1.6746e+07\n",
      "Epoch 4340, Training-Loss 3.4823e+03, Data-loss 1.8026e+03                  , pde-loss 2.9596e-12, initc-loss 1.6729e+04                    bc_loss 1.6780e+07\n",
      "Epoch 4350, Training-Loss 3.4422e+03, Data-loss 1.7592e+03                  , pde-loss 2.8039e-12, initc-loss 1.6656e+04                    bc_loss 1.6813e+07\n",
      "Epoch 4360, Training-Loss 3.5386e+03, Data-loss 1.8524e+03                  , pde-loss 2.8771e-12, initc-loss 1.6584e+04                    bc_loss 1.6846e+07\n",
      "Epoch 4370, Training-Loss 3.5603e+03, Data-loss 1.8708e+03                  , pde-loss 2.8245e-12, initc-loss 1.6511e+04                    bc_loss 1.6879e+07\n",
      "Epoch 4380, Training-Loss 3.5020e+03, Data-loss 1.8092e+03                  , pde-loss 3.0019e-12, initc-loss 1.6438e+04                    bc_loss 1.6912e+07\n",
      "Epoch 4390, Training-Loss 3.3547e+03, Data-loss 1.6588e+03                  , pde-loss 2.9782e-12, initc-loss 1.6369e+04                    bc_loss 1.6943e+07\n",
      "Epoch 4400, Training-Loss 3.4980e+03, Data-loss 1.7991e+03                  , pde-loss 2.9916e-12, initc-loss 1.6303e+04                    bc_loss 1.6973e+07\n",
      "Epoch 4410, Training-Loss 3.5696e+03, Data-loss 1.8677e+03                  , pde-loss 2.9540e-12, initc-loss 1.6239e+04                    bc_loss 1.7002e+07\n",
      "Epoch 4420, Training-Loss 3.1774e+03, Data-loss 1.4727e+03                  , pde-loss 3.1761e-12, initc-loss 1.6177e+04                    bc_loss 1.7031e+07\n",
      "Epoch 4430, Training-Loss 3.4369e+03, Data-loss 1.7296e+03                  , pde-loss 3.2359e-12, initc-loss 1.6119e+04                    bc_loss 1.7058e+07\n",
      "Epoch 4440, Training-Loss 3.5847e+03, Data-loss 1.8746e+03                  , pde-loss 3.2176e-12, initc-loss 1.6059e+04                    bc_loss 1.7085e+07\n",
      "Epoch 4450, Training-Loss 3.4743e+03, Data-loss 1.7613e+03                  , pde-loss 3.4303e-12, initc-loss 1.5998e+04                    bc_loss 1.7113e+07\n",
      "Epoch 4460, Training-Loss 3.4781e+03, Data-loss 1.7624e+03                  , pde-loss 3.3142e-12, initc-loss 1.5938e+04                    bc_loss 1.7141e+07\n",
      "Epoch 4470, Training-Loss 3.3056e+03, Data-loss 1.5872e+03                  , pde-loss 3.4905e-12, initc-loss 1.5881e+04                    bc_loss 1.7167e+07\n",
      "Epoch 4480, Training-Loss 3.5178e+03, Data-loss 1.7969e+03                  , pde-loss 3.5217e-12, initc-loss 1.5825e+04                    bc_loss 1.7193e+07\n",
      "Epoch 4490, Training-Loss 3.4603e+03, Data-loss 1.7369e+03                  , pde-loss 3.8144e-12, initc-loss 1.5773e+04                    bc_loss 1.7218e+07\n",
      "Epoch 4500, Training-Loss 3.2506e+03, Data-loss 1.5248e+03                  , pde-loss 3.5126e-12, initc-loss 1.5721e+04                    bc_loss 1.7242e+07\n",
      "Epoch 4510, Training-Loss 3.2431e+03, Data-loss 1.5149e+03                  , pde-loss 3.7509e-12, initc-loss 1.5669e+04                    bc_loss 1.7266e+07\n",
      "Epoch 4520, Training-Loss 3.2373e+03, Data-loss 1.5067e+03                  , pde-loss 3.8986e-12, initc-loss 1.5620e+04                    bc_loss 1.7290e+07\n",
      "Epoch 4530, Training-Loss 3.3941e+03, Data-loss 1.6613e+03                  , pde-loss 3.8759e-12, initc-loss 1.5572e+04                    bc_loss 1.7312e+07\n",
      "Epoch 4540, Training-Loss 3.3839e+03, Data-loss 1.6488e+03                  , pde-loss 3.9631e-12, initc-loss 1.5522e+04                    bc_loss 1.7336e+07\n",
      "Epoch 4550, Training-Loss 3.4300e+03, Data-loss 1.6925e+03                  , pde-loss 4.1682e-12, initc-loss 1.5472e+04                    bc_loss 1.7360e+07\n",
      "Epoch 4560, Training-Loss 3.4872e+03, Data-loss 1.7474e+03                  , pde-loss 4.1670e-12, initc-loss 1.5423e+04                    bc_loss 1.7382e+07\n",
      "Epoch 4570, Training-Loss 3.4577e+03, Data-loss 1.7158e+03                  , pde-loss 4.2269e-12, initc-loss 1.5378e+04                    bc_loss 1.7404e+07\n",
      "Epoch 4580, Training-Loss 3.3236e+03, Data-loss 1.5795e+03                  , pde-loss 4.1008e-12, initc-loss 1.5333e+04                    bc_loss 1.7425e+07\n",
      "Epoch 4590, Training-Loss 3.5081e+03, Data-loss 1.7620e+03                  , pde-loss 4.0233e-12, initc-loss 1.5291e+04                    bc_loss 1.7446e+07\n",
      "Epoch 4600, Training-Loss 3.3535e+03, Data-loss 1.6053e+03                  , pde-loss 4.2293e-12, initc-loss 1.5247e+04                    bc_loss 1.7466e+07\n",
      "Epoch 4610, Training-Loss 3.4292e+03, Data-loss 1.6790e+03                  , pde-loss 4.5922e-12, initc-loss 1.5204e+04                    bc_loss 1.7487e+07\n",
      "Epoch 4620, Training-Loss 3.3187e+03, Data-loss 1.5665e+03                  , pde-loss 4.8813e-12, initc-loss 1.5164e+04                    bc_loss 1.7506e+07\n",
      "Epoch 4630, Training-Loss 3.4223e+03, Data-loss 1.6683e+03                  , pde-loss 4.7270e-12, initc-loss 1.5124e+04                    bc_loss 1.7525e+07\n",
      "Epoch 4640, Training-Loss 3.3428e+03, Data-loss 1.5869e+03                  , pde-loss 4.7385e-12, initc-loss 1.5086e+04                    bc_loss 1.7544e+07\n",
      "Epoch 4650, Training-Loss 3.4981e+03, Data-loss 1.7404e+03                  , pde-loss 4.6993e-12, initc-loss 1.5049e+04                    bc_loss 1.7562e+07\n",
      "Epoch 4660, Training-Loss 3.3339e+03, Data-loss 1.5743e+03                  , pde-loss 4.5729e-12, initc-loss 1.5010e+04                    bc_loss 1.7580e+07\n",
      "Epoch 4670, Training-Loss 3.3311e+03, Data-loss 1.5699e+03                  , pde-loss 4.6635e-12, initc-loss 1.4975e+04                    bc_loss 1.7598e+07\n",
      "Epoch 4680, Training-Loss 3.1499e+03, Data-loss 1.3869e+03                  , pde-loss 5.0323e-12, initc-loss 1.4938e+04                    bc_loss 1.7616e+07\n",
      "Epoch 4690, Training-Loss 3.1767e+03, Data-loss 1.4117e+03                  , pde-loss 5.3717e-12, initc-loss 1.4899e+04                    bc_loss 1.7634e+07\n",
      "Epoch 4700, Training-Loss 3.3879e+03, Data-loss 1.6211e+03                  , pde-loss 5.3264e-12, initc-loss 1.4861e+04                    bc_loss 1.7653e+07\n",
      "Epoch 4710, Training-Loss 3.3756e+03, Data-loss 1.6071e+03                  , pde-loss 5.3189e-12, initc-loss 1.4827e+04                    bc_loss 1.7670e+07\n",
      "Epoch 4720, Training-Loss 3.3629e+03, Data-loss 1.5929e+03                  , pde-loss 5.4377e-12, initc-loss 1.4795e+04                    bc_loss 1.7685e+07\n",
      "Epoch 4730, Training-Loss 3.3977e+03, Data-loss 1.6262e+03                  , pde-loss 5.5087e-12, initc-loss 1.4764e+04                    bc_loss 1.7700e+07\n",
      "Epoch 4740, Training-Loss 3.2103e+03, Data-loss 1.4374e+03                  , pde-loss 5.4515e-12, initc-loss 1.4736e+04                    bc_loss 1.7714e+07\n",
      "Epoch 4750, Training-Loss 3.5747e+03, Data-loss 1.8004e+03                  , pde-loss 5.7300e-12, initc-loss 1.4706e+04                    bc_loss 1.7729e+07\n",
      "Epoch 4760, Training-Loss 3.1968e+03, Data-loss 1.4208e+03                  , pde-loss 6.0792e-12, initc-loss 1.4672e+04                    bc_loss 1.7746e+07\n",
      "Epoch 4770, Training-Loss 3.2781e+03, Data-loss 1.5005e+03                  , pde-loss 5.8096e-12, initc-loss 1.4640e+04                    bc_loss 1.7761e+07\n",
      "Epoch 4780, Training-Loss 3.3292e+03, Data-loss 1.5503e+03                  , pde-loss 6.0949e-12, initc-loss 1.4613e+04                    bc_loss 1.7775e+07\n",
      "Epoch 4790, Training-Loss 3.2408e+03, Data-loss 1.4605e+03                  , pde-loss 6.6284e-12, initc-loss 1.4586e+04                    bc_loss 1.7788e+07\n",
      "Epoch 4800, Training-Loss 3.5003e+03, Data-loss 1.7187e+03                  , pde-loss 6.0006e-12, initc-loss 1.4559e+04                    bc_loss 1.7801e+07\n",
      "Epoch 4810, Training-Loss 3.1971e+03, Data-loss 1.4140e+03                  , pde-loss 6.6584e-12, initc-loss 1.4529e+04                    bc_loss 1.7816e+07\n",
      "Epoch 4820, Training-Loss 3.4543e+03, Data-loss 1.6697e+03                  , pde-loss 6.8957e-12, initc-loss 1.4499e+04                    bc_loss 1.7831e+07\n",
      "Epoch 4830, Training-Loss 3.2558e+03, Data-loss 1.4700e+03                  , pde-loss 6.7109e-12, initc-loss 1.4472e+04                    bc_loss 1.7844e+07\n",
      "Epoch 4840, Training-Loss 3.3730e+03, Data-loss 1.5858e+03                  , pde-loss 6.6495e-12, initc-loss 1.4446e+04                    bc_loss 1.7857e+07\n",
      "Epoch 4850, Training-Loss 3.2414e+03, Data-loss 1.4529e+03                  , pde-loss 7.3765e-12, initc-loss 1.4421e+04                    bc_loss 1.7870e+07\n",
      "Epoch 4860, Training-Loss 3.2828e+03, Data-loss 1.4932e+03                  , pde-loss 6.8174e-12, initc-loss 1.4397e+04                    bc_loss 1.7881e+07\n",
      "Epoch 4870, Training-Loss 3.3727e+03, Data-loss 1.5818e+03                  , pde-loss 7.2659e-12, initc-loss 1.4372e+04                    bc_loss 1.7894e+07\n",
      "Epoch 4880, Training-Loss 3.3967e+03, Data-loss 1.6046e+03                  , pde-loss 7.3046e-12, initc-loss 1.4348e+04                    bc_loss 1.7906e+07\n",
      "Epoch 4890, Training-Loss 3.3368e+03, Data-loss 1.5435e+03                  , pde-loss 7.9295e-12, initc-loss 1.4321e+04                    bc_loss 1.7920e+07\n",
      "Epoch 4900, Training-Loss 3.2729e+03, Data-loss 1.4783e+03                  , pde-loss 8.1770e-12, initc-loss 1.4297e+04                    bc_loss 1.7932e+07\n",
      "Epoch 4910, Training-Loss 3.2054e+03, Data-loss 1.4098e+03                  , pde-loss 8.2304e-12, initc-loss 1.4277e+04                    bc_loss 1.7942e+07\n",
      "Epoch 4920, Training-Loss 3.2782e+03, Data-loss 1.4816e+03                  , pde-loss 8.2599e-12, initc-loss 1.4258e+04                    bc_loss 1.7951e+07\n",
      "Epoch 4930, Training-Loss 3.3847e+03, Data-loss 1.5872e+03                  , pde-loss 7.8370e-12, initc-loss 1.4239e+04                    bc_loss 1.7961e+07\n",
      "Epoch 4940, Training-Loss 3.2226e+03, Data-loss 1.4242e+03                  , pde-loss 8.3259e-12, initc-loss 1.4221e+04                    bc_loss 1.7970e+07\n",
      "Epoch 4950, Training-Loss 3.3593e+03, Data-loss 1.5599e+03                  , pde-loss 9.4225e-12, initc-loss 1.4202e+04                    bc_loss 1.7979e+07\n",
      "Epoch 4960, Training-Loss 3.4126e+03, Data-loss 1.6124e+03                  , pde-loss 8.8567e-12, initc-loss 1.4184e+04                    bc_loss 1.7988e+07\n",
      "Epoch 4970, Training-Loss 3.2824e+03, Data-loss 1.4812e+03                  , pde-loss 8.9638e-12, initc-loss 1.4165e+04                    bc_loss 1.7998e+07\n",
      "Epoch 4980, Training-Loss 3.3952e+03, Data-loss 1.5930e+03                  , pde-loss 9.0690e-12, initc-loss 1.4145e+04                    bc_loss 1.8008e+07\n",
      "Epoch 4990, Training-Loss 3.4636e+03, Data-loss 1.6604e+03                  , pde-loss 9.5239e-12, initc-loss 1.4126e+04                    bc_loss 1.8018e+07\n",
      "Epoch 5000, Training-Loss 3.1503e+03, Data-loss 1.3461e+03                  , pde-loss 9.5767e-12, initc-loss 1.4106e+04                    bc_loss 1.8028e+07\n",
      "Epoch 5010, Training-Loss 3.4216e+03, Data-loss 1.6164e+03                  , pde-loss 9.4811e-12, initc-loss 1.4085e+04                    bc_loss 1.8038e+07\n",
      "Epoch 5020, Training-Loss 3.5169e+03, Data-loss 1.7105e+03                  , pde-loss 1.0734e-11, initc-loss 1.4063e+04                    bc_loss 1.8050e+07\n",
      "Epoch 5030, Training-Loss 3.3630e+03, Data-loss 1.5556e+03                  , pde-loss 1.0550e-11, initc-loss 1.4043e+04                    bc_loss 1.8060e+07\n",
      "Epoch 5040, Training-Loss 3.1087e+03, Data-loss 1.3005e+03                  , pde-loss 1.1035e-11, initc-loss 1.4027e+04                    bc_loss 1.8068e+07\n",
      "Epoch 5050, Training-Loss 3.3658e+03, Data-loss 1.5570e+03                  , pde-loss 1.0827e-11, initc-loss 1.4014e+04                    bc_loss 1.8074e+07\n",
      "Epoch 5060, Training-Loss 3.5842e+03, Data-loss 1.7746e+03                  , pde-loss 1.1025e-11, initc-loss 1.3998e+04                    bc_loss 1.8083e+07\n",
      "Epoch 5070, Training-Loss 3.4290e+03, Data-loss 1.6183e+03                  , pde-loss 1.1098e-11, initc-loss 1.3978e+04                    bc_loss 1.8093e+07\n",
      "Epoch 5080, Training-Loss 3.4248e+03, Data-loss 1.6133e+03                  , pde-loss 1.1185e-11, initc-loss 1.3961e+04                    bc_loss 1.8101e+07\n",
      "Epoch 5090, Training-Loss 3.3693e+03, Data-loss 1.5570e+03                  , pde-loss 1.2567e-11, initc-loss 1.3945e+04                    bc_loss 1.8109e+07\n",
      "Epoch 5100, Training-Loss 3.3736e+03, Data-loss 1.5605e+03                  , pde-loss 1.2070e-11, initc-loss 1.3931e+04                    bc_loss 1.8117e+07\n",
      "Epoch 5110, Training-Loss 3.3381e+03, Data-loss 1.5244e+03                  , pde-loss 1.2270e-11, initc-loss 1.3919e+04                    bc_loss 1.8123e+07\n",
      "Epoch 5120, Training-Loss 3.1884e+03, Data-loss 1.3741e+03                  , pde-loss 1.2710e-11, initc-loss 1.3907e+04                    bc_loss 1.8129e+07\n",
      "Epoch 5130, Training-Loss 3.2407e+03, Data-loss 1.4256e+03                  , pde-loss 1.3393e-11, initc-loss 1.3892e+04                    bc_loss 1.8137e+07\n",
      "Epoch 5140, Training-Loss 3.3830e+03, Data-loss 1.5675e+03                  , pde-loss 1.3450e-11, initc-loss 1.3882e+04                    bc_loss 1.8142e+07\n",
      "Epoch 5150, Training-Loss 3.5371e+03, Data-loss 1.7212e+03                  , pde-loss 1.3048e-11, initc-loss 1.3875e+04                    bc_loss 1.8145e+07\n",
      "Epoch 5160, Training-Loss 3.4501e+03, Data-loss 1.6336e+03                  , pde-loss 1.4037e-11, initc-loss 1.3863e+04                    bc_loss 1.8151e+07\n",
      "Epoch 5170, Training-Loss 3.3193e+03, Data-loss 1.5022e+03                  , pde-loss 1.4182e-11, initc-loss 1.3853e+04                    bc_loss 1.8157e+07\n",
      "Epoch 5180, Training-Loss 3.2644e+03, Data-loss 1.4470e+03                  , pde-loss 1.5898e-11, initc-loss 1.3846e+04                    bc_loss 1.8160e+07\n",
      "Epoch 5190, Training-Loss 3.3992e+03, Data-loss 1.5814e+03                  , pde-loss 1.5887e-11, initc-loss 1.3836e+04                    bc_loss 1.8165e+07\n",
      "Epoch 5200, Training-Loss 3.3621e+03, Data-loss 1.5438e+03                  , pde-loss 1.4826e-11, initc-loss 1.3828e+04                    bc_loss 1.8169e+07\n",
      "Epoch 5210, Training-Loss 3.2134e+03, Data-loss 1.3946e+03                  , pde-loss 1.6752e-11, initc-loss 1.3818e+04                    bc_loss 1.8175e+07\n",
      "Epoch 5220, Training-Loss 3.5311e+03, Data-loss 1.7117e+03                  , pde-loss 1.4667e-11, initc-loss 1.3807e+04                    bc_loss 1.8180e+07\n",
      "Epoch 5230, Training-Loss 3.1940e+03, Data-loss 1.3740e+03                  , pde-loss 1.7130e-11, initc-loss 1.3795e+04                    bc_loss 1.8186e+07\n",
      "Epoch 5240, Training-Loss 3.2302e+03, Data-loss 1.4098e+03                  , pde-loss 1.6573e-11, initc-loss 1.3786e+04                    bc_loss 1.8191e+07\n",
      "Epoch 5250, Training-Loss 3.6826e+03, Data-loss 1.8617e+03                  , pde-loss 1.7811e-11, initc-loss 1.3778e+04                    bc_loss 1.8195e+07\n",
      "Epoch 5260, Training-Loss 3.5035e+03, Data-loss 1.6822e+03                  , pde-loss 1.7624e-11, initc-loss 1.3769e+04                    bc_loss 1.8200e+07\n",
      "Epoch 5270, Training-Loss 3.3218e+03, Data-loss 1.5001e+03                  , pde-loss 1.9192e-11, initc-loss 1.3761e+04                    bc_loss 1.8204e+07\n",
      "Epoch 5280, Training-Loss 3.2048e+03, Data-loss 1.3827e+03                  , pde-loss 1.9453e-11, initc-loss 1.3753e+04                    bc_loss 1.8208e+07\n",
      "Epoch 5290, Training-Loss 3.3053e+03, Data-loss 1.4828e+03                  , pde-loss 1.8895e-11, initc-loss 1.3745e+04                    bc_loss 1.8212e+07\n",
      "Epoch 5300, Training-Loss 3.3409e+03, Data-loss 1.5178e+03                  , pde-loss 1.9657e-11, initc-loss 1.3734e+04                    bc_loss 1.8217e+07\n",
      "Epoch 5310, Training-Loss 3.1742e+03, Data-loss 1.3504e+03                  , pde-loss 2.0094e-11, initc-loss 1.3722e+04                    bc_loss 1.8224e+07\n",
      "Epoch 5320, Training-Loss 3.3753e+03, Data-loss 1.5510e+03                  , pde-loss 2.1675e-11, initc-loss 1.3712e+04                    bc_loss 1.8229e+07\n",
      "Epoch 5330, Training-Loss 3.4919e+03, Data-loss 1.6672e+03                  , pde-loss 2.0656e-11, initc-loss 1.3705e+04                    bc_loss 1.8233e+07\n",
      "Epoch 5340, Training-Loss 3.4299e+03, Data-loss 1.6047e+03                  , pde-loss 2.0411e-11, initc-loss 1.3693e+04                    bc_loss 1.8239e+07\n",
      "Epoch 5350, Training-Loss 3.3621e+03, Data-loss 1.5364e+03                  , pde-loss 2.1595e-11, initc-loss 1.3684e+04                    bc_loss 1.8244e+07\n",
      "Epoch 5360, Training-Loss 3.3493e+03, Data-loss 1.5231e+03                  , pde-loss 2.2942e-11, initc-loss 1.3674e+04                    bc_loss 1.8248e+07\n",
      "Epoch 5370, Training-Loss 3.4028e+03, Data-loss 1.5759e+03                  , pde-loss 2.2704e-11, initc-loss 1.3660e+04                    bc_loss 1.8256e+07\n",
      "Epoch 5380, Training-Loss 3.3262e+03, Data-loss 1.4987e+03                  , pde-loss 2.5429e-11, initc-loss 1.3649e+04                    bc_loss 1.8261e+07\n",
      "Epoch 5390, Training-Loss 3.2025e+03, Data-loss 1.3747e+03                  , pde-loss 2.5056e-11, initc-loss 1.3643e+04                    bc_loss 1.8264e+07\n",
      "Epoch 5400, Training-Loss 3.2230e+03, Data-loss 1.3949e+03                  , pde-loss 2.6117e-11, initc-loss 1.3636e+04                    bc_loss 1.8268e+07\n",
      "Epoch 5410, Training-Loss 3.2287e+03, Data-loss 1.4002e+03                  , pde-loss 2.7356e-11, initc-loss 1.3630e+04                    bc_loss 1.8272e+07\n",
      "Epoch 5420, Training-Loss 3.2654e+03, Data-loss 1.4368e+03                  , pde-loss 2.8115e-11, initc-loss 1.3626e+04                    bc_loss 1.8273e+07\n",
      "Epoch 5430, Training-Loss 3.2912e+03, Data-loss 1.4625e+03                  , pde-loss 2.6672e-11, initc-loss 1.3626e+04                    bc_loss 1.8273e+07\n",
      "Epoch 5440, Training-Loss 3.2228e+03, Data-loss 1.3941e+03                  , pde-loss 2.7094e-11, initc-loss 1.3627e+04                    bc_loss 1.8273e+07\n",
      "Epoch 5450, Training-Loss 3.3897e+03, Data-loss 1.5610e+03                  , pde-loss 2.9113e-11, initc-loss 1.3628e+04                    bc_loss 1.8273e+07\n",
      "Epoch 5460, Training-Loss 3.4292e+03, Data-loss 1.6006e+03                  , pde-loss 3.0781e-11, initc-loss 1.3629e+04                    bc_loss 1.8272e+07\n",
      "Epoch 5470, Training-Loss 3.3827e+03, Data-loss 1.5541e+03                  , pde-loss 3.3809e-11, initc-loss 1.3628e+04                    bc_loss 1.8272e+07\n",
      "Epoch 5480, Training-Loss 3.4799e+03, Data-loss 1.6509e+03                  , pde-loss 3.3882e-11, initc-loss 1.3621e+04                    bc_loss 1.8276e+07\n",
      "Epoch 5490, Training-Loss 3.3112e+03, Data-loss 1.4818e+03                  , pde-loss 3.1163e-11, initc-loss 1.3612e+04                    bc_loss 1.8280e+07\n",
      "Epoch 5500, Training-Loss 3.3017e+03, Data-loss 1.4718e+03                  , pde-loss 3.8522e-11, initc-loss 1.3602e+04                    bc_loss 1.8286e+07\n",
      "Epoch 5510, Training-Loss 3.1956e+03, Data-loss 1.3652e+03                  , pde-loss 3.7706e-11, initc-loss 1.3594e+04                    bc_loss 1.8290e+07\n",
      "Epoch 5520, Training-Loss 3.3362e+03, Data-loss 1.5056e+03                  , pde-loss 3.8037e-11, initc-loss 1.3590e+04                    bc_loss 1.8292e+07\n",
      "Epoch 5530, Training-Loss 3.2738e+03, Data-loss 1.4430e+03                  , pde-loss 3.7379e-11, initc-loss 1.3586e+04                    bc_loss 1.8294e+07\n",
      "Epoch 5540, Training-Loss 3.3415e+03, Data-loss 1.5106e+03                  , pde-loss 3.9788e-11, initc-loss 1.3584e+04                    bc_loss 1.8295e+07\n",
      "Epoch 5550, Training-Loss 3.3464e+03, Data-loss 1.5155e+03                  , pde-loss 3.6493e-11, initc-loss 1.3583e+04                    bc_loss 1.8296e+07\n",
      "Epoch 5560, Training-Loss 3.5228e+03, Data-loss 1.6915e+03                  , pde-loss 3.8219e-11, initc-loss 1.3576e+04                    bc_loss 1.8299e+07\n",
      "Epoch 5570, Training-Loss 3.2896e+03, Data-loss 1.4581e+03                  , pde-loss 4.1477e-11, initc-loss 1.3573e+04                    bc_loss 1.8301e+07\n",
      "Epoch 5580, Training-Loss 3.2368e+03, Data-loss 1.4052e+03                  , pde-loss 4.4390e-11, initc-loss 1.3570e+04                    bc_loss 1.8302e+07\n",
      "Epoch 5590, Training-Loss 3.3187e+03, Data-loss 1.4871e+03                  , pde-loss 4.5394e-11, initc-loss 1.3569e+04                    bc_loss 1.8303e+07\n",
      "Epoch 5600, Training-Loss 3.2303e+03, Data-loss 1.3986e+03                  , pde-loss 4.9466e-11, initc-loss 1.3567e+04                    bc_loss 1.8304e+07\n",
      "Epoch 5610, Training-Loss 3.4064e+03, Data-loss 1.5743e+03                  , pde-loss 4.7196e-11, initc-loss 1.3560e+04                    bc_loss 1.8307e+07\n",
      "Epoch 5620, Training-Loss 3.3579e+03, Data-loss 1.5255e+03                  , pde-loss 4.9944e-11, initc-loss 1.3556e+04                    bc_loss 1.8310e+07\n",
      "Epoch 5630, Training-Loss 3.2459e+03, Data-loss 1.4135e+03                  , pde-loss 4.9406e-11, initc-loss 1.3555e+04                    bc_loss 1.8310e+07\n",
      "Epoch 5640, Training-Loss 3.2568e+03, Data-loss 1.4243e+03                  , pde-loss 5.9942e-11, initc-loss 1.3554e+04                    bc_loss 1.8311e+07\n",
      "Epoch 5650, Training-Loss 3.3165e+03, Data-loss 1.4839e+03                  , pde-loss 5.3877e-11, initc-loss 1.3550e+04                    bc_loss 1.8313e+07\n",
      "Epoch 5660, Training-Loss 3.2536e+03, Data-loss 1.4207e+03                  , pde-loss 5.6127e-11, initc-loss 1.3546e+04                    bc_loss 1.8315e+07\n",
      "Epoch 5670, Training-Loss 3.3894e+03, Data-loss 1.5563e+03                  , pde-loss 5.9314e-11, initc-loss 1.3542e+04                    bc_loss 1.8317e+07\n",
      "Epoch 5680, Training-Loss 3.3257e+03, Data-loss 1.4926e+03                  , pde-loss 5.9206e-11, initc-loss 1.3540e+04                    bc_loss 1.8318e+07\n",
      "Epoch 5690, Training-Loss 3.1244e+03, Data-loss 1.2909e+03                  , pde-loss 5.8715e-11, initc-loss 1.3534e+04                    bc_loss 1.8321e+07\n",
      "Epoch 5700, Training-Loss 3.3873e+03, Data-loss 1.5536e+03                  , pde-loss 6.4304e-11, initc-loss 1.3530e+04                    bc_loss 1.8323e+07\n",
      "Epoch 5710, Training-Loss 3.3397e+03, Data-loss 1.5060e+03                  , pde-loss 7.0783e-11, initc-loss 1.3529e+04                    bc_loss 1.8324e+07\n",
      "Epoch 5720, Training-Loss 3.2787e+03, Data-loss 1.4449e+03                  , pde-loss 7.1510e-11, initc-loss 1.3528e+04                    bc_loss 1.8324e+07\n",
      "Epoch 5730, Training-Loss 3.1681e+03, Data-loss 1.3342e+03                  , pde-loss 7.4262e-11, initc-loss 1.3525e+04                    bc_loss 1.8326e+07\n",
      "Epoch 5740, Training-Loss 3.2281e+03, Data-loss 1.3940e+03                  , pde-loss 6.9792e-11, initc-loss 1.3522e+04                    bc_loss 1.8327e+07\n",
      "Epoch 5750, Training-Loss 3.2782e+03, Data-loss 1.4440e+03                  , pde-loss 7.1814e-11, initc-loss 1.3520e+04                    bc_loss 1.8329e+07\n",
      "Epoch 5760, Training-Loss 3.3413e+03, Data-loss 1.5067e+03                  , pde-loss 8.0930e-11, initc-loss 1.3512e+04                    bc_loss 1.8333e+07\n",
      "Epoch 5770, Training-Loss 3.5026e+03, Data-loss 1.6677e+03                  , pde-loss 9.6253e-11, initc-loss 1.3507e+04                    bc_loss 1.8335e+07\n",
      "Epoch 5780, Training-Loss 3.4415e+03, Data-loss 1.6067e+03                  , pde-loss 8.7724e-11, initc-loss 1.3508e+04                    bc_loss 1.8335e+07\n",
      "Epoch 5790, Training-Loss 3.6375e+03, Data-loss 1.8026e+03                  , pde-loss 9.4954e-11, initc-loss 1.3506e+04                    bc_loss 1.8335e+07\n",
      "Epoch 5800, Training-Loss 3.4445e+03, Data-loss 1.6098e+03                  , pde-loss 1.0169e-10, initc-loss 1.3509e+04                    bc_loss 1.8334e+07\n",
      "Epoch 5810, Training-Loss 3.1537e+03, Data-loss 1.3194e+03                  , pde-loss 1.0076e-10, initc-loss 1.3518e+04                    bc_loss 1.8329e+07\n",
      "Epoch 5820, Training-Loss 3.3868e+03, Data-loss 1.5529e+03                  , pde-loss 1.0517e-10, initc-loss 1.3526e+04                    bc_loss 1.8325e+07\n",
      "Epoch 5830, Training-Loss 3.1118e+03, Data-loss 1.2780e+03                  , pde-loss 1.0498e-10, initc-loss 1.3528e+04                    bc_loss 1.8324e+07\n",
      "Epoch 5840, Training-Loss 3.3875e+03, Data-loss 1.5540e+03                  , pde-loss 1.1703e-10, initc-loss 1.3533e+04                    bc_loss 1.8322e+07\n",
      "Epoch 5850, Training-Loss 3.3066e+03, Data-loss 1.4734e+03                  , pde-loss 1.0431e-10, initc-loss 1.3538e+04                    bc_loss 1.8319e+07\n",
      "Epoch 5860, Training-Loss 3.5431e+03, Data-loss 1.7098e+03                  , pde-loss 1.1495e-10, initc-loss 1.3537e+04                    bc_loss 1.8319e+07\n",
      "Epoch 5870, Training-Loss 3.3555e+03, Data-loss 1.5221e+03                  , pde-loss 1.0979e-10, initc-loss 1.3535e+04                    bc_loss 1.8321e+07\n",
      "Epoch 5880, Training-Loss 3.6253e+03, Data-loss 1.7917e+03                  , pde-loss 1.2600e-10, initc-loss 1.3531e+04                    bc_loss 1.8323e+07\n",
      "Epoch 5890, Training-Loss 3.3094e+03, Data-loss 1.4755e+03                  , pde-loss 1.3482e-10, initc-loss 1.3527e+04                    bc_loss 1.8325e+07\n",
      "Epoch 5900, Training-Loss 3.2406e+03, Data-loss 1.4067e+03                  , pde-loss 1.6560e-10, initc-loss 1.3526e+04                    bc_loss 1.8325e+07\n",
      "Epoch 5910, Training-Loss 3.3533e+03, Data-loss 1.5197e+03                  , pde-loss 1.3747e-10, initc-loss 1.3531e+04                    bc_loss 1.8323e+07\n",
      "Epoch 5920, Training-Loss 3.4785e+03, Data-loss 1.6450e+03                  , pde-loss 1.4726e-10, initc-loss 1.3532e+04                    bc_loss 1.8322e+07\n",
      "Epoch 5930, Training-Loss 3.1493e+03, Data-loss 1.3156e+03                  , pde-loss 1.7007e-10, initc-loss 1.3530e+04                    bc_loss 1.8323e+07\n",
      "Epoch 5940, Training-Loss 3.2209e+03, Data-loss 1.3871e+03                  , pde-loss 1.9634e-10, initc-loss 1.3527e+04                    bc_loss 1.8325e+07\n",
      "Epoch 5950, Training-Loss 3.2987e+03, Data-loss 1.4651e+03                  , pde-loss 1.6154e-10, initc-loss 1.3531e+04                    bc_loss 1.8322e+07\n",
      "Epoch 5960, Training-Loss 3.4666e+03, Data-loss 1.6329e+03                  , pde-loss 1.8873e-10, initc-loss 1.3530e+04                    bc_loss 1.8323e+07\n",
      "Epoch 5970, Training-Loss 3.2263e+03, Data-loss 1.3924e+03                  , pde-loss 1.8379e-10, initc-loss 1.3525e+04                    bc_loss 1.8326e+07\n",
      "Epoch 5980, Training-Loss 3.4297e+03, Data-loss 1.5954e+03                  , pde-loss 1.9680e-10, initc-loss 1.3518e+04                    bc_loss 1.8329e+07\n",
      "Epoch 5990, Training-Loss 3.3420e+03, Data-loss 1.5072e+03                  , pde-loss 2.0300e-10, initc-loss 1.3510e+04                    bc_loss 1.8334e+07\n",
      "Epoch 6000, Training-Loss 3.2121e+03, Data-loss 1.3773e+03                  , pde-loss 2.1666e-10, initc-loss 1.3508e+04                    bc_loss 1.8335e+07\n",
      "Epoch 6010, Training-Loss 3.5657e+03, Data-loss 1.7311e+03                  , pde-loss 2.5254e-10, initc-loss 1.3512e+04                    bc_loss 1.8333e+07\n",
      "Epoch 6020, Training-Loss 3.3709e+03, Data-loss 1.5365e+03                  , pde-loss 2.8618e-10, initc-loss 1.3516e+04                    bc_loss 1.8331e+07\n",
      "Epoch 6030, Training-Loss 3.2979e+03, Data-loss 1.4640e+03                  , pde-loss 3.1825e-10, initc-loss 1.3526e+04                    bc_loss 1.8325e+07\n",
      "Epoch 6040, Training-Loss 3.3537e+03, Data-loss 1.5204e+03                  , pde-loss 2.8479e-10, initc-loss 1.3537e+04                    bc_loss 1.8320e+07\n",
      "Epoch 6050, Training-Loss 3.1405e+03, Data-loss 1.3073e+03                  , pde-loss 2.7725e-10, initc-loss 1.3539e+04                    bc_loss 1.8318e+07\n",
      "Epoch 6060, Training-Loss 3.4426e+03, Data-loss 1.6096e+03                  , pde-loss 3.2921e-10, initc-loss 1.3543e+04                    bc_loss 1.8317e+07\n",
      "Epoch 6070, Training-Loss 3.1494e+03, Data-loss 1.3159e+03                  , pde-loss 3.4588e-10, initc-loss 1.3534e+04                    bc_loss 1.8321e+07\n",
      "Epoch 6080, Training-Loss 3.3258e+03, Data-loss 1.4922e+03                  , pde-loss 3.5219e-10, initc-loss 1.3532e+04                    bc_loss 1.8322e+07\n",
      "Epoch 6090, Training-Loss 3.2706e+03, Data-loss 1.4368e+03                  , pde-loss 3.8033e-10, initc-loss 1.3528e+04                    bc_loss 1.8324e+07\n",
      "Epoch 6100, Training-Loss 3.3294e+03, Data-loss 1.4950e+03                  , pde-loss 4.2678e-10, initc-loss 1.3516e+04                    bc_loss 1.8330e+07\n",
      "Epoch 6110, Training-Loss 3.3891e+03, Data-loss 1.5545e+03                  , pde-loss 4.6124e-10, initc-loss 1.3513e+04                    bc_loss 1.8332e+07\n",
      "Epoch 6120, Training-Loss 3.3200e+03, Data-loss 1.4853e+03                  , pde-loss 5.1173e-10, initc-loss 1.3510e+04                    bc_loss 1.8333e+07\n",
      "Epoch 6130, Training-Loss 3.2520e+03, Data-loss 1.4174e+03                  , pde-loss 4.2853e-10, initc-loss 1.3512e+04                    bc_loss 1.8332e+07\n",
      "Epoch 6140, Training-Loss 3.2135e+03, Data-loss 1.3787e+03                  , pde-loss 5.1121e-10, initc-loss 1.3508e+04                    bc_loss 1.8334e+07\n",
      "Epoch 6150, Training-Loss 3.2426e+03, Data-loss 1.4075e+03                  , pde-loss 5.8585e-10, initc-loss 1.3503e+04                    bc_loss 1.8337e+07\n",
      "Epoch 6160, Training-Loss 3.2397e+03, Data-loss 1.4046e+03                  , pde-loss 5.9006e-10, initc-loss 1.3502e+04                    bc_loss 1.8338e+07\n",
      "Epoch 6170, Training-Loss 3.5758e+03, Data-loss 1.7407e+03                  , pde-loss 6.6324e-10, initc-loss 1.3503e+04                    bc_loss 1.8337e+07\n",
      "Epoch 6180, Training-Loss 3.2297e+03, Data-loss 1.3946e+03                  , pde-loss 6.5843e-10, initc-loss 1.3502e+04                    bc_loss 1.8338e+07\n",
      "Epoch 6190, Training-Loss 3.1909e+03, Data-loss 1.3558e+03                  , pde-loss 6.8755e-10, initc-loss 1.3502e+04                    bc_loss 1.8338e+07\n",
      "Epoch 6200, Training-Loss 3.2699e+03, Data-loss 1.4346e+03                  , pde-loss 8.9415e-10, initc-loss 1.3500e+04                    bc_loss 1.8339e+07\n",
      "Epoch 6210, Training-Loss 3.2078e+03, Data-loss 1.3726e+03                  , pde-loss 9.1250e-10, initc-loss 1.3502e+04                    bc_loss 1.8338e+07\n",
      "Epoch 6220, Training-Loss 3.2954e+03, Data-loss 1.4608e+03                  , pde-loss 9.9748e-10, initc-loss 1.3513e+04                    bc_loss 1.8332e+07\n",
      "Epoch 6230, Training-Loss 3.3292e+03, Data-loss 1.4949e+03                  , pde-loss 1.2277e-09, initc-loss 1.3519e+04                    bc_loss 1.8329e+07\n",
      "Epoch 6240, Training-Loss 3.3658e+03, Data-loss 1.5319e+03                  , pde-loss 1.3479e-09, initc-loss 1.3525e+04                    bc_loss 1.8326e+07\n",
      "Epoch 6250, Training-Loss 3.3704e+03, Data-loss 1.5367e+03                  , pde-loss 1.4487e-09, initc-loss 1.3530e+04                    bc_loss 1.8323e+07\n",
      "Epoch 6260, Training-Loss 3.1331e+03, Data-loss 1.2996e+03                  , pde-loss 1.4315e-09, initc-loss 1.3534e+04                    bc_loss 1.8321e+07\n",
      "Epoch 6270, Training-Loss 3.6168e+03, Data-loss 1.7834e+03                  , pde-loss 1.9667e-09, initc-loss 1.3535e+04                    bc_loss 1.8320e+07\n",
      "Epoch 6280, Training-Loss 3.4674e+03, Data-loss 1.6340e+03                  , pde-loss 1.8522e-09, initc-loss 1.3536e+04                    bc_loss 1.8320e+07\n",
      "Epoch 6290, Training-Loss 3.3032e+03, Data-loss 1.4696e+03                  , pde-loss 1.9819e-09, initc-loss 1.3531e+04                    bc_loss 1.8323e+07\n",
      "Epoch 6300, Training-Loss 3.5789e+03, Data-loss 1.7450e+03                  , pde-loss 2.3372e-09, initc-loss 1.3525e+04                    bc_loss 1.8326e+07\n",
      "Epoch 6310, Training-Loss 3.0121e+03, Data-loss 1.1777e+03                  , pde-loss 2.1711e-09, initc-loss 1.3516e+04                    bc_loss 1.8331e+07\n",
      "Epoch 6320, Training-Loss 3.4409e+03, Data-loss 1.6062e+03                  , pde-loss 2.9828e-09, initc-loss 1.3511e+04                    bc_loss 1.8333e+07\n",
      "Epoch 6330, Training-Loss 3.4131e+03, Data-loss 1.5781e+03                  , pde-loss 4.3066e-09, initc-loss 1.3505e+04                    bc_loss 1.8336e+07\n",
      "Epoch 6340, Training-Loss 3.3290e+03, Data-loss 1.4937e+03                  , pde-loss 4.7772e-09, initc-loss 1.3500e+04                    bc_loss 1.8339e+07\n",
      "Epoch 6350, Training-Loss 3.4762e+03, Data-loss 1.6411e+03                  , pde-loss 5.5018e-09, initc-loss 1.3503e+04                    bc_loss 1.8338e+07\n",
      "Epoch 6360, Training-Loss 3.3252e+03, Data-loss 1.4897e+03                  , pde-loss 5.6054e-09, initc-loss 1.3496e+04                    bc_loss 1.8341e+07\n",
      "Epoch 6370, Training-Loss 3.2922e+03, Data-loss 1.4564e+03                  , pde-loss 6.9044e-09, initc-loss 1.3488e+04                    bc_loss 1.8345e+07\n",
      "Epoch 6380, Training-Loss 3.3114e+03, Data-loss 1.4753e+03                  , pde-loss 1.0778e-08, initc-loss 1.3482e+04                    bc_loss 1.8348e+07\n",
      "Epoch 6390, Training-Loss 3.3114e+03, Data-loss 1.4751e+03                  , pde-loss 1.3438e-08, initc-loss 1.3480e+04                    bc_loss 1.8349e+07\n",
      "Epoch 6400, Training-Loss 3.1229e+03, Data-loss 1.2867e+03                  , pde-loss 1.3698e-08, initc-loss 1.3482e+04                    bc_loss 1.8348e+07\n",
      "Epoch 6410, Training-Loss 3.2028e+03, Data-loss 1.3665e+03                  , pde-loss 1.8596e-08, initc-loss 1.3480e+04                    bc_loss 1.8349e+07\n",
      "Epoch 6420, Training-Loss 3.1723e+03, Data-loss 1.3359e+03                  , pde-loss 2.2986e-08, initc-loss 1.3476e+04                    bc_loss 1.8351e+07\n",
      "Epoch 6430, Training-Loss 3.5125e+03, Data-loss 1.6762e+03                  , pde-loss 3.8404e-08, initc-loss 1.3479e+04                    bc_loss 1.8350e+07\n",
      "Epoch 6440, Training-Loss 3.2133e+03, Data-loss 1.3771e+03                  , pde-loss 3.2308e-08, initc-loss 1.3482e+04                    bc_loss 1.8348e+07\n",
      "Epoch 6450, Training-Loss 3.2009e+03, Data-loss 1.3647e+03                  , pde-loss 7.8826e-08, initc-loss 1.3481e+04                    bc_loss 1.8349e+07\n",
      "Epoch 6460, Training-Loss 3.3698e+03, Data-loss 1.5337e+03                  , pde-loss 1.3839e-07, initc-loss 1.3484e+04                    bc_loss 1.8347e+07\n",
      "Epoch 6470, Training-Loss 3.3321e+03, Data-loss 1.4962e+03                  , pde-loss 2.3900e-07, initc-loss 1.3487e+04                    bc_loss 1.8346e+07\n",
      "Epoch 6480, Training-Loss 3.3956e+03, Data-loss 1.5602e+03                  , pde-loss 4.1586e-07, initc-loss 1.3496e+04                    bc_loss 1.8341e+07\n",
      "Epoch 6490, Training-Loss 3.2050e+03, Data-loss 1.3698e+03                  , pde-loss 1.2375e-06, initc-loss 1.3500e+04                    bc_loss 1.8339e+07\n",
      "Epoch 6500, Training-Loss 3.2237e+03, Data-loss 1.3885e+03                  , pde-loss 3.5870e-06, initc-loss 1.3501e+04                    bc_loss 1.8339e+07\n",
      "Epoch 6510, Training-Loss 3.4858e+03, Data-loss 1.6504e+03                  , pde-loss 4.9016e-05, initc-loss 1.3498e+04                    bc_loss 1.8340e+07\n",
      "Epoch 6520, Training-Loss 3.3261e+03, Data-loss 1.4904e+03                  , pde-loss 5.2490e-04, initc-loss 1.3492e+04                    bc_loss 1.8343e+07\n",
      "Epoch 6530, Training-Loss 3.1814e+03, Data-loss 1.3458e+03                  , pde-loss 6.4390e-03, initc-loss 1.3488e+04                    bc_loss 1.8343e+07\n",
      "Epoch 6540, Training-Loss 3.3021e+03, Data-loss 1.4712e+03                  , pde-loss 8.4962e-01, initc-loss 1.3493e+04                    bc_loss 1.8295e+07\n",
      "Epoch 6550, Training-Loss 2.9472e+03, Data-loss 1.2283e+03                  , pde-loss 2.7848e+02, initc-loss 1.3532e+04                    bc_loss 1.7175e+07\n",
      "Epoch 6560, Training-Loss 2.8676e+03, Data-loss 1.1662e+03                  , pde-loss 6.2073e+02, initc-loss 1.3372e+04                    bc_loss 1.7000e+07\n",
      "Epoch 6570, Training-Loss 2.7056e+03, Data-loss 1.0129e+03                  , pde-loss 7.7540e+02, initc-loss 1.3208e+04                    bc_loss 1.6912e+07\n",
      "Epoch 6580, Training-Loss 2.7818e+03, Data-loss 1.0914e+03                  , pde-loss 1.0290e+03, initc-loss 1.3037e+04                    bc_loss 1.6890e+07\n",
      "Epoch 6590, Training-Loss 2.5475e+03, Data-loss 8.4423e+02                  , pde-loss 9.7428e+02, initc-loss 1.2858e+04                    bc_loss 1.7018e+07\n",
      "Epoch 6600, Training-Loss 2.7364e+03, Data-loss 1.0435e+03                  , pde-loss 7.9201e+02, initc-loss 1.2708e+04                    bc_loss 1.6915e+07\n",
      "Epoch 6610, Training-Loss 2.6947e+03, Data-loss 9.9905e+02                  , pde-loss 8.0300e+02, initc-loss 1.2576e+04                    bc_loss 1.6943e+07\n",
      "Epoch 6620, Training-Loss 2.5506e+03, Data-loss 8.7365e+02                  , pde-loss 7.6537e+02, initc-loss 1.2592e+04                    bc_loss 1.6756e+07\n",
      "Epoch 6630, Training-Loss 2.7499e+03, Data-loss 1.0688e+03                  , pde-loss 6.0937e+02, initc-loss 1.2686e+04                    bc_loss 1.6797e+07\n",
      "Epoch 6640, Training-Loss 2.5884e+03, Data-loss 9.0049e+02                  , pde-loss 5.0507e+02, initc-loss 1.2808e+04                    bc_loss 1.6866e+07\n",
      "Epoch 6650, Training-Loss 2.6790e+03, Data-loss 9.8801e+02                  , pde-loss 5.3787e+02, initc-loss 1.2975e+04                    bc_loss 1.6897e+07\n",
      "Epoch 6660, Training-Loss 2.5504e+03, Data-loss 8.4749e+02                  , pde-loss 5.4151e+02, initc-loss 1.2859e+04                    bc_loss 1.7015e+07\n",
      "Epoch 6670, Training-Loss 2.6322e+03, Data-loss 9.5573e+02                  , pde-loss 6.3944e+02, initc-loss 1.3970e+04                    bc_loss 1.6750e+07\n",
      "Epoch 6680, Training-Loss 2.4544e+03, Data-loss 7.3872e+02                  , pde-loss 5.9159e+02, initc-loss 1.3178e+04                    bc_loss 1.7143e+07\n",
      "Epoch 6690, Training-Loss 2.5750e+03, Data-loss 8.8541e+02                  , pde-loss 6.6603e+02, initc-loss 1.4248e+04                    bc_loss 1.6881e+07\n",
      "Epoch 6700, Training-Loss 2.4689e+03, Data-loss 7.5710e+02                  , pde-loss 6.1952e+02, initc-loss 1.4146e+04                    bc_loss 1.7104e+07\n",
      "Epoch 6710, Training-Loss 2.4898e+03, Data-loss 7.8391e+02                  , pde-loss 7.6227e+02, initc-loss 1.4768e+04                    bc_loss 1.7044e+07\n",
      "Epoch 6720, Training-Loss 2.5854e+03, Data-loss 8.7463e+02                  , pde-loss 8.2840e+02, initc-loss 1.4416e+04                    bc_loss 1.7093e+07\n",
      "Epoch 6730, Training-Loss 2.5627e+03, Data-loss 8.4736e+02                  , pde-loss 8.1215e+02, initc-loss 1.4648e+04                    bc_loss 1.7138e+07\n",
      "Epoch 6740, Training-Loss 2.3452e+03, Data-loss 6.2568e+02                  , pde-loss 8.5755e+02, initc-loss 1.4422e+04                    bc_loss 1.7180e+07\n",
      "Epoch 6750, Training-Loss 2.4385e+03, Data-loss 7.3159e+02                  , pde-loss 9.3217e+02, initc-loss 1.4416e+04                    bc_loss 1.7054e+07\n",
      "Epoch 6760, Training-Loss 2.2603e+03, Data-loss 5.5362e+02                  , pde-loss 9.9994e+02, initc-loss 1.4466e+04                    bc_loss 1.7051e+07\n",
      "Epoch 6770, Training-Loss 2.2471e+03, Data-loss 5.3201e+02                  , pde-loss 8.2884e+02, initc-loss 1.4716e+04                    bc_loss 1.7135e+07\n",
      "Epoch 6780, Training-Loss 2.4887e+03, Data-loss 7.6667e+02                  , pde-loss 9.3013e+02, initc-loss 1.4345e+04                    bc_loss 1.7205e+07\n",
      "Epoch 6790, Training-Loss 2.3282e+03, Data-loss 6.0752e+02                  , pde-loss 1.0960e+03, initc-loss 1.4415e+04                    bc_loss 1.7191e+07\n",
      "Epoch 6800, Training-Loss 2.2781e+03, Data-loss 5.4668e+02                  , pde-loss 1.0510e+03, initc-loss 1.4289e+04                    bc_loss 1.7299e+07\n",
      "Epoch 6810, Training-Loss 2.2972e+03, Data-loss 5.5560e+02                  , pde-loss 9.8539e+02, initc-loss 1.3958e+04                    bc_loss 1.7401e+07\n",
      "Epoch 6820, Training-Loss 2.3406e+03, Data-loss 6.0175e+02                  , pde-loss 9.5009e+02, initc-loss 1.4125e+04                    bc_loss 1.7373e+07\n",
      "Epoch 6830, Training-Loss 2.3161e+03, Data-loss 5.9754e+02                  , pde-loss 9.9246e+02, initc-loss 1.5099e+04                    bc_loss 1.7170e+07\n",
      "Epoch 6840, Training-Loss 2.3198e+03, Data-loss 6.1263e+02                  , pde-loss 1.0877e+03, initc-loss 1.5427e+04                    bc_loss 1.7055e+07\n",
      "Epoch 6850, Training-Loss 2.2335e+03, Data-loss 5.1472e+02                  , pde-loss 1.1514e+03, initc-loss 1.4693e+04                    bc_loss 1.7172e+07\n",
      "Epoch 6860, Training-Loss 2.3355e+03, Data-loss 6.0682e+02                  , pde-loss 1.0123e+03, initc-loss 1.4365e+04                    bc_loss 1.7272e+07\n",
      "Epoch 6870, Training-Loss 2.3039e+03, Data-loss 5.8129e+02                  , pde-loss 1.0475e+03, initc-loss 1.4815e+04                    bc_loss 1.7211e+07\n",
      "Epoch 6880, Training-Loss 2.2557e+03, Data-loss 5.1694e+02                  , pde-loss 1.0434e+03, initc-loss 1.3965e+04                    bc_loss 1.7373e+07\n",
      "Epoch 6890, Training-Loss 2.2333e+03, Data-loss 5.0308e+02                  , pde-loss 1.1381e+03, initc-loss 1.4451e+04                    bc_loss 1.7287e+07\n",
      "Epoch 6900, Training-Loss 2.1764e+03, Data-loss 4.5171e+02                  , pde-loss 1.1094e+03, initc-loss 1.4586e+04                    bc_loss 1.7231e+07\n",
      "Epoch 6910, Training-Loss 2.1589e+03, Data-loss 4.2227e+02                  , pde-loss 1.1460e+03, initc-loss 1.3901e+04                    bc_loss 1.7351e+07\n",
      "Epoch 6920, Training-Loss 2.1239e+03, Data-loss 3.9607e+02                  , pde-loss 1.1209e+03, initc-loss 1.4151e+04                    bc_loss 1.7264e+07\n",
      "Epoch 6930, Training-Loss 2.2370e+03, Data-loss 5.1427e+02                  , pde-loss 1.0696e+03, initc-loss 1.4345e+04                    bc_loss 1.7212e+07\n",
      "Epoch 6940, Training-Loss 2.2540e+03, Data-loss 5.3961e+02                  , pde-loss 1.1368e+03, initc-loss 1.4506e+04                    bc_loss 1.7128e+07\n",
      "Epoch 6950, Training-Loss 2.1636e+03, Data-loss 4.3766e+02                  , pde-loss 1.1936e+03, initc-loss 1.4031e+04                    bc_loss 1.7244e+07\n",
      "Epoch 6960, Training-Loss 2.2375e+03, Data-loss 5.0865e+02                  , pde-loss 1.2084e+03, initc-loss 1.3708e+04                    bc_loss 1.7273e+07\n",
      "Epoch 6970, Training-Loss 2.2177e+03, Data-loss 5.0515e+02                  , pde-loss 1.2535e+03, initc-loss 1.4094e+04                    bc_loss 1.7110e+07\n",
      "Epoch 6980, Training-Loss 2.2812e+03, Data-loss 5.7389e+02                  , pde-loss 1.1331e+03, initc-loss 1.4076e+04                    bc_loss 1.7058e+07\n",
      "Epoch 6990, Training-Loss 2.1393e+03, Data-loss 4.2450e+02                  , pde-loss 1.1448e+03, initc-loss 1.3990e+04                    bc_loss 1.7133e+07\n",
      "Epoch 7000, Training-Loss 2.1981e+03, Data-loss 4.8266e+02                  , pde-loss 1.2130e+03, initc-loss 1.3553e+04                    bc_loss 1.7140e+07\n",
      "Epoch 7010, Training-Loss 2.1937e+03, Data-loss 5.0867e+02                  , pde-loss 1.1578e+03, initc-loss 1.3859e+04                    bc_loss 1.6835e+07\n",
      "Epoch 7020, Training-Loss 2.1611e+03, Data-loss 4.8289e+02                  , pde-loss 1.1743e+03, initc-loss 1.4176e+04                    bc_loss 1.6767e+07\n",
      "Epoch 7030, Training-Loss 2.0568e+03, Data-loss 4.2152e+02                  , pde-loss 1.2555e+03, initc-loss 1.4681e+04                    bc_loss 1.6337e+07\n",
      "Epoch 7040, Training-Loss 2.0405e+03, Data-loss 3.8601e+02                  , pde-loss 1.1497e+03, initc-loss 1.3785e+04                    bc_loss 1.6530e+07\n",
      "Epoch 7050, Training-Loss 2.1379e+03, Data-loss 5.3239e+02                  , pde-loss 1.1539e+03, initc-loss 1.4221e+04                    bc_loss 1.6040e+07\n",
      "Epoch 7060, Training-Loss 2.0404e+03, Data-loss 5.0529e+02                  , pde-loss 1.2322e+03, initc-loss 1.5104e+04                    bc_loss 1.5334e+07\n",
      "Epoch 7070, Training-Loss 2.0373e+03, Data-loss 4.7567e+02                  , pde-loss 1.2076e+03, initc-loss 1.3516e+04                    bc_loss 1.5602e+07\n",
      "Epoch 7080, Training-Loss 1.9576e+03, Data-loss 3.9412e+02                  , pde-loss 1.1585e+03, initc-loss 1.3166e+04                    bc_loss 1.5620e+07\n",
      "Epoch 7090, Training-Loss 1.9524e+03, Data-loss 4.3195e+02                  , pde-loss 1.3624e+03, initc-loss 1.3198e+04                    bc_loss 1.5190e+07\n",
      "Epoch 7100, Training-Loss 1.9382e+03, Data-loss 5.2099e+02                  , pde-loss 1.4190e+03, initc-loss 1.4204e+04                    bc_loss 1.4156e+07\n",
      "Epoch 7110, Training-Loss 1.8774e+03, Data-loss 5.0286e+02                  , pde-loss 1.4167e+03, initc-loss 1.3923e+04                    bc_loss 1.3730e+07\n",
      "Epoch 7120, Training-Loss 1.8949e+03, Data-loss 5.4290e+02                  , pde-loss 1.3411e+03, initc-loss 1.3177e+04                    bc_loss 1.3505e+07\n",
      "Epoch 7130, Training-Loss 2.0433e+03, Data-loss 5.2458e+02                  , pde-loss 9.6198e+02, initc-loss 1.1368e+04                    bc_loss 1.5175e+07\n",
      "Epoch 7140, Training-Loss 1.8722e+03, Data-loss 6.4238e+02                  , pde-loss 1.3430e+03, initc-loss 1.4434e+04                    bc_loss 1.2282e+07\n",
      "Epoch 7150, Training-Loss 1.9193e+03, Data-loss 7.2181e+02                  , pde-loss 1.1793e+03, initc-loss 1.4252e+04                    bc_loss 1.1959e+07\n",
      "Epoch 7160, Training-Loss 1.7299e+03, Data-loss 5.8212e+02                  , pde-loss 1.4066e+03, initc-loss 1.3802e+04                    bc_loss 1.1463e+07\n",
      "Epoch 7170, Training-Loss 1.6653e+03, Data-loss 5.2890e+02                  , pde-loss 1.5208e+03, initc-loss 1.3355e+04                    bc_loss 1.1349e+07\n",
      "Epoch 7180, Training-Loss 1.6325e+03, Data-loss 6.7848e+02                  , pde-loss 1.4867e+03, initc-loss 1.4173e+04                    bc_loss 9.5248e+06\n",
      "Epoch 7190, Training-Loss 1.7978e+03, Data-loss 6.6758e+02                  , pde-loss 1.0128e+03, initc-loss 1.2149e+04                    bc_loss 1.1289e+07\n",
      "Epoch 7200, Training-Loss 1.6402e+03, Data-loss 7.4886e+02                  , pde-loss 1.4301e+03, initc-loss 1.4921e+04                    bc_loss 8.8975e+06\n",
      "Epoch 7210, Training-Loss 1.5027e+03, Data-loss 6.0531e+02                  , pde-loss 1.4583e+03, initc-loss 1.4706e+04                    bc_loss 8.9579e+06\n",
      "Epoch 7220, Training-Loss 1.4942e+03, Data-loss 5.6335e+02                  , pde-loss 1.4244e+03, initc-loss 1.3669e+04                    bc_loss 9.2937e+06\n",
      "Epoch 7230, Training-Loss 1.4932e+03, Data-loss 6.9571e+02                  , pde-loss 1.4916e+03, initc-loss 1.4035e+04                    bc_loss 7.9592e+06\n",
      "Epoch 7240, Training-Loss 1.4093e+03, Data-loss 7.0585e+02                  , pde-loss 1.4665e+03, initc-loss 1.3947e+04                    bc_loss 7.0191e+06\n",
      "Epoch 7250, Training-Loss 1.5187e+03, Data-loss 8.2487e+02                  , pde-loss 1.2296e+03, initc-loss 1.3354e+04                    bc_loss 6.9233e+06\n",
      "Epoch 7260, Training-Loss 1.3820e+03, Data-loss 6.4004e+02                  , pde-loss 1.1828e+03, initc-loss 1.2941e+04                    bc_loss 7.4056e+06\n",
      "Epoch 7270, Training-Loss 1.2614e+03, Data-loss 6.8932e+02                  , pde-loss 1.2548e+03, initc-loss 1.3936e+04                    bc_loss 5.7052e+06\n",
      "Epoch 7280, Training-Loss 1.1397e+03, Data-loss 6.9670e+02                  , pde-loss 1.2835e+03, initc-loss 1.4242e+04                    bc_loss 4.4146e+06\n",
      "Epoch 7290, Training-Loss 1.0539e+03, Data-loss 7.7446e+02                  , pde-loss 1.2834e+03, initc-loss 1.4922e+04                    bc_loss 2.7777e+06\n",
      "Epoch 7300, Training-Loss 1.1076e+03, Data-loss 5.3329e+02                  , pde-loss 1.1987e+03, initc-loss 1.2983e+04                    bc_loss 5.7287e+06\n",
      "Epoch 7310, Training-Loss 1.0173e+03, Data-loss 7.9151e+02                  , pde-loss 1.2623e+03, initc-loss 1.5360e+04                    bc_loss 2.2418e+06\n",
      "Epoch 7320, Training-Loss 9.9922e+02, Data-loss 5.8736e+02                  , pde-loss 1.2334e+03, initc-loss 1.3663e+04                    bc_loss 4.1037e+06\n",
      "Epoch 7330, Training-Loss 1.0340e+03, Data-loss 7.6965e+02                  , pde-loss 1.0057e+03, initc-loss 1.2974e+04                    bc_loss 2.6293e+06\n",
      "Epoch 7340, Training-Loss 1.2187e+03, Data-loss 1.1074e+03                  , pde-loss 1.2504e+03, initc-loss 1.4985e+04                    bc_loss 1.0968e+06\n",
      "Epoch 7350, Training-Loss 8.0459e+02, Data-loss 5.6722e+02                  , pde-loss 1.1429e+03, initc-loss 1.3855e+04                    bc_loss 2.3587e+06\n",
      "Epoch 7360, Training-Loss 6.8721e+02, Data-loss 4.9820e+02                  , pde-loss 1.0693e+03, initc-loss 1.3546e+04                    bc_loss 1.8754e+06\n",
      "Epoch 7370, Training-Loss 7.1575e+02, Data-loss 6.0435e+02                  , pde-loss 1.0316e+03, initc-loss 1.3777e+04                    bc_loss 1.0991e+06\n",
      "Epoch 7380, Training-Loss 6.7855e+02, Data-loss 6.0097e+02                  , pde-loss 8.9256e+02, initc-loss 1.3679e+04                    bc_loss 7.6125e+05\n",
      "Epoch 7390, Training-Loss 6.2079e+02, Data-loss 5.5620e+02                  , pde-loss 1.0673e+03, initc-loss 1.4121e+04                    bc_loss 6.3065e+05\n",
      "Epoch 7400, Training-Loss 6.4335e+02, Data-loss 5.0637e+02                  , pde-loss 1.0140e+03, initc-loss 1.3256e+04                    bc_loss 1.3555e+06\n",
      "Epoch 7410, Training-Loss 4.2371e+02, Data-loss 3.7060e+02                  , pde-loss 1.0179e+03, initc-loss 1.4635e+04                    bc_loss 5.1543e+05\n",
      "Epoch 7420, Training-Loss 4.5390e+02, Data-loss 4.0367e+02                  , pde-loss 9.8019e+02, initc-loss 1.3742e+04                    bc_loss 4.8758e+05\n",
      "Epoch 7430, Training-Loss 4.2777e+02, Data-loss 3.8515e+02                  , pde-loss 9.5602e+02, initc-loss 1.3502e+04                    bc_loss 4.1176e+05\n",
      "Epoch 7440, Training-Loss 5.6710e+02, Data-loss 5.5063e+02                  , pde-loss 1.0084e+03, initc-loss 1.4030e+04                    bc_loss 1.4963e+05\n",
      "Epoch 7450, Training-Loss 4.3036e+02, Data-loss 3.9530e+02                  , pde-loss 9.9771e+02, initc-loss 1.3412e+04                    bc_loss 3.3624e+05\n",
      "Epoch 7460, Training-Loss 3.9494e+02, Data-loss 3.6617e+02                  , pde-loss 9.5011e+02, initc-loss 1.3162e+04                    bc_loss 2.7363e+05\n",
      "Epoch 7470, Training-Loss 3.9504e+02, Data-loss 3.4893e+02                  , pde-loss 9.4147e+02, initc-loss 1.2716e+04                    bc_loss 4.4742e+05\n",
      "Epoch 7480, Training-Loss 2.7745e+02, Data-loss 2.5789e+02                  , pde-loss 9.8457e+02, initc-loss 1.3110e+04                    bc_loss 1.8156e+05\n",
      "Epoch 7490, Training-Loss 2.4526e+02, Data-loss 2.2742e+02                  , pde-loss 1.0415e+03, initc-loss 1.3259e+04                    bc_loss 1.6410e+05\n",
      "Epoch 7500, Training-Loss 2.7833e+02, Data-loss 2.5382e+02                  , pde-loss 9.6397e+02, initc-loss 1.3197e+04                    bc_loss 2.3090e+05\n",
      "Epoch 7510, Training-Loss 2.9683e+02, Data-loss 2.8828e+02                  , pde-loss 1.0524e+03, initc-loss 1.3277e+04                    bc_loss 7.1127e+04\n",
      "Epoch 7520, Training-Loss 3.0944e+02, Data-loss 2.8795e+02                  , pde-loss 1.0448e+03, initc-loss 1.3181e+04                    bc_loss 2.0068e+05\n",
      "Epoch 7530, Training-Loss 2.5008e+02, Data-loss 2.3560e+02                  , pde-loss 1.0174e+03, initc-loss 1.3010e+04                    bc_loss 1.3072e+05\n",
      "Epoch 7540, Training-Loss 2.1014e+02, Data-loss 2.0236e+02                  , pde-loss 1.0965e+03, initc-loss 1.3130e+04                    bc_loss 6.3579e+04\n",
      "Epoch 7550, Training-Loss 2.7596e+02, Data-loss 2.6779e+02                  , pde-loss 1.0606e+03, initc-loss 1.3285e+04                    bc_loss 6.7369e+04\n",
      "Epoch 7560, Training-Loss 2.1387e+02, Data-loss 2.0137e+02                  , pde-loss 1.0745e+03, initc-loss 1.2956e+04                    bc_loss 1.1099e+05\n",
      "Epoch 7570, Training-Loss 2.3209e+02, Data-loss 2.2385e+02                  , pde-loss 1.0529e+03, initc-loss 1.2949e+04                    bc_loss 6.8414e+04\n",
      "Epoch 7580, Training-Loss 2.4083e+02, Data-loss 2.2301e+02                  , pde-loss 1.0429e+03, initc-loss 1.2769e+04                    bc_loss 1.6441e+05\n",
      "Epoch 7590, Training-Loss 2.2763e+02, Data-loss 2.1806e+02                  , pde-loss 1.0597e+03, initc-loss 1.2693e+04                    bc_loss 8.1914e+04\n",
      "Epoch 7600, Training-Loss 2.8278e+02, Data-loss 2.6686e+02                  , pde-loss 1.0547e+03, initc-loss 1.2783e+04                    bc_loss 1.4536e+05\n",
      "Epoch 7610, Training-Loss 2.2158e+02, Data-loss 2.0849e+02                  , pde-loss 1.0645e+03, initc-loss 1.2875e+04                    bc_loss 1.1697e+05\n",
      "Epoch 7620, Training-Loss 1.7389e+02, Data-loss 1.6392e+02                  , pde-loss 1.1377e+03, initc-loss 1.2850e+04                    bc_loss 8.5786e+04\n",
      "Epoch 7630, Training-Loss 2.1986e+02, Data-loss 2.1286e+02                  , pde-loss 1.1179e+03, initc-loss 1.2791e+04                    bc_loss 5.6130e+04\n",
      "Epoch 7640, Training-Loss 2.0026e+02, Data-loss 1.9307e+02                  , pde-loss 1.1109e+03, initc-loss 1.2830e+04                    bc_loss 5.7932e+04\n",
      "Epoch 7650, Training-Loss 2.7240e+02, Data-loss 2.6640e+02                  , pde-loss 1.1003e+03, initc-loss 1.3141e+04                    bc_loss 4.5818e+04\n",
      "Epoch 7660, Training-Loss 1.8459e+02, Data-loss 1.7845e+02                  , pde-loss 1.1412e+03, initc-loss 1.2959e+04                    bc_loss 4.7340e+04\n",
      "Epoch 7670, Training-Loss 1.8919e+02, Data-loss 1.8500e+02                  , pde-loss 1.1604e+03, initc-loss 1.2916e+04                    bc_loss 2.7867e+04\n",
      "Epoch 7680, Training-Loss 2.1942e+02, Data-loss 2.1554e+02                  , pde-loss 1.1857e+03, initc-loss 1.2858e+04                    bc_loss 2.4769e+04\n",
      "Epoch 7690, Training-Loss 1.8537e+02, Data-loss 1.8090e+02                  , pde-loss 1.1655e+03, initc-loss 1.3038e+04                    bc_loss 3.0517e+04\n",
      "Epoch 7700, Training-Loss 2.1444e+02, Data-loss 2.1106e+02                  , pde-loss 1.2179e+03, initc-loss 1.2769e+04                    bc_loss 1.9810e+04\n",
      "Epoch 7710, Training-Loss 1.5202e+02, Data-loss 1.4780e+02                  , pde-loss 1.1796e+03, initc-loss 1.3058e+04                    bc_loss 2.7986e+04\n",
      "Epoch 7720, Training-Loss 1.6482e+02, Data-loss 1.6136e+02                  , pde-loss 1.1948e+03, initc-loss 1.2832e+04                    bc_loss 2.0566e+04\n",
      "Epoch 7730, Training-Loss 1.5368e+02, Data-loss 1.4934e+02                  , pde-loss 1.2085e+03, initc-loss 1.2910e+04                    bc_loss 2.9244e+04\n",
      "Epoch 7740, Training-Loss 1.8412e+02, Data-loss 1.8010e+02                  , pde-loss 1.2079e+03, initc-loss 1.2724e+04                    bc_loss 2.6202e+04\n",
      "Epoch 7750, Training-Loss 1.9509e+02, Data-loss 1.8410e+02                  , pde-loss 1.2589e+03, initc-loss 1.2695e+04                    bc_loss 9.6026e+04\n",
      "Epoch 7760, Training-Loss 1.7712e+02, Data-loss 1.7016e+02                  , pde-loss 1.1643e+03, initc-loss 1.2690e+04                    bc_loss 5.5712e+04\n",
      "Epoch 7770, Training-Loss 1.5425e+02, Data-loss 1.4982e+02                  , pde-loss 1.2441e+03, initc-loss 1.2862e+04                    bc_loss 3.0142e+04\n",
      "Epoch 7780, Training-Loss 1.7531e+02, Data-loss 1.7092e+02                  , pde-loss 1.3173e+03, initc-loss 1.2951e+04                    bc_loss 2.9655e+04\n",
      "Epoch 7790, Training-Loss 1.4977e+02, Data-loss 1.4726e+02                  , pde-loss 1.2861e+03, initc-loss 1.2915e+04                    bc_loss 1.0939e+04\n",
      "Epoch 7800, Training-Loss 1.7916e+02, Data-loss 1.7604e+02                  , pde-loss 1.3315e+03, initc-loss 1.2828e+04                    bc_loss 1.6992e+04\n",
      "Epoch 7810, Training-Loss 1.7188e+02, Data-loss 1.6855e+02                  , pde-loss 1.2739e+03, initc-loss 1.2899e+04                    bc_loss 1.9171e+04\n",
      "Epoch 7820, Training-Loss 1.2745e+02, Data-loss 1.2386e+02                  , pde-loss 1.2910e+03, initc-loss 1.2809e+04                    bc_loss 2.1875e+04\n",
      "Epoch 7830, Training-Loss 1.5464e+02, Data-loss 1.5182e+02                  , pde-loss 1.2868e+03, initc-loss 1.2832e+04                    bc_loss 1.4119e+04\n",
      "Epoch 7840, Training-Loss 1.7760e+02, Data-loss 1.7464e+02                  , pde-loss 1.2286e+03, initc-loss 1.2797e+04                    bc_loss 1.5510e+04\n",
      "Epoch 7850, Training-Loss 1.5992e+02, Data-loss 1.5610e+02                  , pde-loss 1.3272e+03, initc-loss 1.2750e+04                    bc_loss 2.4061e+04\n",
      "Epoch 7860, Training-Loss 1.0424e+02, Data-loss 1.0156e+02                  , pde-loss 1.3499e+03, initc-loss 1.2786e+04                    bc_loss 1.2699e+04\n",
      "Epoch 7870, Training-Loss 1.6865e+02, Data-loss 1.6517e+02                  , pde-loss 1.2899e+03, initc-loss 1.2671e+04                    bc_loss 2.0824e+04\n",
      "Epoch 7880, Training-Loss 1.1772e+02, Data-loss 1.1471e+02                  , pde-loss 1.3457e+03, initc-loss 1.2846e+04                    bc_loss 1.5904e+04\n",
      "Epoch 7890, Training-Loss 1.1703e+02, Data-loss 1.1370e+02                  , pde-loss 1.4814e+03, initc-loss 1.2946e+04                    bc_loss 1.8844e+04\n",
      "Epoch 7900, Training-Loss 1.5761e+02, Data-loss 1.5237e+02                  , pde-loss 1.3902e+03, initc-loss 1.2769e+04                    bc_loss 3.8214e+04\n",
      "Epoch 7910, Training-Loss 1.3993e+02, Data-loss 1.3732e+02                  , pde-loss 1.4275e+03, initc-loss 1.2887e+04                    bc_loss 1.1777e+04\n",
      "Epoch 7920, Training-Loss 1.4662e+02, Data-loss 1.4344e+02                  , pde-loss 1.3517e+03, initc-loss 1.2759e+04                    bc_loss 1.7653e+04\n",
      "Epoch 7930, Training-Loss 1.3481e+02, Data-loss 1.3265e+02                  , pde-loss 1.3269e+03, initc-loss 1.2859e+04                    bc_loss 7.3434e+03\n",
      "Epoch 7940, Training-Loss 9.0523e+01, Data-loss 8.7853e+01                  , pde-loss 1.4301e+03, initc-loss 1.2950e+04                    bc_loss 1.2317e+04\n",
      "Epoch 7950, Training-Loss 1.1844e+02, Data-loss 1.1597e+02                  , pde-loss 1.3995e+03, initc-loss 1.2787e+04                    bc_loss 1.0565e+04\n",
      "Epoch 7960, Training-Loss 1.0251e+02, Data-loss 9.9814e+01                  , pde-loss 1.4623e+03, initc-loss 1.2986e+04                    bc_loss 1.2497e+04\n",
      "Epoch 7970, Training-Loss 1.1195e+02, Data-loss 1.0932e+02                  , pde-loss 1.4212e+03, initc-loss 1.2704e+04                    bc_loss 1.2257e+04\n",
      "Epoch 7980, Training-Loss 1.2055e+02, Data-loss 1.1794e+02                  , pde-loss 1.4568e+03, initc-loss 1.2814e+04                    bc_loss 1.1820e+04\n",
      "Epoch 7990, Training-Loss 1.2318e+02, Data-loss 1.2054e+02                  , pde-loss 1.5074e+03, initc-loss 1.2889e+04                    bc_loss 1.1988e+04\n",
      "Epoch 8000, Training-Loss 1.1754e+02, Data-loss 1.1526e+02                  , pde-loss 1.4293e+03, initc-loss 1.2880e+04                    bc_loss 8.4268e+03\n",
      "Epoch 8010, Training-Loss 1.1017e+02, Data-loss 1.0791e+02                  , pde-loss 1.4058e+03, initc-loss 1.2924e+04                    bc_loss 8.2702e+03\n",
      "Epoch 8020, Training-Loss 8.3254e+01, Data-loss 8.0848e+01                  , pde-loss 1.5603e+03, initc-loss 1.2830e+04                    bc_loss 9.6686e+03\n",
      "Epoch 8030, Training-Loss 1.1512e+02, Data-loss 1.1260e+02                  , pde-loss 1.5769e+03, initc-loss 1.2865e+04                    bc_loss 1.0782e+04\n",
      "Epoch 8040, Training-Loss 9.9423e+01, Data-loss 9.6771e+01                  , pde-loss 1.5926e+03, initc-loss 1.2871e+04                    bc_loss 1.2056e+04\n",
      "Epoch 8050, Training-Loss 1.0608e+02, Data-loss 1.0354e+02                  , pde-loss 1.5703e+03, initc-loss 1.2901e+04                    bc_loss 1.0979e+04\n",
      "Epoch 8060, Training-Loss 1.3495e+02, Data-loss 1.3256e+02                  , pde-loss 1.5586e+03, initc-loss 1.3143e+04                    bc_loss 9.2652e+03\n",
      "Epoch 8070, Training-Loss 9.8668e+01, Data-loss 9.5962e+01                  , pde-loss 1.5315e+03, initc-loss 1.2902e+04                    bc_loss 1.2624e+04\n",
      "Epoch 8080, Training-Loss 1.0979e+02, Data-loss 1.0682e+02                  , pde-loss 1.5452e+03, initc-loss 1.2904e+04                    bc_loss 1.5267e+04\n",
      "Epoch 8090, Training-Loss 8.6330e+01, Data-loss 8.4091e+01                  , pde-loss 1.5777e+03, initc-loss 1.2888e+04                    bc_loss 7.9250e+03\n",
      "Epoch 8100, Training-Loss 1.5765e+02, Data-loss 1.5484e+02                  , pde-loss 1.5834e+03, initc-loss 1.2860e+04                    bc_loss 1.3618e+04\n",
      "Epoch 8110, Training-Loss 9.5159e+01, Data-loss 9.2794e+01                  , pde-loss 1.4925e+03, initc-loss 1.2849e+04                    bc_loss 9.3126e+03\n",
      "Epoch 8120, Training-Loss 1.1799e+02, Data-loss 1.1272e+02                  , pde-loss 1.5578e+03, initc-loss 1.2759e+04                    bc_loss 3.8350e+04\n",
      "Epoch 8130, Training-Loss 7.9524e+01, Data-loss 7.5587e+01                  , pde-loss 1.6234e+03, initc-loss 1.2824e+04                    bc_loss 2.4923e+04\n",
      "Epoch 8140, Training-Loss 8.0870e+01, Data-loss 7.8456e+01                  , pde-loss 1.6597e+03, initc-loss 1.2917e+04                    bc_loss 9.5714e+03\n",
      "Epoch 8150, Training-Loss 1.0755e+02, Data-loss 1.0503e+02                  , pde-loss 1.6772e+03, initc-loss 1.2814e+04                    bc_loss 1.0663e+04\n",
      "Epoch 8160, Training-Loss 5.9306e+01, Data-loss 5.6894e+01                  , pde-loss 1.7802e+03, initc-loss 1.2820e+04                    bc_loss 9.5185e+03\n",
      "Epoch 8170, Training-Loss 1.0487e+02, Data-loss 1.0248e+02                  , pde-loss 1.6766e+03, initc-loss 1.2784e+04                    bc_loss 9.4026e+03\n",
      "Epoch 8180, Training-Loss 1.1865e+02, Data-loss 1.1630e+02                  , pde-loss 1.5730e+03, initc-loss 1.2856e+04                    bc_loss 9.1003e+03\n",
      "Epoch 8190, Training-Loss 5.7589e+01, Data-loss 5.5105e+01                  , pde-loss 1.8908e+03, initc-loss 1.2944e+04                    bc_loss 1.0013e+04\n",
      "Epoch 8200, Training-Loss 9.6125e+01, Data-loss 9.3549e+01                  , pde-loss 1.7502e+03, initc-loss 1.2944e+04                    bc_loss 1.1058e+04\n",
      "Epoch 8210, Training-Loss 7.6755e+01, Data-loss 7.4170e+01                  , pde-loss 1.8741e+03, initc-loss 1.2970e+04                    bc_loss 1.1008e+04\n",
      "Epoch 8220, Training-Loss 1.3127e+02, Data-loss 1.2907e+02                  , pde-loss 1.6280e+03, initc-loss 1.3073e+04                    bc_loss 7.3239e+03\n",
      "Epoch 8230, Training-Loss 9.8642e+01, Data-loss 9.6037e+01                  , pde-loss 1.7126e+03, initc-loss 1.2924e+04                    bc_loss 1.1410e+04\n",
      "Epoch 8240, Training-Loss 9.8289e+01, Data-loss 9.5795e+01                  , pde-loss 1.8038e+03, initc-loss 1.2989e+04                    bc_loss 1.0146e+04\n",
      "Epoch 8250, Training-Loss 8.7360e+01, Data-loss 8.4744e+01                  , pde-loss 1.8350e+03, initc-loss 1.2946e+04                    bc_loss 1.1378e+04\n",
      "Epoch 8260, Training-Loss 8.1672e+01, Data-loss 7.9338e+01                  , pde-loss 1.7219e+03, initc-loss 1.2962e+04                    bc_loss 8.6602e+03\n",
      "Epoch 8270, Training-Loss 9.1964e+01, Data-loss 8.8622e+01                  , pde-loss 1.8465e+03, initc-loss 1.2872e+04                    bc_loss 1.8700e+04\n",
      "Epoch 8280, Training-Loss 7.3687e+01, Data-loss 7.0736e+01                  , pde-loss 1.7981e+03, initc-loss 1.2968e+04                    bc_loss 1.4746e+04\n",
      "Epoch 8290, Training-Loss 4.2942e+01, Data-loss 4.0770e+01                  , pde-loss 1.8697e+03, initc-loss 1.2949e+04                    bc_loss 6.9052e+03\n",
      "Epoch 8300, Training-Loss 9.2353e+01, Data-loss 8.9103e+01                  , pde-loss 1.8533e+03, initc-loss 1.2833e+04                    bc_loss 1.7818e+04\n",
      "Epoch 8310, Training-Loss 9.2025e+01, Data-loss 8.9203e+01                  , pde-loss 1.8011e+03, initc-loss 1.2923e+04                    bc_loss 1.3495e+04\n",
      "Epoch 8320, Training-Loss 8.3302e+01, Data-loss 8.0606e+01                  , pde-loss 1.8706e+03, initc-loss 1.2798e+04                    bc_loss 1.2292e+04\n",
      "Epoch 8330, Training-Loss 8.4267e+01, Data-loss 8.1776e+01                  , pde-loss 1.7628e+03, initc-loss 1.2838e+04                    bc_loss 1.0316e+04\n",
      "Epoch 8340, Training-Loss 4.4507e+01, Data-loss 4.1193e+01                  , pde-loss 1.9178e+03, initc-loss 1.2935e+04                    bc_loss 1.8282e+04\n",
      "Epoch 8350, Training-Loss 8.1104e+01, Data-loss 7.8864e+01                  , pde-loss 1.9184e+03, initc-loss 1.2854e+04                    bc_loss 7.6228e+03\n",
      "Epoch 8360, Training-Loss 1.0261e+02, Data-loss 9.9070e+01                  , pde-loss 2.1126e+03, initc-loss 1.2835e+04                    bc_loss 2.0469e+04\n",
      "Epoch 8370, Training-Loss 4.6589e+01, Data-loss 4.3758e+01                  , pde-loss 2.0341e+03, initc-loss 1.2908e+04                    bc_loss 1.3367e+04\n",
      "Epoch 8380, Training-Loss 7.7817e+01, Data-loss 7.5110e+01                  , pde-loss 1.9233e+03, initc-loss 1.2840e+04                    bc_loss 1.2306e+04\n",
      "Epoch 8390, Training-Loss 7.3415e+01, Data-loss 7.0717e+01                  , pde-loss 1.9554e+03, initc-loss 1.2755e+04                    bc_loss 1.2277e+04\n",
      "Epoch 8400, Training-Loss 8.4158e+01, Data-loss 8.1965e+01                  , pde-loss 2.0962e+03, initc-loss 1.2879e+04                    bc_loss 6.9528e+03\n",
      "Epoch 8410, Training-Loss 6.4208e+01, Data-loss 6.1996e+01                  , pde-loss 2.0392e+03, initc-loss 1.3073e+04                    bc_loss 7.0148e+03\n",
      "Epoch 8420, Training-Loss 8.2004e+01, Data-loss 7.9769e+01                  , pde-loss 2.1592e+03, initc-loss 1.2860e+04                    bc_loss 7.3252e+03\n",
      "Epoch 8430, Training-Loss 7.2541e+01, Data-loss 7.0215e+01                  , pde-loss 1.9408e+03, initc-loss 1.2957e+04                    bc_loss 8.3622e+03\n",
      "Epoch 8440, Training-Loss 6.6484e+01, Data-loss 6.4104e+01                  , pde-loss 1.9934e+03, initc-loss 1.2993e+04                    bc_loss 8.8055e+03\n",
      "Epoch 8450, Training-Loss 6.5459e+01, Data-loss 6.2605e+01                  , pde-loss 2.3515e+03, initc-loss 1.2877e+04                    bc_loss 1.3312e+04\n",
      "Epoch 8460, Training-Loss 8.0809e+01, Data-loss 7.7670e+01                  , pde-loss 2.1056e+03, initc-loss 1.2760e+04                    bc_loss 1.6525e+04\n",
      "Epoch 8470, Training-Loss 4.0132e+01, Data-loss 3.7938e+01                  , pde-loss 2.0496e+03, initc-loss 1.3014e+04                    bc_loss 6.8743e+03\n",
      "Epoch 8480, Training-Loss 7.0371e+01, Data-loss 6.7844e+01                  , pde-loss 2.1768e+03, initc-loss 1.2926e+04                    bc_loss 1.0171e+04\n",
      "Epoch 8490, Training-Loss 5.9201e+01, Data-loss 5.6539e+01                  , pde-loss 2.1176e+03, initc-loss 1.2945e+04                    bc_loss 1.1549e+04\n",
      "Epoch 8500, Training-Loss 5.7466e+01, Data-loss 5.4298e+01                  , pde-loss 2.1320e+03, initc-loss 1.3085e+04                    bc_loss 1.6464e+04\n",
      "Epoch 8510, Training-Loss 4.5531e+01, Data-loss 4.2582e+01                  , pde-loss 2.2247e+03, initc-loss 1.2890e+04                    bc_loss 1.4381e+04\n",
      "Epoch 8520, Training-Loss 7.1682e+01, Data-loss 6.9024e+01                  , pde-loss 2.3286e+03, initc-loss 1.2875e+04                    bc_loss 1.1371e+04\n",
      "Epoch 8530, Training-Loss 5.7037e+01, Data-loss 5.4515e+01                  , pde-loss 2.0283e+03, initc-loss 1.2970e+04                    bc_loss 1.0223e+04\n",
      "Epoch 8540, Training-Loss 4.7926e+01, Data-loss 4.5367e+01                  , pde-loss 2.4219e+03, initc-loss 1.3099e+04                    bc_loss 1.0073e+04\n",
      "Epoch 8550, Training-Loss 6.0287e+01, Data-loss 5.8073e+01                  , pde-loss 2.1141e+03, initc-loss 1.2942e+04                    bc_loss 7.0801e+03\n",
      "Epoch 8560, Training-Loss 5.1903e+01, Data-loss 4.9634e+01                  , pde-loss 2.4344e+03, initc-loss 1.2880e+04                    bc_loss 7.3733e+03\n",
      "Epoch 8570, Training-Loss 4.2968e+01, Data-loss 4.0762e+01                  , pde-loss 2.2841e+03, initc-loss 1.2831e+04                    bc_loss 6.9469e+03\n",
      "Epoch 8580, Training-Loss 4.3583e+01, Data-loss 4.0922e+01                  , pde-loss 2.6223e+03, initc-loss 1.3008e+04                    bc_loss 1.0976e+04\n",
      "Epoch 8590, Training-Loss 6.8050e+01, Data-loss 6.5223e+01                  , pde-loss 2.3206e+03, initc-loss 1.2880e+04                    bc_loss 1.3068e+04\n",
      "Epoch 8600, Training-Loss 4.2833e+01, Data-loss 4.0348e+01                  , pde-loss 2.4129e+03, initc-loss 1.3019e+04                    bc_loss 9.4276e+03\n",
      "Epoch 8610, Training-Loss 4.7406e+01, Data-loss 4.4543e+01                  , pde-loss 2.3504e+03, initc-loss 1.2868e+04                    bc_loss 1.3410e+04\n",
      "Epoch 8620, Training-Loss 5.6845e+01, Data-loss 5.4572e+01                  , pde-loss 2.4609e+03, initc-loss 1.2904e+04                    bc_loss 7.3678e+03\n",
      "Epoch 8630, Training-Loss 4.7983e+01, Data-loss 4.5359e+01                  , pde-loss 2.3200e+03, initc-loss 1.2948e+04                    bc_loss 1.0972e+04\n",
      "Epoch 8640, Training-Loss 3.9446e+01, Data-loss 3.7282e+01                  , pde-loss 2.4405e+03, initc-loss 1.3055e+04                    bc_loss 6.1473e+03\n",
      "Epoch 8650, Training-Loss 4.7122e+01, Data-loss 4.5102e+01                  , pde-loss 2.3702e+03, initc-loss 1.3164e+04                    bc_loss 4.6660e+03\n",
      "Epoch 8660, Training-Loss 3.6785e+01, Data-loss 3.4539e+01                  , pde-loss 2.2867e+03, initc-loss 1.2787e+04                    bc_loss 7.3799e+03\n",
      "Epoch 8670, Training-Loss 4.3286e+01, Data-loss 4.0992e+01                  , pde-loss 2.6295e+03, initc-loss 1.2778e+04                    bc_loss 7.5283e+03\n",
      "Epoch 8680, Training-Loss 4.7478e+01, Data-loss 4.5318e+01                  , pde-loss 2.2383e+03, initc-loss 1.2946e+04                    bc_loss 6.4113e+03\n",
      "Epoch 8690, Training-Loss 3.7408e+01, Data-loss 3.5060e+01                  , pde-loss 2.4563e+03, initc-loss 1.3105e+04                    bc_loss 7.9237e+03\n",
      "Epoch 8700, Training-Loss 4.8480e+01, Data-loss 4.5589e+01                  , pde-loss 2.5157e+03, initc-loss 1.2834e+04                    bc_loss 1.3561e+04\n",
      "Epoch 8710, Training-Loss 4.6680e+01, Data-loss 4.4821e+01                  , pde-loss 2.5720e+03, initc-loss 1.2907e+04                    bc_loss 3.1089e+03\n",
      "Epoch 8720, Training-Loss 4.4945e+01, Data-loss 4.2713e+01                  , pde-loss 2.5447e+03, initc-loss 1.3098e+04                    bc_loss 6.6774e+03\n",
      "Epoch 8730, Training-Loss 3.4691e+01, Data-loss 3.2777e+01                  , pde-loss 2.6197e+03, initc-loss 1.2841e+04                    bc_loss 3.6834e+03\n",
      "Epoch 8740, Training-Loss 3.5812e+01, Data-loss 3.3628e+01                  , pde-loss 2.6424e+03, initc-loss 1.3050e+04                    bc_loss 6.1532e+03\n",
      "Epoch 8750, Training-Loss 3.0497e+01, Data-loss 2.8511e+01                  , pde-loss 2.6354e+03, initc-loss 1.2942e+04                    bc_loss 4.2826e+03\n",
      "Epoch 8760, Training-Loss 3.8470e+01, Data-loss 3.6354e+01                  , pde-loss 2.5698e+03, initc-loss 1.2786e+04                    bc_loss 5.8057e+03\n",
      "Epoch 8770, Training-Loss 4.1691e+01, Data-loss 3.9666e+01                  , pde-loss 2.7033e+03, initc-loss 1.2912e+04                    bc_loss 4.6348e+03\n",
      "Epoch 8780, Training-Loss 4.5502e+01, Data-loss 4.2718e+01                  , pde-loss 2.9358e+03, initc-loss 1.2823e+04                    bc_loss 1.2086e+04\n",
      "Epoch 8790, Training-Loss 4.7015e+01, Data-loss 4.3683e+01                  , pde-loss 2.5769e+03, initc-loss 1.2850e+04                    bc_loss 1.7891e+04\n",
      "Epoch 8800, Training-Loss 4.2385e+01, Data-loss 4.0115e+01                  , pde-loss 2.7186e+03, initc-loss 1.2820e+04                    bc_loss 7.1615e+03\n",
      "Epoch 8810, Training-Loss 3.2119e+01, Data-loss 3.0232e+01                  , pde-loss 2.6103e+03, initc-loss 1.2981e+04                    bc_loss 3.2823e+03\n",
      "Epoch 8820, Training-Loss 4.1938e+01, Data-loss 3.9996e+01                  , pde-loss 2.3997e+03, initc-loss 1.2940e+04                    bc_loss 4.0831e+03\n",
      "Epoch 8830, Training-Loss 4.1279e+01, Data-loss 3.8682e+01                  , pde-loss 2.8794e+03, initc-loss 1.2950e+04                    bc_loss 1.0149e+04\n",
      "Epoch 8840, Training-Loss 4.0119e+01, Data-loss 3.7796e+01                  , pde-loss 2.6746e+03, initc-loss 1.2907e+04                    bc_loss 7.6517e+03\n",
      "Epoch 8850, Training-Loss 3.4675e+01, Data-loss 3.2753e+01                  , pde-loss 2.8329e+03, initc-loss 1.2965e+04                    bc_loss 3.4172e+03\n",
      "Epoch 8860, Training-Loss 3.5834e+01, Data-loss 3.3683e+01                  , pde-loss 2.8937e+03, initc-loss 1.2875e+04                    bc_loss 5.7416e+03\n",
      "Epoch 8870, Training-Loss 2.7912e+01, Data-loss 2.3203e+01                  , pde-loss 2.7496e+03, initc-loss 1.2774e+04                    bc_loss 3.1567e+04\n",
      "Epoch 8880, Training-Loss 3.0743e+01, Data-loss 2.6387e+01                  , pde-loss 2.7094e+03, initc-loss 1.2821e+04                    bc_loss 2.8033e+04\n",
      "Epoch 8890, Training-Loss 3.1543e+01, Data-loss 2.8489e+01                  , pde-loss 3.0378e+03, initc-loss 1.2944e+04                    bc_loss 1.4555e+04\n",
      "Epoch 8900, Training-Loss 3.5240e+01, Data-loss 3.3236e+01                  , pde-loss 2.7865e+03, initc-loss 1.2891e+04                    bc_loss 4.3582e+03\n",
      "Epoch 8910, Training-Loss 4.3792e+01, Data-loss 4.1785e+01                  , pde-loss 3.0459e+03, initc-loss 1.3059e+04                    bc_loss 3.9640e+03\n",
      "Epoch 8920, Training-Loss 3.3427e+01, Data-loss 3.1381e+01                  , pde-loss 3.1997e+03, initc-loss 1.3073e+04                    bc_loss 4.1893e+03\n",
      "Epoch 8930, Training-Loss 2.5735e+01, Data-loss 2.3577e+01                  , pde-loss 2.9759e+03, initc-loss 1.2839e+04                    bc_loss 5.7679e+03\n",
      "Epoch 8940, Training-Loss 2.5832e+01, Data-loss 2.3528e+01                  , pde-loss 2.8214e+03, initc-loss 1.3082e+04                    bc_loss 7.1386e+03\n",
      "Epoch 8950, Training-Loss 3.0193e+01, Data-loss 2.8257e+01                  , pde-loss 2.7085e+03, initc-loss 1.2916e+04                    bc_loss 3.7394e+03\n",
      "Epoch 8960, Training-Loss 3.2907e+01, Data-loss 3.0528e+01                  , pde-loss 3.2717e+03, initc-loss 1.2844e+04                    bc_loss 7.6752e+03\n",
      "Epoch 8970, Training-Loss 3.4272e+01, Data-loss 3.1183e+01                  , pde-loss 3.1909e+03, initc-loss 1.3010e+04                    bc_loss 1.4686e+04\n",
      "Epoch 8980, Training-Loss 3.1597e+01, Data-loss 2.9317e+01                  , pde-loss 3.4419e+03, initc-loss 1.3052e+04                    bc_loss 6.3084e+03\n",
      "Epoch 8990, Training-Loss 4.3155e+01, Data-loss 4.1057e+01                  , pde-loss 3.2015e+03, initc-loss 1.2987e+04                    bc_loss 4.7949e+03\n",
      "Epoch 9000, Training-Loss 2.5518e+01, Data-loss 2.2647e+01                  , pde-loss 3.0064e+03, initc-loss 1.2854e+04                    bc_loss 1.2854e+04\n",
      "Epoch 9010, Training-Loss 3.1134e+01, Data-loss 2.9159e+01                  , pde-loss 2.9474e+03, initc-loss 1.3082e+04                    bc_loss 3.7276e+03\n",
      "Epoch 9020, Training-Loss 2.6535e+01, Data-loss 2.4311e+01                  , pde-loss 3.2408e+03, initc-loss 1.2932e+04                    bc_loss 6.0719e+03\n",
      "Epoch 9030, Training-Loss 2.2047e+01, Data-loss 1.9076e+01                  , pde-loss 2.8965e+03, initc-loss 1.2989e+04                    bc_loss 1.3824e+04\n",
      "Epoch 9040, Training-Loss 2.2226e+01, Data-loss 2.0331e+01                  , pde-loss 3.1422e+03, initc-loss 1.2909e+04                    bc_loss 2.8972e+03\n",
      "Epoch 9050, Training-Loss 2.7083e+01, Data-loss 2.5226e+01                  , pde-loss 2.4948e+03, initc-loss 1.2861e+04                    bc_loss 3.2194e+03\n",
      "Epoch 9060, Training-Loss 2.8020e+01, Data-loss 2.6087e+01                  , pde-loss 3.1397e+03, initc-loss 1.2844e+04                    bc_loss 3.3464e+03\n",
      "Epoch 9070, Training-Loss 3.5136e+01, Data-loss 3.3090e+01                  , pde-loss 3.3800e+03, initc-loss 1.2879e+04                    bc_loss 4.2054e+03\n",
      "Epoch 9080, Training-Loss 3.0676e+01, Data-loss 2.8440e+01                  , pde-loss 2.9204e+03, initc-loss 1.3008e+04                    bc_loss 6.4318e+03\n",
      "Epoch 9090, Training-Loss 3.1132e+01, Data-loss 2.9008e+01                  , pde-loss 3.0578e+03, initc-loss 1.2925e+04                    bc_loss 5.2621e+03\n",
      "Epoch 9100, Training-Loss 2.9214e+01, Data-loss 2.5836e+01                  , pde-loss 3.3076e+03, initc-loss 1.2887e+04                    bc_loss 1.7585e+04\n",
      "Epoch 9110, Training-Loss 3.8444e+01, Data-loss 3.5641e+01                  , pde-loss 3.1483e+03, initc-loss 1.2901e+04                    bc_loss 1.1979e+04\n",
      "Epoch 9120, Training-Loss 2.3019e+01, Data-loss 2.0727e+01                  , pde-loss 3.5941e+03, initc-loss 1.2937e+04                    bc_loss 6.3938e+03\n",
      "Epoch 9130, Training-Loss 3.3871e+01, Data-loss 3.1967e+01                  , pde-loss 3.0250e+03, initc-loss 1.2876e+04                    bc_loss 3.1402e+03\n",
      "Epoch 9140, Training-Loss 1.9868e+01, Data-loss 1.6915e+01                  , pde-loss 3.4522e+03, initc-loss 1.2961e+04                    bc_loss 1.3121e+04\n",
      "Epoch 9150, Training-Loss 2.7891e+01, Data-loss 2.5701e+01                  , pde-loss 3.7576e+03, initc-loss 1.2988e+04                    bc_loss 5.1531e+03\n",
      "Epoch 9160, Training-Loss 2.5690e+01, Data-loss 2.3642e+01                  , pde-loss 2.9636e+03, initc-loss 1.2977e+04                    bc_loss 4.5336e+03\n",
      "Epoch 9170, Training-Loss 2.2366e+01, Data-loss 2.0378e+01                  , pde-loss 3.4376e+03, initc-loss 1.3009e+04                    bc_loss 3.4368e+03\n",
      "Epoch 9180, Training-Loss 2.3128e+01, Data-loss 2.1285e+01                  , pde-loss 3.4785e+03, initc-loss 1.2863e+04                    bc_loss 2.0876e+03\n",
      "Epoch 9190, Training-Loss 2.6032e+01, Data-loss 2.4129e+01                  , pde-loss 3.6501e+03, initc-loss 1.3062e+04                    bc_loss 2.3154e+03\n",
      "Epoch 9200, Training-Loss 2.6821e+01, Data-loss 2.2571e+01                  , pde-loss 3.0853e+03, initc-loss 1.2839e+04                    bc_loss 2.6569e+04\n",
      "Epoch 9210, Training-Loss 2.6344e+01, Data-loss 2.4513e+01                  , pde-loss 3.4134e+03, initc-loss 1.2920e+04                    bc_loss 1.9683e+03\n",
      "Epoch 9220, Training-Loss 2.7508e+01, Data-loss 2.4127e+01                  , pde-loss 3.3053e+03, initc-loss 1.3013e+04                    bc_loss 1.7493e+04\n",
      "Epoch 9230, Training-Loss 1.6759e+01, Data-loss 1.3499e+01                  , pde-loss 3.1564e+03, initc-loss 1.2782e+04                    bc_loss 1.6662e+04\n",
      "Epoch 9240, Training-Loss 1.7581e+01, Data-loss 1.5073e+01                  , pde-loss 3.6514e+03, initc-loss 1.2946e+04                    bc_loss 8.4814e+03\n",
      "Epoch 9250, Training-Loss 2.7893e+01, Data-loss 2.5637e+01                  , pde-loss 3.4083e+03, initc-loss 1.2864e+04                    bc_loss 6.2958e+03\n",
      "Epoch 9260, Training-Loss 2.2425e+01, Data-loss 2.0484e+01                  , pde-loss 3.7865e+03, initc-loss 1.2788e+04                    bc_loss 2.8330e+03\n",
      "Epoch 9270, Training-Loss 2.2713e+01, Data-loss 2.0661e+01                  , pde-loss 3.5116e+03, initc-loss 1.2964e+04                    bc_loss 4.0443e+03\n",
      "Epoch 9280, Training-Loss 1.5763e+01, Data-loss 1.3878e+01                  , pde-loss 3.2968e+03, initc-loss 1.3011e+04                    bc_loss 2.5368e+03\n",
      "Epoch 9290, Training-Loss 3.2473e+01, Data-loss 2.9380e+01                  , pde-loss 3.4246e+03, initc-loss 1.2909e+04                    bc_loss 1.4595e+04\n",
      "Epoch 9300, Training-Loss 2.0296e+01, Data-loss 1.6598e+01                  , pde-loss 3.3958e+03, initc-loss 1.2861e+04                    bc_loss 2.0721e+04\n",
      "Epoch 9310, Training-Loss 2.3022e+01, Data-loss 2.0120e+01                  , pde-loss 3.4178e+03, initc-loss 1.2890e+04                    bc_loss 1.2710e+04\n",
      "Epoch 9320, Training-Loss 1.9040e+01, Data-loss 1.6733e+01                  , pde-loss 3.1455e+03, initc-loss 1.2918e+04                    bc_loss 7.0043e+03\n",
      "Epoch 9330, Training-Loss 2.1362e+01, Data-loss 1.9346e+01                  , pde-loss 3.8399e+03, initc-loss 1.3016e+04                    bc_loss 3.3095e+03\n",
      "Epoch 9340, Training-Loss 2.2821e+01, Data-loss 2.0546e+01                  , pde-loss 2.8580e+03, initc-loss 1.2904e+04                    bc_loss 6.9866e+03\n",
      "Epoch 9350, Training-Loss 3.1543e+01, Data-loss 2.9020e+01                  , pde-loss 3.7684e+03, initc-loss 1.2891e+04                    bc_loss 8.5701e+03\n",
      "Epoch 9360, Training-Loss 1.7797e+01, Data-loss 1.5032e+01                  , pde-loss 3.1949e+03, initc-loss 1.2953e+04                    bc_loss 1.1504e+04\n",
      "Epoch 9370, Training-Loss 2.2447e+01, Data-loss 1.9915e+01                  , pde-loss 3.4022e+03, initc-loss 1.2867e+04                    bc_loss 9.0508e+03\n",
      "Epoch 9380, Training-Loss 1.7188e+01, Data-loss 1.5065e+01                  , pde-loss 3.9395e+03, initc-loss 1.2833e+04                    bc_loss 4.4548e+03\n",
      "Epoch 9390, Training-Loss 1.9323e+01, Data-loss 1.7389e+01                  , pde-loss 3.4451e+03, initc-loss 1.2793e+04                    bc_loss 3.1097e+03\n",
      "Epoch 9400, Training-Loss 2.6826e+01, Data-loss 2.5020e+01                  , pde-loss 3.3975e+03, initc-loss 1.2902e+04                    bc_loss 1.7608e+03\n",
      "Epoch 9410, Training-Loss 2.7259e+01, Data-loss 2.5360e+01                  , pde-loss 3.5354e+03, initc-loss 1.2996e+04                    bc_loss 2.4528e+03\n",
      "Epoch 9420, Training-Loss 1.8420e+01, Data-loss 1.6275e+01                  , pde-loss 3.5765e+03, initc-loss 1.2959e+04                    bc_loss 4.9130e+03\n",
      "Epoch 9430, Training-Loss 2.6429e+01, Data-loss 1.9625e+01                  , pde-loss 3.1980e+03, initc-loss 1.3026e+04                    bc_loss 5.1812e+04\n",
      "Epoch 9440, Training-Loss 1.9304e+01, Data-loss 1.5200e+01                  , pde-loss 3.9713e+03, initc-loss 1.3028e+04                    bc_loss 2.4041e+04\n",
      "Epoch 9450, Training-Loss 2.7992e+01, Data-loss 2.4814e+01                  , pde-loss 3.4986e+03, initc-loss 1.3034e+04                    bc_loss 1.5243e+04\n",
      "Epoch 9460, Training-Loss 1.6963e+01, Data-loss 1.5027e+01                  , pde-loss 3.4202e+03, initc-loss 1.2942e+04                    bc_loss 2.9989e+03\n",
      "Epoch 9470, Training-Loss 1.6016e+01, Data-loss 1.3769e+01                  , pde-loss 3.3919e+03, initc-loss 1.2882e+04                    bc_loss 6.1974e+03\n",
      "Epoch 9480, Training-Loss 1.8088e+01, Data-loss 1.5576e+01                  , pde-loss 3.9333e+03, initc-loss 1.2908e+04                    bc_loss 8.2793e+03\n",
      "Epoch 9490, Training-Loss 2.0741e+01, Data-loss 1.8478e+01                  , pde-loss 3.6747e+03, initc-loss 1.3059e+04                    bc_loss 5.8989e+03\n",
      "Epoch 9500, Training-Loss 2.3621e+01, Data-loss 1.9758e+01                  , pde-loss 3.4884e+03, initc-loss 1.2874e+04                    bc_loss 2.2265e+04\n",
      "Epoch 9510, Training-Loss 2.5759e+01, Data-loss 2.3873e+01                  , pde-loss 4.1137e+03, initc-loss 1.2913e+04                    bc_loss 1.8359e+03\n",
      "Epoch 9520, Training-Loss 1.2369e+01, Data-loss 1.0123e+01                  , pde-loss 4.0805e+03, initc-loss 1.2933e+04                    bc_loss 5.4483e+03\n",
      "Epoch 9530, Training-Loss 2.3686e+01, Data-loss 2.1731e+01                  , pde-loss 3.6076e+03, initc-loss 1.2873e+04                    bc_loss 3.0757e+03\n",
      "Epoch 9540, Training-Loss 1.2917e+01, Data-loss 1.1021e+01                  , pde-loss 3.7427e+03, initc-loss 1.2992e+04                    bc_loss 2.2339e+03\n",
      "Epoch 9550, Training-Loss 1.2864e+01, Data-loss 1.0318e+01                  , pde-loss 3.8976e+03, initc-loss 1.2927e+04                    bc_loss 8.6391e+03\n",
      "Epoch 9560, Training-Loss 1.6127e+01, Data-loss 1.4283e+01                  , pde-loss 3.6239e+03, initc-loss 1.2949e+04                    bc_loss 1.8637e+03\n",
      "Epoch 9570, Training-Loss 1.3860e+01, Data-loss 1.1911e+01                  , pde-loss 4.3244e+03, initc-loss 1.2849e+04                    bc_loss 2.3155e+03\n",
      "Epoch 9580, Training-Loss 1.3252e+01, Data-loss 1.1110e+01                  , pde-loss 2.9155e+03, initc-loss 1.3061e+04                    bc_loss 5.4453e+03\n",
      "Epoch 9590, Training-Loss 1.1742e+01, Data-loss 9.0558e+00                  , pde-loss 4.0831e+03, initc-loss 1.2957e+04                    bc_loss 9.8267e+03\n",
      "Epoch 9600, Training-Loss 1.7579e+01, Data-loss 1.5716e+01                  , pde-loss 3.9143e+03, initc-loss 1.2930e+04                    bc_loss 1.7858e+03\n",
      "Epoch 9610, Training-Loss 9.2980e+00, Data-loss 7.4957e+00                  , pde-loss 3.4029e+03, initc-loss 1.2902e+04                    bc_loss 1.7187e+03\n",
      "Epoch 9620, Training-Loss 1.2300e+01, Data-loss 1.0376e+01                  , pde-loss 3.4334e+03, initc-loss 1.2942e+04                    bc_loss 2.8649e+03\n",
      "Epoch 9630, Training-Loss 1.4908e+01, Data-loss 1.2740e+01                  , pde-loss 4.1992e+03, initc-loss 1.2971e+04                    bc_loss 4.5080e+03\n",
      "Epoch 9640, Training-Loss 1.4763e+01, Data-loss 1.2784e+01                  , pde-loss 3.9935e+03, initc-loss 1.2802e+04                    bc_loss 2.9953e+03\n",
      "Epoch 9650, Training-Loss 1.5998e+01, Data-loss 1.3515e+01                  , pde-loss 4.4737e+03, initc-loss 1.2989e+04                    bc_loss 7.3724e+03\n",
      "Epoch 9660, Training-Loss 1.7337e+01, Data-loss 1.5395e+01                  , pde-loss 3.4831e+03, initc-loss 1.2900e+04                    bc_loss 3.0332e+03\n",
      "Epoch 9670, Training-Loss 1.3115e+01, Data-loss 1.0809e+01                  , pde-loss 4.6440e+03, initc-loss 1.2969e+04                    bc_loss 5.4412e+03\n",
      "Epoch 9680, Training-Loss 1.3913e+01, Data-loss 1.1853e+01                  , pde-loss 3.6245e+03, initc-loss 1.2885e+04                    bc_loss 4.0941e+03\n",
      "Epoch 9690, Training-Loss 1.9572e+01, Data-loss 1.7483e+01                  , pde-loss 3.7612e+03, initc-loss 1.2906e+04                    bc_loss 4.2227e+03\n",
      "Epoch 9700, Training-Loss 1.2838e+01, Data-loss 1.0983e+01                  , pde-loss 3.1047e+03, initc-loss 1.2994e+04                    bc_loss 2.4431e+03\n",
      "Epoch 9710, Training-Loss 1.1754e+01, Data-loss 9.7337e+00                  , pde-loss 4.4107e+03, initc-loss 1.2964e+04                    bc_loss 2.8227e+03\n",
      "Epoch 9720, Training-Loss 1.2944e+01, Data-loss 1.0986e+01                  , pde-loss 3.6618e+03, initc-loss 1.2859e+04                    bc_loss 3.0677e+03\n",
      "Epoch 9730, Training-Loss 1.5094e+01, Data-loss 1.3034e+01                  , pde-loss 4.2852e+03, initc-loss 1.3011e+04                    bc_loss 3.3115e+03\n",
      "Epoch 9740, Training-Loss 1.1903e+01, Data-loss 9.9559e+00                  , pde-loss 3.2012e+03, initc-loss 1.2898e+04                    bc_loss 3.3746e+03\n",
      "Epoch 9750, Training-Loss 1.0677e+01, Data-loss 8.7549e+00                  , pde-loss 4.3906e+03, initc-loss 1.3013e+04                    bc_loss 1.8228e+03\n",
      "Epoch 9760, Training-Loss 1.1999e+01, Data-loss 9.4125e+00                  , pde-loss 3.8634e+03, initc-loss 1.3076e+04                    bc_loss 8.9256e+03\n",
      "Epoch 9770, Training-Loss 1.0059e+01, Data-loss 8.1600e+00                  , pde-loss 3.8183e+03, initc-loss 1.3080e+04                    bc_loss 2.0868e+03\n",
      "Epoch 9780, Training-Loss 1.2973e+01, Data-loss 1.0898e+01                  , pde-loss 3.4086e+03, initc-loss 1.2931e+04                    bc_loss 4.4081e+03\n",
      "Epoch 9790, Training-Loss 1.0172e+01, Data-loss 7.9382e+00                  , pde-loss 4.2483e+03, initc-loss 1.2843e+04                    bc_loss 5.2488e+03\n",
      "Epoch 9800, Training-Loss 1.0710e+01, Data-loss 8.5812e+00                  , pde-loss 3.9862e+03, initc-loss 1.3103e+04                    bc_loss 4.1970e+03\n",
      "Epoch 9810, Training-Loss 9.8290e+00, Data-loss 7.8231e+00                  , pde-loss 3.5230e+03, initc-loss 1.2886e+04                    bc_loss 3.6490e+03\n",
      "Epoch 9820, Training-Loss 1.3050e+01, Data-loss 1.1163e+01                  , pde-loss 3.7016e+03, initc-loss 1.2899e+04                    bc_loss 2.2715e+03\n",
      "Epoch 9830, Training-Loss 1.1658e+01, Data-loss 9.4088e+00                  , pde-loss 4.9891e+03, initc-loss 1.3016e+04                    bc_loss 4.4919e+03\n",
      "Epoch 9840, Training-Loss 9.1719e+00, Data-loss 7.1213e+00                  , pde-loss 4.1934e+03, initc-loss 1.2904e+04                    bc_loss 3.4082e+03\n",
      "Epoch 9850, Training-Loss 1.4163e+01, Data-loss 1.2088e+01                  , pde-loss 4.4846e+03, initc-loss 1.3104e+04                    bc_loss 3.1543e+03\n",
      "Epoch 9860, Training-Loss 8.7118e+00, Data-loss 6.6472e+00                  , pde-loss 4.6018e+03, initc-loss 1.2974e+04                    bc_loss 3.0693e+03\n",
      "Epoch 9870, Training-Loss 1.4945e+01, Data-loss 1.2262e+01                  , pde-loss 4.7811e+03, initc-loss 1.2825e+04                    bc_loss 9.2301e+03\n",
      "Epoch 9880, Training-Loss 9.4326e+00, Data-loss 7.5319e+00                  , pde-loss 3.7864e+03, initc-loss 1.2874e+04                    bc_loss 2.3454e+03\n",
      "Epoch 9890, Training-Loss 1.0916e+01, Data-loss 8.2952e+00                  , pde-loss 4.6025e+03, initc-loss 1.2882e+04                    bc_loss 8.7263e+03\n",
      "Epoch 9900, Training-Loss 1.3158e+01, Data-loss 1.0649e+01                  , pde-loss 3.5471e+03, initc-loss 1.2954e+04                    bc_loss 8.5894e+03\n",
      "Epoch 9910, Training-Loss 9.6006e+00, Data-loss 7.5706e+00                  , pde-loss 4.1458e+03, initc-loss 1.2893e+04                    bc_loss 3.2616e+03\n",
      "Epoch 9920, Training-Loss 1.1920e+01, Data-loss 9.7336e+00                  , pde-loss 4.2455e+03, initc-loss 1.2946e+04                    bc_loss 4.6769e+03\n",
      "Epoch 9930, Training-Loss 9.0030e+00, Data-loss 6.9999e+00                  , pde-loss 3.7083e+03, initc-loss 1.2951e+04                    bc_loss 3.3717e+03\n",
      "Epoch 9940, Training-Loss 8.1146e+00, Data-loss 6.1953e+00                  , pde-loss 4.5779e+03, initc-loss 1.2960e+04                    bc_loss 1.6550e+03\n",
      "Epoch 9950, Training-Loss 1.0628e+01, Data-loss 8.7036e+00                  , pde-loss 4.2754e+03, initc-loss 1.2965e+04                    bc_loss 2.0010e+03\n",
      "Epoch 9960, Training-Loss 1.0888e+01, Data-loss 8.7864e+00                  , pde-loss 4.6803e+03, initc-loss 1.3006e+04                    bc_loss 3.3288e+03\n",
      "Epoch 9970, Training-Loss 9.0940e+00, Data-loss 7.0904e+00                  , pde-loss 4.0155e+03, initc-loss 1.2935e+04                    bc_loss 3.0849e+03\n",
      "Epoch 9980, Training-Loss 9.7630e+00, Data-loss 7.8797e+00                  , pde-loss 3.7672e+03, initc-loss 1.2962e+04                    bc_loss 2.1038e+03\n",
      "Epoch 9990, Training-Loss 1.1970e+01, Data-loss 1.0053e+01                  , pde-loss 3.9881e+03, initc-loss 1.2967e+04                    bc_loss 2.2099e+03\n",
      "Epoch 10000, Training-Loss 1.1524e+01, Data-loss 9.4908e+00                  , pde-loss 4.1667e+03, initc-loss 1.2892e+04                    bc_loss 3.2747e+03\n",
      "Epoch 10010, Training-Loss 8.7974e+00, Data-loss 6.5671e+00                  , pde-loss 4.5439e+03, initc-loss 1.2917e+04                    bc_loss 4.8426e+03\n",
      "Epoch 10020, Training-Loss 1.0123e+01, Data-loss 8.0067e+00                  , pde-loss 4.7503e+03, initc-loss 1.2966e+04                    bc_loss 3.4454e+03\n",
      "Epoch 10030, Training-Loss 1.3240e+01, Data-loss 1.0676e+01                  , pde-loss 3.3849e+03, initc-loss 1.2891e+04                    bc_loss 9.3623e+03\n",
      "Epoch 10040, Training-Loss 1.0960e+01, Data-loss 9.0338e+00                  , pde-loss 3.8914e+03, initc-loss 1.2971e+04                    bc_loss 2.3976e+03\n",
      "Epoch 10050, Training-Loss 7.2345e+00, Data-loss 5.3401e+00                  , pde-loss 3.8581e+03, initc-loss 1.2928e+04                    bc_loss 2.1578e+03\n",
      "Epoch 10060, Training-Loss 9.0255e+00, Data-loss 5.8547e+00                  , pde-loss 3.8686e+03, initc-loss 1.2937e+04                    bc_loss 1.4902e+04\n",
      "Epoch 10070, Training-Loss 1.1687e+01, Data-loss 9.7624e+00                  , pde-loss 4.6095e+03, initc-loss 1.3039e+04                    bc_loss 1.5973e+03\n",
      "Epoch 10080, Training-Loss 9.9341e+00, Data-loss 7.7212e+00                  , pde-loss 3.7609e+03, initc-loss 1.2945e+04                    bc_loss 5.4231e+03\n",
      "Epoch 10090, Training-Loss 1.0831e+01, Data-loss 8.9613e+00                  , pde-loss 4.0222e+03, initc-loss 1.2904e+04                    bc_loss 1.7712e+03\n",
      "Epoch 10100, Training-Loss 9.8654e+00, Data-loss 7.5782e+00                  , pde-loss 3.9235e+03, initc-loss 1.3111e+04                    bc_loss 5.8379e+03\n",
      "Epoch 10110, Training-Loss 9.8336e+00, Data-loss 7.8592e+00                  , pde-loss 3.9404e+03, initc-loss 1.3018e+04                    bc_loss 2.7852e+03\n",
      "Epoch 10120, Training-Loss 7.7342e+00, Data-loss 4.9635e+00                  , pde-loss 3.8991e+03, initc-loss 1.2885e+04                    bc_loss 1.0922e+04\n",
      "Epoch 10130, Training-Loss 9.3712e+00, Data-loss 7.2872e+00                  , pde-loss 4.2659e+03, initc-loss 1.2923e+04                    bc_loss 3.6511e+03\n",
      "Epoch 10140, Training-Loss 1.1305e+01, Data-loss 8.5596e+00                  , pde-loss 4.8914e+03, initc-loss 1.2877e+04                    bc_loss 9.6826e+03\n",
      "Epoch 10150, Training-Loss 1.1075e+01, Data-loss 8.8185e+00                  , pde-loss 5.3527e+03, initc-loss 1.2956e+04                    bc_loss 4.2599e+03\n",
      "Epoch 10160, Training-Loss 8.3292e+00, Data-loss 5.8345e+00                  , pde-loss 4.4424e+03, initc-loss 1.2877e+04                    bc_loss 7.6267e+03\n",
      "Epoch 10170, Training-Loss 8.2314e+00, Data-loss 6.1594e+00                  , pde-loss 5.2202e+03, initc-loss 1.3012e+04                    bc_loss 2.4871e+03\n",
      "Epoch 10180, Training-Loss 8.3812e+00, Data-loss 6.3385e+00                  , pde-loss 4.1235e+03, initc-loss 1.2977e+04                    bc_loss 3.3271e+03\n",
      "Epoch 10190, Training-Loss 1.2379e+01, Data-loss 1.0128e+01                  , pde-loss 3.8198e+03, initc-loss 1.2997e+04                    bc_loss 5.6981e+03\n",
      "Epoch 10200, Training-Loss 9.6028e+00, Data-loss 7.6209e+00                  , pde-loss 4.7166e+03, initc-loss 1.3060e+04                    bc_loss 2.0419e+03\n",
      "Epoch 10210, Training-Loss 9.4841e+00, Data-loss 7.3230e+00                  , pde-loss 4.9720e+03, initc-loss 1.2949e+04                    bc_loss 3.6900e+03\n",
      "Epoch 10220, Training-Loss 8.6380e+00, Data-loss 5.8784e+00                  , pde-loss 3.4669e+03, initc-loss 1.2827e+04                    bc_loss 1.1302e+04\n",
      "Epoch 10230, Training-Loss 9.2465e+00, Data-loss 7.1694e+00                  , pde-loss 4.5461e+03, initc-loss 1.2971e+04                    bc_loss 3.2534e+03\n",
      "Epoch 10240, Training-Loss 8.3883e+00, Data-loss 6.2755e+00                  , pde-loss 4.1406e+03, initc-loss 1.2967e+04                    bc_loss 4.0208e+03\n",
      "Epoch 10250, Training-Loss 9.0640e+00, Data-loss 7.0413e+00                  , pde-loss 4.8188e+03, initc-loss 1.3052e+04                    bc_loss 2.3569e+03\n",
      "Epoch 10260, Training-Loss 8.0255e+00, Data-loss 6.1122e+00                  , pde-loss 4.6037e+03, initc-loss 1.2937e+04                    bc_loss 1.5920e+03\n",
      "Epoch 10270, Training-Loss 1.0257e+01, Data-loss 7.9586e+00                  , pde-loss 4.7365e+03, initc-loss 1.2877e+04                    bc_loss 5.3742e+03\n",
      "Epoch 10280, Training-Loss 7.9540e+00, Data-loss 5.5826e+00                  , pde-loss 4.4797e+03, initc-loss 1.2970e+04                    bc_loss 6.2641e+03\n",
      "Epoch 10290, Training-Loss 1.0032e+01, Data-loss 7.7879e+00                  , pde-loss 4.3274e+03, initc-loss 1.2977e+04                    bc_loss 5.1317e+03\n",
      "Epoch 10300, Training-Loss 1.1899e+01, Data-loss 9.8931e+00                  , pde-loss 4.4218e+03, initc-loss 1.3070e+04                    bc_loss 2.5651e+03\n",
      "Epoch 10310, Training-Loss 7.7652e+00, Data-loss 5.7440e+00                  , pde-loss 4.2763e+03, initc-loss 1.2952e+04                    bc_loss 2.9838e+03\n",
      "Epoch 10320, Training-Loss 7.3419e+00, Data-loss 5.3802e+00                  , pde-loss 4.7219e+03, initc-loss 1.2885e+04                    bc_loss 2.0110e+03\n",
      "Epoch 10330, Training-Loss 6.6533e+00, Data-loss 4.6959e+00                  , pde-loss 3.8016e+03, initc-loss 1.3015e+04                    bc_loss 2.7579e+03\n",
      "Epoch 10340, Training-Loss 7.7439e+00, Data-loss 5.8031e+00                  , pde-loss 3.9916e+03, initc-loss 1.2891e+04                    bc_loss 2.5259e+03\n",
      "Epoch 10350, Training-Loss 9.5728e+00, Data-loss 7.6082e+00                  , pde-loss 4.9502e+03, initc-loss 1.2943e+04                    bc_loss 1.7524e+03\n",
      "Epoch 10360, Training-Loss 1.0531e+01, Data-loss 8.4461e+00                  , pde-loss 5.1766e+03, initc-loss 1.2803e+04                    bc_loss 2.8732e+03\n",
      "Epoch 10370, Training-Loss 8.4582e+00, Data-loss 5.5717e+00                  , pde-loss 3.7468e+03, initc-loss 1.2957e+04                    bc_loss 1.2161e+04\n",
      "Epoch 10380, Training-Loss 9.4599e+00, Data-loss 7.5371e+00                  , pde-loss 4.0579e+03, initc-loss 1.2913e+04                    bc_loss 2.2577e+03\n",
      "Epoch 10390, Training-Loss 8.6622e+00, Data-loss 6.6288e+00                  , pde-loss 4.6041e+03, initc-loss 1.2973e+04                    bc_loss 2.7577e+03\n",
      "Epoch 10400, Training-Loss 9.4350e+00, Data-loss 7.3690e+00                  , pde-loss 4.5191e+03, initc-loss 1.3015e+04                    bc_loss 3.1256e+03\n",
      "Epoch 10410, Training-Loss 8.4867e+00, Data-loss 6.2828e+00                  , pde-loss 4.8093e+03, initc-loss 1.2975e+04                    bc_loss 4.2550e+03\n",
      "Epoch 10420, Training-Loss 6.2462e+00, Data-loss 4.1308e+00                  , pde-loss 5.4899e+03, initc-loss 1.2932e+04                    bc_loss 2.7326e+03\n",
      "Epoch 10430, Training-Loss 6.7986e+00, Data-loss 4.7779e+00                  , pde-loss 5.0140e+03, initc-loss 1.2942e+04                    bc_loss 2.2512e+03\n",
      "Epoch 10440, Training-Loss 7.9190e+00, Data-loss 5.6891e+00                  , pde-loss 4.7435e+03, initc-loss 1.2976e+04                    bc_loss 4.5791e+03\n",
      "Epoch 10450, Training-Loss 7.1690e+00, Data-loss 4.3804e+00                  , pde-loss 4.3477e+03, initc-loss 1.2905e+04                    bc_loss 1.0633e+04\n",
      "Epoch 10460, Training-Loss 8.8940e+00, Data-loss 6.8962e+00                  , pde-loss 5.0060e+03, initc-loss 1.3055e+04                    bc_loss 1.9169e+03\n",
      "Epoch 10470, Training-Loss 7.1435e+00, Data-loss 5.0047e+00                  , pde-loss 4.2859e+03, initc-loss 1.2952e+04                    bc_loss 4.1502e+03\n",
      "Epoch 10480, Training-Loss 6.0375e+00, Data-loss 3.8661e+00                  , pde-loss 4.6246e+03, initc-loss 1.2911e+04                    bc_loss 4.1784e+03\n",
      "Epoch 10490, Training-Loss 7.7424e+00, Data-loss 5.5118e+00                  , pde-loss 4.8179e+03, initc-loss 1.3035e+04                    bc_loss 4.4526e+03\n",
      "Epoch 10500, Training-Loss 9.9434e+00, Data-loss 7.8970e+00                  , pde-loss 4.5379e+03, initc-loss 1.2810e+04                    bc_loss 3.1164e+03\n",
      "Epoch 10510, Training-Loss 6.7719e+00, Data-loss 4.7640e+00                  , pde-loss 5.2467e+03, initc-loss 1.2929e+04                    bc_loss 1.9039e+03\n",
      "Epoch 10520, Training-Loss 6.0645e+00, Data-loss 4.1090e+00                  , pde-loss 5.0270e+03, initc-loss 1.2925e+04                    bc_loss 1.6028e+03\n",
      "Epoch 10530, Training-Loss 5.8812e+00, Data-loss 3.9551e+00                  , pde-loss 4.8742e+03, initc-loss 1.2988e+04                    bc_loss 1.3983e+03\n",
      "Epoch 10540, Training-Loss 7.2420e+00, Data-loss 4.7541e+00                  , pde-loss 4.6533e+03, initc-loss 1.2912e+04                    bc_loss 7.3136e+03\n",
      "Epoch 10550, Training-Loss 6.4069e+00, Data-loss 4.4195e+00                  , pde-loss 4.9954e+03, initc-loss 1.2911e+04                    bc_loss 1.9673e+03\n",
      "Epoch 10560, Training-Loss 5.2771e+00, Data-loss 3.1943e+00                  , pde-loss 4.6258e+03, initc-loss 1.3010e+04                    bc_loss 3.1925e+03\n",
      "Epoch 10570, Training-Loss 6.3376e+00, Data-loss 4.5758e+00                  , pde-loss 3.2760e+03, initc-loss 1.3013e+04                    bc_loss 1.3296e+03\n",
      "Epoch 10580, Training-Loss 8.2167e+00, Data-loss 6.2661e+00                  , pde-loss 5.0560e+03, initc-loss 1.2904e+04                    bc_loss 1.5468e+03\n",
      "Epoch 10590, Training-Loss 7.1846e+00, Data-loss 5.1454e+00                  , pde-loss 5.9240e+03, initc-loss 1.3038e+04                    bc_loss 1.4296e+03\n",
      "Epoch 10600, Training-Loss 6.4745e+00, Data-loss 4.2354e+00                  , pde-loss 4.1323e+03, initc-loss 1.2728e+04                    bc_loss 5.5312e+03\n",
      "Epoch 10610, Training-Loss 6.3124e+00, Data-loss 3.7858e+00                  , pde-loss 4.8957e+03, initc-loss 1.3027e+04                    bc_loss 7.3424e+03\n",
      "Epoch 10620, Training-Loss 6.8425e+00, Data-loss 4.0983e+00                  , pde-loss 5.4944e+03, initc-loss 1.3008e+04                    bc_loss 8.9395e+03\n",
      "Epoch 10630, Training-Loss 6.0809e+00, Data-loss 3.4618e+00                  , pde-loss 4.9755e+03, initc-loss 1.3095e+04                    bc_loss 8.1204e+03\n",
      "Epoch 10640, Training-Loss 6.3399e+00, Data-loss 3.9360e+00                  , pde-loss 4.5436e+03, initc-loss 1.3026e+04                    bc_loss 6.4681e+03\n",
      "Epoch 10650, Training-Loss 6.9754e+00, Data-loss 4.1864e+00                  , pde-loss 4.1861e+03, initc-loss 1.2949e+04                    bc_loss 1.0756e+04\n",
      "Epoch 10660, Training-Loss 6.9178e+00, Data-loss 4.4063e+00                  , pde-loss 4.9845e+03, initc-loss 1.3144e+04                    bc_loss 6.9868e+03\n",
      "Epoch 10670, Training-Loss 7.0611e+00, Data-loss 4.9122e+00                  , pde-loss 4.8314e+03, initc-loss 1.2994e+04                    bc_loss 3.6630e+03\n",
      "Epoch 10680, Training-Loss 4.5694e+00, Data-loss 2.6403e+00                  , pde-loss 4.7421e+03, initc-loss 1.2959e+04                    bc_loss 1.5898e+03\n",
      "Epoch 10690, Training-Loss 4.6147e+00, Data-loss 2.7127e+00                  , pde-loss 4.5705e+03, initc-loss 1.2920e+04                    bc_loss 1.5293e+03\n",
      "Epoch 10700, Training-Loss 6.6178e+00, Data-loss 4.6253e+00                  , pde-loss 5.1331e+03, initc-loss 1.2880e+04                    bc_loss 1.9115e+03\n",
      "Epoch 10710, Training-Loss 7.5910e+00, Data-loss 5.3056e+00                  , pde-loss 5.0578e+03, initc-loss 1.2983e+04                    bc_loss 4.8118e+03\n",
      "Epoch 10720, Training-Loss 7.8579e+00, Data-loss 5.8485e+00                  , pde-loss 4.9649e+03, initc-loss 1.2885e+04                    bc_loss 2.2439e+03\n",
      "Epoch 10730, Training-Loss 5.5715e+00, Data-loss 3.5331e+00                  , pde-loss 5.3562e+03, initc-loss 1.3078e+04                    bc_loss 1.9496e+03\n",
      "Epoch 10740, Training-Loss 6.6238e+00, Data-loss 4.3691e+00                  , pde-loss 5.6456e+03, initc-loss 1.2888e+04                    bc_loss 4.0139e+03\n",
      "Epoch 10750, Training-Loss 9.1632e+00, Data-loss 7.1815e+00                  , pde-loss 4.4087e+03, initc-loss 1.2915e+04                    bc_loss 2.4932e+03\n",
      "Epoch 10760, Training-Loss 5.1683e+00, Data-loss 2.5451e+00                  , pde-loss 5.2988e+03, initc-loss 1.2904e+04                    bc_loss 8.0285e+03\n",
      "Epoch 10770, Training-Loss 9.9279e+00, Data-loss 5.2488e+00                  , pde-loss 5.1155e+03, initc-loss 1.3075e+04                    bc_loss 2.8600e+04\n",
      "Epoch 10780, Training-Loss 4.7270e+00, Data-loss 2.8240e+00                  , pde-loss 4.4075e+03, initc-loss 1.2842e+04                    bc_loss 1.7807e+03\n",
      "Epoch 10790, Training-Loss 5.8910e+00, Data-loss 3.7919e+00                  , pde-loss 5.3603e+03, initc-loss 1.2919e+04                    bc_loss 2.7118e+03\n",
      "Epoch 10800, Training-Loss 4.4955e+00, Data-loss 2.5302e+00                  , pde-loss 5.1063e+03, initc-loss 1.2921e+04                    bc_loss 1.6253e+03\n",
      "Epoch 10810, Training-Loss 7.4587e+00, Data-loss 5.3880e+00                  , pde-loss 5.3965e+03, initc-loss 1.2947e+04                    bc_loss 2.3641e+03\n",
      "Epoch 10820, Training-Loss 5.6303e+00, Data-loss 3.6551e+00                  , pde-loss 4.4087e+03, initc-loss 1.2981e+04                    bc_loss 2.3625e+03\n",
      "Epoch 10830, Training-Loss 5.4333e+00, Data-loss 3.0948e+00                  , pde-loss 4.1057e+03, initc-loss 1.2877e+04                    bc_loss 6.4021e+03\n",
      "Epoch 10840, Training-Loss 5.8714e+00, Data-loss 3.9176e+00                  , pde-loss 3.9974e+03, initc-loss 1.2719e+04                    bc_loss 2.8218e+03\n",
      "Epoch 10850, Training-Loss 5.5440e+00, Data-loss 3.5114e+00                  , pde-loss 5.0366e+03, initc-loss 1.2894e+04                    bc_loss 2.3946e+03\n",
      "Epoch 10860, Training-Loss 4.7351e+00, Data-loss 2.6622e+00                  , pde-loss 4.7741e+03, initc-loss 1.3018e+04                    bc_loss 2.9367e+03\n",
      "Epoch 10870, Training-Loss 6.0635e+00, Data-loss 3.7342e+00                  , pde-loss 5.2070e+03, initc-loss 1.3026e+04                    bc_loss 5.0602e+03\n",
      "Epoch 10880, Training-Loss 6.8208e+00, Data-loss 4.5886e+00                  , pde-loss 5.0373e+03, initc-loss 1.2961e+04                    bc_loss 4.3244e+03\n",
      "Epoch 10890, Training-Loss 6.3928e+00, Data-loss 4.3104e+00                  , pde-loss 5.4280e+03, initc-loss 1.2883e+04                    bc_loss 2.5129e+03\n",
      "Epoch 10900, Training-Loss 6.4603e+00, Data-loss 3.8922e+00                  , pde-loss 5.2836e+03, initc-loss 1.2741e+04                    bc_loss 7.6565e+03\n",
      "Epoch 10910, Training-Loss 4.8579e+00, Data-loss 2.5974e+00                  , pde-loss 4.0607e+03, initc-loss 1.2914e+04                    bc_loss 5.6299e+03\n",
      "Epoch 10920, Training-Loss 5.9705e+00, Data-loss 3.9130e+00                  , pde-loss 5.3609e+03, initc-loss 1.3024e+04                    bc_loss 2.1902e+03\n",
      "Epoch 10930, Training-Loss 5.9172e+00, Data-loss 3.9160e+00                  , pde-loss 5.1770e+03, initc-loss 1.2953e+04                    bc_loss 1.8825e+03\n",
      "Epoch 10940, Training-Loss 4.3047e+00, Data-loss 2.2452e+00                  , pde-loss 5.7432e+03, initc-loss 1.3013e+04                    bc_loss 1.8386e+03\n",
      "Epoch 10950, Training-Loss 5.1373e+00, Data-loss 3.2273e+00                  , pde-loss 4.5429e+03, initc-loss 1.2807e+04                    bc_loss 1.7501e+03\n",
      "Epoch 10960, Training-Loss 4.7963e+00, Data-loss 2.9308e+00                  , pde-loss 4.4397e+03, initc-loss 1.2887e+04                    bc_loss 1.3288e+03\n",
      "Epoch 10970, Training-Loss 5.1285e+00, Data-loss 3.0613e+00                  , pde-loss 5.3795e+03, initc-loss 1.2900e+04                    bc_loss 2.3933e+03\n",
      "Epoch 10980, Training-Loss 4.9384e+00, Data-loss 2.9721e+00                  , pde-loss 5.0359e+03, initc-loss 1.3072e+04                    bc_loss 1.5557e+03\n",
      "Epoch 10990, Training-Loss 5.1709e+00, Data-loss 3.1315e+00                  , pde-loss 5.6172e+03, initc-loss 1.2760e+04                    bc_loss 2.0175e+03\n",
      "Epoch 11000, Training-Loss 5.2821e+00, Data-loss 3.2701e+00                  , pde-loss 4.7414e+03, initc-loss 1.2858e+04                    bc_loss 2.5209e+03\n",
      "Epoch 11010, Training-Loss 5.9609e+00, Data-loss 3.3348e+00                  , pde-loss 5.0127e+03, initc-loss 1.2811e+04                    bc_loss 8.4375e+03\n",
      "Epoch 11020, Training-Loss 5.8223e+00, Data-loss 3.4715e+00                  , pde-loss 4.4176e+03, initc-loss 1.2897e+04                    bc_loss 6.1931e+03\n",
      "Epoch 11030, Training-Loss 5.9681e+00, Data-loss 3.2817e+00                  , pde-loss 5.4479e+03, initc-loss 1.2776e+04                    bc_loss 8.6408e+03\n",
      "Epoch 11040, Training-Loss 6.4328e+00, Data-loss 4.1099e+00                  , pde-loss 5.7107e+03, initc-loss 1.2841e+04                    bc_loss 4.6769e+03\n",
      "Epoch 11050, Training-Loss 6.1079e+00, Data-loss 4.0910e+00                  , pde-loss 5.8881e+03, initc-loss 1.2966e+04                    bc_loss 1.3146e+03\n",
      "Epoch 11060, Training-Loss 6.0963e+00, Data-loss 3.9035e+00                  , pde-loss 5.2256e+03, initc-loss 1.2859e+04                    bc_loss 3.8433e+03\n",
      "Epoch 11070, Training-Loss 4.7751e+00, Data-loss 2.7728e+00                  , pde-loss 5.3863e+03, initc-loss 1.2899e+04                    bc_loss 1.7372e+03\n",
      "Epoch 11080, Training-Loss 4.7317e+00, Data-loss 2.7051e+00                  , pde-loss 5.6161e+03, initc-loss 1.2969e+04                    bc_loss 1.6811e+03\n",
      "Epoch 11090, Training-Loss 5.7621e+00, Data-loss 3.8141e+00                  , pde-loss 4.8090e+03, initc-loss 1.2903e+04                    bc_loss 1.7682e+03\n",
      "Epoch 11100, Training-Loss 5.5351e+00, Data-loss 3.4565e+00                  , pde-loss 5.4466e+03, initc-loss 1.2748e+04                    bc_loss 2.5920e+03\n",
      "Epoch 11110, Training-Loss 4.5622e+00, Data-loss 2.3787e+00                  , pde-loss 5.6863e+03, initc-loss 1.2792e+04                    bc_loss 3.3575e+03\n",
      "Epoch 11120, Training-Loss 5.0442e+00, Data-loss 2.5859e+00                  , pde-loss 4.6365e+03, initc-loss 1.2872e+04                    bc_loss 7.0748e+03\n",
      "Epoch 11130, Training-Loss 4.2416e+00, Data-loss 2.2942e+00                  , pde-loss 5.4360e+03, initc-loss 1.2853e+04                    bc_loss 1.1842e+03\n",
      "Epoch 11140, Training-Loss 4.9905e+00, Data-loss 2.9450e+00                  , pde-loss 5.0495e+03, initc-loss 1.2953e+04                    bc_loss 2.4519e+03\n",
      "Epoch 11150, Training-Loss 6.5019e+00, Data-loss 4.2093e+00                  , pde-loss 4.8694e+03, initc-loss 1.3000e+04                    bc_loss 5.0561e+03\n",
      "Epoch 11160, Training-Loss 4.1970e+00, Data-loss 2.0638e+00                  , pde-loss 5.3445e+03, initc-loss 1.2962e+04                    bc_loss 3.0247e+03\n",
      "Epoch 11170, Training-Loss 4.9449e+00, Data-loss 2.9506e+00                  , pde-loss 5.6561e+03, initc-loss 1.2874e+04                    bc_loss 1.4131e+03\n",
      "Epoch 11180, Training-Loss 4.6293e+00, Data-loss 2.6453e+00                  , pde-loss 4.5602e+03, initc-loss 1.2967e+04                    bc_loss 2.3124e+03\n",
      "Epoch 11190, Training-Loss 4.2949e+00, Data-loss 2.2112e+00                  , pde-loss 5.8102e+03, initc-loss 1.2916e+04                    bc_loss 2.1113e+03\n",
      "Epoch 11200, Training-Loss 3.9834e+00, Data-loss 2.0553e+00                  , pde-loss 4.6784e+03, initc-loss 1.2820e+04                    bc_loss 1.7827e+03\n",
      "Epoch 11210, Training-Loss 4.7316e+00, Data-loss 2.3944e+00                  , pde-loss 4.7220e+03, initc-loss 1.2833e+04                    bc_loss 5.8164e+03\n",
      "Epoch 11220, Training-Loss 5.5144e+00, Data-loss 2.9534e+00                  , pde-loss 5.3142e+03, initc-loss 1.2907e+04                    bc_loss 7.3892e+03\n",
      "Epoch 11230, Training-Loss 5.2219e+00, Data-loss 2.3758e+00                  , pde-loss 3.8127e+03, initc-loss 1.2838e+04                    bc_loss 1.1811e+04\n",
      "Epoch 11240, Training-Loss 5.1831e+00, Data-loss 2.4814e+00                  , pde-loss 6.0761e+03, initc-loss 1.2957e+04                    bc_loss 7.9840e+03\n",
      "Epoch 11250, Training-Loss 3.7837e+00, Data-loss 1.7493e+00                  , pde-loss 6.0316e+03, initc-loss 1.2874e+04                    bc_loss 1.4385e+03\n",
      "Epoch 11260, Training-Loss 4.8518e+00, Data-loss 2.8672e+00                  , pde-loss 5.0852e+03, initc-loss 1.2899e+04                    bc_loss 1.8614e+03\n",
      "Epoch 11270, Training-Loss 5.3152e+00, Data-loss 3.3632e+00                  , pde-loss 4.8176e+03, initc-loss 1.2971e+04                    bc_loss 1.7317e+03\n",
      "Epoch 11280, Training-Loss 4.5593e+00, Data-loss 2.6277e+00                  , pde-loss 4.5222e+03, initc-loss 1.2904e+04                    bc_loss 1.8890e+03\n",
      "Epoch 11290, Training-Loss 4.3708e+00, Data-loss 2.4441e+00                  , pde-loss 5.0266e+03, initc-loss 1.2892e+04                    bc_loss 1.3485e+03\n",
      "Epoch 11300, Training-Loss 5.1162e+00, Data-loss 3.0780e+00                  , pde-loss 5.2060e+03, initc-loss 1.2968e+04                    bc_loss 2.2076e+03\n",
      "Epoch 11310, Training-Loss 3.8459e+00, Data-loss 1.8356e+00                  , pde-loss 5.1860e+03, initc-loss 1.2956e+04                    bc_loss 1.9608e+03\n",
      "Epoch 11320, Training-Loss 4.4809e+00, Data-loss 2.5098e+00                  , pde-loss 4.7024e+03, initc-loss 1.2991e+04                    bc_loss 2.0184e+03\n",
      "Epoch 11330, Training-Loss 4.0129e+00, Data-loss 2.0304e+00                  , pde-loss 5.7352e+03, initc-loss 1.2847e+04                    bc_loss 1.2428e+03\n",
      "Epoch 11340, Training-Loss 4.8581e+00, Data-loss 2.8663e+00                  , pde-loss 5.4811e+03, initc-loss 1.2682e+04                    bc_loss 1.7544e+03\n",
      "Epoch 11350, Training-Loss 4.5685e+00, Data-loss 2.6254e+00                  , pde-loss 5.2523e+03, initc-loss 1.2932e+04                    bc_loss 1.2463e+03\n",
      "Epoch 11360, Training-Loss 4.0531e+00, Data-loss 1.7828e+00                  , pde-loss 5.3798e+03, initc-loss 1.2967e+04                    bc_loss 4.3558e+03\n",
      "Epoch 11370, Training-Loss 6.0175e+00, Data-loss 2.9917e+00                  , pde-loss 5.7480e+03, initc-loss 1.3050e+04                    bc_loss 1.1460e+04\n",
      "Epoch 11380, Training-Loss 4.0261e+00, Data-loss 1.9940e+00                  , pde-loss 5.7831e+03, initc-loss 1.2939e+04                    bc_loss 1.5992e+03\n",
      "Epoch 11390, Training-Loss 4.5422e+00, Data-loss 2.6352e+00                  , pde-loss 5.0723e+03, initc-loss 1.2861e+04                    bc_loss 1.1370e+03\n",
      "Epoch 11400, Training-Loss 4.2959e+00, Data-loss 2.4028e+00                  , pde-loss 4.4312e+03, initc-loss 1.2873e+04                    bc_loss 1.6264e+03\n",
      "Epoch 11410, Training-Loss 4.3801e+00, Data-loss 2.4721e+00                  , pde-loss 4.3800e+03, initc-loss 1.2807e+04                    bc_loss 1.8930e+03\n",
      "Epoch 11420, Training-Loss 3.9594e+00, Data-loss 1.8495e+00                  , pde-loss 4.7242e+03, initc-loss 1.2827e+04                    bc_loss 3.5477e+03\n",
      "Epoch 11430, Training-Loss 5.8787e+00, Data-loss 2.4732e+00                  , pde-loss 4.7879e+03, initc-loss 1.2819e+04                    bc_loss 1.6448e+04\n",
      "Epoch 11440, Training-Loss 4.0474e+00, Data-loss 2.0465e+00                  , pde-loss 4.6061e+03, initc-loss 1.2828e+04                    bc_loss 2.5748e+03\n",
      "Epoch 11450, Training-Loss 4.2410e+00, Data-loss 2.3396e+00                  , pde-loss 4.4308e+03, initc-loss 1.2826e+04                    bc_loss 1.7567e+03\n",
      "Epoch 11460, Training-Loss 5.6597e+00, Data-loss 3.2658e+00                  , pde-loss 5.0773e+03, initc-loss 1.2854e+04                    bc_loss 6.0079e+03\n",
      "Epoch 11470, Training-Loss 4.4050e+00, Data-loss 2.1635e+00                  , pde-loss 5.4133e+03, initc-loss 1.2717e+04                    bc_loss 4.2850e+03\n",
      "Epoch 11480, Training-Loss 4.2644e+00, Data-loss 2.0799e+00                  , pde-loss 5.5276e+03, initc-loss 1.2849e+04                    bc_loss 3.4687e+03\n",
      "Epoch 11490, Training-Loss 4.1173e+00, Data-loss 2.1390e+00                  , pde-loss 5.2022e+03, initc-loss 1.2843e+04                    bc_loss 1.7369e+03\n",
      "Epoch 11500, Training-Loss 3.7571e+00, Data-loss 1.6255e+00                  , pde-loss 5.0339e+03, initc-loss 1.2911e+04                    bc_loss 3.3710e+03\n",
      "Epoch 11510, Training-Loss 4.2753e+00, Data-loss 2.3255e+00                  , pde-loss 5.5298e+03, initc-loss 1.2919e+04                    bc_loss 1.0494e+03\n",
      "Epoch 11520, Training-Loss 4.4125e+00, Data-loss 2.4518e+00                  , pde-loss 4.9433e+03, initc-loss 1.3040e+04                    bc_loss 1.6244e+03\n",
      "Epoch 11530, Training-Loss 3.9183e+00, Data-loss 1.7003e+00                  , pde-loss 5.0524e+03, initc-loss 1.3042e+04                    bc_loss 4.0858e+03\n",
      "Epoch 11540, Training-Loss 3.6749e+00, Data-loss 1.4256e+00                  , pde-loss 5.6406e+03, initc-loss 1.3028e+04                    bc_loss 3.8245e+03\n",
      "Epoch 11550, Training-Loss 3.8009e+00, Data-loss 1.6936e+00                  , pde-loss 5.3873e+03, initc-loss 1.3062e+04                    bc_loss 2.6235e+03\n",
      "Epoch 11560, Training-Loss 4.3910e+00, Data-loss 2.1577e+00                  , pde-loss 5.6861e+03, initc-loss 1.2962e+04                    bc_loss 3.6852e+03\n",
      "Epoch 11570, Training-Loss 3.5818e+00, Data-loss 1.4769e+00                  , pde-loss 5.7437e+03, initc-loss 1.2980e+04                    bc_loss 2.3258e+03\n",
      "Epoch 11580, Training-Loss 3.7294e+00, Data-loss 1.6286e+00                  , pde-loss 5.0676e+03, initc-loss 1.2890e+04                    bc_loss 3.0508e+03\n",
      "Epoch 11590, Training-Loss 4.2988e+00, Data-loss 2.3892e+00                  , pde-loss 5.1028e+03, initc-loss 1.2914e+04                    bc_loss 1.0801e+03\n",
      "Epoch 11600, Training-Loss 3.9781e+00, Data-loss 1.8897e+00                  , pde-loss 5.7443e+03, initc-loss 1.3024e+04                    bc_loss 2.1169e+03\n",
      "Epoch 11610, Training-Loss 3.5149e+00, Data-loss 1.4615e+00                  , pde-loss 5.5276e+03, initc-loss 1.2901e+04                    bc_loss 2.1054e+03\n",
      "Epoch 11620, Training-Loss 3.9927e+00, Data-loss 1.9079e+00                  , pde-loss 5.2256e+03, initc-loss 1.2917e+04                    bc_loss 2.7061e+03\n",
      "Epoch 11630, Training-Loss 4.6567e+00, Data-loss 1.5908e+00                  , pde-loss 5.4740e+03, initc-loss 1.2807e+04                    bc_loss 1.2378e+04\n",
      "Epoch 11640, Training-Loss 5.2259e+00, Data-loss 2.6863e+00                  , pde-loss 5.2203e+03, initc-loss 1.2777e+04                    bc_loss 7.3991e+03\n",
      "Epoch 11650, Training-Loss 3.7617e+00, Data-loss 1.6298e+00                  , pde-loss 5.4370e+03, initc-loss 1.2778e+04                    bc_loss 3.1036e+03\n",
      "Epoch 11660, Training-Loss 3.4960e+00, Data-loss 1.5940e+00                  , pde-loss 4.5276e+03, initc-loss 1.2873e+04                    bc_loss 1.6198e+03\n",
      "Epoch 11670, Training-Loss 3.9319e+00, Data-loss 1.8884e+00                  , pde-loss 6.1395e+03, initc-loss 1.2886e+04                    bc_loss 1.4092e+03\n",
      "Epoch 11680, Training-Loss 3.7287e+00, Data-loss 1.6755e+00                  , pde-loss 4.7643e+03, initc-loss 1.3000e+04                    bc_loss 2.7674e+03\n",
      "Epoch 11690, Training-Loss 4.6373e+00, Data-loss 2.3582e+00                  , pde-loss 6.1918e+03, initc-loss 1.2887e+04                    bc_loss 3.7123e+03\n",
      "Epoch 11700, Training-Loss 3.5547e+00, Data-loss 1.5680e+00                  , pde-loss 4.2826e+03, initc-loss 1.2845e+04                    bc_loss 2.7405e+03\n",
      "Epoch 11710, Training-Loss 3.9243e+00, Data-loss 1.9862e+00                  , pde-loss 5.4736e+03, initc-loss 1.2886e+04                    bc_loss 1.0216e+03\n",
      "Epoch 11720, Training-Loss 3.2977e+00, Data-loss 1.2984e+00                  , pde-loss 6.0592e+03, initc-loss 1.2865e+04                    bc_loss 1.0696e+03\n",
      "Epoch 11730, Training-Loss 4.2733e+00, Data-loss 2.0427e+00                  , pde-loss 5.2260e+03, initc-loss 1.2831e+04                    bc_loss 4.2488e+03\n",
      "Epoch 11740, Training-Loss 4.3816e+00, Data-loss 1.9038e+00                  , pde-loss 5.1894e+03, initc-loss 1.2780e+04                    bc_loss 6.8089e+03\n",
      "Epoch 11750, Training-Loss 3.2874e+00, Data-loss 1.3505e+00                  , pde-loss 5.3912e+03, initc-loss 1.2885e+04                    bc_loss 1.0919e+03\n",
      "Epoch 11760, Training-Loss 4.0377e+00, Data-loss 2.0422e+00                  , pde-loss 4.9518e+03, initc-loss 1.2925e+04                    bc_loss 2.0777e+03\n",
      "Epoch 11770, Training-Loss 3.5475e+00, Data-loss 1.5681e+00                  , pde-loss 5.7540e+03, initc-loss 1.2947e+04                    bc_loss 1.0929e+03\n",
      "Epoch 11780, Training-Loss 6.3045e+00, Data-loss 3.2573e+00                  , pde-loss 5.5470e+03, initc-loss 1.3066e+04                    bc_loss 1.1858e+04\n",
      "Epoch 11790, Training-Loss 4.2682e+00, Data-loss 2.1314e+00                  , pde-loss 5.8906e+03, initc-loss 1.2964e+04                    bc_loss 2.5127e+03\n",
      "Epoch 11800, Training-Loss 3.6262e+00, Data-loss 1.7027e+00                  , pde-loss 5.0632e+03, initc-loss 1.2902e+04                    bc_loss 1.2692e+03\n",
      "Epoch 11810, Training-Loss 3.9064e+00, Data-loss 1.6409e+00                  , pde-loss 5.6644e+03, initc-loss 1.2943e+04                    bc_loss 4.0474e+03\n",
      "Epoch 11820, Training-Loss 3.7448e+00, Data-loss 1.4697e+00                  , pde-loss 5.1652e+03, initc-loss 1.2863e+04                    bc_loss 4.7224e+03\n",
      "Epoch 11830, Training-Loss 4.3307e+00, Data-loss 1.6897e+00                  , pde-loss 5.5993e+03, initc-loss 1.2894e+04                    bc_loss 7.9168e+03\n",
      "Epoch 11840, Training-Loss 4.4730e+00, Data-loss 2.0089e+00                  , pde-loss 4.8700e+03, initc-loss 1.2801e+04                    bc_loss 6.9710e+03\n",
      "Epoch 11850, Training-Loss 3.3435e+00, Data-loss 1.2765e+00                  , pde-loss 4.9310e+03, initc-loss 1.2862e+04                    bc_loss 2.8768e+03\n",
      "Epoch 11860, Training-Loss 3.1121e+00, Data-loss 1.1869e+00                  , pde-loss 4.5514e+03, initc-loss 1.2848e+04                    bc_loss 1.8529e+03\n",
      "Epoch 11870, Training-Loss 3.3239e+00, Data-loss 1.1466e+00                  , pde-loss 6.4634e+03, initc-loss 1.2953e+04                    bc_loss 2.3573e+03\n",
      "Epoch 11880, Training-Loss 5.4282e+00, Data-loss 2.6071e+00                  , pde-loss 5.7341e+03, initc-loss 1.3080e+04                    bc_loss 9.3967e+03\n",
      "Epoch 11890, Training-Loss 5.1069e+00, Data-loss 2.3420e+00                  , pde-loss 5.1964e+03, initc-loss 1.3078e+04                    bc_loss 9.3738e+03\n",
      "Epoch 11900, Training-Loss 3.4350e+00, Data-loss 1.2089e+00                  , pde-loss 5.1551e+03, initc-loss 1.2968e+04                    bc_loss 4.1377e+03\n",
      "Epoch 11910, Training-Loss 3.9783e+00, Data-loss 1.9939e+00                  , pde-loss 5.5213e+03, initc-loss 1.2886e+04                    bc_loss 1.4363e+03\n",
      "Epoch 11920, Training-Loss 3.0541e+00, Data-loss 1.0966e+00                  , pde-loss 4.8532e+03, initc-loss 1.2865e+04                    bc_loss 1.8574e+03\n",
      "Epoch 11930, Training-Loss 3.3143e+00, Data-loss 1.2820e+00                  , pde-loss 5.6069e+03, initc-loss 1.2904e+04                    bc_loss 1.8118e+03\n",
      "Epoch 11940, Training-Loss 3.2707e+00, Data-loss 1.3255e+00                  , pde-loss 5.6111e+03, initc-loss 1.2929e+04                    bc_loss 9.1158e+02\n",
      "Epoch 11950, Training-Loss 3.6266e+00, Data-loss 1.6223e+00                  , pde-loss 5.6207e+03, initc-loss 1.2855e+04                    bc_loss 1.5677e+03\n",
      "Epoch 11960, Training-Loss 3.1772e+00, Data-loss 1.2421e+00                  , pde-loss 5.5640e+03, initc-loss 1.2930e+04                    bc_loss 8.5722e+02\n",
      "Epoch 11970, Training-Loss 3.1959e+00, Data-loss 1.2135e+00                  , pde-loss 4.8592e+03, initc-loss 1.2910e+04                    bc_loss 2.0548e+03\n",
      "Epoch 11980, Training-Loss 3.0452e+00, Data-loss 1.1258e+00                  , pde-loss 4.7596e+03, initc-loss 1.2958e+04                    bc_loss 1.4764e+03\n",
      "Epoch 11990, Training-Loss 3.6025e+00, Data-loss 1.5957e+00                  , pde-loss 5.5750e+03, initc-loss 1.2895e+04                    bc_loss 1.5977e+03\n",
      "Epoch 12000, Training-Loss 3.5163e+00, Data-loss 1.5196e+00                  , pde-loss 5.2729e+03, initc-loss 1.2842e+04                    bc_loss 1.8520e+03\n",
      "Epoch 12010, Training-Loss 2.8623e+00, Data-loss 9.1386e-01                  , pde-loss 5.4040e+03, initc-loss 1.2991e+04                    bc_loss 1.0895e+03\n",
      "Epoch 12020, Training-Loss 3.2449e+00, Data-loss 1.2722e+00                  , pde-loss 5.8277e+03, initc-loss 1.2909e+04                    bc_loss 9.8931e+02\n",
      "Epoch 12030, Training-Loss 3.6044e+00, Data-loss 1.5385e+00                  , pde-loss 5.6153e+03, initc-loss 1.2960e+04                    bc_loss 2.0840e+03\n",
      "Epoch 12040, Training-Loss 3.0977e+00, Data-loss 1.2135e+00                  , pde-loss 5.0622e+03, initc-loss 1.2906e+04                    bc_loss 8.7417e+02\n",
      "Epoch 12050, Training-Loss 3.0643e+00, Data-loss 1.1094e+00                  , pde-loss 5.6605e+03, initc-loss 1.2924e+04                    bc_loss 9.6401e+02\n",
      "Epoch 12060, Training-Loss 2.9943e+00, Data-loss 9.6716e-01                  , pde-loss 5.9068e+03, initc-loss 1.2980e+04                    bc_loss 1.3849e+03\n",
      "Epoch 12070, Training-Loss 2.9813e+00, Data-loss 1.0810e+00                  , pde-loss 5.2275e+03, initc-loss 1.2847e+04                    bc_loss 9.2839e+02\n",
      "Epoch 12080, Training-Loss 3.2271e+00, Data-loss 1.1644e+00                  , pde-loss 5.2968e+03, initc-loss 1.2893e+04                    bc_loss 2.4372e+03\n",
      "Epoch 12090, Training-Loss 3.7594e+00, Data-loss 1.4127e+00                  , pde-loss 5.5688e+03, initc-loss 1.2724e+04                    bc_loss 5.1748e+03\n",
      "Epoch 12100, Training-Loss 3.5851e+00, Data-loss 1.5402e+00                  , pde-loss 4.9856e+03, initc-loss 1.2832e+04                    bc_loss 2.6311e+03\n",
      "Epoch 12110, Training-Loss 3.3909e+00, Data-loss 1.3726e+00                  , pde-loss 5.2213e+03, initc-loss 1.2863e+04                    bc_loss 2.0979e+03\n",
      "Epoch 12120, Training-Loss 2.8859e+00, Data-loss 9.4357e-01                  , pde-loss 5.2363e+03, initc-loss 1.2827e+04                    bc_loss 1.3598e+03\n",
      "Epoch 12130, Training-Loss 4.3035e+00, Data-loss 1.6566e+00                  , pde-loss 5.7843e+03, initc-loss 1.2958e+04                    bc_loss 7.7261e+03\n",
      "Epoch 12140, Training-Loss 3.1942e+00, Data-loss 1.2007e+00                  , pde-loss 5.9311e+03, initc-loss 1.3047e+04                    bc_loss 9.5679e+02\n",
      "Epoch 12150, Training-Loss 3.5644e+00, Data-loss 1.4466e+00                  , pde-loss 5.1917e+03, initc-loss 1.2997e+04                    bc_loss 2.9896e+03\n",
      "Epoch 12160, Training-Loss 3.1499e+00, Data-loss 1.0920e+00                  , pde-loss 5.3169e+03, initc-loss 1.2994e+04                    bc_loss 2.2680e+03\n",
      "Epoch 12170, Training-Loss 3.3371e+00, Data-loss 1.4346e+00                  , pde-loss 5.2882e+03, initc-loss 1.2940e+04                    bc_loss 7.9706e+02\n",
      "Epoch 12180, Training-Loss 3.1194e+00, Data-loss 1.2337e+00                  , pde-loss 5.1224e+03, initc-loss 1.2878e+04                    bc_loss 8.5772e+02\n",
      "Epoch 12190, Training-Loss 3.1532e+00, Data-loss 1.1708e+00                  , pde-loss 5.7528e+03, initc-loss 1.2800e+04                    bc_loss 1.2712e+03\n",
      "Epoch 12200, Training-Loss 3.4664e+00, Data-loss 1.3449e+00                  , pde-loss 5.6151e+03, initc-loss 1.2759e+04                    bc_loss 2.8410e+03\n",
      "Epoch 12210, Training-Loss 2.9634e+00, Data-loss 1.0742e+00                  , pde-loss 5.1531e+03, initc-loss 1.2894e+04                    bc_loss 8.4511e+02\n",
      "Epoch 12220, Training-Loss 3.3000e+00, Data-loss 1.1033e+00                  , pde-loss 5.8398e+03, initc-loss 1.2820e+04                    bc_loss 3.3074e+03\n",
      "Epoch 12230, Training-Loss 2.9315e+00, Data-loss 1.0290e+00                  , pde-loss 4.6818e+03, initc-loss 1.2971e+04                    bc_loss 1.3721e+03\n",
      "Epoch 12240, Training-Loss 4.0039e+00, Data-loss 1.3629e+00                  , pde-loss 5.0243e+03, initc-loss 1.2752e+04                    bc_loss 8.6336e+03\n",
      "Epoch 12250, Training-Loss 3.0897e+00, Data-loss 1.1811e+00                  , pde-loss 5.1902e+03, initc-loss 1.2824e+04                    bc_loss 1.0726e+03\n",
      "Epoch 12260, Training-Loss 3.8181e+00, Data-loss 1.3838e+00                  , pde-loss 5.2302e+03, initc-loss 1.2956e+04                    bc_loss 6.1567e+03\n",
      "Epoch 12270, Training-Loss 3.0907e+00, Data-loss 1.0206e+00                  , pde-loss 4.5462e+03, initc-loss 1.2830e+04                    bc_loss 3.3252e+03\n",
      "Epoch 12280, Training-Loss 3.7773e+00, Data-loss 1.4764e+00                  , pde-loss 6.1812e+03, initc-loss 1.2853e+04                    bc_loss 3.9750e+03\n",
      "Epoch 12290, Training-Loss 2.7893e+00, Data-loss 8.5434e-01                  , pde-loss 5.7102e+03, initc-loss 1.2801e+04                    bc_loss 8.3806e+02\n",
      "Epoch 12300, Training-Loss 3.7436e+00, Data-loss 1.2517e+00                  , pde-loss 5.0787e+03, initc-loss 1.2979e+04                    bc_loss 6.8604e+03\n",
      "Epoch 12310, Training-Loss 2.6925e+00, Data-loss 7.6289e-01                  , pde-loss 4.9993e+03, initc-loss 1.2839e+04                    bc_loss 1.4576e+03\n",
      "Epoch 12320, Training-Loss 3.2045e+00, Data-loss 1.0830e+00                  , pde-loss 5.7419e+03, initc-loss 1.2837e+04                    bc_loss 2.6361e+03\n",
      "Epoch 12330, Training-Loss 3.0456e+00, Data-loss 1.1662e+00                  , pde-loss 5.1196e+03, initc-loss 1.2921e+04                    bc_loss 7.5333e+02\n",
      "Epoch 12340, Training-Loss 2.8531e+00, Data-loss 9.8168e-01                  , pde-loss 4.9678e+03, initc-loss 1.2825e+04                    bc_loss 9.2166e+02\n",
      "Epoch 12350, Training-Loss 3.1098e+00, Data-loss 1.1119e+00                  , pde-loss 5.5984e+03, initc-loss 1.2862e+04                    bc_loss 1.5189e+03\n",
      "Epoch 12360, Training-Loss 3.4257e+00, Data-loss 1.1326e+00                  , pde-loss 6.3027e+03, initc-loss 1.2910e+04                    bc_loss 3.7184e+03\n",
      "Epoch 12370, Training-Loss 3.4370e+00, Data-loss 1.3529e+00                  , pde-loss 5.0323e+03, initc-loss 1.2783e+04                    bc_loss 3.0251e+03\n",
      "Epoch 12380, Training-Loss 4.0943e+00, Data-loss 1.9082e+00                  , pde-loss 5.6671e+03, initc-loss 1.2705e+04                    bc_loss 3.4895e+03\n",
      "Epoch 12390, Training-Loss 2.7476e+00, Data-loss 7.7725e-01                  , pde-loss 5.6590e+03, initc-loss 1.2915e+04                    bc_loss 1.1293e+03\n",
      "Epoch 12400, Training-Loss 3.8661e+00, Data-loss 1.6183e+00                  , pde-loss 5.7076e+03, initc-loss 1.3089e+04                    bc_loss 3.6815e+03\n",
      "Epoch 12410, Training-Loss 3.8007e+00, Data-loss 1.5947e+00                  , pde-loss 4.9520e+03, initc-loss 1.2865e+04                    bc_loss 4.2431e+03\n",
      "Epoch 12420, Training-Loss 3.9697e+00, Data-loss 1.3983e+00                  , pde-loss 6.1267e+03, initc-loss 1.2836e+04                    bc_loss 6.7520e+03\n",
      "Epoch 12430, Training-Loss 3.4419e+00, Data-loss 1.0986e+00                  , pde-loss 5.8976e+03, initc-loss 1.2912e+04                    bc_loss 4.6241e+03\n",
      "Epoch 12440, Training-Loss 3.7740e+00, Data-loss 1.5045e+00                  , pde-loss 5.6513e+03, initc-loss 1.2869e+04                    bc_loss 4.1741e+03\n",
      "Epoch 12450, Training-Loss 2.7981e+00, Data-loss 8.4230e-01                  , pde-loss 5.9498e+03, initc-loss 1.2917e+04                    bc_loss 6.9125e+02\n",
      "Epoch 12460, Training-Loss 2.7719e+00, Data-loss 8.7136e-01                  , pde-loss 5.2980e+03, initc-loss 1.2826e+04                    bc_loss 8.8163e+02\n",
      "Epoch 12470, Training-Loss 2.9869e+00, Data-loss 9.9343e-01                  , pde-loss 5.5932e+03, initc-loss 1.2944e+04                    bc_loss 1.3970e+03\n",
      "Epoch 12480, Training-Loss 3.1058e+00, Data-loss 1.0467e+00                  , pde-loss 5.5607e+03, initc-loss 1.2772e+04                    bc_loss 2.2582e+03\n",
      "Epoch 12490, Training-Loss 3.4474e+00, Data-loss 1.0500e+00                  , pde-loss 5.1624e+03, initc-loss 1.2968e+04                    bc_loss 5.8438e+03\n",
      "Epoch 12500, Training-Loss 3.0315e+00, Data-loss 1.1162e+00                  , pde-loss 5.5229e+03, initc-loss 1.2813e+04                    bc_loss 8.1748e+02\n",
      "Epoch 12510, Training-Loss 3.6500e+00, Data-loss 1.1094e+00                  , pde-loss 4.8916e+03, initc-loss 1.2716e+04                    bc_loss 7.7987e+03\n",
      "Epoch 12520, Training-Loss 3.4131e+00, Data-loss 1.3856e+00                  , pde-loss 5.6593e+03, initc-loss 1.2842e+04                    bc_loss 1.7738e+03\n",
      "Epoch 12530, Training-Loss 3.1050e+00, Data-loss 9.6865e-01                  , pde-loss 6.0020e+03, initc-loss 1.2771e+04                    bc_loss 2.5907e+03\n",
      "Epoch 12540, Training-Loss 3.0190e+00, Data-loss 8.2288e-01                  , pde-loss 5.5660e+03, initc-loss 1.2956e+04                    bc_loss 3.4388e+03\n",
      "Epoch 12550, Training-Loss 3.7515e+00, Data-loss 1.0561e+00                  , pde-loss 5.9829e+03, initc-loss 1.2994e+04                    bc_loss 7.9763e+03\n",
      "Epoch 12560, Training-Loss 3.6616e+00, Data-loss 1.2545e+00                  , pde-loss 5.8253e+03, initc-loss 1.2945e+04                    bc_loss 5.3002e+03\n",
      "Epoch 12570, Training-Loss 2.9430e+00, Data-loss 1.0358e+00                  , pde-loss 4.9821e+03, initc-loss 1.2915e+04                    bc_loss 1.1751e+03\n",
      "Epoch 12580, Training-Loss 3.3487e+00, Data-loss 1.0258e+00                  , pde-loss 4.9553e+03, initc-loss 1.2797e+04                    bc_loss 5.4763e+03\n",
      "Epoch 12590, Training-Loss 3.2689e+00, Data-loss 1.2034e+00                  , pde-loss 5.3274e+03, initc-loss 1.2755e+04                    bc_loss 2.5724e+03\n",
      "Epoch 12600, Training-Loss 3.1763e+00, Data-loss 1.0805e+00                  , pde-loss 4.2405e+03, initc-loss 1.2810e+04                    bc_loss 3.9065e+03\n",
      "Epoch 12610, Training-Loss 3.2023e+00, Data-loss 9.4699e-01                  , pde-loss 5.7414e+03, initc-loss 1.2875e+04                    bc_loss 3.9371e+03\n",
      "Epoch 12620, Training-Loss 2.6492e+00, Data-loss 7.6221e-01                  , pde-loss 5.0840e+03, initc-loss 1.2878e+04                    bc_loss 9.0808e+02\n",
      "Epoch 12630, Training-Loss 3.1778e+00, Data-loss 1.2747e+00                  , pde-loss 5.2553e+03, initc-loss 1.2856e+04                    bc_loss 9.1951e+02\n",
      "Epoch 12640, Training-Loss 2.9041e+00, Data-loss 9.4013e-01                  , pde-loss 5.9920e+03, initc-loss 1.2813e+04                    bc_loss 8.3487e+02\n",
      "Epoch 12650, Training-Loss 2.6551e+00, Data-loss 7.3102e-01                  , pde-loss 5.2442e+03, initc-loss 1.2817e+04                    bc_loss 1.1795e+03\n",
      "Epoch 12660, Training-Loss 2.7851e+00, Data-loss 8.7193e-01                  , pde-loss 5.3114e+03, initc-loss 1.2836e+04                    bc_loss 9.8463e+02\n",
      "Epoch 12670, Training-Loss 3.0079e+00, Data-loss 1.0936e+00                  , pde-loss 5.3840e+03, initc-loss 1.2916e+04                    bc_loss 8.4285e+02\n",
      "Epoch 12680, Training-Loss 3.3966e+00, Data-loss 1.0064e+00                  , pde-loss 6.4698e+03, initc-loss 1.2969e+04                    bc_loss 4.4627e+03\n",
      "Epoch 12690, Training-Loss 3.2945e+00, Data-loss 9.1649e-01                  , pde-loss 5.5100e+03, initc-loss 1.2919e+04                    bc_loss 5.3517e+03\n",
      "Epoch 12700, Training-Loss 3.1973e+00, Data-loss 1.2209e+00                  , pde-loss 6.1275e+03, initc-loss 1.2908e+04                    bc_loss 7.2900e+02\n",
      "Epoch 12710, Training-Loss 3.0925e+00, Data-loss 1.0509e+00                  , pde-loss 5.8040e+03, initc-loss 1.2928e+04                    bc_loss 1.6843e+03\n",
      "Epoch 12720, Training-Loss 2.7794e+00, Data-loss 6.7651e-01                  , pde-loss 5.3950e+03, initc-loss 1.2913e+04                    bc_loss 2.7206e+03\n",
      "Epoch 12730, Training-Loss 2.9377e+00, Data-loss 9.1631e-01                  , pde-loss 6.0078e+03, initc-loss 1.2844e+04                    bc_loss 1.3616e+03\n",
      "Epoch 12740, Training-Loss 2.8252e+00, Data-loss 9.3124e-01                  , pde-loss 5.4549e+03, initc-loss 1.2861e+04                    bc_loss 6.2372e+02\n",
      "Epoch 12750, Training-Loss 2.9665e+00, Data-loss 1.0576e+00                  , pde-loss 4.9982e+03, initc-loss 1.2893e+04                    bc_loss 1.1971e+03\n",
      "Epoch 12760, Training-Loss 2.9129e+00, Data-loss 8.2897e-01                  , pde-loss 6.9102e+03, initc-loss 1.2922e+04                    bc_loss 1.0069e+03\n",
      "Epoch 12770, Training-Loss 2.8360e+00, Data-loss 9.1803e-01                  , pde-loss 5.1361e+03, initc-loss 1.2885e+04                    bc_loss 1.1595e+03\n",
      "Epoch 12780, Training-Loss 3.9237e+00, Data-loss 9.7778e-01                  , pde-loss 5.1889e+03, initc-loss 1.2752e+04                    bc_loss 1.1518e+04\n",
      "Epoch 12790, Training-Loss 2.8433e+00, Data-loss 9.1055e-01                  , pde-loss 5.7913e+03, initc-loss 1.2830e+04                    bc_loss 7.0623e+02\n",
      "Epoch 12800, Training-Loss 2.8602e+00, Data-loss 8.8481e-01                  , pde-loss 5.3600e+03, initc-loss 1.2870e+04                    bc_loss 1.5238e+03\n",
      "Epoch 12810, Training-Loss 2.7694e+00, Data-loss 8.0108e-01                  , pde-loss 5.1473e+03, initc-loss 1.2841e+04                    bc_loss 1.6953e+03\n",
      "Epoch 12820, Training-Loss 3.1718e+00, Data-loss 1.1980e+00                  , pde-loss 6.2657e+03, initc-loss 1.2839e+04                    bc_loss 6.3411e+02\n",
      "Epoch 12830, Training-Loss 2.9343e+00, Data-loss 7.7962e-01                  , pde-loss 6.3478e+03, initc-loss 1.2847e+04                    bc_loss 2.3517e+03\n",
      "Epoch 12840, Training-Loss 3.0430e+00, Data-loss 9.5284e-01                  , pde-loss 6.4982e+03, initc-loss 1.2912e+04                    bc_loss 1.4910e+03\n",
      "Epoch 12850, Training-Loss 2.7932e+00, Data-loss 8.8433e-01                  , pde-loss 4.7715e+03, initc-loss 1.2888e+04                    bc_loss 1.4299e+03\n",
      "Epoch 12860, Training-Loss 3.1227e+00, Data-loss 1.1136e+00                  , pde-loss 5.3488e+03, initc-loss 1.2817e+04                    bc_loss 1.9248e+03\n",
      "Epoch 12870, Training-Loss 3.2303e+00, Data-loss 1.0005e+00                  , pde-loss 5.1600e+03, initc-loss 1.2770e+04                    bc_loss 4.3681e+03\n",
      "Epoch 12880, Training-Loss 4.5043e+00, Data-loss 1.2894e+00                  , pde-loss 5.6349e+03, initc-loss 1.2767e+04                    bc_loss 1.3747e+04\n",
      "Epoch 12890, Training-Loss 3.4948e+00, Data-loss 1.2165e+00                  , pde-loss 6.3746e+03, initc-loss 1.2757e+04                    bc_loss 3.6506e+03\n",
      "Epoch 12900, Training-Loss 2.7368e+00, Data-loss 7.7057e-01                  , pde-loss 5.8709e+03, initc-loss 1.2834e+04                    bc_loss 9.5798e+02\n",
      "Epoch 12910, Training-Loss 3.1507e+00, Data-loss 1.1028e+00                  , pde-loss 6.1585e+03, initc-loss 1.2830e+04                    bc_loss 1.4907e+03\n",
      "Epoch 12920, Training-Loss 2.6296e+00, Data-loss 6.0159e-01                  , pde-loss 5.7088e+03, initc-loss 1.2927e+04                    bc_loss 1.6447e+03\n",
      "Epoch 12930, Training-Loss 2.7726e+00, Data-loss 8.0834e-01                  , pde-loss 6.0769e+03, initc-loss 1.2884e+04                    bc_loss 6.8172e+02\n",
      "Epoch 12940, Training-Loss 2.8533e+00, Data-loss 9.5180e-01                  , pde-loss 4.9847e+03, initc-loss 1.2857e+04                    bc_loss 1.1732e+03\n",
      "Epoch 12950, Training-Loss 2.8658e+00, Data-loss 9.1933e-01                  , pde-loss 4.7273e+03, initc-loss 1.2921e+04                    bc_loss 1.8165e+03\n",
      "Epoch 12960, Training-Loss 2.8058e+00, Data-loss 8.4512e-01                  , pde-loss 5.7977e+03, initc-loss 1.2863e+04                    bc_loss 9.4580e+02\n",
      "Epoch 12970, Training-Loss 3.2151e+00, Data-loss 1.2513e+00                  , pde-loss 5.1964e+03, initc-loss 1.2825e+04                    bc_loss 1.6165e+03\n",
      "Epoch 12980, Training-Loss 2.7671e+00, Data-loss 8.7414e-01                  , pde-loss 5.3353e+03, initc-loss 1.2852e+04                    bc_loss 7.4195e+02\n",
      "Epoch 12990, Training-Loss 2.6051e+00, Data-loss 6.9873e-01                  , pde-loss 5.4729e+03, initc-loss 1.2884e+04                    bc_loss 7.0662e+02\n",
      "Epoch 13000, Training-Loss 3.1445e+00, Data-loss 1.1819e+00                  , pde-loss 6.1550e+03, initc-loss 1.2888e+04                    bc_loss 5.8293e+02\n",
      "Epoch 13010, Training-Loss 3.0201e+00, Data-loss 1.0680e+00                  , pde-loss 6.1128e+03, initc-loss 1.2905e+04                    bc_loss 5.0305e+02\n",
      "Epoch 13020, Training-Loss 2.7741e+00, Data-loss 8.1224e-01                  , pde-loss 5.8608e+03, initc-loss 1.2856e+04                    bc_loss 9.0217e+02\n",
      "Epoch 13030, Training-Loss 3.2813e+00, Data-loss 1.0700e+00                  , pde-loss 5.6842e+03, initc-loss 1.2938e+04                    bc_loss 3.4902e+03\n",
      "Epoch 13040, Training-Loss 2.7915e+00, Data-loss 9.5524e-01                  , pde-loss 4.9973e+03, initc-loss 1.2814e+04                    bc_loss 5.5153e+02\n",
      "Epoch 13050, Training-Loss 3.0793e+00, Data-loss 9.0570e-01                  , pde-loss 5.9226e+03, initc-loss 1.2913e+04                    bc_loss 2.9010e+03\n",
      "Epoch 13060, Training-Loss 2.6586e+00, Data-loss 6.6776e-01                  , pde-loss 5.6878e+03, initc-loss 1.2918e+04                    bc_loss 1.3025e+03\n",
      "Epoch 13070, Training-Loss 4.0669e+00, Data-loss 1.4726e+00                  , pde-loss 6.3662e+03, initc-loss 1.3025e+04                    bc_loss 6.5522e+03\n",
      "Epoch 13080, Training-Loss 2.8036e+00, Data-loss 8.1716e-01                  , pde-loss 6.1405e+03, initc-loss 1.2915e+04                    bc_loss 8.0957e+02\n",
      "Epoch 13090, Training-Loss 2.8615e+00, Data-loss 8.3036e-01                  , pde-loss 6.5233e+03, initc-loss 1.2987e+04                    bc_loss 8.0111e+02\n",
      "Epoch 13100, Training-Loss 2.7001e+00, Data-loss 7.0426e-01                  , pde-loss 6.1885e+03, initc-loss 1.2831e+04                    bc_loss 9.3930e+02\n",
      "Epoch 13110, Training-Loss 2.6919e+00, Data-loss 7.9075e-01                  , pde-loss 5.5105e+03, initc-loss 1.2913e+04                    bc_loss 5.8779e+02\n",
      "Epoch 13120, Training-Loss 3.5684e+00, Data-loss 9.3749e-01                  , pde-loss 4.9423e+03, initc-loss 1.2733e+04                    bc_loss 8.6332e+03\n",
      "Epoch 13130, Training-Loss 3.1732e+00, Data-loss 9.5086e-01                  , pde-loss 5.1112e+03, initc-loss 1.2946e+04                    bc_loss 4.1665e+03\n",
      "Epoch 13140, Training-Loss 3.2769e+00, Data-loss 9.3127e-01                  , pde-loss 5.8816e+03, initc-loss 1.2825e+04                    bc_loss 4.7497e+03\n",
      "Epoch 13150, Training-Loss 5.1733e+00, Data-loss 2.6983e+00                  , pde-loss 5.9990e+03, initc-loss 1.2654e+04                    bc_loss 6.0971e+03\n",
      "Epoch 13160, Training-Loss 3.0548e+00, Data-loss 9.1475e-01                  , pde-loss 5.4461e+03, initc-loss 1.2780e+04                    bc_loss 3.1753e+03\n",
      "Epoch 13170, Training-Loss 2.6465e+00, Data-loss 7.6015e-01                  , pde-loss 4.9368e+03, initc-loss 1.2927e+04                    bc_loss 9.9983e+02\n",
      "Epoch 13180, Training-Loss 2.8620e+00, Data-loss 8.3408e-01                  , pde-loss 5.1443e+03, initc-loss 1.2904e+04                    bc_loss 2.2315e+03\n",
      "Epoch 13190, Training-Loss 3.4854e+00, Data-loss 1.2227e+00                  , pde-loss 6.0620e+03, initc-loss 1.2885e+04                    bc_loss 3.6796e+03\n",
      "Epoch 13200, Training-Loss 2.8745e+00, Data-loss 8.6886e-01                  , pde-loss 5.9182e+03, initc-loss 1.2796e+04                    bc_loss 1.3427e+03\n",
      "Epoch 13210, Training-Loss 3.2000e+00, Data-loss 9.7392e-01                  , pde-loss 5.8862e+03, initc-loss 1.2732e+04                    bc_loss 3.6434e+03\n",
      "Epoch 13220, Training-Loss 3.3716e+00, Data-loss 1.1923e+00                  , pde-loss 5.2219e+03, initc-loss 1.2812e+04                    bc_loss 3.7595e+03\n",
      "Epoch 13230, Training-Loss 3.3829e+00, Data-loss 1.0684e+00                  , pde-loss 5.5197e+03, initc-loss 1.2800e+04                    bc_loss 4.8256e+03\n",
      "Epoch 13240, Training-Loss 2.8048e+00, Data-loss 8.0297e-01                  , pde-loss 5.9129e+03, initc-loss 1.2860e+04                    bc_loss 1.2452e+03\n",
      "Epoch 13250, Training-Loss 2.6338e+00, Data-loss 6.3259e-01                  , pde-loss 5.3406e+03, initc-loss 1.2841e+04                    bc_loss 1.8305e+03\n",
      "Epoch 13260, Training-Loss 2.7411e+00, Data-loss 7.8486e-01                  , pde-loss 5.0386e+03, initc-loss 1.2944e+04                    bc_loss 1.5802e+03\n",
      "Epoch 13270, Training-Loss 3.3564e+00, Data-loss 1.0929e+00                  , pde-loss 6.1887e+03, initc-loss 1.2993e+04                    bc_loss 3.4537e+03\n",
      "Epoch 13280, Training-Loss 2.9723e+00, Data-loss 9.4421e-01                  , pde-loss 5.9278e+03, initc-loss 1.2939e+04                    bc_loss 1.4142e+03\n",
      "Epoch 13290, Training-Loss 2.8374e+00, Data-loss 7.0856e-01                  , pde-loss 6.2476e+03, initc-loss 1.2919e+04                    bc_loss 2.1213e+03\n",
      "Epoch 13300, Training-Loss 3.7962e+00, Data-loss 1.3873e+00                  , pde-loss 4.9671e+03, initc-loss 1.3027e+04                    bc_loss 6.0952e+03\n",
      "Epoch 13310, Training-Loss 3.8322e+00, Data-loss 1.3698e+00                  , pde-loss 6.3857e+03, initc-loss 1.2937e+04                    bc_loss 5.3009e+03\n",
      "Epoch 13320, Training-Loss 3.9042e+00, Data-loss 1.7839e+00                  , pde-loss 5.6901e+03, initc-loss 1.2996e+04                    bc_loss 2.5166e+03\n",
      "Epoch 13330, Training-Loss 3.4024e+00, Data-loss 9.4771e-01                  , pde-loss 5.8351e+03, initc-loss 1.2954e+04                    bc_loss 5.7580e+03\n",
      "Epoch 13340, Training-Loss 3.1065e+00, Data-loss 8.6288e-01                  , pde-loss 5.9797e+03, initc-loss 1.2920e+04                    bc_loss 3.5364e+03\n",
      "Epoch 13350, Training-Loss 3.0204e+00, Data-loss 1.0319e+00                  , pde-loss 6.2864e+03, initc-loss 1.2877e+04                    bc_loss 7.2182e+02\n",
      "Epoch 13360, Training-Loss 3.7291e+00, Data-loss 1.0558e+00                  , pde-loss 5.8864e+03, initc-loss 1.2943e+04                    bc_loss 7.9039e+03\n",
      "Epoch 13370, Training-Loss 3.5447e+00, Data-loss 1.1726e+00                  , pde-loss 5.7088e+03, initc-loss 1.2958e+04                    bc_loss 5.0540e+03\n",
      "Epoch 13380, Training-Loss 3.5158e+00, Data-loss 1.0969e+00                  , pde-loss 5.3274e+03, initc-loss 1.3017e+04                    bc_loss 5.8445e+03\n",
      "Epoch 13390, Training-Loss 2.7735e+00, Data-loss 8.3966e-01                  , pde-loss 5.8588e+03, initc-loss 1.2931e+04                    bc_loss 5.4921e+02\n",
      "Epoch 13400, Training-Loss 2.8143e+00, Data-loss 8.1069e-01                  , pde-loss 5.2821e+03, initc-loss 1.2898e+04                    bc_loss 1.8554e+03\n",
      "Epoch 13410, Training-Loss 2.8640e+00, Data-loss 9.0633e-01                  , pde-loss 5.6811e+03, initc-loss 1.2888e+04                    bc_loss 1.0077e+03\n",
      "Epoch 13420, Training-Loss 2.7293e+00, Data-loss 8.5929e-01                  , pde-loss 5.3529e+03, initc-loss 1.2871e+04                    bc_loss 4.7645e+02\n",
      "Epoch 13430, Training-Loss 2.9857e+00, Data-loss 9.2444e-01                  , pde-loss 6.5412e+03, initc-loss 1.2916e+04                    bc_loss 1.1553e+03\n",
      "Epoch 13440, Training-Loss 2.7909e+00, Data-loss 7.0020e-01                  , pde-loss 6.4410e+03, initc-loss 1.2883e+04                    bc_loss 1.5832e+03\n",
      "Epoch 13450, Training-Loss 2.5914e+00, Data-loss 6.8331e-01                  , pde-loss 5.7836e+03, initc-loss 1.2866e+04                    bc_loss 4.3225e+02\n",
      "Epoch 13460, Training-Loss 2.5462e+00, Data-loss 6.4559e-01                  , pde-loss 5.6553e+03, initc-loss 1.2917e+04                    bc_loss 4.3329e+02\n",
      "Epoch 13470, Training-Loss 3.3246e+00, Data-loss 1.3107e+00                  , pde-loss 4.5752e+03, initc-loss 1.2732e+04                    bc_loss 2.8319e+03\n",
      "Epoch 13480, Training-Loss 3.4305e+00, Data-loss 1.0215e+00                  , pde-loss 5.4903e+03, initc-loss 1.2852e+04                    bc_loss 5.7473e+03\n",
      "Epoch 13490, Training-Loss 2.8872e+00, Data-loss 8.1855e-01                  , pde-loss 6.1898e+03, initc-loss 1.2841e+04                    bc_loss 1.6559e+03\n",
      "Epoch 13500, Training-Loss 2.7554e+00, Data-loss 8.2270e-01                  , pde-loss 5.9021e+03, initc-loss 1.2825e+04                    bc_loss 5.9990e+02\n",
      "Epoch 13510, Training-Loss 2.6429e+00, Data-loss 7.3045e-01                  , pde-loss 5.8992e+03, initc-loss 1.2874e+04                    bc_loss 3.5147e+02\n",
      "Epoch 13520, Training-Loss 2.5815e+00, Data-loss 6.7256e-01                  , pde-loss 5.5513e+03, initc-loss 1.2844e+04                    bc_loss 6.9336e+02\n",
      "Epoch 13530, Training-Loss 2.8396e+00, Data-loss 8.7311e-01                  , pde-loss 5.7851e+03, initc-loss 1.2872e+04                    bc_loss 1.0074e+03\n",
      "Epoch 13540, Training-Loss 2.8479e+00, Data-loss 7.8233e-01                  , pde-loss 6.4350e+03, initc-loss 1.2880e+04                    bc_loss 1.3410e+03\n",
      "Epoch 13550, Training-Loss 3.6270e+00, Data-loss 1.3672e+00                  , pde-loss 6.6083e+03, initc-loss 1.2762e+04                    bc_loss 3.2271e+03\n",
      "Epoch 13560, Training-Loss 2.5273e+00, Data-loss 5.5650e-01                  , pde-loss 4.9738e+03, initc-loss 1.2926e+04                    bc_loss 1.8090e+03\n",
      "Epoch 13570, Training-Loss 3.1148e+00, Data-loss 1.0602e+00                  , pde-loss 7.0312e+03, initc-loss 1.2909e+04                    bc_loss 6.0606e+02\n",
      "Epoch 13580, Training-Loss 2.6583e+00, Data-loss 7.7588e-01                  , pde-loss 5.4750e+03, initc-loss 1.2900e+04                    bc_loss 4.4849e+02\n",
      "Epoch 13590, Training-Loss 2.4966e+00, Data-loss 5.5777e-01                  , pde-loss 5.2873e+03, initc-loss 1.2867e+04                    bc_loss 1.2345e+03\n",
      "Epoch 13600, Training-Loss 2.8442e+00, Data-loss 9.0421e-01                  , pde-loss 6.0585e+03, initc-loss 1.2840e+04                    bc_loss 5.0110e+02\n",
      "Epoch 13610, Training-Loss 2.7682e+00, Data-loss 8.3146e-01                  , pde-loss 4.9161e+03, initc-loss 1.2856e+04                    bc_loss 1.5950e+03\n",
      "Epoch 13620, Training-Loss 2.6995e+00, Data-loss 7.6119e-01                  , pde-loss 6.0476e+03, initc-loss 1.2863e+04                    bc_loss 4.7266e+02\n",
      "Epoch 13630, Training-Loss 2.4243e+00, Data-loss 6.1785e-01                  , pde-loss 4.7238e+03, initc-loss 1.2891e+04                    bc_loss 4.4895e+02\n",
      "Epoch 13640, Training-Loss 2.7698e+00, Data-loss 7.9262e-01                  , pde-loss 6.0478e+03, initc-loss 1.2788e+04                    bc_loss 9.3554e+02\n",
      "Epoch 13650, Training-Loss 3.3425e+00, Data-loss 1.1818e+00                  , pde-loss 5.5800e+03, initc-loss 1.3023e+04                    bc_loss 3.0046e+03\n",
      "Epoch 13660, Training-Loss 2.6985e+00, Data-loss 6.6134e-01                  , pde-loss 5.8222e+03, initc-loss 1.2984e+04                    bc_loss 1.5655e+03\n",
      "Epoch 13670, Training-Loss 2.6536e+00, Data-loss 8.2008e-01                  , pde-loss 5.0735e+03, initc-loss 1.2885e+04                    bc_loss 3.7704e+02\n",
      "Epoch 13680, Training-Loss 2.7057e+00, Data-loss 7.5585e-01                  , pde-loss 5.4374e+03, initc-loss 1.2875e+04                    bc_loss 1.1870e+03\n",
      "Epoch 13690, Training-Loss 3.4134e+00, Data-loss 9.6331e-01                  , pde-loss 6.1506e+03, initc-loss 1.2764e+04                    bc_loss 5.5863e+03\n",
      "Epoch 13700, Training-Loss 3.8974e+00, Data-loss 1.1271e+00                  , pde-loss 5.5076e+03, initc-loss 1.2812e+04                    bc_loss 9.3834e+03\n",
      "Epoch 13710, Training-Loss 2.8310e+00, Data-loss 7.6115e-01                  , pde-loss 6.5385e+03, initc-loss 1.2929e+04                    bc_loss 1.2311e+03\n",
      "Epoch 13720, Training-Loss 3.6240e+00, Data-loss 1.1882e+00                  , pde-loss 6.3672e+03, initc-loss 1.2689e+04                    bc_loss 5.3023e+03\n",
      "Epoch 13730, Training-Loss 2.7556e+00, Data-loss 6.7367e-01                  , pde-loss 5.3404e+03, initc-loss 1.2866e+04                    bc_loss 2.6125e+03\n",
      "Epoch 13740, Training-Loss 2.9857e+00, Data-loss 1.0190e+00                  , pde-loss 6.1809e+03, initc-loss 1.2904e+04                    bc_loss 5.8150e+02\n",
      "Epoch 13750, Training-Loss 3.2510e+00, Data-loss 1.1051e+00                  , pde-loss 6.2167e+03, initc-loss 1.2865e+04                    bc_loss 2.3784e+03\n",
      "Epoch 13760, Training-Loss 3.4386e+00, Data-loss 1.2945e+00                  , pde-loss 5.9482e+03, initc-loss 1.2796e+04                    bc_loss 2.6971e+03\n",
      "Epoch 13770, Training-Loss 2.9617e+00, Data-loss 9.9257e-01                  , pde-loss 5.5625e+03, initc-loss 1.2838e+04                    bc_loss 1.2908e+03\n",
      "Epoch 13780, Training-Loss 3.1763e+00, Data-loss 8.0498e-01                  , pde-loss 6.3983e+03, initc-loss 1.2928e+04                    bc_loss 4.3864e+03\n",
      "Epoch 13790, Training-Loss 2.8428e+00, Data-loss 7.8627e-01                  , pde-loss 5.4123e+03, initc-loss 1.2850e+04                    bc_loss 2.3030e+03\n",
      "Epoch 13800, Training-Loss 2.8230e+00, Data-loss 8.7505e-01                  , pde-loss 5.9493e+03, initc-loss 1.2929e+04                    bc_loss 6.0076e+02\n",
      "Epoch 13810, Training-Loss 3.0597e+00, Data-loss 9.8075e-01                  , pde-loss 6.0336e+03, initc-loss 1.2817e+04                    bc_loss 1.9386e+03\n",
      "Epoch 13820, Training-Loss 2.8477e+00, Data-loss 6.9440e-01                  , pde-loss 6.4049e+03, initc-loss 1.2824e+04                    bc_loss 2.3041e+03\n",
      "Epoch 13830, Training-Loss 2.5931e+00, Data-loss 6.7350e-01                  , pde-loss 5.4715e+03, initc-loss 1.2884e+04                    bc_loss 8.4009e+02\n",
      "Epoch 13840, Training-Loss 2.7242e+00, Data-loss 7.9318e-01                  , pde-loss 5.5241e+03, initc-loss 1.2894e+04                    bc_loss 8.9264e+02\n",
      "Epoch 13850, Training-Loss 3.1200e+00, Data-loss 1.1109e+00                  , pde-loss 6.3803e+03, initc-loss 1.2961e+04                    bc_loss 7.4945e+02\n",
      "Epoch 13860, Training-Loss 3.3832e+00, Data-loss 9.8861e-01                  , pde-loss 5.6426e+03, initc-loss 1.2982e+04                    bc_loss 5.3212e+03\n",
      "Epoch 13870, Training-Loss 2.9450e+00, Data-loss 9.6885e-01                  , pde-loss 5.8519e+03, initc-loss 1.2922e+04                    bc_loss 9.8738e+02\n",
      "Epoch 13880, Training-Loss 2.7896e+00, Data-loss 6.9520e-01                  , pde-loss 6.7036e+03, initc-loss 1.2836e+04                    bc_loss 1.4044e+03\n",
      "Epoch 13890, Training-Loss 2.7603e+00, Data-loss 8.2804e-01                  , pde-loss 5.8722e+03, initc-loss 1.2863e+04                    bc_loss 5.8699e+02\n",
      "Epoch 13900, Training-Loss 2.9270e+00, Data-loss 9.9033e-01                  , pde-loss 5.8107e+03, initc-loss 1.2880e+04                    bc_loss 6.7639e+02\n",
      "Epoch 13910, Training-Loss 2.6329e+00, Data-loss 7.0665e-01                  , pde-loss 5.8319e+03, initc-loss 1.2950e+04                    bc_loss 4.8139e+02\n",
      "Epoch 13920, Training-Loss 2.4651e+00, Data-loss 5.4588e-01                  , pde-loss 5.8232e+03, initc-loss 1.2821e+04                    bc_loss 5.4765e+02\n",
      "Epoch 13930, Training-Loss 2.3849e+00, Data-loss 4.6973e-01                  , pde-loss 4.9373e+03, initc-loss 1.2946e+04                    bc_loss 1.2685e+03\n",
      "Epoch 13940, Training-Loss 2.7087e+00, Data-loss 8.1948e-01                  , pde-loss 5.5716e+03, initc-loss 1.2845e+04                    bc_loss 4.7472e+02\n",
      "Epoch 13950, Training-Loss 2.6253e+00, Data-loss 6.4868e-01                  , pde-loss 6.0208e+03, initc-loss 1.2909e+04                    bc_loss 8.3662e+02\n",
      "Epoch 13960, Training-Loss 2.6959e+00, Data-loss 7.3468e-01                  , pde-loss 6.1179e+03, initc-loss 1.2863e+04                    bc_loss 6.3134e+02\n",
      "Epoch 13970, Training-Loss 2.6713e+00, Data-loss 6.6374e-01                  , pde-loss 5.1358e+03, initc-loss 1.2818e+04                    bc_loss 2.1214e+03\n",
      "Epoch 13980, Training-Loss 2.7927e+00, Data-loss 6.9461e-01                  , pde-loss 5.9000e+03, initc-loss 1.2951e+04                    bc_loss 2.1294e+03\n",
      "Epoch 13990, Training-Loss 2.5406e+00, Data-loss 6.4379e-01                  , pde-loss 4.6466e+03, initc-loss 1.2842e+04                    bc_loss 1.4798e+03\n",
      "Epoch 14000, Training-Loss 2.8484e+00, Data-loss 9.7279e-01                  , pde-loss 5.1396e+03, initc-loss 1.2939e+04                    bc_loss 6.7689e+02\n",
      "Epoch 14010, Training-Loss 2.8223e+00, Data-loss 9.3391e-01                  , pde-loss 5.4550e+03, initc-loss 1.2761e+04                    bc_loss 6.6713e+02\n",
      "Epoch 14020, Training-Loss 2.8189e+00, Data-loss 8.2148e-01                  , pde-loss 6.0959e+03, initc-loss 1.2884e+04                    bc_loss 9.9487e+02\n",
      "Epoch 14030, Training-Loss 2.8687e+00, Data-loss 8.7271e-01                  , pde-loss 5.2341e+03, initc-loss 1.2864e+04                    bc_loss 1.8620e+03\n",
      "Epoch 14040, Training-Loss 2.6909e+00, Data-loss 7.7447e-01                  , pde-loss 5.5630e+03, initc-loss 1.2802e+04                    bc_loss 7.9890e+02\n",
      "Epoch 14050, Training-Loss 2.6573e+00, Data-loss 7.2648e-01                  , pde-loss 6.0665e+03, initc-loss 1.2902e+04                    bc_loss 3.3960e+02\n",
      "Epoch 14060, Training-Loss 3.1015e+00, Data-loss 9.0018e-01                  , pde-loss 6.1358e+03, initc-loss 1.2858e+04                    bc_loss 3.0195e+03\n",
      "Epoch 14070, Training-Loss 3.4062e+00, Data-loss 1.2719e+00                  , pde-loss 5.6470e+03, initc-loss 1.2970e+04                    bc_loss 2.7269e+03\n",
      "Epoch 14080, Training-Loss 2.8295e+00, Data-loss 7.3185e-01                  , pde-loss 5.8612e+03, initc-loss 1.2925e+04                    bc_loss 2.1905e+03\n",
      "Epoch 14090, Training-Loss 2.6525e+00, Data-loss 6.4780e-01                  , pde-loss 5.8519e+03, initc-loss 1.2896e+04                    bc_loss 1.2998e+03\n",
      "Epoch 14100, Training-Loss 3.1369e+00, Data-loss 1.1261e+00                  , pde-loss 6.1226e+03, initc-loss 1.2819e+04                    bc_loss 1.1674e+03\n",
      "Epoch 14110, Training-Loss 2.7190e+00, Data-loss 6.8974e-01                  , pde-loss 5.4876e+03, initc-loss 1.2840e+04                    bc_loss 1.9648e+03\n",
      "Epoch 14120, Training-Loss 2.8293e+00, Data-loss 8.5723e-01                  , pde-loss 6.2676e+03, initc-loss 1.2859e+04                    bc_loss 5.9422e+02\n",
      "Epoch 14130, Training-Loss 3.1661e+00, Data-loss 1.1241e+00                  , pde-loss 5.6842e+03, initc-loss 1.3053e+04                    bc_loss 1.6830e+03\n",
      "Epoch 14140, Training-Loss 3.4096e+00, Data-loss 1.3163e+00                  , pde-loss 5.6610e+03, initc-loss 1.3021e+04                    bc_loss 2.2503e+03\n",
      "Epoch 14150, Training-Loss 2.3490e+00, Data-loss 4.6094e-01                  , pde-loss 5.5247e+03, initc-loss 1.2844e+04                    bc_loss 5.1164e+02\n",
      "Epoch 14160, Training-Loss 3.2005e+00, Data-loss 9.3909e-01                  , pde-loss 5.5567e+03, initc-loss 1.2860e+04                    bc_loss 4.1977e+03\n",
      "Epoch 14170, Training-Loss 3.0105e+00, Data-loss 8.9697e-01                  , pde-loss 6.0132e+03, initc-loss 1.2812e+04                    bc_loss 2.3098e+03\n",
      "Epoch 14180, Training-Loss 2.9206e+00, Data-loss 8.5183e-01                  , pde-loss 5.2567e+03, initc-loss 1.2800e+04                    bc_loss 2.6315e+03\n",
      "Epoch 14190, Training-Loss 2.5965e+00, Data-loss 6.0840e-01                  , pde-loss 6.2579e+03, initc-loss 1.2930e+04                    bc_loss 6.9304e+02\n",
      "Epoch 14200, Training-Loss 3.0516e+00, Data-loss 1.0041e+00                  , pde-loss 5.2229e+03, initc-loss 1.2999e+04                    bc_loss 2.2532e+03\n",
      "Epoch 14210, Training-Loss 3.1727e+00, Data-loss 1.2015e+00                  , pde-loss 5.7126e+03, initc-loss 1.2947e+04                    bc_loss 1.0526e+03\n",
      "Epoch 14220, Training-Loss 2.5816e+00, Data-loss 6.7411e-01                  , pde-loss 5.5952e+03, initc-loss 1.2792e+04                    bc_loss 6.8797e+02\n",
      "Epoch 14230, Training-Loss 2.7070e+00, Data-loss 8.0257e-01                  , pde-loss 5.7494e+03, initc-loss 1.2829e+04                    bc_loss 4.6556e+02\n",
      "Epoch 14240, Training-Loss 2.4677e+00, Data-loss 5.7760e-01                  , pde-loss 5.4600e+03, initc-loss 1.2859e+04                    bc_loss 5.8235e+02\n",
      "Epoch 14250, Training-Loss 2.6290e+00, Data-loss 6.8657e-01                  , pde-loss 6.1481e+03, initc-loss 1.2881e+04                    bc_loss 3.9560e+02\n",
      "Epoch 14260, Training-Loss 2.5421e+00, Data-loss 6.0730e-01                  , pde-loss 5.4667e+03, initc-loss 1.2804e+04                    bc_loss 1.0779e+03\n",
      "Epoch 14270, Training-Loss 2.6044e+00, Data-loss 7.0071e-01                  , pde-loss 5.4082e+03, initc-loss 1.2968e+04                    bc_loss 6.6139e+02\n",
      "Epoch 14280, Training-Loss 2.6356e+00, Data-loss 6.2314e-01                  , pde-loss 5.5060e+03, initc-loss 1.2883e+04                    bc_loss 1.7360e+03\n",
      "Epoch 14290, Training-Loss 2.5926e+00, Data-loss 7.0629e-01                  , pde-loss 5.3176e+03, initc-loss 1.2945e+04                    bc_loss 6.0099e+02\n",
      "Epoch 14300, Training-Loss 2.8422e+00, Data-loss 8.2059e-01                  , pde-loss 5.8203e+03, initc-loss 1.2865e+04                    bc_loss 1.5313e+03\n",
      "Epoch 14310, Training-Loss 3.7938e+00, Data-loss 1.0662e+00                  , pde-loss 6.0183e+03, initc-loss 1.2979e+04                    bc_loss 8.2786e+03\n",
      "Epoch 14320, Training-Loss 2.8182e+00, Data-loss 8.0697e-01                  , pde-loss 6.8105e+03, initc-loss 1.2919e+04                    bc_loss 3.8254e+02\n",
      "Epoch 14330, Training-Loss 2.5642e+00, Data-loss 7.0117e-01                  , pde-loss 5.1390e+03, initc-loss 1.2804e+04                    bc_loss 6.8785e+02\n",
      "Epoch 14340, Training-Loss 2.9815e+00, Data-loss 7.1850e-01                  , pde-loss 6.2031e+03, initc-loss 1.2797e+04                    bc_loss 3.6300e+03\n",
      "Epoch 14350, Training-Loss 2.6592e+00, Data-loss 5.7151e-01                  , pde-loss 6.2750e+03, initc-loss 1.2846e+04                    bc_loss 1.7560e+03\n",
      "Epoch 14360, Training-Loss 2.5749e+00, Data-loss 6.0245e-01                  , pde-loss 6.2004e+03, initc-loss 1.2949e+04                    bc_loss 5.7517e+02\n",
      "Epoch 14370, Training-Loss 2.5956e+00, Data-loss 6.3688e-01                  , pde-loss 6.2227e+03, initc-loss 1.2945e+04                    bc_loss 4.1969e+02\n",
      "Epoch 14380, Training-Loss 2.5121e+00, Data-loss 5.7152e-01                  , pde-loss 6.0882e+03, initc-loss 1.2901e+04                    bc_loss 4.1618e+02\n",
      "Epoch 14390, Training-Loss 2.4941e+00, Data-loss 5.5251e-01                  , pde-loss 5.6686e+03, initc-loss 1.2830e+04                    bc_loss 9.1794e+02\n",
      "Epoch 14400, Training-Loss 2.7466e+00, Data-loss 5.7616e-01                  , pde-loss 5.8971e+03, initc-loss 1.2897e+04                    bc_loss 2.9103e+03\n",
      "Epoch 14410, Training-Loss 2.6809e+00, Data-loss 7.6789e-01                  , pde-loss 5.7637e+03, initc-loss 1.2958e+04                    bc_loss 4.0811e+02\n",
      "Epoch 14420, Training-Loss 2.5788e+00, Data-loss 5.8816e-01                  , pde-loss 5.8840e+03, initc-loss 1.2843e+04                    bc_loss 1.1799e+03\n",
      "Epoch 14430, Training-Loss 2.7080e+00, Data-loss 6.1281e-01                  , pde-loss 5.9594e+03, initc-loss 1.2872e+04                    bc_loss 2.1205e+03\n",
      "Epoch 14440, Training-Loss 2.8704e+00, Data-loss 8.7455e-01                  , pde-loss 5.6065e+03, initc-loss 1.2834e+04                    bc_loss 1.5180e+03\n",
      "Epoch 14450, Training-Loss 2.5649e+00, Data-loss 6.2735e-01                  , pde-loss 5.9830e+03, initc-loss 1.2871e+04                    bc_loss 5.2155e+02\n",
      "Epoch 14460, Training-Loss 3.1059e+00, Data-loss 9.5591e-01                  , pde-loss 5.9693e+03, initc-loss 1.2995e+04                    bc_loss 2.5357e+03\n",
      "Epoch 14470, Training-Loss 3.3775e+00, Data-loss 8.5485e-01                  , pde-loss 5.7816e+03, initc-loss 1.2965e+04                    bc_loss 6.4800e+03\n",
      "Epoch 14480, Training-Loss 3.0425e+00, Data-loss 8.7525e-01                  , pde-loss 6.1281e+03, initc-loss 1.2811e+04                    bc_loss 2.7335e+03\n",
      "Epoch 14490, Training-Loss 2.7522e+00, Data-loss 7.7242e-01                  , pde-loss 5.8581e+03, initc-loss 1.2898e+04                    bc_loss 1.0416e+03\n",
      "Epoch 14500, Training-Loss 2.5298e+00, Data-loss 6.5030e-01                  , pde-loss 5.1486e+03, initc-loss 1.2881e+04                    bc_loss 7.6542e+02\n",
      "Epoch 14510, Training-Loss 3.1190e+00, Data-loss 9.0337e-01                  , pde-loss 5.3350e+03, initc-loss 1.2742e+04                    bc_loss 4.0795e+03\n",
      "Epoch 14520, Training-Loss 2.8352e+00, Data-loss 9.1975e-01                  , pde-loss 5.7511e+03, initc-loss 1.2901e+04                    bc_loss 5.0221e+02\n",
      "Epoch 14530, Training-Loss 3.1946e+00, Data-loss 7.5368e-01                  , pde-loss 6.6233e+03, initc-loss 1.2879e+04                    bc_loss 4.9072e+03\n",
      "Epoch 14540, Training-Loss 2.6816e+00, Data-loss 6.5087e-01                  , pde-loss 5.9336e+03, initc-loss 1.2922e+04                    bc_loss 1.4515e+03\n",
      "Epoch 14550, Training-Loss 2.7275e+00, Data-loss 8.0958e-01                  , pde-loss 5.5108e+03, initc-loss 1.2918e+04                    bc_loss 7.5003e+02\n",
      "Epoch 14560, Training-Loss 2.6440e+00, Data-loss 7.1412e-01                  , pde-loss 5.5683e+03, initc-loss 1.2917e+04                    bc_loss 8.1386e+02\n",
      "Epoch 14570, Training-Loss 2.4694e+00, Data-loss 5.1627e-01                  , pde-loss 5.0396e+03, initc-loss 1.2864e+04                    bc_loss 1.6276e+03\n",
      "Epoch 14580, Training-Loss 2.9940e+00, Data-loss 7.8915e-01                  , pde-loss 5.6861e+03, initc-loss 1.2836e+04                    bc_loss 3.5261e+03\n",
      "Epoch 14590, Training-Loss 2.7076e+00, Data-loss 7.6072e-01                  , pde-loss 6.0411e+03, initc-loss 1.2846e+04                    bc_loss 5.8105e+02\n",
      "Epoch 14600, Training-Loss 2.4406e+00, Data-loss 5.1709e-01                  , pde-loss 5.9489e+03, initc-loss 1.2918e+04                    bc_loss 3.6870e+02\n",
      "Epoch 14610, Training-Loss 2.4868e+00, Data-loss 5.9801e-01                  , pde-loss 5.7549e+03, initc-loss 1.2889e+04                    bc_loss 2.4324e+02\n",
      "Epoch 14620, Training-Loss 2.6433e+00, Data-loss 6.1928e-01                  , pde-loss 6.0256e+03, initc-loss 1.2836e+04                    bc_loss 1.3783e+03\n",
      "Epoch 14630, Training-Loss 2.7632e+00, Data-loss 7.9364e-01                  , pde-loss 6.0605e+03, initc-loss 1.2883e+04                    bc_loss 7.5160e+02\n",
      "Epoch 14640, Training-Loss 2.4187e+00, Data-loss 5.3202e-01                  , pde-loss 5.3169e+03, initc-loss 1.2884e+04                    bc_loss 6.6620e+02\n",
      "Epoch 14650, Training-Loss 3.0683e+00, Data-loss 7.6596e-01                  , pde-loss 6.1541e+03, initc-loss 1.2839e+04                    bc_loss 4.0312e+03\n",
      "Epoch 14660, Training-Loss 2.6354e+00, Data-loss 8.5472e-01                  , pde-loss 4.0811e+03, initc-loss 1.2816e+04                    bc_loss 9.0934e+02\n",
      "Epoch 14670, Training-Loss 2.6707e+00, Data-loss 6.8052e-01                  , pde-loss 5.7517e+03, initc-loss 1.2882e+04                    bc_loss 1.2681e+03\n",
      "Epoch 14680, Training-Loss 3.2795e+00, Data-loss 9.2777e-01                  , pde-loss 5.5248e+03, initc-loss 1.2848e+04                    bc_loss 5.1444e+03\n",
      "Epoch 14690, Training-Loss 2.4877e+00, Data-loss 5.9144e-01                  , pde-loss 5.7083e+03, initc-loss 1.2915e+04                    bc_loss 3.3931e+02\n",
      "Epoch 14700, Training-Loss 3.0167e+00, Data-loss 9.2891e-01                  , pde-loss 5.4504e+03, initc-loss 1.2734e+04                    bc_loss 2.6942e+03\n",
      "Epoch 14710, Training-Loss 2.4450e+00, Data-loss 5.7682e-01                  , pde-loss 5.0194e+03, initc-loss 1.2913e+04                    bc_loss 7.4893e+02\n",
      "Epoch 14720, Training-Loss 3.2029e+00, Data-loss 7.2520e-01                  , pde-loss 5.5801e+03, initc-loss 1.2918e+04                    bc_loss 6.2792e+03\n",
      "Epoch 14730, Training-Loss 2.4436e+00, Data-loss 5.5910e-01                  , pde-loss 5.6135e+03, initc-loss 1.2872e+04                    bc_loss 3.5961e+02\n",
      "Epoch 14740, Training-Loss 2.6077e+00, Data-loss 6.4198e-01                  , pde-loss 5.7603e+03, initc-loss 1.2901e+04                    bc_loss 9.9596e+02\n",
      "Epoch 14750, Training-Loss 2.6596e+00, Data-loss 6.6785e-01                  , pde-loss 5.6246e+03, initc-loss 1.2850e+04                    bc_loss 1.4432e+03\n",
      "Epoch 14760, Training-Loss 2.4552e+00, Data-loss 6.0211e-01                  , pde-loss 5.3648e+03, initc-loss 1.2899e+04                    bc_loss 2.6687e+02\n",
      "Epoch 14770, Training-Loss 2.5632e+00, Data-loss 6.1871e-01                  , pde-loss 6.2834e+03, initc-loss 1.2870e+04                    bc_loss 2.9150e+02\n",
      "Epoch 14780, Training-Loss 2.8538e+00, Data-loss 7.9450e-01                  , pde-loss 5.2599e+03, initc-loss 1.2943e+04                    bc_loss 2.3894e+03\n",
      "Epoch 14790, Training-Loss 3.1211e+00, Data-loss 1.1696e+00                  , pde-loss 5.8565e+03, initc-loss 1.2892e+04                    bc_loss 7.6684e+02\n",
      "Epoch 14800, Training-Loss 2.9905e+00, Data-loss 7.6870e-01                  , pde-loss 7.0070e+03, initc-loss 1.2888e+04                    bc_loss 2.3233e+03\n",
      "Epoch 14810, Training-Loss 3.0562e+00, Data-loss 9.2104e-01                  , pde-loss 5.9609e+03, initc-loss 1.2795e+04                    bc_loss 2.5959e+03\n",
      "Epoch 14820, Training-Loss 4.1707e+00, Data-loss 1.3085e+00                  , pde-loss 5.4656e+03, initc-loss 1.3060e+04                    bc_loss 1.0096e+04\n",
      "Epoch 14830, Training-Loss 2.5343e+00, Data-loss 6.0964e-01                  , pde-loss 5.0339e+03, initc-loss 1.2916e+04                    bc_loss 1.2969e+03\n",
      "Epoch 14840, Training-Loss 2.9050e+00, Data-loss 9.4784e-01                  , pde-loss 5.3411e+03, initc-loss 1.2978e+04                    bc_loss 1.2523e+03\n",
      "Epoch 14850, Training-Loss 2.6395e+00, Data-loss 6.5148e-01                  , pde-loss 6.4160e+03, initc-loss 1.2837e+04                    bc_loss 6.2750e+02\n",
      "Epoch 14860, Training-Loss 2.7690e+00, Data-loss 8.0636e-01                  , pde-loss 5.9395e+03, initc-loss 1.2786e+04                    bc_loss 9.0052e+02\n",
      "Epoch 14870, Training-Loss 4.3061e+00, Data-loss 1.2960e+00                  , pde-loss 6.1064e+03, initc-loss 1.2984e+04                    bc_loss 1.1010e+04\n",
      "Epoch 14880, Training-Loss 2.7306e+00, Data-loss 7.4695e-01                  , pde-loss 5.6147e+03, initc-loss 1.2986e+04                    bc_loss 1.2355e+03\n",
      "Epoch 14890, Training-Loss 2.5651e+00, Data-loss 6.5783e-01                  , pde-loss 5.5129e+03, initc-loss 1.2974e+04                    bc_loss 5.8606e+02\n",
      "Epoch 14900, Training-Loss 2.7943e+00, Data-loss 7.6981e-01                  , pde-loss 6.2325e+03, initc-loss 1.3003e+04                    bc_loss 1.0101e+03\n",
      "Epoch 14910, Training-Loss 2.7109e+00, Data-loss 7.3985e-01                  , pde-loss 5.5761e+03, initc-loss 1.2827e+04                    bc_loss 1.3079e+03\n",
      "Epoch 14920, Training-Loss 3.2286e+00, Data-loss 1.0018e+00                  , pde-loss 5.8004e+03, initc-loss 1.2767e+04                    bc_loss 3.7015e+03\n",
      "Epoch 14930, Training-Loss 3.1388e+00, Data-loss 1.0089e+00                  , pde-loss 6.7020e+03, initc-loss 1.2820e+04                    bc_loss 1.7772e+03\n",
      "Epoch 14940, Training-Loss 2.6683e+00, Data-loss 5.8031e-01                  , pde-loss 6.5923e+03, initc-loss 1.2833e+04                    bc_loss 1.4545e+03\n",
      "Epoch 14950, Training-Loss 2.5755e+00, Data-loss 6.1381e-01                  , pde-loss 5.9273e+03, initc-loss 1.2952e+04                    bc_loss 7.3814e+02\n",
      "Epoch 14960, Training-Loss 2.9039e+00, Data-loss 9.3486e-01                  , pde-loss 5.8181e+03, initc-loss 1.2983e+04                    bc_loss 8.8913e+02\n",
      "Epoch 14970, Training-Loss 2.5770e+00, Data-loss 5.5560e-01                  , pde-loss 6.8893e+03, initc-loss 1.2847e+04                    bc_loss 4.7762e+02\n",
      "Epoch 14980, Training-Loss 2.6196e+00, Data-loss 6.0628e-01                  , pde-loss 6.5267e+03, initc-loss 1.2930e+04                    bc_loss 6.7739e+02\n",
      "Epoch 14990, Training-Loss 3.0166e+00, Data-loss 7.6135e-01                  , pde-loss 5.7292e+03, initc-loss 1.2928e+04                    bc_loss 3.8949e+03\n",
      "Epoch 15000, Training-Loss 2.7721e+00, Data-loss 7.8768e-01                  , pde-loss 6.1385e+03, initc-loss 1.3035e+04                    bc_loss 6.7089e+02\n",
      "Epoch 15010, Training-Loss 3.1244e+00, Data-loss 1.0151e+00                  , pde-loss 6.7242e+03, initc-loss 1.2887e+04                    bc_loss 1.4822e+03\n",
      "Epoch 15020, Training-Loss 2.4632e+00, Data-loss 5.0955e-01                  , pde-loss 6.2797e+03, initc-loss 1.2894e+04                    bc_loss 3.6352e+02\n",
      "Epoch 15030, Training-Loss 2.7728e+00, Data-loss 8.1200e-01                  , pde-loss 5.8678e+03, initc-loss 1.2865e+04                    bc_loss 8.7551e+02\n",
      "Epoch 15040, Training-Loss 2.8009e+00, Data-loss 7.3393e-01                  , pde-loss 7.1399e+03, initc-loss 1.2932e+04                    bc_loss 5.9724e+02\n",
      "Epoch 15050, Training-Loss 2.7346e+00, Data-loss 6.6328e-01                  , pde-loss 6.8551e+03, initc-loss 1.2913e+04                    bc_loss 9.4482e+02\n",
      "Epoch 15060, Training-Loss 2.4982e+00, Data-loss 5.5038e-01                  , pde-loss 5.3409e+03, initc-loss 1.2789e+04                    bc_loss 1.3480e+03\n",
      "Epoch 15070, Training-Loss 2.4052e+00, Data-loss 5.3248e-01                  , pde-loss 5.0024e+03, initc-loss 1.2920e+04                    bc_loss 8.0448e+02\n",
      "Epoch 15080, Training-Loss 3.0128e+00, Data-loss 8.3039e-01                  , pde-loss 5.3045e+03, initc-loss 1.2956e+04                    bc_loss 3.5638e+03\n",
      "Epoch 15090, Training-Loss 3.2398e+00, Data-loss 7.3844e-01                  , pde-loss 5.5556e+03, initc-loss 1.2790e+04                    bc_loss 6.6672e+03\n",
      "Epoch 15100, Training-Loss 2.6476e+00, Data-loss 7.6130e-01                  , pde-loss 5.6748e+03, initc-loss 1.2814e+04                    bc_loss 3.7515e+02\n",
      "Epoch 15110, Training-Loss 2.7287e+00, Data-loss 7.6783e-01                  , pde-loss 6.2465e+03, initc-loss 1.2928e+04                    bc_loss 4.3450e+02\n",
      "Epoch 15120, Training-Loss 2.7510e+00, Data-loss 7.4328e-01                  , pde-loss 6.5349e+03, initc-loss 1.2916e+04                    bc_loss 6.2586e+02\n",
      "Epoch 15130, Training-Loss 2.6066e+00, Data-loss 5.7821e-01                  , pde-loss 6.5145e+03, initc-loss 1.2887e+04                    bc_loss 8.8266e+02\n",
      "Epoch 15140, Training-Loss 3.5208e+00, Data-loss 1.2537e+00                  , pde-loss 6.1648e+03, initc-loss 1.2713e+04                    bc_loss 3.7932e+03\n",
      "Epoch 15150, Training-Loss 2.6896e+00, Data-loss 8.1034e-01                  , pde-loss 5.6464e+03, initc-loss 1.2924e+04                    bc_loss 2.2274e+02\n",
      "Epoch 15160, Training-Loss 2.7507e+00, Data-loss 7.3981e-01                  , pde-loss 4.9836e+03, initc-loss 1.2965e+04                    bc_loss 2.1600e+03\n",
      "Epoch 15170, Training-Loss 3.6949e+00, Data-loss 1.1586e+00                  , pde-loss 5.4025e+03, initc-loss 1.2978e+04                    bc_loss 6.9822e+03\n",
      "Epoch 15180, Training-Loss 2.8413e+00, Data-loss 8.2483e-01                  , pde-loss 6.2806e+03, initc-loss 1.2967e+04                    bc_loss 9.1719e+02\n",
      "Epoch 15190, Training-Loss 2.8780e+00, Data-loss 6.2234e-01                  , pde-loss 5.2266e+03, initc-loss 1.2907e+04                    bc_loss 4.4223e+03\n",
      "Epoch 15200, Training-Loss 2.4292e+00, Data-loss 5.8685e-01                  , pde-loss 4.9459e+03, initc-loss 1.2819e+04                    bc_loss 6.5837e+02\n",
      "Epoch 15210, Training-Loss 2.7769e+00, Data-loss 7.0347e-01                  , pde-loss 5.1041e+03, initc-loss 1.2843e+04                    bc_loss 2.7871e+03\n",
      "Epoch 15220, Training-Loss 2.5269e+00, Data-loss 6.4942e-01                  , pde-loss 5.6328e+03, initc-loss 1.2929e+04                    bc_loss 2.1306e+02\n",
      "Epoch 15230, Training-Loss 2.7038e+00, Data-loss 8.2522e-01                  , pde-loss 5.6288e+03, initc-loss 1.2911e+04                    bc_loss 2.4633e+02\n",
      "Epoch 15240, Training-Loss 2.5485e+00, Data-loss 5.9283e-01                  , pde-loss 6.2316e+03, initc-loss 1.2882e+04                    bc_loss 4.4316e+02\n",
      "Epoch 15250, Training-Loss 2.5982e+00, Data-loss 6.2465e-01                  , pde-loss 5.5276e+03, initc-loss 1.2869e+04                    bc_loss 1.3389e+03\n",
      "Epoch 15260, Training-Loss 2.5368e+00, Data-loss 5.8503e-01                  , pde-loss 6.1874e+03, initc-loss 1.2937e+04                    bc_loss 3.9346e+02\n",
      "Epoch 15270, Training-Loss 2.5246e+00, Data-loss 6.0622e-01                  , pde-loss 5.6271e+03, initc-loss 1.2910e+04                    bc_loss 6.4664e+02\n",
      "Epoch 15280, Training-Loss 2.5280e+00, Data-loss 6.0266e-01                  , pde-loss 6.1736e+03, initc-loss 1.2868e+04                    bc_loss 2.1199e+02\n",
      "Epoch 15290, Training-Loss 2.5673e+00, Data-loss 6.6715e-01                  , pde-loss 5.6089e+03, initc-loss 1.2841e+04                    bc_loss 5.5163e+02\n",
      "Epoch 15300, Training-Loss 2.8142e+00, Data-loss 8.4612e-01                  , pde-loss 5.7244e+03, initc-loss 1.2971e+04                    bc_loss 9.8523e+02\n",
      "Epoch 15310, Training-Loss 2.7351e+00, Data-loss 8.2360e-01                  , pde-loss 5.6392e+03, initc-loss 1.2958e+04                    bc_loss 5.1716e+02\n",
      "Epoch 15320, Training-Loss 2.5929e+00, Data-loss 6.7312e-01                  , pde-loss 5.8304e+03, initc-loss 1.2853e+04                    bc_loss 5.1451e+02\n",
      "Epoch 15330, Training-Loss 2.5440e+00, Data-loss 6.5805e-01                  , pde-loss 5.6883e+03, initc-loss 1.2839e+04                    bc_loss 3.3173e+02\n",
      "Epoch 15340, Training-Loss 2.5285e+00, Data-loss 6.4926e-01                  , pde-loss 5.4351e+03, initc-loss 1.2818e+04                    bc_loss 5.3916e+02\n",
      "Epoch 15350, Training-Loss 3.1909e+00, Data-loss 1.0269e+00                  , pde-loss 6.2327e+03, initc-loss 1.2803e+04                    bc_loss 2.6046e+03\n",
      "Epoch 15360, Training-Loss 2.5189e+00, Data-loss 5.5628e-01                  , pde-loss 5.9675e+03, initc-loss 1.2876e+04                    bc_loss 7.8282e+02\n",
      "Epoch 15370, Training-Loss 2.5297e+00, Data-loss 6.3193e-01                  , pde-loss 5.7864e+03, initc-loss 1.2859e+04                    bc_loss 3.3216e+02\n",
      "Epoch 15380, Training-Loss 2.6179e+00, Data-loss 6.0159e-01                  , pde-loss 6.4820e+03, initc-loss 1.2887e+04                    bc_loss 7.9409e+02\n",
      "Epoch 15390, Training-Loss 2.7500e+00, Data-loss 7.3299e-01                  , pde-loss 6.0405e+03, initc-loss 1.2929e+04                    bc_loss 1.2008e+03\n",
      "Epoch 15400, Training-Loss 2.5032e+00, Data-loss 5.8446e-01                  , pde-loss 5.9150e+03, initc-loss 1.2820e+04                    bc_loss 4.5246e+02\n",
      "Epoch 15410, Training-Loss 2.4621e+00, Data-loss 5.6653e-01                  , pde-loss 5.7075e+03, initc-loss 1.2861e+04                    bc_loss 3.8644e+02\n",
      "Epoch 15420, Training-Loss 2.4159e+00, Data-loss 5.4849e-01                  , pde-loss 5.4750e+03, initc-loss 1.2905e+04                    bc_loss 2.9426e+02\n",
      "Epoch 15430, Training-Loss 2.5444e+00, Data-loss 5.3746e-01                  , pde-loss 6.0717e+03, initc-loss 1.2939e+04                    bc_loss 1.0586e+03\n",
      "Epoch 15440, Training-Loss 2.8960e+00, Data-loss 6.5278e-01                  , pde-loss 6.9420e+03, initc-loss 1.2955e+04                    bc_loss 2.5358e+03\n",
      "Epoch 15450, Training-Loss 2.6464e+00, Data-loss 6.2977e-01                  , pde-loss 5.4450e+03, initc-loss 1.2846e+04                    bc_loss 1.8744e+03\n",
      "Epoch 15460, Training-Loss 2.5109e+00, Data-loss 5.8749e-01                  , pde-loss 5.8256e+03, initc-loss 1.2846e+04                    bc_loss 5.6254e+02\n",
      "Epoch 15470, Training-Loss 2.7917e+00, Data-loss 8.2014e-01                  , pde-loss 5.6147e+03, initc-loss 1.2857e+04                    bc_loss 1.2440e+03\n",
      "Epoch 15480, Training-Loss 4.2525e+00, Data-loss 1.6001e+00                  , pde-loss 5.8554e+03, initc-loss 1.2752e+04                    bc_loss 7.9159e+03\n",
      "Epoch 15490, Training-Loss 2.5248e+00, Data-loss 6.2231e-01                  , pde-loss 5.6504e+03, initc-loss 1.2938e+04                    bc_loss 4.3676e+02\n",
      "Epoch 15500, Training-Loss 2.5120e+00, Data-loss 5.9993e-01                  , pde-loss 5.6943e+03, initc-loss 1.2896e+04                    bc_loss 5.2963e+02\n",
      "Epoch 15510, Training-Loss 2.5711e+00, Data-loss 6.1805e-01                  , pde-loss 5.9104e+03, initc-loss 1.2908e+04                    bc_loss 7.1283e+02\n",
      "Epoch 15520, Training-Loss 2.9103e+00, Data-loss 8.5947e-01                  , pde-loss 6.6152e+03, initc-loss 1.2888e+04                    bc_loss 1.0054e+03\n",
      "Epoch 15530, Training-Loss 2.6496e+00, Data-loss 7.2414e-01                  , pde-loss 5.8125e+03, initc-loss 1.2904e+04                    bc_loss 5.3732e+02\n",
      "Epoch 15540, Training-Loss 2.7929e+00, Data-loss 8.0892e-01                  , pde-loss 5.9594e+03, initc-loss 1.2948e+04                    bc_loss 9.3210e+02\n",
      "Epoch 15550, Training-Loss 2.7769e+00, Data-loss 8.2450e-01                  , pde-loss 6.2533e+03, initc-loss 1.2857e+04                    bc_loss 4.1391e+02\n",
      "Epoch 15560, Training-Loss 2.7226e+00, Data-loss 5.9805e-01                  , pde-loss 6.0132e+03, initc-loss 1.2870e+04                    bc_loss 2.3620e+03\n",
      "Epoch 15570, Training-Loss 2.4605e+00, Data-loss 5.3212e-01                  , pde-loss 5.3372e+03, initc-loss 1.2875e+04                    bc_loss 1.0714e+03\n",
      "Epoch 15580, Training-Loss 3.0274e+00, Data-loss 1.0559e+00                  , pde-loss 5.9032e+03, initc-loss 1.2768e+04                    bc_loss 1.0437e+03\n",
      "Epoch 15590, Training-Loss 2.4042e+00, Data-loss 5.4466e-01                  , pde-loss 5.4622e+03, initc-loss 1.2833e+04                    bc_loss 2.9976e+02\n",
      "Epoch 15600, Training-Loss 2.4473e+00, Data-loss 5.3465e-01                  , pde-loss 5.4487e+03, initc-loss 1.2940e+04                    bc_loss 7.3813e+02\n",
      "Epoch 15610, Training-Loss 2.7732e+00, Data-loss 7.2714e-01                  , pde-loss 7.0523e+03, initc-loss 1.2865e+04                    bc_loss 5.4347e+02\n",
      "Epoch 15620, Training-Loss 2.7050e+00, Data-loss 6.7747e-01                  , pde-loss 6.3327e+03, initc-loss 1.2890e+04                    bc_loss 1.0523e+03\n",
      "Epoch 15630, Training-Loss 2.7379e+00, Data-loss 6.9849e-01                  , pde-loss 6.1088e+03, initc-loss 1.2886e+04                    bc_loss 1.4000e+03\n",
      "Epoch 15640, Training-Loss 2.6004e+00, Data-loss 5.6882e-01                  , pde-loss 5.7205e+03, initc-loss 1.2902e+04                    bc_loss 1.6934e+03\n",
      "Epoch 15650, Training-Loss 2.5834e+00, Data-loss 5.8238e-01                  , pde-loss 5.6009e+03, initc-loss 1.2795e+04                    bc_loss 1.6135e+03\n",
      "Epoch 15660, Training-Loss 2.7257e+00, Data-loss 7.7129e-01                  , pde-loss 5.9733e+03, initc-loss 1.2907e+04                    bc_loss 6.6315e+02\n",
      "Epoch 15670, Training-Loss 2.4925e+00, Data-loss 5.5197e-01                  , pde-loss 5.7379e+03, initc-loss 1.2868e+04                    bc_loss 7.9953e+02\n",
      "Epoch 15680, Training-Loss 3.0416e+00, Data-loss 9.7340e-01                  , pde-loss 5.7447e+03, initc-loss 1.3037e+04                    bc_loss 1.9004e+03\n",
      "Epoch 15690, Training-Loss 3.1818e+00, Data-loss 8.0362e-01                  , pde-loss 5.8773e+03, initc-loss 1.2955e+04                    bc_loss 4.9500e+03\n",
      "Epoch 15700, Training-Loss 2.8736e+00, Data-loss 8.3892e-01                  , pde-loss 7.0666e+03, initc-loss 1.2841e+04                    bc_loss 4.3883e+02\n",
      "Epoch 15710, Training-Loss 2.9291e+00, Data-loss 9.1260e-01                  , pde-loss 6.3936e+03, initc-loss 1.2939e+04                    bc_loss 8.3265e+02\n",
      "Epoch 15720, Training-Loss 2.4325e+00, Data-loss 5.4370e-01                  , pde-loss 5.8419e+03, initc-loss 1.2846e+04                    bc_loss 2.0092e+02\n",
      "Epoch 15730, Training-Loss 2.6392e+00, Data-loss 7.0618e-01                  , pde-loss 5.7775e+03, initc-loss 1.3026e+04                    bc_loss 5.2653e+02\n",
      "Epoch 15740, Training-Loss 2.3398e+00, Data-loss 5.0778e-01                  , pde-loss 4.5711e+03, initc-loss 1.2933e+04                    bc_loss 8.1702e+02\n",
      "Epoch 15750, Training-Loss 2.6443e+00, Data-loss 6.7109e-01                  , pde-loss 6.4786e+03, initc-loss 1.2795e+04                    bc_loss 4.5924e+02\n",
      "Epoch 15760, Training-Loss 2.6254e+00, Data-loss 7.1131e-01                  , pde-loss 5.8241e+03, initc-loss 1.2867e+04                    bc_loss 4.5043e+02\n",
      "Epoch 15770, Training-Loss 2.4237e+00, Data-loss 5.7149e-01                  , pde-loss 5.2005e+03, initc-loss 1.2843e+04                    bc_loss 4.7885e+02\n",
      "Epoch 15780, Training-Loss 2.1604e+00, Data-loss 4.0646e-01                  , pde-loss 4.4098e+03, initc-loss 1.2847e+04                    bc_loss 2.8183e+02\n",
      "Epoch 15790, Training-Loss 2.4325e+00, Data-loss 5.2372e-01                  , pde-loss 5.4706e+03, initc-loss 1.2848e+04                    bc_loss 7.6945e+02\n",
      "Epoch 15800, Training-Loss 2.9581e+00, Data-loss 7.6058e-01                  , pde-loss 5.8974e+03, initc-loss 1.2766e+04                    bc_loss 3.3109e+03\n",
      "Epoch 15810, Training-Loss 2.5632e+00, Data-loss 5.8825e-01                  , pde-loss 6.5432e+03, initc-loss 1.2840e+04                    bc_loss 3.6577e+02\n",
      "Epoch 15820, Training-Loss 2.4132e+00, Data-loss 5.1345e-01                  , pde-loss 5.1657e+03, initc-loss 1.2908e+04                    bc_loss 9.2329e+02\n",
      "Epoch 15830, Training-Loss 3.0442e+00, Data-loss 9.3801e-01                  , pde-loss 6.5683e+03, initc-loss 1.2910e+04                    bc_loss 1.5837e+03\n",
      "Epoch 15840, Training-Loss 2.5534e+00, Data-loss 5.4156e-01                  , pde-loss 6.6074e+03, initc-loss 1.2847e+04                    bc_loss 6.6376e+02\n",
      "Epoch 15850, Training-Loss 2.6517e+00, Data-loss 7.1763e-01                  , pde-loss 5.8199e+03, initc-loss 1.2894e+04                    bc_loss 6.2624e+02\n",
      "Epoch 15860, Training-Loss 2.4345e+00, Data-loss 5.3423e-01                  , pde-loss 5.5156e+03, initc-loss 1.2888e+04                    bc_loss 5.9901e+02\n",
      "Epoch 15870, Training-Loss 2.4114e+00, Data-loss 4.9349e-01                  , pde-loss 5.7317e+03, initc-loss 1.2850e+04                    bc_loss 5.9763e+02\n",
      "Epoch 15880, Training-Loss 2.5489e+00, Data-loss 5.9474e-01                  , pde-loss 5.8876e+03, initc-loss 1.2867e+04                    bc_loss 7.8682e+02\n",
      "Epoch 15890, Training-Loss 2.4264e+00, Data-loss 5.8549e-01                  , pde-loss 5.1918e+03, initc-loss 1.2888e+04                    bc_loss 3.2916e+02\n",
      "Epoch 15900, Training-Loss 2.7226e+00, Data-loss 6.7046e-01                  , pde-loss 6.7970e+03, initc-loss 1.2914e+04                    bc_loss 8.0958e+02\n",
      "Epoch 15910, Training-Loss 2.6508e+00, Data-loss 6.3718e-01                  , pde-loss 5.0984e+03, initc-loss 1.2850e+04                    bc_loss 2.1880e+03\n",
      "Epoch 15920, Training-Loss 2.5975e+00, Data-loss 6.7703e-01                  , pde-loss 5.6423e+03, initc-loss 1.2930e+04                    bc_loss 6.3270e+02\n",
      "Epoch 15930, Training-Loss 2.7659e+00, Data-loss 8.1973e-01                  , pde-loss 5.7704e+03, initc-loss 1.2901e+04                    bc_loss 7.9035e+02\n",
      "Epoch 15940, Training-Loss 2.9390e+00, Data-loss 7.3447e-01                  , pde-loss 6.2298e+03, initc-loss 1.2990e+04                    bc_loss 2.8260e+03\n",
      "Epoch 15950, Training-Loss 2.6437e+00, Data-loss 6.9042e-01                  , pde-loss 5.9321e+03, initc-loss 1.2901e+04                    bc_loss 6.9989e+02\n",
      "Epoch 15960, Training-Loss 2.6049e+00, Data-loss 5.3745e-01                  , pde-loss 5.3989e+03, initc-loss 1.3037e+04                    bc_loss 2.2391e+03\n",
      "Epoch 15970, Training-Loss 2.5506e+00, Data-loss 5.4933e-01                  , pde-loss 5.9271e+03, initc-loss 1.2901e+04                    bc_loss 1.1839e+03\n",
      "Epoch 15980, Training-Loss 2.5808e+00, Data-loss 6.0099e-01                  , pde-loss 6.0077e+03, initc-loss 1.2922e+04                    bc_loss 8.6863e+02\n",
      "Epoch 15990, Training-Loss 2.5966e+00, Data-loss 6.6480e-01                  , pde-loss 5.6377e+03, initc-loss 1.2832e+04                    bc_loss 8.4819e+02\n",
      "Epoch 16000, Training-Loss 2.6042e+00, Data-loss 5.3578e-01                  , pde-loss 5.2184e+03, initc-loss 1.2825e+04                    bc_loss 2.6403e+03\n",
      "Epoch 16010, Training-Loss 3.3487e+00, Data-loss 1.0383e+00                  , pde-loss 5.5990e+03, initc-loss 1.2724e+04                    bc_loss 4.7817e+03\n",
      "Epoch 16020, Training-Loss 2.9588e+00, Data-loss 9.6637e-01                  , pde-loss 6.1677e+03, initc-loss 1.2709e+04                    bc_loss 1.0481e+03\n",
      "Epoch 16030, Training-Loss 2.7190e+00, Data-loss 6.6904e-01                  , pde-loss 6.3705e+03, initc-loss 1.2845e+04                    bc_loss 1.2842e+03\n",
      "Epoch 16040, Training-Loss 2.5660e+00, Data-loss 6.6700e-01                  , pde-loss 5.7194e+03, initc-loss 1.2938e+04                    bc_loss 3.3205e+02\n",
      "Epoch 16050, Training-Loss 2.9152e+00, Data-loss 8.5517e-01                  , pde-loss 5.7841e+03, initc-loss 1.2852e+04                    bc_loss 1.9642e+03\n",
      "Epoch 16060, Training-Loss 2.6113e+00, Data-loss 5.7787e-01                  , pde-loss 5.3032e+03, initc-loss 1.2897e+04                    bc_loss 2.1334e+03\n",
      "Epoch 16070, Training-Loss 2.5306e+00, Data-loss 5.9643e-01                  , pde-loss 5.1946e+03, initc-loss 1.2864e+04                    bc_loss 1.2835e+03\n",
      "Epoch 16080, Training-Loss 2.4738e+00, Data-loss 5.3806e-01                  , pde-loss 5.6203e+03, initc-loss 1.2917e+04                    bc_loss 8.1990e+02\n",
      "Epoch 16090, Training-Loss 2.5781e+00, Data-loss 6.5686e-01                  , pde-loss 5.8994e+03, initc-loss 1.2824e+04                    bc_loss 4.8877e+02\n",
      "Epoch 16100, Training-Loss 2.6591e+00, Data-loss 5.8039e-01                  , pde-loss 5.7064e+03, initc-loss 1.2835e+04                    bc_loss 2.2455e+03\n",
      "Epoch 16110, Training-Loss 2.4016e+00, Data-loss 5.3712e-01                  , pde-loss 5.0579e+03, initc-loss 1.2967e+04                    bc_loss 6.1994e+02\n",
      "Epoch 16120, Training-Loss 2.4529e+00, Data-loss 5.8623e-01                  , pde-loss 5.6441e+03, initc-loss 1.2846e+04                    bc_loss 1.7614e+02\n",
      "Epoch 16130, Training-Loss 2.6411e+00, Data-loss 5.8133e-01                  , pde-loss 6.0558e+03, initc-loss 1.2914e+04                    bc_loss 1.6274e+03\n",
      "Epoch 16140, Training-Loss 2.5200e+00, Data-loss 5.7798e-01                  , pde-loss 6.0852e+03, initc-loss 1.2904e+04                    bc_loss 4.3149e+02\n",
      "Epoch 16150, Training-Loss 3.3017e+00, Data-loss 8.3611e-01                  , pde-loss 6.0177e+03, initc-loss 1.2919e+04                    bc_loss 5.7192e+03\n",
      "Epoch 16160, Training-Loss 2.6329e+00, Data-loss 6.1505e-01                  , pde-loss 6.9923e+03, initc-loss 1.2921e+04                    bc_loss 2.6504e+02\n",
      "Epoch 16170, Training-Loss 2.3839e+00, Data-loss 4.6997e-01                  , pde-loss 5.6611e+03, initc-loss 1.2815e+04                    bc_loss 6.6307e+02\n",
      "Epoch 16180, Training-Loss 2.7173e+00, Data-loss 6.5090e-01                  , pde-loss 7.1038e+03, initc-loss 1.2863e+04                    bc_loss 6.9656e+02\n",
      "Epoch 16190, Training-Loss 2.9222e+00, Data-loss 7.5191e-01                  , pde-loss 6.6737e+03, initc-loss 1.2956e+04                    bc_loss 2.0735e+03\n",
      "Epoch 16200, Training-Loss 2.4641e+00, Data-loss 5.8318e-01                  , pde-loss 5.3982e+03, initc-loss 1.2884e+04                    bc_loss 5.2689e+02\n",
      "Epoch 16210, Training-Loss 2.5431e+00, Data-loss 6.1925e-01                  , pde-loss 5.9112e+03, initc-loss 1.2836e+04                    bc_loss 4.9108e+02\n",
      "Epoch 16220, Training-Loss 3.0034e+00, Data-loss 9.7377e-01                  , pde-loss 6.8485e+03, initc-loss 1.2834e+04                    bc_loss 6.1332e+02\n",
      "Epoch 16230, Training-Loss 2.4708e+00, Data-loss 5.4231e-01                  , pde-loss 6.1955e+03, initc-loss 1.2833e+04                    bc_loss 2.5627e+02\n",
      "Epoch 16240, Training-Loss 2.7244e+00, Data-loss 6.5717e-01                  , pde-loss 5.9128e+03, initc-loss 1.2887e+04                    bc_loss 1.8728e+03\n",
      "Epoch 16250, Training-Loss 2.2835e+00, Data-loss 4.6934e-01                  , pde-loss 4.6102e+03, initc-loss 1.2860e+04                    bc_loss 6.7136e+02\n",
      "Epoch 16260, Training-Loss 2.4366e+00, Data-loss 4.9679e-01                  , pde-loss 5.7740e+03, initc-loss 1.2830e+04                    bc_loss 7.9398e+02\n",
      "Epoch 16270, Training-Loss 2.6318e+00, Data-loss 5.8774e-01                  , pde-loss 6.7416e+03, initc-loss 1.2838e+04                    bc_loss 8.6104e+02\n",
      "Epoch 16280, Training-Loss 2.3902e+00, Data-loss 5.4394e-01                  , pde-loss 5.0094e+03, initc-loss 1.2979e+04                    bc_loss 4.7381e+02\n",
      "Epoch 16290, Training-Loss 2.5729e+00, Data-loss 5.7073e-01                  , pde-loss 6.3298e+03, initc-loss 1.2871e+04                    bc_loss 8.2110e+02\n",
      "Epoch 16300, Training-Loss 2.8107e+00, Data-loss 7.9271e-01                  , pde-loss 6.8397e+03, initc-loss 1.2868e+04                    bc_loss 4.7279e+02\n",
      "Epoch 16310, Training-Loss 2.4973e+00, Data-loss 4.9920e-01                  , pde-loss 5.3699e+03, initc-loss 1.2825e+04                    bc_loss 1.7858e+03\n",
      "Epoch 16320, Training-Loss 2.3863e+00, Data-loss 3.8753e-01                  , pde-loss 5.0863e+03, initc-loss 1.2980e+04                    bc_loss 1.9211e+03\n",
      "Epoch 16330, Training-Loss 2.6296e+00, Data-loss 5.9013e-01                  , pde-loss 5.5413e+03, initc-loss 1.2852e+04                    bc_loss 2.0010e+03\n",
      "Epoch 16340, Training-Loss 2.4841e+00, Data-loss 5.4721e-01                  , pde-loss 6.1665e+03, initc-loss 1.2880e+04                    bc_loss 3.2235e+02\n",
      "Epoch 16350, Training-Loss 2.4367e+00, Data-loss 5.9932e-01                  , pde-loss 5.0592e+03, initc-loss 1.2755e+04                    bc_loss 5.5940e+02\n",
      "Epoch 16360, Training-Loss 2.5963e+00, Data-loss 6.7956e-01                  , pde-loss 5.5531e+03, initc-loss 1.2910e+04                    bc_loss 7.0388e+02\n",
      "Epoch 16370, Training-Loss 2.7105e+00, Data-loss 5.0175e-01                  , pde-loss 6.2805e+03, initc-loss 1.2859e+04                    bc_loss 2.9480e+03\n",
      "Epoch 16380, Training-Loss 2.5926e+00, Data-loss 5.9022e-01                  , pde-loss 6.7386e+03, initc-loss 1.2906e+04                    bc_loss 3.7951e+02\n",
      "Epoch 16390, Training-Loss 2.5984e+00, Data-loss 6.5675e-01                  , pde-loss 6.0598e+03, initc-loss 1.2869e+04                    bc_loss 4.8770e+02\n",
      "Epoch 16400, Training-Loss 2.5618e+00, Data-loss 5.7741e-01                  , pde-loss 6.0995e+03, initc-loss 1.2903e+04                    bc_loss 8.4159e+02\n",
      "Epoch 16410, Training-Loss 2.9071e+00, Data-loss 8.6943e-01                  , pde-loss 5.7248e+03, initc-loss 1.2904e+04                    bc_loss 1.7476e+03\n",
      "Epoch 16420, Training-Loss 3.4127e+00, Data-loss 1.0136e+00                  , pde-loss 7.3195e+03, initc-loss 1.2971e+04                    bc_loss 3.7010e+03\n",
      "Epoch 16430, Training-Loss 2.8201e+00, Data-loss 6.3263e-01                  , pde-loss 6.4588e+03, initc-loss 1.2908e+04                    bc_loss 2.5073e+03\n",
      "Epoch 16440, Training-Loss 2.7513e+00, Data-loss 5.8087e-01                  , pde-loss 6.3957e+03, initc-loss 1.2915e+04                    bc_loss 2.3935e+03\n",
      "Epoch 16450, Training-Loss 2.5050e+00, Data-loss 5.2997e-01                  , pde-loss 5.9302e+03, initc-loss 1.2870e+04                    bc_loss 9.5010e+02\n",
      "Epoch 16460, Training-Loss 2.5369e+00, Data-loss 6.2614e-01                  , pde-loss 5.9542e+03, initc-loss 1.2900e+04                    bc_loss 2.5310e+02\n",
      "Epoch 16470, Training-Loss 2.2908e+00, Data-loss 4.8703e-01                  , pde-loss 4.9348e+03, initc-loss 1.2850e+04                    bc_loss 2.5295e+02\n",
      "Epoch 16480, Training-Loss 2.7776e+00, Data-loss 7.5511e-01                  , pde-loss 6.1605e+03, initc-loss 1.2892e+04                    bc_loss 1.1725e+03\n",
      "Epoch 16490, Training-Loss 2.8968e+00, Data-loss 8.1312e-01                  , pde-loss 5.7964e+03, initc-loss 1.3034e+04                    bc_loss 2.0060e+03\n",
      "Epoch 16500, Training-Loss 2.4596e+00, Data-loss 5.3157e-01                  , pde-loss 5.8673e+03, initc-loss 1.2854e+04                    bc_loss 5.5912e+02\n",
      "Epoch 16510, Training-Loss 2.6766e+00, Data-loss 7.9420e-01                  , pde-loss 5.3307e+03, initc-loss 1.2808e+04                    bc_loss 6.8546e+02\n",
      "Epoch 16520, Training-Loss 2.6000e+00, Data-loss 6.5525e-01                  , pde-loss 6.0508e+03, initc-loss 1.2826e+04                    bc_loss 5.7124e+02\n",
      "Epoch 16530, Training-Loss 2.6812e+00, Data-loss 6.8962e-01                  , pde-loss 5.9799e+03, initc-loss 1.2800e+04                    bc_loss 1.1359e+03\n",
      "Epoch 16540, Training-Loss 2.6011e+00, Data-loss 6.8096e-01                  , pde-loss 5.9896e+03, initc-loss 1.2834e+04                    bc_loss 3.7763e+02\n",
      "Epoch 16550, Training-Loss 2.8694e+00, Data-loss 8.7578e-01                  , pde-loss 5.9733e+03, initc-loss 1.2889e+04                    bc_loss 1.0739e+03\n",
      "Epoch 16560, Training-Loss 2.7593e+00, Data-loss 5.2970e-01                  , pde-loss 6.1718e+03, initc-loss 1.2870e+04                    bc_loss 3.2547e+03\n",
      "Epoch 16570, Training-Loss 2.6112e+00, Data-loss 6.1951e-01                  , pde-loss 6.2093e+03, initc-loss 1.2796e+04                    bc_loss 9.1099e+02\n",
      "Epoch 16580, Training-Loss 3.6860e+00, Data-loss 1.0534e+00                  , pde-loss 6.6744e+03, initc-loss 1.2748e+04                    bc_loss 6.9036e+03\n",
      "Epoch 16590, Training-Loss 3.0640e+00, Data-loss 9.5314e-01                  , pde-loss 6.1430e+03, initc-loss 1.2757e+04                    bc_loss 2.2081e+03\n",
      "Epoch 16600, Training-Loss 2.6599e+00, Data-loss 8.4771e-01                  , pde-loss 4.9121e+03, initc-loss 1.2792e+04                    bc_loss 4.1839e+02\n",
      "Epoch 16610, Training-Loss 2.5013e+00, Data-loss 5.2252e-01                  , pde-loss 5.8152e+03, initc-loss 1.2837e+04                    bc_loss 1.1350e+03\n",
      "Epoch 16620, Training-Loss 2.8894e+00, Data-loss 7.4005e-01                  , pde-loss 5.5125e+03, initc-loss 1.2944e+04                    bc_loss 3.0368e+03\n",
      "Epoch 16630, Training-Loss 3.0731e+00, Data-loss 7.0067e-01                  , pde-loss 6.3383e+03, initc-loss 1.2957e+04                    bc_loss 4.4292e+03\n",
      "Epoch 16640, Training-Loss 2.9268e+00, Data-loss 8.6371e-01                  , pde-loss 6.2695e+03, initc-loss 1.3021e+04                    bc_loss 1.3410e+03\n",
      "Epoch 16650, Training-Loss 2.4237e+00, Data-loss 4.9324e-01                  , pde-loss 5.6307e+03, initc-loss 1.2884e+04                    bc_loss 7.8988e+02\n",
      "Epoch 16660, Training-Loss 2.6236e+00, Data-loss 5.8170e-01                  , pde-loss 6.1732e+03, initc-loss 1.2914e+04                    bc_loss 1.3316e+03\n",
      "Epoch 16670, Training-Loss 2.7146e+00, Data-loss 7.3776e-01                  , pde-loss 5.3971e+03, initc-loss 1.2791e+04                    bc_loss 1.5803e+03\n",
      "Epoch 16680, Training-Loss 3.5307e+00, Data-loss 1.2303e+00                  , pde-loss 5.5392e+03, initc-loss 1.2834e+04                    bc_loss 4.6309e+03\n",
      "Epoch 16690, Training-Loss 2.5182e+00, Data-loss 5.4865e-01                  , pde-loss 6.0326e+03, initc-loss 1.2908e+04                    bc_loss 7.5548e+02\n",
      "Epoch 16700, Training-Loss 2.7734e+00, Data-loss 8.1547e-01                  , pde-loss 5.8892e+03, initc-loss 1.2910e+04                    bc_loss 7.8042e+02\n",
      "Epoch 16710, Training-Loss 2.4174e+00, Data-loss 5.5643e-01                  , pde-loss 4.9407e+03, initc-loss 1.2901e+04                    bc_loss 7.6743e+02\n",
      "Epoch 16720, Training-Loss 2.4584e+00, Data-loss 5.3238e-01                  , pde-loss 5.6020e+03, initc-loss 1.2905e+04                    bc_loss 7.5312e+02\n",
      "Epoch 16730, Training-Loss 2.8538e+00, Data-loss 7.7181e-01                  , pde-loss 5.6131e+03, initc-loss 1.2989e+04                    bc_loss 2.2182e+03\n",
      "Epoch 16740, Training-Loss 2.7942e+00, Data-loss 7.6426e-01                  , pde-loss 6.1916e+03, initc-loss 1.2993e+04                    bc_loss 1.1154e+03\n",
      "Epoch 16750, Training-Loss 2.4395e+00, Data-loss 4.5596e-01                  , pde-loss 5.4929e+03, initc-loss 1.2835e+04                    bc_loss 1.5077e+03\n",
      "Epoch 16760, Training-Loss 2.9572e+00, Data-loss 9.4982e-01                  , pde-loss 5.2951e+03, initc-loss 1.2789e+04                    bc_loss 1.9891e+03\n",
      "Epoch 16770, Training-Loss 3.2972e+00, Data-loss 7.9218e-01                  , pde-loss 5.6280e+03, initc-loss 1.2803e+04                    bc_loss 6.6191e+03\n",
      "Epoch 16780, Training-Loss 2.4591e+00, Data-loss 5.5176e-01                  , pde-loss 6.0103e+03, initc-loss 1.2829e+04                    bc_loss 2.3439e+02\n",
      "Epoch 16790, Training-Loss 2.5146e+00, Data-loss 5.6656e-01                  , pde-loss 5.3230e+03, initc-loss 1.2915e+04                    bc_loss 1.2417e+03\n",
      "Epoch 16800, Training-Loss 2.5182e+00, Data-loss 5.9123e-01                  , pde-loss 5.8856e+03, initc-loss 1.2829e+04                    bc_loss 5.5512e+02\n",
      "Epoch 16810, Training-Loss 2.6199e+00, Data-loss 6.4833e-01                  , pde-loss 5.5806e+03, initc-loss 1.2857e+04                    bc_loss 1.2781e+03\n",
      "Epoch 16820, Training-Loss 2.6584e+00, Data-loss 7.2413e-01                  , pde-loss 6.0181e+03, initc-loss 1.2924e+04                    bc_loss 3.9997e+02\n",
      "Epoch 16830, Training-Loss 2.5209e+00, Data-loss 6.5631e-01                  , pde-loss 5.1923e+03, initc-loss 1.2816e+04                    bc_loss 6.3726e+02\n",
      "Epoch 16840, Training-Loss 2.7947e+00, Data-loss 7.0411e-01                  , pde-loss 5.6208e+03, initc-loss 1.2814e+04                    bc_loss 2.4709e+03\n",
      "Epoch 16850, Training-Loss 2.7111e+00, Data-loss 7.9226e-01                  , pde-loss 6.2072e+03, initc-loss 1.2844e+04                    bc_loss 1.3719e+02\n",
      "Epoch 16860, Training-Loss 2.3881e+00, Data-loss 5.3483e-01                  , pde-loss 5.1274e+03, initc-loss 1.2920e+04                    bc_loss 4.8567e+02\n",
      "Epoch 16870, Training-Loss 2.4190e+00, Data-loss 5.0233e-01                  , pde-loss 5.4906e+03, initc-loss 1.2873e+04                    bc_loss 8.0323e+02\n",
      "Epoch 16880, Training-Loss 2.3837e+00, Data-loss 4.4756e-01                  , pde-loss 5.7713e+03, initc-loss 1.2849e+04                    bc_loss 7.4084e+02\n",
      "Epoch 16890, Training-Loss 2.8736e+00, Data-loss 8.1708e-01                  , pde-loss 6.5260e+03, initc-loss 1.2867e+04                    bc_loss 1.1717e+03\n",
      "Epoch 16900, Training-Loss 2.6843e+00, Data-loss 7.0486e-01                  , pde-loss 6.0263e+03, initc-loss 1.2954e+04                    bc_loss 8.1383e+02\n",
      "Epoch 16910, Training-Loss 2.4588e+00, Data-loss 4.8821e-01                  , pde-loss 6.2095e+03, initc-loss 1.2973e+04                    bc_loss 5.2385e+02\n",
      "Epoch 16920, Training-Loss 2.5335e+00, Data-loss 6.0510e-01                  , pde-loss 5.9521e+03, initc-loss 1.2844e+04                    bc_loss 4.8820e+02\n",
      "Epoch 16930, Training-Loss 2.3755e+00, Data-loss 4.7069e-01                  , pde-loss 5.8906e+03, initc-loss 1.2837e+04                    bc_loss 3.2102e+02\n",
      "Epoch 16940, Training-Loss 3.5856e+00, Data-loss 1.2529e+00                  , pde-loss 6.2075e+03, initc-loss 1.2963e+04                    bc_loss 4.1559e+03\n",
      "Epoch 16950, Training-Loss 2.5784e+00, Data-loss 5.9319e-01                  , pde-loss 6.0785e+03, initc-loss 1.2903e+04                    bc_loss 8.7043e+02\n",
      "Epoch 16960, Training-Loss 3.6634e+00, Data-loss 1.0377e+00                  , pde-loss 6.1051e+03, initc-loss 1.3043e+04                    bc_loss 7.1088e+03\n",
      "Epoch 16970, Training-Loss 2.6049e+00, Data-loss 5.6791e-01                  , pde-loss 5.5784e+03, initc-loss 1.3019e+04                    bc_loss 1.7724e+03\n",
      "Epoch 16980, Training-Loss 2.5880e+00, Data-loss 6.4660e-01                  , pde-loss 5.5219e+03, initc-loss 1.2837e+04                    bc_loss 1.0554e+03\n",
      "Epoch 16990, Training-Loss 2.5426e+00, Data-loss 5.3221e-01                  , pde-loss 5.7662e+03, initc-loss 1.2859e+04                    bc_loss 1.4788e+03\n",
      "Epoch 17000, Training-Loss 2.5826e+00, Data-loss 6.4671e-01                  , pde-loss 6.0557e+03, initc-loss 1.2872e+04                    bc_loss 4.3088e+02\n",
      "Epoch 17010, Training-Loss 2.7239e+00, Data-loss 7.2346e-01                  , pde-loss 6.5207e+03, initc-loss 1.2957e+04                    bc_loss 5.2671e+02\n",
      "Epoch 17020, Training-Loss 2.7330e+00, Data-loss 8.1293e-01                  , pde-loss 5.7685e+03, initc-loss 1.2946e+04                    bc_loss 4.8567e+02\n",
      "Epoch 17030, Training-Loss 2.6303e+00, Data-loss 4.7353e-01                  , pde-loss 6.3035e+03, initc-loss 1.2895e+04                    bc_loss 2.3698e+03\n",
      "Epoch 17040, Training-Loss 2.7850e+00, Data-loss 6.9201e-01                  , pde-loss 5.9095e+03, initc-loss 1.2908e+04                    bc_loss 2.1122e+03\n",
      "Epoch 17050, Training-Loss 2.5189e+00, Data-loss 5.5966e-01                  , pde-loss 6.3577e+03, initc-loss 1.2847e+04                    bc_loss 3.8754e+02\n",
      "Epoch 17060, Training-Loss 2.3971e+00, Data-loss 4.8163e-01                  , pde-loss 5.6240e+03, initc-loss 1.2802e+04                    bc_loss 7.2872e+02\n",
      "Epoch 17070, Training-Loss 2.4094e+00, Data-loss 4.9807e-01                  , pde-loss 5.5579e+03, initc-loss 1.2844e+04                    bc_loss 7.1159e+02\n",
      "Epoch 17080, Training-Loss 2.5865e+00, Data-loss 5.0677e-01                  , pde-loss 6.2029e+03, initc-loss 1.2885e+04                    bc_loss 1.7099e+03\n",
      "Epoch 17090, Training-Loss 2.4776e+00, Data-loss 4.8948e-01                  , pde-loss 6.7197e+03, initc-loss 1.2848e+04                    bc_loss 3.1387e+02\n",
      "Epoch 17100, Training-Loss 2.8893e+00, Data-loss 7.1852e-01                  , pde-loss 6.8124e+03, initc-loss 1.2876e+04                    bc_loss 2.0194e+03\n",
      "Epoch 17110, Training-Loss 2.5638e+00, Data-loss 5.3745e-01                  , pde-loss 6.9557e+03, initc-loss 1.2849e+04                    bc_loss 4.5798e+02\n",
      "Epoch 17120, Training-Loss 2.2681e+00, Data-loss 4.1833e-01                  , pde-loss 4.9728e+03, initc-loss 1.2890e+04                    bc_loss 6.3502e+02\n",
      "Epoch 17130, Training-Loss 2.4013e+00, Data-loss 4.3279e-01                  , pde-loss 6.2460e+03, initc-loss 1.2958e+04                    bc_loss 4.8096e+02\n",
      "Epoch 17140, Training-Loss 2.4062e+00, Data-loss 5.5791e-01                  , pde-loss 5.4119e+03, initc-loss 1.2908e+04                    bc_loss 1.6252e+02\n",
      "Epoch 17150, Training-Loss 2.6372e+00, Data-loss 7.5900e-01                  , pde-loss 5.6352e+03, initc-loss 1.2894e+04                    bc_loss 2.5269e+02\n",
      "Epoch 17160, Training-Loss 2.6566e+00, Data-loss 6.7344e-01                  , pde-loss 6.2353e+03, initc-loss 1.2930e+04                    bc_loss 6.6633e+02\n",
      "Epoch 17170, Training-Loss 2.5759e+00, Data-loss 5.9703e-01                  , pde-loss 6.5988e+03, initc-loss 1.2916e+04                    bc_loss 2.7393e+02\n",
      "Epoch 17180, Training-Loss 2.5793e+00, Data-loss 6.6575e-01                  , pde-loss 5.5255e+03, initc-loss 1.2960e+04                    bc_loss 6.4984e+02\n",
      "Epoch 17190, Training-Loss 2.4574e+00, Data-loss 5.2306e-01                  , pde-loss 5.4249e+03, initc-loss 1.2861e+04                    bc_loss 1.0577e+03\n",
      "Epoch 17200, Training-Loss 2.7062e+00, Data-loss 7.8594e-01                  , pde-loss 5.5863e+03, initc-loss 1.2961e+04                    bc_loss 6.5549e+02\n",
      "Epoch 17210, Training-Loss 2.4319e+00, Data-loss 5.0829e-01                  , pde-loss 5.2046e+03, initc-loss 1.2901e+04                    bc_loss 1.1307e+03\n",
      "Epoch 17220, Training-Loss 2.4684e+00, Data-loss 5.2603e-01                  , pde-loss 5.1149e+03, initc-loss 1.2864e+04                    bc_loss 1.4450e+03\n",
      "Epoch 17230, Training-Loss 2.4728e+00, Data-loss 5.8082e-01                  , pde-loss 5.7731e+03, initc-loss 1.2817e+04                    bc_loss 3.2986e+02\n",
      "Epoch 17240, Training-Loss 2.4476e+00, Data-loss 4.3498e-01                  , pde-loss 6.6736e+03, initc-loss 1.3013e+04                    bc_loss 4.3922e+02\n",
      "Epoch 17250, Training-Loss 2.5210e+00, Data-loss 6.1743e-01                  , pde-loss 6.0389e+03, initc-loss 1.2837e+04                    bc_loss 1.6043e+02\n",
      "Epoch 17260, Training-Loss 2.5550e+00, Data-loss 5.3185e-01                  , pde-loss 6.8702e+03, initc-loss 1.2885e+04                    bc_loss 4.7546e+02\n",
      "Epoch 17270, Training-Loss 2.3876e+00, Data-loss 4.9746e-01                  , pde-loss 5.4564e+03, initc-loss 1.2841e+04                    bc_loss 6.0464e+02\n",
      "Epoch 17280, Training-Loss 2.7581e+00, Data-loss 5.9081e-01                  , pde-loss 6.7040e+03, initc-loss 1.2756e+04                    bc_loss 2.2128e+03\n",
      "Epoch 17290, Training-Loss 2.9515e+00, Data-loss 6.8415e-01                  , pde-loss 4.8898e+03, initc-loss 1.2818e+04                    bc_loss 4.9658e+03\n",
      "Epoch 17300, Training-Loss 2.3984e+00, Data-loss 5.0716e-01                  , pde-loss 5.5946e+03, initc-loss 1.2870e+04                    bc_loss 4.4754e+02\n",
      "Epoch 17310, Training-Loss 2.4991e+00, Data-loss 5.9721e-01                  , pde-loss 5.6565e+03, initc-loss 1.2914e+04                    bc_loss 4.4828e+02\n",
      "Epoch 17320, Training-Loss 3.2890e+00, Data-loss 8.6034e-01                  , pde-loss 6.5010e+03, initc-loss 1.2814e+04                    bc_loss 4.9718e+03\n",
      "Epoch 17330, Training-Loss 2.8886e+00, Data-loss 7.4105e-01                  , pde-loss 5.8272e+03, initc-loss 1.2770e+04                    bc_loss 2.8785e+03\n",
      "Epoch 17340, Training-Loss 2.4596e+00, Data-loss 4.9866e-01                  , pde-loss 6.1516e+03, initc-loss 1.2821e+04                    bc_loss 6.3733e+02\n",
      "Epoch 17350, Training-Loss 2.5876e+00, Data-loss 6.1826e-01                  , pde-loss 6.4730e+03, initc-loss 1.2968e+04                    bc_loss 2.5252e+02\n",
      "Epoch 17360, Training-Loss 2.4170e+00, Data-loss 5.1710e-01                  , pde-loss 5.8137e+03, initc-loss 1.2915e+04                    bc_loss 2.7053e+02\n",
      "Epoch 17370, Training-Loss 2.5119e+00, Data-loss 4.1299e-01                  , pde-loss 5.7819e+03, initc-loss 1.2932e+04                    bc_loss 2.2754e+03\n",
      "Epoch 17380, Training-Loss 2.6257e+00, Data-loss 7.3069e-01                  , pde-loss 5.9503e+03, initc-loss 1.2848e+04                    bc_loss 1.5172e+02\n",
      "Epoch 17390, Training-Loss 2.5879e+00, Data-loss 6.1033e-01                  , pde-loss 6.3778e+03, initc-loss 1.2877e+04                    bc_loss 5.2119e+02\n",
      "Epoch 17400, Training-Loss 2.5223e+00, Data-loss 5.8700e-01                  , pde-loss 6.1451e+03, initc-loss 1.2976e+04                    bc_loss 2.3236e+02\n",
      "Epoch 17410, Training-Loss 2.6165e+00, Data-loss 7.1776e-01                  , pde-loss 5.1727e+03, initc-loss 1.2994e+04                    bc_loss 8.2094e+02\n",
      "Epoch 17420, Training-Loss 2.4526e+00, Data-loss 4.8909e-01                  , pde-loss 5.5542e+03, initc-loss 1.2892e+04                    bc_loss 1.1891e+03\n",
      "Epoch 17430, Training-Loss 2.8780e+00, Data-loss 9.1223e-01                  , pde-loss 5.9567e+03, initc-loss 1.2865e+04                    bc_loss 8.3629e+02\n",
      "Epoch 17440, Training-Loss 3.0796e+00, Data-loss 7.3350e-01                  , pde-loss 5.1656e+03, initc-loss 1.2814e+04                    bc_loss 5.4818e+03\n",
      "Epoch 17450, Training-Loss 3.0219e+00, Data-loss 9.2723e-01                  , pde-loss 6.5099e+03, initc-loss 1.2982e+04                    bc_loss 1.4545e+03\n",
      "Epoch 17460, Training-Loss 2.5493e+00, Data-loss 6.3847e-01                  , pde-loss 5.8438e+03, initc-loss 1.2834e+04                    bc_loss 4.3073e+02\n",
      "Epoch 17470, Training-Loss 3.2074e+00, Data-loss 8.0950e-01                  , pde-loss 6.0299e+03, initc-loss 1.2776e+04                    bc_loss 5.1726e+03\n",
      "Epoch 17480, Training-Loss 2.7074e+00, Data-loss 7.2021e-01                  , pde-loss 5.7723e+03, initc-loss 1.2923e+04                    bc_loss 1.1770e+03\n",
      "Epoch 17490, Training-Loss 2.7470e+00, Data-loss 5.8960e-01                  , pde-loss 5.3911e+03, initc-loss 1.2935e+04                    bc_loss 3.2473e+03\n",
      "Epoch 17500, Training-Loss 2.4778e+00, Data-loss 6.7330e-01                  , pde-loss 4.8455e+03, initc-loss 1.2912e+04                    bc_loss 2.8694e+02\n",
      "Epoch 17510, Training-Loss 3.0797e+00, Data-loss 6.9497e-01                  , pde-loss 5.5192e+03, initc-loss 1.2785e+04                    bc_loss 5.5435e+03\n",
      "Epoch 17520, Training-Loss 2.4726e+00, Data-loss 6.6808e-01                  , pde-loss 4.9128e+03, initc-loss 1.2856e+04                    bc_loss 2.7573e+02\n",
      "Epoch 17530, Training-Loss 2.6333e+00, Data-loss 6.8440e-01                  , pde-loss 6.0642e+03, initc-loss 1.2992e+04                    bc_loss 4.3228e+02\n",
      "Epoch 17540, Training-Loss 2.6693e+00, Data-loss 7.3168e-01                  , pde-loss 5.7230e+03, initc-loss 1.2837e+04                    bc_loss 8.1639e+02\n",
      "Epoch 17550, Training-Loss 2.6636e+00, Data-loss 6.8826e-01                  , pde-loss 6.1195e+03, initc-loss 1.2833e+04                    bc_loss 8.0101e+02\n",
      "Epoch 17560, Training-Loss 2.4564e+00, Data-loss 4.8270e-01                  , pde-loss 6.1064e+03, initc-loss 1.2865e+04                    bc_loss 7.6639e+02\n",
      "Epoch 17570, Training-Loss 2.5373e+00, Data-loss 5.9227e-01                  , pde-loss 6.0923e+03, initc-loss 1.2919e+04                    bc_loss 4.3912e+02\n",
      "Epoch 17580, Training-Loss 2.4613e+00, Data-loss 5.4617e-01                  , pde-loss 5.6349e+03, initc-loss 1.2870e+04                    bc_loss 6.4564e+02\n",
      "Epoch 17590, Training-Loss 2.4565e+00, Data-loss 5.0823e-01                  , pde-loss 5.8121e+03, initc-loss 1.2890e+04                    bc_loss 7.8040e+02\n",
      "Epoch 17600, Training-Loss 2.8969e+00, Data-loss 8.3514e-01                  , pde-loss 6.5230e+03, initc-loss 1.2862e+04                    bc_loss 1.2325e+03\n",
      "Epoch 17610, Training-Loss 2.7675e+00, Data-loss 7.7376e-01                  , pde-loss 5.8092e+03, initc-loss 1.3002e+04                    bc_loss 1.1264e+03\n",
      "Epoch 17620, Training-Loss 2.3900e+00, Data-loss 4.0169e-01                  , pde-loss 5.2469e+03, initc-loss 1.2886e+04                    bc_loss 1.7505e+03\n",
      "Epoch 17630, Training-Loss 3.3312e+00, Data-loss 1.1681e+00                  , pde-loss 5.9205e+03, initc-loss 1.2773e+04                    bc_loss 2.9375e+03\n",
      "Epoch 17640, Training-Loss 2.7396e+00, Data-loss 5.9400e-01                  , pde-loss 6.6454e+03, initc-loss 1.2900e+04                    bc_loss 1.9102e+03\n",
      "Epoch 17650, Training-Loss 2.8371e+00, Data-loss 8.3623e-01                  , pde-loss 6.3958e+03, initc-loss 1.2917e+04                    bc_loss 6.9561e+02\n",
      "Epoch 17660, Training-Loss 2.4999e+00, Data-loss 5.5759e-01                  , pde-loss 5.8475e+03, initc-loss 1.2845e+04                    bc_loss 7.3109e+02\n",
      "Epoch 17670, Training-Loss 2.6292e+00, Data-loss 6.1362e-01                  , pde-loss 5.7991e+03, initc-loss 1.2877e+04                    bc_loss 1.4793e+03\n",
      "Epoch 17680, Training-Loss 2.4092e+00, Data-loss 5.2523e-01                  , pde-loss 5.6583e+03, initc-loss 1.2892e+04                    bc_loss 2.8934e+02\n",
      "Epoch 17690, Training-Loss 2.8974e+00, Data-loss 8.4344e-01                  , pde-loss 6.7242e+03, initc-loss 1.3032e+04                    bc_loss 7.8360e+02\n",
      "Epoch 17700, Training-Loss 2.6254e+00, Data-loss 6.5938e-01                  , pde-loss 5.7397e+03, initc-loss 1.2831e+04                    bc_loss 1.0892e+03\n",
      "Epoch 17710, Training-Loss 2.3422e+00, Data-loss 4.6434e-01                  , pde-loss 5.7716e+03, initc-loss 1.2860e+04                    bc_loss 1.4715e+02\n",
      "Epoch 17720, Training-Loss 2.6104e+00, Data-loss 7.2659e-01                  , pde-loss 5.8354e+03, initc-loss 1.2856e+04                    bc_loss 1.4708e+02\n",
      "Epoch 17730, Training-Loss 2.4700e+00, Data-loss 6.2519e-01                  , pde-loss 4.9520e+03, initc-loss 1.2954e+04                    bc_loss 5.4207e+02\n",
      "Epoch 17740, Training-Loss 2.4583e+00, Data-loss 6.3069e-01                  , pde-loss 5.1672e+03, initc-loss 1.2858e+04                    bc_loss 2.5039e+02\n",
      "Epoch 17750, Training-Loss 2.4715e+00, Data-loss 6.0294e-01                  , pde-loss 5.4470e+03, initc-loss 1.2862e+04                    bc_loss 3.7635e+02\n",
      "Epoch 17760, Training-Loss 2.9834e+00, Data-loss 9.7323e-01                  , pde-loss 6.2792e+03, initc-loss 1.2784e+04                    bc_loss 1.0385e+03\n",
      "Epoch 17770, Training-Loss 2.7808e+00, Data-loss 8.5262e-01                  , pde-loss 5.5256e+03, initc-loss 1.2963e+04                    bc_loss 7.9289e+02\n",
      "Epoch 17780, Training-Loss 2.5712e+00, Data-loss 4.4094e-01                  , pde-loss 5.8473e+03, initc-loss 1.2910e+04                    bc_loss 2.5458e+03\n",
      "Epoch 17790, Training-Loss 2.7351e+00, Data-loss 7.2883e-01                  , pde-loss 6.4767e+03, initc-loss 1.2887e+04                    bc_loss 6.9905e+02\n",
      "Epoch 17800, Training-Loss 2.4129e+00, Data-loss 6.1401e-01                  , pde-loss 4.8255e+03, initc-loss 1.2906e+04                    bc_loss 2.5697e+02\n",
      "Epoch 17810, Training-Loss 2.3671e+00, Data-loss 5.0316e-01                  , pde-loss 5.1375e+03, initc-loss 1.2806e+04                    bc_loss 6.9505e+02\n",
      "Epoch 17820, Training-Loss 2.6405e+00, Data-loss 7.8319e-01                  , pde-loss 5.0608e+03, initc-loss 1.2866e+04                    bc_loss 6.4588e+02\n",
      "Epoch 17830, Training-Loss 2.5394e+00, Data-loss 6.1465e-01                  , pde-loss 5.7195e+03, initc-loss 1.2854e+04                    bc_loss 6.7369e+02\n",
      "Epoch 17840, Training-Loss 2.7601e+00, Data-loss 7.5207e-01                  , pde-loss 5.3458e+03, initc-loss 1.2896e+04                    bc_loss 1.8388e+03\n",
      "Epoch 17850, Training-Loss 2.6066e+00, Data-loss 6.6354e-01                  , pde-loss 5.9239e+03, initc-loss 1.2811e+04                    bc_loss 6.9612e+02\n",
      "Epoch 17860, Training-Loss 2.9904e+00, Data-loss 8.3102e-01                  , pde-loss 5.9150e+03, initc-loss 1.2799e+04                    bc_loss 2.8797e+03\n",
      "Epoch 17870, Training-Loss 2.6039e+00, Data-loss 5.7534e-01                  , pde-loss 6.2389e+03, initc-loss 1.2911e+04                    bc_loss 1.1359e+03\n",
      "Epoch 17880, Training-Loss 2.5887e+00, Data-loss 5.0795e-01                  , pde-loss 6.3756e+03, initc-loss 1.2960e+04                    bc_loss 1.4721e+03\n",
      "Epoch 17890, Training-Loss 2.4932e+00, Data-loss 6.1640e-01                  , pde-loss 4.8895e+03, initc-loss 1.2875e+04                    bc_loss 1.0032e+03\n",
      "Epoch 17900, Training-Loss 2.5378e+00, Data-loss 6.9060e-01                  , pde-loss 5.5680e+03, initc-loss 1.2782e+04                    bc_loss 1.2214e+02\n",
      "Epoch 17910, Training-Loss 2.6920e+00, Data-loss 7.0561e-01                  , pde-loss 5.4476e+03, initc-loss 1.2964e+04                    bc_loss 1.4514e+03\n",
      "Epoch 17920, Training-Loss 2.4779e+00, Data-loss 5.0558e-01                  , pde-loss 6.1311e+03, initc-loss 1.2884e+04                    bc_loss 7.0853e+02\n",
      "Epoch 17930, Training-Loss 2.4518e+00, Data-loss 5.4196e-01                  , pde-loss 5.8232e+03, initc-loss 1.2809e+04                    bc_loss 4.6573e+02\n",
      "Epoch 17940, Training-Loss 2.3485e+00, Data-loss 4.1041e-01                  , pde-loss 5.8609e+03, initc-loss 1.2918e+04                    bc_loss 6.0145e+02\n",
      "Epoch 17950, Training-Loss 2.6424e+00, Data-loss 5.2944e-01                  , pde-loss 6.3591e+03, initc-loss 1.2870e+04                    bc_loss 1.9006e+03\n",
      "Epoch 17960, Training-Loss 2.4201e+00, Data-loss 4.4690e-01                  , pde-loss 5.8221e+03, initc-loss 1.2861e+04                    bc_loss 1.0482e+03\n",
      "Epoch 17970, Training-Loss 2.4561e+00, Data-loss 5.6217e-01                  , pde-loss 5.9287e+03, initc-loss 1.2866e+04                    bc_loss 1.4471e+02\n",
      "Epoch 17980, Training-Loss 2.2624e+00, Data-loss 4.3280e-01                  , pde-loss 4.9526e+03, initc-loss 1.2943e+04                    bc_loss 4.0033e+02\n",
      "Epoch 17990, Training-Loss 2.9486e+00, Data-loss 7.9503e-01                  , pde-loss 6.0214e+03, initc-loss 1.2853e+04                    bc_loss 2.6607e+03\n",
      "Epoch 18000, Training-Loss 3.9252e+00, Data-loss 1.7454e+00                  , pde-loss 5.4704e+03, initc-loss 1.3090e+04                    bc_loss 3.2373e+03\n",
      "Epoch 18010, Training-Loss 2.8768e+00, Data-loss 8.7689e-01                  , pde-loss 6.0468e+03, initc-loss 1.2853e+04                    bc_loss 1.0993e+03\n",
      "Epoch 18020, Training-Loss 2.8613e+00, Data-loss 7.1314e-01                  , pde-loss 6.3320e+03, initc-loss 1.2811e+04                    bc_loss 2.3385e+03\n",
      "Epoch 18030, Training-Loss 2.5447e+00, Data-loss 5.2741e-01                  , pde-loss 4.8394e+03, initc-loss 1.2921e+04                    bc_loss 2.4126e+03\n",
      "Epoch 18040, Training-Loss 2.5726e+00, Data-loss 5.7940e-01                  , pde-loss 6.2074e+03, initc-loss 1.2947e+04                    bc_loss 7.7747e+02\n",
      "Epoch 18050, Training-Loss 2.6949e+00, Data-loss 5.8957e-01                  , pde-loss 6.1367e+03, initc-loss 1.2911e+04                    bc_loss 2.0063e+03\n",
      "Epoch 18060, Training-Loss 2.3982e+00, Data-loss 5.0800e-01                  , pde-loss 5.7834e+03, initc-loss 1.2863e+04                    bc_loss 2.5558e+02\n",
      "Epoch 18070, Training-Loss 2.5523e+00, Data-loss 5.9699e-01                  , pde-loss 6.4079e+03, initc-loss 1.2910e+04                    bc_loss 2.3482e+02\n",
      "Epoch 18080, Training-Loss 2.2589e+00, Data-loss 3.6162e-01                  , pde-loss 5.8079e+03, initc-loss 1.2911e+04                    bc_loss 2.5426e+02\n",
      "Epoch 18090, Training-Loss 2.4733e+00, Data-loss 4.7458e-01                  , pde-loss 5.8317e+03, initc-loss 1.2860e+04                    bc_loss 1.2952e+03\n",
      "Epoch 18100, Training-Loss 2.3662e+00, Data-loss 5.1715e-01                  , pde-loss 5.4126e+03, initc-loss 1.2874e+04                    bc_loss 2.0321e+02\n",
      "Epoch 18110, Training-Loss 2.3744e+00, Data-loss 5.1685e-01                  , pde-loss 5.3708e+03, initc-loss 1.2832e+04                    bc_loss 3.7311e+02\n",
      "Epoch 18120, Training-Loss 2.4336e+00, Data-loss 5.2148e-01                  , pde-loss 5.9965e+03, initc-loss 1.2833e+04                    bc_loss 2.9133e+02\n",
      "Epoch 18130, Training-Loss 2.5678e+00, Data-loss 6.0157e-01                  , pde-loss 6.5012e+03, initc-loss 1.2898e+04                    bc_loss 2.6358e+02\n",
      "Epoch 18140, Training-Loss 2.6374e+00, Data-loss 5.5896e-01                  , pde-loss 6.3592e+03, initc-loss 1.2802e+04                    bc_loss 1.6227e+03\n",
      "Epoch 18150, Training-Loss 2.3346e+00, Data-loss 3.7192e-01                  , pde-loss 6.2790e+03, initc-loss 1.2938e+04                    bc_loss 4.0956e+02\n",
      "Epoch 18160, Training-Loss 2.2905e+00, Data-loss 4.3265e-01                  , pde-loss 5.5896e+03, initc-loss 1.2816e+04                    bc_loss 1.7248e+02\n",
      "Epoch 18170, Training-Loss 2.4780e+00, Data-loss 5.3033e-01                  , pde-loss 5.2592e+03, initc-loss 1.2872e+04                    bc_loss 1.3454e+03\n",
      "Epoch 18180, Training-Loss 2.7920e+00, Data-loss 6.9133e-01                  , pde-loss 6.5800e+03, initc-loss 1.2947e+04                    bc_loss 1.4798e+03\n",
      "Epoch 18190, Training-Loss 2.4657e+00, Data-loss 5.3261e-01                  , pde-loss 6.1038e+03, initc-loss 1.2827e+04                    bc_loss 3.9957e+02\n",
      "Epoch 18200, Training-Loss 2.1954e+00, Data-loss 3.6361e-01                  , pde-loss 4.9818e+03, initc-loss 1.2891e+04                    bc_loss 4.4593e+02\n",
      "Epoch 18210, Training-Loss 2.5512e+00, Data-loss 5.6312e-01                  , pde-loss 6.5605e+03, initc-loss 1.2882e+04                    bc_loss 4.3845e+02\n",
      "Epoch 18220, Training-Loss 2.5052e+00, Data-loss 6.3541e-01                  , pde-loss 5.5325e+03, initc-loss 1.2912e+04                    bc_loss 2.5266e+02\n",
      "Epoch 18230, Training-Loss 2.4537e+00, Data-loss 4.9528e-01                  , pde-loss 6.3808e+03, initc-loss 1.2910e+04                    bc_loss 2.9295e+02\n",
      "Epoch 18240, Training-Loss 2.3452e+00, Data-loss 3.9628e-01                  , pde-loss 6.5082e+03, initc-loss 1.2819e+04                    bc_loss 1.6140e+02\n",
      "Epoch 18250, Training-Loss 2.4594e+00, Data-loss 4.1906e-01                  , pde-loss 6.2007e+03, initc-loss 1.3030e+04                    bc_loss 1.1730e+03\n",
      "Epoch 18260, Training-Loss 2.6461e+00, Data-loss 6.5997e-01                  , pde-loss 6.2173e+03, initc-loss 1.2911e+04                    bc_loss 7.3304e+02\n",
      "Epoch 18270, Training-Loss 2.6908e+00, Data-loss 6.7034e-01                  , pde-loss 6.5139e+03, initc-loss 1.2936e+04                    bc_loss 7.5556e+02\n",
      "Epoch 18280, Training-Loss 2.7006e+00, Data-loss 8.0882e-01                  , pde-loss 5.3137e+03, initc-loss 1.2935e+04                    bc_loss 6.6921e+02\n",
      "Epoch 18290, Training-Loss 2.6989e+00, Data-loss 6.0853e-01                  , pde-loss 5.9916e+03, initc-loss 1.2858e+04                    bc_loss 2.0535e+03\n",
      "Epoch 18300, Training-Loss 2.4633e+00, Data-loss 4.8446e-01                  , pde-loss 5.9303e+03, initc-loss 1.2948e+04                    bc_loss 9.1022e+02\n",
      "Epoch 18310, Training-Loss 2.9765e+00, Data-loss 8.0031e-01                  , pde-loss 5.5037e+03, initc-loss 1.2761e+04                    bc_loss 3.4974e+03\n",
      "Epoch 18320, Training-Loss 2.9387e+00, Data-loss 7.9888e-01                  , pde-loss 6.7618e+03, initc-loss 1.2798e+04                    bc_loss 1.8385e+03\n",
      "Epoch 18330, Training-Loss 2.4291e+00, Data-loss 5.2337e-01                  , pde-loss 5.9674e+03, initc-loss 1.2945e+04                    bc_loss 1.4434e+02\n",
      "Epoch 18340, Training-Loss 2.5546e+00, Data-loss 6.0885e-01                  , pde-loss 5.9649e+03, initc-loss 1.2931e+04                    bc_loss 5.6167e+02\n",
      "Epoch 18350, Training-Loss 2.4504e+00, Data-loss 5.3498e-01                  , pde-loss 5.1843e+03, initc-loss 1.2962e+04                    bc_loss 1.0079e+03\n",
      "Epoch 18360, Training-Loss 2.5728e+00, Data-loss 6.1246e-01                  , pde-loss 6.1958e+03, initc-loss 1.2945e+04                    bc_loss 4.6252e+02\n",
      "Epoch 18370, Training-Loss 2.5212e+00, Data-loss 5.4051e-01                  , pde-loss 5.8358e+03, initc-loss 1.2868e+04                    bc_loss 1.1029e+03\n",
      "Epoch 18380, Training-Loss 3.0168e+00, Data-loss 7.5560e-01                  , pde-loss 6.6031e+03, initc-loss 1.2797e+04                    bc_loss 3.2117e+03\n",
      "Epoch 18390, Training-Loss 2.6028e+00, Data-loss 5.5692e-01                  , pde-loss 7.0724e+03, initc-loss 1.2858e+04                    bc_loss 5.2891e+02\n",
      "Epoch 18400, Training-Loss 2.2779e+00, Data-loss 4.3142e-01                  , pde-loss 5.4269e+03, initc-loss 1.2831e+04                    bc_loss 2.0665e+02\n",
      "Epoch 18410, Training-Loss 2.2924e+00, Data-loss 4.5996e-01                  , pde-loss 5.1773e+03, initc-loss 1.2826e+04                    bc_loss 3.2125e+02\n",
      "Epoch 18420, Training-Loss 2.7171e+00, Data-loss 8.3796e-01                  , pde-loss 5.3874e+03, initc-loss 1.2912e+04                    bc_loss 4.9212e+02\n",
      "Epoch 18430, Training-Loss 2.4292e+00, Data-loss 5.8128e-01                  , pde-loss 5.2244e+03, initc-loss 1.2867e+04                    bc_loss 3.8810e+02\n",
      "Epoch 18440, Training-Loss 2.7476e+00, Data-loss 7.4405e-01                  , pde-loss 6.2888e+03, initc-loss 1.2855e+04                    bc_loss 8.9209e+02\n",
      "Epoch 18450, Training-Loss 3.0050e+00, Data-loss 1.0519e+00                  , pde-loss 5.6084e+03, initc-loss 1.2806e+04                    bc_loss 1.1178e+03\n",
      "Epoch 18460, Training-Loss 2.4314e+00, Data-loss 5.4470e-01                  , pde-loss 5.4028e+03, initc-loss 1.2904e+04                    bc_loss 5.5949e+02\n",
      "Epoch 18470, Training-Loss 2.3364e+00, Data-loss 4.7645e-01                  , pde-loss 5.6170e+03, initc-loss 1.2842e+04                    bc_loss 1.4115e+02\n",
      "Epoch 18480, Training-Loss 2.5553e+00, Data-loss 4.9119e-01                  , pde-loss 6.6755e+03, initc-loss 1.2925e+04                    bc_loss 1.0403e+03\n",
      "Epoch 18490, Training-Loss 2.4698e+00, Data-loss 5.9828e-01                  , pde-loss 5.5999e+03, initc-loss 1.2890e+04                    bc_loss 2.2552e+02\n",
      "Epoch 18500, Training-Loss 2.8171e+00, Data-loss 8.9959e-01                  , pde-loss 5.2091e+03, initc-loss 1.2978e+04                    bc_loss 9.8807e+02\n",
      "Epoch 18510, Training-Loss 2.5177e+00, Data-loss 5.5818e-01                  , pde-loss 6.1699e+03, initc-loss 1.2862e+04                    bc_loss 5.6374e+02\n",
      "Epoch 18520, Training-Loss 2.4126e+00, Data-loss 4.8525e-01                  , pde-loss 6.2125e+03, initc-loss 1.2914e+04                    bc_loss 1.4669e+02\n",
      "Epoch 18530, Training-Loss 2.3764e+00, Data-loss 4.9702e-01                  , pde-loss 5.6292e+03, initc-loss 1.2896e+04                    bc_loss 2.6851e+02\n",
      "Epoch 18540, Training-Loss 3.2147e+00, Data-loss 1.0050e+00                  , pde-loss 5.5044e+03, initc-loss 1.2772e+04                    bc_loss 3.8210e+03\n",
      "Epoch 18550, Training-Loss 3.3989e+00, Data-loss 1.1344e+00                  , pde-loss 6.0902e+03, initc-loss 1.2842e+04                    bc_loss 3.7131e+03\n",
      "Epoch 18560, Training-Loss 2.4434e+00, Data-loss 5.8161e-01                  , pde-loss 5.5255e+03, initc-loss 1.2903e+04                    bc_loss 1.8902e+02\n",
      "Epoch 18570, Training-Loss 2.4342e+00, Data-loss 5.0035e-01                  , pde-loss 5.0087e+03, initc-loss 1.2865e+04                    bc_loss 1.4650e+03\n",
      "Epoch 18580, Training-Loss 2.6056e+00, Data-loss 5.1261e-01                  , pde-loss 5.8367e+03, initc-loss 1.2946e+04                    bc_loss 2.1470e+03\n",
      "Epoch 18590, Training-Loss 2.6464e+00, Data-loss 5.0635e-01                  , pde-loss 6.2957e+03, initc-loss 1.2928e+04                    bc_loss 2.1767e+03\n",
      "Epoch 18600, Training-Loss 2.7606e+00, Data-loss 7.5251e-01                  , pde-loss 5.8754e+03, initc-loss 1.2823e+04                    bc_loss 1.3821e+03\n",
      "Epoch 18610, Training-Loss 2.3020e+00, Data-loss 4.6625e-01                  , pde-loss 5.3049e+03, initc-loss 1.2850e+04                    bc_loss 2.0252e+02\n",
      "Epoch 18620, Training-Loss 2.3865e+00, Data-loss 4.8297e-01                  , pde-loss 5.7958e+03, initc-loss 1.2878e+04                    bc_loss 3.6122e+02\n",
      "Epoch 18630, Training-Loss 2.4594e+00, Data-loss 3.9469e-01                  , pde-loss 6.7396e+03, initc-loss 1.2949e+04                    bc_loss 9.5847e+02\n",
      "Epoch 18640, Training-Loss 2.5940e+00, Data-loss 4.8930e-01                  , pde-loss 6.5882e+03, initc-loss 1.2904e+04                    bc_loss 1.5553e+03\n",
      "Epoch 18650, Training-Loss 2.4230e+00, Data-loss 5.0416e-01                  , pde-loss 6.0020e+03, initc-loss 1.2863e+04                    bc_loss 3.2323e+02\n",
      "Epoch 18660, Training-Loss 2.5083e+00, Data-loss 6.3264e-01                  , pde-loss 5.6655e+03, initc-loss 1.2897e+04                    bc_loss 1.9373e+02\n",
      "Epoch 18670, Training-Loss 2.3887e+00, Data-loss 4.6686e-01                  , pde-loss 6.2628e+03, initc-loss 1.2817e+04                    bc_loss 1.3818e+02\n",
      "Epoch 18680, Training-Loss 2.3947e+00, Data-loss 5.1770e-01                  , pde-loss 5.5293e+03, initc-loss 1.2928e+04                    bc_loss 3.1283e+02\n",
      "Epoch 18690, Training-Loss 2.4426e+00, Data-loss 5.1400e-01                  , pde-loss 6.2131e+03, initc-loss 1.2933e+04                    bc_loss 1.3996e+02\n",
      "Epoch 18700, Training-Loss 2.3999e+00, Data-loss 4.6722e-01                  , pde-loss 6.0654e+03, initc-loss 1.2899e+04                    bc_loss 3.6229e+02\n",
      "Epoch 18710, Training-Loss 2.4897e+00, Data-loss 4.7323e-01                  , pde-loss 5.5628e+03, initc-loss 1.2972e+04                    bc_loss 1.6292e+03\n",
      "Epoch 18720, Training-Loss 2.5703e+00, Data-loss 5.7817e-01                  , pde-loss 6.4555e+03, initc-loss 1.2887e+04                    bc_loss 5.7958e+02\n",
      "Epoch 18730, Training-Loss 2.8301e+00, Data-loss 7.1234e-01                  , pde-loss 5.6155e+03, initc-loss 1.2735e+04                    bc_loss 2.8279e+03\n",
      "Epoch 18740, Training-Loss 2.4887e+00, Data-loss 4.9634e-01                  , pde-loss 6.4830e+03, initc-loss 1.2796e+04                    bc_loss 6.4480e+02\n",
      "Epoch 18750, Training-Loss 2.4561e+00, Data-loss 5.1571e-01                  , pde-loss 5.8795e+03, initc-loss 1.2927e+04                    bc_loss 5.9746e+02\n",
      "Epoch 18760, Training-Loss 2.3574e+00, Data-loss 4.7533e-01                  , pde-loss 5.6383e+03, initc-loss 1.2893e+04                    bc_loss 2.8916e+02\n",
      "Epoch 18770, Training-Loss 2.4310e+00, Data-loss 5.0379e-01                  , pde-loss 6.2380e+03, initc-loss 1.2808e+04                    bc_loss 2.2580e+02\n",
      "Epoch 18780, Training-Loss 2.4148e+00, Data-loss 4.4871e-01                  , pde-loss 6.3893e+03, initc-loss 1.2838e+04                    bc_loss 4.3383e+02\n",
      "Epoch 18790, Training-Loss 2.9648e+00, Data-loss 9.2502e-01                  , pde-loss 6.2953e+03, initc-loss 1.3004e+04                    bc_loss 1.0980e+03\n",
      "Epoch 18800, Training-Loss 2.8711e+00, Data-loss 5.9764e-01                  , pde-loss 5.9525e+03, initc-loss 1.2963e+04                    bc_loss 3.8189e+03\n",
      "Epoch 18810, Training-Loss 2.4040e+00, Data-loss 4.0576e-01                  , pde-loss 6.4369e+03, initc-loss 1.2916e+04                    bc_loss 6.3001e+02\n",
      "Epoch 18820, Training-Loss 2.5233e+00, Data-loss 5.0288e-01                  , pde-loss 6.6584e+03, initc-loss 1.2909e+04                    bc_loss 6.3728e+02\n",
      "Epoch 18830, Training-Loss 2.5890e+00, Data-loss 5.9600e-01                  , pde-loss 6.1152e+03, initc-loss 1.2826e+04                    bc_loss 9.8930e+02\n",
      "Epoch 18840, Training-Loss 2.4318e+00, Data-loss 4.4576e-01                  , pde-loss 6.8010e+03, initc-loss 1.2922e+04                    bc_loss 1.3744e+02\n",
      "Epoch 18850, Training-Loss 2.5717e+00, Data-loss 5.9788e-01                  , pde-loss 6.5811e+03, initc-loss 1.2869e+04                    bc_loss 2.8742e+02\n",
      "Epoch 18860, Training-Loss 2.7410e+00, Data-loss 6.4060e-01                  , pde-loss 5.9097e+03, initc-loss 1.2950e+04                    bc_loss 2.1444e+03\n",
      "Epoch 18870, Training-Loss 2.5339e+00, Data-loss 5.4263e-01                  , pde-loss 6.6735e+03, initc-loss 1.2882e+04                    bc_loss 3.5715e+02\n",
      "Epoch 18880, Training-Loss 2.8823e+00, Data-loss 7.9327e-01                  , pde-loss 5.9712e+03, initc-loss 1.2967e+04                    bc_loss 1.9518e+03\n",
      "Epoch 18890, Training-Loss 2.6322e+00, Data-loss 7.3064e-01                  , pde-loss 6.0277e+03, initc-loss 1.2855e+04                    bc_loss 1.3305e+02\n",
      "Epoch 18900, Training-Loss 3.3106e+00, Data-loss 1.0328e+00                  , pde-loss 5.8832e+03, initc-loss 1.3084e+04                    bc_loss 3.8110e+03\n",
      "Epoch 18910, Training-Loss 2.5333e+00, Data-loss 5.1303e-01                  , pde-loss 5.5113e+03, initc-loss 1.2953e+04                    bc_loss 1.7381e+03\n",
      "Epoch 18920, Training-Loss 2.8387e+00, Data-loss 8.5705e-01                  , pde-loss 5.8916e+03, initc-loss 1.2797e+04                    bc_loss 1.1277e+03\n",
      "Epoch 18930, Training-Loss 2.6402e+00, Data-loss 7.2074e-01                  , pde-loss 6.1331e+03, initc-loss 1.2864e+04                    bc_loss 1.9757e+02\n",
      "Epoch 18940, Training-Loss 2.4739e+00, Data-loss 4.5137e-01                  , pde-loss 6.9338e+03, initc-loss 1.2905e+04                    bc_loss 3.8637e+02\n",
      "Epoch 18950, Training-Loss 2.7218e+00, Data-loss 7.0714e-01                  , pde-loss 6.6215e+03, initc-loss 1.2997e+04                    bc_loss 5.2820e+02\n",
      "Epoch 18960, Training-Loss 2.6506e+00, Data-loss 5.5896e-01                  , pde-loss 5.5960e+03, initc-loss 1.2940e+04                    bc_loss 2.3803e+03\n",
      "Epoch 18970, Training-Loss 2.4587e+00, Data-loss 4.8436e-01                  , pde-loss 6.2452e+03, initc-loss 1.2883e+04                    bc_loss 6.1471e+02\n",
      "Epoch 18980, Training-Loss 2.5659e+00, Data-loss 5.5752e-01                  , pde-loss 6.4565e+03, initc-loss 1.2911e+04                    bc_loss 7.1632e+02\n",
      "Epoch 18990, Training-Loss 2.2884e+00, Data-loss 4.1274e-01                  , pde-loss 5.3922e+03, initc-loss 1.2871e+04                    bc_loss 4.9340e+02\n",
      "Epoch 19000, Training-Loss 2.4391e+00, Data-loss 4.8783e-01                  , pde-loss 5.7214e+03, initc-loss 1.2843e+04                    bc_loss 9.4807e+02\n",
      "Epoch 19010, Training-Loss 2.3931e+00, Data-loss 4.5393e-01                  , pde-loss 6.3778e+03, initc-loss 1.2873e+04                    bc_loss 1.4143e+02\n",
      "Epoch 19020, Training-Loss 2.4615e+00, Data-loss 4.1450e-01                  , pde-loss 6.2058e+03, initc-loss 1.2872e+04                    bc_loss 1.3914e+03\n",
      "Epoch 19030, Training-Loss 2.8530e+00, Data-loss 7.8283e-01                  , pde-loss 5.9438e+03, initc-loss 1.2946e+04                    bc_loss 1.8123e+03\n",
      "Epoch 19040, Training-Loss 2.8970e+00, Data-loss 7.5233e-01                  , pde-loss 5.7996e+03, initc-loss 1.2932e+04                    bc_loss 2.7149e+03\n",
      "Epoch 19050, Training-Loss 3.0688e+00, Data-loss 1.0155e+00                  , pde-loss 5.5467e+03, initc-loss 1.3072e+04                    bc_loss 1.9147e+03\n",
      "Epoch 19060, Training-Loss 2.6252e+00, Data-loss 5.5937e-01                  , pde-loss 6.1315e+03, initc-loss 1.2879e+04                    bc_loss 1.6482e+03\n",
      "Epoch 19070, Training-Loss 3.0118e+00, Data-loss 9.5682e-01                  , pde-loss 6.0779e+03, initc-loss 1.2853e+04                    bc_loss 1.6186e+03\n",
      "Epoch 19080, Training-Loss 2.5215e+00, Data-loss 6.6319e-01                  , pde-loss 5.3145e+03, initc-loss 1.3016e+04                    bc_loss 2.5244e+02\n",
      "Epoch 19090, Training-Loss 2.5323e+00, Data-loss 5.3570e-01                  , pde-loss 6.4965e+03, initc-loss 1.2861e+04                    bc_loss 6.0863e+02\n",
      "Epoch 19100, Training-Loss 2.5317e+00, Data-loss 6.2997e-01                  , pde-loss 5.5075e+03, initc-loss 1.2919e+04                    bc_loss 5.9035e+02\n",
      "Epoch 19110, Training-Loss 2.6658e+00, Data-loss 5.9039e-01                  , pde-loss 6.5506e+03, initc-loss 1.2856e+04                    bc_loss 1.3470e+03\n",
      "Epoch 19120, Training-Loss 2.6178e+00, Data-loss 7.4259e-01                  , pde-loss 5.0659e+03, initc-loss 1.2778e+04                    bc_loss 9.0845e+02\n",
      "Epoch 19130, Training-Loss 3.1463e+00, Data-loss 1.0155e+00                  , pde-loss 6.3949e+03, initc-loss 1.3032e+04                    bc_loss 1.8812e+03\n",
      "Epoch 19140, Training-Loss 2.3880e+00, Data-loss 4.8177e-01                  , pde-loss 5.9664e+03, initc-loss 1.2826e+04                    bc_loss 2.6972e+02\n",
      "Epoch 19150, Training-Loss 2.3969e+00, Data-loss 4.3864e-01                  , pde-loss 6.1186e+03, initc-loss 1.2953e+04                    bc_loss 5.1128e+02\n",
      "Epoch 19160, Training-Loss 2.4417e+00, Data-loss 4.9330e-01                  , pde-loss 6.4368e+03, initc-loss 1.2891e+04                    bc_loss 1.5705e+02\n",
      "Epoch 19170, Training-Loss 2.3811e+00, Data-loss 4.5214e-01                  , pde-loss 5.7614e+03, initc-loss 1.2890e+04                    bc_loss 6.3797e+02\n",
      "Epoch 19180, Training-Loss 2.4668e+00, Data-loss 5.2972e-01                  , pde-loss 5.9230e+03, initc-loss 1.2885e+04                    bc_loss 5.6251e+02\n",
      "Epoch 19190, Training-Loss 2.4851e+00, Data-loss 5.7766e-01                  , pde-loss 5.7352e+03, initc-loss 1.2847e+04                    bc_loss 4.9159e+02\n",
      "Epoch 19200, Training-Loss 2.6727e+00, Data-loss 6.2967e-01                  , pde-loss 5.7586e+03, initc-loss 1.2898e+04                    bc_loss 1.7737e+03\n",
      "Epoch 19210, Training-Loss 2.4009e+00, Data-loss 4.1178e-01                  , pde-loss 6.2888e+03, initc-loss 1.2881e+04                    bc_loss 7.2092e+02\n",
      "Epoch 19220, Training-Loss 2.4918e+00, Data-loss 5.7473e-01                  , pde-loss 5.1659e+03, initc-loss 1.2917e+04                    bc_loss 1.0874e+03\n",
      "Epoch 19230, Training-Loss 2.3652e+00, Data-loss 5.0222e-01                  , pde-loss 5.5502e+03, initc-loss 1.2843e+04                    bc_loss 2.3678e+02\n",
      "Epoch 19240, Training-Loss 2.5509e+00, Data-loss 5.5986e-01                  , pde-loss 5.9435e+03, initc-loss 1.2907e+04                    bc_loss 1.0590e+03\n",
      "Epoch 19250, Training-Loss 2.7915e+00, Data-loss 7.2273e-01                  , pde-loss 5.4909e+03, initc-loss 1.3001e+04                    bc_loss 2.1960e+03\n",
      "Epoch 19260, Training-Loss 2.3651e+00, Data-loss 4.5531e-01                  , pde-loss 5.8589e+03, initc-loss 1.2875e+04                    bc_loss 3.6382e+02\n",
      "Epoch 19270, Training-Loss 2.7911e+00, Data-loss 6.0811e-01                  , pde-loss 5.9959e+03, initc-loss 1.2836e+04                    bc_loss 2.9976e+03\n",
      "Epoch 19280, Training-Loss 2.5481e+00, Data-loss 6.0744e-01                  , pde-loss 5.9103e+03, initc-loss 1.2995e+04                    bc_loss 5.0109e+02\n",
      "Epoch 19290, Training-Loss 2.5516e+00, Data-loss 5.9249e-01                  , pde-loss 6.0210e+03, initc-loss 1.2978e+04                    bc_loss 5.9214e+02\n",
      "Epoch 19300, Training-Loss 2.4210e+00, Data-loss 4.8134e-01                  , pde-loss 6.3571e+03, initc-loss 1.2907e+04                    bc_loss 1.3260e+02\n",
      "Epoch 19310, Training-Loss 2.4873e+00, Data-loss 5.2588e-01                  , pde-loss 6.1815e+03, initc-loss 1.2877e+04                    bc_loss 5.5596e+02\n",
      "Epoch 19320, Training-Loss 2.3955e+00, Data-loss 4.3392e-01                  , pde-loss 6.3860e+03, initc-loss 1.2926e+04                    bc_loss 3.0416e+02\n",
      "Epoch 19330, Training-Loss 2.5466e+00, Data-loss 6.0676e-01                  , pde-loss 5.8822e+03, initc-loss 1.2824e+04                    bc_loss 6.9153e+02\n",
      "Epoch 19340, Training-Loss 2.6255e+00, Data-loss 5.7848e-01                  , pde-loss 6.5424e+03, initc-loss 1.2830e+04                    bc_loss 1.0983e+03\n",
      "Epoch 19350, Training-Loss 2.7752e+00, Data-loss 8.2227e-01                  , pde-loss 5.5936e+03, initc-loss 1.3002e+04                    bc_loss 9.3387e+02\n",
      "Epoch 19360, Training-Loss 2.8090e+00, Data-loss 5.5686e-01                  , pde-loss 6.4296e+03, initc-loss 1.2951e+04                    bc_loss 3.1407e+03\n",
      "Epoch 19370, Training-Loss 2.3150e+00, Data-loss 4.0843e-01                  , pde-loss 5.7184e+03, initc-loss 1.2859e+04                    bc_loss 4.8830e+02\n",
      "Epoch 19380, Training-Loss 2.3582e+00, Data-loss 4.8446e-01                  , pde-loss 5.6645e+03, initc-loss 1.2889e+04                    bc_loss 1.8318e+02\n",
      "Epoch 19390, Training-Loss 2.8971e+00, Data-loss 8.7205e-01                  , pde-loss 5.6845e+03, initc-loss 1.2983e+04                    bc_loss 1.5832e+03\n",
      "Epoch 19400, Training-Loss 2.4900e+00, Data-loss 5.9172e-01                  , pde-loss 5.3327e+03, initc-loss 1.2932e+04                    bc_loss 7.1885e+02\n",
      "Epoch 19410, Training-Loss 2.8783e+00, Data-loss 8.2965e-01                  , pde-loss 6.5488e+03, initc-loss 1.2991e+04                    bc_loss 9.4725e+02\n",
      "Epoch 19420, Training-Loss 2.4709e+00, Data-loss 4.5947e-01                  , pde-loss 6.2917e+03, initc-loss 1.2894e+04                    bc_loss 9.2869e+02\n",
      "Epoch 19430, Training-Loss 2.7808e+00, Data-loss 8.2912e-01                  , pde-loss 5.6369e+03, initc-loss 1.2829e+04                    bc_loss 1.0517e+03\n",
      "Epoch 19440, Training-Loss 2.5862e+00, Data-loss 5.7980e-01                  , pde-loss 6.5913e+03, initc-loss 1.2978e+04                    bc_loss 4.9493e+02\n",
      "Epoch 19450, Training-Loss 2.4613e+00, Data-loss 5.1837e-01                  , pde-loss 5.7208e+03, initc-loss 1.2875e+04                    bc_loss 8.3364e+02\n",
      "Epoch 19460, Training-Loss 2.4492e+00, Data-loss 4.5831e-01                  , pde-loss 5.6539e+03, initc-loss 1.2928e+04                    bc_loss 1.3272e+03\n",
      "Epoch 19470, Training-Loss 2.5568e+00, Data-loss 5.8858e-01                  , pde-loss 5.1771e+03, initc-loss 1.2937e+04                    bc_loss 1.5681e+03\n",
      "Epoch 19480, Training-Loss 2.2832e+00, Data-loss 4.1410e-01                  , pde-loss 5.5676e+03, initc-loss 1.2881e+04                    bc_loss 2.4201e+02\n",
      "Epoch 19490, Training-Loss 2.7323e+00, Data-loss 5.5126e-01                  , pde-loss 5.3723e+03, initc-loss 1.2851e+04                    bc_loss 3.5866e+03\n",
      "Epoch 19500, Training-Loss 2.4028e+00, Data-loss 4.7689e-01                  , pde-loss 5.9385e+03, initc-loss 1.2909e+04                    bc_loss 4.1186e+02\n",
      "Epoch 19510, Training-Loss 2.3484e+00, Data-loss 4.4779e-01                  , pde-loss 5.7630e+03, initc-loss 1.2926e+04                    bc_loss 3.1768e+02\n",
      "Epoch 19520, Training-Loss 2.5870e+00, Data-loss 6.3771e-01                  , pde-loss 5.9250e+03, initc-loss 1.2806e+04                    bc_loss 7.6208e+02\n",
      "Epoch 19530, Training-Loss 2.3143e+00, Data-loss 3.6252e-01                  , pde-loss 6.2607e+03, initc-loss 1.2836e+04                    bc_loss 4.2075e+02\n",
      "Epoch 19540, Training-Loss 2.6103e+00, Data-loss 6.2981e-01                  , pde-loss 6.5606e+03, initc-loss 1.2886e+04                    bc_loss 3.5751e+02\n",
      "Epoch 19550, Training-Loss 2.5084e+00, Data-loss 6.0525e-01                  , pde-loss 5.8680e+03, initc-loss 1.2805e+04                    bc_loss 3.5850e+02\n",
      "Epoch 19560, Training-Loss 2.5144e+00, Data-loss 5.6596e-01                  , pde-loss 5.8124e+03, initc-loss 1.2801e+04                    bc_loss 8.7114e+02\n",
      "Epoch 19570, Training-Loss 2.6982e+00, Data-loss 5.9434e-01                  , pde-loss 5.4860e+03, initc-loss 1.2937e+04                    bc_loss 2.6157e+03\n",
      "Epoch 19580, Training-Loss 2.3562e+00, Data-loss 4.6028e-01                  , pde-loss 5.4178e+03, initc-loss 1.2855e+04                    bc_loss 6.8625e+02\n",
      "Epoch 19590, Training-Loss 2.3337e+00, Data-loss 4.2460e-01                  , pde-loss 5.9054e+03, initc-loss 1.2873e+04                    bc_loss 3.1248e+02\n",
      "Epoch 19600, Training-Loss 2.2619e+00, Data-loss 4.1331e-01                  , pde-loss 5.1457e+03, initc-loss 1.2861e+04                    bc_loss 4.7930e+02\n",
      "Epoch 19610, Training-Loss 2.4665e+00, Data-loss 5.1878e-01                  , pde-loss 6.4191e+03, initc-loss 1.2946e+04                    bc_loss 1.1238e+02\n",
      "Epoch 19620, Training-Loss 2.5948e+00, Data-loss 6.2573e-01                  , pde-loss 6.0332e+03, initc-loss 1.2958e+04                    bc_loss 7.0016e+02\n",
      "Epoch 19630, Training-Loss 2.5456e+00, Data-loss 4.8895e-01                  , pde-loss 5.8473e+03, initc-loss 1.2918e+04                    bc_loss 1.8010e+03\n",
      "Epoch 19640, Training-Loss 2.6511e+00, Data-loss 6.9304e-01                  , pde-loss 6.2044e+03, initc-loss 1.2806e+04                    bc_loss 5.6968e+02\n",
      "Epoch 19650, Training-Loss 2.3889e+00, Data-loss 4.9487e-01                  , pde-loss 5.5077e+03, initc-loss 1.2912e+04                    bc_loss 5.2029e+02\n",
      "Epoch 19660, Training-Loss 2.3936e+00, Data-loss 4.8617e-01                  , pde-loss 6.0008e+03, initc-loss 1.2837e+04                    bc_loss 2.3626e+02\n",
      "Epoch 19670, Training-Loss 2.5240e+00, Data-loss 5.4451e-01                  , pde-loss 6.6988e+03, initc-loss 1.2914e+04                    bc_loss 1.8196e+02\n",
      "Epoch 19680, Training-Loss 2.4009e+00, Data-loss 5.2479e-01                  , pde-loss 5.3671e+03, initc-loss 1.2914e+04                    bc_loss 4.8040e+02\n",
      "Epoch 19690, Training-Loss 2.7113e+00, Data-loss 8.0189e-01                  , pde-loss 6.0076e+03, initc-loss 1.2784e+04                    bc_loss 3.0330e+02\n",
      "Epoch 19700, Training-Loss 2.9083e+00, Data-loss 9.3123e-01                  , pde-loss 5.5511e+03, initc-loss 1.2798e+04                    bc_loss 1.4215e+03\n",
      "Epoch 19710, Training-Loss 2.5800e+00, Data-loss 5.9098e-01                  , pde-loss 6.7376e+03, initc-loss 1.2899e+04                    bc_loss 2.5388e+02\n",
      "Epoch 19720, Training-Loss 2.4298e+00, Data-loss 4.7329e-01                  , pde-loss 5.7384e+03, initc-loss 1.2950e+04                    bc_loss 8.7657e+02\n",
      "Epoch 19730, Training-Loss 2.3236e+00, Data-loss 3.6786e-01                  , pde-loss 6.3471e+03, initc-loss 1.2907e+04                    bc_loss 3.0380e+02\n",
      "Epoch 19740, Training-Loss 2.5225e+00, Data-loss 5.6319e-01                  , pde-loss 5.3773e+03, initc-loss 1.2852e+04                    bc_loss 1.3632e+03\n",
      "Epoch 19750, Training-Loss 2.5549e+00, Data-loss 4.8355e-01                  , pde-loss 6.9213e+03, initc-loss 1.2863e+04                    bc_loss 9.2916e+02\n",
      "Epoch 19760, Training-Loss 2.4747e+00, Data-loss 5.2022e-01                  , pde-loss 6.1173e+03, initc-loss 1.2817e+04                    bc_loss 6.1037e+02\n",
      "Epoch 19770, Training-Loss 2.2914e+00, Data-loss 4.0884e-01                  , pde-loss 5.8602e+03, initc-loss 1.2788e+04                    bc_loss 1.7684e+02\n",
      "Epoch 19780, Training-Loss 2.3629e+00, Data-loss 4.8157e-01                  , pde-loss 5.6271e+03, initc-loss 1.2943e+04                    bc_loss 2.4295e+02\n",
      "Epoch 19790, Training-Loss 2.3798e+00, Data-loss 4.9015e-01                  , pde-loss 5.5394e+03, initc-loss 1.2873e+04                    bc_loss 4.8357e+02\n",
      "Epoch 19800, Training-Loss 2.4071e+00, Data-loss 4.6168e-01                  , pde-loss 5.4809e+03, initc-loss 1.2870e+04                    bc_loss 1.1039e+03\n",
      "Epoch 19810, Training-Loss 2.3024e+00, Data-loss 3.6589e-01                  , pde-loss 6.4104e+03, initc-loss 1.2853e+04                    bc_loss 1.0260e+02\n",
      "Epoch 19820, Training-Loss 2.3706e+00, Data-loss 4.9452e-01                  , pde-loss 5.3019e+03, initc-loss 1.2868e+04                    bc_loss 5.9040e+02\n",
      "Epoch 19830, Training-Loss 2.7418e+00, Data-loss 7.2377e-01                  , pde-loss 5.7685e+03, initc-loss 1.2987e+04                    bc_loss 1.4245e+03\n",
      "Epoch 19840, Training-Loss 2.5526e+00, Data-loss 5.5702e-01                  , pde-loss 6.6648e+03, initc-loss 1.2868e+04                    bc_loss 4.2272e+02\n",
      "Epoch 19850, Training-Loss 2.5222e+00, Data-loss 5.9867e-01                  , pde-loss 5.6342e+03, initc-loss 1.2732e+04                    bc_loss 8.6868e+02\n",
      "Epoch 19860, Training-Loss 2.2567e+00, Data-loss 4.0177e-01                  , pde-loss 5.3098e+03, initc-loss 1.2888e+04                    bc_loss 3.5152e+02\n",
      "Epoch 19870, Training-Loss 2.3219e+00, Data-loss 4.5043e-01                  , pde-loss 5.5920e+03, initc-loss 1.2839e+04                    bc_loss 2.8325e+02\n",
      "Epoch 19880, Training-Loss 2.3971e+00, Data-loss 4.1687e-01                  , pde-loss 6.3740e+03, initc-loss 1.2915e+04                    bc_loss 5.1306e+02\n",
      "Epoch 19890, Training-Loss 2.4658e+00, Data-loss 5.8058e-01                  , pde-loss 5.3151e+03, initc-loss 1.2902e+04                    bc_loss 6.3526e+02\n",
      "Epoch 19900, Training-Loss 2.5419e+00, Data-loss 5.1721e-01                  , pde-loss 6.6474e+03, initc-loss 1.2953e+04                    bc_loss 6.4646e+02\n",
      "Epoch 19910, Training-Loss 2.2663e+00, Data-loss 3.7864e-01                  , pde-loss 5.8305e+03, initc-loss 1.2855e+04                    bc_loss 1.9093e+02\n",
      "Epoch 19920, Training-Loss 2.5269e+00, Data-loss 5.5116e-01                  , pde-loss 5.9486e+03, initc-loss 1.2986e+04                    bc_loss 8.2226e+02\n",
      "Epoch 19930, Training-Loss 2.6169e+00, Data-loss 6.1302e-01                  , pde-loss 6.2539e+03, initc-loss 1.2969e+04                    bc_loss 8.1614e+02\n",
      "Epoch 19940, Training-Loss 2.4576e+00, Data-loss 4.4721e-01                  , pde-loss 6.8033e+03, initc-loss 1.2877e+04                    bc_loss 4.2416e+02\n",
      "Epoch 19950, Training-Loss 2.3508e+00, Data-loss 4.2150e-01                  , pde-loss 6.0782e+03, initc-loss 1.2770e+04                    bc_loss 4.4500e+02\n",
      "Epoch 19960, Training-Loss 2.3677e+00, Data-loss 4.2890e-01                  , pde-loss 5.7661e+03, initc-loss 1.2914e+04                    bc_loss 7.0832e+02\n",
      "Epoch 19970, Training-Loss 2.3907e+00, Data-loss 4.8657e-01                  , pde-loss 5.6923e+03, initc-loss 1.2887e+04                    bc_loss 4.6142e+02\n",
      "Epoch 19980, Training-Loss 2.5467e+00, Data-loss 6.8484e-01                  , pde-loss 5.1452e+03, initc-loss 1.2869e+04                    bc_loss 6.0412e+02\n",
      "Epoch 19990, Training-Loss 2.5382e+00, Data-loss 5.8908e-01                  , pde-loss 6.3566e+03, initc-loss 1.2868e+04                    bc_loss 2.6676e+02\n",
      "Epoch 20000, Training-Loss 2.8005e+00, Data-loss 8.6692e-01                  , pde-loss 6.0945e+03, initc-loss 1.2975e+04                    bc_loss 2.6581e+02\n",
      "Epoch 20010, Training-Loss 2.4335e+00, Data-loss 5.2235e-01                  , pde-loss 5.4983e+03, initc-loss 1.2907e+04                    bc_loss 7.0667e+02\n",
      "Epoch 20020, Training-Loss 2.3671e+00, Data-loss 4.9003e-01                  , pde-loss 5.5104e+03, initc-loss 1.2918e+04                    bc_loss 3.4246e+02\n",
      "Epoch 20030, Training-Loss 2.8101e+00, Data-loss 6.5357e-01                  , pde-loss 5.7130e+03, initc-loss 1.2840e+04                    bc_loss 3.0121e+03\n",
      "Epoch 20040, Training-Loss 2.4048e+00, Data-loss 4.3774e-01                  , pde-loss 6.4026e+03, initc-loss 1.2930e+04                    bc_loss 3.3794e+02\n",
      "Epoch 20050, Training-Loss 2.5523e+00, Data-loss 5.8311e-01                  , pde-loss 6.3833e+03, initc-loss 1.2970e+04                    bc_loss 3.3846e+02\n",
      "Epoch 20060, Training-Loss 2.4782e+00, Data-loss 4.9154e-01                  , pde-loss 5.3874e+03, initc-loss 1.2838e+04                    bc_loss 1.6409e+03\n",
      "Epoch 20070, Training-Loss 2.3734e+00, Data-loss 3.3413e-01                  , pde-loss 5.9686e+03, initc-loss 1.2925e+04                    bc_loss 1.4992e+03\n",
      "Epoch 20080, Training-Loss 2.5021e+00, Data-loss 6.0742e-01                  , pde-loss 5.8389e+03, initc-loss 1.2837e+04                    bc_loss 2.7079e+02\n",
      "Epoch 20090, Training-Loss 2.4530e+00, Data-loss 5.9951e-01                  , pde-loss 5.2909e+03, initc-loss 1.2866e+04                    bc_loss 3.7740e+02\n",
      "Epoch 20100, Training-Loss 2.5688e+00, Data-loss 5.6978e-01                  , pde-loss 5.7189e+03, initc-loss 1.2937e+04                    bc_loss 1.3336e+03\n",
      "Epoch 20110, Training-Loss 2.4296e+00, Data-loss 5.5889e-01                  , pde-loss 5.3904e+03, initc-loss 1.2938e+04                    bc_loss 3.7863e+02\n",
      "Epoch 20120, Training-Loss 2.5420e+00, Data-loss 5.5880e-01                  , pde-loss 5.9337e+03, initc-loss 1.2984e+04                    bc_loss 9.1412e+02\n",
      "Epoch 20130, Training-Loss 2.4383e+00, Data-loss 5.4968e-01                  , pde-loss 5.8434e+03, initc-loss 1.2802e+04                    bc_loss 2.4118e+02\n",
      "Epoch 20140, Training-Loss 2.3398e+00, Data-loss 4.8348e-01                  , pde-loss 5.2033e+03, initc-loss 1.2923e+04                    bc_loss 4.3657e+02\n",
      "Epoch 20150, Training-Loss 2.3169e+00, Data-loss 4.0093e-01                  , pde-loss 5.9614e+03, initc-loss 1.2931e+04                    bc_loss 2.6755e+02\n",
      "Epoch 20160, Training-Loss 3.0689e+00, Data-loss 9.6496e-01                  , pde-loss 5.6695e+03, initc-loss 1.2773e+04                    bc_loss 2.5966e+03\n",
      "Epoch 20170, Training-Loss 2.4895e+00, Data-loss 5.8271e-01                  , pde-loss 6.0101e+03, initc-loss 1.2836e+04                    bc_loss 2.2177e+02\n",
      "Epoch 20180, Training-Loss 2.3365e+00, Data-loss 4.8636e-01                  , pde-loss 5.0928e+03, initc-loss 1.2997e+04                    bc_loss 4.1130e+02\n",
      "Epoch 20190, Training-Loss 2.5222e+00, Data-loss 5.6328e-01                  , pde-loss 6.2685e+03, initc-loss 1.2985e+04                    bc_loss 3.3543e+02\n",
      "Epoch 20200, Training-Loss 2.4060e+00, Data-loss 4.2601e-01                  , pde-loss 6.2028e+03, initc-loss 1.2920e+04                    bc_loss 6.7716e+02\n",
      "Epoch 20210, Training-Loss 2.3805e+00, Data-loss 4.3085e-01                  , pde-loss 5.6358e+03, initc-loss 1.2854e+04                    bc_loss 1.0068e+03\n",
      "Epoch 20220, Training-Loss 2.3700e+00, Data-loss 5.2759e-01                  , pde-loss 5.1509e+03, initc-loss 1.2780e+04                    bc_loss 4.9320e+02\n",
      "Epoch 20230, Training-Loss 2.6080e+00, Data-loss 5.5726e-01                  , pde-loss 5.5835e+03, initc-loss 1.2875e+04                    bc_loss 2.0494e+03\n",
      "Epoch 20240, Training-Loss 2.4776e+00, Data-loss 5.6377e-01                  , pde-loss 5.5119e+03, initc-loss 1.2867e+04                    bc_loss 7.5950e+02\n",
      "Epoch 20250, Training-Loss 2.0946e+00, Data-loss 3.4245e-01                  , pde-loss 4.3700e+03, initc-loss 1.2948e+04                    bc_loss 2.0317e+02\n",
      "Epoch 20260, Training-Loss 2.2946e+00, Data-loss 4.1599e-01                  , pde-loss 5.5070e+03, initc-loss 1.3012e+04                    bc_loss 2.6737e+02\n",
      "Epoch 20270, Training-Loss 2.4017e+00, Data-loss 4.8312e-01                  , pde-loss 5.7845e+03, initc-loss 1.2897e+04                    bc_loss 5.0380e+02\n",
      "Epoch 20280, Training-Loss 2.5476e+00, Data-loss 4.9330e-01                  , pde-loss 5.6468e+03, initc-loss 1.2932e+04                    bc_loss 1.9641e+03\n",
      "Epoch 20290, Training-Loss 2.7697e+00, Data-loss 6.6538e-01                  , pde-loss 6.2531e+03, initc-loss 1.2970e+04                    bc_loss 1.8200e+03\n",
      "Epoch 20300, Training-Loss 3.2147e+00, Data-loss 7.2013e-01                  , pde-loss 6.8783e+03, initc-loss 1.2971e+04                    bc_loss 5.0969e+03\n",
      "Epoch 20310, Training-Loss 2.4556e+00, Data-loss 4.9524e-01                  , pde-loss 6.3343e+03, initc-loss 1.2969e+04                    bc_loss 2.9958e+02\n",
      "Epoch 20320, Training-Loss 2.4891e+00, Data-loss 5.3598e-01                  , pde-loss 5.9363e+03, initc-loss 1.2922e+04                    bc_loss 6.7252e+02\n",
      "Epoch 20330, Training-Loss 2.4521e+00, Data-loss 5.2929e-01                  , pde-loss 5.7957e+03, initc-loss 1.2951e+04                    bc_loss 4.8113e+02\n",
      "Epoch 20340, Training-Loss 2.6640e+00, Data-loss 6.8005e-01                  , pde-loss 6.1837e+03, initc-loss 1.2938e+04                    bc_loss 7.1779e+02\n",
      "Epoch 20350, Training-Loss 2.4404e+00, Data-loss 4.4619e-01                  , pde-loss 6.2563e+03, initc-loss 1.2901e+04                    bc_loss 7.8537e+02\n",
      "Epoch 20360, Training-Loss 2.4805e+00, Data-loss 5.4136e-01                  , pde-loss 5.4300e+03, initc-loss 1.2925e+04                    bc_loss 1.0365e+03\n",
      "Epoch 20370, Training-Loss 2.3735e+00, Data-loss 4.4941e-01                  , pde-loss 6.0230e+03, initc-loss 1.2845e+04                    bc_loss 3.7276e+02\n",
      "Epoch 20380, Training-Loss 2.2630e+00, Data-loss 3.7507e-01                  , pde-loss 5.7305e+03, initc-loss 1.2909e+04                    bc_loss 2.3926e+02\n",
      "Epoch 20390, Training-Loss 2.2784e+00, Data-loss 4.5276e-01                  , pde-loss 5.0660e+03, initc-loss 1.2853e+04                    bc_loss 3.3660e+02\n",
      "Epoch 20400, Training-Loss 3.1551e+00, Data-loss 9.4060e-01                  , pde-loss 5.9475e+03, initc-loss 1.3068e+04                    bc_loss 3.1288e+03\n",
      "Epoch 20410, Training-Loss 2.5672e+00, Data-loss 6.4521e-01                  , pde-loss 5.5391e+03, initc-loss 1.2940e+04                    bc_loss 7.4070e+02\n",
      "Epoch 20420, Training-Loss 2.4849e+00, Data-loss 4.6016e-01                  , pde-loss 6.5461e+03, initc-loss 1.2896e+04                    bc_loss 8.0483e+02\n",
      "Epoch 20430, Training-Loss 2.4231e+00, Data-loss 3.3337e-01                  , pde-loss 5.8683e+03, initc-loss 1.2915e+04                    bc_loss 2.1135e+03\n",
      "Epoch 20440, Training-Loss 2.4447e+00, Data-loss 4.9699e-01                  , pde-loss 5.8643e+03, initc-loss 1.2951e+04                    bc_loss 6.6178e+02\n",
      "Epoch 20450, Training-Loss 2.4219e+00, Data-loss 5.4807e-01                  , pde-loss 5.3978e+03, initc-loss 1.2929e+04                    bc_loss 4.1143e+02\n",
      "Epoch 20460, Training-Loss 2.5611e+00, Data-loss 6.0891e-01                  , pde-loss 6.3461e+03, initc-loss 1.2863e+04                    bc_loss 3.1330e+02\n",
      "Epoch 20470, Training-Loss 2.8886e+00, Data-loss 6.8452e-01                  , pde-loss 6.1430e+03, initc-loss 1.2935e+04                    bc_loss 2.9630e+03\n",
      "Epoch 20480, Training-Loss 2.4887e+00, Data-loss 5.0810e-01                  , pde-loss 5.6756e+03, initc-loss 1.2913e+04                    bc_loss 1.2177e+03\n",
      "Epoch 20490, Training-Loss 2.4212e+00, Data-loss 4.1299e-01                  , pde-loss 6.2318e+03, initc-loss 1.2974e+04                    bc_loss 8.7660e+02\n",
      "Epoch 20500, Training-Loss 2.3800e+00, Data-loss 5.4083e-01                  , pde-loss 4.4266e+03, initc-loss 1.2840e+04                    bc_loss 1.1253e+03\n",
      "Epoch 20510, Training-Loss 2.4106e+00, Data-loss 3.8695e-01                  , pde-loss 5.9590e+03, initc-loss 1.2957e+04                    bc_loss 1.3207e+03\n",
      "Epoch 20520, Training-Loss 2.4051e+00, Data-loss 4.0822e-01                  , pde-loss 6.3937e+03, initc-loss 1.2920e+04                    bc_loss 6.5516e+02\n",
      "Epoch 20530, Training-Loss 2.3364e+00, Data-loss 4.9014e-01                  , pde-loss 5.2632e+03, initc-loss 1.2939e+04                    bc_loss 2.6079e+02\n",
      "Epoch 20540, Training-Loss 2.6311e+00, Data-loss 6.9115e-01                  , pde-loss 6.0984e+03, initc-loss 1.2954e+04                    bc_loss 3.4664e+02\n",
      "Epoch 20550, Training-Loss 3.1911e+00, Data-loss 1.0379e+00                  , pde-loss 5.7615e+03, initc-loss 1.3049e+04                    bc_loss 2.7210e+03\n",
      "Epoch 20560, Training-Loss 2.2664e+00, Data-loss 3.3146e-01                  , pde-loss 5.8852e+03, initc-loss 1.2866e+04                    bc_loss 5.9797e+02\n",
      "Epoch 20570, Training-Loss 2.8029e+00, Data-loss 6.7337e-01                  , pde-loss 6.4029e+03, initc-loss 1.3014e+04                    bc_loss 1.8785e+03\n",
      "Epoch 20580, Training-Loss 2.3796e+00, Data-loss 4.7276e-01                  , pde-loss 5.9105e+03, initc-loss 1.2932e+04                    bc_loss 2.2564e+02\n",
      "Epoch 20590, Training-Loss 2.2797e+00, Data-loss 3.7759e-01                  , pde-loss 5.9174e+03, initc-loss 1.2866e+04                    bc_loss 2.3721e+02\n",
      "Epoch 20600, Training-Loss 2.8758e+00, Data-loss 8.3887e-01                  , pde-loss 6.0905e+03, initc-loss 1.2818e+04                    bc_loss 1.4602e+03\n",
      "Epoch 20610, Training-Loss 2.4268e+00, Data-loss 5.2023e-01                  , pde-loss 5.9825e+03, initc-loss 1.2871e+04                    bc_loss 2.1212e+02\n",
      "Epoch 20620, Training-Loss 2.2889e+00, Data-loss 3.6897e-01                  , pde-loss 6.0642e+03, initc-loss 1.2950e+04                    bc_loss 1.8477e+02\n",
      "Epoch 20630, Training-Loss 2.3472e+00, Data-loss 4.3166e-01                  , pde-loss 6.2366e+03, initc-loss 1.2843e+04                    bc_loss 7.6039e+01\n",
      "Epoch 20640, Training-Loss 2.4390e+00, Data-loss 4.6395e-01                  , pde-loss 6.3498e+03, initc-loss 1.2871e+04                    bc_loss 5.2967e+02\n",
      "Epoch 20650, Training-Loss 3.1274e+00, Data-loss 8.7844e-01                  , pde-loss 5.6430e+03, initc-loss 1.2994e+04                    bc_loss 3.8529e+03\n",
      "Epoch 20660, Training-Loss 2.5000e+00, Data-loss 6.0707e-01                  , pde-loss 5.8831e+03, initc-loss 1.2862e+04                    bc_loss 1.8428e+02\n",
      "Epoch 20670, Training-Loss 2.5121e+00, Data-loss 5.9369e-01                  , pde-loss 5.5950e+03, initc-loss 1.2805e+04                    bc_loss 7.8334e+02\n",
      "Epoch 20680, Training-Loss 2.5293e+00, Data-loss 5.8331e-01                  , pde-loss 5.8931e+03, initc-loss 1.3014e+04                    bc_loss 5.5293e+02\n",
      "Epoch 20690, Training-Loss 2.4079e+00, Data-loss 4.6038e-01                  , pde-loss 6.0985e+03, initc-loss 1.2956e+04                    bc_loss 4.2070e+02\n",
      "Epoch 20700, Training-Loss 2.7567e+00, Data-loss 6.2647e-01                  , pde-loss 6.2944e+03, initc-loss 1.2836e+04                    bc_loss 2.1720e+03\n",
      "Epoch 20710, Training-Loss 2.5695e+00, Data-loss 6.3461e-01                  , pde-loss 6.2868e+03, initc-loss 1.2866e+04                    bc_loss 1.9567e+02\n",
      "Epoch 20720, Training-Loss 2.4728e+00, Data-loss 5.5899e-01                  , pde-loss 5.2511e+03, initc-loss 1.2952e+04                    bc_loss 9.3571e+02\n",
      "Epoch 20730, Training-Loss 2.4970e+00, Data-loss 5.4259e-01                  , pde-loss 6.3550e+03, initc-loss 1.2869e+04                    bc_loss 3.1982e+02\n",
      "Epoch 20740, Training-Loss 2.4881e+00, Data-loss 4.1539e-01                  , pde-loss 6.8370e+03, initc-loss 1.2831e+04                    bc_loss 1.0597e+03\n",
      "Epoch 20750, Training-Loss 2.5214e+00, Data-loss 6.1213e-01                  , pde-loss 5.8428e+03, initc-loss 1.2950e+04                    bc_loss 2.9985e+02\n",
      "Epoch 20760, Training-Loss 2.4673e+00, Data-loss 5.7297e-01                  , pde-loss 5.9639e+03, initc-loss 1.2860e+04                    bc_loss 1.1948e+02\n",
      "Epoch 20770, Training-Loss 2.5200e+00, Data-loss 5.6798e-01                  , pde-loss 6.0063e+03, initc-loss 1.2870e+04                    bc_loss 6.4342e+02\n",
      "Epoch 20780, Training-Loss 2.4855e+00, Data-loss 5.3553e-01                  , pde-loss 6.2540e+03, initc-loss 1.2995e+04                    bc_loss 2.5092e+02\n",
      "Epoch 20790, Training-Loss 2.9983e+00, Data-loss 8.1580e-01                  , pde-loss 5.1920e+03, initc-loss 1.2804e+04                    bc_loss 3.8286e+03\n",
      "Epoch 20800, Training-Loss 2.3547e+00, Data-loss 4.5412e-01                  , pde-loss 5.7509e+03, initc-loss 1.2900e+04                    bc_loss 3.5509e+02\n",
      "Epoch 20810, Training-Loss 2.4027e+00, Data-loss 4.3530e-01                  , pde-loss 6.1681e+03, initc-loss 1.2876e+04                    bc_loss 6.3004e+02\n",
      "Epoch 20820, Training-Loss 2.6049e+00, Data-loss 5.5073e-01                  , pde-loss 6.5623e+03, initc-loss 1.2796e+04                    bc_loss 1.1827e+03\n",
      "Epoch 20830, Training-Loss 2.3374e+00, Data-loss 5.0930e-01                  , pde-loss 5.1379e+03, initc-loss 1.2873e+04                    bc_loss 2.7023e+02\n",
      "Epoch 20840, Training-Loss 3.0103e+00, Data-loss 7.4456e-01                  , pde-loss 5.5843e+03, initc-loss 1.3011e+04                    bc_loss 4.0620e+03\n",
      "Epoch 20850, Training-Loss 2.3408e+00, Data-loss 4.1461e-01                  , pde-loss 5.5491e+03, initc-loss 1.2835e+04                    bc_loss 8.7816e+02\n",
      "Epoch 20860, Training-Loss 2.6022e+00, Data-loss 6.9572e-01                  , pde-loss 5.6180e+03, initc-loss 1.2781e+04                    bc_loss 6.6581e+02\n",
      "Epoch 20870, Training-Loss 2.9529e+00, Data-loss 8.8964e-01                  , pde-loss 6.9174e+03, initc-loss 1.2999e+04                    bc_loss 7.1573e+02\n",
      "Epoch 20880, Training-Loss 2.3820e+00, Data-loss 5.0975e-01                  , pde-loss 5.5422e+03, initc-loss 1.2958e+04                    bc_loss 2.2213e+02\n",
      "Epoch 20890, Training-Loss 2.4188e+00, Data-loss 4.8200e-01                  , pde-loss 5.9914e+03, initc-loss 1.2853e+04                    bc_loss 5.2407e+02\n",
      "Epoch 20900, Training-Loss 2.2740e+00, Data-loss 3.8886e-01                  , pde-loss 5.7629e+03, initc-loss 1.2889e+04                    bc_loss 1.9942e+02\n",
      "Epoch 20910, Training-Loss 2.4246e+00, Data-loss 5.1478e-01                  , pde-loss 6.0468e+03, initc-loss 1.2873e+04                    bc_loss 1.7804e+02\n",
      "Epoch 20920, Training-Loss 2.3782e+00, Data-loss 4.2820e-01                  , pde-loss 5.7927e+03, initc-loss 1.2901e+04                    bc_loss 8.0619e+02\n",
      "Epoch 20930, Training-Loss 2.3394e+00, Data-loss 4.4494e-01                  , pde-loss 5.7921e+03, initc-loss 1.2922e+04                    bc_loss 2.3035e+02\n",
      "Epoch 20940, Training-Loss 2.4710e+00, Data-loss 5.2741e-01                  , pde-loss 5.7339e+03, initc-loss 1.2830e+04                    bc_loss 8.7249e+02\n",
      "Epoch 20950, Training-Loss 2.4371e+00, Data-loss 5.0312e-01                  , pde-loss 6.1837e+03, initc-loss 1.2846e+04                    bc_loss 3.1060e+02\n",
      "Epoch 20960, Training-Loss 2.3358e+00, Data-loss 3.8364e-01                  , pde-loss 5.9754e+03, initc-loss 1.2932e+04                    bc_loss 6.1403e+02\n",
      "Epoch 20970, Training-Loss 2.4927e+00, Data-loss 5.6428e-01                  , pde-loss 5.7494e+03, initc-loss 1.3005e+04                    bc_loss 5.2950e+02\n",
      "Epoch 20980, Training-Loss 2.3376e+00, Data-loss 3.6688e-01                  , pde-loss 5.9653e+03, initc-loss 1.2852e+04                    bc_loss 8.8976e+02\n",
      "Epoch 20990, Training-Loss 2.9723e+00, Data-loss 1.0322e+00                  , pde-loss 6.2953e+03, initc-loss 1.2739e+04                    bc_loss 3.6681e+02\n",
      "Epoch 21000, Training-Loss 2.3319e+00, Data-loss 5.2255e-01                  , pde-loss 4.9878e+03, initc-loss 1.2892e+04                    bc_loss 2.1419e+02\n",
      "Epoch 21010, Training-Loss 2.3955e+00, Data-loss 4.2405e-01                  , pde-loss 6.2855e+03, initc-loss 1.2862e+04                    bc_loss 5.6767e+02\n",
      "Epoch 21020, Training-Loss 2.2829e+00, Data-loss 4.7123e-01                  , pde-loss 5.1300e+03, initc-loss 1.2875e+04                    bc_loss 1.1186e+02\n",
      "Epoch 21030, Training-Loss 2.5769e+00, Data-loss 6.2967e-01                  , pde-loss 6.4665e+03, initc-loss 1.2811e+04                    bc_loss 1.9544e+02\n",
      "Epoch 21040, Training-Loss 2.2684e+00, Data-loss 3.6653e-01                  , pde-loss 5.6392e+03, initc-loss 1.2879e+04                    bc_loss 5.0010e+02\n",
      "Epoch 21050, Training-Loss 2.4909e+00, Data-loss 4.6962e-01                  , pde-loss 6.4668e+03, initc-loss 1.3002e+04                    bc_loss 7.4381e+02\n",
      "Epoch 21060, Training-Loss 2.3719e+00, Data-loss 3.7436e-01                  , pde-loss 6.8201e+03, initc-loss 1.2964e+04                    bc_loss 1.9137e+02\n",
      "Epoch 21070, Training-Loss 2.2671e+00, Data-loss 4.1129e-01                  , pde-loss 5.4576e+03, initc-loss 1.2867e+04                    bc_loss 2.3353e+02\n",
      "Epoch 21080, Training-Loss 2.6976e+00, Data-loss 7.0104e-01                  , pde-loss 6.2003e+03, initc-loss 1.2986e+04                    bc_loss 7.7985e+02\n",
      "Epoch 21090, Training-Loss 2.4782e+00, Data-loss 5.6518e-01                  , pde-loss 5.5078e+03, initc-loss 1.2905e+04                    bc_loss 7.1739e+02\n",
      "Epoch 21100, Training-Loss 2.3741e+00, Data-loss 4.2621e-01                  , pde-loss 6.3090e+03, initc-loss 1.2932e+04                    bc_loss 2.3793e+02\n",
      "Epoch 21110, Training-Loss 2.3819e+00, Data-loss 4.3611e-01                  , pde-loss 6.0989e+03, initc-loss 1.2872e+04                    bc_loss 4.8693e+02\n",
      "Epoch 21120, Training-Loss 2.4310e+00, Data-loss 4.6496e-01                  , pde-loss 6.4533e+03, initc-loss 1.2966e+04                    bc_loss 2.4186e+02\n",
      "Epoch 21130, Training-Loss 2.5391e+00, Data-loss 5.8315e-01                  , pde-loss 6.1368e+03, initc-loss 1.2947e+04                    bc_loss 4.7567e+02\n",
      "Epoch 21140, Training-Loss 2.3329e+00, Data-loss 4.6768e-01                  , pde-loss 4.8693e+03, initc-loss 1.2934e+04                    bc_loss 8.4832e+02\n",
      "Epoch 21150, Training-Loss 2.3295e+00, Data-loss 3.9963e-01                  , pde-loss 5.7165e+03, initc-loss 1.2944e+04                    bc_loss 6.3779e+02\n",
      "Epoch 21160, Training-Loss 2.6560e+00, Data-loss 7.2409e-01                  , pde-loss 5.6833e+03, initc-loss 1.2816e+04                    bc_loss 8.2035e+02\n",
      "Epoch 21170, Training-Loss 2.1644e+00, Data-loss 3.0405e-01                  , pde-loss 5.5059e+03, initc-loss 1.2958e+04                    bc_loss 1.3975e+02\n",
      "Epoch 21180, Training-Loss 2.4895e+00, Data-loss 4.8907e-01                  , pde-loss 6.3868e+03, initc-loss 1.2903e+04                    bc_loss 7.1427e+02\n",
      "Epoch 21190, Training-Loss 2.3311e+00, Data-loss 3.8362e-01                  , pde-loss 6.1832e+03, initc-loss 1.2927e+04                    bc_loss 3.6433e+02\n",
      "Epoch 21200, Training-Loss 2.4559e+00, Data-loss 4.7200e-01                  , pde-loss 6.2960e+03, initc-loss 1.2935e+04                    bc_loss 6.0831e+02\n",
      "Epoch 21210, Training-Loss 2.4344e+00, Data-loss 5.1333e-01                  , pde-loss 6.0979e+03, initc-loss 1.2911e+04                    bc_loss 2.0227e+02\n",
      "Epoch 21220, Training-Loss 2.5526e+00, Data-loss 5.6161e-01                  , pde-loss 6.3420e+03, initc-loss 1.2939e+04                    bc_loss 6.2865e+02\n",
      "Epoch 21230, Training-Loss 2.5173e+00, Data-loss 6.3375e-01                  , pde-loss 5.7142e+03, initc-loss 1.2859e+04                    bc_loss 2.6241e+02\n",
      "Epoch 21240, Training-Loss 2.3410e+00, Data-loss 4.4273e-01                  , pde-loss 5.8093e+03, initc-loss 1.2879e+04                    bc_loss 2.9503e+02\n",
      "Epoch 21250, Training-Loss 3.1854e+00, Data-loss 1.1638e+00                  , pde-loss 6.1276e+03, initc-loss 1.2994e+04                    bc_loss 1.0936e+03\n",
      "Epoch 21260, Training-Loss 2.3065e+00, Data-loss 3.9617e-01                  , pde-loss 5.5809e+03, initc-loss 1.2874e+04                    bc_loss 6.4854e+02\n",
      "Epoch 21270, Training-Loss 2.4434e+00, Data-loss 5.1169e-01                  , pde-loss 6.2124e+03, initc-loss 1.2839e+04                    bc_loss 2.6606e+02\n",
      "Epoch 21280, Training-Loss 2.4701e+00, Data-loss 4.6500e-01                  , pde-loss 5.3156e+03, initc-loss 1.2916e+04                    bc_loss 1.8191e+03\n",
      "Epoch 21290, Training-Loss 2.7350e+00, Data-loss 6.7652e-01                  , pde-loss 6.5375e+03, initc-loss 1.2986e+04                    bc_loss 1.0609e+03\n",
      "Epoch 21300, Training-Loss 2.4359e+00, Data-loss 6.1552e-01                  , pde-loss 4.7186e+03, initc-loss 1.3017e+04                    bc_loss 4.6868e+02\n",
      "Epoch 21310, Training-Loss 2.8937e+00, Data-loss 8.8214e-01                  , pde-loss 6.7885e+03, initc-loss 1.2986e+04                    bc_loss 3.4141e+02\n",
      "Epoch 21320, Training-Loss 2.9126e+00, Data-loss 7.0482e-01                  , pde-loss 5.8995e+03, initc-loss 1.2916e+04                    bc_loss 3.2622e+03\n",
      "Epoch 21330, Training-Loss 2.5387e+00, Data-loss 4.7637e-01                  , pde-loss 7.0878e+03, initc-loss 1.2906e+04                    bc_loss 6.2930e+02\n",
      "Epoch 21340, Training-Loss 3.0613e+00, Data-loss 8.8158e-01                  , pde-loss 5.9685e+03, initc-loss 1.2999e+04                    bc_loss 2.8297e+03\n",
      "Epoch 21350, Training-Loss 2.4044e+00, Data-loss 5.0157e-01                  , pde-loss 5.5640e+03, initc-loss 1.2910e+04                    bc_loss 5.5484e+02\n",
      "Epoch 21360, Training-Loss 2.3918e+00, Data-loss 4.5322e-01                  , pde-loss 6.2397e+03, initc-loss 1.2832e+04                    bc_loss 3.1456e+02\n",
      "Epoch 21370, Training-Loss 2.3480e+00, Data-loss 4.7234e-01                  , pde-loss 5.3159e+03, initc-loss 1.2912e+04                    bc_loss 5.2898e+02\n",
      "Epoch 21380, Training-Loss 2.5847e+00, Data-loss 5.9086e-01                  , pde-loss 6.2623e+03, initc-loss 1.2802e+04                    bc_loss 8.7394e+02\n",
      "Epoch 21390, Training-Loss 2.4328e+00, Data-loss 4.3688e-01                  , pde-loss 5.8688e+03, initc-loss 1.2956e+04                    bc_loss 1.1337e+03\n",
      "Epoch 21400, Training-Loss 2.5085e+00, Data-loss 5.4091e-01                  , pde-loss 5.9528e+03, initc-loss 1.2916e+04                    bc_loss 8.0688e+02\n",
      "Epoch 21410, Training-Loss 2.6766e+00, Data-loss 6.6786e-01                  , pde-loss 6.2852e+03, initc-loss 1.3040e+04                    bc_loss 7.6221e+02\n",
      "Epoch 21420, Training-Loss 2.4226e+00, Data-loss 4.7265e-01                  , pde-loss 5.9099e+03, initc-loss 1.2811e+04                    bc_loss 7.7876e+02\n",
      "Epoch 21430, Training-Loss 2.2044e+00, Data-loss 3.6747e-01                  , pde-loss 5.3286e+03, initc-loss 1.2839e+04                    bc_loss 2.0151e+02\n",
      "Epoch 21440, Training-Loss 2.6988e+00, Data-loss 6.6683e-01                  , pde-loss 6.1508e+03, initc-loss 1.3044e+04                    bc_loss 1.1243e+03\n",
      "Epoch 21450, Training-Loss 2.3278e+00, Data-loss 4.5004e-01                  , pde-loss 5.8513e+03, initc-loss 1.2851e+04                    bc_loss 7.6107e+01\n",
      "Epoch 21460, Training-Loss 2.3656e+00, Data-loss 4.9760e-01                  , pde-loss 5.1777e+03, initc-loss 1.2860e+04                    bc_loss 6.4231e+02\n",
      "Epoch 21470, Training-Loss 2.2607e+00, Data-loss 3.1825e-01                  , pde-loss 5.6442e+03, initc-loss 1.2887e+04                    bc_loss 8.9349e+02\n",
      "Epoch 21480, Training-Loss 2.9940e+00, Data-loss 8.5609e-01                  , pde-loss 5.9419e+03, initc-loss 1.2909e+04                    bc_loss 2.5280e+03\n",
      "Epoch 21490, Training-Loss 2.5630e+00, Data-loss 5.6464e-01                  , pde-loss 5.4277e+03, initc-loss 1.2857e+04                    bc_loss 1.6989e+03\n",
      "Epoch 21500, Training-Loss 2.3918e+00, Data-loss 4.0914e-01                  , pde-loss 6.7746e+03, initc-loss 1.2916e+04                    bc_loss 1.3686e+02\n",
      "Epoch 21510, Training-Loss 2.2748e+00, Data-loss 3.7646e-01                  , pde-loss 5.6725e+03, initc-loss 1.2928e+04                    bc_loss 3.8288e+02\n",
      "Epoch 21520, Training-Loss 2.3758e+00, Data-loss 4.8947e-01                  , pde-loss 5.6556e+03, initc-loss 1.2859e+04                    bc_loss 3.4791e+02\n",
      "Epoch 21530, Training-Loss 2.4027e+00, Data-loss 5.1024e-01                  , pde-loss 5.9314e+03, initc-loss 1.2885e+04                    bc_loss 1.0794e+02\n",
      "Epoch 21540, Training-Loss 2.3534e+00, Data-loss 3.7652e-01                  , pde-loss 5.3710e+03, initc-loss 1.2967e+04                    bc_loss 1.4307e+03\n",
      "Epoch 21550, Training-Loss 2.4993e+00, Data-loss 4.6101e-01                  , pde-loss 6.9647e+03, initc-loss 1.2874e+04                    bc_loss 5.4372e+02\n",
      "Epoch 21560, Training-Loss 2.4770e+00, Data-loss 5.6383e-01                  , pde-loss 5.7252e+03, initc-loss 1.2918e+04                    bc_loss 4.8887e+02\n",
      "Epoch 21570, Training-Loss 2.6347e+00, Data-loss 6.7764e-01                  , pde-loss 5.9491e+03, initc-loss 1.3020e+04                    bc_loss 6.0231e+02\n",
      "Epoch 21580, Training-Loss 2.4967e+00, Data-loss 5.7801e-01                  , pde-loss 5.8419e+03, initc-loss 1.2895e+04                    bc_loss 4.5043e+02\n",
      "Epoch 21590, Training-Loss 2.2728e+00, Data-loss 3.7640e-01                  , pde-loss 5.7402e+03, initc-loss 1.2857e+04                    bc_loss 3.6693e+02\n",
      "Epoch 21600, Training-Loss 2.2775e+00, Data-loss 4.3068e-01                  , pde-loss 5.4130e+03, initc-loss 1.2864e+04                    bc_loss 1.9025e+02\n",
      "Epoch 21610, Training-Loss 2.5954e+00, Data-loss 5.5295e-01                  , pde-loss 6.2959e+03, initc-loss 1.2895e+04                    bc_loss 1.2332e+03\n",
      "Epoch 21620, Training-Loss 2.8399e+00, Data-loss 5.0118e-01                  , pde-loss 6.6835e+03, initc-loss 1.2876e+04                    bc_loss 3.8279e+03\n",
      "Epoch 21630, Training-Loss 2.2713e+00, Data-loss 4.1836e-01                  , pde-loss 5.2892e+03, initc-loss 1.2856e+04                    bc_loss 3.8386e+02\n",
      "Epoch 21640, Training-Loss 2.3024e+00, Data-loss 4.1512e-01                  , pde-loss 5.7936e+03, initc-loss 1.2882e+04                    bc_loss 1.9646e+02\n",
      "Epoch 21650, Training-Loss 2.4083e+00, Data-loss 3.8554e-01                  , pde-loss 6.7096e+03, initc-loss 1.2933e+04                    bc_loss 5.8569e+02\n",
      "Epoch 21660, Training-Loss 2.2130e+00, Data-loss 4.1895e-01                  , pde-loss 4.9642e+03, initc-loss 1.2880e+04                    bc_loss 9.6812e+01\n",
      "Epoch 21670, Training-Loss 2.9100e+00, Data-loss 6.5558e-01                  , pde-loss 6.1137e+03, initc-loss 1.2781e+04                    bc_loss 3.6497e+03\n",
      "Epoch 21680, Training-Loss 2.3406e+00, Data-loss 4.0574e-01                  , pde-loss 6.1343e+03, initc-loss 1.3035e+04                    bc_loss 1.7921e+02\n",
      "Epoch 21690, Training-Loss 2.2925e+00, Data-loss 3.7017e-01                  , pde-loss 5.3156e+03, initc-loss 1.2983e+04                    bc_loss 9.2473e+02\n",
      "Epoch 21700, Training-Loss 2.8826e+00, Data-loss 7.1289e-01                  , pde-loss 7.4210e+03, initc-loss 1.2795e+04                    bc_loss 1.4808e+03\n",
      "Epoch 21710, Training-Loss 2.6557e+00, Data-loss 5.8015e-01                  , pde-loss 6.8830e+03, initc-loss 1.2809e+04                    bc_loss 1.0639e+03\n",
      "Epoch 21720, Training-Loss 2.3872e+00, Data-loss 5.4622e-01                  , pde-loss 5.0708e+03, initc-loss 1.2939e+04                    bc_loss 4.0033e+02\n",
      "Epoch 21730, Training-Loss 2.3280e+00, Data-loss 4.4469e-01                  , pde-loss 5.7147e+03, initc-loss 1.2887e+04                    bc_loss 2.3156e+02\n",
      "Epoch 21740, Training-Loss 2.3766e+00, Data-loss 4.3668e-01                  , pde-loss 5.7978e+03, initc-loss 1.2904e+04                    bc_loss 6.9731e+02\n",
      "Epoch 21750, Training-Loss 2.5273e+00, Data-loss 5.2769e-01                  , pde-loss 6.2089e+03, initc-loss 1.2963e+04                    bc_loss 8.2436e+02\n",
      "Epoch 21760, Training-Loss 2.4799e+00, Data-loss 6.3840e-01                  , pde-loss 5.4236e+03, initc-loss 1.2822e+04                    bc_loss 1.6927e+02\n",
      "Epoch 21770, Training-Loss 2.2886e+00, Data-loss 3.8486e-01                  , pde-loss 5.9378e+03, initc-loss 1.2885e+04                    bc_loss 2.1468e+02\n",
      "Epoch 21780, Training-Loss 2.6967e+00, Data-loss 5.5347e-01                  , pde-loss 6.1295e+03, initc-loss 1.2942e+04                    bc_loss 2.3611e+03\n",
      "Epoch 21790, Training-Loss 2.3860e+00, Data-loss 5.4040e-01                  , pde-loss 5.4993e+03, initc-loss 1.2855e+04                    bc_loss 1.0210e+02\n",
      "Epoch 21800, Training-Loss 2.2332e+00, Data-loss 4.1526e-01                  , pde-loss 4.9845e+03, initc-loss 1.2930e+04                    bc_loss 2.6397e+02\n",
      "Epoch 21810, Training-Loss 2.4419e+00, Data-loss 4.5578e-01                  , pde-loss 5.9296e+03, initc-loss 1.2894e+04                    bc_loss 1.0380e+03\n",
      "Epoch 21820, Training-Loss 2.2936e+00, Data-loss 4.5191e-01                  , pde-loss 4.7218e+03, initc-loss 1.2977e+04                    bc_loss 7.1772e+02\n",
      "Epoch 21830, Training-Loss 2.4674e+00, Data-loss 5.2639e-01                  , pde-loss 6.0322e+03, initc-loss 1.2863e+04                    bc_loss 5.1414e+02\n",
      "Epoch 21840, Training-Loss 2.2810e+00, Data-loss 4.0182e-01                  , pde-loss 5.7212e+03, initc-loss 1.2894e+04                    bc_loss 1.7628e+02\n",
      "Epoch 21850, Training-Loss 2.5733e+00, Data-loss 6.0777e-01                  , pde-loss 6.5418e+03, initc-loss 1.2854e+04                    bc_loss 2.5896e+02\n",
      "Epoch 21860, Training-Loss 2.3058e+00, Data-loss 4.1836e-01                  , pde-loss 5.6366e+03, initc-loss 1.2982e+04                    bc_loss 2.5598e+02\n",
      "Epoch 21870, Training-Loss 2.4068e+00, Data-loss 4.3667e-01                  , pde-loss 6.0582e+03, initc-loss 1.2952e+04                    bc_loss 6.9031e+02\n",
      "Epoch 21880, Training-Loss 2.6106e+00, Data-loss 7.3710e-01                  , pde-loss 5.4948e+03, initc-loss 1.2943e+04                    bc_loss 2.9717e+02\n",
      "Epoch 21890, Training-Loss 2.6822e+00, Data-loss 4.8477e-01                  , pde-loss 6.8372e+03, initc-loss 1.2889e+04                    bc_loss 2.2478e+03\n",
      "Epoch 21900, Training-Loss 2.3773e+00, Data-loss 4.5040e-01                  , pde-loss 5.6755e+03, initc-loss 1.2963e+04                    bc_loss 6.3064e+02\n",
      "Epoch 21910, Training-Loss 2.4769e+00, Data-loss 5.5547e-01                  , pde-loss 5.5983e+03, initc-loss 1.2989e+04                    bc_loss 6.2742e+02\n",
      "Epoch 21920, Training-Loss 2.4384e+00, Data-loss 5.3551e-01                  , pde-loss 6.0275e+03, initc-loss 1.2912e+04                    bc_loss 8.9104e+01\n",
      "Epoch 21930, Training-Loss 2.4167e+00, Data-loss 5.4548e-01                  , pde-loss 5.7169e+03, initc-loss 1.2821e+04                    bc_loss 1.7346e+02\n",
      "Epoch 21940, Training-Loss 2.3131e+00, Data-loss 4.2675e-01                  , pde-loss 5.2999e+03, initc-loss 1.2819e+04                    bc_loss 7.4519e+02\n",
      "Epoch 21950, Training-Loss 2.6755e+00, Data-loss 5.5538e-01                  , pde-loss 6.5099e+03, initc-loss 1.2882e+04                    bc_loss 1.8093e+03\n",
      "Epoch 21960, Training-Loss 2.4900e+00, Data-loss 6.8958e-01                  , pde-loss 4.7733e+03, initc-loss 1.2865e+04                    bc_loss 3.6647e+02\n",
      "Epoch 21970, Training-Loss 2.4210e+00, Data-loss 6.0749e-01                  , pde-loss 5.2018e+03, initc-loss 1.2782e+04                    bc_loss 1.5098e+02\n",
      "Epoch 21980, Training-Loss 2.5149e+00, Data-loss 6.1596e-01                  , pde-loss 6.0209e+03, initc-loss 1.2834e+04                    bc_loss 1.3475e+02\n",
      "Epoch 21990, Training-Loss 2.2097e+00, Data-loss 3.1712e-01                  , pde-loss 5.8586e+03, initc-loss 1.2939e+04                    bc_loss 1.2789e+02\n",
      "Epoch 22000, Training-Loss 2.2792e+00, Data-loss 4.1058e-01                  , pde-loss 5.5242e+03, initc-loss 1.2938e+04                    bc_loss 2.2357e+02\n",
      "Epoch 22010, Training-Loss 2.5386e+00, Data-loss 5.4216e-01                  , pde-loss 5.6922e+03, initc-loss 1.2828e+04                    bc_loss 1.4444e+03\n",
      "Epoch 22020, Training-Loss 2.6114e+00, Data-loss 6.5290e-01                  , pde-loss 6.1850e+03, initc-loss 1.3006e+04                    bc_loss 3.9360e+02\n",
      "Epoch 22030, Training-Loss 2.3944e+00, Data-loss 5.2108e-01                  , pde-loss 5.4151e+03, initc-loss 1.2950e+04                    bc_loss 3.6864e+02\n",
      "Epoch 22040, Training-Loss 2.3658e+00, Data-loss 4.9194e-01                  , pde-loss 5.4338e+03, initc-loss 1.2851e+04                    bc_loss 4.5366e+02\n",
      "Epoch 22050, Training-Loss 2.2851e+00, Data-loss 3.9484e-01                  , pde-loss 5.8193e+03, initc-loss 1.2928e+04                    bc_loss 1.5538e+02\n",
      "Epoch 22060, Training-Loss 2.3015e+00, Data-loss 4.2279e-01                  , pde-loss 5.6674e+03, initc-loss 1.2941e+04                    bc_loss 1.7798e+02\n",
      "Epoch 22070, Training-Loss 2.3491e+00, Data-loss 4.4151e-01                  , pde-loss 5.7898e+03, initc-loss 1.2876e+04                    bc_loss 4.0937e+02\n",
      "Epoch 22080, Training-Loss 2.3712e+00, Data-loss 4.2784e-01                  , pde-loss 5.9604e+03, initc-loss 1.2949e+04                    bc_loss 5.2474e+02\n",
      "Epoch 22090, Training-Loss 2.5428e+00, Data-loss 5.7837e-01                  , pde-loss 6.5312e+03, initc-loss 1.2902e+04                    bc_loss 2.1163e+02\n",
      "Epoch 22100, Training-Loss 2.5102e+00, Data-loss 6.2577e-01                  , pde-loss 4.9145e+03, initc-loss 1.2859e+04                    bc_loss 1.0713e+03\n",
      "Epoch 22110, Training-Loss 2.5081e+00, Data-loss 4.4919e-01                  , pde-loss 6.2575e+03, initc-loss 1.2794e+04                    bc_loss 1.5378e+03\n",
      "Epoch 22120, Training-Loss 2.5625e+00, Data-loss 6.4025e-01                  , pde-loss 5.5449e+03, initc-loss 1.2982e+04                    bc_loss 6.9616e+02\n",
      "Epoch 22130, Training-Loss 2.3965e+00, Data-loss 4.7064e-01                  , pde-loss 5.9018e+03, initc-loss 1.2941e+04                    bc_loss 4.1574e+02\n",
      "Epoch 22140, Training-Loss 2.6227e+00, Data-loss 6.8746e-01                  , pde-loss 5.0253e+03, initc-loss 1.2979e+04                    bc_loss 1.3477e+03\n",
      "Epoch 22150, Training-Loss 2.4299e+00, Data-loss 4.8916e-01                  , pde-loss 6.1006e+03, initc-loss 1.2886e+04                    bc_loss 4.2016e+02\n",
      "Epoch 22160, Training-Loss 2.9004e+00, Data-loss 8.2641e-01                  , pde-loss 6.7365e+03, initc-loss 1.2828e+04                    bc_loss 1.1748e+03\n",
      "Epoch 22170, Training-Loss 2.2593e+00, Data-loss 3.3517e-01                  , pde-loss 5.8059e+03, initc-loss 1.2975e+04                    bc_loss 4.6059e+02\n",
      "Epoch 22180, Training-Loss 2.3320e+00, Data-loss 3.9798e-01                  , pde-loss 5.2460e+03, initc-loss 1.2965e+04                    bc_loss 1.1291e+03\n",
      "Epoch 22190, Training-Loss 2.5334e+00, Data-loss 6.1584e-01                  , pde-loss 5.5188e+03, initc-loss 1.2872e+04                    bc_loss 7.8487e+02\n",
      "Epoch 22200, Training-Loss 2.3479e+00, Data-loss 4.6965e-01                  , pde-loss 5.3946e+03, initc-loss 1.2847e+04                    bc_loss 5.4101e+02\n",
      "Epoch 22210, Training-Loss 2.4370e+00, Data-loss 5.0409e-01                  , pde-loss 6.0506e+03, initc-loss 1.2924e+04                    bc_loss 3.5443e+02\n",
      "Epoch 22220, Training-Loss 2.6711e+00, Data-loss 7.1635e-01                  , pde-loss 6.2601e+03, initc-loss 1.3000e+04                    bc_loss 2.8783e+02\n",
      "Epoch 22230, Training-Loss 2.6065e+00, Data-loss 6.7899e-01                  , pde-loss 5.5058e+03, initc-loss 1.3040e+04                    bc_loss 7.2955e+02\n",
      "Epoch 22240, Training-Loss 2.4983e+00, Data-loss 7.0963e-01                  , pde-loss 4.6333e+03, initc-loss 1.3064e+04                    bc_loss 1.8952e+02\n",
      "Epoch 22250, Training-Loss 2.4921e+00, Data-loss 5.3873e-01                  , pde-loss 5.5977e+03, initc-loss 1.2862e+04                    bc_loss 1.0740e+03\n",
      "Epoch 22260, Training-Loss 2.4605e+00, Data-loss 5.3478e-01                  , pde-loss 5.9174e+03, initc-loss 1.2813e+04                    bc_loss 5.2615e+02\n",
      "Epoch 22270, Training-Loss 2.4513e+00, Data-loss 4.4437e-01                  , pde-loss 6.6938e+03, initc-loss 1.2770e+04                    bc_loss 6.0562e+02\n",
      "Epoch 22280, Training-Loss 2.4701e+00, Data-loss 3.5210e-01                  , pde-loss 5.6417e+03, initc-loss 1.2942e+04                    bc_loss 2.5965e+03\n",
      "Epoch 22290, Training-Loss 2.5668e+00, Data-loss 7.6167e-01                  , pde-loss 5.0664e+03, initc-loss 1.2725e+04                    bc_loss 2.6056e+02\n",
      "Epoch 22300, Training-Loss 2.3992e+00, Data-loss 5.0162e-01                  , pde-loss 5.6033e+03, initc-loss 1.2910e+04                    bc_loss 4.6223e+02\n",
      "Epoch 22310, Training-Loss 2.2748e+00, Data-loss 3.4900e-01                  , pde-loss 6.0393e+03, initc-loss 1.3002e+04                    bc_loss 2.1670e+02\n",
      "Epoch 22320, Training-Loss 2.4663e+00, Data-loss 5.1462e-01                  , pde-loss 6.5254e+03, initc-loss 1.2909e+04                    bc_loss 8.2811e+01\n",
      "Epoch 22330, Training-Loss 2.5570e+00, Data-loss 6.8017e-01                  , pde-loss 5.5729e+03, initc-loss 1.2887e+04                    bc_loss 3.0808e+02\n",
      "Epoch 22340, Training-Loss 2.3404e+00, Data-loss 3.8907e-01                  , pde-loss 6.1241e+03, initc-loss 1.3009e+04                    bc_loss 3.8036e+02\n",
      "Epoch 22350, Training-Loss 2.8591e+00, Data-loss 7.0674e-01                  , pde-loss 5.5662e+03, initc-loss 1.2770e+04                    bc_loss 3.1871e+03\n",
      "Epoch 22360, Training-Loss 2.4999e+00, Data-loss 5.0622e-01                  , pde-loss 6.5865e+03, initc-loss 1.2998e+04                    bc_loss 3.5270e+02\n",
      "Epoch 22370, Training-Loss 2.6024e+00, Data-loss 4.1740e-01                  , pde-loss 5.9251e+03, initc-loss 1.2979e+04                    bc_loss 2.9457e+03\n",
      "Epoch 22380, Training-Loss 2.4949e+00, Data-loss 6.3907e-01                  , pde-loss 5.2588e+03, initc-loss 1.2846e+04                    bc_loss 4.5405e+02\n",
      "Epoch 22390, Training-Loss 2.4580e+00, Data-loss 4.9604e-01                  , pde-loss 6.3719e+03, initc-loss 1.2873e+04                    bc_loss 3.7419e+02\n",
      "Epoch 22400, Training-Loss 2.5686e+00, Data-loss 6.4045e-01                  , pde-loss 5.8903e+03, initc-loss 1.2974e+04                    bc_loss 4.1679e+02\n",
      "Epoch 22410, Training-Loss 2.6329e+00, Data-loss 6.0273e-01                  , pde-loss 5.7590e+03, initc-loss 1.2822e+04                    bc_loss 1.7207e+03\n",
      "Epoch 22420, Training-Loss 2.9991e+00, Data-loss 9.1154e-01                  , pde-loss 5.5562e+03, initc-loss 1.2976e+04                    bc_loss 2.3437e+03\n",
      "Epoch 22430, Training-Loss 2.2360e+00, Data-loss 3.0654e-01                  , pde-loss 5.7074e+03, initc-loss 1.2931e+04                    bc_loss 6.5632e+02\n",
      "Epoch 22440, Training-Loss 2.4053e+00, Data-loss 4.8882e-01                  , pde-loss 6.0305e+03, initc-loss 1.2939e+04                    bc_loss 1.9555e+02\n",
      "Epoch 22450, Training-Loss 2.3582e+00, Data-loss 4.6928e-01                  , pde-loss 5.5550e+03, initc-loss 1.2906e+04                    bc_loss 4.2851e+02\n",
      "Epoch 22460, Training-Loss 2.5093e+00, Data-loss 5.0740e-01                  , pde-loss 6.7671e+03, initc-loss 1.2996e+04                    bc_loss 2.5572e+02\n",
      "Epoch 22470, Training-Loss 2.5092e+00, Data-loss 5.4719e-01                  , pde-loss 5.6734e+03, initc-loss 1.2836e+04                    bc_loss 1.1111e+03\n",
      "Epoch 22480, Training-Loss 2.4187e+00, Data-loss 3.9772e-01                  , pde-loss 6.8250e+03, initc-loss 1.2878e+04                    bc_loss 5.0660e+02\n",
      "Epoch 22490, Training-Loss 2.3032e+00, Data-loss 4.5047e-01                  , pde-loss 5.3308e+03, initc-loss 1.2889e+04                    bc_loss 3.0742e+02\n",
      "Epoch 22500, Training-Loss 2.1943e+00, Data-loss 3.4587e-01                  , pde-loss 5.4773e+03, initc-loss 1.2885e+04                    bc_loss 1.2181e+02\n",
      "Epoch 22510, Training-Loss 2.2454e+00, Data-loss 3.2224e-01                  , pde-loss 5.5924e+03, initc-loss 1.2949e+04                    bc_loss 6.8981e+02\n",
      "Epoch 22520, Training-Loss 2.5954e+00, Data-loss 5.0831e-01                  , pde-loss 6.3732e+03, initc-loss 1.2893e+04                    bc_loss 1.6041e+03\n",
      "Epoch 22530, Training-Loss 2.4921e+00, Data-loss 4.9280e-01                  , pde-loss 6.8045e+03, initc-loss 1.3031e+04                    bc_loss 1.5790e+02\n",
      "Epoch 22540, Training-Loss 2.4586e+00, Data-loss 5.6938e-01                  , pde-loss 5.2065e+03, initc-loss 1.2906e+04                    bc_loss 7.7964e+02\n",
      "Epoch 22550, Training-Loss 2.4733e+00, Data-loss 5.2887e-01                  , pde-loss 6.2507e+03, initc-loss 1.2904e+04                    bc_loss 2.8914e+02\n",
      "Epoch 22560, Training-Loss 2.2937e+00, Data-loss 3.7924e-01                  , pde-loss 5.9847e+03, initc-loss 1.2881e+04                    bc_loss 2.7915e+02\n",
      "Epoch 22570, Training-Loss 2.3191e+00, Data-loss 4.2360e-01                  , pde-loss 5.8719e+03, initc-loss 1.2923e+04                    bc_loss 1.5977e+02\n",
      "Epoch 22580, Training-Loss 2.3604e+00, Data-loss 4.6792e-01                  , pde-loss 5.4243e+03, initc-loss 1.2940e+04                    bc_loss 5.6049e+02\n",
      "Epoch 22590, Training-Loss 2.3069e+00, Data-loss 4.5045e-01                  , pde-loss 5.2021e+03, initc-loss 1.2942e+04                    bc_loss 4.2127e+02\n",
      "Epoch 22600, Training-Loss 2.4209e+00, Data-loss 5.5342e-01                  , pde-loss 5.6432e+03, initc-loss 1.2841e+04                    bc_loss 1.9071e+02\n",
      "Epoch 22610, Training-Loss 2.3416e+00, Data-loss 4.2727e-01                  , pde-loss 5.8333e+03, initc-loss 1.2863e+04                    bc_loss 4.4687e+02\n",
      "Epoch 22620, Training-Loss 2.8527e+00, Data-loss 8.3116e-01                  , pde-loss 6.6565e+03, initc-loss 1.3032e+04                    bc_loss 5.2758e+02\n",
      "Epoch 22630, Training-Loss 2.3353e+00, Data-loss 3.2051e-01                  , pde-loss 6.2419e+03, initc-loss 1.2859e+04                    bc_loss 1.0472e+03\n",
      "Epoch 22640, Training-Loss 2.4377e+00, Data-loss 4.3380e-01                  , pde-loss 6.5721e+03, initc-loss 1.3005e+04                    bc_loss 4.6171e+02\n",
      "Epoch 22650, Training-Loss 2.3406e+00, Data-loss 5.2503e-01                  , pde-loss 4.9478e+03, initc-loss 1.2994e+04                    bc_loss 2.1393e+02\n",
      "Epoch 22660, Training-Loss 2.5832e+00, Data-loss 5.8573e-01                  , pde-loss 6.5063e+03, initc-loss 1.2900e+04                    bc_loss 5.6870e+02\n",
      "Epoch 22670, Training-Loss 2.4441e+00, Data-loss 5.0555e-01                  , pde-loss 5.8820e+03, initc-loss 1.2862e+04                    bc_loss 6.4132e+02\n",
      "Epoch 22680, Training-Loss 2.2925e+00, Data-loss 3.6834e-01                  , pde-loss 5.9154e+03, initc-loss 1.2836e+04                    bc_loss 4.9065e+02\n",
      "Epoch 22690, Training-Loss 2.4541e+00, Data-loss 5.6213e-01                  , pde-loss 5.6703e+03, initc-loss 1.2983e+04                    bc_loss 2.6669e+02\n",
      "Epoch 22700, Training-Loss 2.4629e+00, Data-loss 5.2198e-01                  , pde-loss 6.0678e+03, initc-loss 1.2822e+04                    bc_loss 5.1965e+02\n",
      "Epoch 22710, Training-Loss 2.3310e+00, Data-loss 4.1598e-01                  , pde-loss 6.1108e+03, initc-loss 1.2943e+04                    bc_loss 9.5837e+01\n",
      "Epoch 22720, Training-Loss 2.4942e+00, Data-loss 6.1597e-01                  , pde-loss 5.5035e+03, initc-loss 1.2947e+04                    bc_loss 3.3099e+02\n",
      "Epoch 22730, Training-Loss 2.4233e+00, Data-loss 4.4643e-01                  , pde-loss 5.8776e+03, initc-loss 1.2912e+04                    bc_loss 9.7852e+02\n",
      "Epoch 22740, Training-Loss 2.4787e+00, Data-loss 5.3250e-01                  , pde-loss 5.5738e+03, initc-loss 1.2823e+04                    bc_loss 1.0652e+03\n",
      "Epoch 22750, Training-Loss 2.9065e+00, Data-loss 9.7883e-01                  , pde-loss 5.6378e+03, initc-loss 1.3006e+04                    bc_loss 6.3220e+02\n",
      "Epoch 22760, Training-Loss 2.3571e+00, Data-loss 4.5444e-01                  , pde-loss 5.9720e+03, initc-loss 1.2848e+04                    bc_loss 2.0635e+02\n",
      "Epoch 22770, Training-Loss 2.4427e+00, Data-loss 4.8649e-01                  , pde-loss 6.4029e+03, initc-loss 1.2901e+04                    bc_loss 2.5850e+02\n",
      "Epoch 22780, Training-Loss 2.6576e+00, Data-loss 5.8445e-01                  , pde-loss 6.0426e+03, initc-loss 1.3003e+04                    bc_loss 1.6851e+03\n",
      "Epoch 22790, Training-Loss 2.3908e+00, Data-loss 5.3898e-01                  , pde-loss 5.2776e+03, initc-loss 1.2942e+04                    bc_loss 2.9880e+02\n",
      "Epoch 22800, Training-Loss 2.3461e+00, Data-loss 3.9387e-01                  , pde-loss 5.9908e+03, initc-loss 1.2912e+04                    bc_loss 6.1959e+02\n",
      "Epoch 22810, Training-Loss 2.5292e+00, Data-loss 6.6558e-01                  , pde-loss 5.4560e+03, initc-loss 1.2849e+04                    bc_loss 3.3096e+02\n",
      "Epoch 22820, Training-Loss 2.4509e+00, Data-loss 4.4867e-01                  , pde-loss 6.7951e+03, initc-loss 1.2843e+04                    bc_loss 3.8370e+02\n",
      "Epoch 22830, Training-Loss 2.5449e+00, Data-loss 5.0141e-01                  , pde-loss 6.6744e+03, initc-loss 1.2924e+04                    bc_loss 8.3649e+02\n",
      "Epoch 22840, Training-Loss 2.4712e+00, Data-loss 4.9601e-01                  , pde-loss 6.4346e+03, initc-loss 1.2906e+04                    bc_loss 4.1159e+02\n",
      "Epoch 22850, Training-Loss 2.5241e+00, Data-loss 6.0270e-01                  , pde-loss 5.2229e+03, initc-loss 1.2865e+04                    bc_loss 1.1266e+03\n",
      "Epoch 22860, Training-Loss 2.3982e+00, Data-loss 3.7389e-01                  , pde-loss 6.7361e+03, initc-loss 1.2852e+04                    bc_loss 6.5585e+02\n",
      "Epoch 22870, Training-Loss 2.5100e+00, Data-loss 4.6210e-01                  , pde-loss 6.4218e+03, initc-loss 1.2896e+04                    bc_loss 1.1616e+03\n",
      "Epoch 22880, Training-Loss 2.1044e+00, Data-loss 3.0519e-01                  , pde-loss 4.8401e+03, initc-loss 1.2988e+04                    bc_loss 1.6461e+02\n",
      "Epoch 22890, Training-Loss 2.4160e+00, Data-loss 4.0361e-01                  , pde-loss 6.8061e+03, initc-loss 1.2905e+04                    bc_loss 4.1259e+02\n",
      "Epoch 22900, Training-Loss 2.3619e+00, Data-loss 4.3297e-01                  , pde-loss 6.3442e+03, initc-loss 1.2879e+04                    bc_loss 6.6223e+01\n",
      "Epoch 22910, Training-Loss 2.3695e+00, Data-loss 4.4221e-01                  , pde-loss 6.2735e+03, initc-loss 1.2873e+04                    bc_loss 1.2598e+02\n",
      "Epoch 22920, Training-Loss 2.6559e+00, Data-loss 6.5187e-01                  , pde-loss 5.5612e+03, initc-loss 1.2830e+04                    bc_loss 1.6497e+03\n",
      "Epoch 22930, Training-Loss 2.1730e+00, Data-loss 2.8224e-01                  , pde-loss 5.7990e+03, initc-loss 1.2852e+04                    bc_loss 2.5667e+02\n",
      "Epoch 22940, Training-Loss 2.3923e+00, Data-loss 5.1409e-01                  , pde-loss 5.6894e+03, initc-loss 1.2922e+04                    bc_loss 1.7139e+02\n",
      "Epoch 22950, Training-Loss 2.4157e+00, Data-loss 4.5205e-01                  , pde-loss 6.5939e+03, initc-loss 1.2813e+04                    bc_loss 2.2935e+02\n",
      "Epoch 22960, Training-Loss 2.4923e+00, Data-loss 5.0965e-01                  , pde-loss 6.4497e+03, initc-loss 1.2888e+04                    bc_loss 4.8886e+02\n",
      "Epoch 22970, Training-Loss 2.3684e+00, Data-loss 4.8861e-01                  , pde-loss 5.6279e+03, initc-loss 1.2978e+04                    bc_loss 1.9260e+02\n",
      "Epoch 22980, Training-Loss 2.3656e+00, Data-loss 4.6064e-01                  , pde-loss 5.8102e+03, initc-loss 1.2921e+04                    bc_loss 3.1866e+02\n",
      "Epoch 22990, Training-Loss 2.2516e+00, Data-loss 3.5686e-01                  , pde-loss 5.7015e+03, initc-loss 1.2897e+04                    bc_loss 3.4835e+02\n",
      "Epoch 23000, Training-Loss 2.3121e+00, Data-loss 3.7298e-01                  , pde-loss 5.9975e+03, initc-loss 1.2915e+04                    bc_loss 4.7851e+02\n",
      "Epoch 23010, Training-Loss 2.3862e+00, Data-loss 5.0526e-01                  , pde-loss 5.6735e+03, initc-loss 1.2902e+04                    bc_loss 2.3390e+02\n",
      "Epoch 23020, Training-Loss 2.3664e+00, Data-loss 4.4063e-01                  , pde-loss 6.1597e+03, initc-loss 1.2903e+04                    bc_loss 1.9459e+02\n",
      "Epoch 23030, Training-Loss 2.3925e+00, Data-loss 4.7218e-01                  , pde-loss 6.2499e+03, initc-loss 1.2864e+04                    bc_loss 8.9744e+01\n",
      "Epoch 23040, Training-Loss 2.2816e+00, Data-loss 3.7214e-01                  , pde-loss 5.7884e+03, initc-loss 1.2939e+04                    bc_loss 3.6745e+02\n",
      "Epoch 23050, Training-Loss 2.3641e+00, Data-loss 3.8214e-01                  , pde-loss 5.9346e+03, initc-loss 1.2899e+04                    bc_loss 9.8588e+02\n",
      "Epoch 23060, Training-Loss 2.4307e+00, Data-loss 4.5487e-01                  , pde-loss 6.3338e+03, initc-loss 1.2871e+04                    bc_loss 5.5320e+02\n",
      "Epoch 23070, Training-Loss 2.3845e+00, Data-loss 4.8190e-01                  , pde-loss 5.4215e+03, initc-loss 1.2903e+04                    bc_loss 7.0133e+02\n",
      "Epoch 23080, Training-Loss 2.5151e+00, Data-loss 6.2010e-01                  , pde-loss 5.3947e+03, initc-loss 1.2823e+04                    bc_loss 7.3254e+02\n",
      "Epoch 23090, Training-Loss 2.7489e+00, Data-loss 7.3189e-01                  , pde-loss 5.8500e+03, initc-loss 1.2748e+04                    bc_loss 1.5718e+03\n",
      "Epoch 23100, Training-Loss 2.3323e+00, Data-loss 4.8667e-01                  , pde-loss 5.2129e+03, initc-loss 1.2855e+04                    bc_loss 3.8891e+02\n",
      "Epoch 23110, Training-Loss 2.5020e+00, Data-loss 5.9932e-01                  , pde-loss 5.2854e+03, initc-loss 1.2954e+04                    bc_loss 7.8779e+02\n",
      "Epoch 23120, Training-Loss 2.4080e+00, Data-loss 4.4795e-01                  , pde-loss 5.6304e+03, initc-loss 1.2887e+04                    bc_loss 1.0827e+03\n",
      "Epoch 23130, Training-Loss 2.3343e+00, Data-loss 3.6800e-01                  , pde-loss 6.3242e+03, initc-loss 1.2908e+04                    bc_loss 4.3084e+02\n",
      "Epoch 23140, Training-Loss 2.5234e+00, Data-loss 5.6229e-01                  , pde-loss 5.6864e+03, initc-loss 1.2972e+04                    bc_loss 9.5245e+02\n",
      "Epoch 23150, Training-Loss 2.4773e+00, Data-loss 5.4953e-01                  , pde-loss 6.0092e+03, initc-loss 1.2978e+04                    bc_loss 2.9064e+02\n",
      "Epoch 23160, Training-Loss 2.3264e+00, Data-loss 4.7766e-01                  , pde-loss 4.9267e+03, initc-loss 1.2803e+04                    bc_loss 7.5798e+02\n",
      "Epoch 23170, Training-Loss 2.2150e+00, Data-loss 3.9191e-01                  , pde-loss 5.3053e+03, initc-loss 1.2852e+04                    bc_loss 7.2781e+01\n",
      "Epoch 23180, Training-Loss 2.5569e+00, Data-loss 4.9800e-01                  , pde-loss 7.1798e+03, initc-loss 1.2932e+04                    bc_loss 4.7623e+02\n",
      "Epoch 23190, Training-Loss 2.5741e+00, Data-loss 6.4003e-01                  , pde-loss 5.8885e+03, initc-loss 1.2973e+04                    bc_loss 4.7942e+02\n",
      "Epoch 23200, Training-Loss 2.6907e+00, Data-loss 7.0772e-01                  , pde-loss 6.4512e+03, initc-loss 1.2941e+04                    bc_loss 4.3774e+02\n",
      "Epoch 23210, Training-Loss 3.1220e+00, Data-loss 8.3113e-01                  , pde-loss 6.4028e+03, initc-loss 1.3006e+04                    bc_loss 3.4996e+03\n",
      "Epoch 23220, Training-Loss 2.3794e+00, Data-loss 4.7098e-01                  , pde-loss 5.7544e+03, initc-loss 1.2918e+04                    bc_loss 4.1186e+02\n",
      "Epoch 23230, Training-Loss 2.4095e+00, Data-loss 3.7990e-01                  , pde-loss 6.4768e+03, initc-loss 1.2972e+04                    bc_loss 8.4707e+02\n",
      "Epoch 23240, Training-Loss 2.3710e+00, Data-loss 4.5171e-01                  , pde-loss 6.1319e+03, initc-loss 1.2883e+04                    bc_loss 1.7782e+02\n",
      "Epoch 23250, Training-Loss 2.3105e+00, Data-loss 3.9169e-01                  , pde-loss 6.0770e+03, initc-loss 1.2920e+04                    bc_loss 1.9040e+02\n",
      "Epoch 23260, Training-Loss 2.5636e+00, Data-loss 6.6465e-01                  , pde-loss 5.6587e+03, initc-loss 1.3035e+04                    bc_loss 2.9607e+02\n",
      "Epoch 23270, Training-Loss 2.4726e+00, Data-loss 5.5732e-01                  , pde-loss 5.9496e+03, initc-loss 1.2998e+04                    bc_loss 2.0499e+02\n",
      "Epoch 23280, Training-Loss 2.2902e+00, Data-loss 4.2654e-01                  , pde-loss 5.5887e+03, initc-loss 1.2982e+04                    bc_loss 6.6470e+01\n",
      "Epoch 23290, Training-Loss 2.5211e+00, Data-loss 5.6118e-01                  , pde-loss 6.2307e+03, initc-loss 1.2901e+04                    bc_loss 4.6756e+02\n",
      "Epoch 23300, Training-Loss 2.2979e+00, Data-loss 4.4950e-01                  , pde-loss 5.3105e+03, initc-loss 1.2854e+04                    bc_loss 3.1947e+02\n",
      "Epoch 23310, Training-Loss 2.2910e+00, Data-loss 3.5793e-01                  , pde-loss 6.2709e+03, initc-loss 1.2943e+04                    bc_loss 1.1658e+02\n",
      "Epoch 23320, Training-Loss 2.2646e+00, Data-loss 3.5004e-01                  , pde-loss 5.9924e+03, initc-loss 1.2893e+04                    bc_loss 2.6055e+02\n",
      "Epoch 23330, Training-Loss 2.3433e+00, Data-loss 3.3581e-01                  , pde-loss 6.9695e+03, initc-loss 1.2902e+04                    bc_loss 2.0321e+02\n",
      "Epoch 23340, Training-Loss 2.3438e+00, Data-loss 4.8711e-01                  , pde-loss 5.2519e+03, initc-loss 1.2913e+04                    bc_loss 4.0287e+02\n",
      "Epoch 23350, Training-Loss 2.3936e+00, Data-loss 3.5664e-01                  , pde-loss 6.3991e+03, initc-loss 1.2810e+04                    bc_loss 1.1603e+03\n",
      "Epoch 23360, Training-Loss 2.2668e+00, Data-loss 3.6719e-01                  , pde-loss 5.7856e+03, initc-loss 1.2956e+04                    bc_loss 2.5486e+02\n",
      "Epoch 23370, Training-Loss 2.1700e+00, Data-loss 3.5105e-01                  , pde-loss 4.9309e+03, initc-loss 1.2982e+04                    bc_loss 2.7656e+02\n",
      "Epoch 23380, Training-Loss 2.5330e+00, Data-loss 5.3911e-01                  , pde-loss 5.8568e+03, initc-loss 1.2997e+04                    bc_loss 1.0849e+03\n",
      "Epoch 23390, Training-Loss 2.3685e+00, Data-loss 4.4246e-01                  , pde-loss 5.9345e+03, initc-loss 1.2889e+04                    bc_loss 4.3692e+02\n",
      "Epoch 23400, Training-Loss 2.3123e+00, Data-loss 4.0352e-01                  , pde-loss 5.7331e+03, initc-loss 1.2912e+04                    bc_loss 4.4243e+02\n",
      "Epoch 23410, Training-Loss 2.3449e+00, Data-loss 5.0322e-01                  , pde-loss 5.3379e+03, initc-loss 1.2914e+04                    bc_loss 1.6581e+02\n",
      "Epoch 23420, Training-Loss 2.2834e+00, Data-loss 3.7706e-01                  , pde-loss 5.8762e+03, initc-loss 1.2940e+04                    bc_loss 2.4742e+02\n",
      "Epoch 23430, Training-Loss 2.3976e+00, Data-loss 5.2957e-01                  , pde-loss 5.5711e+03, initc-loss 1.2996e+04                    bc_loss 1.1271e+02\n",
      "Epoch 23440, Training-Loss 2.3754e+00, Data-loss 4.2562e-01                  , pde-loss 6.3315e+03, initc-loss 1.2880e+04                    bc_loss 2.8583e+02\n",
      "Epoch 23450, Training-Loss 2.4352e+00, Data-loss 3.8209e-01                  , pde-loss 6.9446e+03, initc-loss 1.2961e+04                    bc_loss 6.2616e+02\n",
      "Epoch 23460, Training-Loss 2.3377e+00, Data-loss 4.5554e-01                  , pde-loss 5.5344e+03, initc-loss 1.2928e+04                    bc_loss 3.5947e+02\n",
      "Epoch 23470, Training-Loss 2.3885e+00, Data-loss 4.1796e-01                  , pde-loss 6.6908e+03, initc-loss 1.2917e+04                    bc_loss 9.7874e+01\n",
      "Epoch 23480, Training-Loss 2.5001e+00, Data-loss 4.5508e-01                  , pde-loss 6.1365e+03, initc-loss 1.2894e+04                    bc_loss 1.4200e+03\n",
      "Epoch 23490, Training-Loss 3.1157e+00, Data-loss 1.2072e+00                  , pde-loss 5.3499e+03, initc-loss 1.2774e+04                    bc_loss 9.6088e+02\n",
      "Epoch 23500, Training-Loss 2.3299e+00, Data-loss 4.9833e-01                  , pde-loss 5.2775e+03, initc-loss 1.2934e+04                    bc_loss 1.0427e+02\n",
      "Epoch 23510, Training-Loss 2.5637e+00, Data-loss 6.7923e-01                  , pde-loss 5.7502e+03, initc-loss 1.2942e+04                    bc_loss 1.5218e+02\n",
      "Epoch 23520, Training-Loss 2.9164e+00, Data-loss 5.5572e-01                  , pde-loss 6.3638e+03, initc-loss 1.2875e+04                    bc_loss 4.3678e+03\n",
      "Epoch 23530, Training-Loss 2.7494e+00, Data-loss 7.2514e-01                  , pde-loss 5.9677e+03, initc-loss 1.2982e+04                    bc_loss 1.2927e+03\n",
      "Epoch 23540, Training-Loss 2.3144e+00, Data-loss 4.0741e-01                  , pde-loss 6.1045e+03, initc-loss 1.2882e+04                    bc_loss 8.3050e+01\n",
      "Epoch 23550, Training-Loss 2.2918e+00, Data-loss 3.4016e-01                  , pde-loss 5.2661e+03, initc-loss 1.2957e+04                    bc_loss 1.2936e+03\n",
      "Epoch 23560, Training-Loss 2.3836e+00, Data-loss 4.7649e-01                  , pde-loss 5.8146e+03, initc-loss 1.2844e+04                    bc_loss 4.1307e+02\n",
      "Epoch 23570, Training-Loss 2.2845e+00, Data-loss 4.2844e-01                  , pde-loss 5.3194e+03, initc-loss 1.2921e+04                    bc_loss 3.1968e+02\n",
      "Epoch 23580, Training-Loss 2.4706e+00, Data-loss 5.0970e-01                  , pde-loss 6.4280e+03, initc-loss 1.2760e+04                    bc_loss 4.2105e+02\n",
      "Epoch 23590, Training-Loss 2.4009e+00, Data-loss 5.2257e-01                  , pde-loss 5.4594e+03, initc-loss 1.2987e+04                    bc_loss 3.3762e+02\n",
      "Epoch 23600, Training-Loss 2.2770e+00, Data-loss 3.4573e-01                  , pde-loss 5.8921e+03, initc-loss 1.2870e+04                    bc_loss 5.5129e+02\n",
      "Epoch 23610, Training-Loss 2.4814e+00, Data-loss 4.3591e-01                  , pde-loss 5.8356e+03, initc-loss 1.2955e+04                    bc_loss 1.6649e+03\n",
      "Epoch 23620, Training-Loss 2.4274e+00, Data-loss 4.6322e-01                  , pde-loss 6.4422e+03, initc-loss 1.2791e+04                    bc_loss 4.0852e+02\n",
      "Epoch 23630, Training-Loss 2.3177e+00, Data-loss 3.3537e-01                  , pde-loss 6.4451e+03, initc-loss 1.2931e+04                    bc_loss 4.4740e+02\n",
      "Epoch 23640, Training-Loss 2.3917e+00, Data-loss 5.1792e-01                  , pde-loss 5.5446e+03, initc-loss 1.2888e+04                    bc_loss 3.0544e+02\n",
      "Epoch 23650, Training-Loss 2.3103e+00, Data-loss 4.0281e-01                  , pde-loss 5.8192e+03, initc-loss 1.2952e+04                    bc_loss 3.0444e+02\n",
      "Epoch 23660, Training-Loss 2.2645e+00, Data-loss 3.6588e-01                  , pde-loss 5.7911e+03, initc-loss 1.2874e+04                    bc_loss 3.2099e+02\n",
      "Epoch 23670, Training-Loss 2.2912e+00, Data-loss 3.6638e-01                  , pde-loss 5.8519e+03, initc-loss 1.2913e+04                    bc_loss 4.8403e+02\n",
      "Epoch 23680, Training-Loss 2.3402e+00, Data-loss 4.6430e-01                  , pde-loss 5.5636e+03, initc-loss 1.3026e+04                    bc_loss 1.6905e+02\n",
      "Epoch 23690, Training-Loss 2.2717e+00, Data-loss 3.2242e-01                  , pde-loss 5.8153e+03, initc-loss 1.2873e+04                    bc_loss 8.0447e+02\n",
      "Epoch 23700, Training-Loss 2.3880e+00, Data-loss 4.8902e-01                  , pde-loss 5.6894e+03, initc-loss 1.2894e+04                    bc_loss 4.0659e+02\n",
      "Epoch 23710, Training-Loss 2.5008e+00, Data-loss 4.4167e-01                  , pde-loss 6.2941e+03, initc-loss 1.2994e+04                    bc_loss 1.3026e+03\n",
      "Epoch 23720, Training-Loss 2.5989e+00, Data-loss 4.8408e-01                  , pde-loss 6.4689e+03, initc-loss 1.2873e+04                    bc_loss 1.8061e+03\n",
      "Epoch 23730, Training-Loss 2.4981e+00, Data-loss 4.8665e-01                  , pde-loss 6.6849e+03, initc-loss 1.2959e+04                    bc_loss 4.7096e+02\n",
      "Epoch 23740, Training-Loss 2.3885e+00, Data-loss 4.1607e-01                  , pde-loss 6.3911e+03, initc-loss 1.2989e+04                    bc_loss 3.4436e+02\n",
      "Epoch 23750, Training-Loss 2.3153e+00, Data-loss 3.7017e-01                  , pde-loss 6.0708e+03, initc-loss 1.2944e+04                    bc_loss 4.3673e+02\n",
      "Epoch 23760, Training-Loss 2.5996e+00, Data-loss 6.3997e-01                  , pde-loss 6.2310e+03, initc-loss 1.3069e+04                    bc_loss 2.9601e+02\n",
      "Epoch 23770, Training-Loss 2.4233e+00, Data-loss 4.6875e-01                  , pde-loss 5.7352e+03, initc-loss 1.2846e+04                    bc_loss 9.6354e+02\n",
      "Epoch 23780, Training-Loss 2.3733e+00, Data-loss 4.7082e-01                  , pde-loss 5.9057e+03, initc-loss 1.2944e+04                    bc_loss 1.7470e+02\n",
      "Epoch 23790, Training-Loss 2.1839e+00, Data-loss 3.5232e-01                  , pde-loss 5.2281e+03, initc-loss 1.2904e+04                    bc_loss 1.8409e+02\n",
      "Epoch 23800, Training-Loss 2.2394e+00, Data-loss 4.0688e-01                  , pde-loss 5.2346e+03, initc-loss 1.2913e+04                    bc_loss 1.7713e+02\n",
      "Epoch 23810, Training-Loss 2.2913e+00, Data-loss 3.4278e-01                  , pde-loss 6.4730e+03, initc-loss 1.2932e+04                    bc_loss 7.9571e+01\n",
      "Epoch 23820, Training-Loss 2.4411e+00, Data-loss 4.8683e-01                  , pde-loss 6.1634e+03, initc-loss 1.2873e+04                    bc_loss 5.0630e+02\n",
      "Epoch 23830, Training-Loss 2.4347e+00, Data-loss 3.9422e-01                  , pde-loss 5.7085e+03, initc-loss 1.2937e+04                    bc_loss 1.7593e+03\n",
      "Epoch 23840, Training-Loss 2.7752e+00, Data-loss 7.3524e-01                  , pde-loss 6.4252e+03, initc-loss 1.2866e+04                    bc_loss 1.1085e+03\n",
      "Epoch 23850, Training-Loss 2.3186e+00, Data-loss 3.5736e-01                  , pde-loss 6.5520e+03, initc-loss 1.2875e+04                    bc_loss 1.8591e+02\n",
      "Epoch 23860, Training-Loss 2.2565e+00, Data-loss 3.2454e-01                  , pde-loss 5.9213e+03, initc-loss 1.2942e+04                    bc_loss 4.5657e+02\n",
      "Epoch 23870, Training-Loss 2.4008e+00, Data-loss 4.8123e-01                  , pde-loss 5.5847e+03, initc-loss 1.2980e+04                    bc_loss 6.3118e+02\n",
      "Epoch 23880, Training-Loss 2.4136e+00, Data-loss 5.0681e-01                  , pde-loss 6.1035e+03, initc-loss 1.2876e+04                    bc_loss 8.9165e+01\n",
      "Epoch 23890, Training-Loss 2.2193e+00, Data-loss 3.4263e-01                  , pde-loss 5.4715e+03, initc-loss 1.2895e+04                    bc_loss 3.9995e+02\n",
      "Epoch 23900, Training-Loss 2.4985e+00, Data-loss 5.4555e-01                  , pde-loss 6.1346e+03, initc-loss 1.2836e+04                    bc_loss 5.5900e+02\n",
      "Epoch 23910, Training-Loss 2.3236e+00, Data-loss 3.9988e-01                  , pde-loss 6.1475e+03, initc-loss 1.2877e+04                    bc_loss 2.1273e+02\n",
      "Epoch 23920, Training-Loss 2.3057e+00, Data-loss 4.2791e-01                  , pde-loss 5.3885e+03, initc-loss 1.2874e+04                    bc_loss 5.1483e+02\n",
      "Epoch 23930, Training-Loss 2.5756e+00, Data-loss 5.8993e-01                  , pde-loss 6.2769e+03, initc-loss 1.2823e+04                    bc_loss 7.5696e+02\n",
      "Epoch 23940, Training-Loss 2.4258e+00, Data-loss 4.8530e-01                  , pde-loss 5.9812e+03, initc-loss 1.2932e+04                    bc_loss 4.9157e+02\n",
      "Epoch 23950, Training-Loss 2.2108e+00, Data-loss 3.3950e-01                  , pde-loss 5.2081e+03, initc-loss 1.2902e+04                    bc_loss 6.0268e+02\n",
      "Epoch 23960, Training-Loss 2.2407e+00, Data-loss 3.7142e-01                  , pde-loss 5.7577e+03, initc-loss 1.2830e+04                    bc_loss 1.0487e+02\n",
      "Epoch 23970, Training-Loss 2.4430e+00, Data-loss 5.3166e-01                  , pde-loss 6.1832e+03, initc-loss 1.2838e+04                    bc_loss 9.1639e+01\n",
      "Epoch 23980, Training-Loss 2.4129e+00, Data-loss 5.0592e-01                  , pde-loss 5.3531e+03, initc-loss 1.2988e+04                    bc_loss 7.2897e+02\n",
      "Epoch 23990, Training-Loss 2.6179e+00, Data-loss 7.1027e-01                  , pde-loss 5.7208e+03, initc-loss 1.2956e+04                    bc_loss 3.9953e+02\n",
      "Epoch 24000, Training-Loss 2.2573e+00, Data-loss 3.6874e-01                  , pde-loss 5.2429e+03, initc-loss 1.2924e+04                    bc_loss 7.1782e+02\n",
      "Epoch 24010, Training-Loss 2.4482e+00, Data-loss 4.9255e-01                  , pde-loss 5.6299e+03, initc-loss 1.2866e+04                    bc_loss 1.0614e+03\n",
      "Epoch 24020, Training-Loss 2.4802e+00, Data-loss 5.7976e-01                  , pde-loss 5.6495e+03, initc-loss 1.3006e+04                    bc_loss 3.4906e+02\n",
      "Epoch 24030, Training-Loss 2.4548e+00, Data-loss 4.5678e-01                  , pde-loss 6.1525e+03, initc-loss 1.2946e+04                    bc_loss 8.8131e+02\n",
      "Epoch 24040, Training-Loss 2.3776e+00, Data-loss 4.3074e-01                  , pde-loss 6.3262e+03, initc-loss 1.2917e+04                    bc_loss 2.2547e+02\n",
      "Epoch 24050, Training-Loss 2.2664e+00, Data-loss 3.3241e-01                  , pde-loss 5.5159e+03, initc-loss 1.2936e+04                    bc_loss 8.8734e+02\n",
      "Epoch 24060, Training-Loss 2.2820e+00, Data-loss 3.7013e-01                  , pde-loss 5.6861e+03, initc-loss 1.2866e+04                    bc_loss 5.6685e+02\n",
      "Epoch 24070, Training-Loss 2.3658e+00, Data-loss 4.3314e-01                  , pde-loss 5.6975e+03, initc-loss 1.2933e+04                    bc_loss 6.9699e+02\n",
      "Epoch 24080, Training-Loss 2.2437e+00, Data-loss 3.3666e-01                  , pde-loss 5.7986e+03, initc-loss 1.2971e+04                    bc_loss 3.0112e+02\n",
      "Epoch 24090, Training-Loss 2.6519e+00, Data-loss 6.8526e-01                  , pde-loss 6.2551e+03, initc-loss 1.2787e+04                    bc_loss 6.2463e+02\n",
      "Epoch 24100, Training-Loss 2.3240e+00, Data-loss 4.6959e-01                  , pde-loss 5.4097e+03, initc-loss 1.2912e+04                    bc_loss 2.2224e+02\n",
      "Epoch 24110, Training-Loss 2.5472e+00, Data-loss 5.1275e-01                  , pde-loss 6.3423e+03, initc-loss 1.2892e+04                    bc_loss 1.1106e+03\n",
      "Epoch 24120, Training-Loss 2.3038e+00, Data-loss 4.1506e-01                  , pde-loss 5.5719e+03, initc-loss 1.2993e+04                    bc_loss 3.2238e+02\n",
      "Epoch 24130, Training-Loss 3.2099e+00, Data-loss 1.1193e+00                  , pde-loss 6.4388e+03, initc-loss 1.2973e+04                    bc_loss 1.4942e+03\n",
      "Epoch 24140, Training-Loss 2.2865e+00, Data-loss 4.5633e-01                  , pde-loss 5.1942e+03, initc-loss 1.2900e+04                    bc_loss 2.0730e+02\n",
      "Epoch 24150, Training-Loss 2.3976e+00, Data-loss 5.0281e-01                  , pde-loss 5.5557e+03, initc-loss 1.2879e+04                    bc_loss 5.1333e+02\n",
      "Epoch 24160, Training-Loss 2.4579e+00, Data-loss 4.0797e-01                  , pde-loss 6.1822e+03, initc-loss 1.2926e+04                    bc_loss 1.3918e+03\n",
      "Epoch 24170, Training-Loss 2.4095e+00, Data-loss 4.6128e-01                  , pde-loss 6.4308e+03, initc-loss 1.2841e+04                    bc_loss 2.1005e+02\n",
      "Epoch 24180, Training-Loss 2.3336e+00, Data-loss 4.3538e-01                  , pde-loss 5.7140e+03, initc-loss 1.2829e+04                    bc_loss 4.3838e+02\n",
      "Epoch 24190, Training-Loss 2.1632e+00, Data-loss 3.2762e-01                  , pde-loss 5.2710e+03, initc-loss 1.2929e+04                    bc_loss 1.5554e+02\n",
      "Epoch 24200, Training-Loss 2.5420e+00, Data-loss 5.8597e-01                  , pde-loss 6.2832e+03, initc-loss 1.2863e+04                    bc_loss 4.1372e+02\n",
      "Epoch 24210, Training-Loss 2.1665e+00, Data-loss 3.7476e-01                  , pde-loss 4.8177e+03, initc-loss 1.2994e+04                    bc_loss 1.0575e+02\n",
      "Epoch 24220, Training-Loss 2.2937e+00, Data-loss 3.8662e-01                  , pde-loss 5.9256e+03, initc-loss 1.2905e+04                    bc_loss 2.4018e+02\n",
      "Epoch 24230, Training-Loss 2.3845e+00, Data-loss 4.1269e-01                  , pde-loss 6.7139e+03, initc-loss 1.2921e+04                    bc_loss 8.3837e+01\n",
      "Epoch 24240, Training-Loss 2.3786e+00, Data-loss 3.9926e-01                  , pde-loss 5.9084e+03, initc-loss 1.2981e+04                    bc_loss 9.0391e+02\n",
      "Epoch 24250, Training-Loss 2.3061e+00, Data-loss 3.2011e-01                  , pde-loss 5.5963e+03, initc-loss 1.2985e+04                    bc_loss 1.2782e+03\n",
      "Epoch 24260, Training-Loss 2.3421e+00, Data-loss 4.9373e-01                  , pde-loss 5.4474e+03, initc-loss 1.2872e+04                    bc_loss 1.6426e+02\n",
      "Epoch 24270, Training-Loss 2.2633e+00, Data-loss 3.8539e-01                  , pde-loss 5.7824e+03, initc-loss 1.2914e+04                    bc_loss 8.2461e+01\n",
      "Epoch 24280, Training-Loss 2.3087e+00, Data-loss 4.0440e-01                  , pde-loss 5.7133e+03, initc-loss 1.2918e+04                    bc_loss 4.1207e+02\n",
      "Epoch 24290, Training-Loss 2.2356e+00, Data-loss 3.3777e-01                  , pde-loss 5.5608e+03, initc-loss 1.2852e+04                    bc_loss 5.6567e+02\n",
      "Epoch 24300, Training-Loss 2.2747e+00, Data-loss 4.0295e-01                  , pde-loss 5.5733e+03, initc-loss 1.2963e+04                    bc_loss 1.8125e+02\n",
      "Epoch 24310, Training-Loss 2.3099e+00, Data-loss 3.6362e-01                  , pde-loss 5.7311e+03, initc-loss 1.2860e+04                    bc_loss 8.7179e+02\n",
      "Epoch 24320, Training-Loss 2.5031e+00, Data-loss 5.8493e-01                  , pde-loss 5.8748e+03, initc-loss 1.2840e+04                    bc_loss 4.6685e+02\n",
      "Epoch 24330, Training-Loss 2.4165e+00, Data-loss 5.0102e-01                  , pde-loss 5.5947e+03, initc-loss 1.2857e+04                    bc_loss 7.0383e+02\n",
      "Epoch 24340, Training-Loss 2.4676e+00, Data-loss 5.5236e-01                  , pde-loss 5.2916e+03, initc-loss 1.2958e+04                    bc_loss 9.0298e+02\n",
      "Epoch 24350, Training-Loss 2.2788e+00, Data-loss 4.1386e-01                  , pde-loss 5.2562e+03, initc-loss 1.2947e+04                    bc_loss 4.4707e+02\n",
      "Epoch 24360, Training-Loss 2.1421e+00, Data-loss 3.0187e-01                  , pde-loss 5.4048e+03, initc-loss 1.2832e+04                    bc_loss 1.6505e+02\n",
      "Epoch 24370, Training-Loss 2.2824e+00, Data-loss 3.5693e-01                  , pde-loss 5.6474e+03, initc-loss 1.2898e+04                    bc_loss 7.1005e+02\n",
      "Epoch 24380, Training-Loss 2.5037e+00, Data-loss 5.2136e-01                  , pde-loss 6.3745e+03, initc-loss 1.2878e+04                    bc_loss 5.7129e+02\n",
      "Epoch 24390, Training-Loss 2.4908e+00, Data-loss 5.8346e-01                  , pde-loss 5.7560e+03, initc-loss 1.2926e+04                    bc_loss 3.9169e+02\n",
      "Epoch 24400, Training-Loss 2.2695e+00, Data-loss 4.1369e-01                  , pde-loss 5.2829e+03, initc-loss 1.2933e+04                    bc_loss 3.4190e+02\n",
      "Epoch 24410, Training-Loss 2.2619e+00, Data-loss 3.8894e-01                  , pde-loss 5.4174e+03, initc-loss 1.2985e+04                    bc_loss 3.2719e+02\n",
      "Epoch 24420, Training-Loss 2.2428e+00, Data-loss 4.4962e-01                  , pde-loss 4.8895e+03, initc-loss 1.2925e+04                    bc_loss 1.1734e+02\n",
      "Epoch 24430, Training-Loss 2.7319e+00, Data-loss 5.4919e-01                  , pde-loss 6.1456e+03, initc-loss 1.2886e+04                    bc_loss 2.7956e+03\n",
      "Epoch 24440, Training-Loss 2.5426e+00, Data-loss 6.1878e-01                  , pde-loss 5.9838e+03, initc-loss 1.3005e+04                    bc_loss 2.4935e+02\n",
      "Epoch 24450, Training-Loss 2.3838e+00, Data-loss 5.0845e-01                  , pde-loss 5.6833e+03, initc-loss 1.2894e+04                    bc_loss 1.7612e+02\n",
      "Epoch 24460, Training-Loss 2.5026e+00, Data-loss 5.3807e-01                  , pde-loss 6.4318e+03, initc-loss 1.2847e+04                    bc_loss 3.6739e+02\n",
      "Epoch 24470, Training-Loss 2.4446e+00, Data-loss 4.5087e-01                  , pde-loss 6.0704e+03, initc-loss 1.2969e+04                    bc_loss 8.9791e+02\n",
      "Epoch 24480, Training-Loss 2.1989e+00, Data-loss 3.9060e-01                  , pde-loss 5.0014e+03, initc-loss 1.2917e+04                    bc_loss 1.6457e+02\n",
      "Epoch 24490, Training-Loss 2.4105e+00, Data-loss 4.6610e-01                  , pde-loss 5.6682e+03, initc-loss 1.2935e+04                    bc_loss 8.4045e+02\n",
      "Epoch 24500, Training-Loss 2.4057e+00, Data-loss 4.8618e-01                  , pde-loss 4.9367e+03, initc-loss 1.3001e+04                    bc_loss 1.2581e+03\n",
      "Epoch 24510, Training-Loss 2.5590e+00, Data-loss 5.6566e-01                  , pde-loss 5.6640e+03, initc-loss 1.2817e+04                    bc_loss 1.4526e+03\n",
      "Epoch 24520, Training-Loss 2.3337e+00, Data-loss 3.7354e-01                  , pde-loss 6.1620e+03, initc-loss 1.2911e+04                    bc_loss 5.2842e+02\n",
      "Epoch 24530, Training-Loss 2.3567e+00, Data-loss 4.8496e-01                  , pde-loss 5.6849e+03, initc-loss 1.2942e+04                    bc_loss 9.0842e+01\n",
      "Epoch 24540, Training-Loss 2.1645e+00, Data-loss 3.4761e-01                  , pde-loss 5.0676e+03, initc-loss 1.2892e+04                    bc_loss 2.0871e+02\n",
      "Epoch 24550, Training-Loss 2.2948e+00, Data-loss 3.9079e-01                  , pde-loss 5.9567e+03, initc-loss 1.2982e+04                    bc_loss 1.0151e+02\n",
      "Epoch 24560, Training-Loss 2.4007e+00, Data-loss 4.4891e-01                  , pde-loss 6.1643e+03, initc-loss 1.2952e+04                    bc_loss 4.0158e+02\n",
      "Epoch 24570, Training-Loss 2.4111e+00, Data-loss 5.0948e-01                  , pde-loss 5.9106e+03, initc-loss 1.2877e+04                    bc_loss 2.2766e+02\n",
      "Epoch 24580, Training-Loss 2.4522e+00, Data-loss 4.2138e-01                  , pde-loss 5.8368e+03, initc-loss 1.2955e+04                    bc_loss 1.5166e+03\n",
      "Epoch 24590, Training-Loss 2.8789e+00, Data-loss 8.7593e-01                  , pde-loss 6.2624e+03, initc-loss 1.2778e+04                    bc_loss 9.8987e+02\n",
      "Epoch 24600, Training-Loss 2.6195e+00, Data-loss 5.0095e-01                  , pde-loss 5.3917e+03, initc-loss 1.3031e+04                    bc_loss 2.7626e+03\n",
      "Epoch 24610, Training-Loss 2.1764e+00, Data-loss 2.8915e-01                  , pde-loss 5.4665e+03, initc-loss 1.2958e+04                    bc_loss 4.4804e+02\n",
      "Epoch 24620, Training-Loss 2.2705e+00, Data-loss 4.0245e-01                  , pde-loss 5.5225e+03, initc-loss 1.2934e+04                    bc_loss 2.2430e+02\n",
      "Epoch 24630, Training-Loss 2.8129e+00, Data-loss 8.3695e-01                  , pde-loss 6.1705e+03, initc-loss 1.2972e+04                    bc_loss 6.1702e+02\n",
      "Epoch 24640, Training-Loss 2.1924e+00, Data-loss 3.7081e-01                  , pde-loss 4.9393e+03, initc-loss 1.2927e+04                    bc_loss 3.5031e+02\n",
      "Epoch 24650, Training-Loss 2.3311e+00, Data-loss 4.6766e-01                  , pde-loss 5.2651e+03, initc-loss 1.2946e+04                    bc_loss 4.2369e+02\n",
      "Epoch 24660, Training-Loss 2.5154e+00, Data-loss 5.8270e-01                  , pde-loss 5.4970e+03, initc-loss 1.2851e+04                    bc_loss 9.7805e+02\n",
      "Epoch 24670, Training-Loss 2.3986e+00, Data-loss 4.6932e-01                  , pde-loss 5.9031e+03, initc-loss 1.2912e+04                    bc_loss 4.7770e+02\n",
      "Epoch 24680, Training-Loss 2.4361e+00, Data-loss 5.3960e-01                  , pde-loss 5.2347e+03, initc-loss 1.2937e+04                    bc_loss 7.9255e+02\n",
      "Epoch 24690, Training-Loss 2.2645e+00, Data-loss 3.4649e-01                  , pde-loss 5.5233e+03, initc-loss 1.3017e+04                    bc_loss 6.3958e+02\n",
      "Epoch 24700, Training-Loss 2.3729e+00, Data-loss 4.0189e-01                  , pde-loss 6.6070e+03, initc-loss 1.2917e+04                    bc_loss 1.8635e+02\n",
      "Epoch 24710, Training-Loss 2.2179e+00, Data-loss 3.7070e-01                  , pde-loss 5.3585e+03, initc-loss 1.2956e+04                    bc_loss 1.5719e+02\n",
      "Epoch 24720, Training-Loss 2.3647e+00, Data-loss 4.4554e-01                  , pde-loss 5.7293e+03, initc-loss 1.2919e+04                    bc_loss 5.4400e+02\n",
      "Epoch 24730, Training-Loss 2.6643e+00, Data-loss 4.4411e-01                  , pde-loss 6.3521e+03, initc-loss 1.2822e+04                    bc_loss 3.0275e+03\n",
      "Epoch 24740, Training-Loss 2.2219e+00, Data-loss 3.2042e-01                  , pde-loss 4.8570e+03, initc-loss 1.2859e+04                    bc_loss 1.2990e+03\n",
      "Epoch 24750, Training-Loss 2.4632e+00, Data-loss 5.4370e-01                  , pde-loss 5.5802e+03, initc-loss 1.2974e+04                    bc_loss 6.4075e+02\n",
      "Epoch 24760, Training-Loss 2.3485e+00, Data-loss 3.9542e-01                  , pde-loss 5.6626e+03, initc-loss 1.2915e+04                    bc_loss 9.5261e+02\n",
      "Epoch 24770, Training-Loss 2.2377e+00, Data-loss 3.1840e-01                  , pde-loss 6.1088e+03, initc-loss 1.2859e+04                    bc_loss 2.2554e+02\n",
      "Epoch 24780, Training-Loss 2.3559e+00, Data-loss 3.2904e-01                  , pde-loss 7.1247e+03, initc-loss 1.2933e+04                    bc_loss 2.1070e+02\n",
      "Epoch 24790, Training-Loss 2.2864e+00, Data-loss 3.5959e-01                  , pde-loss 5.8568e+03, initc-loss 1.2902e+04                    bc_loss 5.0897e+02\n",
      "Epoch 24800, Training-Loss 2.5371e+00, Data-loss 5.4512e-01                  , pde-loss 6.7892e+03, initc-loss 1.2846e+04                    bc_loss 2.8441e+02\n",
      "Epoch 24810, Training-Loss 2.2866e+00, Data-loss 4.2673e-01                  , pde-loss 5.3988e+03, initc-loss 1.2996e+04                    bc_loss 2.0407e+02\n",
      "Epoch 24820, Training-Loss 2.3404e+00, Data-loss 3.9000e-01                  , pde-loss 6.3361e+03, initc-loss 1.2891e+04                    bc_loss 2.7672e+02\n",
      "Epoch 24830, Training-Loss 2.4992e+00, Data-loss 4.7951e-01                  , pde-loss 6.7229e+03, initc-loss 1.2931e+04                    bc_loss 5.4253e+02\n",
      "Epoch 24840, Training-Loss 2.4226e+00, Data-loss 4.6016e-01                  , pde-loss 6.2094e+03, initc-loss 1.2858e+04                    bc_loss 5.5723e+02\n",
      "Epoch 24850, Training-Loss 2.3956e+00, Data-loss 3.6721e-01                  , pde-loss 6.7315e+03, initc-loss 1.2860e+04                    bc_loss 6.9273e+02\n",
      "Epoch 24860, Training-Loss 2.4092e+00, Data-loss 5.5247e-01                  , pde-loss 5.2713e+03, initc-loss 1.2987e+04                    bc_loss 3.0840e+02\n",
      "Epoch 24870, Training-Loss 2.4410e+00, Data-loss 4.3458e-01                  , pde-loss 5.8548e+03, initc-loss 1.2847e+04                    bc_loss 1.3627e+03\n",
      "Epoch 24880, Training-Loss 2.3311e+00, Data-loss 3.8829e-01                  , pde-loss 6.2835e+03, initc-loss 1.2857e+04                    bc_loss 2.8799e+02\n",
      "Epoch 24890, Training-Loss 2.2379e+00, Data-loss 3.3547e-01                  , pde-loss 5.7959e+03, initc-loss 1.2961e+04                    bc_loss 2.6727e+02\n",
      "Epoch 24900, Training-Loss 2.3844e+00, Data-loss 4.8968e-01                  , pde-loss 5.2670e+03, initc-loss 1.2806e+04                    bc_loss 8.7378e+02\n",
      "Epoch 24910, Training-Loss 2.3332e+00, Data-loss 3.9883e-01                  , pde-loss 5.9576e+03, initc-loss 1.2941e+04                    bc_loss 4.4504e+02\n",
      "Epoch 24920, Training-Loss 2.3342e+00, Data-loss 4.0760e-01                  , pde-loss 6.0673e+03, initc-loss 1.2807e+04                    bc_loss 3.9120e+02\n",
      "Epoch 24930, Training-Loss 2.4646e+00, Data-loss 3.8764e-01                  , pde-loss 6.4186e+03, initc-loss 1.2942e+04                    bc_loss 1.4081e+03\n",
      "Epoch 24940, Training-Loss 2.4320e+00, Data-loss 5.1135e-01                  , pde-loss 4.9928e+03, initc-loss 1.2960e+04                    bc_loss 1.2533e+03\n",
      "Epoch 24950, Training-Loss 2.2679e+00, Data-loss 3.2877e-01                  , pde-loss 6.2440e+03, initc-loss 1.2908e+04                    bc_loss 2.3883e+02\n",
      "Epoch 24960, Training-Loss 2.3329e+00, Data-loss 4.7571e-01                  , pde-loss 5.5588e+03, initc-loss 1.2880e+04                    bc_loss 1.3326e+02\n",
      "Epoch 24970, Training-Loss 2.4005e+00, Data-loss 4.4750e-01                  , pde-loss 6.2991e+03, initc-loss 1.2900e+04                    bc_loss 3.3105e+02\n",
      "Epoch 24980, Training-Loss 2.3565e+00, Data-loss 4.2788e-01                  , pde-loss 6.3363e+03, initc-loss 1.2891e+04                    bc_loss 5.8787e+01\n",
      "Epoch 24990, Training-Loss 2.6135e+00, Data-loss 5.6900e-01                  , pde-loss 6.2649e+03, initc-loss 1.2962e+04                    bc_loss 1.2179e+03\n",
      "Epoch 25000, Training-Loss 2.6471e+00, Data-loss 5.4539e-01                  , pde-loss 6.9787e+03, initc-loss 1.3027e+04                    bc_loss 1.0112e+03\n",
      "Epoch 25010, Training-Loss 2.3461e+00, Data-loss 4.2235e-01                  , pde-loss 5.8473e+03, initc-loss 1.2931e+04                    bc_loss 4.5916e+02\n",
      "Epoch 25020, Training-Loss 2.6122e+00, Data-loss 6.4066e-01                  , pde-loss 6.6826e+03, initc-loss 1.2881e+04                    bc_loss 1.5175e+02\n",
      "Epoch 25030, Training-Loss 2.4688e+00, Data-loss 4.8387e-01                  , pde-loss 5.6119e+03, initc-loss 1.2966e+04                    bc_loss 1.2714e+03\n",
      "Epoch 25040, Training-Loss 2.3792e+00, Data-loss 4.6432e-01                  , pde-loss 5.9495e+03, initc-loss 1.2832e+04                    bc_loss 3.6733e+02\n",
      "Epoch 25050, Training-Loss 2.4066e+00, Data-loss 3.5776e-01                  , pde-loss 7.1427e+03, initc-loss 1.2865e+04                    bc_loss 4.8067e+02\n",
      "Epoch 25060, Training-Loss 2.3009e+00, Data-loss 3.9232e-01                  , pde-loss 5.8799e+03, initc-loss 1.2864e+04                    bc_loss 3.4132e+02\n",
      "Epoch 25070, Training-Loss 2.8869e+00, Data-loss 9.0847e-01                  , pde-loss 5.8719e+03, initc-loss 1.2810e+04                    bc_loss 1.1022e+03\n",
      "Epoch 25080, Training-Loss 2.5890e+00, Data-loss 5.4757e-01                  , pde-loss 5.9299e+03, initc-loss 1.2885e+04                    bc_loss 1.5998e+03\n",
      "Epoch 25090, Training-Loss 2.5082e+00, Data-loss 4.2159e-01                  , pde-loss 6.6116e+03, initc-loss 1.2913e+04                    bc_loss 1.3415e+03\n",
      "Epoch 25100, Training-Loss 2.8881e+00, Data-loss 8.0392e-01                  , pde-loss 6.5729e+03, initc-loss 1.2815e+04                    bc_loss 1.4541e+03\n",
      "Epoch 25110, Training-Loss 2.4412e+00, Data-loss 5.2550e-01                  , pde-loss 5.9563e+03, initc-loss 1.2983e+04                    bc_loss 2.1715e+02\n",
      "Epoch 25120, Training-Loss 2.4704e+00, Data-loss 5.7275e-01                  , pde-loss 5.6179e+03, initc-loss 1.2896e+04                    bc_loss 4.6314e+02\n",
      "Epoch 25130, Training-Loss 2.6574e+00, Data-loss 7.8593e-01                  , pde-loss 5.5613e+03, initc-loss 1.3021e+04                    bc_loss 1.3252e+02\n",
      "Epoch 25140, Training-Loss 2.3743e+00, Data-loss 3.6679e-01                  , pde-loss 6.4223e+03, initc-loss 1.2912e+04                    bc_loss 7.4113e+02\n",
      "Epoch 25150, Training-Loss 2.1959e+00, Data-loss 3.1781e-01                  , pde-loss 5.5820e+03, initc-loss 1.2876e+04                    bc_loss 3.2335e+02\n",
      "Epoch 25160, Training-Loss 2.4343e+00, Data-loss 4.0606e-01                  , pde-loss 6.4889e+03, initc-loss 1.2915e+04                    bc_loss 8.7859e+02\n",
      "Epoch 25170, Training-Loss 2.7609e+00, Data-loss 7.2360e-01                  , pde-loss 6.1874e+03, initc-loss 1.2860e+04                    bc_loss 1.3262e+03\n",
      "Epoch 25180, Training-Loss 2.3127e+00, Data-loss 3.8269e-01                  , pde-loss 5.9955e+03, initc-loss 1.2873e+04                    bc_loss 4.3151e+02\n",
      "Epoch 25190, Training-Loss 2.4866e+00, Data-loss 5.5619e-01                  , pde-loss 5.2191e+03, initc-loss 1.2844e+04                    bc_loss 1.2410e+03\n",
      "Epoch 25200, Training-Loss 2.2762e+00, Data-loss 4.0993e-01                  , pde-loss 5.3747e+03, initc-loss 1.2893e+04                    bc_loss 3.9497e+02\n",
      "Epoch 25210, Training-Loss 2.6314e+00, Data-loss 6.2352e-01                  , pde-loss 6.9989e+03, initc-loss 1.2988e+04                    bc_loss 9.2132e+01\n",
      "Epoch 25220, Training-Loss 2.4677e+00, Data-loss 3.9148e-01                  , pde-loss 5.9929e+03, initc-loss 1.2876e+04                    bc_loss 1.8929e+03\n",
      "Epoch 25230, Training-Loss 2.3435e+00, Data-loss 4.1464e-01                  , pde-loss 6.1207e+03, initc-loss 1.2992e+04                    bc_loss 1.7610e+02\n",
      "Epoch 25240, Training-Loss 2.3634e+00, Data-loss 4.3831e-01                  , pde-loss 5.8658e+03, initc-loss 1.2933e+04                    bc_loss 4.5127e+02\n",
      "Epoch 25250, Training-Loss 2.3509e+00, Data-loss 4.5778e-01                  , pde-loss 5.9730e+03, initc-loss 1.2813e+04                    bc_loss 1.4515e+02\n",
      "Epoch 25260, Training-Loss 2.3525e+00, Data-loss 4.3650e-01                  , pde-loss 6.0516e+03, initc-loss 1.2952e+04                    bc_loss 1.5621e+02\n",
      "Epoch 25270, Training-Loss 2.4822e+00, Data-loss 4.1611e-01                  , pde-loss 6.0901e+03, initc-loss 1.2963e+04                    bc_loss 1.6079e+03\n",
      "Epoch 25280, Training-Loss 2.3162e+00, Data-loss 3.2675e-01                  , pde-loss 6.6582e+03, initc-loss 1.2945e+04                    bc_loss 2.9158e+02\n",
      "Epoch 25290, Training-Loss 2.4012e+00, Data-loss 4.9294e-01                  , pde-loss 5.9976e+03, initc-loss 1.2856e+04                    bc_loss 2.2895e+02\n",
      "Epoch 25300, Training-Loss 2.3811e+00, Data-loss 4.0469e-01                  , pde-loss 6.4543e+03, initc-loss 1.2817e+04                    bc_loss 4.9204e+02\n",
      "Epoch 25310, Training-Loss 2.4973e+00, Data-loss 3.9661e-01                  , pde-loss 6.7514e+03, initc-loss 1.2890e+04                    bc_loss 1.3657e+03\n",
      "Epoch 25320, Training-Loss 2.2631e+00, Data-loss 4.3392e-01                  , pde-loss 5.1565e+03, initc-loss 1.2979e+04                    bc_loss 1.5628e+02\n",
      "Epoch 25330, Training-Loss 2.4887e+00, Data-loss 4.8432e-01                  , pde-loss 5.4379e+03, initc-loss 1.2991e+04                    bc_loss 1.6156e+03\n",
      "Epoch 25340, Training-Loss 2.4398e+00, Data-loss 4.4185e-01                  , pde-loss 5.6326e+03, initc-loss 1.2881e+04                    bc_loss 1.4658e+03\n",
      "Epoch 25350, Training-Loss 2.6575e+00, Data-loss 7.0641e-01                  , pde-loss 5.9411e+03, initc-loss 1.3111e+04                    bc_loss 4.5865e+02\n",
      "Epoch 25360, Training-Loss 2.6770e+00, Data-loss 5.9032e-01                  , pde-loss 6.6049e+03, initc-loss 1.2823e+04                    bc_loss 1.4383e+03\n",
      "Epoch 25370, Training-Loss 2.4956e+00, Data-loss 5.5104e-01                  , pde-loss 5.8352e+03, initc-loss 1.3011e+04                    bc_loss 5.9990e+02\n",
      "Epoch 25380, Training-Loss 2.2142e+00, Data-loss 3.4250e-01                  , pde-loss 5.3870e+03, initc-loss 1.2875e+04                    bc_loss 4.5468e+02\n",
      "Epoch 25390, Training-Loss 2.2492e+00, Data-loss 3.3313e-01                  , pde-loss 5.8863e+03, initc-loss 1.2897e+04                    bc_loss 3.7779e+02\n",
      "Epoch 25400, Training-Loss 2.4520e+00, Data-loss 5.5283e-01                  , pde-loss 5.9146e+03, initc-loss 1.2991e+04                    bc_loss 8.6179e+01\n",
      "Epoch 25410, Training-Loss 2.3808e+00, Data-loss 4.6452e-01                  , pde-loss 6.0536e+03, initc-loss 1.2954e+04                    bc_loss 1.5558e+02\n",
      "Epoch 25420, Training-Loss 2.4322e+00, Data-loss 4.7116e-01                  , pde-loss 6.3428e+03, initc-loss 1.3016e+04                    bc_loss 2.5180e+02\n",
      "Epoch 25430, Training-Loss 2.5286e+00, Data-loss 5.9403e-01                  , pde-loss 6.0630e+03, initc-loss 1.2796e+04                    bc_loss 4.8619e+02\n",
      "Epoch 25440, Training-Loss 2.7344e+00, Data-loss 5.8013e-01                  , pde-loss 5.7188e+03, initc-loss 1.3013e+04                    bc_loss 2.8111e+03\n",
      "Epoch 25450, Training-Loss 2.3516e+00, Data-loss 4.6239e-01                  , pde-loss 5.7846e+03, initc-loss 1.2881e+04                    bc_loss 2.2700e+02\n",
      "Epoch 25460, Training-Loss 2.3084e+00, Data-loss 3.4958e-01                  , pde-loss 5.8741e+03, initc-loss 1.2855e+04                    bc_loss 8.5894e+02\n",
      "Epoch 25470, Training-Loss 2.1409e+00, Data-loss 2.6263e-01                  , pde-loss 5.5946e+03, initc-loss 1.2887e+04                    bc_loss 3.0076e+02\n",
      "Epoch 25480, Training-Loss 2.1689e+00, Data-loss 3.5200e-01                  , pde-loss 5.1323e+03, initc-loss 1.2905e+04                    bc_loss 1.3125e+02\n",
      "Epoch 25490, Training-Loss 2.2698e+00, Data-loss 3.6905e-01                  , pde-loss 6.0150e+03, initc-loss 1.2909e+04                    bc_loss 8.4206e+01\n",
      "Epoch 25500, Training-Loss 2.2678e+00, Data-loss 3.5742e-01                  , pde-loss 5.4059e+03, initc-loss 1.2927e+04                    bc_loss 7.7076e+02\n",
      "Epoch 25510, Training-Loss 2.2799e+00, Data-loss 3.9643e-01                  , pde-loss 5.9537e+03, initc-loss 1.2859e+04                    bc_loss 2.2185e+01\n",
      "Epoch 25520, Training-Loss 2.1996e+00, Data-loss 3.2387e-01                  , pde-loss 5.6996e+03, initc-loss 1.2926e+04                    bc_loss 1.3222e+02\n",
      "Epoch 25530, Training-Loss 2.4021e+00, Data-loss 3.9985e-01                  , pde-loss 6.4440e+03, initc-loss 1.2916e+04                    bc_loss 6.6334e+02\n",
      "Epoch 25540, Training-Loss 2.5349e+00, Data-loss 5.5372e-01                  , pde-loss 6.1530e+03, initc-loss 1.2796e+04                    bc_loss 8.6288e+02\n",
      "Epoch 25550, Training-Loss 2.8018e+00, Data-loss 8.1401e-01                  , pde-loss 5.7972e+03, initc-loss 1.3002e+04                    bc_loss 1.0792e+03\n",
      "Epoch 25560, Training-Loss 2.2299e+00, Data-loss 3.5801e-01                  , pde-loss 5.6091e+03, initc-loss 1.2967e+04                    bc_loss 1.4344e+02\n",
      "Epoch 25570, Training-Loss 2.4796e+00, Data-loss 5.5085e-01                  , pde-loss 6.1621e+03, initc-loss 1.2858e+04                    bc_loss 2.6781e+02\n",
      "Epoch 25580, Training-Loss 2.3796e+00, Data-loss 4.7622e-01                  , pde-loss 5.5097e+03, initc-loss 1.2959e+04                    bc_loss 5.6501e+02\n",
      "Epoch 25590, Training-Loss 2.3820e+00, Data-loss 4.2040e-01                  , pde-loss 6.4961e+03, initc-loss 1.2971e+04                    bc_loss 1.4918e+02\n",
      "Epoch 25600, Training-Loss 2.3697e+00, Data-loss 4.1115e-01                  , pde-loss 5.8008e+03, initc-loss 1.2932e+04                    bc_loss 8.5292e+02\n",
      "Epoch 25610, Training-Loss 2.2483e+00, Data-loss 3.7966e-01                  , pde-loss 5.7580e+03, initc-loss 1.2858e+04                    bc_loss 7.0728e+01\n",
      "Epoch 25620, Training-Loss 2.3207e+00, Data-loss 4.6520e-01                  , pde-loss 5.4683e+03, initc-loss 1.2958e+04                    bc_loss 1.2849e+02\n",
      "Epoch 25630, Training-Loss 2.3814e+00, Data-loss 5.1471e-01                  , pde-loss 5.1167e+03, initc-loss 1.2880e+04                    bc_loss 6.7040e+02\n",
      "Epoch 25640, Training-Loss 2.2557e+00, Data-loss 3.4894e-01                  , pde-loss 5.7332e+03, initc-loss 1.2914e+04                    bc_loss 4.1975e+02\n",
      "Epoch 25650, Training-Loss 2.1790e+00, Data-loss 3.5595e-01                  , pde-loss 5.1409e+03, initc-loss 1.2916e+04                    bc_loss 1.7355e+02\n",
      "Epoch 25660, Training-Loss 2.2359e+00, Data-loss 3.2046e-01                  , pde-loss 6.2011e+03, initc-loss 1.2879e+04                    bc_loss 7.4918e+01\n",
      "Epoch 25670, Training-Loss 2.3419e+00, Data-loss 3.6709e-01                  , pde-loss 6.5929e+03, initc-loss 1.3014e+04                    bc_loss 1.4172e+02\n",
      "Epoch 25680, Training-Loss 2.2578e+00, Data-loss 3.9111e-01                  , pde-loss 5.3649e+03, initc-loss 1.2940e+04                    bc_loss 3.6255e+02\n",
      "Epoch 25690, Training-Loss 2.1098e+00, Data-loss 2.7138e-01                  , pde-loss 5.2791e+03, initc-loss 1.2919e+04                    bc_loss 1.8575e+02\n",
      "Epoch 25700, Training-Loss 2.2621e+00, Data-loss 3.1223e-01                  , pde-loss 6.3514e+03, initc-loss 1.2854e+04                    bc_loss 2.9305e+02\n",
      "Epoch 25710, Training-Loss 2.5319e+00, Data-loss 5.3680e-01                  , pde-loss 6.7834e+03, initc-loss 1.3014e+04                    bc_loss 1.5325e+02\n",
      "Epoch 25720, Training-Loss 2.1916e+00, Data-loss 2.8122e-01                  , pde-loss 6.2108e+03, initc-loss 1.2854e+04                    bc_loss 3.9135e+01\n",
      "Epoch 25730, Training-Loss 2.2355e+00, Data-loss 3.0151e-01                  , pde-loss 6.2197e+03, initc-loss 1.2905e+04                    bc_loss 2.1498e+02\n",
      "Epoch 25740, Training-Loss 2.3005e+00, Data-loss 4.3588e-01                  , pde-loss 5.1002e+03, initc-loss 1.2891e+04                    bc_loss 6.5473e+02\n",
      "Epoch 25750, Training-Loss 2.2865e+00, Data-loss 3.9959e-01                  , pde-loss 5.4533e+03, initc-loss 1.2994e+04                    bc_loss 4.2164e+02\n",
      "Epoch 25760, Training-Loss 2.2197e+00, Data-loss 3.6359e-01                  , pde-loss 5.5890e+03, initc-loss 1.2897e+04                    bc_loss 7.5597e+01\n",
      "Epoch 25770, Training-Loss 2.4187e+00, Data-loss 5.3363e-01                  , pde-loss 5.5290e+03, initc-loss 1.2917e+04                    bc_loss 4.0452e+02\n",
      "Epoch 25780, Training-Loss 2.4266e+00, Data-loss 4.4999e-01                  , pde-loss 6.5420e+03, initc-loss 1.2984e+04                    bc_loss 2.4047e+02\n",
      "Epoch 25790, Training-Loss 2.2384e+00, Data-loss 3.5652e-01                  , pde-loss 5.8032e+03, initc-loss 1.2842e+04                    bc_loss 1.7282e+02\n",
      "Epoch 25800, Training-Loss 2.3998e+00, Data-loss 5.3982e-01                  , pde-loss 5.4379e+03, initc-loss 1.2969e+04                    bc_loss 1.9359e+02\n",
      "Epoch 25810, Training-Loss 2.2641e+00, Data-loss 4.0185e-01                  , pde-loss 5.6030e+03, initc-loss 1.2918e+04                    bc_loss 1.0100e+02\n",
      "Epoch 25820, Training-Loss 2.3353e+00, Data-loss 4.5826e-01                  , pde-loss 5.8584e+03, initc-loss 1.2824e+04                    bc_loss 8.7712e+01\n",
      "Epoch 25830, Training-Loss 2.3163e+00, Data-loss 4.1304e-01                  , pde-loss 5.8477e+03, initc-loss 1.2831e+04                    bc_loss 3.5406e+02\n",
      "Epoch 25840, Training-Loss 2.2568e+00, Data-loss 2.9727e-01                  , pde-loss 6.2182e+03, initc-loss 1.2936e+04                    bc_loss 4.4131e+02\n",
      "Epoch 25850, Training-Loss 2.4166e+00, Data-loss 4.9851e-01                  , pde-loss 5.3813e+03, initc-loss 1.2987e+04                    bc_loss 8.1269e+02\n",
      "Epoch 25860, Training-Loss 2.2220e+00, Data-loss 3.5690e-01                  , pde-loss 5.5355e+03, initc-loss 1.2953e+04                    bc_loss 1.6216e+02\n",
      "Epoch 25870, Training-Loss 2.4057e+00, Data-loss 4.9724e-01                  , pde-loss 6.1529e+03, initc-loss 1.2810e+04                    bc_loss 1.2108e+02\n",
      "Epoch 25880, Training-Loss 2.2385e+00, Data-loss 3.7100e-01                  , pde-loss 5.4594e+03, initc-loss 1.2848e+04                    bc_loss 3.6754e+02\n",
      "Epoch 25890, Training-Loss 3.1376e+00, Data-loss 1.1356e+00                  , pde-loss 5.7939e+03, initc-loss 1.3043e+04                    bc_loss 1.1831e+03\n",
      "Epoch 25900, Training-Loss 2.4513e+00, Data-loss 4.8933e-01                  , pde-loss 6.2253e+03, initc-loss 1.2943e+04                    bc_loss 4.5162e+02\n",
      "Epoch 25910, Training-Loss 2.4951e+00, Data-loss 5.2652e-01                  , pde-loss 6.6210e+03, initc-loss 1.2918e+04                    bc_loss 1.4657e+02\n",
      "Epoch 25920, Training-Loss 2.6901e+00, Data-loss 7.0348e-01                  , pde-loss 6.1074e+03, initc-loss 1.2890e+04                    bc_loss 8.6916e+02\n",
      "Epoch 25930, Training-Loss 2.3076e+00, Data-loss 4.0470e-01                  , pde-loss 5.8741e+03, initc-loss 1.2907e+04                    bc_loss 2.4760e+02\n",
      "Epoch 25940, Training-Loss 2.5624e+00, Data-loss 4.5753e-01                  , pde-loss 6.2690e+03, initc-loss 1.2873e+04                    bc_loss 1.9067e+03\n",
      "Epoch 25950, Training-Loss 2.4980e+00, Data-loss 5.1258e-01                  , pde-loss 5.8451e+03, initc-loss 1.2894e+04                    bc_loss 1.1149e+03\n",
      "Epoch 25960, Training-Loss 2.9843e+00, Data-loss 8.7804e-01                  , pde-loss 6.4273e+03, initc-loss 1.2972e+04                    bc_loss 1.6640e+03\n",
      "Epoch 25970, Training-Loss 2.2514e+00, Data-loss 3.5105e-01                  , pde-loss 5.9933e+03, initc-loss 1.2905e+04                    bc_loss 1.0506e+02\n",
      "Epoch 25980, Training-Loss 2.2222e+00, Data-loss 3.1012e-01                  , pde-loss 5.7876e+03, initc-loss 1.2938e+04                    bc_loss 3.9551e+02\n",
      "Epoch 25990, Training-Loss 2.1630e+00, Data-loss 2.7794e-01                  , pde-loss 5.4283e+03, initc-loss 1.2927e+04                    bc_loss 4.9530e+02\n",
      "Epoch 26000, Training-Loss 2.6540e+00, Data-loss 6.5012e-01                  , pde-loss 6.2393e+03, initc-loss 1.2938e+04                    bc_loss 8.6174e+02\n",
      "Epoch 26010, Training-Loss 2.4692e+00, Data-loss 4.9142e-01                  , pde-loss 5.2347e+03, initc-loss 1.2883e+04                    bc_loss 1.6602e+03\n",
      "Epoch 26020, Training-Loss 2.3721e+00, Data-loss 4.0628e-01                  , pde-loss 6.5523e+03, initc-loss 1.2943e+04                    bc_loss 1.6342e+02\n",
      "Epoch 26030, Training-Loss 2.3936e+00, Data-loss 3.8441e-01                  , pde-loss 6.8047e+03, initc-loss 1.2915e+04                    bc_loss 3.7233e+02\n",
      "Epoch 26040, Training-Loss 2.4065e+00, Data-loss 5.0775e-01                  , pde-loss 5.9146e+03, initc-loss 1.3007e+04                    bc_loss 6.5928e+01\n",
      "Epoch 26050, Training-Loss 2.2273e+00, Data-loss 2.8841e-01                  , pde-loss 5.7830e+03, initc-loss 1.2958e+04                    bc_loss 6.4770e+02\n",
      "Epoch 26060, Training-Loss 2.2563e+00, Data-loss 4.2468e-01                  , pde-loss 5.2915e+03, initc-loss 1.2890e+04                    bc_loss 1.3497e+02\n",
      "Epoch 26070, Training-Loss 2.3088e+00, Data-loss 3.7704e-01                  , pde-loss 6.2662e+03, initc-loss 1.2872e+04                    bc_loss 1.7957e+02\n",
      "Epoch 26080, Training-Loss 3.0406e+00, Data-loss 9.1553e-01                  , pde-loss 6.5528e+03, initc-loss 1.2786e+04                    bc_loss 1.9122e+03\n",
      "Epoch 26090, Training-Loss 2.2785e+00, Data-loss 4.3682e-01                  , pde-loss 5.1307e+03, initc-loss 1.2971e+04                    bc_loss 3.1555e+02\n",
      "Epoch 26100, Training-Loss 2.4537e+00, Data-loss 4.5390e-01                  , pde-loss 6.7378e+03, initc-loss 1.2910e+04                    bc_loss 3.4982e+02\n",
      "Epoch 26110, Training-Loss 2.5517e+00, Data-loss 6.2902e-01                  , pde-loss 5.6750e+03, initc-loss 1.2968e+04                    bc_loss 5.8461e+02\n",
      "Epoch 26120, Training-Loss 2.5902e+00, Data-loss 5.6377e-01                  , pde-loss 5.9713e+03, initc-loss 1.2881e+04                    bc_loss 1.4122e+03\n",
      "Epoch 26130, Training-Loss 2.2429e+00, Data-loss 3.1427e-01                  , pde-loss 5.9765e+03, initc-loss 1.2929e+04                    bc_loss 3.8061e+02\n",
      "Epoch 26140, Training-Loss 2.3356e+00, Data-loss 4.5486e-01                  , pde-loss 5.6703e+03, initc-loss 1.2958e+04                    bc_loss 1.7867e+02\n",
      "Epoch 26150, Training-Loss 2.3837e+00, Data-loss 5.2206e-01                  , pde-loss 4.9359e+03, initc-loss 1.2976e+04                    bc_loss 7.0440e+02\n",
      "Epoch 26160, Training-Loss 2.5198e+00, Data-loss 4.7437e-01                  , pde-loss 7.1083e+03, initc-loss 1.2946e+04                    bc_loss 4.0023e+02\n",
      "Epoch 26170, Training-Loss 2.1986e+00, Data-loss 3.5714e-01                  , pde-loss 5.2533e+03, initc-loss 1.2917e+04                    bc_loss 2.4417e+02\n",
      "Epoch 26180, Training-Loss 2.4112e+00, Data-loss 4.8758e-01                  , pde-loss 5.7466e+03, initc-loss 1.2869e+04                    bc_loss 6.2032e+02\n",
      "Epoch 26190, Training-Loss 2.3600e+00, Data-loss 2.8543e-01                  , pde-loss 6.8561e+03, initc-loss 1.2960e+04                    bc_loss 9.2953e+02\n",
      "Epoch 26200, Training-Loss 2.2720e+00, Data-loss 4.4640e-01                  , pde-loss 4.9446e+03, initc-loss 1.2889e+04                    bc_loss 4.2222e+02\n",
      "Epoch 26210, Training-Loss 2.2540e+00, Data-loss 4.0335e-01                  , pde-loss 5.1404e+03, initc-loss 1.2849e+04                    bc_loss 5.1731e+02\n",
      "Epoch 26220, Training-Loss 2.3812e+00, Data-loss 4.3604e-01                  , pde-loss 6.0067e+03, initc-loss 1.2856e+04                    bc_loss 5.8906e+02\n",
      "Epoch 26230, Training-Loss 2.2411e+00, Data-loss 3.9870e-01                  , pde-loss 5.2920e+03, initc-loss 1.2912e+04                    bc_loss 2.1992e+02\n",
      "Epoch 26240, Training-Loss 2.3462e+00, Data-loss 4.2093e-01                  , pde-loss 6.1792e+03, initc-loss 1.2899e+04                    bc_loss 1.7490e+02\n",
      "Epoch 26250, Training-Loss 2.4439e+00, Data-loss 5.9347e-01                  , pde-loss 5.5264e+03, initc-loss 1.2828e+04                    bc_loss 1.5009e+02\n",
      "Epoch 26260, Training-Loss 2.3148e+00, Data-loss 3.3196e-01                  , pde-loss 6.4016e+03, initc-loss 1.2900e+04                    bc_loss 5.2714e+02\n",
      "Epoch 26270, Training-Loss 2.3372e+00, Data-loss 4.7405e-01                  , pde-loss 5.6673e+03, initc-loss 1.2851e+04                    bc_loss 1.1373e+02\n",
      "Epoch 26280, Training-Loss 2.6621e+00, Data-loss 6.5909e-01                  , pde-loss 6.3108e+03, initc-loss 1.2964e+04                    bc_loss 7.5521e+02\n",
      "Epoch 26290, Training-Loss 2.4733e+00, Data-loss 5.2682e-01                  , pde-loss 5.9553e+03, initc-loss 1.2848e+04                    bc_loss 6.6097e+02\n",
      "Epoch 26300, Training-Loss 2.4440e+00, Data-loss 5.3511e-01                  , pde-loss 6.0106e+03, initc-loss 1.2891e+04                    bc_loss 1.8749e+02\n",
      "Epoch 26310, Training-Loss 2.5438e+00, Data-loss 5.5390e-01                  , pde-loss 5.9503e+03, initc-loss 1.2963e+04                    bc_loss 9.8549e+02\n",
      "Epoch 26320, Training-Loss 3.0729e+00, Data-loss 9.6621e-01                  , pde-loss 5.8976e+03, initc-loss 1.2818e+04                    bc_loss 2.3511e+03\n",
      "Epoch 26330, Training-Loss 2.2994e+00, Data-loss 3.9717e-01                  , pde-loss 5.1523e+03, initc-loss 1.2864e+04                    bc_loss 1.0059e+03\n",
      "Epoch 26340, Training-Loss 2.4464e+00, Data-loss 4.2370e-01                  , pde-loss 6.5547e+03, initc-loss 1.2969e+04                    bc_loss 7.0337e+02\n",
      "Epoch 26350, Training-Loss 2.3491e+00, Data-loss 3.5004e-01                  , pde-loss 5.9139e+03, initc-loss 1.2971e+04                    bc_loss 1.1056e+03\n",
      "Epoch 26360, Training-Loss 2.3165e+00, Data-loss 3.9967e-01                  , pde-loss 5.9682e+03, initc-loss 1.2909e+04                    bc_loss 2.9178e+02\n",
      "Epoch 26370, Training-Loss 2.3217e+00, Data-loss 4.2159e-01                  , pde-loss 5.2503e+03, initc-loss 1.2987e+04                    bc_loss 7.6399e+02\n",
      "Epoch 26380, Training-Loss 2.4688e+00, Data-loss 5.7518e-01                  , pde-loss 5.4244e+03, initc-loss 1.2862e+04                    bc_loss 6.4992e+02\n",
      "Epoch 26390, Training-Loss 2.5111e+00, Data-loss 4.9490e-01                  , pde-loss 6.5713e+03, initc-loss 1.2954e+04                    bc_loss 6.3705e+02\n",
      "Epoch 26400, Training-Loss 2.7069e+00, Data-loss 6.6334e-01                  , pde-loss 5.7788e+03, initc-loss 1.2813e+04                    bc_loss 1.8440e+03\n",
      "Epoch 26410, Training-Loss 2.4707e+00, Data-loss 4.6983e-01                  , pde-loss 6.3061e+03, initc-loss 1.2945e+04                    bc_loss 7.5717e+02\n",
      "Epoch 26420, Training-Loss 2.3677e+00, Data-loss 3.9753e-01                  , pde-loss 5.9364e+03, initc-loss 1.2910e+04                    bc_loss 8.5529e+02\n",
      "Epoch 26430, Training-Loss 2.2692e+00, Data-loss 3.2981e-01                  , pde-loss 6.2667e+03, initc-loss 1.2913e+04                    bc_loss 2.1363e+02\n",
      "Epoch 26440, Training-Loss 2.3833e+00, Data-loss 3.9427e-01                  , pde-loss 6.5270e+03, initc-loss 1.2943e+04                    bc_loss 4.1955e+02\n",
      "Epoch 26450, Training-Loss 2.3192e+00, Data-loss 4.2946e-01                  , pde-loss 5.5147e+03, initc-loss 1.2871e+04                    bc_loss 5.1229e+02\n",
      "Epoch 26460, Training-Loss 2.3495e+00, Data-loss 3.0445e-01                  , pde-loss 5.4639e+03, initc-loss 1.2915e+04                    bc_loss 2.0717e+03\n",
      "Epoch 26470, Training-Loss 2.2583e+00, Data-loss 4.1942e-01                  , pde-loss 5.4656e+03, initc-loss 1.2885e+04                    bc_loss 3.8010e+01\n",
      "Epoch 26480, Training-Loss 2.2330e+00, Data-loss 3.5747e-01                  , pde-loss 5.7131e+03, initc-loss 1.2875e+04                    bc_loss 1.6643e+02\n",
      "Epoch 26490, Training-Loss 2.1760e+00, Data-loss 2.9882e-01                  , pde-loss 5.6918e+03, initc-loss 1.2914e+04                    bc_loss 1.6627e+02\n",
      "Epoch 26500, Training-Loss 2.1119e+00, Data-loss 2.8658e-01                  , pde-loss 5.1571e+03, initc-loss 1.2957e+04                    bc_loss 1.3932e+02\n",
      "Epoch 26510, Training-Loss 2.2200e+00, Data-loss 3.4895e-01                  , pde-loss 5.6719e+03, initc-loss 1.2856e+04                    bc_loss 1.8207e+02\n",
      "Epoch 26520, Training-Loss 2.3719e+00, Data-loss 4.6316e-01                  , pde-loss 5.8801e+03, initc-loss 1.2996e+04                    bc_loss 2.1132e+02\n",
      "Epoch 26530, Training-Loss 2.2643e+00, Data-loss 3.5210e-01                  , pde-loss 5.9588e+03, initc-loss 1.2923e+04                    bc_loss 2.3948e+02\n",
      "Epoch 26540, Training-Loss 2.1589e+00, Data-loss 2.8733e-01                  , pde-loss 5.6342e+03, initc-loss 1.2899e+04                    bc_loss 1.8328e+02\n",
      "Epoch 26550, Training-Loss 2.3760e+00, Data-loss 4.0284e-01                  , pde-loss 6.6590e+03, initc-loss 1.2896e+04                    bc_loss 1.7600e+02\n",
      "Epoch 26560, Training-Loss 2.3336e+00, Data-loss 3.9915e-01                  , pde-loss 6.2930e+03, initc-loss 1.2879e+04                    bc_loss 1.7186e+02\n",
      "Epoch 26570, Training-Loss 2.2769e+00, Data-loss 3.1261e-01                  , pde-loss 6.5192e+03, initc-loss 1.2855e+04                    bc_loss 2.6944e+02\n",
      "Epoch 26580, Training-Loss 2.2645e+00, Data-loss 4.1167e-01                  , pde-loss 5.5828e+03, initc-loss 1.2919e+04                    bc_loss 2.6123e+01\n",
      "Epoch 26590, Training-Loss 2.2268e+00, Data-loss 3.2306e-01                  , pde-loss 5.8323e+03, initc-loss 1.2942e+04                    bc_loss 2.6360e+02\n",
      "Epoch 26600, Training-Loss 2.6486e+00, Data-loss 7.4286e-01                  , pde-loss 5.6806e+03, initc-loss 1.2992e+04                    bc_loss 3.8458e+02\n",
      "Epoch 26610, Training-Loss 2.5613e+00, Data-loss 5.3320e-01                  , pde-loss 6.0462e+03, initc-loss 1.2871e+04                    bc_loss 1.3633e+03\n",
      "Epoch 26620, Training-Loss 2.5623e+00, Data-loss 4.9438e-01                  , pde-loss 6.5457e+03, initc-loss 1.2917e+04                    bc_loss 1.2166e+03\n",
      "Epoch 26630, Training-Loss 2.5025e+00, Data-loss 5.7585e-01                  , pde-loss 5.7867e+03, initc-loss 1.2787e+04                    bc_loss 6.9339e+02\n",
      "Epoch 26640, Training-Loss 2.4691e+00, Data-loss 4.8240e-01                  , pde-loss 6.4484e+03, initc-loss 1.2914e+04                    bc_loss 5.0532e+02\n",
      "Epoch 26650, Training-Loss 2.1813e+00, Data-loss 3.5896e-01                  , pde-loss 5.0278e+03, initc-loss 1.2967e+04                    bc_loss 2.2830e+02\n",
      "Epoch 26660, Training-Loss 2.4329e+00, Data-loss 5.5632e-01                  , pde-loss 5.4875e+03, initc-loss 1.2963e+04                    bc_loss 3.1512e+02\n",
      "Epoch 26670, Training-Loss 2.4929e+00, Data-loss 4.9999e-01                  , pde-loss 6.0366e+03, initc-loss 1.2847e+04                    bc_loss 1.0447e+03\n",
      "Epoch 26680, Training-Loss 2.3598e+00, Data-loss 4.0156e-01                  , pde-loss 6.4931e+03, initc-loss 1.2922e+04                    bc_loss 1.6728e+02\n",
      "Epoch 26690, Training-Loss 2.2184e+00, Data-loss 3.6582e-01                  , pde-loss 5.4604e+03, initc-loss 1.2928e+04                    bc_loss 1.3728e+02\n",
      "Epoch 26700, Training-Loss 2.3269e+00, Data-loss 3.8328e-01                  , pde-loss 6.3970e+03, initc-loss 1.2894e+04                    bc_loss 1.4506e+02\n",
      "Epoch 26710, Training-Loss 2.2574e+00, Data-loss 3.4451e-01                  , pde-loss 5.7152e+03, initc-loss 1.2905e+04                    bc_loss 5.0897e+02\n",
      "Epoch 26720, Training-Loss 2.4078e+00, Data-loss 4.4536e-01                  , pde-loss 6.6117e+03, initc-loss 1.2959e+04                    bc_loss 5.3128e+01\n",
      "Epoch 26730, Training-Loss 2.1554e+00, Data-loss 2.7298e-01                  , pde-loss 5.6853e+03, initc-loss 1.2891e+04                    bc_loss 2.4797e+02\n",
      "Epoch 26740, Training-Loss 2.3618e+00, Data-loss 4.0513e-01                  , pde-loss 6.2667e+03, initc-loss 1.2850e+04                    bc_loss 4.5013e+02\n",
      "Epoch 26750, Training-Loss 2.7726e+00, Data-loss 8.8710e-01                  , pde-loss 5.7288e+03, initc-loss 1.3007e+04                    bc_loss 1.1976e+02\n",
      "Epoch 26760, Training-Loss 2.4645e+00, Data-loss 5.6204e-01                  , pde-loss 5.7808e+03, initc-loss 1.2877e+04                    bc_loss 3.6759e+02\n",
      "Epoch 26770, Training-Loss 2.3092e+00, Data-loss 3.1921e-01                  , pde-loss 6.5303e+03, initc-loss 1.2844e+04                    bc_loss 5.2622e+02\n",
      "Epoch 26780, Training-Loss 2.3100e+00, Data-loss 3.4441e-01                  , pde-loss 5.8979e+03, initc-loss 1.2913e+04                    bc_loss 8.4455e+02\n",
      "Epoch 26790, Training-Loss 2.2501e+00, Data-loss 3.1716e-01                  , pde-loss 6.1086e+03, initc-loss 1.2832e+04                    bc_loss 3.8911e+02\n",
      "Epoch 26800, Training-Loss 2.3403e+00, Data-loss 4.1176e-01                  , pde-loss 6.3046e+03, initc-loss 1.2952e+04                    bc_loss 2.9635e+01\n",
      "Epoch 26810, Training-Loss 2.2730e+00, Data-loss 3.3366e-01                  , pde-loss 5.9460e+03, initc-loss 1.2864e+04                    bc_loss 5.8369e+02\n",
      "Epoch 26820, Training-Loss 2.2707e+00, Data-loss 3.6331e-01                  , pde-loss 5.9411e+03, initc-loss 1.2980e+04                    bc_loss 1.5253e+02\n",
      "Epoch 26830, Training-Loss 2.3187e+00, Data-loss 4.1724e-01                  , pde-loss 5.9870e+03, initc-loss 1.2902e+04                    bc_loss 1.2538e+02\n",
      "Epoch 26840, Training-Loss 2.2456e+00, Data-loss 3.5327e-01                  , pde-loss 5.8198e+03, initc-loss 1.2906e+04                    bc_loss 1.9711e+02\n",
      "Epoch 26850, Training-Loss 2.1597e+00, Data-loss 3.3235e-01                  , pde-loss 5.2667e+03, initc-loss 1.2901e+04                    bc_loss 1.0540e+02\n",
      "Epoch 26860, Training-Loss 2.3293e+00, Data-loss 4.3330e-01                  , pde-loss 5.8791e+03, initc-loss 1.2834e+04                    bc_loss 2.4680e+02\n",
      "Epoch 26870, Training-Loss 2.2880e+00, Data-loss 3.8984e-01                  , pde-loss 5.9434e+03, initc-loss 1.2899e+04                    bc_loss 1.3966e+02\n",
      "Epoch 26880, Training-Loss 2.2874e+00, Data-loss 2.6439e-01                  , pde-loss 6.4790e+03, initc-loss 1.2961e+04                    bc_loss 7.8925e+02\n",
      "Epoch 26890, Training-Loss 2.3783e+00, Data-loss 2.8649e-01                  , pde-loss 7.5159e+03, initc-loss 1.2903e+04                    bc_loss 4.9978e+02\n",
      "Epoch 26900, Training-Loss 2.4694e+00, Data-loss 4.4194e-01                  , pde-loss 6.8517e+03, initc-loss 1.2988e+04                    bc_loss 4.3451e+02\n",
      "Epoch 26910, Training-Loss 2.7445e+00, Data-loss 7.8745e-01                  , pde-loss 6.4068e+03, initc-loss 1.2778e+04                    bc_loss 3.8548e+02\n",
      "Epoch 26920, Training-Loss 2.3775e+00, Data-loss 4.2675e-01                  , pde-loss 6.2402e+03, initc-loss 1.3008e+04                    bc_loss 2.5865e+02\n",
      "Epoch 26930, Training-Loss 2.3194e+00, Data-loss 4.5215e-01                  , pde-loss 5.6946e+03, initc-loss 1.2864e+04                    bc_loss 1.1427e+02\n",
      "Epoch 26940, Training-Loss 2.3173e+00, Data-loss 2.6359e-01                  , pde-loss 6.4296e+03, initc-loss 1.3006e+04                    bc_loss 1.1022e+03\n",
      "Epoch 26950, Training-Loss 2.2489e+00, Data-loss 3.5841e-01                  , pde-loss 5.7617e+03, initc-loss 1.3012e+04                    bc_loss 1.3111e+02\n",
      "Epoch 26960, Training-Loss 2.2051e+00, Data-loss 3.0634e-01                  , pde-loss 5.8921e+03, initc-loss 1.2988e+04                    bc_loss 1.0771e+02\n",
      "Epoch 26970, Training-Loss 2.2145e+00, Data-loss 2.4558e-01                  , pde-loss 6.3550e+03, initc-loss 1.2943e+04                    bc_loss 3.9109e+02\n",
      "Epoch 26980, Training-Loss 2.5084e+00, Data-loss 4.8326e-01                  , pde-loss 6.0763e+03, initc-loss 1.2895e+04                    bc_loss 1.2797e+03\n",
      "Epoch 26990, Training-Loss 2.2785e+00, Data-loss 3.3812e-01                  , pde-loss 6.4601e+03, initc-loss 1.2893e+04                    bc_loss 5.0546e+01\n",
      "Epoch 27000, Training-Loss 2.4763e+00, Data-loss 5.7474e-01                  , pde-loss 5.9354e+03, initc-loss 1.2888e+04                    bc_loss 1.9219e+02\n",
      "Epoch 27010, Training-Loss 2.3359e+00, Data-loss 4.1113e-01                  , pde-loss 6.1232e+03, initc-loss 1.2927e+04                    bc_loss 1.9729e+02\n",
      "Epoch 27020, Training-Loss 2.3725e+00, Data-loss 4.8198e-01                  , pde-loss 5.8004e+03, initc-loss 1.2937e+04                    bc_loss 1.6828e+02\n",
      "Epoch 27030, Training-Loss 2.4458e+00, Data-loss 5.1235e-01                  , pde-loss 5.7050e+03, initc-loss 1.2862e+04                    bc_loss 7.6719e+02\n",
      "Epoch 27040, Training-Loss 2.1880e+00, Data-loss 2.4434e-01                  , pde-loss 6.2928e+03, initc-loss 1.3017e+04                    bc_loss 1.2685e+02\n",
      "Epoch 27050, Training-Loss 2.3807e+00, Data-loss 4.7621e-01                  , pde-loss 5.7898e+03, initc-loss 1.2884e+04                    bc_loss 3.7190e+02\n",
      "Epoch 27060, Training-Loss 2.2596e+00, Data-loss 2.8889e-01                  , pde-loss 6.2967e+03, initc-loss 1.2920e+04                    bc_loss 4.9057e+02\n",
      "Epoch 27070, Training-Loss 2.3399e+00, Data-loss 3.8458e-01                  , pde-loss 6.3546e+03, initc-loss 1.2911e+04                    bc_loss 2.8702e+02\n",
      "Epoch 27080, Training-Loss 2.2272e+00, Data-loss 3.0552e-01                  , pde-loss 6.1225e+03, initc-loss 1.2961e+04                    bc_loss 1.3291e+02\n",
      "Epoch 27090, Training-Loss 2.3072e+00, Data-loss 3.6606e-01                  , pde-loss 6.4853e+03, initc-loss 1.2872e+04                    bc_loss 5.4107e+01\n",
      "Epoch 27100, Training-Loss 2.5307e+00, Data-loss 6.1035e-01                  , pde-loss 6.1954e+03, initc-loss 1.2852e+04                    bc_loss 1.5642e+02\n",
      "Epoch 27110, Training-Loss 2.4728e+00, Data-loss 5.1334e-01                  , pde-loss 5.7520e+03, initc-loss 1.3000e+04                    bc_loss 8.4313e+02\n",
      "Epoch 27120, Training-Loss 2.3031e+00, Data-loss 3.6541e-01                  , pde-loss 6.3735e+03, initc-loss 1.2843e+04                    bc_loss 1.6005e+02\n",
      "Epoch 27130, Training-Loss 2.3511e+00, Data-loss 4.2578e-01                  , pde-loss 5.8467e+03, initc-loss 1.2862e+04                    bc_loss 5.4466e+02\n",
      "Epoch 27140, Training-Loss 2.2698e+00, Data-loss 4.0098e-01                  , pde-loss 5.5076e+03, initc-loss 1.2914e+04                    bc_loss 2.6725e+02\n",
      "Epoch 27150, Training-Loss 2.2607e+00, Data-loss 4.2391e-01                  , pde-loss 5.3123e+03, initc-loss 1.2796e+04                    bc_loss 2.5941e+02\n",
      "Epoch 27160, Training-Loss 2.6484e+00, Data-loss 5.6231e-01                  , pde-loss 6.3853e+03, initc-loss 1.3046e+04                    bc_loss 1.4291e+03\n",
      "Epoch 27170, Training-Loss 2.3209e+00, Data-loss 3.8796e-01                  , pde-loss 5.5726e+03, initc-loss 1.2897e+04                    bc_loss 8.6079e+02\n",
      "Epoch 27180, Training-Loss 2.3347e+00, Data-loss 4.0495e-01                  , pde-loss 6.2194e+03, initc-loss 1.2935e+04                    bc_loss 1.4274e+02\n",
      "Epoch 27190, Training-Loss 2.3328e+00, Data-loss 4.3542e-01                  , pde-loss 5.8246e+03, initc-loss 1.2943e+04                    bc_loss 2.0615e+02\n",
      "Epoch 27200, Training-Loss 2.3621e+00, Data-loss 4.2247e-01                  , pde-loss 6.2941e+03, initc-loss 1.2947e+04                    bc_loss 1.5474e+02\n",
      "Epoch 27210, Training-Loss 2.2675e+00, Data-loss 3.8390e-01                  , pde-loss 5.4405e+03, initc-loss 1.3038e+04                    bc_loss 3.5693e+02\n",
      "Epoch 27220, Training-Loss 2.2921e+00, Data-loss 3.4996e-01                  , pde-loss 6.5324e+03, initc-loss 1.2853e+04                    bc_loss 3.5764e+01\n",
      "Epoch 27230, Training-Loss 2.7368e+00, Data-loss 6.8798e-01                  , pde-loss 5.7475e+03, initc-loss 1.2978e+04                    bc_loss 1.7626e+03\n",
      "Epoch 27240, Training-Loss 2.3871e+00, Data-loss 5.2420e-01                  , pde-loss 5.6176e+03, initc-loss 1.2792e+04                    bc_loss 2.1899e+02\n",
      "Epoch 27250, Training-Loss 2.1754e+00, Data-loss 3.2424e-01                  , pde-loss 5.3413e+03, initc-loss 1.2949e+04                    bc_loss 2.2183e+02\n",
      "Epoch 27260, Training-Loss 2.2419e+00, Data-loss 4.0261e-01                  , pde-loss 5.4077e+03, initc-loss 1.2911e+04                    bc_loss 7.4051e+01\n",
      "Epoch 27270, Training-Loss 2.1549e+00, Data-loss 2.9190e-01                  , pde-loss 5.4474e+03, initc-loss 1.2888e+04                    bc_loss 2.9528e+02\n",
      "Epoch 27280, Training-Loss 2.5029e+00, Data-loss 4.9884e-01                  , pde-loss 5.5268e+03, initc-loss 1.3008e+04                    bc_loss 1.5058e+03\n",
      "Epoch 27290, Training-Loss 2.4573e+00, Data-loss 3.7792e-01                  , pde-loss 7.2266e+03, initc-loss 1.2968e+04                    bc_loss 5.9938e+02\n",
      "Epoch 27300, Training-Loss 2.3702e+00, Data-loss 3.9503e-01                  , pde-loss 6.5717e+03, initc-loss 1.2953e+04                    bc_loss 2.2705e+02\n",
      "Epoch 27310, Training-Loss 2.3932e+00, Data-loss 4.0085e-01                  , pde-loss 6.8283e+03, initc-loss 1.2924e+04                    bc_loss 1.7064e+02\n",
      "Epoch 27320, Training-Loss 2.2992e+00, Data-loss 3.7982e-01                  , pde-loss 6.1567e+03, initc-loss 1.2883e+04                    bc_loss 1.5392e+02\n",
      "Epoch 27330, Training-Loss 2.5570e+00, Data-loss 5.4357e-01                  , pde-loss 7.1210e+03, initc-loss 1.2949e+04                    bc_loss 6.4105e+01\n",
      "Epoch 27340, Training-Loss 2.8289e+00, Data-loss 8.9930e-01                  , pde-loss 6.1135e+03, initc-loss 1.3040e+04                    bc_loss 1.4304e+02\n",
      "Epoch 27350, Training-Loss 2.8604e+00, Data-loss 8.3420e-01                  , pde-loss 5.2147e+03, initc-loss 1.2826e+04                    bc_loss 2.2211e+03\n",
      "Epoch 27360, Training-Loss 2.2686e+00, Data-loss 3.7721e-01                  , pde-loss 5.6953e+03, initc-loss 1.2901e+04                    bc_loss 3.1766e+02\n",
      "Epoch 27370, Training-Loss 2.3935e+00, Data-loss 5.1197e-01                  , pde-loss 5.6874e+03, initc-loss 1.2989e+04                    bc_loss 1.3877e+02\n",
      "Epoch 27380, Training-Loss 2.2219e+00, Data-loss 2.8047e-01                  , pde-loss 6.2943e+03, initc-loss 1.2892e+04                    bc_loss 2.2784e+02\n",
      "Epoch 27390, Training-Loss 2.2925e+00, Data-loss 4.0216e-01                  , pde-loss 5.9669e+03, initc-loss 1.2828e+04                    bc_loss 1.0803e+02\n",
      "Epoch 27400, Training-Loss 2.1544e+00, Data-loss 3.0786e-01                  , pde-loss 5.4556e+03, initc-loss 1.2942e+04                    bc_loss 6.7018e+01\n",
      "Epoch 27410, Training-Loss 2.2672e+00, Data-loss 4.1339e-01                  , pde-loss 5.3909e+03, initc-loss 1.2898e+04                    bc_loss 2.4853e+02\n",
      "Epoch 27420, Training-Loss 2.4865e+00, Data-loss 4.8252e-01                  , pde-loss 6.8434e+03, initc-loss 1.3025e+04                    bc_loss 1.7122e+02\n",
      "Epoch 27430, Training-Loss 2.3109e+00, Data-loss 4.5453e-01                  , pde-loss 5.5183e+03, initc-loss 1.2898e+04                    bc_loss 1.4832e+02\n",
      "Epoch 27440, Training-Loss 2.3465e+00, Data-loss 4.0837e-01                  , pde-loss 6.4249e+03, initc-loss 1.2903e+04                    bc_loss 5.2754e+01\n",
      "Epoch 27450, Training-Loss 2.5406e+00, Data-loss 5.4120e-01                  , pde-loss 6.5601e+03, initc-loss 1.2988e+04                    bc_loss 4.4636e+02\n",
      "Epoch 27460, Training-Loss 2.3252e+00, Data-loss 4.2771e-01                  , pde-loss 5.8512e+03, initc-loss 1.2953e+04                    bc_loss 1.7130e+02\n",
      "Epoch 27470, Training-Loss 2.2123e+00, Data-loss 3.8056e-01                  , pde-loss 5.3536e+03, initc-loss 1.2935e+04                    bc_loss 2.8171e+01\n",
      "Epoch 27480, Training-Loss 2.1954e+00, Data-loss 3.0081e-01                  , pde-loss 5.9537e+03, initc-loss 1.2882e+04                    bc_loss 1.1016e+02\n",
      "Epoch 27490, Training-Loss 2.2233e+00, Data-loss 3.6668e-01                  , pde-loss 5.5050e+03, initc-loss 1.2960e+04                    bc_loss 1.0084e+02\n",
      "Epoch 27500, Training-Loss 2.3444e+00, Data-loss 3.7041e-01                  , pde-loss 6.4763e+03, initc-loss 1.2948e+04                    bc_loss 3.1573e+02\n",
      "Epoch 27510, Training-Loss 2.3490e+00, Data-loss 3.6675e-01                  , pde-loss 6.6146e+03, initc-loss 1.2924e+04                    bc_loss 2.8389e+02\n",
      "Epoch 27520, Training-Loss 2.3405e+00, Data-loss 3.8802e-01                  , pde-loss 6.2578e+03, initc-loss 1.2938e+04                    bc_loss 3.2896e+02\n",
      "Epoch 27530, Training-Loss 2.4226e+00, Data-loss 5.1947e-01                  , pde-loss 6.0357e+03, initc-loss 1.2869e+04                    bc_loss 1.2590e+02\n",
      "Epoch 27540, Training-Loss 2.2533e+00, Data-loss 3.2405e-01                  , pde-loss 6.2843e+03, initc-loss 1.2912e+04                    bc_loss 9.6166e+01\n",
      "Epoch 27550, Training-Loss 2.2733e+00, Data-loss 2.6612e-01                  , pde-loss 6.8979e+03, initc-loss 1.2921e+04                    bc_loss 2.5358e+02\n",
      "Epoch 27560, Training-Loss 2.3104e+00, Data-loss 3.8744e-01                  , pde-loss 5.7898e+03, initc-loss 1.2930e+04                    bc_loss 5.0933e+02\n",
      "Epoch 27570, Training-Loss 2.3406e+00, Data-loss 4.9547e-01                  , pde-loss 5.4252e+03, initc-loss 1.2938e+04                    bc_loss 8.7990e+01\n",
      "Epoch 27580, Training-Loss 2.2189e+00, Data-loss 3.2375e-01                  , pde-loss 5.8215e+03, initc-loss 1.2857e+04                    bc_loss 2.7345e+02\n",
      "Epoch 27590, Training-Loss 2.2191e+00, Data-loss 3.2104e-01                  , pde-loss 4.8954e+03, initc-loss 1.2964e+04                    bc_loss 1.1216e+03\n",
      "Epoch 27600, Training-Loss 2.2204e+00, Data-loss 3.6825e-01                  , pde-loss 5.4538e+03, initc-loss 1.2915e+04                    bc_loss 1.5205e+02\n",
      "Epoch 27610, Training-Loss 2.1686e+00, Data-loss 3.5529e-01                  , pde-loss 4.8678e+03, initc-loss 1.2948e+04                    bc_loss 3.1706e+02\n",
      "Epoch 27620, Training-Loss 2.1958e+00, Data-loss 3.1938e-01                  , pde-loss 5.7597e+03, initc-loss 1.2967e+04                    bc_loss 3.7040e+01\n",
      "Epoch 27630, Training-Loss 2.2523e+00, Data-loss 3.7122e-01                  , pde-loss 5.6764e+03, initc-loss 1.2907e+04                    bc_loss 2.2756e+02\n",
      "Epoch 27640, Training-Loss 2.2329e+00, Data-loss 3.7165e-01                  , pde-loss 5.6029e+03, initc-loss 1.2882e+04                    bc_loss 1.2708e+02\n",
      "Epoch 27650, Training-Loss 2.2791e+00, Data-loss 3.4510e-01                  , pde-loss 6.3764e+03, initc-loss 1.2924e+04                    bc_loss 3.9732e+01\n",
      "Epoch 27660, Training-Loss 2.4551e+00, Data-loss 4.6861e-01                  , pde-loss 6.2642e+03, initc-loss 1.2823e+04                    bc_loss 7.7736e+02\n",
      "Epoch 27670, Training-Loss 2.5751e+00, Data-loss 6.4833e-01                  , pde-loss 5.8755e+03, initc-loss 1.3063e+04                    bc_loss 3.2902e+02\n",
      "Epoch 27680, Training-Loss 2.3285e+00, Data-loss 4.4981e-01                  , pde-loss 5.5191e+03, initc-loss 1.2862e+04                    bc_loss 4.0595e+02\n",
      "Epoch 27690, Training-Loss 2.4552e+00, Data-loss 5.1264e-01                  , pde-loss 6.0750e+03, initc-loss 1.2837e+04                    bc_loss 5.1370e+02\n",
      "Epoch 27700, Training-Loss 2.6491e+00, Data-loss 7.0891e-01                  , pde-loss 6.1733e+03, initc-loss 1.2968e+04                    bc_loss 2.6079e+02\n",
      "Epoch 27710, Training-Loss 2.2871e+00, Data-loss 4.0189e-01                  , pde-loss 5.7544e+03, initc-loss 1.2899e+04                    bc_loss 1.9845e+02\n",
      "Epoch 27720, Training-Loss 2.3284e+00, Data-loss 4.3112e-01                  , pde-loss 5.5328e+03, initc-loss 1.2882e+04                    bc_loss 5.5745e+02\n",
      "Epoch 27730, Training-Loss 2.3225e+00, Data-loss 3.9140e-01                  , pde-loss 5.6731e+03, initc-loss 1.2934e+04                    bc_loss 7.0450e+02\n",
      "Epoch 27740, Training-Loss 2.3058e+00, Data-loss 3.6396e-01                  , pde-loss 6.2140e+03, initc-loss 1.2895e+04                    bc_loss 3.0902e+02\n",
      "Epoch 27750, Training-Loss 2.3180e+00, Data-loss 2.9386e-01                  , pde-loss 7.0867e+03, initc-loss 1.2920e+04                    bc_loss 2.3516e+02\n",
      "Epoch 27760, Training-Loss 2.1315e+00, Data-loss 2.6529e-01                  , pde-loss 5.4506e+03, initc-loss 1.2871e+04                    bc_loss 3.4085e+02\n",
      "Epoch 27770, Training-Loss 2.3948e+00, Data-loss 4.0743e-01                  , pde-loss 5.6933e+03, initc-loss 1.2888e+04                    bc_loss 1.2922e+03\n",
      "Epoch 27780, Training-Loss 2.5541e+00, Data-loss 6.2621e-01                  , pde-loss 6.1620e+03, initc-loss 1.2992e+04                    bc_loss 1.2483e+02\n",
      "Epoch 27790, Training-Loss 2.4081e+00, Data-loss 4.9476e-01                  , pde-loss 5.6812e+03, initc-loss 1.2863e+04                    bc_loss 5.8939e+02\n",
      "Epoch 27800, Training-Loss 2.1475e+00, Data-loss 2.7897e-01                  , pde-loss 5.5879e+03, initc-loss 1.2884e+04                    bc_loss 2.1411e+02\n",
      "Epoch 27810, Training-Loss 2.3401e+00, Data-loss 4.6366e-01                  , pde-loss 5.1244e+03, initc-loss 1.2840e+04                    bc_loss 8.0073e+02\n",
      "Epoch 27820, Training-Loss 2.2614e+00, Data-loss 3.4716e-01                  , pde-loss 5.8771e+03, initc-loss 1.2983e+04                    bc_loss 2.8272e+02\n",
      "Epoch 27830, Training-Loss 2.4436e+00, Data-loss 4.3834e-01                  , pde-loss 6.2723e+03, initc-loss 1.2947e+04                    bc_loss 8.3271e+02\n",
      "Epoch 27840, Training-Loss 2.3120e+00, Data-loss 3.7182e-01                  , pde-loss 6.0319e+03, initc-loss 1.2879e+04                    bc_loss 4.9122e+02\n",
      "Epoch 27850, Training-Loss 2.4313e+00, Data-loss 4.9730e-01                  , pde-loss 6.1127e+03, initc-loss 1.2951e+04                    bc_loss 2.7658e+02\n",
      "Epoch 27860, Training-Loss 2.5117e+00, Data-loss 4.7494e-01                  , pde-loss 6.3589e+03, initc-loss 1.2933e+04                    bc_loss 1.0750e+03\n",
      "Epoch 27870, Training-Loss 2.3651e+00, Data-loss 4.4489e-01                  , pde-loss 6.2466e+03, initc-loss 1.2905e+04                    bc_loss 5.0501e+01\n",
      "Epoch 27880, Training-Loss 2.3476e+00, Data-loss 3.5911e-01                  , pde-loss 6.6480e+03, initc-loss 1.2988e+04                    bc_loss 2.4856e+02\n",
      "Epoch 27890, Training-Loss 2.3324e+00, Data-loss 3.2696e-01                  , pde-loss 6.8621e+03, initc-loss 1.2863e+04                    bc_loss 3.2930e+02\n",
      "Epoch 27900, Training-Loss 2.3520e+00, Data-loss 5.3503e-01                  , pde-loss 4.9960e+03, initc-loss 1.2901e+04                    bc_loss 2.7302e+02\n",
      "Epoch 27910, Training-Loss 2.2323e+00, Data-loss 3.0284e-01                  , pde-loss 5.9372e+03, initc-loss 1.2909e+04                    bc_loss 4.4797e+02\n",
      "Epoch 27920, Training-Loss 2.3926e+00, Data-loss 4.4935e-01                  , pde-loss 6.0675e+03, initc-loss 1.2966e+04                    bc_loss 3.9964e+02\n",
      "Epoch 27930, Training-Loss 2.1063e+00, Data-loss 2.3926e-01                  , pde-loss 5.4798e+03, initc-loss 1.2924e+04                    bc_loss 2.6611e+02\n",
      "Epoch 27940, Training-Loss 2.3035e+00, Data-loss 3.8091e-01                  , pde-loss 6.2370e+03, initc-loss 1.2888e+04                    bc_loss 1.0046e+02\n",
      "Epoch 27950, Training-Loss 2.2361e+00, Data-loss 3.2513e-01                  , pde-loss 5.6743e+03, initc-loss 1.2927e+04                    bc_loss 5.0875e+02\n",
      "Epoch 27960, Training-Loss 2.5817e+00, Data-loss 5.2025e-01                  , pde-loss 6.4927e+03, initc-loss 1.2887e+04                    bc_loss 1.2355e+03\n",
      "Epoch 27970, Training-Loss 2.3703e+00, Data-loss 4.6494e-01                  , pde-loss 6.0238e+03, initc-loss 1.2946e+04                    bc_loss 8.3977e+01\n",
      "Epoch 27980, Training-Loss 2.2535e+00, Data-loss 3.4429e-01                  , pde-loss 6.0102e+03, initc-loss 1.2911e+04                    bc_loss 1.7047e+02\n",
      "Epoch 27990, Training-Loss 2.5361e+00, Data-loss 5.6219e-01                  , pde-loss 5.6434e+03, initc-loss 1.2826e+04                    bc_loss 1.2704e+03\n",
      "Epoch 28000, Training-Loss 2.3707e+00, Data-loss 4.5001e-01                  , pde-loss 6.1704e+03, initc-loss 1.2929e+04                    bc_loss 1.0747e+02\n",
      "Epoch 28010, Training-Loss 2.1264e+00, Data-loss 2.5443e-01                  , pde-loss 5.6869e+03, initc-loss 1.2938e+04                    bc_loss 9.5052e+01\n",
      "Epoch 28020, Training-Loss 2.1877e+00, Data-loss 2.8615e-01                  , pde-loss 6.0769e+03, initc-loss 1.2924e+04                    bc_loss 1.4495e+01\n",
      "Epoch 28030, Training-Loss 2.6064e+00, Data-loss 6.3962e-01                  , pde-loss 6.1890e+03, initc-loss 1.2806e+04                    bc_loss 6.7226e+02\n",
      "Epoch 28040, Training-Loss 2.1966e+00, Data-loss 3.4096e-01                  , pde-loss 4.8912e+03, initc-loss 1.2953e+04                    bc_loss 7.1148e+02\n",
      "Epoch 28050, Training-Loss 2.2244e+00, Data-loss 3.4764e-01                  , pde-loss 5.8098e+03, initc-loss 1.2855e+04                    bc_loss 1.0321e+02\n",
      "Epoch 28060, Training-Loss 2.2228e+00, Data-loss 3.0518e-01                  , pde-loss 5.9890e+03, initc-loss 1.2860e+04                    bc_loss 3.2750e+02\n",
      "Epoch 28070, Training-Loss 2.2208e+00, Data-loss 3.9462e-01                  , pde-loss 5.1506e+03, initc-loss 1.2918e+04                    bc_loss 1.9260e+02\n",
      "Epoch 28080, Training-Loss 2.2114e+00, Data-loss 3.0645e-01                  , pde-loss 5.4072e+03, initc-loss 1.2904e+04                    bc_loss 7.3839e+02\n",
      "Epoch 28090, Training-Loss 2.4027e+00, Data-loss 3.2770e-01                  , pde-loss 5.7324e+03, initc-loss 1.2941e+04                    bc_loss 2.0765e+03\n",
      "Epoch 28100, Training-Loss 2.7226e+00, Data-loss 8.7490e-01                  , pde-loss 5.1657e+03, initc-loss 1.2785e+04                    bc_loss 5.2624e+02\n",
      "Epoch 28110, Training-Loss 2.7857e+00, Data-loss 7.1926e-01                  , pde-loss 6.2685e+03, initc-loss 1.3026e+04                    bc_loss 1.3700e+03\n",
      "Epoch 28120, Training-Loss 2.2762e+00, Data-loss 3.1843e-01                  , pde-loss 6.6756e+03, initc-loss 1.2863e+04                    bc_loss 3.9140e+01\n",
      "Epoch 28130, Training-Loss 2.1218e+00, Data-loss 2.7815e-01                  , pde-loss 5.2133e+03, initc-loss 1.2953e+04                    bc_loss 2.7050e+02\n",
      "Epoch 28140, Training-Loss 2.5536e+00, Data-loss 5.6233e-01                  , pde-loss 6.2478e+03, initc-loss 1.2824e+04                    bc_loss 8.4050e+02\n",
      "Epoch 28150, Training-Loss 2.3473e+00, Data-loss 3.7953e-01                  , pde-loss 5.9494e+03, initc-loss 1.2875e+04                    bc_loss 8.5296e+02\n",
      "Epoch 28160, Training-Loss 2.1967e+00, Data-loss 2.6980e-01                  , pde-loss 6.1116e+03, initc-loss 1.2916e+04                    bc_loss 2.4171e+02\n",
      "Epoch 28170, Training-Loss 2.4187e+00, Data-loss 5.6931e-01                  , pde-loss 5.4841e+03, initc-loss 1.2812e+04                    bc_loss 1.9760e+02\n",
      "Epoch 28180, Training-Loss 2.4834e+00, Data-loss 5.7030e-01                  , pde-loss 6.1366e+03, initc-loss 1.2881e+04                    bc_loss 1.1300e+02\n",
      "Epoch 28190, Training-Loss 2.4151e+00, Data-loss 3.9664e-01                  , pde-loss 5.4208e+03, initc-loss 1.2932e+04                    bc_loss 1.8315e+03\n",
      "Epoch 28200, Training-Loss 2.1690e+00, Data-loss 3.0915e-01                  , pde-loss 5.5297e+03, initc-loss 1.2958e+04                    bc_loss 1.1068e+02\n",
      "Epoch 28210, Training-Loss 2.1506e+00, Data-loss 2.9944e-01                  , pde-loss 5.4265e+03, initc-loss 1.2964e+04                    bc_loss 1.2145e+02\n",
      "Epoch 28220, Training-Loss 2.4196e+00, Data-loss 4.1544e-01                  , pde-loss 6.8543e+03, initc-loss 1.2985e+04                    bc_loss 2.0248e+02\n",
      "Epoch 28230, Training-Loss 2.1940e+00, Data-loss 3.4492e-01                  , pde-loss 5.5082e+03, initc-loss 1.2851e+04                    bc_loss 1.3203e+02\n",
      "Epoch 28240, Training-Loss 2.4238e+00, Data-loss 4.3214e-01                  , pde-loss 6.7822e+03, initc-loss 1.2867e+04                    bc_loss 2.6724e+02\n",
      "Epoch 28250, Training-Loss 2.4409e+00, Data-loss 5.5734e-01                  , pde-loss 5.5188e+03, initc-loss 1.2984e+04                    bc_loss 3.3317e+02\n",
      "Epoch 28260, Training-Loss 2.2404e+00, Data-loss 3.3428e-01                  , pde-loss 5.4332e+03, initc-loss 1.2846e+04                    bc_loss 7.8188e+02\n",
      "Epoch 28270, Training-Loss 2.3654e+00, Data-loss 4.3712e-01                  , pde-loss 6.1541e+03, initc-loss 1.2835e+04                    bc_loss 2.9341e+02\n",
      "Epoch 28280, Training-Loss 2.4469e+00, Data-loss 5.5248e-01                  , pde-loss 5.8277e+03, initc-loss 1.2998e+04                    bc_loss 1.1830e+02\n",
      "Epoch 28290, Training-Loss 2.3013e+00, Data-loss 3.8418e-01                  , pde-loss 5.8825e+03, initc-loss 1.2908e+04                    bc_loss 3.8089e+02\n",
      "Epoch 28300, Training-Loss 2.2986e+00, Data-loss 3.9363e-01                  , pde-loss 5.7372e+03, initc-loss 1.2955e+04                    bc_loss 3.5721e+02\n",
      "Epoch 28310, Training-Loss 2.3041e+00, Data-loss 3.3753e-01                  , pde-loss 6.4179e+03, initc-loss 1.2917e+04                    bc_loss 3.3029e+02\n",
      "Epoch 28320, Training-Loss 2.5121e+00, Data-loss 5.9042e-01                  , pde-loss 6.1755e+03, initc-loss 1.2932e+04                    bc_loss 1.0897e+02\n",
      "Epoch 28330, Training-Loss 2.1134e+00, Data-loss 2.8239e-01                  , pde-loss 5.1098e+03, initc-loss 1.2935e+04                    bc_loss 2.6535e+02\n",
      "Epoch 28340, Training-Loss 2.3191e+00, Data-loss 3.4510e-01                  , pde-loss 6.0945e+03, initc-loss 1.2934e+04                    bc_loss 7.1119e+02\n",
      "Epoch 28350, Training-Loss 2.4343e+00, Data-loss 4.5987e-01                  , pde-loss 6.3234e+03, initc-loss 1.2970e+04                    bc_loss 4.5146e+02\n",
      "Epoch 28360, Training-Loss 2.2686e+00, Data-loss 3.7201e-01                  , pde-loss 5.2676e+03, initc-loss 1.2826e+04                    bc_loss 8.7277e+02\n",
      "Epoch 28370, Training-Loss 2.1884e+00, Data-loss 3.3717e-01                  , pde-loss 5.4766e+03, initc-loss 1.2966e+04                    bc_loss 6.9955e+01\n",
      "Epoch 28380, Training-Loss 2.2146e+00, Data-loss 3.3056e-01                  , pde-loss 5.8625e+03, initc-loss 1.2896e+04                    bc_loss 8.2207e+01\n",
      "Epoch 28390, Training-Loss 2.2884e+00, Data-loss 4.5514e-01                  , pde-loss 5.2110e+03, initc-loss 1.2887e+04                    bc_loss 2.3493e+02\n",
      "Epoch 28400, Training-Loss 2.1544e+00, Data-loss 2.6924e-01                  , pde-loss 5.8542e+03, initc-loss 1.2929e+04                    bc_loss 6.8373e+01\n",
      "Epoch 28410, Training-Loss 2.0985e+00, Data-loss 3.0465e-01                  , pde-loss 4.9951e+03, initc-loss 1.2889e+04                    bc_loss 5.5280e+01\n",
      "Epoch 28420, Training-Loss 2.1874e+00, Data-loss 2.9691e-01                  , pde-loss 5.6595e+03, initc-loss 1.2957e+04                    bc_loss 2.8864e+02\n",
      "Epoch 28430, Training-Loss 2.2854e+00, Data-loss 3.9758e-01                  , pde-loss 5.8399e+03, initc-loss 1.2910e+04                    bc_loss 1.2860e+02\n",
      "Epoch 28440, Training-Loss 2.4709e+00, Data-loss 4.8094e-01                  , pde-loss 6.7462e+03, initc-loss 1.2848e+04                    bc_loss 3.0559e+02\n",
      "Epoch 28450, Training-Loss 2.3616e+00, Data-loss 3.5806e-01                  , pde-loss 6.3213e+03, initc-loss 1.2889e+04                    bc_loss 8.2492e+02\n",
      "Epoch 28460, Training-Loss 2.3379e+00, Data-loss 4.2334e-01                  , pde-loss 5.7760e+03, initc-loss 1.2947e+04                    bc_loss 4.2244e+02\n",
      "Epoch 28470, Training-Loss 2.4398e+00, Data-loss 4.6520e-01                  , pde-loss 5.7826e+03, initc-loss 1.2857e+04                    bc_loss 1.1069e+03\n",
      "Epoch 28480, Training-Loss 2.1766e+00, Data-loss 3.2581e-01                  , pde-loss 5.4819e+03, initc-loss 1.2911e+04                    bc_loss 1.1520e+02\n",
      "Epoch 28490, Training-Loss 2.3306e+00, Data-loss 4.0624e-01                  , pde-loss 6.1563e+03, initc-loss 1.2947e+04                    bc_loss 1.4029e+02\n",
      "Epoch 28500, Training-Loss 2.3034e+00, Data-loss 3.3239e-01                  , pde-loss 6.4299e+03, initc-loss 1.2895e+04                    bc_loss 3.8537e+02\n",
      "Epoch 28510, Training-Loss 2.4698e+00, Data-loss 4.1039e-01                  , pde-loss 7.3761e+03, initc-loss 1.2844e+04                    bc_loss 3.7402e+02\n",
      "Epoch 28520, Training-Loss 2.2365e+00, Data-loss 4.3929e-01                  , pde-loss 4.9787e+03, initc-loss 1.2888e+04                    bc_loss 1.0610e+02\n",
      "Epoch 28530, Training-Loss 2.2183e+00, Data-loss 3.4370e-01                  , pde-loss 5.7292e+03, initc-loss 1.2954e+04                    bc_loss 6.2430e+01\n",
      "Epoch 28540, Training-Loss 2.2724e+00, Data-loss 3.4172e-01                  , pde-loss 6.0683e+03, initc-loss 1.2902e+04                    bc_loss 3.3650e+02\n",
      "Epoch 28550, Training-Loss 2.3263e+00, Data-loss 4.3671e-01                  , pde-loss 5.7602e+03, initc-loss 1.2877e+04                    bc_loss 2.5930e+02\n",
      "Epoch 28560, Training-Loss 2.3170e+00, Data-loss 3.8858e-01                  , pde-loss 6.2825e+03, initc-loss 1.2841e+04                    bc_loss 1.6006e+02\n",
      "Epoch 28570, Training-Loss 2.3002e+00, Data-loss 4.0945e-01                  , pde-loss 5.8828e+03, initc-loss 1.2964e+04                    bc_loss 6.1146e+01\n",
      "Epoch 28580, Training-Loss 2.4521e+00, Data-loss 3.8880e-01                  , pde-loss 6.2516e+03, initc-loss 1.2904e+04                    bc_loss 1.4768e+03\n",
      "Epoch 28590, Training-Loss 2.3730e+00, Data-loss 4.7502e-01                  , pde-loss 6.0107e+03, initc-loss 1.2856e+04                    bc_loss 1.1245e+02\n",
      "Epoch 28600, Training-Loss 2.2999e+00, Data-loss 3.7107e-01                  , pde-loss 6.2698e+03, initc-loss 1.2904e+04                    bc_loss 1.1505e+02\n",
      "Epoch 28610, Training-Loss 2.4246e+00, Data-loss 4.6178e-01                  , pde-loss 6.0912e+03, initc-loss 1.2869e+04                    bc_loss 6.6787e+02\n",
      "Epoch 28620, Training-Loss 2.3373e+00, Data-loss 3.7465e-01                  , pde-loss 6.4945e+03, initc-loss 1.2949e+04                    bc_loss 1.8333e+02\n",
      "Epoch 28630, Training-Loss 2.3043e+00, Data-loss 3.8802e-01                  , pde-loss 5.7200e+03, initc-loss 1.2952e+04                    bc_loss 4.9036e+02\n",
      "Epoch 28640, Training-Loss 2.2350e+00, Data-loss 3.6974e-01                  , pde-loss 5.3228e+03, initc-loss 1.2870e+04                    bc_loss 4.6001e+02\n",
      "Epoch 28650, Training-Loss 2.3009e+00, Data-loss 3.8728e-01                  , pde-loss 5.9845e+03, initc-loss 1.2941e+04                    bc_loss 2.1112e+02\n",
      "Epoch 28660, Training-Loss 2.2227e+00, Data-loss 3.4166e-01                  , pde-loss 5.7842e+03, initc-loss 1.2886e+04                    bc_loss 1.3979e+02\n",
      "Epoch 28670, Training-Loss 2.2627e+00, Data-loss 3.5592e-01                  , pde-loss 6.0460e+03, initc-loss 1.2959e+04                    bc_loss 6.3248e+01\n",
      "Epoch 28680, Training-Loss 2.2871e+00, Data-loss 4.1120e-01                  , pde-loss 5.6381e+03, initc-loss 1.2904e+04                    bc_loss 2.1710e+02\n",
      "Epoch 28690, Training-Loss 2.1837e+00, Data-loss 3.1309e-01                  , pde-loss 5.6094e+03, initc-loss 1.2906e+04                    bc_loss 1.9117e+02\n",
      "Epoch 28700, Training-Loss 2.2167e+00, Data-loss 3.0155e-01                  , pde-loss 6.0902e+03, initc-loss 1.2844e+04                    bc_loss 2.1679e+02\n",
      "Epoch 28710, Training-Loss 2.3558e+00, Data-loss 4.2408e-01                  , pde-loss 6.0726e+03, initc-loss 1.2884e+04                    bc_loss 3.6041e+02\n",
      "Epoch 28720, Training-Loss 2.2680e+00, Data-loss 4.3296e-01                  , pde-loss 5.1327e+03, initc-loss 1.2823e+04                    bc_loss 3.9464e+02\n",
      "Epoch 28730, Training-Loss 2.1265e+00, Data-loss 2.5158e-01                  , pde-loss 5.5889e+03, initc-loss 1.2985e+04                    bc_loss 1.7504e+02\n",
      "Epoch 28740, Training-Loss 2.5630e+00, Data-loss 4.2482e-01                  , pde-loss 6.1913e+03, initc-loss 1.2875e+04                    bc_loss 2.3156e+03\n",
      "Epoch 28750, Training-Loss 2.4005e+00, Data-loss 4.3119e-01                  , pde-loss 6.5350e+03, initc-loss 1.2981e+04                    bc_loss 1.7707e+02\n",
      "Epoch 28760, Training-Loss 2.3438e+00, Data-loss 4.3351e-01                  , pde-loss 5.8985e+03, initc-loss 1.2869e+04                    bc_loss 3.3502e+02\n",
      "Epoch 28770, Training-Loss 2.2114e+00, Data-loss 3.6779e-01                  , pde-loss 5.3055e+03, initc-loss 1.2980e+04                    bc_loss 1.5119e+02\n",
      "Epoch 28780, Training-Loss 2.5023e+00, Data-loss 6.1758e-01                  , pde-loss 5.6935e+03, initc-loss 1.2787e+04                    bc_loss 3.6584e+02\n",
      "Epoch 28790, Training-Loss 2.1793e+00, Data-loss 2.8694e-01                  , pde-loss 5.8724e+03, initc-loss 1.2896e+04                    bc_loss 1.5543e+02\n",
      "Epoch 28800, Training-Loss 2.3562e+00, Data-loss 4.1185e-01                  , pde-loss 6.2484e+03, initc-loss 1.3002e+04                    bc_loss 1.9259e+02\n",
      "Epoch 28810, Training-Loss 2.2433e+00, Data-loss 2.9736e-01                  , pde-loss 6.0645e+03, initc-loss 1.2881e+04                    bc_loss 5.1473e+02\n",
      "Epoch 28820, Training-Loss 2.2725e+00, Data-loss 3.4813e-01                  , pde-loss 5.9648e+03, initc-loss 1.2978e+04                    bc_loss 3.0104e+02\n",
      "Epoch 28830, Training-Loss 2.3876e+00, Data-loss 4.4717e-01                  , pde-loss 5.9514e+03, initc-loss 1.2972e+04                    bc_loss 4.8084e+02\n",
      "Epoch 28840, Training-Loss 2.5306e+00, Data-loss 4.8653e-01                  , pde-loss 6.3107e+03, initc-loss 1.2853e+04                    bc_loss 1.2767e+03\n",
      "Epoch 28850, Training-Loss 2.4105e+00, Data-loss 4.1818e-01                  , pde-loss 6.8374e+03, initc-loss 1.2925e+04                    bc_loss 1.6035e+02\n",
      "Epoch 28860, Training-Loss 2.2752e+00, Data-loss 4.5372e-01                  , pde-loss 5.0581e+03, initc-loss 1.2878e+04                    bc_loss 2.7795e+02\n",
      "Epoch 28870, Training-Loss 2.3560e+00, Data-loss 4.2502e-01                  , pde-loss 5.9525e+03, initc-loss 1.2812e+04                    bc_loss 5.4497e+02\n",
      "Epoch 28880, Training-Loss 2.4403e+00, Data-loss 4.6961e-01                  , pde-loss 5.8015e+03, initc-loss 1.3016e+04                    bc_loss 8.8971e+02\n",
      "Epoch 28890, Training-Loss 2.3178e+00, Data-loss 4.3291e-01                  , pde-loss 5.9050e+03, initc-loss 1.2873e+04                    bc_loss 7.1735e+01\n",
      "Epoch 28900, Training-Loss 2.3469e+00, Data-loss 3.8166e-01                  , pde-loss 6.4478e+03, initc-loss 1.2897e+04                    bc_loss 3.0696e+02\n",
      "Epoch 28910, Training-Loss 2.2205e+00, Data-loss 2.9556e-01                  , pde-loss 6.0610e+03, initc-loss 1.2907e+04                    bc_loss 2.8189e+02\n",
      "Epoch 28920, Training-Loss 2.3551e+00, Data-loss 3.6272e-01                  , pde-loss 6.4189e+03, initc-loss 1.2870e+04                    bc_loss 6.3516e+02\n",
      "Epoch 28930, Training-Loss 2.1243e+00, Data-loss 2.5989e-01                  , pde-loss 5.6609e+03, initc-loss 1.2939e+04                    bc_loss 4.3456e+01\n",
      "Epoch 28940, Training-Loss 2.2604e+00, Data-loss 3.1232e-01                  , pde-loss 6.3819e+03, initc-loss 1.2863e+04                    bc_loss 2.3593e+02\n",
      "Epoch 28950, Training-Loss 2.4265e+00, Data-loss 4.2759e-01                  , pde-loss 6.2880e+03, initc-loss 1.2907e+04                    bc_loss 7.9436e+02\n",
      "Epoch 28960, Training-Loss 2.2898e+00, Data-loss 3.2839e-01                  , pde-loss 5.9897e+03, initc-loss 1.2886e+04                    bc_loss 7.3825e+02\n",
      "Epoch 28970, Training-Loss 2.3415e+00, Data-loss 4.5925e-01                  , pde-loss 5.8466e+03, initc-loss 1.2932e+04                    bc_loss 4.4045e+01\n",
      "Epoch 28980, Training-Loss 2.2799e+00, Data-loss 3.5320e-01                  , pde-loss 6.1038e+03, initc-loss 1.2854e+04                    bc_loss 3.0904e+02\n",
      "Epoch 28990, Training-Loss 2.3414e+00, Data-loss 3.1525e-01                  , pde-loss 7.0216e+03, initc-loss 1.2904e+04                    bc_loss 3.3551e+02\n",
      "Epoch 29000, Training-Loss 2.2313e+00, Data-loss 3.2145e-01                  , pde-loss 6.1831e+03, initc-loss 1.2858e+04                    bc_loss 5.7086e+01\n",
      "Epoch 29010, Training-Loss 2.2492e+00, Data-loss 3.9369e-01                  , pde-loss 5.1839e+03, initc-loss 1.2904e+04                    bc_loss 4.6692e+02\n",
      "Epoch 29020, Training-Loss 2.3878e+00, Data-loss 4.5610e-01                  , pde-loss 6.3488e+03, initc-loss 1.2861e+04                    bc_loss 1.0680e+02\n",
      "Epoch 29030, Training-Loss 2.6623e+00, Data-loss 7.3473e-01                  , pde-loss 5.6163e+03, initc-loss 1.2853e+04                    bc_loss 8.0688e+02\n",
      "Epoch 29040, Training-Loss 2.2276e+00, Data-loss 3.0456e-01                  , pde-loss 5.9723e+03, initc-loss 1.2924e+04                    bc_loss 3.3392e+02\n",
      "Epoch 29050, Training-Loss 2.2507e+00, Data-loss 3.4328e-01                  , pde-loss 5.8866e+03, initc-loss 1.2836e+04                    bc_loss 3.5147e+02\n",
      "Epoch 29060, Training-Loss 2.2799e+00, Data-loss 4.5000e-01                  , pde-loss 5.3484e+03, initc-loss 1.2854e+04                    bc_loss 9.6444e+01\n",
      "Epoch 29070, Training-Loss 2.3459e+00, Data-loss 4.1799e-01                  , pde-loss 6.2060e+03, initc-loss 1.2854e+04                    bc_loss 2.1911e+02\n",
      "Epoch 29080, Training-Loss 2.1689e+00, Data-loss 3.5802e-01                  , pde-loss 5.0540e+03, initc-loss 1.2962e+04                    bc_loss 9.3655e+01\n",
      "Epoch 29090, Training-Loss 2.2360e+00, Data-loss 3.4388e-01                  , pde-loss 5.7352e+03, initc-loss 1.2981e+04                    bc_loss 2.0482e+02\n",
      "Epoch 29100, Training-Loss 2.2696e+00, Data-loss 3.4811e-01                  , pde-loss 6.1776e+03, initc-loss 1.2922e+04                    bc_loss 1.1614e+02\n",
      "Epoch 29110, Training-Loss 2.5321e+00, Data-loss 5.0670e-01                  , pde-loss 6.8361e+03, initc-loss 1.2904e+04                    bc_loss 5.1486e+02\n",
      "Epoch 29120, Training-Loss 2.2487e+00, Data-loss 3.1083e-01                  , pde-loss 5.8684e+03, initc-loss 1.2989e+04                    bc_loss 5.2130e+02\n",
      "Epoch 29130, Training-Loss 2.3076e+00, Data-loss 3.7932e-01                  , pde-loss 6.0691e+03, initc-loss 1.2970e+04                    bc_loss 2.4367e+02\n",
      "Epoch 29140, Training-Loss 2.2373e+00, Data-loss 3.5018e-01                  , pde-loss 5.8128e+03, initc-loss 1.2959e+04                    bc_loss 9.8992e+01\n",
      "Epoch 29150, Training-Loss 2.4135e+00, Data-loss 5.2168e-01                  , pde-loss 5.8875e+03, initc-loss 1.2829e+04                    bc_loss 2.0184e+02\n",
      "Epoch 29160, Training-Loss 2.2745e+00, Data-loss 3.1072e-01                  , pde-loss 5.8230e+03, initc-loss 1.2928e+04                    bc_loss 8.8681e+02\n",
      "Epoch 29170, Training-Loss 2.2018e+00, Data-loss 3.3314e-01                  , pde-loss 5.3565e+03, initc-loss 1.2893e+04                    bc_loss 4.3702e+02\n",
      "Epoch 29180, Training-Loss 2.5609e+00, Data-loss 5.7163e-01                  , pde-loss 6.1370e+03, initc-loss 1.3002e+04                    bc_loss 7.5355e+02\n",
      "Epoch 29190, Training-Loss 2.2400e+00, Data-loss 4.1187e-01                  , pde-loss 5.1792e+03, initc-loss 1.2979e+04                    bc_loss 1.2287e+02\n",
      "Epoch 29200, Training-Loss 2.3969e+00, Data-loss 4.0531e-01                  , pde-loss 6.8100e+03, initc-loss 1.2867e+04                    bc_loss 2.3933e+02\n",
      "Epoch 29210, Training-Loss 2.1759e+00, Data-loss 3.0757e-01                  , pde-loss 5.7716e+03, initc-loss 1.2873e+04                    bc_loss 3.8261e+01\n",
      "Epoch 29220, Training-Loss 2.1047e+00, Data-loss 2.7885e-01                  , pde-loss 5.2285e+03, initc-loss 1.2933e+04                    bc_loss 9.7623e+01\n",
      "Epoch 29230, Training-Loss 2.1639e+00, Data-loss 2.9015e-01                  , pde-loss 5.7721e+03, initc-loss 1.2863e+04                    bc_loss 1.0225e+02\n",
      "Epoch 29240, Training-Loss 2.2172e+00, Data-loss 2.9677e-01                  , pde-loss 6.2223e+03, initc-loss 1.2901e+04                    bc_loss 8.0536e+01\n",
      "Epoch 29250, Training-Loss 2.1643e+00, Data-loss 3.0791e-01                  , pde-loss 5.6014e+03, initc-loss 1.2839e+04                    bc_loss 1.2383e+02\n",
      "Epoch 29260, Training-Loss 2.1246e+00, Data-loss 2.2662e-01                  , pde-loss 5.4410e+03, initc-loss 1.2939e+04                    bc_loss 6.0037e+02\n",
      "Epoch 29270, Training-Loss 2.3428e+00, Data-loss 3.2412e-01                  , pde-loss 7.0347e+03, initc-loss 1.2935e+04                    bc_loss 2.1735e+02\n",
      "Epoch 29280, Training-Loss 2.2978e+00, Data-loss 3.2728e-01                  , pde-loss 6.6614e+03, initc-loss 1.2910e+04                    bc_loss 1.3416e+02\n",
      "Epoch 29290, Training-Loss 2.5088e+00, Data-loss 5.3420e-01                  , pde-loss 5.9206e+03, initc-loss 1.2916e+04                    bc_loss 9.1031e+02\n",
      "Epoch 29300, Training-Loss 2.2564e+00, Data-loss 3.5573e-01                  , pde-loss 5.8998e+03, initc-loss 1.2854e+04                    bc_loss 2.5289e+02\n",
      "Epoch 29310, Training-Loss 2.0970e+00, Data-loss 2.6302e-01                  , pde-loss 5.2897e+03, initc-loss 1.2893e+04                    bc_loss 1.5695e+02\n",
      "Epoch 29320, Training-Loss 2.3313e+00, Data-loss 3.9976e-01                  , pde-loss 6.1096e+03, initc-loss 1.2867e+04                    bc_loss 3.3897e+02\n",
      "Epoch 29330, Training-Loss 2.4864e+00, Data-loss 5.4847e-01                  , pde-loss 6.0018e+03, initc-loss 1.2943e+04                    bc_loss 4.3426e+02\n",
      "Epoch 29340, Training-Loss 2.4805e+00, Data-loss 4.7353e-01                  , pde-loss 6.0714e+03, initc-loss 1.3036e+04                    bc_loss 9.6227e+02\n",
      "Epoch 29350, Training-Loss 2.2734e+00, Data-loss 3.3412e-01                  , pde-loss 5.6177e+03, initc-loss 1.2943e+04                    bc_loss 8.3236e+02\n",
      "Epoch 29360, Training-Loss 2.2904e+00, Data-loss 3.6241e-01                  , pde-loss 5.4442e+03, initc-loss 1.2883e+04                    bc_loss 9.5286e+02\n",
      "Epoch 29370, Training-Loss 2.2062e+00, Data-loss 3.4278e-01                  , pde-loss 5.6174e+03, initc-loss 1.2918e+04                    bc_loss 9.7972e+01\n",
      "Epoch 29380, Training-Loss 2.3055e+00, Data-loss 3.6045e-01                  , pde-loss 6.1695e+03, initc-loss 1.2903e+04                    bc_loss 3.7885e+02\n",
      "Epoch 29390, Training-Loss 2.2720e+00, Data-loss 3.5826e-01                  , pde-loss 5.7793e+03, initc-loss 1.2990e+04                    bc_loss 3.6831e+02\n",
      "Epoch 29400, Training-Loss 2.2641e+00, Data-loss 3.0171e-01                  , pde-loss 6.1163e+03, initc-loss 1.2917e+04                    bc_loss 5.9144e+02\n",
      "Epoch 29410, Training-Loss 2.4497e+00, Data-loss 4.8936e-01                  , pde-loss 6.4175e+03, initc-loss 1.2955e+04                    bc_loss 2.3068e+02\n",
      "Epoch 29420, Training-Loss 2.2002e+00, Data-loss 3.4380e-01                  , pde-loss 5.4793e+03, initc-loss 1.2884e+04                    bc_loss 2.0002e+02\n",
      "Epoch 29430, Training-Loss 2.1845e+00, Data-loss 2.6460e-01                  , pde-loss 5.7270e+03, initc-loss 1.2917e+04                    bc_loss 5.5453e+02\n",
      "Epoch 29440, Training-Loss 2.2696e+00, Data-loss 3.7534e-01                  , pde-loss 5.9559e+03, initc-loss 1.2883e+04                    bc_loss 1.0335e+02\n",
      "Epoch 29450, Training-Loss 2.3638e+00, Data-loss 4.1892e-01                  , pde-loss 6.2479e+03, initc-loss 1.2944e+04                    bc_loss 2.5747e+02\n",
      "Epoch 29460, Training-Loss 2.3056e+00, Data-loss 3.9142e-01                  , pde-loss 5.8789e+03, initc-loss 1.2885e+04                    bc_loss 3.7805e+02\n",
      "Epoch 29470, Training-Loss 2.3092e+00, Data-loss 4.2259e-01                  , pde-loss 5.6568e+03, initc-loss 1.3017e+04                    bc_loss 1.9174e+02\n",
      "Epoch 29480, Training-Loss 2.3826e+00, Data-loss 4.3795e-01                  , pde-loss 6.1757e+03, initc-loss 1.2935e+04                    bc_loss 3.3623e+02\n",
      "Epoch 29490, Training-Loss 2.2698e+00, Data-loss 3.7717e-01                  , pde-loss 5.8893e+03, initc-loss 1.2871e+04                    bc_loss 1.6624e+02\n",
      "Epoch 29500, Training-Loss 2.1229e+00, Data-loss 2.8654e-01                  , pde-loss 5.2771e+03, initc-loss 1.2864e+04                    bc_loss 2.2218e+02\n",
      "Epoch 29510, Training-Loss 2.3579e+00, Data-loss 3.9570e-01                  , pde-loss 6.2794e+03, initc-loss 1.2831e+04                    bc_loss 5.1192e+02\n",
      "Epoch 29520, Training-Loss 2.3604e+00, Data-loss 4.2430e-01                  , pde-loss 6.1376e+03, initc-loss 1.2861e+04                    bc_loss 3.6201e+02\n",
      "Epoch 29530, Training-Loss 2.3219e+00, Data-loss 4.2877e-01                  , pde-loss 5.7623e+03, initc-loss 1.2937e+04                    bc_loss 2.3262e+02\n",
      "Epoch 29540, Training-Loss 2.1527e+00, Data-loss 3.2979e-01                  , pde-loss 5.2081e+03, initc-loss 1.2905e+04                    bc_loss 1.1597e+02\n",
      "Epoch 29550, Training-Loss 2.4564e+00, Data-loss 5.2939e-01                  , pde-loss 6.0387e+03, initc-loss 1.3011e+04                    bc_loss 2.2039e+02\n",
      "Epoch 29560, Training-Loss 2.3363e+00, Data-loss 4.2720e-01                  , pde-loss 5.4810e+03, initc-loss 1.2861e+04                    bc_loss 7.4894e+02\n",
      "Epoch 29570, Training-Loss 2.2069e+00, Data-loss 3.2166e-01                  , pde-loss 5.6553e+03, initc-loss 1.2947e+04                    bc_loss 2.5000e+02\n",
      "Epoch 29580, Training-Loss 2.3594e+00, Data-loss 3.6746e-01                  , pde-loss 6.0376e+03, initc-loss 1.2929e+04                    bc_loss 9.5256e+02\n",
      "Epoch 29590, Training-Loss 2.2547e+00, Data-loss 3.6039e-01                  , pde-loss 5.6467e+03, initc-loss 1.2924e+04                    bc_loss 3.7257e+02\n",
      "Epoch 29600, Training-Loss 2.2754e+00, Data-loss 3.6369e-01                  , pde-loss 6.1583e+03, initc-loss 1.2902e+04                    bc_loss 5.6699e+01\n",
      "Epoch 29610, Training-Loss 2.3935e+00, Data-loss 4.4327e-01                  , pde-loss 6.4995e+03, initc-loss 1.2926e+04                    bc_loss 7.6693e+01\n",
      "Epoch 29620, Training-Loss 2.2933e+00, Data-loss 4.0938e-01                  , pde-loss 5.8475e+03, initc-loss 1.2929e+04                    bc_loss 6.2506e+01\n",
      "Epoch 29630, Training-Loss 2.2914e+00, Data-loss 3.6022e-01                  , pde-loss 6.3787e+03, initc-loss 1.2866e+04                    bc_loss 6.6990e+01\n",
      "Epoch 29640, Training-Loss 2.2600e+00, Data-loss 3.7045e-01                  , pde-loss 5.5822e+03, initc-loss 1.2986e+04                    bc_loss 3.2752e+02\n",
      "Epoch 29650, Training-Loss 2.2544e+00, Data-loss 3.0601e-01                  , pde-loss 6.4672e+03, initc-loss 1.2888e+04                    bc_loss 1.2949e+02\n",
      "Epoch 29660, Training-Loss 2.2082e+00, Data-loss 3.3735e-01                  , pde-loss 5.6257e+03, initc-loss 1.2911e+04                    bc_loss 1.7153e+02\n",
      "Epoch 29670, Training-Loss 2.1789e+00, Data-loss 3.0086e-01                  , pde-loss 5.7086e+03, initc-loss 1.2995e+04                    bc_loss 7.6502e+01\n",
      "Epoch 29680, Training-Loss 2.1276e+00, Data-loss 2.5976e-01                  , pde-loss 5.5993e+03, initc-loss 1.2901e+04                    bc_loss 1.7884e+02\n",
      "Epoch 29690, Training-Loss 2.1901e+00, Data-loss 3.7891e-01                  , pde-loss 5.0506e+03, initc-loss 1.2944e+04                    bc_loss 1.1784e+02\n",
      "Epoch 29700, Training-Loss 2.3346e+00, Data-loss 4.0574e-01                  , pde-loss 6.2876e+03, initc-loss 1.2895e+04                    bc_loss 1.0614e+02\n",
      "Epoch 29710, Training-Loss 2.3280e+00, Data-loss 4.1677e-01                  , pde-loss 6.1509e+03, initc-loss 1.2849e+04                    bc_loss 1.1298e+02\n",
      "Epoch 29720, Training-Loss 2.4363e+00, Data-loss 4.9108e-01                  , pde-loss 5.7858e+03, initc-loss 1.2852e+04                    bc_loss 8.1447e+02\n",
      "Epoch 29730, Training-Loss 2.3046e+00, Data-loss 3.9354e-01                  , pde-loss 5.6110e+03, initc-loss 1.2906e+04                    bc_loss 5.9267e+02\n",
      "Epoch 29740, Training-Loss 2.4697e+00, Data-loss 5.1016e-01                  , pde-loss 6.5322e+03, initc-loss 1.2987e+04                    bc_loss 7.6405e+01\n",
      "Epoch 29750, Training-Loss 2.1336e+00, Data-loss 2.4833e-01                  , pde-loss 5.7647e+03, initc-loss 1.2879e+04                    bc_loss 2.0850e+02\n",
      "Epoch 29760, Training-Loss 2.3168e+00, Data-loss 3.6317e-01                  , pde-loss 6.2362e+03, initc-loss 1.2864e+04                    bc_loss 4.3631e+02\n",
      "Epoch 29770, Training-Loss 2.3735e+00, Data-loss 4.4480e-01                  , pde-loss 6.1996e+03, initc-loss 1.2973e+04                    bc_loss 1.1439e+02\n",
      "Epoch 29780, Training-Loss 2.6201e+00, Data-loss 4.1103e-01                  , pde-loss 6.4580e+03, initc-loss 1.2836e+04                    bc_loss 2.7970e+03\n",
      "Epoch 29790, Training-Loss 2.3821e+00, Data-loss 4.8693e-01                  , pde-loss 5.8405e+03, initc-loss 1.2918e+04                    bc_loss 1.9320e+02\n",
      "Epoch 29800, Training-Loss 2.2674e+00, Data-loss 4.0040e-01                  , pde-loss 5.5505e+03, initc-loss 1.2939e+04                    bc_loss 1.8107e+02\n",
      "Epoch 29810, Training-Loss 2.1631e+00, Data-loss 2.9462e-01                  , pde-loss 5.5939e+03, initc-loss 1.2919e+04                    bc_loss 1.7194e+02\n",
      "Epoch 29820, Training-Loss 2.2145e+00, Data-loss 3.5886e-01                  , pde-loss 5.1769e+03, initc-loss 1.2916e+04                    bc_loss 4.6415e+02\n",
      "Epoch 29830, Training-Loss 2.1603e+00, Data-loss 3.1836e-01                  , pde-loss 5.4193e+03, initc-loss 1.2923e+04                    bc_loss 7.7534e+01\n",
      "Epoch 29840, Training-Loss 2.2919e+00, Data-loss 4.2849e-01                  , pde-loss 5.6360e+03, initc-loss 1.2876e+04                    bc_loss 1.2217e+02\n",
      "Epoch 29850, Training-Loss 2.1490e+00, Data-loss 2.6034e-01                  , pde-loss 5.6228e+03, initc-loss 1.2882e+04                    bc_loss 3.8203e+02\n",
      "Epoch 29860, Training-Loss 2.1729e+00, Data-loss 3.0842e-01                  , pde-loss 5.7371e+03, initc-loss 1.2864e+04                    bc_loss 4.4551e+01\n",
      "Epoch 29870, Training-Loss 2.2366e+00, Data-loss 3.0862e-01                  , pde-loss 5.8930e+03, initc-loss 1.2951e+04                    bc_loss 4.3585e+02\n",
      "Epoch 29880, Training-Loss 2.2781e+00, Data-loss 4.3838e-01                  , pde-loss 5.4403e+03, initc-loss 1.2865e+04                    bc_loss 9.1133e+01\n",
      "Epoch 29890, Training-Loss 2.4420e+00, Data-loss 4.7563e-01                  , pde-loss 6.0682e+03, initc-loss 1.2965e+04                    bc_loss 6.3043e+02\n",
      "Epoch 29900, Training-Loss 2.2121e+00, Data-loss 2.9305e-01                  , pde-loss 5.8508e+03, initc-loss 1.2930e+04                    bc_loss 4.1040e+02\n",
      "Epoch 29910, Training-Loss 2.1422e+00, Data-loss 3.5926e-01                  , pde-loss 4.7952e+03, initc-loss 1.2968e+04                    bc_loss 6.5777e+01\n",
      "Epoch 29920, Training-Loss 2.1068e+00, Data-loss 3.0491e-01                  , pde-loss 5.0021e+03, initc-loss 1.2894e+04                    bc_loss 1.2366e+02\n",
      "Epoch 29930, Training-Loss 2.1946e+00, Data-loss 3.1590e-01                  , pde-loss 5.3532e+03, initc-loss 1.2943e+04                    bc_loss 4.9126e+02\n",
      "Epoch 29940, Training-Loss 2.2791e+00, Data-loss 3.6073e-01                  , pde-loss 5.7207e+03, initc-loss 1.2750e+04                    bc_loss 7.1278e+02\n",
      "Epoch 29950, Training-Loss 2.4647e+00, Data-loss 5.0004e-01                  , pde-loss 6.0674e+03, initc-loss 1.2954e+04                    bc_loss 6.2578e+02\n",
      "Epoch 29960, Training-Loss 2.1569e+00, Data-loss 2.7319e-01                  , pde-loss 5.6829e+03, initc-loss 1.2989e+04                    bc_loss 1.6570e+02\n",
      "Epoch 29970, Training-Loss 2.3665e+00, Data-loss 4.2350e-01                  , pde-loss 6.3578e+03, initc-loss 1.2918e+04                    bc_loss 1.5463e+02\n",
      "Epoch 29980, Training-Loss 2.2243e+00, Data-loss 3.5460e-01                  , pde-loss 5.6826e+03, initc-loss 1.2915e+04                    bc_loss 9.8740e+01\n",
      "Epoch 29990, Training-Loss 2.3488e+00, Data-loss 3.8844e-01                  , pde-loss 6.6273e+03, initc-loss 1.2838e+04                    bc_loss 1.3779e+02\n",
      "Epoch 30000, Training-Loss 2.3514e+00, Data-loss 4.0398e-01                  , pde-loss 6.1100e+03, initc-loss 1.2913e+04                    bc_loss 4.5113e+02\n",
      "Epoch 30010, Training-Loss 2.2089e+00, Data-loss 3.6295e-01                  , pde-loss 5.3029e+03, initc-loss 1.2917e+04                    bc_loss 2.3972e+02\n",
      "Epoch 30020, Training-Loss 2.2437e+00, Data-loss 2.4357e-01                  , pde-loss 6.7414e+03, initc-loss 1.2960e+04                    bc_loss 3.0042e+02\n",
      "Epoch 30030, Training-Loss 2.5073e+00, Data-loss 5.6220e-01                  , pde-loss 5.9379e+03, initc-loss 1.2787e+04                    bc_loss 7.2564e+02\n",
      "Epoch 30040, Training-Loss 2.6905e+00, Data-loss 5.1464e-01                  , pde-loss 5.4881e+03, initc-loss 1.2987e+04                    bc_loss 3.2837e+03\n",
      "Epoch 30050, Training-Loss 2.1107e+00, Data-loss 2.7570e-01                  , pde-loss 4.7750e+03, initc-loss 1.3032e+04                    bc_loss 5.4334e+02\n",
      "Epoch 30060, Training-Loss 2.2323e+00, Data-loss 3.8616e-01                  , pde-loss 5.3129e+03, initc-loss 1.2884e+04                    bc_loss 2.6489e+02\n",
      "Epoch 30070, Training-Loss 2.4309e+00, Data-loss 5.9705e-01                  , pde-loss 4.8292e+03, initc-loss 1.2989e+04                    bc_loss 5.2103e+02\n",
      "Epoch 30080, Training-Loss 2.6596e+00, Data-loss 7.1459e-01                  , pde-loss 6.1704e+03, initc-loss 1.2870e+04                    bc_loss 4.0937e+02\n",
      "Epoch 30090, Training-Loss 2.2682e+00, Data-loss 4.1812e-01                  , pde-loss 5.3766e+03, initc-loss 1.2949e+04                    bc_loss 1.7556e+02\n",
      "Epoch 30100, Training-Loss 2.1736e+00, Data-loss 3.3642e-01                  , pde-loss 5.2226e+03, initc-loss 1.2854e+04                    bc_loss 2.9536e+02\n",
      "Epoch 30110, Training-Loss 2.3186e+00, Data-loss 3.9954e-01                  , pde-loss 6.2300e+03, initc-loss 1.2852e+04                    bc_loss 1.0783e+02\n",
      "Epoch 30120, Training-Loss 2.2982e+00, Data-loss 3.5678e-01                  , pde-loss 5.7340e+03, initc-loss 1.2959e+04                    bc_loss 7.2115e+02\n",
      "Epoch 30130, Training-Loss 2.1471e+00, Data-loss 2.8502e-01                  , pde-loss 5.4499e+03, initc-loss 1.2914e+04                    bc_loss 2.5687e+02\n",
      "Epoch 30140, Training-Loss 2.2777e+00, Data-loss 3.5083e-01                  , pde-loss 5.9845e+03, initc-loss 1.3022e+04                    bc_loss 2.6154e+02\n",
      "Epoch 30150, Training-Loss 2.0980e+00, Data-loss 2.1857e-01                  , pde-loss 5.7689e+03, initc-loss 1.2896e+04                    bc_loss 1.2904e+02\n",
      "Epoch 30160, Training-Loss 2.2429e+00, Data-loss 2.7049e-01                  , pde-loss 6.7317e+03, initc-loss 1.2869e+04                    bc_loss 1.2329e+02\n",
      "Epoch 30170, Training-Loss 2.3247e+00, Data-loss 4.2465e-01                  , pde-loss 5.6964e+03, initc-loss 1.2899e+04                    bc_loss 4.0546e+02\n",
      "Epoch 30180, Training-Loss 2.4552e+00, Data-loss 4.4545e-01                  , pde-loss 6.2769e+03, initc-loss 1.2858e+04                    bc_loss 9.6265e+02\n",
      "Epoch 30190, Training-Loss 2.2698e+00, Data-loss 2.8816e-01                  , pde-loss 6.1765e+03, initc-loss 1.2941e+04                    bc_loss 6.9890e+02\n",
      "Epoch 30200, Training-Loss 2.1091e+00, Data-loss 2.8048e-01                  , pde-loss 5.2365e+03, initc-loss 1.2954e+04                    bc_loss 9.5148e+01\n",
      "Epoch 30210, Training-Loss 2.3877e+00, Data-loss 4.5143e-01                  , pde-loss 6.2228e+03, initc-loss 1.2836e+04                    bc_loss 3.0359e+02\n",
      "Epoch 30220, Training-Loss 2.3479e+00, Data-loss 5.0548e-01                  , pde-loss 5.3319e+03, initc-loss 1.2862e+04                    bc_loss 2.2982e+02\n",
      "Epoch 30230, Training-Loss 2.1660e+00, Data-loss 2.8171e-01                  , pde-loss 5.1446e+03, initc-loss 1.2856e+04                    bc_loss 8.4242e+02\n",
      "Epoch 30240, Training-Loss 2.2592e+00, Data-loss 3.3753e-01                  , pde-loss 5.9333e+03, initc-loss 1.2942e+04                    bc_loss 3.4162e+02\n",
      "Epoch 30250, Training-Loss 2.1739e+00, Data-loss 2.8104e-01                  , pde-loss 5.8102e+03, initc-loss 1.2881e+04                    bc_loss 2.3804e+02\n",
      "Epoch 30260, Training-Loss 2.1730e+00, Data-loss 3.0039e-01                  , pde-loss 5.6603e+03, initc-loss 1.2889e+04                    bc_loss 1.7669e+02\n",
      "Epoch 30270, Training-Loss 2.3484e+00, Data-loss 4.3873e-01                  , pde-loss 5.9029e+03, initc-loss 1.2825e+04                    bc_loss 3.6873e+02\n",
      "Epoch 30280, Training-Loss 2.3278e+00, Data-loss 3.4395e-01                  , pde-loss 6.2730e+03, initc-loss 1.2931e+04                    bc_loss 6.3410e+02\n",
      "Epoch 30290, Training-Loss 2.2014e+00, Data-loss 2.8557e-01                  , pde-loss 6.0226e+03, initc-loss 1.2855e+04                    bc_loss 2.7984e+02\n",
      "Epoch 30300, Training-Loss 2.1968e+00, Data-loss 3.5487e-01                  , pde-loss 5.3692e+03, initc-loss 1.2887e+04                    bc_loss 1.6288e+02\n",
      "Epoch 30310, Training-Loss 2.2343e+00, Data-loss 3.5868e-01                  , pde-loss 5.5495e+03, initc-loss 1.3018e+04                    bc_loss 1.8900e+02\n",
      "Epoch 30320, Training-Loss 2.1446e+00, Data-loss 2.7258e-01                  , pde-loss 5.6892e+03, initc-loss 1.2845e+04                    bc_loss 1.8664e+02\n",
      "Epoch 30330, Training-Loss 2.2719e+00, Data-loss 4.2444e-01                  , pde-loss 5.0633e+03, initc-loss 1.2984e+04                    bc_loss 4.2740e+02\n",
      "Epoch 30340, Training-Loss 2.2012e+00, Data-loss 3.0213e-01                  , pde-loss 5.8646e+03, initc-loss 1.2993e+04                    bc_loss 1.3235e+02\n",
      "Epoch 30350, Training-Loss 2.2904e+00, Data-loss 4.3034e-01                  , pde-loss 5.5520e+03, initc-loss 1.2817e+04                    bc_loss 2.3200e+02\n",
      "Epoch 30360, Training-Loss 2.4140e+00, Data-loss 5.4881e-01                  , pde-loss 4.9197e+03, initc-loss 1.3009e+04                    bc_loss 7.2381e+02\n",
      "Epoch 30370, Training-Loss 2.2988e+00, Data-loss 4.3475e-01                  , pde-loss 5.4378e+03, initc-loss 1.2809e+04                    bc_loss 3.9318e+02\n",
      "Epoch 30380, Training-Loss 2.7532e+00, Data-loss 7.2696e-01                  , pde-loss 6.5306e+03, initc-loss 1.3010e+04                    bc_loss 7.2223e+02\n",
      "Epoch 30390, Training-Loss 2.1660e+00, Data-loss 3.0573e-01                  , pde-loss 5.5198e+03, initc-loss 1.2907e+04                    bc_loss 1.7582e+02\n",
      "Epoch 30400, Training-Loss 2.2561e+00, Data-loss 3.4683e-01                  , pde-loss 6.0815e+03, initc-loss 1.2841e+04                    bc_loss 1.6952e+02\n",
      "Epoch 30410, Training-Loss 2.4241e+00, Data-loss 3.6727e-01                  , pde-loss 6.5930e+03, initc-loss 1.2952e+04                    bc_loss 1.0240e+03\n",
      "Epoch 30420, Training-Loss 2.2348e+00, Data-loss 2.6208e-01                  , pde-loss 6.1190e+03, initc-loss 1.2889e+04                    bc_loss 7.1892e+02\n",
      "Epoch 30430, Training-Loss 2.3780e+00, Data-loss 4.6764e-01                  , pde-loss 5.7402e+03, initc-loss 1.2943e+04                    bc_loss 4.2050e+02\n",
      "Epoch 30440, Training-Loss 2.2617e+00, Data-loss 3.8102e-01                  , pde-loss 5.6115e+03, initc-loss 1.2891e+04                    bc_loss 3.0469e+02\n",
      "Epoch 30450, Training-Loss 2.6521e+00, Data-loss 5.9261e-01                  , pde-loss 7.0693e+03, initc-loss 1.2954e+04                    bc_loss 5.7157e+02\n",
      "Epoch 30460, Training-Loss 2.2604e+00, Data-loss 3.5384e-01                  , pde-loss 5.6331e+03, initc-loss 1.2816e+04                    bc_loss 6.1616e+02\n",
      "Epoch 30470, Training-Loss 2.2981e+00, Data-loss 3.7700e-01                  , pde-loss 5.8932e+03, initc-loss 1.2923e+04                    bc_loss 3.9564e+02\n",
      "Epoch 30480, Training-Loss 2.3567e+00, Data-loss 4.3144e-01                  , pde-loss 5.9376e+03, initc-loss 1.2951e+04                    bc_loss 3.6394e+02\n",
      "Epoch 30490, Training-Loss 2.3742e+00, Data-loss 3.5777e-01                  , pde-loss 6.7045e+03, initc-loss 1.2798e+04                    bc_loss 6.6192e+02\n",
      "Epoch 30500, Training-Loss 2.1732e+00, Data-loss 3.3415e-01                  , pde-loss 5.4142e+03, initc-loss 1.2884e+04                    bc_loss 9.2413e+01\n",
      "Epoch 30510, Training-Loss 2.1498e+00, Data-loss 2.7375e-01                  , pde-loss 5.7538e+03, initc-loss 1.2956e+04                    bc_loss 5.1301e+01\n",
      "Epoch 30520, Training-Loss 2.1280e+00, Data-loss 2.6590e-01                  , pde-loss 5.5683e+03, initc-loss 1.2832e+04                    bc_loss 2.2130e+02\n",
      "Epoch 30530, Training-Loss 2.1880e+00, Data-loss 3.2428e-01                  , pde-loss 5.5948e+03, initc-loss 1.2844e+04                    bc_loss 1.9813e+02\n",
      "Epoch 30540, Training-Loss 2.2513e+00, Data-loss 3.7308e-01                  , pde-loss 5.6827e+03, initc-loss 1.2751e+04                    bc_loss 3.4837e+02\n",
      "Epoch 30550, Training-Loss 2.3037e+00, Data-loss 3.7014e-01                  , pde-loss 6.1611e+03, initc-loss 1.2963e+04                    bc_loss 2.1243e+02\n",
      "Epoch 30560, Training-Loss 2.2343e+00, Data-loss 3.2283e-01                  , pde-loss 5.8935e+03, initc-loss 1.2845e+04                    bc_loss 3.7680e+02\n",
      "Epoch 30570, Training-Loss 2.2074e+00, Data-loss 3.1459e-01                  , pde-loss 5.7783e+03, initc-loss 1.2987e+04                    bc_loss 1.6371e+02\n",
      "Epoch 30580, Training-Loss 2.1023e+00, Data-loss 2.9432e-01                  , pde-loss 4.9927e+03, initc-loss 1.2922e+04                    bc_loss 1.6447e+02\n",
      "Epoch 30590, Training-Loss 2.3678e+00, Data-loss 3.8877e-01                  , pde-loss 6.6117e+03, initc-loss 1.2952e+04                    bc_loss 2.2662e+02\n",
      "Epoch 30600, Training-Loss 2.1683e+00, Data-loss 2.5163e-01                  , pde-loss 6.1710e+03, initc-loss 1.2894e+04                    bc_loss 1.0179e+02\n",
      "Epoch 30610, Training-Loss 2.2848e+00, Data-loss 3.2036e-01                  , pde-loss 6.6040e+03, initc-loss 1.2931e+04                    bc_loss 1.0923e+02\n",
      "Epoch 30620, Training-Loss 2.2648e+00, Data-loss 3.5160e-01                  , pde-loss 5.9996e+03, initc-loss 1.2898e+04                    bc_loss 2.3508e+02\n",
      "Epoch 30630, Training-Loss 2.0863e+00, Data-loss 1.9315e-01                  , pde-loss 5.9656e+03, initc-loss 1.2902e+04                    bc_loss 6.4488e+01\n",
      "Epoch 30640, Training-Loss 2.3566e+00, Data-loss 3.8960e-01                  , pde-loss 6.5469e+03, initc-loss 1.2941e+04                    bc_loss 1.8155e+02\n",
      "Epoch 30650, Training-Loss 2.4125e+00, Data-loss 4.5351e-01                  , pde-loss 5.6464e+03, initc-loss 1.2882e+04                    bc_loss 1.0615e+03\n",
      "Epoch 30660, Training-Loss 2.4878e+00, Data-loss 4.7393e-01                  , pde-loss 5.5041e+03, initc-loss 1.2932e+04                    bc_loss 1.7019e+03\n",
      "Epoch 30670, Training-Loss 2.2349e+00, Data-loss 4.3396e-01                  , pde-loss 5.0512e+03, initc-loss 1.2860e+04                    bc_loss 9.8125e+01\n",
      "Epoch 30680, Training-Loss 2.3037e+00, Data-loss 3.2785e-01                  , pde-loss 6.6573e+03, initc-loss 1.2853e+04                    bc_loss 2.4847e+02\n",
      "Epoch 30690, Training-Loss 2.3173e+00, Data-loss 3.9158e-01                  , pde-loss 6.2879e+03, initc-loss 1.2868e+04                    bc_loss 1.0108e+02\n",
      "Epoch 30700, Training-Loss 2.2344e+00, Data-loss 3.1141e-01                  , pde-loss 6.2542e+03, initc-loss 1.2851e+04                    bc_loss 1.2535e+02\n",
      "Epoch 30710, Training-Loss 2.1522e+00, Data-loss 2.7603e-01                  , pde-loss 5.6129e+03, initc-loss 1.2901e+04                    bc_loss 2.4806e+02\n",
      "Epoch 30720, Training-Loss 2.0594e+00, Data-loss 2.3804e-01                  , pde-loss 5.2023e+03, initc-loss 1.2924e+04                    bc_loss 8.6913e+01\n",
      "Epoch 30730, Training-Loss 2.1745e+00, Data-loss 2.3024e-01                  , pde-loss 6.4645e+03, initc-loss 1.2878e+04                    bc_loss 1.0016e+02\n",
      "Epoch 30740, Training-Loss 2.1288e+00, Data-loss 2.5149e-01                  , pde-loss 5.7775e+03, initc-loss 1.2915e+04                    bc_loss 8.0509e+01\n",
      "Epoch 30750, Training-Loss 2.2656e+00, Data-loss 4.1153e-01                  , pde-loss 5.5559e+03, initc-loss 1.2894e+04                    bc_loss 9.0578e+01\n",
      "Epoch 30760, Training-Loss 2.2218e+00, Data-loss 2.9839e-01                  , pde-loss 5.7773e+03, initc-loss 1.2983e+04                    bc_loss 4.7308e+02\n",
      "Epoch 30770, Training-Loss 2.2950e+00, Data-loss 4.4030e-01                  , pde-loss 5.1880e+03, initc-loss 1.3022e+04                    bc_loss 3.3624e+02\n",
      "Epoch 30780, Training-Loss 2.4534e+00, Data-loss 4.6555e-01                  , pde-loss 6.5918e+03, initc-loss 1.2924e+04                    bc_loss 3.6196e+02\n",
      "Epoch 30790, Training-Loss 2.1997e+00, Data-loss 3.5401e-01                  , pde-loss 5.2501e+03, initc-loss 1.3003e+04                    bc_loss 2.0355e+02\n",
      "Epoch 30800, Training-Loss 2.0926e+00, Data-loss 2.8512e-01                  , pde-loss 5.0930e+03, initc-loss 1.2911e+04                    bc_loss 7.0213e+01\n",
      "Epoch 30810, Training-Loss 2.3462e+00, Data-loss 4.1624e-01                  , pde-loss 5.9066e+03, initc-loss 1.2906e+04                    bc_loss 4.8707e+02\n",
      "Epoch 30820, Training-Loss 2.1380e+00, Data-loss 2.9268e-01                  , pde-loss 5.4233e+03, initc-loss 1.2959e+04                    bc_loss 7.0462e+01\n",
      "Epoch 30830, Training-Loss 2.7209e+00, Data-loss 6.9558e-01                  , pde-loss 6.4131e+03, initc-loss 1.2830e+04                    bc_loss 1.0094e+03\n",
      "Epoch 30840, Training-Loss 2.4114e+00, Data-loss 4.5645e-01                  , pde-loss 6.3636e+03, initc-loss 1.3011e+04                    bc_loss 1.7517e+02\n",
      "Epoch 30850, Training-Loss 2.2756e+00, Data-loss 4.0321e-01                  , pde-loss 5.1691e+03, initc-loss 1.2892e+04                    bc_loss 6.6248e+02\n",
      "Epoch 30860, Training-Loss 2.1642e+00, Data-loss 3.0225e-01                  , pde-loss 5.2646e+03, initc-loss 1.2938e+04                    bc_loss 4.1672e+02\n",
      "Epoch 30870, Training-Loss 2.1795e+00, Data-loss 3.4447e-01                  , pde-loss 5.1604e+03, initc-loss 1.2878e+04                    bc_loss 3.1190e+02\n",
      "Epoch 30880, Training-Loss 2.3564e+00, Data-loss 4.4629e-01                  , pde-loss 5.7252e+03, initc-loss 1.2918e+04                    bc_loss 4.5791e+02\n",
      "Epoch 30890, Training-Loss 2.3002e+00, Data-loss 2.9515e-01                  , pde-loss 7.0190e+03, initc-loss 1.2907e+04                    bc_loss 1.2450e+02\n",
      "Epoch 30900, Training-Loss 2.1202e+00, Data-loss 2.5180e-01                  , pde-loss 5.7172e+03, initc-loss 1.2876e+04                    bc_loss 9.0035e+01\n",
      "Epoch 30910, Training-Loss 2.2678e+00, Data-loss 3.0730e-01                  , pde-loss 6.4764e+03, initc-loss 1.2953e+04                    bc_loss 1.7512e+02\n",
      "Epoch 30920, Training-Loss 2.1309e+00, Data-loss 2.0501e-01                  , pde-loss 5.0300e+03, initc-loss 1.2910e+04                    bc_loss 1.3192e+03\n",
      "Epoch 30930, Training-Loss 2.1421e+00, Data-loss 2.8956e-01                  , pde-loss 5.2885e+03, initc-loss 1.2907e+04                    bc_loss 3.2985e+02\n",
      "Epoch 30940, Training-Loss 2.2399e+00, Data-loss 3.5023e-01                  , pde-loss 5.8985e+03, initc-loss 1.2876e+04                    bc_loss 1.2218e+02\n",
      "Epoch 30950, Training-Loss 2.2667e+00, Data-loss 3.5254e-01                  , pde-loss 5.8860e+03, initc-loss 1.2944e+04                    bc_loss 3.1129e+02\n",
      "Epoch 30960, Training-Loss 2.3290e+00, Data-loss 4.4608e-01                  , pde-loss 5.6436e+03, initc-loss 1.2865e+04                    bc_loss 3.2038e+02\n",
      "Epoch 30970, Training-Loss 2.3683e+00, Data-loss 4.5044e-01                  , pde-loss 5.8092e+03, initc-loss 1.2954e+04                    bc_loss 4.1477e+02\n",
      "Epoch 30980, Training-Loss 2.2824e+00, Data-loss 4.0492e-01                  , pde-loss 5.7174e+03, initc-loss 1.2923e+04                    bc_loss 1.3512e+02\n",
      "Epoch 30990, Training-Loss 2.1485e+00, Data-loss 3.1278e-01                  , pde-loss 5.4958e+03, initc-loss 1.2817e+04                    bc_loss 4.4388e+01\n",
      "Epoch 31000, Training-Loss 2.2444e+00, Data-loss 3.5253e-01                  , pde-loss 5.8444e+03, initc-loss 1.2959e+04                    bc_loss 1.1612e+02\n",
      "Epoch 31010, Training-Loss 2.4206e+00, Data-loss 4.7708e-01                  , pde-loss 6.4469e+03, initc-loss 1.2906e+04                    bc_loss 8.2414e+01\n",
      "Epoch 31020, Training-Loss 2.1867e+00, Data-loss 2.4073e-01                  , pde-loss 6.0938e+03, initc-loss 1.2934e+04                    bc_loss 4.3261e+02\n",
      "Epoch 31030, Training-Loss 2.3015e+00, Data-loss 4.3559e-01                  , pde-loss 5.6291e+03, initc-loss 1.2857e+04                    bc_loss 1.7334e+02\n",
      "Epoch 31040, Training-Loss 2.3158e+00, Data-loss 4.6392e-01                  , pde-loss 5.5859e+03, initc-loss 1.2789e+04                    bc_loss 1.4309e+02\n",
      "Epoch 31050, Training-Loss 2.2670e+00, Data-loss 3.5681e-01                  , pde-loss 5.9982e+03, initc-loss 1.2883e+04                    bc_loss 2.2083e+02\n",
      "Epoch 31060, Training-Loss 2.2816e+00, Data-loss 3.9349e-01                  , pde-loss 5.8121e+03, initc-loss 1.2918e+04                    bc_loss 1.5118e+02\n",
      "Epoch 31070, Training-Loss 2.2297e+00, Data-loss 3.6896e-01                  , pde-loss 5.5402e+03, initc-loss 1.2938e+04                    bc_loss 1.2921e+02\n",
      "Epoch 31080, Training-Loss 2.2243e+00, Data-loss 3.2586e-01                  , pde-loss 5.9864e+03, initc-loss 1.2903e+04                    bc_loss 9.4618e+01\n",
      "Epoch 31090, Training-Loss 2.2838e+00, Data-loss 3.7635e-01                  , pde-loss 5.9041e+03, initc-loss 1.2895e+04                    bc_loss 2.7570e+02\n",
      "Epoch 31100, Training-Loss 2.2713e+00, Data-loss 3.9847e-01                  , pde-loss 5.5243e+03, initc-loss 1.2854e+04                    bc_loss 3.5046e+02\n",
      "Epoch 31110, Training-Loss 2.2607e+00, Data-loss 3.9443e-01                  , pde-loss 5.1582e+03, initc-loss 1.2874e+04                    bc_loss 6.2984e+02\n",
      "Epoch 31120, Training-Loss 2.2281e+00, Data-loss 3.4665e-01                  , pde-loss 5.2808e+03, initc-loss 1.2963e+04                    bc_loss 5.7028e+02\n",
      "Epoch 31130, Training-Loss 2.4351e+00, Data-loss 4.8049e-01                  , pde-loss 6.5284e+03, initc-loss 1.2835e+04                    bc_loss 1.8283e+02\n",
      "Epoch 31140, Training-Loss 2.1628e+00, Data-loss 2.7971e-01                  , pde-loss 5.7839e+03, initc-loss 1.2883e+04                    bc_loss 1.6439e+02\n",
      "Epoch 31150, Training-Loss 2.6110e+00, Data-loss 5.9578e-01                  , pde-loss 5.9123e+03, initc-loss 1.2974e+04                    bc_loss 1.2654e+03\n",
      "Epoch 31160, Training-Loss 2.3724e+00, Data-loss 5.2156e-01                  , pde-loss 5.6117e+03, initc-loss 1.2806e+04                    bc_loss 9.0609e+01\n",
      "Epoch 31170, Training-Loss 2.2784e+00, Data-loss 3.5728e-01                  , pde-loss 5.8557e+03, initc-loss 1.3003e+04                    bc_loss 3.5201e+02\n",
      "Epoch 31180, Training-Loss 2.1666e+00, Data-loss 3.2510e-01                  , pde-loss 5.4246e+03, initc-loss 1.2883e+04                    bc_loss 1.0711e+02\n",
      "Epoch 31190, Training-Loss 2.2503e+00, Data-loss 2.8209e-01                  , pde-loss 6.6493e+03, initc-loss 1.2960e+04                    bc_loss 7.2324e+01\n",
      "Epoch 31200, Training-Loss 2.1488e+00, Data-loss 2.4225e-01                  , pde-loss 6.1887e+03, initc-loss 1.2842e+04                    bc_loss 3.4933e+01\n",
      "Epoch 31210, Training-Loss 2.2855e+00, Data-loss 2.8568e-01                  , pde-loss 6.3276e+03, initc-loss 1.2913e+04                    bc_loss 7.5750e+02\n",
      "Epoch 31220, Training-Loss 2.1058e+00, Data-loss 3.1002e-01                  , pde-loss 4.9488e+03, initc-loss 1.2850e+04                    bc_loss 1.5891e+02\n",
      "Epoch 31230, Training-Loss 2.4684e+00, Data-loss 5.2596e-01                  , pde-loss 6.2920e+03, initc-loss 1.2994e+04                    bc_loss 1.3855e+02\n",
      "Epoch 31240, Training-Loss 2.2736e+00, Data-loss 3.7786e-01                  , pde-loss 5.7868e+03, initc-loss 1.2899e+04                    bc_loss 2.7180e+02\n",
      "Epoch 31250, Training-Loss 2.3308e+00, Data-loss 3.9169e-01                  , pde-loss 6.0278e+03, initc-loss 1.2950e+04                    bc_loss 4.1283e+02\n",
      "Epoch 31260, Training-Loss 2.2332e+00, Data-loss 3.5700e-01                  , pde-loss 5.7343e+03, initc-loss 1.2934e+04                    bc_loss 9.4577e+01\n",
      "Epoch 31270, Training-Loss 2.3296e+00, Data-loss 3.5986e-01                  , pde-loss 5.9801e+03, initc-loss 1.2919e+04                    bc_loss 7.9791e+02\n",
      "Epoch 31280, Training-Loss 2.3398e+00, Data-loss 4.1151e-01                  , pde-loss 5.3043e+03, initc-loss 1.3023e+04                    bc_loss 9.5564e+02\n",
      "Epoch 31290, Training-Loss 2.3845e+00, Data-loss 5.4369e-01                  , pde-loss 5.2352e+03, initc-loss 1.2786e+04                    bc_loss 3.8669e+02\n",
      "Epoch 31300, Training-Loss 2.2698e+00, Data-loss 4.0606e-01                  , pde-loss 5.6053e+03, initc-loss 1.2950e+04                    bc_loss 8.2302e+01\n",
      "Epoch 31310, Training-Loss 2.2566e+00, Data-loss 4.2083e-01                  , pde-loss 5.2972e+03, initc-loss 1.2861e+04                    bc_loss 2.0016e+02\n",
      "Epoch 31320, Training-Loss 2.2313e+00, Data-loss 2.9180e-01                  , pde-loss 6.2818e+03, initc-loss 1.2945e+04                    bc_loss 1.6731e+02\n",
      "Epoch 31330, Training-Loss 2.2770e+00, Data-loss 3.1970e-01                  , pde-loss 6.6032e+03, initc-loss 1.2871e+04                    bc_loss 9.8656e+01\n",
      "Epoch 31340, Training-Loss 2.0895e+00, Data-loss 2.9748e-01                  , pde-loss 4.9940e+03, initc-loss 1.2832e+04                    bc_loss 9.4746e+01\n",
      "Epoch 31350, Training-Loss 2.1018e+00, Data-loss 2.2981e-01                  , pde-loss 5.6416e+03, initc-loss 1.2835e+04                    bc_loss 2.4256e+02\n",
      "Epoch 31360, Training-Loss 2.2715e+00, Data-loss 3.3750e-01                  , pde-loss 6.3102e+03, initc-loss 1.2919e+04                    bc_loss 1.1012e+02\n",
      "Epoch 31370, Training-Loss 2.2372e+00, Data-loss 2.8659e-01                  , pde-loss 6.4036e+03, initc-loss 1.2944e+04                    bc_loss 1.5946e+02\n",
      "Epoch 31380, Training-Loss 2.1970e+00, Data-loss 2.7868e-01                  , pde-loss 6.1090e+03, initc-loss 1.2926e+04                    bc_loss 1.4787e+02\n",
      "Epoch 31390, Training-Loss 2.2115e+00, Data-loss 3.3787e-01                  , pde-loss 5.6745e+03, initc-loss 1.2950e+04                    bc_loss 1.1229e+02\n",
      "Epoch 31400, Training-Loss 2.4491e+00, Data-loss 4.4912e-01                  , pde-loss 5.9598e+03, initc-loss 1.2991e+04                    bc_loss 1.0493e+03\n",
      "Epoch 31410, Training-Loss 2.3113e+00, Data-loss 4.2288e-01                  , pde-loss 5.8167e+03, initc-loss 1.2853e+04                    bc_loss 2.1460e+02\n",
      "Epoch 31420, Training-Loss 2.4161e+00, Data-loss 4.9067e-01                  , pde-loss 6.1429e+03, initc-loss 1.2995e+04                    bc_loss 1.1681e+02\n",
      "Epoch 31430, Training-Loss 2.1867e+00, Data-loss 2.0724e-01                  , pde-loss 6.7944e+03, initc-loss 1.2860e+04                    bc_loss 1.3997e+02\n",
      "Epoch 31440, Training-Loss 2.4000e+00, Data-loss 5.3685e-01                  , pde-loss 5.2095e+03, initc-loss 1.3050e+04                    bc_loss 3.7219e+02\n",
      "Epoch 31450, Training-Loss 2.1469e+00, Data-loss 3.3828e-01                  , pde-loss 4.8233e+03, initc-loss 1.2869e+04                    bc_loss 3.9371e+02\n",
      "Epoch 31460, Training-Loss 2.2563e+00, Data-loss 3.8534e-01                  , pde-loss 5.5338e+03, initc-loss 1.2850e+04                    bc_loss 3.2523e+02\n",
      "Epoch 31470, Training-Loss 1.9945e+00, Data-loss 2.1551e-01                  , pde-loss 4.7498e+03, initc-loss 1.2866e+04                    bc_loss 1.7458e+02\n",
      "Epoch 31480, Training-Loss 2.2811e+00, Data-loss 3.6222e-01                  , pde-loss 5.9125e+03, initc-loss 1.2893e+04                    bc_loss 3.8283e+02\n",
      "Epoch 31490, Training-Loss 2.1769e+00, Data-loss 2.6569e-01                  , pde-loss 5.8799e+03, initc-loss 1.2985e+04                    bc_loss 2.4690e+02\n",
      "Epoch 31500, Training-Loss 2.2846e+00, Data-loss 3.2976e-01                  , pde-loss 6.5993e+03, initc-loss 1.2892e+04                    bc_loss 5.7305e+01\n",
      "Epoch 31510, Training-Loss 2.2128e+00, Data-loss 2.8503e-01                  , pde-loss 5.8407e+03, initc-loss 1.2867e+04                    bc_loss 5.7015e+02\n",
      "Epoch 31520, Training-Loss 2.1715e+00, Data-loss 2.9742e-01                  , pde-loss 5.5372e+03, initc-loss 1.2940e+04                    bc_loss 2.6317e+02\n",
      "Epoch 31530, Training-Loss 2.3079e+00, Data-loss 3.5146e-01                  , pde-loss 6.0731e+03, initc-loss 1.2913e+04                    bc_loss 5.7880e+02\n",
      "Epoch 31540, Training-Loss 2.1471e+00, Data-loss 3.2712e-01                  , pde-loss 5.1900e+03, initc-loss 1.2895e+04                    bc_loss 1.1564e+02\n",
      "Epoch 31550, Training-Loss 2.1498e+00, Data-loss 2.7021e-01                  , pde-loss 5.5587e+03, initc-loss 1.2916e+04                    bc_loss 3.2052e+02\n",
      "Epoch 31560, Training-Loss 2.2541e+00, Data-loss 3.5701e-01                  , pde-loss 5.7891e+03, initc-loss 1.2884e+04                    bc_loss 2.9781e+02\n",
      "Epoch 31570, Training-Loss 2.1873e+00, Data-loss 3.2077e-01                  , pde-loss 5.4423e+03, initc-loss 1.2958e+04                    bc_loss 2.6507e+02\n",
      "Epoch 31580, Training-Loss 2.4355e+00, Data-loss 4.0658e-01                  , pde-loss 5.9666e+03, initc-loss 1.2893e+04                    bc_loss 1.4304e+03\n",
      "Epoch 31590, Training-Loss 2.3075e+00, Data-loss 4.5437e-01                  , pde-loss 5.2235e+03, initc-loss 1.2971e+04                    bc_loss 3.3761e+02\n",
      "Epoch 31600, Training-Loss 2.4236e+00, Data-loss 4.5176e-01                  , pde-loss 5.9243e+03, initc-loss 1.2877e+04                    bc_loss 9.1719e+02\n",
      "Epoch 31610, Training-Loss 2.5139e+00, Data-loss 5.2783e-01                  , pde-loss 6.4346e+03, initc-loss 1.2987e+04                    bc_loss 4.3871e+02\n",
      "Epoch 31620, Training-Loss 2.5578e+00, Data-loss 6.1575e-01                  , pde-loss 6.2610e+03, initc-loss 1.2787e+04                    bc_loss 3.7262e+02\n",
      "Epoch 31630, Training-Loss 2.3679e+00, Data-loss 3.3791e-01                  , pde-loss 6.0611e+03, initc-loss 1.2974e+04                    bc_loss 1.2649e+03\n",
      "Epoch 31640, Training-Loss 2.4141e+00, Data-loss 5.6804e-01                  , pde-loss 5.3091e+03, initc-loss 1.2770e+04                    bc_loss 3.8191e+02\n",
      "Epoch 31650, Training-Loss 2.4545e+00, Data-loss 4.7058e-01                  , pde-loss 6.0067e+03, initc-loss 1.3091e+04                    bc_loss 7.4182e+02\n",
      "Epoch 31660, Training-Loss 2.2695e+00, Data-loss 3.7444e-01                  , pde-loss 6.0540e+03, initc-loss 1.2786e+04                    bc_loss 1.1075e+02\n",
      "Epoch 31670, Training-Loss 2.4067e+00, Data-loss 5.2537e-01                  , pde-loss 5.9116e+03, initc-loss 1.2774e+04                    bc_loss 1.2712e+02\n",
      "Epoch 31680, Training-Loss 2.1174e+00, Data-loss 3.1538e-01                  , pde-loss 4.7654e+03, initc-loss 1.2974e+04                    bc_loss 2.8089e+02\n",
      "Epoch 31690, Training-Loss 2.1276e+00, Data-loss 2.7140e-01                  , pde-loss 5.3859e+03, initc-loss 1.2930e+04                    bc_loss 2.4606e+02\n",
      "Epoch 31700, Training-Loss 2.3275e+00, Data-loss 3.6280e-01                  , pde-loss 6.6911e+03, initc-loss 1.2838e+04                    bc_loss 1.1830e+02\n",
      "Epoch 31710, Training-Loss 2.1765e+00, Data-loss 2.1481e-01                  , pde-loss 6.5680e+03, initc-loss 1.2910e+04                    bc_loss 1.3902e+02\n",
      "Epoch 31720, Training-Loss 2.3373e+00, Data-loss 3.8136e-01                  , pde-loss 6.2068e+03, initc-loss 1.2955e+04                    bc_loss 3.9764e+02\n",
      "Epoch 31730, Training-Loss 2.2427e+00, Data-loss 3.7131e-01                  , pde-loss 5.4224e+03, initc-loss 1.2874e+04                    bc_loss 4.1712e+02\n",
      "Epoch 31740, Training-Loss 2.3704e+00, Data-loss 4.0917e-01                  , pde-loss 6.1876e+03, initc-loss 1.2896e+04                    bc_loss 5.2916e+02\n",
      "Epoch 31750, Training-Loss 2.3325e+00, Data-loss 4.0905e-01                  , pde-loss 5.6684e+03, initc-loss 1.2830e+04                    bc_loss 7.3582e+02\n",
      "Epoch 31760, Training-Loss 2.4640e+00, Data-loss 5.3226e-01                  , pde-loss 5.3525e+03, initc-loss 1.2962e+04                    bc_loss 1.0037e+03\n",
      "Epoch 31770, Training-Loss 2.2377e+00, Data-loss 3.8884e-01                  , pde-loss 5.4885e+03, initc-loss 1.2873e+04                    bc_loss 1.2681e+02\n",
      "Epoch 31780, Training-Loss 2.0356e+00, Data-loss 2.2960e-01                  , pde-loss 4.9541e+03, initc-loss 1.2931e+04                    bc_loss 1.7505e+02\n",
      "Epoch 31790, Training-Loss 2.0720e+00, Data-loss 2.8043e-01                  , pde-loss 4.9831e+03, initc-loss 1.2896e+04                    bc_loss 3.6462e+01\n",
      "Epoch 31800, Training-Loss 2.2383e+00, Data-loss 2.8888e-01                  , pde-loss 5.9904e+03, initc-loss 1.2991e+04                    bc_loss 5.1314e+02\n",
      "Epoch 31810, Training-Loss 2.1892e+00, Data-loss 2.3471e-01                  , pde-loss 6.4497e+03, initc-loss 1.2901e+04                    bc_loss 1.9407e+02\n",
      "Epoch 31820, Training-Loss 2.1864e+00, Data-loss 3.1489e-01                  , pde-loss 5.5593e+03, initc-loss 1.2829e+04                    bc_loss 3.2691e+02\n",
      "Epoch 31830, Training-Loss 2.2861e+00, Data-loss 3.3973e-01                  , pde-loss 6.0414e+03, initc-loss 1.2982e+04                    bc_loss 4.4091e+02\n",
      "Epoch 31840, Training-Loss 2.2184e+00, Data-loss 3.3200e-01                  , pde-loss 5.7751e+03, initc-loss 1.2854e+04                    bc_loss 2.3541e+02\n",
      "Epoch 31850, Training-Loss 2.1521e+00, Data-loss 2.6813e-01                  , pde-loss 5.6209e+03, initc-loss 1.2940e+04                    bc_loss 2.7865e+02\n",
      "Epoch 31860, Training-Loss 2.2680e+00, Data-loss 3.3532e-01                  , pde-loss 6.3030e+03, initc-loss 1.2946e+04                    bc_loss 7.7701e+01\n",
      "Epoch 31870, Training-Loss 2.2279e+00, Data-loss 2.9109e-01                  , pde-loss 5.9481e+03, initc-loss 1.2945e+04                    bc_loss 4.7510e+02\n",
      "Epoch 31880, Training-Loss 2.1173e+00, Data-loss 2.5829e-01                  , pde-loss 5.5541e+03, initc-loss 1.2917e+04                    bc_loss 1.1920e+02\n",
      "Epoch 31890, Training-Loss 2.1426e+00, Data-loss 2.6088e-01                  , pde-loss 5.7014e+03, initc-loss 1.2924e+04                    bc_loss 1.9107e+02\n",
      "Epoch 31900, Training-Loss 2.1003e+00, Data-loss 2.8175e-01                  , pde-loss 5.1217e+03, initc-loss 1.2937e+04                    bc_loss 1.2628e+02\n",
      "Epoch 31910, Training-Loss 2.2850e+00, Data-loss 3.9559e-01                  , pde-loss 5.8152e+03, initc-loss 1.2930e+04                    bc_loss 1.4949e+02\n",
      "Epoch 31920, Training-Loss 2.6345e+00, Data-loss 6.1194e-01                  , pde-loss 6.0972e+03, initc-loss 1.2907e+04                    bc_loss 1.2208e+03\n",
      "Epoch 31930, Training-Loss 2.4037e+00, Data-loss 4.8002e-01                  , pde-loss 5.7864e+03, initc-loss 1.2959e+04                    bc_loss 4.9187e+02\n",
      "Epoch 31940, Training-Loss 2.1798e+00, Data-loss 3.2814e-01                  , pde-loss 5.4389e+03, initc-loss 1.2900e+04                    bc_loss 1.7777e+02\n",
      "Epoch 31950, Training-Loss 2.2670e+00, Data-loss 3.6154e-01                  , pde-loss 5.6167e+03, initc-loss 1.2880e+04                    bc_loss 5.5746e+02\n",
      "Epoch 31960, Training-Loss 2.4432e+00, Data-loss 4.2276e-01                  , pde-loss 7.0514e+03, initc-loss 1.2970e+04                    bc_loss 1.8362e+02\n",
      "Epoch 31970, Training-Loss 2.2615e+00, Data-loss 3.2633e-01                  , pde-loss 6.0082e+03, initc-loss 1.2920e+04                    bc_loss 4.2381e+02\n",
      "Epoch 31980, Training-Loss 2.0686e+00, Data-loss 2.2924e-01                  , pde-loss 5.3724e+03, initc-loss 1.2853e+04                    bc_loss 1.6768e+02\n",
      "Epoch 31990, Training-Loss 2.1663e+00, Data-loss 2.9210e-01                  , pde-loss 5.8531e+03, initc-loss 1.2867e+04                    bc_loss 2.2441e+01\n",
      "Epoch 32000, Training-Loss 2.0591e+00, Data-loss 2.1690e-01                  , pde-loss 5.4978e+03, initc-loss 1.2870e+04                    bc_loss 5.4678e+01\n",
      "Epoch 32010, Training-Loss 2.1913e+00, Data-loss 2.9335e-01                  , pde-loss 5.7731e+03, initc-loss 1.2881e+04                    bc_loss 3.2468e+02\n",
      "Epoch 32020, Training-Loss 2.2607e+00, Data-loss 3.7219e-01                  , pde-loss 5.8302e+03, initc-loss 1.2957e+04                    bc_loss 9.7993e+01\n",
      "Epoch 32030, Training-Loss 2.2587e+00, Data-loss 3.6310e-01                  , pde-loss 5.6972e+03, initc-loss 1.2959e+04                    bc_loss 2.9959e+02\n",
      "Epoch 32040, Training-Loss 2.2619e+00, Data-loss 4.0449e-01                  , pde-loss 5.6112e+03, initc-loss 1.2804e+04                    bc_loss 1.5921e+02\n",
      "Epoch 32050, Training-Loss 2.1315e+00, Data-loss 2.5660e-01                  , pde-loss 5.8280e+03, initc-loss 1.2842e+04                    bc_loss 7.9623e+01\n",
      "Epoch 32060, Training-Loss 2.2495e+00, Data-loss 2.8888e-01                  , pde-loss 6.6041e+03, initc-loss 1.2850e+04                    bc_loss 1.5274e+02\n",
      "Epoch 32070, Training-Loss 2.2274e+00, Data-loss 3.5850e-01                  , pde-loss 5.7415e+03, initc-loss 1.2871e+04                    bc_loss 7.7172e+01\n",
      "Epoch 32080, Training-Loss 2.2585e+00, Data-loss 3.5869e-01                  , pde-loss 5.9739e+03, initc-loss 1.2901e+04                    bc_loss 1.2330e+02\n",
      "Epoch 32090, Training-Loss 2.2945e+00, Data-loss 3.9118e-01                  , pde-loss 6.0904e+03, initc-loss 1.2876e+04                    bc_loss 6.6330e+01\n",
      "Epoch 32100, Training-Loss 2.1944e+00, Data-loss 3.4311e-01                  , pde-loss 5.5193e+03, initc-loss 1.2835e+04                    bc_loss 1.5816e+02\n",
      "Epoch 32110, Training-Loss 2.2279e+00, Data-loss 3.4382e-01                  , pde-loss 5.7755e+03, initc-loss 1.2941e+04                    bc_loss 1.2363e+02\n",
      "Epoch 32120, Training-Loss 2.1816e+00, Data-loss 3.0078e-01                  , pde-loss 5.5239e+03, initc-loss 1.2907e+04                    bc_loss 3.7712e+02\n",
      "Epoch 32130, Training-Loss 2.1344e+00, Data-loss 2.4725e-01                  , pde-loss 5.8714e+03, initc-loss 1.2813e+04                    bc_loss 1.8769e+02\n",
      "Epoch 32140, Training-Loss 2.3326e+00, Data-loss 3.6983e-01                  , pde-loss 6.3783e+03, initc-loss 1.3027e+04                    bc_loss 2.2175e+02\n",
      "Epoch 32150, Training-Loss 2.3579e+00, Data-loss 4.6450e-01                  , pde-loss 5.8473e+03, initc-loss 1.2923e+04                    bc_loss 1.6342e+02\n",
      "Epoch 32160, Training-Loss 2.0400e+00, Data-loss 2.1644e-01                  , pde-loss 5.1877e+03, initc-loss 1.2951e+04                    bc_loss 9.6491e+01\n",
      "Epoch 32170, Training-Loss 2.2503e+00, Data-loss 3.0341e-01                  , pde-loss 6.1939e+03, initc-loss 1.2908e+04                    bc_loss 3.6655e+02\n",
      "Epoch 32180, Training-Loss 2.2118e+00, Data-loss 2.6798e-01                  , pde-loss 6.4085e+03, initc-loss 1.2948e+04                    bc_loss 8.1650e+01\n",
      "Epoch 32190, Training-Loss 2.4704e+00, Data-loss 6.0884e-01                  , pde-loss 5.3594e+03, initc-loss 1.2795e+04                    bc_loss 4.6177e+02\n",
      "Epoch 32200, Training-Loss 2.2174e+00, Data-loss 2.8048e-01                  , pde-loss 6.2358e+03, initc-loss 1.2949e+04                    bc_loss 1.8437e+02\n",
      "Epoch 32210, Training-Loss 2.2281e+00, Data-loss 2.8406e-01                  , pde-loss 6.2518e+03, initc-loss 1.2894e+04                    bc_loss 2.9381e+02\n",
      "Epoch 32220, Training-Loss 2.1971e+00, Data-loss 3.1062e-01                  , pde-loss 5.3945e+03, initc-loss 1.2872e+04                    bc_loss 5.9855e+02\n",
      "Epoch 32230, Training-Loss 2.2136e+00, Data-loss 3.0042e-01                  , pde-loss 6.1994e+03, initc-loss 1.2896e+04                    bc_loss 3.6717e+01\n",
      "Epoch 32240, Training-Loss 2.1262e+00, Data-loss 2.1054e-01                  , pde-loss 6.2139e+03, initc-loss 1.2904e+04                    bc_loss 3.8751e+01\n",
      "Epoch 32250, Training-Loss 2.1696e+00, Data-loss 2.9790e-01                  , pde-loss 5.7905e+03, initc-loss 1.2846e+04                    bc_loss 8.0282e+01\n",
      "Epoch 32260, Training-Loss 2.0670e+00, Data-loss 1.9641e-01                  , pde-loss 5.4743e+03, initc-loss 1.2920e+04                    bc_loss 3.1160e+02\n",
      "Epoch 32270, Training-Loss 2.1595e+00, Data-loss 2.2538e-01                  , pde-loss 6.2706e+03, initc-loss 1.2893e+04                    bc_loss 1.7798e+02\n",
      "Epoch 32280, Training-Loss 2.2019e+00, Data-loss 2.5732e-01                  , pde-loss 6.2276e+03, initc-loss 1.2922e+04                    bc_loss 2.9592e+02\n",
      "Epoch 32290, Training-Loss 2.0864e+00, Data-loss 2.1187e-01                  , pde-loss 5.5920e+03, initc-loss 1.2946e+04                    bc_loss 2.0737e+02\n",
      "Epoch 32300, Training-Loss 2.1826e+00, Data-loss 2.9812e-01                  , pde-loss 5.4730e+03, initc-loss 1.2967e+04                    bc_loss 4.0492e+02\n",
      "Epoch 32310, Training-Loss 2.1581e+00, Data-loss 3.1094e-01                  , pde-loss 4.8750e+03, initc-loss 1.2879e+04                    bc_loss 7.1718e+02\n",
      "Epoch 32320, Training-Loss 2.3040e+00, Data-loss 3.8625e-01                  , pde-loss 6.2277e+03, initc-loss 1.2873e+04                    bc_loss 7.6482e+01\n",
      "Epoch 32330, Training-Loss 2.3273e+00, Data-loss 4.3843e-01                  , pde-loss 5.5587e+03, initc-loss 1.2974e+04                    bc_loss 3.5597e+02\n",
      "Epoch 32340, Training-Loss 2.2862e+00, Data-loss 2.8595e-01                  , pde-loss 6.7190e+03, initc-loss 1.2923e+04                    bc_loss 3.6097e+02\n",
      "Epoch 32350, Training-Loss 2.0607e+00, Data-loss 2.0055e-01                  , pde-loss 5.5805e+03, initc-loss 1.2886e+04                    bc_loss 1.3417e+02\n",
      "Epoch 32360, Training-Loss 2.2784e+00, Data-loss 3.7714e-01                  , pde-loss 6.0191e+03, initc-loss 1.2834e+04                    bc_loss 1.5973e+02\n",
      "Epoch 32370, Training-Loss 2.5242e+00, Data-loss 5.9171e-01                  , pde-loss 6.1832e+03, initc-loss 1.2905e+04                    bc_loss 2.3605e+02\n",
      "Epoch 32380, Training-Loss 2.0720e+00, Data-loss 2.8308e-01                  , pde-loss 4.7070e+03, initc-loss 1.2984e+04                    bc_loss 1.9815e+02\n",
      "Epoch 32390, Training-Loss 2.1001e+00, Data-loss 3.0779e-01                  , pde-loss 4.9314e+03, initc-loss 1.2814e+04                    bc_loss 1.7754e+02\n",
      "Epoch 32400, Training-Loss 2.2857e+00, Data-loss 2.7597e-01                  , pde-loss 7.0712e+03, initc-loss 1.2880e+04                    bc_loss 1.4612e+02\n",
      "Epoch 32410, Training-Loss 2.0945e+00, Data-loss 2.2755e-01                  , pde-loss 5.7112e+03, initc-loss 1.2905e+04                    bc_loss 5.3437e+01\n",
      "Epoch 32420, Training-Loss 2.1924e+00, Data-loss 3.3181e-01                  , pde-loss 5.5965e+03, initc-loss 1.2902e+04                    bc_loss 1.0697e+02\n",
      "Epoch 32430, Training-Loss 2.3176e+00, Data-loss 3.8305e-01                  , pde-loss 6.2956e+03, initc-loss 1.2934e+04                    bc_loss 1.1621e+02\n",
      "Epoch 32440, Training-Loss 2.2220e+00, Data-loss 3.6806e-01                  , pde-loss 5.5292e+03, initc-loss 1.2894e+04                    bc_loss 1.1691e+02\n",
      "Epoch 32450, Training-Loss 2.1882e+00, Data-loss 3.3997e-01                  , pde-loss 5.4337e+03, initc-loss 1.2827e+04                    bc_loss 2.2075e+02\n",
      "Epoch 32460, Training-Loss 2.1708e+00, Data-loss 2.6257e-01                  , pde-loss 5.7785e+03, initc-loss 1.2935e+04                    bc_loss 3.6875e+02\n",
      "Epoch 32470, Training-Loss 2.3111e+00, Data-loss 4.4163e-01                  , pde-loss 5.5320e+03, initc-loss 1.2858e+04                    bc_loss 3.0410e+02\n",
      "Epoch 32480, Training-Loss 2.2196e+00, Data-loss 3.8491e-01                  , pde-loss 5.4525e+03, initc-loss 1.2830e+04                    bc_loss 6.4081e+01\n",
      "Epoch 32490, Training-Loss 2.5379e+00, Data-loss 5.0603e-01                  , pde-loss 5.4751e+03, initc-loss 1.3010e+04                    bc_loss 1.8333e+03\n",
      "Epoch 32500, Training-Loss 2.5321e+00, Data-loss 6.2089e-01                  , pde-loss 5.5855e+03, initc-loss 1.2794e+04                    bc_loss 7.3273e+02\n",
      "Epoch 32510, Training-Loss 2.1611e+00, Data-loss 2.6588e-01                  , pde-loss 5.5842e+03, initc-loss 1.3015e+04                    bc_loss 3.5359e+02\n",
      "Epoch 32520, Training-Loss 2.0899e+00, Data-loss 2.2188e-01                  , pde-loss 5.5662e+03, initc-loss 1.2967e+04                    bc_loss 1.4716e+02\n",
      "Epoch 32530, Training-Loss 2.2476e+00, Data-loss 3.5734e-01                  , pde-loss 5.6738e+03, initc-loss 1.2930e+04                    bc_loss 2.9861e+02\n",
      "Epoch 32540, Training-Loss 2.2384e+00, Data-loss 3.2745e-01                  , pde-loss 6.1284e+03, initc-loss 1.2922e+04                    bc_loss 5.8795e+01\n",
      "Epoch 32550, Training-Loss 2.1824e+00, Data-loss 3.0442e-01                  , pde-loss 5.8503e+03, initc-loss 1.2868e+04                    bc_loss 6.1937e+01\n",
      "Epoch 32560, Training-Loss 2.3428e+00, Data-loss 3.6697e-01                  , pde-loss 6.5887e+03, initc-loss 1.2983e+04                    bc_loss 1.8695e+02\n",
      "Epoch 32570, Training-Loss 2.3108e+00, Data-loss 2.7960e-01                  , pde-loss 7.3115e+03, initc-loss 1.2941e+04                    bc_loss 5.8859e+01\n",
      "Epoch 32580, Training-Loss 2.0946e+00, Data-loss 3.0822e-01                  , pde-loss 4.8460e+03, initc-loss 1.2870e+04                    bc_loss 1.4745e+02\n",
      "Epoch 32590, Training-Loss 2.3135e+00, Data-loss 3.6611e-01                  , pde-loss 5.6423e+03, initc-loss 1.2901e+04                    bc_loss 9.2973e+02\n",
      "Epoch 32600, Training-Loss 2.5888e+00, Data-loss 6.6401e-01                  , pde-loss 5.9873e+03, initc-loss 1.2815e+04                    bc_loss 4.4589e+02\n",
      "Epoch 32610, Training-Loss 2.2844e+00, Data-loss 3.9004e-01                  , pde-loss 5.6660e+03, initc-loss 1.2998e+04                    bc_loss 2.7928e+02\n",
      "Epoch 32620, Training-Loss 2.1069e+00, Data-loss 2.7004e-01                  , pde-loss 5.3782e+03, initc-loss 1.2901e+04                    bc_loss 9.0127e+01\n",
      "Epoch 32630, Training-Loss 2.2353e+00, Data-loss 2.9301e-01                  , pde-loss 6.3087e+03, initc-loss 1.2898e+04                    bc_loss 2.1612e+02\n",
      "Epoch 32640, Training-Loss 2.1602e+00, Data-loss 3.0519e-01                  , pde-loss 5.4626e+03, initc-loss 1.2872e+04                    bc_loss 2.1515e+02\n",
      "Epoch 32650, Training-Loss 2.1963e+00, Data-loss 2.7058e-01                  , pde-loss 6.2285e+03, initc-loss 1.2926e+04                    bc_loss 1.0287e+02\n",
      "Epoch 32660, Training-Loss 2.2790e+00, Data-loss 3.1793e-01                  , pde-loss 6.6691e+03, initc-loss 1.2852e+04                    bc_loss 8.9374e+01\n",
      "Epoch 32670, Training-Loss 2.2473e+00, Data-loss 2.8380e-01                  , pde-loss 6.6019e+03, initc-loss 1.2916e+04                    bc_loss 1.1698e+02\n",
      "Epoch 32680, Training-Loss 2.1955e+00, Data-loss 3.6151e-01                  , pde-loss 5.1876e+03, initc-loss 1.3002e+04                    bc_loss 1.5038e+02\n",
      "Epoch 32690, Training-Loss 2.3471e+00, Data-loss 3.7463e-01                  , pde-loss 5.9598e+03, initc-loss 1.2775e+04                    bc_loss 9.9022e+02\n",
      "Epoch 32700, Training-Loss 2.1464e+00, Data-loss 2.7181e-01                  , pde-loss 5.8250e+03, initc-loss 1.2870e+04                    bc_loss 5.0894e+01\n",
      "Epoch 32710, Training-Loss 2.1137e+00, Data-loss 2.2055e-01                  , pde-loss 6.0334e+03, initc-loss 1.2811e+04                    bc_loss 8.7238e+01\n",
      "Epoch 32720, Training-Loss 2.1211e+00, Data-loss 3.2228e-01                  , pde-loss 4.7706e+03, initc-loss 1.2908e+04                    bc_loss 3.0979e+02\n",
      "Epoch 32730, Training-Loss 2.4276e+00, Data-loss 6.1325e-01                  , pde-loss 4.7428e+03, initc-loss 1.2799e+04                    bc_loss 6.0116e+02\n",
      "Epoch 32740, Training-Loss 2.3216e+00, Data-loss 4.0901e-01                  , pde-loss 6.0254e+03, initc-loss 1.2988e+04                    bc_loss 1.1322e+02\n",
      "Epoch 32750, Training-Loss 2.1648e+00, Data-loss 3.2088e-01                  , pde-loss 5.4970e+03, initc-loss 1.2840e+04                    bc_loss 1.0260e+02\n",
      "Epoch 32760, Training-Loss 2.2840e+00, Data-loss 4.4899e-01                  , pde-loss 5.0472e+03, initc-loss 1.3017e+04                    bc_loss 2.8598e+02\n",
      "Epoch 32770, Training-Loss 2.2278e+00, Data-loss 3.7337e-01                  , pde-loss 5.3286e+03, initc-loss 1.2901e+04                    bc_loss 3.1492e+02\n",
      "Epoch 32780, Training-Loss 2.2088e+00, Data-loss 2.6500e-01                  , pde-loss 6.3649e+03, initc-loss 1.2889e+04                    bc_loss 1.8435e+02\n",
      "Epoch 32790, Training-Loss 2.1638e+00, Data-loss 2.1122e-01                  , pde-loss 6.3277e+03, initc-loss 1.2904e+04                    bc_loss 2.9417e+02\n",
      "Epoch 32800, Training-Loss 2.1623e+00, Data-loss 2.1975e-01                  , pde-loss 6.5724e+03, initc-loss 1.2822e+04                    bc_loss 3.1119e+01\n",
      "Epoch 32810, Training-Loss 2.4148e+00, Data-loss 4.2669e-01                  , pde-loss 6.5999e+03, initc-loss 1.2892e+04                    bc_loss 3.8952e+02\n",
      "Epoch 32820, Training-Loss 2.2533e+00, Data-loss 3.0157e-01                  , pde-loss 6.5077e+03, initc-loss 1.2892e+04                    bc_loss 1.1670e+02\n",
      "Epoch 32830, Training-Loss 2.1436e+00, Data-loss 2.4464e-01                  , pde-loss 5.6796e+03, initc-loss 1.2966e+04                    bc_loss 3.4377e+02\n",
      "Epoch 32840, Training-Loss 2.2874e+00, Data-loss 3.3969e-01                  , pde-loss 6.3234e+03, initc-loss 1.2870e+04                    bc_loss 2.8422e+02\n",
      "Epoch 32850, Training-Loss 2.2186e+00, Data-loss 3.2254e-01                  , pde-loss 5.8844e+03, initc-loss 1.2906e+04                    bc_loss 1.7014e+02\n",
      "Epoch 32860, Training-Loss 2.2382e+00, Data-loss 3.4454e-01                  , pde-loss 5.6337e+03, initc-loss 1.2871e+04                    bc_loss 4.3180e+02\n",
      "Epoch 32870, Training-Loss 2.2128e+00, Data-loss 3.0827e-01                  , pde-loss 5.6102e+03, initc-loss 1.2911e+04                    bc_loss 5.2437e+02\n",
      "Epoch 32880, Training-Loss 2.1331e+00, Data-loss 2.0085e-01                  , pde-loss 6.3388e+03, initc-loss 1.2854e+04                    bc_loss 1.2900e+02\n",
      "Epoch 32890, Training-Loss 2.1786e+00, Data-loss 3.3114e-01                  , pde-loss 5.3757e+03, initc-loss 1.2947e+04                    bc_loss 1.5139e+02\n",
      "Epoch 32900, Training-Loss 2.5392e+00, Data-loss 6.0044e-01                  , pde-loss 6.3223e+03, initc-loss 1.2897e+04                    bc_loss 1.6793e+02\n",
      "Epoch 32910, Training-Loss 2.2839e+00, Data-loss 4.4385e-01                  , pde-loss 5.4179e+03, initc-loss 1.2813e+04                    bc_loss 1.7026e+02\n",
      "Epoch 32920, Training-Loss 2.3660e+00, Data-loss 4.1786e-01                  , pde-loss 6.1808e+03, initc-loss 1.2928e+04                    bc_loss 3.7288e+02\n",
      "Epoch 32930, Training-Loss 2.1730e+00, Data-loss 2.9384e-01                  , pde-loss 5.6745e+03, initc-loss 1.2962e+04                    bc_loss 1.5443e+02\n",
      "Epoch 32940, Training-Loss 2.1818e+00, Data-loss 2.7510e-01                  , pde-loss 6.0236e+03, initc-loss 1.2918e+04                    bc_loss 1.2594e+02\n",
      "Epoch 32950, Training-Loss 2.1645e+00, Data-loss 2.8381e-01                  , pde-loss 5.8499e+03, initc-loss 1.2882e+04                    bc_loss 7.5411e+01\n",
      "Epoch 32960, Training-Loss 2.1867e+00, Data-loss 3.0078e-01                  , pde-loss 5.8875e+03, initc-loss 1.2923e+04                    bc_loss 4.8773e+01\n",
      "Epoch 32970, Training-Loss 2.3573e+00, Data-loss 4.0644e-01                  , pde-loss 6.3886e+03, initc-loss 1.2973e+04                    bc_loss 1.4681e+02\n",
      "Epoch 32980, Training-Loss 2.2806e+00, Data-loss 3.0444e-01                  , pde-loss 6.6081e+03, initc-loss 1.2942e+04                    bc_loss 2.1155e+02\n",
      "Epoch 32990, Training-Loss 2.1810e+00, Data-loss 2.4248e-01                  , pde-loss 6.2513e+03, initc-loss 1.2898e+04                    bc_loss 2.3625e+02\n",
      "Epoch 33000, Training-Loss 2.0747e+00, Data-loss 2.2655e-01                  , pde-loss 5.4668e+03, initc-loss 1.2916e+04                    bc_loss 9.9275e+01\n",
      "Epoch 33010, Training-Loss 2.2396e+00, Data-loss 3.4692e-01                  , pde-loss 5.6959e+03, initc-loss 1.2913e+04                    bc_loss 3.1757e+02\n",
      "Epoch 33020, Training-Loss 2.1774e+00, Data-loss 3.4027e-01                  , pde-loss 5.3758e+03, initc-loss 1.2869e+04                    bc_loss 1.2598e+02\n",
      "Epoch 33030, Training-Loss 2.0886e+00, Data-loss 2.3631e-01                  , pde-loss 5.3599e+03, initc-loss 1.2860e+04                    bc_loss 3.0327e+02\n",
      "Epoch 33040, Training-Loss 2.1835e+00, Data-loss 2.8369e-01                  , pde-loss 5.9405e+03, initc-loss 1.2939e+04                    bc_loss 1.1811e+02\n",
      "Epoch 33050, Training-Loss 2.3080e+00, Data-loss 2.7633e-01                  , pde-loss 7.0241e+03, initc-loss 1.2900e+04                    bc_loss 3.9249e+02\n",
      "Epoch 33060, Training-Loss 2.1560e+00, Data-loss 2.4218e-01                  , pde-loss 5.9883e+03, initc-loss 1.2952e+04                    bc_loss 1.9813e+02\n",
      "Epoch 33070, Training-Loss 2.2683e+00, Data-loss 4.0616e-01                  , pde-loss 5.4590e+03, initc-loss 1.2780e+04                    bc_loss 3.8281e+02\n",
      "Epoch 33080, Training-Loss 2.4734e+00, Data-loss 4.9928e-01                  , pde-loss 5.7767e+03, initc-loss 1.2953e+04                    bc_loss 1.0112e+03\n",
      "Epoch 33090, Training-Loss 2.3965e+00, Data-loss 4.0409e-01                  , pde-loss 6.5865e+03, initc-loss 1.2850e+04                    bc_loss 4.8735e+02\n",
      "Epoch 33100, Training-Loss 2.1995e+00, Data-loss 3.2916e-01                  , pde-loss 5.6210e+03, initc-loss 1.2972e+04                    bc_loss 1.1018e+02\n",
      "Epoch 33110, Training-Loss 2.2012e+00, Data-loss 3.2068e-01                  , pde-loss 5.6728e+03, initc-loss 1.2939e+04                    bc_loss 1.9347e+02\n",
      "Epoch 33120, Training-Loss 2.1743e+00, Data-loss 2.9661e-01                  , pde-loss 5.6936e+03, initc-loss 1.2901e+04                    bc_loss 1.8197e+02\n",
      "Epoch 33130, Training-Loss 2.2348e+00, Data-loss 3.2584e-01                  , pde-loss 5.9584e+03, initc-loss 1.2976e+04                    bc_loss 1.5512e+02\n",
      "Epoch 33140, Training-Loss 2.2266e+00, Data-loss 3.0052e-01                  , pde-loss 6.1807e+03, initc-loss 1.2973e+04                    bc_loss 1.0638e+02\n",
      "Epoch 33150, Training-Loss 2.3878e+00, Data-loss 3.4358e-01                  , pde-loss 7.1063e+03, initc-loss 1.2924e+04                    bc_loss 4.1168e+02\n",
      "Epoch 33160, Training-Loss 2.4534e+00, Data-loss 5.3930e-01                  , pde-loss 5.8229e+03, initc-loss 1.2912e+04                    bc_loss 4.0615e+02\n",
      "Epoch 33170, Training-Loss 2.1077e+00, Data-loss 2.5349e-01                  , pde-loss 5.3303e+03, initc-loss 1.2888e+04                    bc_loss 3.2302e+02\n",
      "Epoch 33180, Training-Loss 2.3457e+00, Data-loss 4.0851e-01                  , pde-loss 6.3259e+03, initc-loss 1.2965e+04                    bc_loss 8.0215e+01\n",
      "Epoch 33190, Training-Loss 2.2416e+00, Data-loss 2.7192e-01                  , pde-loss 6.4517e+03, initc-loss 1.2890e+04                    bc_loss 3.5502e+02\n",
      "Epoch 33200, Training-Loss 2.2152e+00, Data-loss 3.2841e-01                  , pde-loss 5.8525e+03, initc-loss 1.2923e+04                    bc_loss 9.1925e+01\n",
      "Epoch 33210, Training-Loss 2.2201e+00, Data-loss 3.2272e-01                  , pde-loss 5.9943e+03, initc-loss 1.2908e+04                    bc_loss 7.1376e+01\n",
      "Epoch 33220, Training-Loss 2.1516e+00, Data-loss 2.7448e-01                  , pde-loss 5.8877e+03, initc-loss 1.2798e+04                    bc_loss 8.5414e+01\n",
      "Epoch 33230, Training-Loss 2.0810e+00, Data-loss 2.3161e-01                  , pde-loss 5.5022e+03, initc-loss 1.2884e+04                    bc_loss 1.0772e+02\n",
      "Epoch 33240, Training-Loss 2.1606e+00, Data-loss 2.7269e-01                  , pde-loss 5.9919e+03, initc-loss 1.2834e+04                    bc_loss 5.3027e+01\n",
      "Epoch 33250, Training-Loss 2.0691e+00, Data-loss 2.1598e-01                  , pde-loss 5.4187e+03, initc-loss 1.2926e+04                    bc_loss 1.8625e+02\n",
      "Epoch 33260, Training-Loss 2.1323e+00, Data-loss 2.8897e-01                  , pde-loss 5.2471e+03, initc-loss 1.2891e+04                    bc_loss 2.9535e+02\n",
      "Epoch 33270, Training-Loss 2.1087e+00, Data-loss 2.9159e-01                  , pde-loss 5.1243e+03, initc-loss 1.2934e+04                    bc_loss 1.1214e+02\n",
      "Epoch 33280, Training-Loss 2.4520e+00, Data-loss 5.1690e-01                  , pde-loss 5.6123e+03, initc-loss 1.2992e+04                    bc_loss 7.4747e+02\n",
      "Epoch 33290, Training-Loss 2.1833e+00, Data-loss 2.7510e-01                  , pde-loss 5.9672e+03, initc-loss 1.2883e+04                    bc_loss 2.3158e+02\n",
      "Epoch 33300, Training-Loss 2.2120e+00, Data-loss 2.8855e-01                  , pde-loss 6.0049e+03, initc-loss 1.2947e+04                    bc_loss 2.8230e+02\n",
      "Epoch 33310, Training-Loss 2.1099e+00, Data-loss 2.1480e-01                  , pde-loss 5.9483e+03, initc-loss 1.2890e+04                    bc_loss 1.1196e+02\n",
      "Epoch 33320, Training-Loss 2.2192e+00, Data-loss 3.2163e-01                  , pde-loss 5.9001e+03, initc-loss 1.2919e+04                    bc_loss 1.5620e+02\n",
      "Epoch 33330, Training-Loss 2.1700e+00, Data-loss 2.2432e-01                  , pde-loss 6.3602e+03, initc-loss 1.2897e+04                    bc_loss 2.0024e+02\n",
      "Epoch 33340, Training-Loss 2.1143e+00, Data-loss 2.7988e-01                  , pde-loss 5.2234e+03, initc-loss 1.2927e+04                    bc_loss 1.9383e+02\n",
      "Epoch 33350, Training-Loss 2.4925e+00, Data-loss 5.3759e-01                  , pde-loss 6.2993e+03, initc-loss 1.2977e+04                    bc_loss 2.7276e+02\n",
      "Epoch 33360, Training-Loss 2.3710e+00, Data-loss 4.0004e-01                  , pde-loss 6.2977e+03, initc-loss 1.2876e+04                    bc_loss 5.3555e+02\n",
      "Epoch 33370, Training-Loss 2.4768e+00, Data-loss 5.0221e-01                  , pde-loss 6.4570e+03, initc-loss 1.2971e+04                    bc_loss 3.1809e+02\n",
      "Epoch 33380, Training-Loss 2.2380e+00, Data-loss 2.6985e-01                  , pde-loss 6.3644e+03, initc-loss 1.2863e+04                    bc_loss 4.5324e+02\n",
      "Epoch 33390, Training-Loss 2.1997e+00, Data-loss 2.0989e-01                  , pde-loss 6.4260e+03, initc-loss 1.2930e+04                    bc_loss 5.4217e+02\n",
      "Epoch 33400, Training-Loss 2.0636e+00, Data-loss 2.4725e-01                  , pde-loss 5.2055e+03, initc-loss 1.2903e+04                    bc_loss 5.5160e+01\n",
      "Epoch 33410, Training-Loss 2.1175e+00, Data-loss 2.7505e-01                  , pde-loss 5.4502e+03, initc-loss 1.2874e+04                    bc_loss 1.0043e+02\n",
      "Epoch 33420, Training-Loss 2.1171e+00, Data-loss 2.1654e-01                  , pde-loss 5.9281e+03, initc-loss 1.2925e+04                    bc_loss 1.5180e+02\n",
      "Epoch 33430, Training-Loss 2.0948e+00, Data-loss 2.4115e-01                  , pde-loss 5.5483e+03, initc-loss 1.2903e+04                    bc_loss 8.4957e+01\n",
      "Epoch 33440, Training-Loss 2.0904e+00, Data-loss 2.3752e-01                  , pde-loss 5.4915e+03, initc-loss 1.2869e+04                    bc_loss 1.6810e+02\n",
      "Epoch 33450, Training-Loss 2.1963e+00, Data-loss 2.8279e-01                  , pde-loss 6.0288e+03, initc-loss 1.2939e+04                    bc_loss 1.6692e+02\n",
      "Epoch 33460, Training-Loss 2.2912e+00, Data-loss 3.1764e-01                  , pde-loss 6.5771e+03, initc-loss 1.2946e+04                    bc_loss 2.1250e+02\n",
      "Epoch 33470, Training-Loss 2.2408e+00, Data-loss 3.4250e-01                  , pde-loss 5.8597e+03, initc-loss 1.2907e+04                    bc_loss 2.1711e+02\n",
      "Epoch 33480, Training-Loss 2.1276e+00, Data-loss 2.7131e-01                  , pde-loss 5.5488e+03, initc-loss 1.2886e+04                    bc_loss 1.2767e+02\n",
      "Epoch 33490, Training-Loss 2.1593e+00, Data-loss 2.8315e-01                  , pde-loss 5.6947e+03, initc-loss 1.2932e+04                    bc_loss 1.3491e+02\n",
      "Epoch 33500, Training-Loss 2.0466e+00, Data-loss 2.5725e-01                  , pde-loss 4.9485e+03, initc-loss 1.2896e+04                    bc_loss 4.8929e+01\n",
      "Epoch 33510, Training-Loss 2.1074e+00, Data-loss 2.7720e-01                  , pde-loss 5.2731e+03, initc-loss 1.2969e+04                    bc_loss 5.9524e+01\n",
      "Epoch 33520, Training-Loss 2.1646e+00, Data-loss 2.7650e-01                  , pde-loss 5.9386e+03, initc-loss 1.2893e+04                    bc_loss 4.9787e+01\n",
      "Epoch 33530, Training-Loss 2.2701e+00, Data-loss 2.8550e-01                  , pde-loss 6.8325e+03, initc-loss 1.2907e+04                    bc_loss 1.0636e+02\n",
      "Epoch 33540, Training-Loss 2.0944e+00, Data-loss 2.5862e-01                  , pde-loss 5.2085e+03, initc-loss 1.2891e+04                    bc_loss 2.5853e+02\n",
      "Epoch 33550, Training-Loss 2.2321e+00, Data-loss 3.1142e-01                  , pde-loss 6.0009e+03, initc-loss 1.2841e+04                    bc_loss 3.6440e+02\n",
      "Epoch 33560, Training-Loss 2.1971e+00, Data-loss 3.0519e-01                  , pde-loss 5.8137e+03, initc-loss 1.2933e+04                    bc_loss 1.7145e+02\n",
      "Epoch 33570, Training-Loss 2.3336e+00, Data-loss 3.8850e-01                  , pde-loss 6.0441e+03, initc-loss 1.2995e+04                    bc_loss 4.1186e+02\n",
      "Epoch 33580, Training-Loss 2.3545e+00, Data-loss 4.9626e-01                  , pde-loss 5.6020e+03, initc-loss 1.2841e+04                    bc_loss 1.3872e+02\n",
      "Epoch 33590, Training-Loss 2.1770e+00, Data-loss 2.3577e-01                  , pde-loss 6.4155e+03, initc-loss 1.2901e+04                    bc_loss 9.4975e+01\n",
      "Epoch 33600, Training-Loss 2.2690e+00, Data-loss 2.7215e-01                  , pde-loss 6.9304e+03, initc-loss 1.2910e+04                    bc_loss 1.2774e+02\n",
      "Epoch 33610, Training-Loss 2.2625e+00, Data-loss 2.5105e-01                  , pde-loss 6.9356e+03, initc-loss 1.2993e+04                    bc_loss 1.8637e+02\n",
      "Epoch 33620, Training-Loss 2.2021e+00, Data-loss 3.4314e-01                  , pde-loss 5.6148e+03, initc-loss 1.2881e+04                    bc_loss 9.3225e+01\n",
      "Epoch 33630, Training-Loss 2.2487e+00, Data-loss 3.2139e-01                  , pde-loss 6.3187e+03, initc-loss 1.2918e+04                    bc_loss 3.6608e+01\n",
      "Epoch 33640, Training-Loss 2.1222e+00, Data-loss 2.6346e-01                  , pde-loss 5.5528e+03, initc-loss 1.2890e+04                    bc_loss 1.4376e+02\n",
      "Epoch 33650, Training-Loss 2.1314e+00, Data-loss 2.5388e-01                  , pde-loss 5.7200e+03, initc-loss 1.2927e+04                    bc_loss 1.2789e+02\n",
      "Epoch 33660, Training-Loss 2.2580e+00, Data-loss 4.0266e-01                  , pde-loss 5.3836e+03, initc-loss 1.2904e+04                    bc_loss 2.6522e+02\n",
      "Epoch 33670, Training-Loss 2.1964e+00, Data-loss 2.8744e-01                  , pde-loss 5.9878e+03, initc-loss 1.2901e+04                    bc_loss 2.0060e+02\n",
      "Epoch 33680, Training-Loss 2.0997e+00, Data-loss 2.4360e-01                  , pde-loss 5.6373e+03, initc-loss 1.2847e+04                    bc_loss 7.6603e+01\n",
      "Epoch 33690, Training-Loss 2.1980e+00, Data-loss 2.9215e-01                  , pde-loss 6.0206e+03, initc-loss 1.2977e+04                    bc_loss 6.0960e+01\n",
      "Epoch 33700, Training-Loss 2.2270e+00, Data-loss 2.7904e-01                  , pde-loss 6.3831e+03, initc-loss 1.2832e+04                    bc_loss 2.6464e+02\n",
      "Epoch 33710, Training-Loss 2.2687e+00, Data-loss 2.9653e-01                  , pde-loss 6.6556e+03, initc-loss 1.2933e+04                    bc_loss 1.3302e+02\n",
      "Epoch 33720, Training-Loss 2.0429e+00, Data-loss 2.5383e-01                  , pde-loss 4.9323e+03, initc-loss 1.2862e+04                    bc_loss 9.6040e+01\n",
      "Epoch 33730, Training-Loss 2.1255e+00, Data-loss 2.6033e-01                  , pde-loss 5.6687e+03, initc-loss 1.2936e+04                    bc_loss 4.6419e+01\n",
      "Epoch 33740, Training-Loss 2.1439e+00, Data-loss 2.5114e-01                  , pde-loss 5.5312e+03, initc-loss 1.2881e+04                    bc_loss 5.1546e+02\n",
      "Epoch 33750, Training-Loss 2.0867e+00, Data-loss 2.6532e-01                  , pde-loss 5.2390e+03, initc-loss 1.2887e+04                    bc_loss 8.7860e+01\n",
      "Epoch 33760, Training-Loss 2.2434e+00, Data-loss 3.0457e-01                  , pde-loss 6.3501e+03, initc-loss 1.2946e+04                    bc_loss 9.2174e+01\n",
      "Epoch 33770, Training-Loss 2.0232e+00, Data-loss 2.1524e-01                  , pde-loss 5.0855e+03, initc-loss 1.2919e+04                    bc_loss 7.5794e+01\n",
      "Epoch 33780, Training-Loss 2.2307e+00, Data-loss 3.5073e-01                  , pde-loss 5.5563e+03, initc-loss 1.2842e+04                    bc_loss 4.0177e+02\n",
      "Epoch 33790, Training-Loss 2.1100e+00, Data-loss 2.4673e-01                  , pde-loss 5.6617e+03, initc-loss 1.2841e+04                    bc_loss 1.2991e+02\n",
      "Epoch 33800, Training-Loss 2.0915e+00, Data-loss 1.9333e-01                  , pde-loss 5.8857e+03, initc-loss 1.2813e+04                    bc_loss 2.8343e+02\n",
      "Epoch 33810, Training-Loss 2.2105e+00, Data-loss 3.0915e-01                  , pde-loss 5.8161e+03, initc-loss 1.2987e+04                    bc_loss 2.1025e+02\n",
      "Epoch 33820, Training-Loss 2.1862e+00, Data-loss 2.5520e-01                  , pde-loss 6.2097e+03, initc-loss 1.2951e+04                    bc_loss 1.4937e+02\n",
      "Epoch 33830, Training-Loss 2.2019e+00, Data-loss 2.9881e-01                  , pde-loss 5.3375e+03, initc-loss 1.2905e+04                    bc_loss 7.8843e+02\n",
      "Epoch 33840, Training-Loss 2.2196e+00, Data-loss 3.7379e-01                  , pde-loss 5.2851e+03, initc-loss 1.2940e+04                    bc_loss 2.3375e+02\n",
      "Epoch 33850, Training-Loss 2.1640e+00, Data-loss 2.5859e-01                  , pde-loss 5.9524e+03, initc-loss 1.2891e+04                    bc_loss 2.1011e+02\n",
      "Epoch 33860, Training-Loss 2.2366e+00, Data-loss 3.4607e-01                  , pde-loss 5.5679e+03, initc-loss 1.2919e+04                    bc_loss 4.1808e+02\n",
      "Epoch 33870, Training-Loss 2.2458e+00, Data-loss 3.5760e-01                  , pde-loss 5.8190e+03, initc-loss 1.2926e+04                    bc_loss 1.3694e+02\n",
      "Epoch 33880, Training-Loss 2.1842e+00, Data-loss 3.3461e-01                  , pde-loss 5.4412e+03, initc-loss 1.2914e+04                    bc_loss 1.4039e+02\n",
      "Epoch 33890, Training-Loss 2.2964e+00, Data-loss 3.0971e-01                  , pde-loss 6.6565e+03, initc-loss 1.2845e+04                    bc_loss 3.6537e+02\n",
      "Epoch 33900, Training-Loss 2.2259e+00, Data-loss 2.9579e-01                  , pde-loss 6.2652e+03, initc-loss 1.2919e+04                    bc_loss 1.1686e+02\n",
      "Epoch 33910, Training-Loss 2.2035e+00, Data-loss 3.4662e-01                  , pde-loss 5.6606e+03, initc-loss 1.2811e+04                    bc_loss 9.6583e+01\n",
      "Epoch 33920, Training-Loss 2.2052e+00, Data-loss 2.9982e-01                  , pde-loss 5.9130e+03, initc-loss 1.2897e+04                    bc_loss 2.4382e+02\n",
      "Epoch 33930, Training-Loss 2.1757e+00, Data-loss 3.2677e-01                  , pde-loss 5.4273e+03, initc-loss 1.2847e+04                    bc_loss 2.1508e+02\n",
      "Epoch 33940, Training-Loss 2.3313e+00, Data-loss 3.8668e-01                  , pde-loss 6.2693e+03, initc-loss 1.2889e+04                    bc_loss 2.8842e+02\n",
      "Epoch 33950, Training-Loss 2.3829e+00, Data-loss 5.3708e-01                  , pde-loss 5.3376e+03, initc-loss 1.2788e+04                    bc_loss 3.3273e+02\n",
      "Epoch 33960, Training-Loss 2.1225e+00, Data-loss 2.6435e-01                  , pde-loss 5.3645e+03, initc-loss 1.2921e+04                    bc_loss 2.9608e+02\n",
      "Epoch 33970, Training-Loss 1.8874e+00, Data-loss 1.2323e-01                  , pde-loss 4.6238e+03, initc-loss 1.2900e+04                    bc_loss 1.1769e+02\n",
      "Epoch 33980, Training-Loss 2.1140e+00, Data-loss 2.2952e-01                  , pde-loss 5.8779e+03, initc-loss 1.2880e+04                    bc_loss 8.6525e+01\n",
      "Epoch 33990, Training-Loss 2.3622e+00, Data-loss 4.5869e-01                  , pde-loss 6.1506e+03, initc-loss 1.2810e+04                    bc_loss 7.3943e+01\n",
      "Epoch 34000, Training-Loss 2.1883e+00, Data-loss 2.7063e-01                  , pde-loss 5.4477e+03, initc-loss 1.2905e+04                    bc_loss 8.2486e+02\n",
      "Epoch 34010, Training-Loss 2.1740e+00, Data-loss 2.8574e-01                  , pde-loss 5.8046e+03, initc-loss 1.2885e+04                    bc_loss 1.9298e+02\n",
      "Epoch 34020, Training-Loss 2.1108e+00, Data-loss 2.2801e-01                  , pde-loss 5.6710e+03, initc-loss 1.3045e+04                    bc_loss 1.1183e+02\n",
      "Epoch 34030, Training-Loss 2.4256e+00, Data-loss 5.0885e-01                  , pde-loss 5.9279e+03, initc-loss 1.2822e+04                    bc_loss 4.1770e+02\n",
      "Epoch 34040, Training-Loss 2.1806e+00, Data-loss 2.6767e-01                  , pde-loss 5.9433e+03, initc-loss 1.2863e+04                    bc_loss 3.2278e+02\n",
      "Epoch 34050, Training-Loss 2.2045e+00, Data-loss 3.2038e-01                  , pde-loss 5.6420e+03, initc-loss 1.2952e+04                    bc_loss 2.4649e+02\n",
      "Epoch 34060, Training-Loss 2.2966e+00, Data-loss 3.9037e-01                  , pde-loss 5.6148e+03, initc-loss 1.2841e+04                    bc_loss 6.0644e+02\n",
      "Epoch 34070, Training-Loss 2.2779e+00, Data-loss 3.6974e-01                  , pde-loss 5.9364e+03, initc-loss 1.2943e+04                    bc_loss 2.0175e+02\n",
      "Epoch 34080, Training-Loss 2.1993e+00, Data-loss 3.0447e-01                  , pde-loss 5.8369e+03, initc-loss 1.2831e+04                    bc_loss 2.8038e+02\n",
      "Epoch 34090, Training-Loss 2.0638e+00, Data-loss 1.7402e-01                  , pde-loss 5.8283e+03, initc-loss 1.2886e+04                    bc_loss 1.8351e+02\n",
      "Epoch 34100, Training-Loss 2.1318e+00, Data-loss 3.0240e-01                  , pde-loss 5.3482e+03, initc-loss 1.2862e+04                    bc_loss 8.4194e+01\n",
      "Epoch 34110, Training-Loss 2.1164e+00, Data-loss 2.2435e-01                  , pde-loss 5.8689e+03, initc-loss 1.2809e+04                    bc_loss 2.4324e+02\n",
      "Epoch 34120, Training-Loss 2.1196e+00, Data-loss 2.3058e-01                  , pde-loss 5.7871e+03, initc-loss 1.2968e+04                    bc_loss 1.3551e+02\n",
      "Epoch 34130, Training-Loss 2.1841e+00, Data-loss 3.0904e-01                  , pde-loss 5.3864e+03, initc-loss 1.2860e+04                    bc_loss 5.0422e+02\n",
      "Epoch 34140, Training-Loss 2.1096e+00, Data-loss 2.6025e-01                  , pde-loss 5.5411e+03, initc-loss 1.2876e+04                    bc_loss 7.6067e+01\n",
      "Epoch 34150, Training-Loss 2.1808e+00, Data-loss 2.8756e-01                  , pde-loss 5.9207e+03, initc-loss 1.2938e+04                    bc_loss 7.3529e+01\n",
      "Epoch 34160, Training-Loss 2.1994e+00, Data-loss 2.9467e-01                  , pde-loss 6.0798e+03, initc-loss 1.2913e+04                    bc_loss 5.4495e+01\n",
      "Epoch 34170, Training-Loss 2.1292e+00, Data-loss 1.9410e-01                  , pde-loss 6.1789e+03, initc-loss 1.2868e+04                    bc_loss 3.0378e+02\n",
      "Epoch 34180, Training-Loss 2.2037e+00, Data-loss 2.2311e-01                  , pde-loss 6.7779e+03, initc-loss 1.2950e+04                    bc_loss 7.8547e+01\n",
      "Epoch 34190, Training-Loss 2.5868e+00, Data-loss 5.9839e-01                  , pde-loss 6.4428e+03, initc-loss 1.2805e+04                    bc_loss 6.3626e+02\n",
      "Epoch 34200, Training-Loss 2.3473e+00, Data-loss 4.2192e-01                  , pde-loss 5.3502e+03, initc-loss 1.2968e+04                    bc_loss 9.3516e+02\n",
      "Epoch 34210, Training-Loss 2.3272e+00, Data-loss 3.8370e-01                  , pde-loss 5.7628e+03, initc-loss 1.2901e+04                    bc_loss 7.7061e+02\n",
      "Epoch 34220, Training-Loss 1.9630e+00, Data-loss 1.6024e-01                  , pde-loss 5.0025e+03, initc-loss 1.2898e+04                    bc_loss 1.2702e+02\n",
      "Epoch 34230, Training-Loss 2.1972e+00, Data-loss 2.8206e-01                  , pde-loss 6.0999e+03, initc-loss 1.2963e+04                    bc_loss 8.8710e+01\n",
      "Epoch 34240, Training-Loss 2.0011e+00, Data-loss 2.3769e-01                  , pde-loss 4.6163e+03, initc-loss 1.2896e+04                    bc_loss 1.2125e+02\n",
      "Epoch 34250, Training-Loss 2.0521e+00, Data-loss 2.1033e-01                  , pde-loss 5.3084e+03, initc-loss 1.2946e+04                    bc_loss 1.6310e+02\n",
      "Epoch 34260, Training-Loss 2.1404e+00, Data-loss 2.7264e-01                  , pde-loss 5.6363e+03, initc-loss 1.2833e+04                    bc_loss 2.0848e+02\n",
      "Epoch 34270, Training-Loss 2.2941e+00, Data-loss 2.8246e-01                  , pde-loss 6.9583e+03, initc-loss 1.2976e+04                    bc_loss 1.8190e+02\n",
      "Epoch 34280, Training-Loss 2.2169e+00, Data-loss 2.9848e-01                  , pde-loss 5.6476e+03, initc-loss 1.2942e+04                    bc_loss 5.9415e+02\n",
      "Epoch 34290, Training-Loss 2.1601e+00, Data-loss 2.7690e-01                  , pde-loss 5.7613e+03, initc-loss 1.2934e+04                    bc_loss 1.3744e+02\n",
      "Epoch 34300, Training-Loss 2.1456e+00, Data-loss 2.4180e-01                  , pde-loss 5.7883e+03, initc-loss 1.2888e+04                    bc_loss 3.6103e+02\n",
      "Epoch 34310, Training-Loss 2.2991e+00, Data-loss 2.7024e-01                  , pde-loss 7.1327e+03, initc-loss 1.2997e+04                    bc_loss 1.5885e+02\n",
      "Epoch 34320, Training-Loss 2.1030e+00, Data-loss 2.1723e-01                  , pde-loss 5.8069e+03, initc-loss 1.2883e+04                    bc_loss 1.6801e+02\n",
      "Epoch 34330, Training-Loss 2.1749e+00, Data-loss 2.4977e-01                  , pde-loss 6.1380e+03, initc-loss 1.2949e+04                    bc_loss 1.6384e+02\n",
      "Epoch 34340, Training-Loss 2.2622e+00, Data-loss 3.9909e-01                  , pde-loss 5.5443e+03, initc-loss 1.2896e+04                    bc_loss 1.9062e+02\n",
      "Epoch 34350, Training-Loss 2.0427e+00, Data-loss 2.4775e-01                  , pde-loss 4.9554e+03, initc-loss 1.2948e+04                    bc_loss 4.6449e+01\n",
      "Epoch 34360, Training-Loss 2.3620e+00, Data-loss 3.6984e-01                  , pde-loss 6.1849e+03, initc-loss 1.2989e+04                    bc_loss 7.4706e+02\n",
      "Epoch 34370, Training-Loss 2.5656e+00, Data-loss 5.2934e-01                  , pde-loss 6.3638e+03, initc-loss 1.2827e+04                    bc_loss 1.1718e+03\n",
      "Epoch 34380, Training-Loss 2.1366e+00, Data-loss 2.4913e-01                  , pde-loss 5.9081e+03, initc-loss 1.2848e+04                    bc_loss 1.1848e+02\n",
      "Epoch 34390, Training-Loss 2.3671e+00, Data-loss 5.0026e-01                  , pde-loss 5.5994e+03, initc-loss 1.2920e+04                    bc_loss 1.4930e+02\n",
      "Epoch 34400, Training-Loss 2.1060e+00, Data-loss 2.3289e-01                  , pde-loss 5.2990e+03, initc-loss 1.2977e+04                    bc_loss 4.5502e+02\n",
      "Epoch 34410, Training-Loss 2.2218e+00, Data-loss 3.0199e-01                  , pde-loss 5.9877e+03, initc-loss 1.2874e+04                    bc_loss 3.3713e+02\n",
      "Epoch 34420, Training-Loss 2.2630e+00, Data-loss 3.8854e-01                  , pde-loss 5.8064e+03, initc-loss 1.2820e+04                    bc_loss 1.1843e+02\n",
      "Epoch 34430, Training-Loss 2.3609e+00, Data-loss 4.0713e-01                  , pde-loss 6.2677e+03, initc-loss 1.2922e+04                    bc_loss 3.4817e+02\n",
      "Epoch 34440, Training-Loss 2.7713e+00, Data-loss 8.4960e-01                  , pde-loss 6.0443e+03, initc-loss 1.2806e+04                    bc_loss 3.6712e+02\n",
      "Epoch 34450, Training-Loss 2.2403e+00, Data-loss 3.5042e-01                  , pde-loss 5.5372e+03, initc-loss 1.2872e+04                    bc_loss 4.8972e+02\n",
      "Epoch 34460, Training-Loss 2.1660e+00, Data-loss 2.9741e-01                  , pde-loss 5.5933e+03, initc-loss 1.2864e+04                    bc_loss 2.2781e+02\n",
      "Epoch 34470, Training-Loss 2.1846e+00, Data-loss 2.9413e-01                  , pde-loss 5.6821e+03, initc-loss 1.3005e+04                    bc_loss 2.1764e+02\n",
      "Epoch 34480, Training-Loss 2.1655e+00, Data-loss 3.0334e-01                  , pde-loss 5.6734e+03, initc-loss 1.2868e+04                    bc_loss 8.0603e+01\n",
      "Epoch 34490, Training-Loss 2.1763e+00, Data-loss 2.6891e-01                  , pde-loss 6.1472e+03, initc-loss 1.2833e+04                    bc_loss 9.4306e+01\n",
      "Epoch 34500, Training-Loss 2.1583e+00, Data-loss 3.2065e-01                  , pde-loss 5.4933e+03, initc-loss 1.2815e+04                    bc_loss 6.7218e+01\n",
      "Epoch 34510, Training-Loss 2.2552e+00, Data-loss 2.8418e-01                  , pde-loss 6.5825e+03, initc-loss 1.2952e+04                    bc_loss 1.7528e+02\n",
      "Epoch 34520, Training-Loss 2.2538e+00, Data-loss 2.8784e-01                  , pde-loss 6.5760e+03, initc-loss 1.2902e+04                    bc_loss 1.8168e+02\n",
      "Epoch 34530, Training-Loss 2.1126e+00, Data-loss 2.6182e-01                  , pde-loss 5.4997e+03, initc-loss 1.2921e+04                    bc_loss 8.6984e+01\n",
      "Epoch 34540, Training-Loss 2.1748e+00, Data-loss 1.9977e-01                  , pde-loss 6.6663e+03, initc-loss 1.2908e+04                    bc_loss 1.7600e+02\n",
      "Epoch 34550, Training-Loss 2.1310e+00, Data-loss 2.2502e-01                  , pde-loss 6.0427e+03, initc-loss 1.2901e+04                    bc_loss 1.1554e+02\n",
      "Epoch 34560, Training-Loss 2.1146e+00, Data-loss 2.5521e-01                  , pde-loss 5.6046e+03, initc-loss 1.2873e+04                    bc_loss 1.1626e+02\n",
      "Epoch 34570, Training-Loss 2.1706e+00, Data-loss 3.2551e-01                  , pde-loss 5.4881e+03, initc-loss 1.2875e+04                    bc_loss 8.8187e+01\n",
      "Epoch 34580, Training-Loss 2.2018e+00, Data-loss 2.8221e-01                  , pde-loss 5.7569e+03, initc-loss 1.2887e+04                    bc_loss 5.5171e+02\n",
      "Epoch 34590, Training-Loss 2.2949e+00, Data-loss 3.0427e-01                  , pde-loss 6.9038e+03, initc-loss 1.2883e+04                    bc_loss 1.1880e+02\n",
      "Epoch 34600, Training-Loss 2.1492e+00, Data-loss 2.0302e-01                  , pde-loss 6.4144e+03, initc-loss 1.2925e+04                    bc_loss 1.2289e+02\n",
      "Epoch 34610, Training-Loss 2.1735e+00, Data-loss 3.1457e-01                  , pde-loss 5.6213e+03, initc-loss 1.2900e+04                    bc_loss 6.8478e+01\n",
      "Epoch 34620, Training-Loss 2.2399e+00, Data-loss 3.0878e-01                  , pde-loss 6.2320e+03, initc-loss 1.2880e+04                    bc_loss 1.9880e+02\n",
      "Epoch 34630, Training-Loss 2.1726e+00, Data-loss 2.8233e-01                  , pde-loss 5.7537e+03, initc-loss 1.2991e+04                    bc_loss 1.5817e+02\n",
      "Epoch 34640, Training-Loss 2.3692e+00, Data-loss 4.3042e-01                  , pde-loss 6.2308e+03, initc-loss 1.2852e+04                    bc_loss 3.0435e+02\n",
      "Epoch 34650, Training-Loss 2.1080e+00, Data-loss 1.8752e-01                  , pde-loss 5.9975e+03, initc-loss 1.2933e+04                    bc_loss 2.7436e+02\n",
      "Epoch 34660, Training-Loss 2.2040e+00, Data-loss 2.9403e-01                  , pde-loss 6.0169e+03, initc-loss 1.2860e+04                    bc_loss 2.2292e+02\n",
      "Epoch 34670, Training-Loss 2.1189e+00, Data-loss 2.4907e-01                  , pde-loss 5.7798e+03, initc-loss 1.2840e+04                    bc_loss 7.9089e+01\n",
      "Epoch 34680, Training-Loss 2.2611e+00, Data-loss 3.0677e-01                  , pde-loss 6.5965e+03, initc-loss 1.2808e+04                    bc_loss 1.3861e+02\n",
      "Epoch 34690, Training-Loss 2.7030e+00, Data-loss 4.9635e-01                  , pde-loss 7.1536e+03, initc-loss 1.2890e+04                    bc_loss 2.0232e+03\n",
      "Epoch 34700, Training-Loss 2.2251e+00, Data-loss 3.5143e-01                  , pde-loss 5.7517e+03, initc-loss 1.2927e+04                    bc_loss 5.8364e+01\n",
      "Epoch 34710, Training-Loss 2.1806e+00, Data-loss 2.6631e-01                  , pde-loss 6.0307e+03, initc-loss 1.2846e+04                    bc_loss 2.6642e+02\n",
      "Epoch 34720, Training-Loss 2.2788e+00, Data-loss 3.8792e-01                  , pde-loss 5.8008e+03, initc-loss 1.2924e+04                    bc_loss 1.8322e+02\n",
      "Epoch 34730, Training-Loss 2.2599e+00, Data-loss 3.7811e-01                  , pde-loss 5.8041e+03, initc-loss 1.2924e+04                    bc_loss 9.0156e+01\n",
      "Epoch 34740, Training-Loss 2.0959e+00, Data-loss 1.9578e-01                  , pde-loss 5.9285e+03, initc-loss 1.2913e+04                    bc_loss 1.6030e+02\n",
      "Epoch 34750, Training-Loss 2.1322e+00, Data-loss 1.9904e-01                  , pde-loss 6.2457e+03, initc-loss 1.2897e+04                    bc_loss 1.8834e+02\n",
      "Epoch 34760, Training-Loss 2.1754e+00, Data-loss 3.0174e-01                  , pde-loss 5.7798e+03, initc-loss 1.2868e+04                    bc_loss 8.8697e+01\n",
      "Epoch 34770, Training-Loss 2.0350e+00, Data-loss 2.3737e-01                  , pde-loss 4.9926e+03, initc-loss 1.2902e+04                    bc_loss 8.1521e+01\n",
      "Epoch 34780, Training-Loss 2.3014e+00, Data-loss 3.6302e-01                  , pde-loss 6.0958e+03, initc-loss 1.3048e+04                    bc_loss 2.4008e+02\n",
      "Epoch 34790, Training-Loss 2.5240e+00, Data-loss 6.1314e-01                  , pde-loss 5.6835e+03, initc-loss 1.2773e+04                    bc_loss 6.5203e+02\n",
      "Epoch 34800, Training-Loss 2.3416e+00, Data-loss 3.3539e-01                  , pde-loss 6.7234e+03, initc-loss 1.2977e+04                    bc_loss 3.6173e+02\n",
      "Epoch 34810, Training-Loss 2.2979e+00, Data-loss 3.3474e-01                  , pde-loss 6.5779e+03, initc-loss 1.2878e+04                    bc_loss 1.7623e+02\n",
      "Epoch 34820, Training-Loss 2.3308e+00, Data-loss 3.9383e-01                  , pde-loss 5.8169e+03, initc-loss 1.2934e+04                    bc_loss 6.1881e+02\n",
      "Epoch 34830, Training-Loss 2.1777e+00, Data-loss 2.9595e-01                  , pde-loss 5.4800e+03, initc-loss 1.2839e+04                    bc_loss 4.9863e+02\n",
      "Epoch 34840, Training-Loss 2.2188e+00, Data-loss 2.7241e-01                  , pde-loss 6.2830e+03, initc-loss 1.2935e+04                    bc_loss 2.4584e+02\n",
      "Epoch 34850, Training-Loss 2.4182e+00, Data-loss 4.9844e-01                  , pde-loss 6.2019e+03, initc-loss 1.2843e+04                    bc_loss 1.5248e+02\n",
      "Epoch 34860, Training-Loss 2.5656e+00, Data-loss 7.1056e-01                  , pde-loss 5.3911e+03, initc-loss 1.3004e+04                    bc_loss 1.5560e+02\n",
      "Epoch 34870, Training-Loss 2.3366e+00, Data-loss 3.6335e-01                  , pde-loss 5.6263e+03, initc-loss 1.2913e+04                    bc_loss 1.1934e+03\n",
      "Epoch 34880, Training-Loss 2.1021e+00, Data-loss 2.7774e-01                  , pde-loss 5.2390e+03, initc-loss 1.2906e+04                    bc_loss 9.8216e+01\n",
      "Epoch 34890, Training-Loss 2.2354e+00, Data-loss 3.0809e-01                  , pde-loss 6.1152e+03, initc-loss 1.2947e+04                    bc_loss 2.1004e+02\n",
      "Epoch 34900, Training-Loss 2.2285e+00, Data-loss 3.1702e-01                  , pde-loss 5.7455e+03, initc-loss 1.2857e+04                    bc_loss 5.1278e+02\n",
      "Epoch 34910, Training-Loss 2.2583e+00, Data-loss 4.0454e-01                  , pde-loss 5.3531e+03, initc-loss 1.2994e+04                    bc_loss 1.9010e+02\n",
      "Epoch 34920, Training-Loss 2.0511e+00, Data-loss 2.1314e-01                  , pde-loss 5.4085e+03, initc-loss 1.2880e+04                    bc_loss 9.0963e+01\n",
      "Epoch 34930, Training-Loss 2.1896e+00, Data-loss 3.1494e-01                  , pde-loss 5.5353e+03, initc-loss 1.2898e+04                    bc_loss 3.1255e+02\n",
      "Epoch 34940, Training-Loss 2.0168e+00, Data-loss 1.8315e-01                  , pde-loss 5.3478e+03, initc-loss 1.2955e+04                    bc_loss 3.3485e+01\n",
      "Epoch 34950, Training-Loss 2.1943e+00, Data-loss 2.7995e-01                  , pde-loss 6.0524e+03, initc-loss 1.2865e+04                    bc_loss 2.2593e+02\n",
      "Epoch 34960, Training-Loss 2.0985e+00, Data-loss 2.5723e-01                  , pde-loss 5.3731e+03, initc-loss 1.2916e+04                    bc_loss 1.2293e+02\n",
      "Epoch 34970, Training-Loss 2.1618e+00, Data-loss 2.6782e-01                  , pde-loss 5.8821e+03, initc-loss 1.2934e+04                    bc_loss 1.2424e+02\n",
      "Epoch 34980, Training-Loss 2.2056e+00, Data-loss 2.6133e-01                  , pde-loss 6.1642e+03, initc-loss 1.2888e+04                    bc_loss 3.9090e+02\n",
      "Epoch 34990, Training-Loss 2.0654e+00, Data-loss 1.5927e-01                  , pde-loss 5.9762e+03, initc-loss 1.2957e+04                    bc_loss 1.2743e+02\n",
      "Epoch 35000, Training-Loss 2.2239e+00, Data-loss 3.7100e-01                  , pde-loss 5.4872e+03, initc-loss 1.2889e+04                    bc_loss 1.5267e+02\n",
      "Epoch 35010, Training-Loss 2.1288e+00, Data-loss 2.7691e-01                  , pde-loss 5.2712e+03, initc-loss 1.2863e+04                    bc_loss 3.8500e+02\n",
      "Epoch 35020, Training-Loss 2.1009e+00, Data-loss 2.2640e-01                  , pde-loss 5.7039e+03, initc-loss 1.2889e+04                    bc_loss 1.5119e+02\n",
      "Epoch 35030, Training-Loss 2.2157e+00, Data-loss 2.5905e-01                  , pde-loss 6.3618e+03, initc-loss 1.2938e+04                    bc_loss 2.6675e+02\n",
      "Epoch 35040, Training-Loss 2.0138e+00, Data-loss 1.9629e-01                  , pde-loss 5.1634e+03, initc-loss 1.2880e+04                    bc_loss 1.3173e+02\n",
      "Epoch 35050, Training-Loss 2.0989e+00, Data-loss 2.4588e-01                  , pde-loss 5.4589e+03, initc-loss 1.2901e+04                    bc_loss 1.6977e+02\n",
      "Epoch 35060, Training-Loss 2.1598e+00, Data-loss 2.5978e-01                  , pde-loss 5.8858e+03, initc-loss 1.2918e+04                    bc_loss 1.9670e+02\n",
      "Epoch 35070, Training-Loss 2.2018e+00, Data-loss 2.9888e-01                  , pde-loss 5.9305e+03, initc-loss 1.2893e+04                    bc_loss 2.0577e+02\n",
      "Epoch 35080, Training-Loss 2.1939e+00, Data-loss 2.5444e-01                  , pde-loss 6.2121e+03, initc-loss 1.2970e+04                    bc_loss 2.1159e+02\n",
      "Epoch 35090, Training-Loss 2.0523e+00, Data-loss 1.5474e-01                  , pde-loss 5.8253e+03, initc-loss 1.2944e+04                    bc_loss 2.0580e+02\n",
      "Epoch 35100, Training-Loss 2.1173e+00, Data-loss 2.4566e-01                  , pde-loss 5.7612e+03, initc-loss 1.2840e+04                    bc_loss 1.1599e+02\n",
      "Epoch 35110, Training-Loss 2.1943e+00, Data-loss 2.2147e-01                  , pde-loss 6.4463e+03, initc-loss 1.2983e+04                    bc_loss 2.9914e+02\n",
      "Epoch 35120, Training-Loss 2.1809e+00, Data-loss 2.3536e-01                  , pde-loss 6.3528e+03, initc-loss 1.2915e+04                    bc_loss 1.8832e+02\n",
      "Epoch 35130, Training-Loss 2.0811e+00, Data-loss 2.4190e-01                  , pde-loss 5.2892e+03, initc-loss 1.2926e+04                    bc_loss 1.7605e+02\n",
      "Epoch 35140, Training-Loss 2.2149e+00, Data-loss 2.7566e-01                  , pde-loss 6.2184e+03, initc-loss 1.2861e+04                    bc_loss 3.1340e+02\n",
      "Epoch 35150, Training-Loss 2.0486e+00, Data-loss 2.2360e-01                  , pde-loss 5.0993e+03, initc-loss 1.2906e+04                    bc_loss 2.4499e+02\n",
      "Epoch 35160, Training-Loss 2.3080e+00, Data-loss 3.5962e-01                  , pde-loss 5.4497e+03, initc-loss 1.2949e+04                    bc_loss 1.0849e+03\n",
      "Epoch 35170, Training-Loss 2.2780e+00, Data-loss 3.3626e-01                  , pde-loss 6.3520e+03, initc-loss 1.2885e+04                    bc_loss 1.8025e+02\n",
      "Epoch 35180, Training-Loss 2.1512e+00, Data-loss 3.4151e-01                  , pde-loss 5.1701e+03, initc-loss 1.2849e+04                    bc_loss 7.7780e+01\n",
      "Epoch 35190, Training-Loss 2.1234e+00, Data-loss 3.0911e-01                  , pde-loss 5.1182e+03, initc-loss 1.2913e+04                    bc_loss 1.1258e+02\n",
      "Epoch 35200, Training-Loss 2.1310e+00, Data-loss 2.6354e-01                  , pde-loss 5.6142e+03, initc-loss 1.2928e+04                    bc_loss 1.3166e+02\n",
      "Epoch 35210, Training-Loss 2.1703e+00, Data-loss 3.2327e-01                  , pde-loss 5.5074e+03, initc-loss 1.2867e+04                    bc_loss 9.6697e+01\n",
      "Epoch 35220, Training-Loss 2.1157e+00, Data-loss 2.5288e-01                  , pde-loss 5.7163e+03, initc-loss 1.2847e+04                    bc_loss 6.4595e+01\n",
      "Epoch 35230, Training-Loss 2.3602e+00, Data-loss 4.0604e-01                  , pde-loss 6.4321e+03, initc-loss 1.2919e+04                    bc_loss 1.9105e+02\n",
      "Epoch 35240, Training-Loss 2.1413e+00, Data-loss 2.7335e-01                  , pde-loss 5.7587e+03, initc-loss 1.2818e+04                    bc_loss 1.0264e+02\n",
      "Epoch 35250, Training-Loss 2.3387e+00, Data-loss 3.1315e-01                  , pde-loss 7.2129e+03, initc-loss 1.2953e+04                    bc_loss 8.9331e+01\n",
      "Epoch 35260, Training-Loss 2.1853e+00, Data-loss 2.1649e-01                  , pde-loss 6.5334e+03, initc-loss 1.2897e+04                    bc_loss 2.5772e+02\n",
      "Epoch 35270, Training-Loss 2.2306e+00, Data-loss 3.2000e-01                  , pde-loss 5.8452e+03, initc-loss 1.3002e+04                    bc_loss 2.5855e+02\n",
      "Epoch 35280, Training-Loss 2.0241e+00, Data-loss 1.9920e-01                  , pde-loss 5.2948e+03, initc-loss 1.2902e+04                    bc_loss 5.2071e+01\n",
      "Epoch 35290, Training-Loss 2.0893e+00, Data-loss 2.2826e-01                  , pde-loss 5.6169e+03, initc-loss 1.2852e+04                    bc_loss 1.4151e+02\n",
      "Epoch 35300, Training-Loss 2.0064e+00, Data-loss 1.8135e-01                  , pde-loss 5.1478e+03, initc-loss 1.2953e+04                    bc_loss 1.4934e+02\n",
      "Epoch 35310, Training-Loss 2.0519e+00, Data-loss 2.0989e-01                  , pde-loss 5.5011e+03, initc-loss 1.2852e+04                    bc_loss 6.6701e+01\n",
      "Epoch 35320, Training-Loss 2.1107e+00, Data-loss 2.2986e-01                  , pde-loss 5.7754e+03, initc-loss 1.2903e+04                    bc_loss 1.2988e+02\n",
      "Epoch 35330, Training-Loss 2.1129e+00, Data-loss 1.9082e-01                  , pde-loss 6.3199e+03, initc-loss 1.2841e+04                    bc_loss 6.0503e+01\n",
      "Epoch 35340, Training-Loss 2.1224e+00, Data-loss 2.0758e-01                  , pde-loss 5.9981e+03, initc-loss 1.2981e+04                    bc_loss 1.6989e+02\n",
      "Epoch 35350, Training-Loss 2.0805e+00, Data-loss 1.7702e-01                  , pde-loss 5.9247e+03, initc-loss 1.2972e+04                    bc_loss 1.3824e+02\n",
      "Epoch 35360, Training-Loss 2.1430e+00, Data-loss 3.0472e-01                  , pde-loss 5.4364e+03, initc-loss 1.2834e+04                    bc_loss 1.1287e+02\n",
      "Epoch 35370, Training-Loss 1.9948e+00, Data-loss 1.9802e-01                  , pde-loss 4.9183e+03, initc-loss 1.2975e+04                    bc_loss 7.4403e+01\n",
      "Epoch 35380, Training-Loss 2.1735e+00, Data-loss 2.8493e-01                  , pde-loss 5.8654e+03, initc-loss 1.2831e+04                    bc_loss 1.8912e+02\n",
      "Epoch 35390, Training-Loss 2.2161e+00, Data-loss 2.4799e-01                  , pde-loss 5.8272e+03, initc-loss 1.3013e+04                    bc_loss 8.4070e+02\n",
      "Epoch 35400, Training-Loss 2.3127e+00, Data-loss 3.8382e-01                  , pde-loss 6.1503e+03, initc-loss 1.2832e+04                    bc_loss 3.0636e+02\n",
      "Epoch 35410, Training-Loss 2.2752e+00, Data-loss 3.9690e-01                  , pde-loss 5.7662e+03, initc-loss 1.2910e+04                    bc_loss 1.0675e+02\n",
      "Epoch 35420, Training-Loss 2.1259e+00, Data-loss 2.5282e-01                  , pde-loss 5.7883e+03, initc-loss 1.2883e+04                    bc_loss 5.9608e+01\n",
      "Epoch 35430, Training-Loss 1.9917e+00, Data-loss 1.5954e-01                  , pde-loss 5.2657e+03, initc-loss 1.2882e+04                    bc_loss 1.7362e+02\n",
      "Epoch 35440, Training-Loss 2.1459e+00, Data-loss 3.0163e-01                  , pde-loss 5.2685e+03, initc-loss 1.2987e+04                    bc_loss 1.8677e+02\n",
      "Epoch 35450, Training-Loss 2.1008e+00, Data-loss 2.7151e-01                  , pde-loss 5.2381e+03, initc-loss 1.2901e+04                    bc_loss 1.5304e+02\n",
      "Epoch 35460, Training-Loss 2.1170e+00, Data-loss 1.9709e-01                  , pde-loss 6.2294e+03, initc-loss 1.2891e+04                    bc_loss 7.8524e+01\n",
      "Epoch 35470, Training-Loss 1.9703e+00, Data-loss 8.4945e-02                  , pde-loss 5.7135e+03, initc-loss 1.2881e+04                    bc_loss 2.5814e+02\n",
      "Epoch 35480, Training-Loss 2.0658e+00, Data-loss 1.2716e-01                  , pde-loss 6.3854e+03, initc-loss 1.2859e+04                    bc_loss 1.4267e+02\n",
      "Epoch 35490, Training-Loss 2.0047e+00, Data-loss 1.6150e-01                  , pde-loss 5.3535e+03, initc-loss 1.2909e+04                    bc_loss 1.6945e+02\n",
      "Epoch 35500, Training-Loss 1.9231e+00, Data-loss 1.7376e-01                  , pde-loss 4.5738e+03, initc-loss 1.2842e+04                    bc_loss 7.7249e+01\n",
      "Epoch 35510, Training-Loss 2.0447e+00, Data-loss 1.9462e-01                  , pde-loss 5.1332e+03, initc-loss 1.2920e+04                    bc_loss 4.4796e+02\n",
      "Epoch 35520, Training-Loss 2.2156e+00, Data-loss 2.4212e-01                  , pde-loss 6.5113e+03, initc-loss 1.2910e+04                    bc_loss 3.1336e+02\n",
      "Epoch 35530, Training-Loss 2.1295e+00, Data-loss 2.3660e-01                  , pde-loss 5.7752e+03, initc-loss 1.2904e+04                    bc_loss 2.4968e+02\n",
      "Epoch 35540, Training-Loss 2.2096e+00, Data-loss 3.6669e-01                  , pde-loss 5.3524e+03, initc-loss 1.2838e+04                    bc_loss 2.3815e+02\n",
      "Epoch 35550, Training-Loss 2.1770e+00, Data-loss 2.4284e-01                  , pde-loss 6.1931e+03, initc-loss 1.2955e+04                    bc_loss 1.9367e+02\n",
      "Epoch 35560, Training-Loss 2.0812e+00, Data-loss 1.8097e-01                  , pde-loss 5.9592e+03, initc-loss 1.2875e+04                    bc_loss 1.6733e+02\n",
      "Epoch 35570, Training-Loss 1.9979e+00, Data-loss 1.6109e-01                  , pde-loss 5.3485e+03, initc-loss 1.2868e+04                    bc_loss 1.5138e+02\n",
      "Epoch 35580, Training-Loss 2.2197e+00, Data-loss 3.5885e-01                  , pde-loss 5.2827e+03, initc-loss 1.2963e+04                    bc_loss 3.6279e+02\n",
      "Epoch 35590, Training-Loss 2.0322e+00, Data-loss 2.1611e-01                  , pde-loss 5.2048e+03, initc-loss 1.2814e+04                    bc_loss 1.4182e+02\n",
      "Epoch 35600, Training-Loss 2.3543e+00, Data-loss 4.2056e-01                  , pde-loss 6.0371e+03, initc-loss 1.3039e+04                    bc_loss 2.6208e+02\n",
      "Epoch 35610, Training-Loss 2.3512e+00, Data-loss 3.7242e-01                  , pde-loss 6.7888e+03, initc-loss 1.2913e+04                    bc_loss 8.6444e+01\n",
      "Epoch 35620, Training-Loss 2.1632e+00, Data-loss 2.0786e-01                  , pde-loss 6.5569e+03, initc-loss 1.2930e+04                    bc_loss 6.5857e+01\n",
      "Epoch 35630, Training-Loss 2.2043e+00, Data-loss 2.3982e-01                  , pde-loss 6.5200e+03, initc-loss 1.2814e+04                    bc_loss 3.1067e+02\n",
      "Epoch 35640, Training-Loss 2.1565e+00, Data-loss 2.3169e-01                  , pde-loss 6.1861e+03, initc-loss 1.2937e+04                    bc_loss 1.2455e+02\n",
      "Epoch 35650, Training-Loss 2.0329e+00, Data-loss 2.5550e-01                  , pde-loss 4.5908e+03, initc-loss 1.2883e+04                    bc_loss 3.0027e+02\n",
      "Epoch 35660, Training-Loss 2.0676e+00, Data-loss 2.2663e-01                  , pde-loss 5.4477e+03, initc-loss 1.2841e+04                    bc_loss 1.2151e+02\n",
      "Epoch 35670, Training-Loss 2.1475e+00, Data-loss 2.5308e-01                  , pde-loss 5.7870e+03, initc-loss 1.3038e+04                    bc_loss 1.1988e+02\n",
      "Epoch 35680, Training-Loss 2.0985e+00, Data-loss 2.0163e-01                  , pde-loss 5.8641e+03, initc-loss 1.2916e+04                    bc_loss 1.8886e+02\n",
      "Epoch 35690, Training-Loss 2.0539e+00, Data-loss 2.1501e-01                  , pde-loss 5.4176e+03, initc-loss 1.2844e+04                    bc_loss 1.2742e+02\n",
      "Epoch 35700, Training-Loss 1.9435e+00, Data-loss 1.2923e-01                  , pde-loss 5.0704e+03, initc-loss 1.2847e+04                    bc_loss 2.2498e+02\n",
      "Epoch 35710, Training-Loss 2.1499e+00, Data-loss 1.9976e-01                  , pde-loss 6.3493e+03, initc-loss 1.2925e+04                    bc_loss 2.2738e+02\n",
      "Epoch 35720, Training-Loss 2.0389e+00, Data-loss 1.0695e-01                  , pde-loss 6.2146e+03, initc-loss 1.2973e+04                    bc_loss 1.3200e+02\n",
      "Epoch 35730, Training-Loss 2.0767e+00, Data-loss 1.6630e-01                  , pde-loss 6.1108e+03, initc-loss 1.2873e+04                    bc_loss 1.1981e+02\n",
      "Epoch 35740, Training-Loss 1.9820e+00, Data-loss 1.5523e-01                  , pde-loss 5.3521e+03, initc-loss 1.2854e+04                    bc_loss 6.1358e+01\n",
      "Epoch 35750, Training-Loss 2.1358e+00, Data-loss 1.8401e-01                  , pde-loss 6.5166e+03, initc-loss 1.2928e+04                    bc_loss 7.2877e+01\n",
      "Epoch 35760, Training-Loss 2.1604e+00, Data-loss 2.8911e-01                  , pde-loss 5.6134e+03, initc-loss 1.2907e+04                    bc_loss 1.9338e+02\n",
      "Epoch 35770, Training-Loss 2.1208e+00, Data-loss 2.4268e-01                  , pde-loss 5.6791e+03, initc-loss 1.2910e+04                    bc_loss 1.9283e+02\n",
      "Epoch 35780, Training-Loss 2.0987e+00, Data-loss 2.0307e-01                  , pde-loss 6.0124e+03, initc-loss 1.2878e+04                    bc_loss 6.6390e+01\n",
      "Epoch 35790, Training-Loss 2.0850e+00, Data-loss 1.6454e-01                  , pde-loss 6.2794e+03, initc-loss 1.2866e+04                    bc_loss 5.9641e+01\n",
      "Epoch 35800, Training-Loss 2.2387e+00, Data-loss 3.2004e-01                  , pde-loss 6.0551e+03, initc-loss 1.2880e+04                    bc_loss 2.5142e+02\n",
      "Epoch 35810, Training-Loss 2.0098e+00, Data-loss 1.5942e-01                  , pde-loss 5.5668e+03, initc-loss 1.2861e+04                    bc_loss 7.5311e+01\n",
      "Epoch 35820, Training-Loss 2.0129e+00, Data-loss 1.5391e-01                  , pde-loss 5.2988e+03, initc-loss 1.2895e+04                    bc_loss 3.9569e+02\n",
      "Epoch 35830, Training-Loss 1.9896e+00, Data-loss 1.4199e-01                  , pde-loss 5.3686e+03, initc-loss 1.2913e+04                    bc_loss 1.9398e+02\n",
      "Epoch 35840, Training-Loss 2.1386e+00, Data-loss 2.1103e-01                  , pde-loss 6.1639e+03, initc-loss 1.2979e+04                    bc_loss 1.3355e+02\n",
      "Epoch 35850, Training-Loss 2.0085e+00, Data-loss 1.1802e-01                  , pde-loss 5.9385e+03, initc-loss 1.2908e+04                    bc_loss 5.8232e+01\n",
      "Epoch 35860, Training-Loss 2.1724e+00, Data-loss 2.5362e-01                  , pde-loss 6.1449e+03, initc-loss 1.2924e+04                    bc_loss 1.1956e+02\n",
      "Epoch 35870, Training-Loss 2.1409e+00, Data-loss 2.2874e-01                  , pde-loss 5.8867e+03, initc-loss 1.2973e+04                    bc_loss 2.6166e+02\n",
      "Epoch 35880, Training-Loss 2.1809e+00, Data-loss 2.9697e-01                  , pde-loss 5.7517e+03, initc-loss 1.2805e+04                    bc_loss 2.8350e+02\n",
      "Epoch 35890, Training-Loss 2.0518e+00, Data-loss 2.6990e-01                  , pde-loss 4.8049e+03, initc-loss 1.2894e+04                    bc_loss 1.2029e+02\n",
      "Epoch 35900, Training-Loss 2.1686e+00, Data-loss 2.2252e-01                  , pde-loss 6.4163e+03, initc-loss 1.2877e+04                    bc_loss 1.6751e+02\n",
      "Epoch 35910, Training-Loss 2.0929e+00, Data-loss 1.3810e-01                  , pde-loss 6.5523e+03, initc-loss 1.2934e+04                    bc_loss 6.1789e+01\n",
      "Epoch 35920, Training-Loss 2.0850e+00, Data-loss 1.5961e-01                  , pde-loss 6.2651e+03, initc-loss 1.2886e+04                    bc_loss 1.0347e+02\n",
      "Epoch 35930, Training-Loss 2.0066e+00, Data-loss 1.9983e-01                  , pde-loss 5.1053e+03, initc-loss 1.2910e+04                    bc_loss 5.2370e+01\n",
      "Epoch 35940, Training-Loss 1.9418e+00, Data-loss 1.6606e-01                  , pde-loss 4.6813e+03, initc-loss 1.2923e+04                    bc_loss 1.5370e+02\n",
      "Epoch 35950, Training-Loss 1.9983e+00, Data-loss 1.5958e-01                  , pde-loss 5.2242e+03, initc-loss 1.2889e+04                    bc_loss 2.7393e+02\n",
      "Epoch 35960, Training-Loss 2.0344e+00, Data-loss 1.3367e-01                  , pde-loss 6.0651e+03, initc-loss 1.2884e+04                    bc_loss 5.7861e+01\n",
      "Epoch 35970, Training-Loss 2.1168e+00, Data-loss 1.4244e-01                  , pde-loss 6.6783e+03, initc-loss 1.2923e+04                    bc_loss 1.4299e+02\n",
      "Epoch 35980, Training-Loss 2.1063e+00, Data-loss 1.4062e-01                  , pde-loss 6.6410e+03, initc-loss 1.2929e+04                    bc_loss 8.6224e+01\n",
      "Epoch 35990, Training-Loss 2.1515e+00, Data-loss 2.1566e-01                  , pde-loss 6.2095e+03, initc-loss 1.2911e+04                    bc_loss 2.3752e+02\n",
      "Epoch 36000, Training-Loss 2.3046e+00, Data-loss 4.1266e-01                  , pde-loss 5.9229e+03, initc-loss 1.2828e+04                    bc_loss 1.6786e+02\n",
      "Epoch 36010, Training-Loss 2.1000e+00, Data-loss 2.0556e-01                  , pde-loss 5.8468e+03, initc-loss 1.2973e+04                    bc_loss 1.2414e+02\n",
      "Epoch 36020, Training-Loss 2.3847e+00, Data-loss 2.7591e-01                  , pde-loss 7.1160e+03, initc-loss 1.2946e+04                    bc_loss 1.0263e+03\n",
      "Epoch 36030, Training-Loss 2.1777e+00, Data-loss 2.7483e-01                  , pde-loss 5.8920e+03, initc-loss 1.2896e+04                    bc_loss 2.4052e+02\n",
      "Epoch 36040, Training-Loss 2.0076e+00, Data-loss 1.4961e-01                  , pde-loss 5.2348e+03, initc-loss 1.2854e+04                    bc_loss 4.9122e+02\n",
      "Epoch 36050, Training-Loss 2.0493e+00, Data-loss 1.8084e-01                  , pde-loss 5.7169e+03, initc-loss 1.2891e+04                    bc_loss 7.6693e+01\n",
      "Epoch 36060, Training-Loss 2.0134e+00, Data-loss 1.8614e-01                  , pde-loss 5.3001e+03, initc-loss 1.2892e+04                    bc_loss 8.0384e+01\n",
      "Epoch 36070, Training-Loss 2.0615e+00, Data-loss 1.7934e-01                  , pde-loss 5.7963e+03, initc-loss 1.2871e+04                    bc_loss 1.5447e+02\n",
      "Epoch 36080, Training-Loss 1.9931e+00, Data-loss 9.4369e-02                  , pde-loss 5.9660e+03, initc-loss 1.2898e+04                    bc_loss 1.2336e+02\n",
      "Epoch 36090, Training-Loss 2.0038e+00, Data-loss 1.7515e-01                  , pde-loss 5.2702e+03, initc-loss 1.2931e+04                    bc_loss 8.5885e+01\n",
      "Epoch 36100, Training-Loss 2.0668e+00, Data-loss 2.1271e-01                  , pde-loss 5.1980e+03, initc-loss 1.2943e+04                    bc_loss 4.0019e+02\n",
      "Epoch 36110, Training-Loss 2.0973e+00, Data-loss 2.0068e-01                  , pde-loss 5.9097e+03, initc-loss 1.2914e+04                    bc_loss 1.4179e+02\n",
      "Epoch 36120, Training-Loss 2.1508e+00, Data-loss 2.1135e-01                  , pde-loss 6.4319e+03, initc-loss 1.2868e+04                    bc_loss 9.4501e+01\n",
      "Epoch 36130, Training-Loss 2.1085e+00, Data-loss 1.5196e-01                  , pde-loss 6.6173e+03, initc-loss 1.2851e+04                    bc_loss 9.7121e+01\n",
      "Epoch 36140, Training-Loss 2.0848e+00, Data-loss 2.1512e-01                  , pde-loss 5.6088e+03, initc-loss 1.2846e+04                    bc_loss 2.4146e+02\n",
      "Epoch 36150, Training-Loss 2.1106e+00, Data-loss 2.0934e-01                  , pde-loss 6.0365e+03, initc-loss 1.2838e+04                    bc_loss 1.3734e+02\n",
      "Epoch 36160, Training-Loss 1.9712e+00, Data-loss 1.3447e-01                  , pde-loss 5.3776e+03, initc-loss 1.2907e+04                    bc_loss 8.2612e+01\n",
      "Epoch 36170, Training-Loss 2.0004e+00, Data-loss 1.6111e-01                  , pde-loss 5.4541e+03, initc-loss 1.2846e+04                    bc_loss 9.2665e+01\n",
      "Epoch 36180, Training-Loss 2.0510e+00, Data-loss 2.2201e-01                  , pde-loss 5.3205e+03, initc-loss 1.2783e+04                    bc_loss 1.8615e+02\n",
      "Epoch 36190, Training-Loss 2.0776e+00, Data-loss 1.9194e-01                  , pde-loss 5.8315e+03, initc-loss 1.2913e+04                    bc_loss 1.1211e+02\n",
      "Epoch 36200, Training-Loss 2.1637e+00, Data-loss 2.9655e-01                  , pde-loss 5.7272e+03, initc-loss 1.2823e+04                    bc_loss 1.2116e+02\n",
      "Epoch 36210, Training-Loss 1.9380e+00, Data-loss 1.1296e-01                  , pde-loss 5.2382e+03, initc-loss 1.2953e+04                    bc_loss 5.9671e+01\n",
      "Epoch 36220, Training-Loss 2.0060e+00, Data-loss 1.0217e-01                  , pde-loss 6.0443e+03, initc-loss 1.2923e+04                    bc_loss 7.1370e+01\n",
      "Epoch 36230, Training-Loss 2.0357e+00, Data-loss 1.7036e-01                  , pde-loss 5.5996e+03, initc-loss 1.2912e+04                    bc_loss 1.4117e+02\n",
      "Epoch 36240, Training-Loss 2.0217e+00, Data-loss 1.7566e-01                  , pde-loss 5.4625e+03, initc-loss 1.2902e+04                    bc_loss 9.5348e+01\n",
      "Epoch 36250, Training-Loss 2.0995e+00, Data-loss 2.1479e-01                  , pde-loss 5.9544e+03, initc-loss 1.2810e+04                    bc_loss 8.2646e+01\n",
      "Epoch 36260, Training-Loss 2.1449e+00, Data-loss 2.5413e-01                  , pde-loss 5.5800e+03, initc-loss 1.2809e+04                    bc_loss 5.1898e+02\n",
      "Epoch 36270, Training-Loss 2.2134e+00, Data-loss 2.3883e-01                  , pde-loss 6.3880e+03, initc-loss 1.2926e+04                    bc_loss 4.3176e+02\n",
      "Epoch 36280, Training-Loss 2.2113e+00, Data-loss 2.8866e-01                  , pde-loss 6.1373e+03, initc-loss 1.2843e+04                    bc_loss 2.4664e+02\n",
      "Epoch 36290, Training-Loss 2.0911e+00, Data-loss 1.8784e-01                  , pde-loss 6.0287e+03, initc-loss 1.2948e+04                    bc_loss 5.5756e+01\n",
      "Epoch 36300, Training-Loss 2.2923e+00, Data-loss 3.2039e-01                  , pde-loss 6.1677e+03, initc-loss 1.2938e+04                    bc_loss 6.1377e+02\n",
      "Epoch 36310, Training-Loss 2.1937e+00, Data-loss 2.7184e-01                  , pde-loss 6.2079e+03, initc-loss 1.2825e+04                    bc_loss 1.8515e+02\n",
      "Epoch 36320, Training-Loss 2.1799e+00, Data-loss 2.6999e-01                  , pde-loss 5.8577e+03, initc-loss 1.2963e+04                    bc_loss 2.7860e+02\n",
      "Epoch 36330, Training-Loss 1.9237e+00, Data-loss 1.0834e-01                  , pde-loss 5.1924e+03, initc-loss 1.2919e+04                    bc_loss 4.2245e+01\n",
      "Epoch 36340, Training-Loss 1.9703e+00, Data-loss 1.4004e-01                  , pde-loss 5.2812e+03, initc-loss 1.2950e+04                    bc_loss 7.1507e+01\n",
      "Epoch 36350, Training-Loss 2.1199e+00, Data-loss 2.7425e-01                  , pde-loss 5.5112e+03, initc-loss 1.2797e+04                    bc_loss 1.4815e+02\n",
      "Epoch 36360, Training-Loss 2.0864e+00, Data-loss 1.8857e-01                  , pde-loss 5.5631e+03, initc-loss 1.2994e+04                    bc_loss 4.2092e+02\n",
      "Epoch 36370, Training-Loss 2.0751e+00, Data-loss 1.6987e-01                  , pde-loss 5.9078e+03, initc-loss 1.2887e+04                    bc_loss 2.5725e+02\n",
      "Epoch 36380, Training-Loss 1.9960e+00, Data-loss 1.2754e-01                  , pde-loss 5.7388e+03, initc-loss 1.2907e+04                    bc_loss 3.8710e+01\n",
      "Epoch 36390, Training-Loss 2.0532e+00, Data-loss 2.4141e-01                  , pde-loss 5.2032e+03, initc-loss 1.2821e+04                    bc_loss 9.3644e+01\n",
      "Epoch 36400, Training-Loss 1.9504e+00, Data-loss 1.2026e-01                  , pde-loss 5.2199e+03, initc-loss 1.2872e+04                    bc_loss 2.0925e+02\n",
      "Epoch 36410, Training-Loss 2.0020e+00, Data-loss 1.4820e-01                  , pde-loss 5.5730e+03, initc-loss 1.2876e+04                    bc_loss 8.8895e+01\n",
      "Epoch 36420, Training-Loss 2.0678e+00, Data-loss 1.5376e-01                  , pde-loss 6.1256e+03, initc-loss 1.2910e+04                    bc_loss 1.0478e+02\n",
      "Epoch 36430, Training-Loss 2.1598e+00, Data-loss 2.0196e-01                  , pde-loss 6.4410e+03, initc-loss 1.3012e+04                    bc_loss 1.2530e+02\n",
      "Epoch 36440, Training-Loss 2.0214e+00, Data-loss 1.2169e-01                  , pde-loss 5.8692e+03, initc-loss 1.2863e+04                    bc_loss 2.6483e+02\n",
      "Epoch 36450, Training-Loss 1.9559e+00, Data-loss 9.9679e-02                  , pde-loss 5.4956e+03, initc-loss 1.2894e+04                    bc_loss 1.7286e+02\n",
      "Epoch 36460, Training-Loss 1.9466e+00, Data-loss 9.4184e-02                  , pde-loss 5.5058e+03, initc-loss 1.2918e+04                    bc_loss 9.9485e+01\n",
      "Epoch 36470, Training-Loss 2.0609e+00, Data-loss 1.7998e-01                  , pde-loss 5.7303e+03, initc-loss 1.2878e+04                    bc_loss 2.0132e+02\n",
      "Epoch 36480, Training-Loss 2.3020e+00, Data-loss 3.4712e-01                  , pde-loss 6.0950e+03, initc-loss 1.2794e+04                    bc_loss 6.5994e+02\n",
      "Epoch 36490, Training-Loss 2.0200e+00, Data-loss 1.7562e-01                  , pde-loss 5.2443e+03, initc-loss 1.2978e+04                    bc_loss 2.2094e+02\n",
      "Epoch 36500, Training-Loss 1.9626e+00, Data-loss 1.4588e-01                  , pde-loss 5.1615e+03, initc-loss 1.2951e+04                    bc_loss 5.4120e+01\n",
      "Epoch 36510, Training-Loss 2.0297e+00, Data-loss 1.4065e-01                  , pde-loss 5.7993e+03, initc-loss 1.2923e+04                    bc_loss 1.6800e+02\n",
      "Epoch 36520, Training-Loss 2.2234e+00, Data-loss 1.7522e-01                  , pde-loss 7.2235e+03, initc-loss 1.2943e+04                    bc_loss 3.1564e+02\n",
      "Epoch 36530, Training-Loss 1.9360e+00, Data-loss 1.0097e-01                  , pde-loss 5.3855e+03, initc-loss 1.2896e+04                    bc_loss 6.7967e+01\n",
      "Epoch 36540, Training-Loss 1.9698e+00, Data-loss 1.2884e-01                  , pde-loss 5.3870e+03, initc-loss 1.2901e+04                    bc_loss 1.2172e+02\n",
      "Epoch 36550, Training-Loss 2.0418e+00, Data-loss 1.3486e-01                  , pde-loss 6.0583e+03, initc-loss 1.2930e+04                    bc_loss 8.1193e+01\n",
      "Epoch 36560, Training-Loss 2.0094e+00, Data-loss 1.8031e-01                  , pde-loss 5.1417e+03, initc-loss 1.2857e+04                    bc_loss 2.9290e+02\n",
      "Epoch 36570, Training-Loss 2.2460e+00, Data-loss 2.4238e-01                  , pde-loss 6.5595e+03, initc-loss 1.2935e+04                    bc_loss 5.4151e+02\n",
      "Epoch 36580, Training-Loss 1.9713e+00, Data-loss 1.3299e-01                  , pde-loss 5.4330e+03, initc-loss 1.2868e+04                    bc_loss 8.2217e+01\n",
      "Epoch 36590, Training-Loss 2.0943e+00, Data-loss 1.5872e-01                  , pde-loss 6.1455e+03, initc-loss 1.2923e+04                    bc_loss 2.8749e+02\n",
      "Epoch 36600, Training-Loss 2.1175e+00, Data-loss 1.6398e-01                  , pde-loss 6.4051e+03, initc-loss 1.2954e+04                    bc_loss 1.7574e+02\n",
      "Epoch 36610, Training-Loss 2.0285e+00, Data-loss 1.2053e-01                  , pde-loss 6.0401e+03, initc-loss 1.2899e+04                    bc_loss 1.4093e+02\n",
      "Epoch 36620, Training-Loss 2.0138e+00, Data-loss 1.0932e-01                  , pde-loss 5.9784e+03, initc-loss 1.2935e+04                    bc_loss 1.3092e+02\n",
      "Epoch 36630, Training-Loss 2.0216e+00, Data-loss 1.5864e-01                  , pde-loss 5.5750e+03, initc-loss 1.2986e+04                    bc_loss 6.8651e+01\n",
      "Epoch 36640, Training-Loss 2.1039e+00, Data-loss 1.2766e-01                  , pde-loss 6.7074e+03, initc-loss 1.2941e+04                    bc_loss 1.1383e+02\n",
      "Epoch 36650, Training-Loss 2.0741e+00, Data-loss 1.6253e-01                  , pde-loss 6.0246e+03, initc-loss 1.2926e+04                    bc_loss 1.6540e+02\n",
      "Epoch 36660, Training-Loss 1.9942e+00, Data-loss 1.3665e-01                  , pde-loss 5.6015e+03, initc-loss 1.2879e+04                    bc_loss 9.4499e+01\n",
      "Epoch 36670, Training-Loss 2.0626e+00, Data-loss 1.0306e-01                  , pde-loss 6.5050e+03, initc-loss 1.2927e+04                    bc_loss 1.6316e+02\n",
      "Epoch 36680, Training-Loss 2.0191e+00, Data-loss 1.2525e-01                  , pde-loss 5.9503e+03, initc-loss 1.2949e+04                    bc_loss 3.8617e+01\n",
      "Epoch 36690, Training-Loss 1.9726e+00, Data-loss 1.2633e-01                  , pde-loss 5.4814e+03, initc-loss 1.2877e+04                    bc_loss 1.0427e+02\n",
      "Epoch 36700, Training-Loss 1.9606e+00, Data-loss 1.0078e-01                  , pde-loss 5.6231e+03, initc-loss 1.2882e+04                    bc_loss 9.3827e+01\n",
      "Epoch 36710, Training-Loss 2.0013e+00, Data-loss 1.2515e-01                  , pde-loss 5.8413e+03, initc-loss 1.2869e+04                    bc_loss 5.0608e+01\n",
      "Epoch 36720, Training-Loss 2.2280e+00, Data-loss 2.5563e-01                  , pde-loss 6.5743e+03, initc-loss 1.2939e+04                    bc_loss 2.1067e+02\n",
      "Epoch 36730, Training-Loss 1.9260e+00, Data-loss 1.1062e-01                  , pde-loss 5.1264e+03, initc-loss 1.2912e+04                    bc_loss 1.1495e+02\n",
      "Epoch 36740, Training-Loss 1.9644e+00, Data-loss 7.5658e-02                  , pde-loss 5.9686e+03, initc-loss 1.2865e+04                    bc_loss 5.4438e+01\n",
      "Epoch 36750, Training-Loss 2.0643e+00, Data-loss 1.4612e-01                  , pde-loss 6.2141e+03, initc-loss 1.2890e+04                    bc_loss 7.7467e+01\n",
      "Epoch 36760, Training-Loss 1.8871e+00, Data-loss 7.9748e-02                  , pde-loss 5.0691e+03, initc-loss 1.2925e+04                    bc_loss 7.9391e+01\n",
      "Epoch 36770, Training-Loss 1.9988e+00, Data-loss 7.9748e-02                  , pde-loss 6.2809e+03, initc-loss 1.2846e+04                    bc_loss 6.4229e+01\n",
      "Epoch 36780, Training-Loss 1.9483e+00, Data-loss 1.1397e-01                  , pde-loss 5.4158e+03, initc-loss 1.2900e+04                    bc_loss 2.7012e+01\n",
      "Epoch 36790, Training-Loss 2.1155e+00, Data-loss 1.5758e-01                  , pde-loss 6.6320e+03, initc-loss 1.2904e+04                    bc_loss 4.2929e+01\n",
      "Epoch 36800, Training-Loss 1.9871e+00, Data-loss 1.6052e-01                  , pde-loss 5.3739e+03, initc-loss 1.2804e+04                    bc_loss 8.7378e+01\n",
      "Epoch 36810, Training-Loss 2.3063e+00, Data-loss 3.7436e-01                  , pde-loss 6.0103e+03, initc-loss 1.2844e+04                    bc_loss 4.6500e+02\n",
      "Epoch 36820, Training-Loss 2.0002e+00, Data-loss 1.2697e-01                  , pde-loss 5.7457e+03, initc-loss 1.2826e+04                    bc_loss 1.6064e+02\n",
      "Epoch 36830, Training-Loss 2.0150e+00, Data-loss 1.0765e-01                  , pde-loss 5.9835e+03, initc-loss 1.2922e+04                    bc_loss 1.6813e+02\n",
      "Epoch 36840, Training-Loss 1.9983e+00, Data-loss 1.0532e-01                  , pde-loss 5.9758e+03, initc-loss 1.2904e+04                    bc_loss 5.0174e+01\n",
      "Epoch 36850, Training-Loss 1.9956e+00, Data-loss 1.2594e-01                  , pde-loss 5.5347e+03, initc-loss 1.2951e+04                    bc_loss 2.1127e+02\n",
      "Epoch 36860, Training-Loss 2.0051e+00, Data-loss 1.1121e-01                  , pde-loss 5.8951e+03, initc-loss 1.2885e+04                    bc_loss 1.5903e+02\n",
      "Epoch 36870, Training-Loss 2.4134e+00, Data-loss 4.8645e-01                  , pde-loss 6.4079e+03, initc-loss 1.2797e+04                    bc_loss 6.5489e+01\n",
      "Epoch 36880, Training-Loss 2.0473e+00, Data-loss 2.2157e-01                  , pde-loss 5.2795e+03, initc-loss 1.2930e+04                    bc_loss 4.7711e+01\n",
      "Epoch 36890, Training-Loss 1.9866e+00, Data-loss 1.7190e-01                  , pde-loss 5.1033e+03, initc-loss 1.2864e+04                    bc_loss 1.7949e+02\n",
      "Epoch 36900, Training-Loss 2.2009e+00, Data-loss 2.8039e-01                  , pde-loss 6.1642e+03, initc-loss 1.2880e+04                    bc_loss 1.6096e+02\n",
      "Epoch 36910, Training-Loss 2.0561e+00, Data-loss 1.4421e-01                  , pde-loss 6.1840e+03, initc-loss 1.2854e+04                    bc_loss 8.1558e+01\n",
      "Epoch 36920, Training-Loss 1.9767e+00, Data-loss 1.2636e-01                  , pde-loss 5.4874e+03, initc-loss 1.2922e+04                    bc_loss 9.4561e+01\n",
      "Epoch 36930, Training-Loss 1.9922e+00, Data-loss 2.3558e-01                  , pde-loss 4.6150e+03, initc-loss 1.2855e+04                    bc_loss 9.6603e+01\n",
      "Epoch 36940, Training-Loss 1.9448e+00, Data-loss 1.0470e-01                  , pde-loss 5.3598e+03, initc-loss 1.2932e+04                    bc_loss 1.0983e+02\n",
      "Epoch 36950, Training-Loss 1.9419e+00, Data-loss 1.0140e-01                  , pde-loss 5.5238e+03, initc-loss 1.2833e+04                    bc_loss 4.8837e+01\n",
      "Epoch 36960, Training-Loss 2.0311e+00, Data-loss 1.4231e-01                  , pde-loss 5.9165e+03, initc-loss 1.2919e+04                    bc_loss 5.2703e+01\n",
      "Epoch 36970, Training-Loss 2.0953e+00, Data-loss 2.0780e-01                  , pde-loss 5.7459e+03, initc-loss 1.2818e+04                    bc_loss 3.1078e+02\n",
      "Epoch 36980, Training-Loss 2.1693e+00, Data-loss 3.4863e-01                  , pde-loss 5.3209e+03, initc-loss 1.2746e+04                    bc_loss 1.3937e+02\n",
      "Epoch 36990, Training-Loss 2.0318e+00, Data-loss 1.3958e-01                  , pde-loss 5.8535e+03, initc-loss 1.2966e+04                    bc_loss 1.0302e+02\n",
      "Epoch 37000, Training-Loss 2.0969e+00, Data-loss 1.7005e-01                  , pde-loss 6.1648e+03, initc-loss 1.2895e+04                    bc_loss 2.0868e+02\n",
      "Epoch 37010, Training-Loss 2.1250e+00, Data-loss 2.0802e-01                  , pde-loss 6.0090e+03, initc-loss 1.2902e+04                    bc_loss 2.5917e+02\n",
      "Epoch 37020, Training-Loss 1.9824e+00, Data-loss 1.5692e-01                  , pde-loss 5.1340e+03, initc-loss 1.2898e+04                    bc_loss 2.2348e+02\n",
      "Epoch 37030, Training-Loss 2.0858e+00, Data-loss 1.9255e-01                  , pde-loss 5.9939e+03, initc-loss 1.2858e+04                    bc_loss 8.0551e+01\n",
      "Epoch 37040, Training-Loss 2.1131e+00, Data-loss 2.0407e-01                  , pde-loss 5.6213e+03, initc-loss 1.2891e+04                    bc_loss 5.7716e+02\n",
      "Epoch 37050, Training-Loss 2.3357e+00, Data-loss 3.2715e-01                  , pde-loss 6.2655e+03, initc-loss 1.2889e+04                    bc_loss 9.3040e+02\n",
      "Epoch 37060, Training-Loss 2.2671e+00, Data-loss 4.6911e-01                  , pde-loss 5.0855e+03, initc-loss 1.2733e+04                    bc_loss 1.6142e+02\n",
      "Epoch 37070, Training-Loss 2.2340e+00, Data-loss 2.3216e-01                  , pde-loss 6.4693e+03, initc-loss 1.2913e+04                    bc_loss 6.3653e+02\n",
      "Epoch 37080, Training-Loss 2.0489e+00, Data-loss 1.3268e-01                  , pde-loss 5.7804e+03, initc-loss 1.2936e+04                    bc_loss 4.4566e+02\n",
      "Epoch 37090, Training-Loss 1.9083e+00, Data-loss 1.1492e-01                  , pde-loss 4.9271e+03, initc-loss 1.2863e+04                    bc_loss 1.4393e+02\n",
      "Epoch 37100, Training-Loss 2.0021e+00, Data-loss 1.3287e-01                  , pde-loss 5.7000e+03, initc-loss 1.2920e+04                    bc_loss 7.2558e+01\n",
      "Epoch 37110, Training-Loss 1.9686e+00, Data-loss 1.5892e-01                  , pde-loss 5.1002e+03, initc-loss 1.2848e+04                    bc_loss 1.4779e+02\n",
      "Epoch 37120, Training-Loss 1.9455e+00, Data-loss 1.3994e-01                  , pde-loss 4.9674e+03, initc-loss 1.2934e+04                    bc_loss 1.5368e+02\n",
      "Epoch 37130, Training-Loss 2.0120e+00, Data-loss 1.3046e-01                  , pde-loss 5.8590e+03, initc-loss 1.2883e+04                    bc_loss 7.2756e+01\n",
      "Epoch 37140, Training-Loss 1.9422e+00, Data-loss 8.2637e-02                  , pde-loss 5.5796e+03, initc-loss 1.2947e+04                    bc_loss 6.8793e+01\n",
      "Epoch 37150, Training-Loss 2.1811e+00, Data-loss 2.4065e-01                  , pde-loss 6.4061e+03, initc-loss 1.2916e+04                    bc_loss 8.3054e+01\n",
      "Epoch 37160, Training-Loss 2.0217e+00, Data-loss 1.1276e-01                  , pde-loss 6.0938e+03, initc-loss 1.2949e+04                    bc_loss 4.7050e+01\n",
      "Epoch 37170, Training-Loss 1.9795e+00, Data-loss 1.5593e-01                  , pde-loss 5.2698e+03, initc-loss 1.2910e+04                    bc_loss 5.5495e+01\n",
      "Epoch 37180, Training-Loss 2.1472e+00, Data-loss 2.6058e-01                  , pde-loss 5.9878e+03, initc-loss 1.2790e+04                    bc_loss 8.8218e+01\n",
      "Epoch 37190, Training-Loss 2.2262e+00, Data-loss 2.6329e-01                  , pde-loss 6.3399e+03, initc-loss 1.2786e+04                    bc_loss 5.0300e+02\n",
      "Epoch 37200, Training-Loss 2.0561e+00, Data-loss 2.4976e-01                  , pde-loss 4.9860e+03, initc-loss 1.2841e+04                    bc_loss 2.3615e+02\n",
      "Epoch 37210, Training-Loss 2.2003e+00, Data-loss 2.5474e-01                  , pde-loss 6.5216e+03, initc-loss 1.2857e+04                    bc_loss 7.7304e+01\n",
      "Epoch 37220, Training-Loss 2.0905e+00, Data-loss 2.0925e-01                  , pde-loss 5.9108e+03, initc-loss 1.2863e+04                    bc_loss 3.8195e+01\n",
      "Epoch 37230, Training-Loss 2.0022e+00, Data-loss 1.1758e-01                  , pde-loss 5.8300e+03, initc-loss 1.2951e+04                    bc_loss 6.5291e+01\n",
      "Epoch 37240, Training-Loss 2.1517e+00, Data-loss 2.3913e-01                  , pde-loss 6.0368e+03, initc-loss 1.2896e+04                    bc_loss 1.9276e+02\n",
      "Epoch 37250, Training-Loss 1.8718e+00, Data-loss 9.7441e-02                  , pde-loss 4.8040e+03, initc-loss 1.2876e+04                    bc_loss 6.4374e+01\n",
      "Epoch 37260, Training-Loss 2.0018e+00, Data-loss 1.4014e-01                  , pde-loss 5.4161e+03, initc-loss 1.2856e+04                    bc_loss 3.4387e+02\n",
      "Epoch 37270, Training-Loss 2.0454e+00, Data-loss 1.1385e-01                  , pde-loss 6.3372e+03, initc-loss 1.2773e+04                    bc_loss 2.0557e+02\n",
      "Epoch 37280, Training-Loss 1.9179e+00, Data-loss 1.0076e-01                  , pde-loss 5.2392e+03, initc-loss 1.2843e+04                    bc_loss 9.0028e+01\n",
      "Epoch 37290, Training-Loss 2.0207e+00, Data-loss 1.1983e-01                  , pde-loss 6.0159e+03, initc-loss 1.2916e+04                    bc_loss 7.7315e+01\n",
      "Epoch 37300, Training-Loss 2.0886e+00, Data-loss 1.4768e-01                  , pde-loss 6.4675e+03, initc-loss 1.2844e+04                    bc_loss 9.7501e+01\n",
      "Epoch 37310, Training-Loss 1.9546e+00, Data-loss 1.6009e-01                  , pde-loss 4.9305e+03, initc-loss 1.2926e+04                    bc_loss 8.8653e+01\n",
      "Epoch 37320, Training-Loss 2.0982e+00, Data-loss 2.2326e-01                  , pde-loss 5.7369e+03, initc-loss 1.2950e+04                    bc_loss 6.1829e+01\n",
      "Epoch 37330, Training-Loss 1.9672e+00, Data-loss 9.1880e-02                  , pde-loss 5.7049e+03, initc-loss 1.2931e+04                    bc_loss 1.1647e+02\n",
      "Epoch 37340, Training-Loss 2.1134e+00, Data-loss 2.3244e-01                  , pde-loss 5.9062e+03, initc-loss 1.2841e+04                    bc_loss 6.2986e+01\n",
      "Epoch 37350, Training-Loss 2.1053e+00, Data-loss 1.8339e-01                  , pde-loss 6.2533e+03, initc-loss 1.2918e+04                    bc_loss 4.7782e+01\n",
      "Epoch 37360, Training-Loss 2.1662e+00, Data-loss 3.1299e-01                  , pde-loss 5.3338e+03, initc-loss 1.2848e+04                    bc_loss 3.5038e+02\n",
      "Epoch 37370, Training-Loss 2.0137e+00, Data-loss 1.2946e-01                  , pde-loss 5.6524e+03, initc-loss 1.2933e+04                    bc_loss 2.5733e+02\n",
      "Epoch 37380, Training-Loss 1.9406e+00, Data-loss 1.1434e-01                  , pde-loss 5.2358e+03, initc-loss 1.2954e+04                    bc_loss 7.2465e+01\n",
      "Epoch 37390, Training-Loss 2.0552e+00, Data-loss 2.4877e-01                  , pde-loss 5.0372e+03, initc-loss 1.2795e+04                    bc_loss 2.3261e+02\n",
      "Epoch 37400, Training-Loss 2.1474e+00, Data-loss 1.7909e-01                  , pde-loss 6.1986e+03, initc-loss 1.2934e+04                    bc_loss 5.5099e+02\n",
      "Epoch 37410, Training-Loss 2.0513e+00, Data-loss 1.3203e-01                  , pde-loss 6.1518e+03, initc-loss 1.2956e+04                    bc_loss 8.3986e+01\n",
      "Epoch 37420, Training-Loss 2.0075e+00, Data-loss 1.0453e-01                  , pde-loss 6.0420e+03, initc-loss 1.2867e+04                    bc_loss 1.1987e+02\n",
      "Epoch 37430, Training-Loss 1.9796e+00, Data-loss 1.4543e-01                  , pde-loss 5.1530e+03, initc-loss 1.2936e+04                    bc_loss 2.5209e+02\n",
      "Epoch 37440, Training-Loss 2.0097e+00, Data-loss 1.4485e-01                  , pde-loss 5.5186e+03, initc-loss 1.2886e+04                    bc_loss 2.4403e+02\n",
      "Epoch 37450, Training-Loss 1.9750e+00, Data-loss 1.2891e-01                  , pde-loss 5.5062e+03, initc-loss 1.2890e+04                    bc_loss 6.4423e+01\n",
      "Epoch 37460, Training-Loss 1.9973e+00, Data-loss 9.5837e-02                  , pde-loss 6.0607e+03, initc-loss 1.2892e+04                    bc_loss 6.2819e+01\n",
      "Epoch 37470, Training-Loss 1.9182e+00, Data-loss 1.2779e-01                  , pde-loss 4.9551e+03, initc-loss 1.2826e+04                    bc_loss 1.2287e+02\n",
      "Epoch 37480, Training-Loss 2.0847e+00, Data-loss 2.0288e-01                  , pde-loss 5.8235e+03, initc-loss 1.2919e+04                    bc_loss 7.5793e+01\n",
      "Epoch 37490, Training-Loss 1.9767e+00, Data-loss 1.3600e-01                  , pde-loss 5.4728e+03, initc-loss 1.2832e+04                    bc_loss 1.0242e+02\n",
      "Epoch 37500, Training-Loss 2.0317e+00, Data-loss 1.4675e-01                  , pde-loss 5.7883e+03, initc-loss 1.2957e+04                    bc_loss 1.0473e+02\n",
      "Epoch 37510, Training-Loss 2.0260e+00, Data-loss 1.0351e-01                  , pde-loss 6.2709e+03, initc-loss 1.2852e+04                    bc_loss 1.0218e+02\n",
      "Epoch 37520, Training-Loss 1.9442e+00, Data-loss 9.1217e-02                  , pde-loss 5.5507e+03, initc-loss 1.2896e+04                    bc_loss 8.2324e+01\n",
      "Epoch 37530, Training-Loss 2.0935e+00, Data-loss 1.9468e-01                  , pde-loss 5.9125e+03, initc-loss 1.2898e+04                    bc_loss 1.7704e+02\n",
      "Epoch 37540, Training-Loss 2.1410e+00, Data-loss 1.9740e-01                  , pde-loss 6.4368e+03, initc-loss 1.2899e+04                    bc_loss 9.9807e+01\n",
      "Epoch 37550, Training-Loss 2.1115e+00, Data-loss 1.9292e-01                  , pde-loss 6.1944e+03, initc-loss 1.2897e+04                    bc_loss 9.4155e+01\n",
      "Epoch 37560, Training-Loss 1.9110e+00, Data-loss 1.4744e-01                  , pde-loss 4.6603e+03, initc-loss 1.2891e+04                    bc_loss 8.4918e+01\n",
      "Epoch 37570, Training-Loss 1.9564e+00, Data-loss 7.3392e-02                  , pde-loss 5.7333e+03, initc-loss 1.2832e+04                    bc_loss 2.6482e+02\n",
      "Epoch 37580, Training-Loss 1.9531e+00, Data-loss 1.0844e-01                  , pde-loss 5.2953e+03, initc-loss 1.2899e+04                    bc_loss 2.5204e+02\n",
      "Epoch 37590, Training-Loss 2.0754e+00, Data-loss 1.4428e-01                  , pde-loss 6.2171e+03, initc-loss 1.2902e+04                    bc_loss 1.9192e+02\n",
      "Epoch 37600, Training-Loss 2.0169e+00, Data-loss 1.3874e-01                  , pde-loss 5.7112e+03, initc-loss 1.2825e+04                    bc_loss 2.4480e+02\n",
      "Epoch 37610, Training-Loss 1.9990e+00, Data-loss 1.2551e-01                  , pde-loss 5.7154e+03, initc-loss 1.2931e+04                    bc_loss 8.8610e+01\n",
      "Epoch 37620, Training-Loss 2.0514e+00, Data-loss 1.4819e-01                  , pde-loss 5.7623e+03, initc-loss 1.2935e+04                    bc_loss 3.3421e+02\n",
      "Epoch 37630, Training-Loss 1.9320e+00, Data-loss 1.3532e-01                  , pde-loss 4.9731e+03, initc-loss 1.2760e+04                    bc_loss 2.3397e+02\n",
      "Epoch 37640, Training-Loss 2.0811e+00, Data-loss 1.9106e-01                  , pde-loss 5.5331e+03, initc-loss 1.2839e+04                    bc_loss 5.2834e+02\n",
      "Epoch 37650, Training-Loss 2.1520e+00, Data-loss 1.7051e-01                  , pde-loss 6.6646e+03, initc-loss 1.2908e+04                    bc_loss 2.4233e+02\n",
      "Epoch 37660, Training-Loss 2.0040e+00, Data-loss 1.2581e-01                  , pde-loss 5.6879e+03, initc-loss 1.2960e+04                    bc_loss 1.3417e+02\n",
      "Epoch 37670, Training-Loss 2.0144e+00, Data-loss 1.7342e-01                  , pde-loss 5.4147e+03, initc-loss 1.2804e+04                    bc_loss 1.9203e+02\n",
      "Epoch 37680, Training-Loss 2.0238e+00, Data-loss 1.3432e-01                  , pde-loss 5.8880e+03, initc-loss 1.2863e+04                    bc_loss 1.4404e+02\n",
      "Epoch 37690, Training-Loss 2.0364e+00, Data-loss 1.2864e-01                  , pde-loss 5.9403e+03, initc-loss 1.2925e+04                    bc_loss 2.1173e+02\n",
      "Epoch 37700, Training-Loss 2.0623e+00, Data-loss 2.0372e-01                  , pde-loss 5.5219e+03, initc-loss 1.2938e+04                    bc_loss 1.2539e+02\n",
      "Epoch 37710, Training-Loss 2.0300e+00, Data-loss 1.5263e-01                  , pde-loss 5.8762e+03, initc-loss 1.2849e+04                    bc_loss 4.9231e+01\n",
      "Epoch 37720, Training-Loss 1.9733e+00, Data-loss 1.3467e-01                  , pde-loss 5.4650e+03, initc-loss 1.2832e+04                    bc_loss 8.9352e+01\n",
      "Epoch 37730, Training-Loss 1.8842e+00, Data-loss 7.3235e-02                  , pde-loss 5.1689e+03, initc-loss 1.2881e+04                    bc_loss 5.8908e+01\n",
      "Epoch 37740, Training-Loss 2.0320e+00, Data-loss 1.5707e-01                  , pde-loss 5.5444e+03, initc-loss 1.2966e+04                    bc_loss 2.3876e+02\n",
      "Epoch 37750, Training-Loss 2.0597e+00, Data-loss 1.3350e-01                  , pde-loss 6.0620e+03, initc-loss 1.2901e+04                    bc_loss 2.9940e+02\n",
      "Epoch 37760, Training-Loss 1.9807e+00, Data-loss 9.4451e-02                  , pde-loss 5.8667e+03, initc-loss 1.2904e+04                    bc_loss 9.1720e+01\n",
      "Epoch 37770, Training-Loss 1.9007e+00, Data-loss 6.2274e-02                  , pde-loss 5.3696e+03, initc-loss 1.2956e+04                    bc_loss 5.9312e+01\n",
      "Epoch 37780, Training-Loss 2.0650e+00, Data-loss 1.6611e-01                  , pde-loss 5.9959e+03, initc-loss 1.2898e+04                    bc_loss 9.4654e+01\n",
      "Epoch 37790, Training-Loss 2.0740e+00, Data-loss 1.1779e-01                  , pde-loss 6.6190e+03, initc-loss 1.2838e+04                    bc_loss 1.0464e+02\n",
      "Epoch 37800, Training-Loss 2.0182e+00, Data-loss 1.0537e-01                  , pde-loss 5.9581e+03, initc-loss 1.3006e+04                    bc_loss 1.6407e+02\n",
      "Epoch 37810, Training-Loss 1.9492e+00, Data-loss 1.1256e-01                  , pde-loss 5.4102e+03, initc-loss 1.2891e+04                    bc_loss 6.4362e+01\n",
      "Epoch 37820, Training-Loss 1.9635e+00, Data-loss 1.0208e-01                  , pde-loss 5.5837e+03, initc-loss 1.2867e+04                    bc_loss 1.6375e+02\n",
      "Epoch 37830, Training-Loss 2.0137e+00, Data-loss 9.6014e-02                  , pde-loss 6.1446e+03, initc-loss 1.2903e+04                    bc_loss 1.2973e+02\n",
      "Epoch 37840, Training-Loss 1.9276e+00, Data-loss 1.1926e-01                  , pde-loss 5.1591e+03, initc-loss 1.2890e+04                    bc_loss 3.4472e+01\n",
      "Epoch 37850, Training-Loss 2.0016e+00, Data-loss 1.0808e-01                  , pde-loss 5.9788e+03, initc-loss 1.2863e+04                    bc_loss 9.3755e+01\n",
      "Epoch 37860, Training-Loss 1.9470e+00, Data-loss 9.4836e-02                  , pde-loss 5.6060e+03, initc-loss 1.2845e+04                    bc_loss 7.1060e+01\n",
      "Epoch 37870, Training-Loss 1.9310e+00, Data-loss 1.0142e-01                  , pde-loss 5.1343e+03, initc-loss 1.2882e+04                    bc_loss 2.8011e+02\n",
      "Epoch 37880, Training-Loss 2.3413e+00, Data-loss 4.5615e-01                  , pde-loss 5.6484e+03, initc-loss 1.2834e+04                    bc_loss 3.6900e+02\n",
      "Epoch 37890, Training-Loss 2.9536e+00, Data-loss 9.8621e-01                  , pde-loss 5.8735e+03, initc-loss 1.3091e+04                    bc_loss 7.0871e+02\n",
      "Epoch 37900, Training-Loss 2.1215e+00, Data-loss 2.2155e-01                  , pde-loss 5.6340e+03, initc-loss 1.2860e+04                    bc_loss 5.0478e+02\n",
      "Epoch 37910, Training-Loss 2.6954e+00, Data-loss 1.1677e-01                  , pde-loss 5.1450e+03, initc-loss 1.2952e+04                    bc_loss 7.6900e+03\n",
      "Epoch 37920, Training-Loss 6.5871e+01, Data-loss 3.2131e+01                  , pde-loss 5.0804e+03, initc-loss 1.2617e+04                    bc_loss 3.1970e+05\n",
      "Epoch 37930, Training-Loss 3.0696e+01, Data-loss 2.3836e+01                  , pde-loss 4.5684e+03, initc-loss 1.3899e+04                    bc_loss 5.0134e+04\n",
      "Epoch 37940, Training-Loss 8.1857e+00, Data-loss 5.3033e+00                  , pde-loss 5.4718e+03, initc-loss 1.3199e+04                    bc_loss 1.0153e+04\n",
      "Epoch 37950, Training-Loss 3.9180e+00, Data-loss 1.4754e+00                  , pde-loss 4.9422e+03, initc-loss 1.2939e+04                    bc_loss 6.5450e+03\n",
      "Epoch 37960, Training-Loss 3.0734e+00, Data-loss 1.0293e+00                  , pde-loss 5.5381e+03, initc-loss 1.2803e+04                    bc_loss 2.0998e+03\n",
      "Epoch 37970, Training-Loss 2.6662e+00, Data-loss 6.8523e-01                  , pde-loss 6.0642e+03, initc-loss 1.2919e+04                    bc_loss 8.2645e+02\n",
      "Epoch 37980, Training-Loss 2.5616e+00, Data-loss 5.6901e-01                  , pde-loss 5.8151e+03, initc-loss 1.3023e+04                    bc_loss 1.0879e+03\n",
      "Epoch 37990, Training-Loss 2.6009e+00, Data-loss 7.0457e-01                  , pde-loss 5.5934e+03, initc-loss 1.2939e+04                    bc_loss 4.3118e+02\n",
      "Epoch 38000, Training-Loss 2.2830e+00, Data-loss 4.0204e-01                  , pde-loss 5.5393e+03, initc-loss 1.2913e+04                    bc_loss 3.5683e+02\n",
      "Epoch 38010, Training-Loss 2.3844e+00, Data-loss 4.2972e-01                  , pde-loss 6.3904e+03, initc-loss 1.2895e+04                    bc_loss 2.6164e+02\n",
      "Epoch 38020, Training-Loss 2.1266e+00, Data-loss 2.3842e-01                  , pde-loss 5.7861e+03, initc-loss 1.2886e+04                    bc_loss 2.0890e+02\n",
      "Epoch 38030, Training-Loss 2.0787e+00, Data-loss 2.7751e-01                  , pde-loss 4.9560e+03, initc-loss 1.2855e+04                    bc_loss 2.0093e+02\n",
      "Epoch 38040, Training-Loss 2.2886e+00, Data-loss 3.7364e-01                  , pde-loss 6.0987e+03, initc-loss 1.2862e+04                    bc_loss 1.8868e+02\n",
      "Epoch 38050, Training-Loss 2.0521e+00, Data-loss 2.6328e-01                  , pde-loss 4.8327e+03, initc-loss 1.2867e+04                    bc_loss 1.8818e+02\n",
      "Epoch 38060, Training-Loss 2.0967e+00, Data-loss 2.6834e-01                  , pde-loss 5.3035e+03, initc-loss 1.2821e+04                    bc_loss 1.5908e+02\n",
      "Epoch 38070, Training-Loss 2.0438e+00, Data-loss 2.0276e-01                  , pde-loss 5.3630e+03, initc-loss 1.2910e+04                    bc_loss 1.3668e+02\n",
      "Epoch 38080, Training-Loss 2.0500e+00, Data-loss 2.0304e-01                  , pde-loss 5.4572e+03, initc-loss 1.2867e+04                    bc_loss 1.4503e+02\n",
      "Epoch 38090, Training-Loss 2.1635e+00, Data-loss 2.5106e-01                  , pde-loss 6.0714e+03, initc-loss 1.2916e+04                    bc_loss 1.3719e+02\n",
      "Epoch 38100, Training-Loss 2.0327e+00, Data-loss 1.9245e-01                  , pde-loss 5.3937e+03, initc-loss 1.2892e+04                    bc_loss 1.1723e+02\n",
      "Epoch 38110, Training-Loss 2.0825e+00, Data-loss 1.7051e-01                  , pde-loss 6.1304e+03, initc-loss 1.2901e+04                    bc_loss 8.7782e+01\n",
      "Epoch 38120, Training-Loss 1.9252e+00, Data-loss 1.5011e-01                  , pde-loss 4.7816e+03, initc-loss 1.2881e+04                    bc_loss 8.8755e+01\n",
      "Epoch 38130, Training-Loss 2.1808e+00, Data-loss 2.6323e-01                  , pde-loss 6.1800e+03, initc-loss 1.2902e+04                    bc_loss 9.3979e+01\n",
      "Epoch 38140, Training-Loss 1.9362e+00, Data-loss 1.4121e-01                  , pde-loss 4.9703e+03, initc-loss 1.2902e+04                    bc_loss 7.7530e+01\n",
      "Epoch 38150, Training-Loss 2.1201e+00, Data-loss 2.0132e-01                  , pde-loss 6.2297e+03, initc-loss 1.2871e+04                    bc_loss 8.6740e+01\n",
      "Epoch 38160, Training-Loss 2.0421e+00, Data-loss 1.5482e-01                  , pde-loss 5.9045e+03, initc-loss 1.2892e+04                    bc_loss 7.6531e+01\n",
      "Epoch 38170, Training-Loss 2.1131e+00, Data-loss 1.7709e-01                  , pde-loss 6.3606e+03, initc-loss 1.2916e+04                    bc_loss 8.3160e+01\n",
      "Epoch 38180, Training-Loss 1.9931e+00, Data-loss 1.2004e-01                  , pde-loss 5.7545e+03, initc-loss 1.2911e+04                    bc_loss 6.5649e+01\n",
      "Epoch 38190, Training-Loss 2.0439e+00, Data-loss 2.1188e-01                  , pde-loss 5.3752e+03, initc-loss 1.2892e+04                    bc_loss 5.3050e+01\n",
      "Epoch 38200, Training-Loss 1.9293e+00, Data-loss 1.2665e-01                  , pde-loss 5.1351e+03, initc-loss 1.2830e+04                    bc_loss 6.0835e+01\n",
      "Epoch 38210, Training-Loss 2.0827e+00, Data-loss 1.8473e-01                  , pde-loss 5.9870e+03, initc-loss 1.2923e+04                    bc_loss 6.9430e+01\n",
      "Epoch 38220, Training-Loss 2.2815e+00, Data-loss 2.7117e-01                  , pde-loss 7.1234e+03, initc-loss 1.2916e+04                    bc_loss 6.4190e+01\n",
      "Epoch 38230, Training-Loss 2.0123e+00, Data-loss 1.3122e-01                  , pde-loss 5.9149e+03, initc-loss 1.2832e+04                    bc_loss 6.4679e+01\n",
      "Epoch 38240, Training-Loss 2.1741e+00, Data-loss 1.7804e-01                  , pde-loss 6.9825e+03, initc-loss 1.2894e+04                    bc_loss 8.3374e+01\n",
      "Epoch 38250, Training-Loss 2.0150e+00, Data-loss 1.3161e-01                  , pde-loss 5.9300e+03, initc-loss 1.2855e+04                    bc_loss 4.8839e+01\n",
      "Epoch 38260, Training-Loss 1.9594e+00, Data-loss 1.2736e-01                  , pde-loss 5.4163e+03, initc-loss 1.2861e+04                    bc_loss 4.2305e+01\n",
      "Epoch 38270, Training-Loss 2.0074e+00, Data-loss 1.6291e-01                  , pde-loss 5.5102e+03, initc-loss 1.2881e+04                    bc_loss 5.3899e+01\n",
      "Epoch 38280, Training-Loss 2.0984e+00, Data-loss 2.0332e-01                  , pde-loss 6.0504e+03, initc-loss 1.2862e+04                    bc_loss 3.8161e+01\n",
      "Epoch 38290, Training-Loss 1.9567e+00, Data-loss 1.4524e-01                  , pde-loss 5.1885e+03, initc-loss 1.2886e+04                    bc_loss 3.9766e+01\n",
      "Epoch 38300, Training-Loss 2.0767e+00, Data-loss 1.6405e-01                  , pde-loss 6.2646e+03, initc-loss 1.2821e+04                    bc_loss 4.0903e+01\n",
      "Epoch 38310, Training-Loss 2.0652e+00, Data-loss 1.2460e-01                  , pde-loss 6.5392e+03, initc-loss 1.2831e+04                    bc_loss 3.6056e+01\n",
      "Epoch 38320, Training-Loss 2.0101e+00, Data-loss 1.6723e-01                  , pde-loss 5.4968e+03, initc-loss 1.2871e+04                    bc_loss 6.0848e+01\n",
      "Epoch 38330, Training-Loss 1.9110e+00, Data-loss 1.2124e-01                  , pde-loss 5.0042e+03, initc-loss 1.2849e+04                    bc_loss 4.4593e+01\n",
      "Epoch 38340, Training-Loss 2.1129e+00, Data-loss 1.8183e-01                  , pde-loss 6.4332e+03, initc-loss 1.2849e+04                    bc_loss 2.7775e+01\n",
      "Epoch 38350, Training-Loss 1.9904e+00, Data-loss 1.1165e-01                  , pde-loss 5.8233e+03, initc-loss 1.2934e+04                    bc_loss 3.0586e+01\n",
      "Epoch 38360, Training-Loss 1.9415e+00, Data-loss 1.1320e-01                  , pde-loss 5.4212e+03, initc-loss 1.2829e+04                    bc_loss 3.3009e+01\n",
      "Epoch 38370, Training-Loss 2.0230e+00, Data-loss 1.2201e-01                  , pde-loss 6.0308e+03, initc-loss 1.2947e+04                    bc_loss 3.2440e+01\n",
      "Epoch 38380, Training-Loss 1.9332e+00, Data-loss 1.2268e-01                  , pde-loss 5.2428e+03, initc-loss 1.2833e+04                    bc_loss 2.9287e+01\n",
      "Epoch 38390, Training-Loss 1.9450e+00, Data-loss 1.2215e-01                  , pde-loss 5.3638e+03, initc-loss 1.2824e+04                    bc_loss 4.0039e+01\n",
      "Epoch 38400, Training-Loss 1.9810e+00, Data-loss 9.7793e-02                  , pde-loss 5.8944e+03, initc-loss 1.2885e+04                    bc_loss 5.2921e+01\n",
      "Epoch 38410, Training-Loss 1.9157e+00, Data-loss 8.9491e-02                  , pde-loss 5.3675e+03, initc-loss 1.2868e+04                    bc_loss 2.6941e+01\n",
      "Epoch 38420, Training-Loss 1.9381e+00, Data-loss 1.4339e-01                  , pde-loss 5.0306e+03, initc-loss 1.2895e+04                    bc_loss 2.1862e+01\n",
      "Epoch 38430, Training-Loss 2.0319e+00, Data-loss 1.0564e-01                  , pde-loss 6.3047e+03, initc-loss 1.2934e+04                    bc_loss 2.4560e+01\n",
      "Epoch 38440, Training-Loss 1.9173e+00, Data-loss 8.1053e-02                  , pde-loss 5.4629e+03, initc-loss 1.2878e+04                    bc_loss 2.1602e+01\n",
      "Epoch 38450, Training-Loss 2.0162e+00, Data-loss 1.0708e-01                  , pde-loss 6.2348e+03, initc-loss 1.2836e+04                    bc_loss 2.0211e+01\n",
      "Epoch 38460, Training-Loss 2.0356e+00, Data-loss 1.1837e-01                  , pde-loss 6.2603e+03, initc-loss 1.2879e+04                    bc_loss 3.2555e+01\n",
      "Epoch 38470, Training-Loss 1.9785e+00, Data-loss 9.3442e-02                  , pde-loss 5.9314e+03, initc-loss 1.2875e+04                    bc_loss 4.4548e+01\n",
      "Epoch 38480, Training-Loss 1.9674e+00, Data-loss 1.2629e-01                  , pde-loss 5.4946e+03, initc-loss 1.2890e+04                    bc_loss 2.7253e+01\n",
      "Epoch 38490, Training-Loss 2.0093e+00, Data-loss 1.4563e-01                  , pde-loss 5.7460e+03, initc-loss 1.2861e+04                    bc_loss 2.9510e+01\n",
      "Epoch 38500, Training-Loss 1.9746e+00, Data-loss 1.3458e-01                  , pde-loss 5.4295e+03, initc-loss 1.2955e+04                    bc_loss 1.6087e+01\n",
      "Epoch 38510, Training-Loss 2.0839e+00, Data-loss 1.2970e-01                  , pde-loss 6.6436e+03, initc-loss 1.2861e+04                    bc_loss 3.7424e+01\n",
      "Epoch 38520, Training-Loss 1.9885e+00, Data-loss 1.6662e-01                  , pde-loss 5.3316e+03, initc-loss 1.2864e+04                    bc_loss 2.3330e+01\n",
      "Epoch 38530, Training-Loss 2.0030e+00, Data-loss 9.7497e-02                  , pde-loss 6.2041e+03, initc-loss 1.2834e+04                    bc_loss 1.6599e+01\n",
      "Epoch 38540, Training-Loss 1.9397e+00, Data-loss 1.3573e-01                  , pde-loss 5.1231e+03, initc-loss 1.2894e+04                    bc_loss 2.2355e+01\n",
      "Epoch 38550, Training-Loss 2.0175e+00, Data-loss 8.2444e-02                  , pde-loss 6.3772e+03, initc-loss 1.2949e+04                    bc_loss 2.3983e+01\n",
      "Epoch 38560, Training-Loss 2.0530e+00, Data-loss 1.3891e-01                  , pde-loss 6.3194e+03, initc-loss 1.2797e+04                    bc_loss 2.4788e+01\n",
      "Epoch 38570, Training-Loss 1.8430e+00, Data-loss 8.6337e-02                  , pde-loss 4.6494e+03, initc-loss 1.2894e+04                    bc_loss 2.2958e+01\n",
      "Epoch 38580, Training-Loss 1.9751e+00, Data-loss 1.8024e-01                  , pde-loss 5.0540e+03, initc-loss 1.2870e+04                    bc_loss 2.4588e+01\n",
      "Epoch 38590, Training-Loss 2.0123e+00, Data-loss 1.0516e-01                  , pde-loss 6.0991e+03, initc-loss 1.2949e+04                    bc_loss 2.3273e+01\n",
      "Epoch 38600, Training-Loss 2.0112e+00, Data-loss 9.8212e-02                  , pde-loss 6.2561e+03, initc-loss 1.2838e+04                    bc_loss 3.5916e+01\n",
      "Epoch 38610, Training-Loss 1.9832e+00, Data-loss 1.0004e-01                  , pde-loss 5.8564e+03, initc-loss 1.2953e+04                    bc_loss 2.1858e+01\n",
      "Epoch 38620, Training-Loss 1.9342e+00, Data-loss 1.2004e-01                  , pde-loss 5.2731e+03, initc-loss 1.2818e+04                    bc_loss 5.0574e+01\n",
      "Epoch 38630, Training-Loss 1.9414e+00, Data-loss 7.7604e-02                  , pde-loss 5.6913e+03, initc-loss 1.2926e+04                    bc_loss 2.0113e+01\n",
      "Epoch 38640, Training-Loss 1.9894e+00, Data-loss 1.4228e-01                  , pde-loss 5.5685e+03, initc-loss 1.2885e+04                    bc_loss 1.7842e+01\n",
      "Epoch 38650, Training-Loss 1.9451e+00, Data-loss 8.3711e-02                  , pde-loss 5.6823e+03, initc-loss 1.2915e+04                    bc_loss 1.6986e+01\n",
      "Epoch 38660, Training-Loss 1.8736e+00, Data-loss 7.1965e-02                  , pde-loss 5.1123e+03, initc-loss 1.2886e+04                    bc_loss 1.7680e+01\n",
      "Epoch 38670, Training-Loss 1.9698e+00, Data-loss 8.1226e-02                  , pde-loss 5.9407e+03, initc-loss 1.2921e+04                    bc_loss 2.4520e+01\n",
      "Epoch 38680, Training-Loss 1.9390e+00, Data-loss 8.6140e-02                  , pde-loss 5.5796e+03, initc-loss 1.2917e+04                    bc_loss 3.1749e+01\n",
      "Epoch 38690, Training-Loss 1.9804e+00, Data-loss 8.1308e-02                  , pde-loss 6.0328e+03, initc-loss 1.2923e+04                    bc_loss 3.5030e+01\n",
      "Epoch 38700, Training-Loss 1.9164e+00, Data-loss 7.4251e-02                  , pde-loss 5.5195e+03, initc-loss 1.2863e+04                    bc_loss 3.9220e+01\n",
      "Epoch 38710, Training-Loss 2.1544e+00, Data-loss 1.1656e-01                  , pde-loss 7.4305e+03, initc-loss 1.2918e+04                    bc_loss 2.9010e+01\n",
      "Epoch 38720, Training-Loss 2.1141e+00, Data-loss 2.5138e-01                  , pde-loss 5.6776e+03, initc-loss 1.2908e+04                    bc_loss 4.1906e+01\n",
      "Epoch 38730, Training-Loss 2.0643e+00, Data-loss 1.5123e-01                  , pde-loss 6.1241e+03, initc-loss 1.2958e+04                    bc_loss 4.9068e+01\n",
      "Epoch 38740, Training-Loss 1.9431e+00, Data-loss 1.1078e-01                  , pde-loss 5.3763e+03, initc-loss 1.2927e+04                    bc_loss 2.0761e+01\n",
      "Epoch 38750, Training-Loss 1.9877e+00, Data-loss 1.0772e-01                  , pde-loss 5.9139e+03, initc-loss 1.2868e+04                    bc_loss 1.7973e+01\n",
      "Epoch 38760, Training-Loss 2.0159e+00, Data-loss 1.4490e-01                  , pde-loss 5.6979e+03, initc-loss 1.2978e+04                    bc_loss 3.4066e+01\n",
      "Epoch 38770, Training-Loss 1.9639e+00, Data-loss 9.0918e-02                  , pde-loss 5.8134e+03, initc-loss 1.2886e+04                    bc_loss 3.0457e+01\n",
      "Epoch 38780, Training-Loss 1.9777e+00, Data-loss 1.3324e-01                  , pde-loss 5.4991e+03, initc-loss 1.2927e+04                    bc_loss 1.8712e+01\n",
      "Epoch 38790, Training-Loss 2.0328e+00, Data-loss 1.2438e-01                  , pde-loss 6.2145e+03, initc-loss 1.2847e+04                    bc_loss 2.2701e+01\n",
      "Epoch 38800, Training-Loss 2.0061e+00, Data-loss 1.1712e-01                  , pde-loss 5.9495e+03, initc-loss 1.2922e+04                    bc_loss 1.9083e+01\n",
      "Epoch 38810, Training-Loss 1.9447e+00, Data-loss 1.0055e-01                  , pde-loss 5.5717e+03, initc-loss 1.2840e+04                    bc_loss 2.9863e+01\n",
      "Epoch 38820, Training-Loss 1.9172e+00, Data-loss 1.0864e-01                  , pde-loss 5.2048e+03, initc-loss 1.2862e+04                    bc_loss 1.8778e+01\n",
      "Epoch 38830, Training-Loss 2.0785e+00, Data-loss 1.8025e-01                  , pde-loss 6.0112e+03, initc-loss 1.2947e+04                    bc_loss 2.3664e+01\n",
      "Epoch 38840, Training-Loss 2.0310e+00, Data-loss 1.0962e-01                  , pde-loss 6.3107e+03, initc-loss 1.2880e+04                    bc_loss 2.3637e+01\n",
      "Epoch 38850, Training-Loss 1.9098e+00, Data-loss 7.0505e-02                  , pde-loss 5.4580e+03, initc-loss 1.2911e+04                    bc_loss 2.4069e+01\n",
      "Epoch 38860, Training-Loss 1.9716e+00, Data-loss 1.1293e-01                  , pde-loss 5.6512e+03, initc-loss 1.2916e+04                    bc_loss 1.9623e+01\n",
      "Epoch 38870, Training-Loss 1.9988e+00, Data-loss 1.1151e-01                  , pde-loss 5.9701e+03, initc-loss 1.2862e+04                    bc_loss 4.0873e+01\n",
      "Epoch 38880, Training-Loss 2.0382e+00, Data-loss 1.1697e-01                  , pde-loss 6.2348e+03, initc-loss 1.2941e+04                    bc_loss 3.6281e+01\n",
      "Epoch 38890, Training-Loss 1.8552e+00, Data-loss 8.4641e-02                  , pde-loss 4.7481e+03, initc-loss 1.2935e+04                    bc_loss 2.2697e+01\n",
      "Epoch 38900, Training-Loss 2.0076e+00, Data-loss 1.3643e-01                  , pde-loss 5.8695e+03, initc-loss 1.2823e+04                    bc_loss 1.9188e+01\n",
      "Epoch 38910, Training-Loss 2.0680e+00, Data-loss 2.4985e-01                  , pde-loss 5.2614e+03, initc-loss 1.2898e+04                    bc_loss 2.1952e+01\n",
      "Epoch 38920, Training-Loss 1.9664e+00, Data-loss 1.2557e-01                  , pde-loss 5.4733e+03, initc-loss 1.2913e+04                    bc_loss 2.2165e+01\n",
      "Epoch 38930, Training-Loss 2.0227e+00, Data-loss 9.4380e-02                  , pde-loss 6.3062e+03, initc-loss 1.2943e+04                    bc_loss 3.3129e+01\n",
      "Epoch 38940, Training-Loss 1.9865e+00, Data-loss 1.2672e-01                  , pde-loss 5.5579e+03, initc-loss 1.2933e+04                    bc_loss 1.0762e+02\n",
      "Epoch 38950, Training-Loss 2.1071e+00, Data-loss 1.2580e-01                  , pde-loss 6.9108e+03, initc-loss 1.2869e+04                    bc_loss 3.3028e+01\n",
      "Epoch 38960, Training-Loss 1.9993e+00, Data-loss 1.2331e-01                  , pde-loss 5.8331e+03, initc-loss 1.2885e+04                    bc_loss 4.1437e+01\n",
      "Epoch 38970, Training-Loss 2.0122e+00, Data-loss 9.3083e-02                  , pde-loss 6.2250e+03, initc-loss 1.2920e+04                    bc_loss 4.6217e+01\n",
      "Epoch 38980, Training-Loss 2.0196e+00, Data-loss 1.3504e-01                  , pde-loss 5.9352e+03, initc-loss 1.2891e+04                    bc_loss 2.0309e+01\n",
      "Epoch 38990, Training-Loss 1.9760e+00, Data-loss 1.0834e-01                  , pde-loss 5.7515e+03, initc-loss 1.2901e+04                    bc_loss 2.4169e+01\n",
      "Epoch 39000, Training-Loss 1.9565e+00, Data-loss 1.1038e-01                  , pde-loss 5.5681e+03, initc-loss 1.2873e+04                    bc_loss 2.0586e+01\n",
      "Epoch 39010, Training-Loss 2.1029e+00, Data-loss 2.2264e-01                  , pde-loss 5.8673e+03, initc-loss 1.2911e+04                    bc_loss 2.4583e+01\n",
      "Epoch 39020, Training-Loss 1.8980e+00, Data-loss 8.3897e-02                  , pde-loss 5.2308e+03, initc-loss 1.2881e+04                    bc_loss 2.8698e+01\n",
      "Epoch 39030, Training-Loss 1.9395e+00, Data-loss 1.0066e-01                  , pde-loss 5.4404e+03, initc-loss 1.2928e+04                    bc_loss 2.0143e+01\n",
      "Epoch 39040, Training-Loss 1.9304e+00, Data-loss 7.0117e-02                  , pde-loss 5.7069e+03, initc-loss 1.2856e+04                    bc_loss 3.8921e+01\n",
      "Epoch 39050, Training-Loss 1.9102e+00, Data-loss 8.2314e-02                  , pde-loss 5.4736e+03, initc-loss 1.2780e+04                    bc_loss 2.5536e+01\n",
      "Epoch 39060, Training-Loss 2.0859e+00, Data-loss 1.4220e-01                  , pde-loss 6.5026e+03, initc-loss 1.2883e+04                    bc_loss 5.1242e+01\n",
      "Epoch 39070, Training-Loss 1.9340e+00, Data-loss 8.7597e-02                  , pde-loss 5.5538e+03, initc-loss 1.2886e+04                    bc_loss 2.4900e+01\n",
      "Epoch 39080, Training-Loss 1.9598e+00, Data-loss 9.7325e-02                  , pde-loss 5.6852e+03, initc-loss 1.2916e+04                    bc_loss 2.3556e+01\n",
      "Epoch 39090, Training-Loss 1.9662e+00, Data-loss 9.2922e-02                  , pde-loss 5.7847e+03, initc-loss 1.2919e+04                    bc_loss 2.8547e+01\n",
      "Epoch 39100, Training-Loss 2.0381e+00, Data-loss 9.7192e-02                  , pde-loss 6.5047e+03, initc-loss 1.2857e+04                    bc_loss 4.6957e+01\n",
      "Epoch 39110, Training-Loss 1.9912e+00, Data-loss 1.2901e-01                  , pde-loss 5.7706e+03, initc-loss 1.2820e+04                    bc_loss 3.1719e+01\n",
      "Epoch 39120, Training-Loss 1.9713e+00, Data-loss 1.2319e-01                  , pde-loss 5.5568e+03, initc-loss 1.2874e+04                    bc_loss 4.9949e+01\n",
      "Epoch 39130, Training-Loss 2.0682e+00, Data-loss 1.2155e-01                  , pde-loss 6.5745e+03, initc-loss 1.2835e+04                    bc_loss 5.7187e+01\n",
      "Epoch 39140, Training-Loss 2.0569e+00, Data-loss 8.8227e-02                  , pde-loss 6.7478e+03, initc-loss 1.2897e+04                    bc_loss 4.2279e+01\n",
      "Epoch 39150, Training-Loss 2.0589e+00, Data-loss 1.1815e-01                  , pde-loss 6.5153e+03, initc-loss 1.2865e+04                    bc_loss 2.6540e+01\n",
      "Epoch 39160, Training-Loss 1.9153e+00, Data-loss 8.4887e-02                  , pde-loss 5.3183e+03, initc-loss 1.2964e+04                    bc_loss 2.1217e+01\n",
      "Epoch 39170, Training-Loss 1.9479e+00, Data-loss 1.0492e-01                  , pde-loss 5.4594e+03, initc-loss 1.2942e+04                    bc_loss 2.7914e+01\n",
      "Epoch 39180, Training-Loss 1.9925e+00, Data-loss 1.1686e-01                  , pde-loss 5.8079e+03, initc-loss 1.2921e+04                    bc_loss 2.7233e+01\n",
      "Epoch 39190, Training-Loss 1.9719e+00, Data-loss 1.3052e-01                  , pde-loss 5.5009e+03, initc-loss 1.2876e+04                    bc_loss 3.7147e+01\n",
      "Epoch 39200, Training-Loss 1.9647e+00, Data-loss 9.9486e-02                  , pde-loss 5.7508e+03, initc-loss 1.2861e+04                    bc_loss 4.0747e+01\n",
      "Epoch 39210, Training-Loss 2.0077e+00, Data-loss 1.0020e-01                  , pde-loss 6.1001e+03, initc-loss 1.2920e+04                    bc_loss 5.5382e+01\n",
      "Epoch 39220, Training-Loss 1.9332e+00, Data-loss 1.1193e-01                  , pde-loss 5.3051e+03, initc-loss 1.2872e+04                    bc_loss 3.6257e+01\n",
      "Epoch 39230, Training-Loss 2.0062e+00, Data-loss 1.4873e-01                  , pde-loss 5.6820e+03, initc-loss 1.2872e+04                    bc_loss 2.0805e+01\n",
      "Epoch 39240, Training-Loss 1.9422e+00, Data-loss 1.1416e-01                  , pde-loss 5.3505e+03, initc-loss 1.2887e+04                    bc_loss 4.2666e+01\n",
      "Epoch 39250, Training-Loss 1.9550e+00, Data-loss 1.0375e-01                  , pde-loss 5.5819e+03, initc-loss 1.2898e+04                    bc_loss 3.2035e+01\n",
      "Epoch 39260, Training-Loss 1.9728e+00, Data-loss 9.7409e-02                  , pde-loss 5.8853e+03, initc-loss 1.2823e+04                    bc_loss 4.5886e+01\n",
      "Epoch 39270, Training-Loss 2.0921e+00, Data-loss 1.2624e-01                  , pde-loss 6.6924e+03, initc-loss 1.2926e+04                    bc_loss 3.9662e+01\n",
      "Epoch 39280, Training-Loss 1.9524e+00, Data-loss 9.7466e-02                  , pde-loss 5.7226e+03, initc-loss 1.2780e+04                    bc_loss 4.7723e+01\n",
      "Epoch 39290, Training-Loss 1.8982e+00, Data-loss 8.2347e-02                  , pde-loss 5.2301e+03, initc-loss 1.2908e+04                    bc_loss 2.0513e+01\n",
      "Epoch 39300, Training-Loss 2.0644e+00, Data-loss 1.6026e-01                  , pde-loss 6.1303e+03, initc-loss 1.2891e+04                    bc_loss 1.9412e+01\n",
      "Epoch 39310, Training-Loss 1.9978e+00, Data-loss 1.3861e-01                  , pde-loss 5.6734e+03, initc-loss 1.2888e+04                    bc_loss 2.9996e+01\n",
      "Epoch 39320, Training-Loss 1.9548e+00, Data-loss 9.8623e-02                  , pde-loss 5.6186e+03, initc-loss 1.2908e+04                    bc_loss 3.4533e+01\n",
      "Epoch 39330, Training-Loss 1.8953e+00, Data-loss 8.9093e-02                  , pde-loss 5.2090e+03, initc-loss 1.2820e+04                    bc_loss 3.3616e+01\n",
      "Epoch 39340, Training-Loss 1.8752e+00, Data-loss 7.5267e-02                  , pde-loss 5.1126e+03, initc-loss 1.2868e+04                    bc_loss 1.8212e+01\n",
      "Epoch 39350, Training-Loss 1.9551e+00, Data-loss 9.8702e-02                  , pde-loss 5.5794e+03, initc-loss 1.2967e+04                    bc_loss 1.6802e+01\n",
      "Epoch 39360, Training-Loss 1.9874e+00, Data-loss 6.9337e-02                  , pde-loss 6.2645e+03, initc-loss 1.2894e+04                    bc_loss 2.1336e+01\n",
      "Epoch 39370, Training-Loss 2.0045e+00, Data-loss 1.0113e-01                  , pde-loss 6.1635e+03, initc-loss 1.2852e+04                    bc_loss 1.8276e+01\n",
      "Epoch 39380, Training-Loss 2.0075e+00, Data-loss 1.2639e-01                  , pde-loss 5.9134e+03, initc-loss 1.2863e+04                    bc_loss 3.3913e+01\n",
      "Epoch 39390, Training-Loss 2.0045e+00, Data-loss 7.8377e-02                  , pde-loss 6.2714e+03, initc-loss 1.2936e+04                    bc_loss 5.3415e+01\n",
      "Epoch 39400, Training-Loss 2.0013e+00, Data-loss 9.9862e-02                  , pde-loss 6.0740e+03, initc-loss 1.2891e+04                    bc_loss 4.9278e+01\n",
      "Epoch 39410, Training-Loss 1.9741e+00, Data-loss 8.1064e-02                  , pde-loss 5.9910e+03, initc-loss 1.2901e+04                    bc_loss 3.8319e+01\n",
      "Epoch 39420, Training-Loss 1.9846e+00, Data-loss 1.1429e-01                  , pde-loss 5.8280e+03, initc-loss 1.2838e+04                    bc_loss 3.7041e+01\n",
      "Epoch 39430, Training-Loss 2.0326e+00, Data-loss 1.2246e-01                  , pde-loss 6.2380e+03, initc-loss 1.2841e+04                    bc_loss 2.2961e+01\n",
      "Epoch 39440, Training-Loss 1.9875e+00, Data-loss 1.1409e-01                  , pde-loss 5.8153e+03, initc-loss 1.2873e+04                    bc_loss 4.5988e+01\n",
      "Epoch 39450, Training-Loss 1.9397e+00, Data-loss 9.3286e-02                  , pde-loss 5.5573e+03, initc-loss 1.2875e+04                    bc_loss 3.2051e+01\n",
      "Epoch 39460, Training-Loss 1.8303e+00, Data-loss 8.2111e-02                  , pde-loss 4.5090e+03, initc-loss 1.2943e+04                    bc_loss 2.9354e+01\n",
      "Epoch 39470, Training-Loss 2.0005e+00, Data-loss 1.2646e-01                  , pde-loss 5.8173e+03, initc-loss 1.2892e+04                    bc_loss 3.1191e+01\n",
      "Epoch 39480, Training-Loss 2.0704e+00, Data-loss 1.1079e-01                  , pde-loss 6.6944e+03, initc-loss 1.2865e+04                    bc_loss 3.6291e+01\n",
      "Epoch 39490, Training-Loss 1.9823e+00, Data-loss 1.1721e-01                  , pde-loss 5.6148e+03, initc-loss 1.2976e+04                    bc_loss 6.0295e+01\n",
      "Epoch 39500, Training-Loss 2.0631e+00, Data-loss 1.5600e-01                  , pde-loss 6.1984e+03, initc-loss 1.2834e+04                    bc_loss 3.9182e+01\n",
      "Epoch 39510, Training-Loss 1.9825e+00, Data-loss 9.9296e-02                  , pde-loss 5.8645e+03, initc-loss 1.2945e+04                    bc_loss 2.2048e+01\n",
      "Epoch 39520, Training-Loss 1.9995e+00, Data-loss 9.3873e-02                  , pde-loss 6.1498e+03, initc-loss 1.2865e+04                    bc_loss 4.1520e+01\n",
      "Epoch 39530, Training-Loss 1.9100e+00, Data-loss 1.1113e-01                  , pde-loss 5.0335e+03, initc-loss 1.2877e+04                    bc_loss 7.7510e+01\n",
      "Epoch 39540, Training-Loss 1.9561e+00, Data-loss 6.0452e-02                  , pde-loss 5.9996e+03, initc-loss 1.2868e+04                    bc_loss 8.8776e+01\n",
      "Epoch 39550, Training-Loss 2.1753e+00, Data-loss 2.0824e-01                  , pde-loss 6.7512e+03, initc-loss 1.2885e+04                    bc_loss 3.4071e+01\n",
      "Epoch 39560, Training-Loss 2.0279e+00, Data-loss 1.4756e-01                  , pde-loss 5.8699e+03, initc-loss 1.2887e+04                    bc_loss 4.6460e+01\n",
      "Epoch 39570, Training-Loss 1.9247e+00, Data-loss 1.1695e-01                  , pde-loss 5.2707e+03, initc-loss 1.2782e+04                    bc_loss 2.4720e+01\n",
      "Epoch 39580, Training-Loss 2.1296e+00, Data-loss 2.2303e-01                  , pde-loss 6.0855e+03, initc-loss 1.2927e+04                    bc_loss 5.2916e+01\n",
      "Epoch 39590, Training-Loss 2.0412e+00, Data-loss 1.7207e-01                  , pde-loss 5.7202e+03, initc-loss 1.2878e+04                    bc_loss 9.2914e+01\n",
      "Epoch 39600, Training-Loss 1.8888e+00, Data-loss 7.5791e-02                  , pde-loss 5.1642e+03, initc-loss 1.2932e+04                    bc_loss 3.3131e+01\n",
      "Epoch 39610, Training-Loss 1.9979e+00, Data-loss 1.2706e-01                  , pde-loss 5.7327e+03, initc-loss 1.2916e+04                    bc_loss 5.9676e+01\n",
      "Epoch 39620, Training-Loss 2.0145e+00, Data-loss 1.1739e-01                  , pde-loss 6.0567e+03, initc-loss 1.2894e+04                    bc_loss 2.0614e+01\n",
      "Epoch 39630, Training-Loss 1.9659e+00, Data-loss 7.8884e-02                  , pde-loss 5.9548e+03, initc-loss 1.2895e+04                    bc_loss 2.0593e+01\n",
      "Epoch 39640, Training-Loss 1.9509e+00, Data-loss 9.5435e-02                  , pde-loss 5.7175e+03, initc-loss 1.2777e+04                    bc_loss 6.0693e+01\n",
      "Epoch 39650, Training-Loss 1.9590e+00, Data-loss 1.1145e-01                  , pde-loss 5.4819e+03, initc-loss 1.2918e+04                    bc_loss 7.5782e+01\n",
      "Epoch 39660, Training-Loss 2.0254e+00, Data-loss 1.2052e-01                  , pde-loss 6.1614e+03, initc-loss 1.2863e+04                    bc_loss 2.4568e+01\n",
      "Epoch 39670, Training-Loss 1.9089e+00, Data-loss 8.5823e-02                  , pde-loss 5.1918e+03, initc-loss 1.2965e+04                    bc_loss 7.3524e+01\n",
      "Epoch 39680, Training-Loss 2.0490e+00, Data-loss 1.3083e-01                  , pde-loss 6.2426e+03, initc-loss 1.2900e+04                    bc_loss 3.9158e+01\n",
      "Epoch 39690, Training-Loss 2.0031e+00, Data-loss 1.4242e-01                  , pde-loss 5.7355e+03, initc-loss 1.2837e+04                    bc_loss 3.4708e+01\n",
      "Epoch 39700, Training-Loss 1.8890e+00, Data-loss 1.0147e-01                  , pde-loss 4.9695e+03, initc-loss 1.2882e+04                    bc_loss 2.4254e+01\n",
      "Epoch 39710, Training-Loss 1.9591e+00, Data-loss 7.5383e-02                  , pde-loss 5.8410e+03, initc-loss 1.2935e+04                    bc_loss 6.1183e+01\n",
      "Epoch 39720, Training-Loss 1.9812e+00, Data-loss 9.6124e-02                  , pde-loss 5.9204e+03, initc-loss 1.2915e+04                    bc_loss 1.5877e+01\n",
      "Epoch 39730, Training-Loss 1.9137e+00, Data-loss 8.8160e-02                  , pde-loss 5.2709e+03, initc-loss 1.2954e+04                    bc_loss 3.0296e+01\n",
      "Epoch 39740, Training-Loss 2.0651e+00, Data-loss 1.0929e-01                  , pde-loss 6.5500e+03, initc-loss 1.2898e+04                    bc_loss 1.1061e+02\n",
      "Epoch 39750, Training-Loss 1.8813e+00, Data-loss 1.0580e-01                  , pde-loss 4.8259e+03, initc-loss 1.2890e+04                    bc_loss 3.9063e+01\n",
      "Epoch 39760, Training-Loss 2.0655e+00, Data-loss 8.9539e-02                  , pde-loss 6.7846e+03, initc-loss 1.2930e+04                    bc_loss 4.4640e+01\n",
      "Epoch 39770, Training-Loss 1.9449e+00, Data-loss 6.3361e-02                  , pde-loss 5.8645e+03, initc-loss 1.2896e+04                    bc_loss 5.5514e+01\n",
      "Epoch 39780, Training-Loss 1.9990e+00, Data-loss 1.1832e-01                  , pde-loss 5.8352e+03, initc-loss 1.2940e+04                    bc_loss 3.1694e+01\n",
      "Epoch 39790, Training-Loss 1.9471e+00, Data-loss 9.3585e-02                  , pde-loss 5.5448e+03, initc-loss 1.2947e+04                    bc_loss 4.3360e+01\n",
      "Epoch 39800, Training-Loss 1.9412e+00, Data-loss 7.6064e-02                  , pde-loss 5.7671e+03, initc-loss 1.2857e+04                    bc_loss 2.7329e+01\n",
      "Epoch 39810, Training-Loss 2.0041e+00, Data-loss 9.1518e-02                  , pde-loss 6.2069e+03, initc-loss 1.2870e+04                    bc_loss 4.8716e+01\n",
      "Epoch 39820, Training-Loss 1.9996e+00, Data-loss 8.7854e-02                  , pde-loss 6.0761e+03, initc-loss 1.2927e+04                    bc_loss 1.1378e+02\n",
      "Epoch 39830, Training-Loss 1.9914e+00, Data-loss 1.4146e-01                  , pde-loss 5.5675e+03, initc-loss 1.2846e+04                    bc_loss 8.6165e+01\n",
      "Epoch 39840, Training-Loss 2.0162e+00, Data-loss 1.2522e-01                  , pde-loss 5.8434e+03, initc-loss 1.2900e+04                    bc_loss 1.6603e+02\n",
      "Epoch 39850, Training-Loss 2.0597e+00, Data-loss 1.8901e-01                  , pde-loss 5.7866e+03, initc-loss 1.2894e+04                    bc_loss 2.6163e+01\n",
      "Epoch 39860, Training-Loss 2.0045e+00, Data-loss 1.1677e-01                  , pde-loss 5.8784e+03, initc-loss 1.2857e+04                    bc_loss 1.4224e+02\n",
      "Epoch 39870, Training-Loss 2.0983e+00, Data-loss 2.3190e-01                  , pde-loss 5.7126e+03, initc-loss 1.2877e+04                    bc_loss 7.3954e+01\n",
      "Epoch 39880, Training-Loss 1.9570e+00, Data-loss 1.1037e-01                  , pde-loss 5.4526e+03, initc-loss 1.2885e+04                    bc_loss 1.2914e+02\n",
      "Epoch 39890, Training-Loss 2.0290e+00, Data-loss 9.0974e-02                  , pde-loss 6.4542e+03, initc-loss 1.2905e+04                    bc_loss 2.0753e+01\n",
      "Epoch 39900, Training-Loss 2.0559e+00, Data-loss 1.2652e-01                  , pde-loss 6.3508e+03, initc-loss 1.2903e+04                    bc_loss 3.9798e+01\n",
      "Epoch 39910, Training-Loss 1.9530e+00, Data-loss 8.3885e-02                  , pde-loss 5.7661e+03, initc-loss 1.2879e+04                    bc_loss 4.5635e+01\n",
      "Epoch 39920, Training-Loss 1.9827e+00, Data-loss 9.1434e-02                  , pde-loss 5.9578e+03, initc-loss 1.2915e+04                    bc_loss 3.9199e+01\n",
      "Epoch 39930, Training-Loss 1.9612e+00, Data-loss 8.4171e-02                  , pde-loss 5.8043e+03, initc-loss 1.2926e+04                    bc_loss 4.0220e+01\n",
      "Epoch 39940, Training-Loss 1.8955e+00, Data-loss 7.5874e-02                  , pde-loss 5.2021e+03, initc-loss 1.2970e+04                    bc_loss 2.3209e+01\n",
      "Epoch 39950, Training-Loss 1.9620e+00, Data-loss 7.5336e-02                  , pde-loss 5.9568e+03, initc-loss 1.2889e+04                    bc_loss 2.0429e+01\n",
      "Epoch 39960, Training-Loss 1.9448e+00, Data-loss 9.9282e-02                  , pde-loss 5.5610e+03, initc-loss 1.2857e+04                    bc_loss 3.7219e+01\n",
      "Epoch 39970, Training-Loss 1.9781e+00, Data-loss 8.7216e-02                  , pde-loss 5.9671e+03, initc-loss 1.2928e+04                    bc_loss 1.4111e+01\n",
      "Epoch 39980, Training-Loss 1.9516e+00, Data-loss 1.0705e-01                  , pde-loss 5.5241e+03, initc-loss 1.2891e+04                    bc_loss 3.0390e+01\n",
      "Epoch 39990, Training-Loss 1.9181e+00, Data-loss 6.7565e-02                  , pde-loss 5.5096e+03, initc-loss 1.2968e+04                    bc_loss 2.7182e+01\n",
      "Epoch 40000, Training-Loss 1.9160e+00, Data-loss 1.1040e-01                  , pde-loss 5.0792e+03, initc-loss 1.2937e+04                    bc_loss 3.9851e+01\n",
      "Epoch 40010, Training-Loss 2.0214e+00, Data-loss 1.3199e-01                  , pde-loss 5.9243e+03, initc-loss 1.2916e+04                    bc_loss 5.3445e+01\n",
      "Epoch 40020, Training-Loss 2.0240e+00, Data-loss 1.2350e-01                  , pde-loss 6.0928e+03, initc-loss 1.2851e+04                    bc_loss 6.1517e+01\n",
      "Epoch 40030, Training-Loss 1.9402e+00, Data-loss 7.7762e-02                  , pde-loss 5.6942e+03, initc-loss 1.2914e+04                    bc_loss 1.6064e+01\n",
      "Epoch 40040, Training-Loss 2.0195e+00, Data-loss 1.3520e-01                  , pde-loss 5.9048e+03, initc-loss 1.2899e+04                    bc_loss 3.8507e+01\n",
      "Epoch 40050, Training-Loss 1.9126e+00, Data-loss 8.8122e-02                  , pde-loss 5.3553e+03, initc-loss 1.2840e+04                    bc_loss 5.0202e+01\n",
      "Epoch 40060, Training-Loss 2.1072e+00, Data-loss 1.6764e-01                  , pde-loss 6.3999e+03, initc-loss 1.2974e+04                    bc_loss 2.1626e+01\n",
      "Epoch 40070, Training-Loss 2.0082e+00, Data-loss 1.2156e-01                  , pde-loss 5.9586e+03, initc-loss 1.2870e+04                    bc_loss 3.7693e+01\n",
      "Epoch 40080, Training-Loss 1.9168e+00, Data-loss 6.8129e-02                  , pde-loss 5.5609e+03, initc-loss 1.2883e+04                    bc_loss 4.3068e+01\n",
      "Epoch 40090, Training-Loss 1.8266e+00, Data-loss 9.6517e-02                  , pde-loss 4.3302e+03, initc-loss 1.2897e+04                    bc_loss 7.2759e+01\n",
      "Epoch 40100, Training-Loss 1.8939e+00, Data-loss 8.8604e-02                  , pde-loss 5.0892e+03, initc-loss 1.2922e+04                    bc_loss 4.2437e+01\n",
      "Epoch 40110, Training-Loss 1.9971e+00, Data-loss 1.2683e-01                  , pde-loss 5.7433e+03, initc-loss 1.2909e+04                    bc_loss 4.9832e+01\n",
      "Epoch 40120, Training-Loss 2.1142e+00, Data-loss 1.1965e-01                  , pde-loss 7.0116e+03, initc-loss 1.2900e+04                    bc_loss 3.3997e+01\n",
      "Epoch 40130, Training-Loss 1.8941e+00, Data-loss 1.1991e-01                  , pde-loss 4.7866e+03, initc-loss 1.2880e+04                    bc_loss 7.5256e+01\n",
      "Epoch 40140, Training-Loss 2.0129e+00, Data-loss 1.3927e-01                  , pde-loss 5.7422e+03, initc-loss 1.2854e+04                    bc_loss 1.3972e+02\n",
      "Epoch 40150, Training-Loss 2.0352e+00, Data-loss 1.4460e-01                  , pde-loss 5.8579e+03, initc-loss 1.2896e+04                    bc_loss 1.5285e+02\n",
      "Epoch 40160, Training-Loss 1.9675e+00, Data-loss 1.3187e-01                  , pde-loss 5.3671e+03, initc-loss 1.2898e+04                    bc_loss 9.0717e+01\n",
      "Epoch 40170, Training-Loss 2.0185e+00, Data-loss 1.1975e-01                  , pde-loss 6.0405e+03, initc-loss 1.2924e+04                    bc_loss 2.2920e+01\n",
      "Epoch 40180, Training-Loss 1.9456e+00, Data-loss 1.1433e-01                  , pde-loss 5.2776e+03, initc-loss 1.2970e+04                    bc_loss 6.5529e+01\n",
      "Epoch 40190, Training-Loss 2.0222e+00, Data-loss 1.0684e-01                  , pde-loss 6.1638e+03, initc-loss 1.2927e+04                    bc_loss 6.2215e+01\n",
      "Epoch 40200, Training-Loss 2.0654e+00, Data-loss 1.3152e-01                  , pde-loss 6.4350e+03, initc-loss 1.2856e+04                    bc_loss 4.8076e+01\n",
      "Epoch 40210, Training-Loss 2.0736e+00, Data-loss 9.8559e-02                  , pde-loss 6.8380e+03, initc-loss 1.2888e+04                    bc_loss 2.4448e+01\n",
      "Epoch 40220, Training-Loss 1.8844e+00, Data-loss 7.0610e-02                  , pde-loss 5.2320e+03, initc-loss 1.2886e+04                    bc_loss 1.9810e+01\n",
      "Epoch 40230, Training-Loss 1.9794e+00, Data-loss 8.8137e-02                  , pde-loss 6.0015e+03, initc-loss 1.2898e+04                    bc_loss 1.3300e+01\n",
      "Epoch 40240, Training-Loss 2.0398e+00, Data-loss 6.0516e-02                  , pde-loss 6.8819e+03, initc-loss 1.2860e+04                    bc_loss 5.0822e+01\n",
      "Epoch 40250, Training-Loss 2.0225e+00, Data-loss 1.5483e-01                  , pde-loss 5.7767e+03, initc-loss 1.2822e+04                    bc_loss 7.8599e+01\n",
      "Epoch 40260, Training-Loss 1.9532e+00, Data-loss 6.6085e-02                  , pde-loss 5.9129e+03, initc-loss 1.2856e+04                    bc_loss 1.0197e+02\n",
      "Epoch 40270, Training-Loss 2.0803e+00, Data-loss 1.2887e-01                  , pde-loss 6.5246e+03, initc-loss 1.2935e+04                    bc_loss 5.4299e+01\n",
      "Epoch 40280, Training-Loss 2.0554e+00, Data-loss 1.5721e-01                  , pde-loss 5.9902e+03, initc-loss 1.2931e+04                    bc_loss 6.1538e+01\n",
      "Epoch 40290, Training-Loss 1.9817e+00, Data-loss 8.5743e-02                  , pde-loss 5.8353e+03, initc-loss 1.2922e+04                    bc_loss 2.0266e+02\n",
      "Epoch 40300, Training-Loss 1.9157e+00, Data-loss 9.3490e-02                  , pde-loss 5.2350e+03, initc-loss 1.2926e+04                    bc_loss 6.0845e+01\n",
      "Epoch 40310, Training-Loss 2.0433e+00, Data-loss 6.3196e-02                  , pde-loss 6.6269e+03, initc-loss 1.2957e+04                    bc_loss 2.1748e+02\n",
      "Epoch 40320, Training-Loss 1.9519e+00, Data-loss 9.6826e-02                  , pde-loss 5.6055e+03, initc-loss 1.2899e+04                    bc_loss 4.6234e+01\n",
      "Epoch 40330, Training-Loss 2.1642e+00, Data-loss 2.8820e-01                  , pde-loss 5.8503e+03, initc-loss 1.2877e+04                    bc_loss 3.2380e+01\n",
      "Epoch 40340, Training-Loss 2.0494e+00, Data-loss 1.1319e-01                  , pde-loss 6.4089e+03, initc-loss 1.2875e+04                    bc_loss 7.8135e+01\n",
      "Epoch 40350, Training-Loss 1.9201e+00, Data-loss 1.3837e-01                  , pde-loss 4.9438e+03, initc-loss 1.2829e+04                    bc_loss 4.4113e+01\n",
      "Epoch 40360, Training-Loss 1.9423e+00, Data-loss 8.9516e-02                  , pde-loss 5.5177e+03, initc-loss 1.2820e+04                    bc_loss 1.9021e+02\n",
      "Epoch 40370, Training-Loss 1.9887e+00, Data-loss 1.2049e-01                  , pde-loss 5.8131e+03, initc-loss 1.2843e+04                    bc_loss 2.5142e+01\n",
      "Epoch 40380, Training-Loss 2.1044e+00, Data-loss 1.0460e-01                  , pde-loss 7.0364e+03, initc-loss 1.2860e+04                    bc_loss 1.0131e+02\n",
      "Epoch 40390, Training-Loss 2.0212e+00, Data-loss 1.4792e-01                  , pde-loss 5.6242e+03, initc-loss 1.2965e+04                    bc_loss 1.4375e+02\n",
      "Epoch 40400, Training-Loss 2.0392e+00, Data-loss 1.4475e-01                  , pde-loss 6.0626e+03, initc-loss 1.2838e+04                    bc_loss 4.4019e+01\n",
      "Epoch 40410, Training-Loss 1.9855e+00, Data-loss 1.4653e-01                  , pde-loss 5.4439e+03, initc-loss 1.2903e+04                    bc_loss 4.2136e+01\n",
      "Epoch 40420, Training-Loss 1.9573e+00, Data-loss 6.7288e-02                  , pde-loss 5.9682e+03, initc-loss 1.2898e+04                    bc_loss 3.4063e+01\n",
      "Epoch 40430, Training-Loss 1.9055e+00, Data-loss 7.1251e-02                  , pde-loss 5.4419e+03, initc-loss 1.2875e+04                    bc_loss 2.5740e+01\n",
      "Epoch 40440, Training-Loss 1.9475e+00, Data-loss 5.4916e-02                  , pde-loss 5.9875e+03, initc-loss 1.2882e+04                    bc_loss 5.5427e+01\n",
      "Epoch 40450, Training-Loss 2.0280e+00, Data-loss 1.2335e-01                  , pde-loss 5.9645e+03, initc-loss 1.2922e+04                    bc_loss 1.6031e+02\n",
      "Epoch 40460, Training-Loss 2.0569e+00, Data-loss 1.4916e-01                  , pde-loss 6.0929e+03, initc-loss 1.2965e+04                    bc_loss 1.9222e+01\n",
      "Epoch 40470, Training-Loss 2.0466e+00, Data-loss 1.4454e-01                  , pde-loss 6.0602e+03, initc-loss 1.2900e+04                    bc_loss 6.0132e+01\n",
      "Epoch 40480, Training-Loss 2.0089e+00, Data-loss 1.2539e-01                  , pde-loss 5.7067e+03, initc-loss 1.2859e+04                    bc_loss 2.6930e+02\n",
      "Epoch 40490, Training-Loss 1.9071e+00, Data-loss 9.3511e-02                  , pde-loss 5.1595e+03, initc-loss 1.2950e+04                    bc_loss 2.6306e+01\n",
      "Epoch 40500, Training-Loss 2.1064e+00, Data-loss 1.8472e-01                  , pde-loss 6.0626e+03, initc-loss 1.3008e+04                    bc_loss 1.4561e+02\n",
      "Epoch 40510, Training-Loss 1.9791e+00, Data-loss 1.8144e-01                  , pde-loss 4.9495e+03, initc-loss 1.2933e+04                    bc_loss 9.4218e+01\n",
      "Epoch 40520, Training-Loss 1.9066e+00, Data-loss 9.8303e-02                  , pde-loss 4.9941e+03, initc-loss 1.2985e+04                    bc_loss 1.0450e+02\n",
      "Epoch 40530, Training-Loss 1.9646e+00, Data-loss 1.0335e-01                  , pde-loss 5.7931e+03, initc-loss 1.2775e+04                    bc_loss 4.4353e+01\n",
      "Epoch 40540, Training-Loss 1.9638e+00, Data-loss 1.1734e-01                  , pde-loss 5.5188e+03, initc-loss 1.2804e+04                    bc_loss 1.4145e+02\n",
      "Epoch 40550, Training-Loss 1.9742e+00, Data-loss 1.0020e-01                  , pde-loss 5.7745e+03, initc-loss 1.2914e+04                    bc_loss 5.1024e+01\n",
      "Epoch 40560, Training-Loss 2.0110e+00, Data-loss 1.3933e-01                  , pde-loss 5.7778e+03, initc-loss 1.2915e+04                    bc_loss 2.4205e+01\n",
      "Epoch 40570, Training-Loss 1.9608e+00, Data-loss 1.3329e-01                  , pde-loss 5.2859e+03, initc-loss 1.2928e+04                    bc_loss 6.1472e+01\n",
      "Epoch 40580, Training-Loss 1.9920e+00, Data-loss 1.4413e-01                  , pde-loss 5.5449e+03, initc-loss 1.2907e+04                    bc_loss 2.6816e+01\n",
      "Epoch 40590, Training-Loss 1.8739e+00, Data-loss 1.1036e-01                  , pde-loss 4.7312e+03, initc-loss 1.2883e+04                    bc_loss 2.1868e+01\n",
      "Epoch 40600, Training-Loss 1.9261e+00, Data-loss 9.8625e-02                  , pde-loss 5.3275e+03, initc-loss 1.2914e+04                    bc_loss 3.3664e+01\n",
      "Epoch 40610, Training-Loss 1.8186e+00, Data-loss 7.3209e-02                  , pde-loss 4.5726e+03, initc-loss 1.2849e+04                    bc_loss 3.2379e+01\n",
      "Epoch 40620, Training-Loss 1.9775e+00, Data-loss 6.9500e-02                  , pde-loss 6.1402e+03, initc-loss 1.2893e+04                    bc_loss 4.5972e+01\n",
      "Epoch 40630, Training-Loss 1.9102e+00, Data-loss 8.6500e-02                  , pde-loss 5.2172e+03, initc-loss 1.2989e+04                    bc_loss 3.0543e+01\n",
      "Epoch 40640, Training-Loss 1.9041e+00, Data-loss 7.6458e-02                  , pde-loss 5.3944e+03, initc-loss 1.2865e+04                    bc_loss 1.7625e+01\n",
      "Epoch 40650, Training-Loss 1.9713e+00, Data-loss 8.5136e-02                  , pde-loss 5.9536e+03, initc-loss 1.2878e+04                    bc_loss 2.9917e+01\n",
      "Epoch 40660, Training-Loss 1.9878e+00, Data-loss 9.9273e-02                  , pde-loss 5.9413e+03, initc-loss 1.2875e+04                    bc_loss 6.8581e+01\n",
      "Epoch 40670, Training-Loss 2.0086e+00, Data-loss 1.5285e-01                  , pde-loss 5.6763e+03, initc-loss 1.2829e+04                    bc_loss 5.2214e+01\n",
      "Epoch 40680, Training-Loss 1.9802e+00, Data-loss 1.1554e-01                  , pde-loss 5.8288e+03, initc-loss 1.2797e+04                    bc_loss 2.1449e+01\n",
      "Epoch 40690, Training-Loss 1.9887e+00, Data-loss 1.0993e-01                  , pde-loss 5.8716e+03, initc-loss 1.2904e+04                    bc_loss 1.2250e+01\n",
      "Epoch 40700, Training-Loss 1.8629e+00, Data-loss 6.1209e-02                  , pde-loss 5.1114e+03, initc-loss 1.2859e+04                    bc_loss 4.6890e+01\n",
      "Epoch 40710, Training-Loss 2.0371e+00, Data-loss 1.4258e-01                  , pde-loss 6.0251e+03, initc-loss 1.2890e+04                    bc_loss 2.9968e+01\n",
      "Epoch 40720, Training-Loss 2.0241e+00, Data-loss 7.8808e-02                  , pde-loss 6.5002e+03, initc-loss 1.2863e+04                    bc_loss 9.0018e+01\n",
      "Epoch 40730, Training-Loss 1.9576e+00, Data-loss 1.2425e-01                  , pde-loss 5.4747e+03, initc-loss 1.2837e+04                    bc_loss 2.2332e+01\n",
      "Epoch 40740, Training-Loss 2.0166e+00, Data-loss 8.1400e-02                  , pde-loss 6.4229e+03, initc-loss 1.2880e+04                    bc_loss 4.9591e+01\n",
      "Epoch 40750, Training-Loss 1.8761e+00, Data-loss 7.9043e-02                  , pde-loss 5.0213e+03, initc-loss 1.2891e+04                    bc_loss 5.8194e+01\n",
      "Epoch 40760, Training-Loss 1.9666e+00, Data-loss 7.7812e-02                  , pde-loss 5.9175e+03, initc-loss 1.2921e+04                    bc_loss 4.9326e+01\n",
      "Epoch 40770, Training-Loss 1.9204e+00, Data-loss 7.2615e-02                  , pde-loss 5.5765e+03, initc-loss 1.2871e+04                    bc_loss 3.0867e+01\n",
      "Epoch 40780, Training-Loss 1.9651e+00, Data-loss 1.1818e-01                  , pde-loss 5.4547e+03, initc-loss 1.2926e+04                    bc_loss 8.8521e+01\n",
      "Epoch 40790, Training-Loss 1.9181e+00, Data-loss 7.7643e-02                  , pde-loss 5.4066e+03, initc-loss 1.2879e+04                    bc_loss 1.1951e+02\n",
      "Epoch 40800, Training-Loss 1.9329e+00, Data-loss 1.0535e-01                  , pde-loss 5.2357e+03, initc-loss 1.2898e+04                    bc_loss 1.4130e+02\n",
      "Epoch 40810, Training-Loss 1.9528e+00, Data-loss 9.7793e-02                  , pde-loss 5.4063e+03, initc-loss 1.2942e+04                    bc_loss 2.0168e+02\n",
      "Epoch 40820, Training-Loss 2.0633e+00, Data-loss 1.6026e-01                  , pde-loss 6.1015e+03, initc-loss 1.2848e+04                    bc_loss 8.0983e+01\n",
      "Epoch 40830, Training-Loss 2.0305e+00, Data-loss 9.2734e-02                  , pde-loss 6.3304e+03, initc-loss 1.2859e+04                    bc_loss 1.8803e+02\n",
      "Epoch 40840, Training-Loss 1.9907e+00, Data-loss 1.3249e-01                  , pde-loss 5.6021e+03, initc-loss 1.2943e+04                    bc_loss 3.6457e+01\n",
      "Epoch 40850, Training-Loss 1.9361e+00, Data-loss 8.0924e-02                  , pde-loss 5.6075e+03, initc-loss 1.2894e+04                    bc_loss 5.0646e+01\n",
      "Epoch 40860, Training-Loss 1.9892e+00, Data-loss 9.5149e-02                  , pde-loss 6.0545e+03, initc-loss 1.2869e+04                    bc_loss 1.6946e+01\n",
      "Epoch 40870, Training-Loss 1.9772e+00, Data-loss 1.0568e-01                  , pde-loss 5.7521e+03, initc-loss 1.2906e+04                    bc_loss 5.7083e+01\n",
      "Epoch 40880, Training-Loss 2.1038e+00, Data-loss 1.7025e-01                  , pde-loss 6.3138e+03, initc-loss 1.2959e+04                    bc_loss 6.2394e+01\n",
      "Epoch 40890, Training-Loss 2.0781e+00, Data-loss 1.8816e-01                  , pde-loss 5.9513e+03, initc-loss 1.2896e+04                    bc_loss 5.1779e+01\n",
      "Epoch 40900, Training-Loss 2.1373e+00, Data-loss 1.9166e-01                  , pde-loss 6.3659e+03, initc-loss 1.3003e+04                    bc_loss 8.7325e+01\n",
      "Epoch 40910, Training-Loss 2.0567e+00, Data-loss 1.8579e-01                  , pde-loss 5.6582e+03, initc-loss 1.3015e+04                    bc_loss 3.5962e+01\n",
      "Epoch 40920, Training-Loss 1.9614e+00, Data-loss 7.5003e-02                  , pde-loss 5.8683e+03, initc-loss 1.2932e+04                    bc_loss 6.4537e+01\n",
      "Epoch 40930, Training-Loss 1.9269e+00, Data-loss 7.8360e-02                  , pde-loss 5.6065e+03, initc-loss 1.2838e+04                    bc_loss 4.0246e+01\n",
      "Epoch 40940, Training-Loss 2.0050e+00, Data-loss 1.8601e-01                  , pde-loss 5.3192e+03, initc-loss 1.2816e+04                    bc_loss 5.4735e+01\n",
      "Epoch 40950, Training-Loss 1.9076e+00, Data-loss 1.0150e-01                  , pde-loss 5.1313e+03, initc-loss 1.2896e+04                    bc_loss 3.3702e+01\n",
      "Epoch 40960, Training-Loss 2.0375e+00, Data-loss 1.5104e-01                  , pde-loss 5.9076e+03, initc-loss 1.2928e+04                    bc_loss 2.8376e+01\n",
      "Epoch 40970, Training-Loss 2.0977e+00, Data-loss 1.0886e-01                  , pde-loss 6.8665e+03, initc-loss 1.2852e+04                    bc_loss 1.6969e+02\n",
      "Epoch 40980, Training-Loss 1.8871e+00, Data-loss 7.8940e-02                  , pde-loss 5.1838e+03, initc-loss 1.2842e+04                    bc_loss 5.6658e+01\n",
      "Epoch 40990, Training-Loss 2.0095e+00, Data-loss 7.8946e-02                  , pde-loss 6.3402e+03, initc-loss 1.2843e+04                    bc_loss 1.2314e+02\n",
      "Epoch 41000, Training-Loss 1.9732e+00, Data-loss 1.2515e-01                  , pde-loss 5.5179e+03, initc-loss 1.2921e+04                    bc_loss 4.1495e+01\n",
      "Epoch 41010, Training-Loss 1.9508e+00, Data-loss 1.1687e-01                  , pde-loss 5.4292e+03, initc-loss 1.2844e+04                    bc_loss 6.6282e+01\n",
      "Epoch 41020, Training-Loss 1.9913e+00, Data-loss 1.0948e-01                  , pde-loss 5.8895e+03, initc-loss 1.2876e+04                    bc_loss 5.2585e+01\n",
      "Epoch 41030, Training-Loss 2.0378e+00, Data-loss 1.4605e-01                  , pde-loss 5.8449e+03, initc-loss 1.3005e+04                    bc_loss 6.7384e+01\n",
      "Epoch 41040, Training-Loss 2.0137e+00, Data-loss 1.8107e-01                  , pde-loss 5.4015e+03, initc-loss 1.2863e+04                    bc_loss 6.1943e+01\n",
      "Epoch 41050, Training-Loss 1.9699e+00, Data-loss 1.5061e-01                  , pde-loss 5.1755e+03, initc-loss 1.2840e+04                    bc_loss 1.7760e+02\n",
      "Epoch 41060, Training-Loss 1.8386e+00, Data-loss 6.8041e-02                  , pde-loss 4.8362e+03, initc-loss 1.2844e+04                    bc_loss 2.5548e+01\n",
      "Epoch 41070, Training-Loss 1.9548e+00, Data-loss 9.6154e-02                  , pde-loss 5.6748e+03, initc-loss 1.2859e+04                    bc_loss 5.2342e+01\n",
      "Epoch 41080, Training-Loss 1.9703e+00, Data-loss 9.4459e-02                  , pde-loss 5.7966e+03, initc-loss 1.2939e+04                    bc_loss 2.3244e+01\n",
      "Epoch 41090, Training-Loss 1.8941e+00, Data-loss 1.0504e-01                  , pde-loss 4.7184e+03, initc-loss 1.2935e+04                    bc_loss 2.3735e+02\n",
      "Epoch 41100, Training-Loss 2.0347e+00, Data-loss 9.5544e-02                  , pde-loss 6.4762e+03, initc-loss 1.2852e+04                    bc_loss 6.3417e+01\n",
      "Epoch 41110, Training-Loss 2.0225e+00, Data-loss 2.1419e-01                  , pde-loss 5.1521e+03, initc-loss 1.2836e+04                    bc_loss 9.5352e+01\n",
      "Epoch 41120, Training-Loss 1.9682e+00, Data-loss 9.4185e-02                  , pde-loss 5.7961e+03, initc-loss 1.2890e+04                    bc_loss 5.4482e+01\n",
      "Epoch 41130, Training-Loss 1.7793e+00, Data-loss 5.4425e-02                  , pde-loss 4.3244e+03, initc-loss 1.2911e+04                    bc_loss 1.3595e+01\n",
      "Epoch 41140, Training-Loss 2.0678e+00, Data-loss 9.3609e-02                  , pde-loss 6.7821e+03, initc-loss 1.2886e+04                    bc_loss 7.3886e+01\n",
      "Epoch 41150, Training-Loss 1.9310e+00, Data-loss 8.3500e-02                  , pde-loss 5.4902e+03, initc-loss 1.2904e+04                    bc_loss 8.0778e+01\n",
      "Epoch 41160, Training-Loss 1.9928e+00, Data-loss 7.8604e-02                  , pde-loss 6.1733e+03, initc-loss 1.2842e+04                    bc_loss 1.2629e+02\n",
      "Epoch 41170, Training-Loss 2.0803e+00, Data-loss 1.2272e-01                  , pde-loss 6.5460e+03, initc-loss 1.2913e+04                    bc_loss 1.1717e+02\n",
      "Epoch 41180, Training-Loss 1.9173e+00, Data-loss 1.4516e-01                  , pde-loss 4.7752e+03, initc-loss 1.2922e+04                    bc_loss 2.4320e+01\n",
      "Epoch 41190, Training-Loss 2.0081e+00, Data-loss 1.0747e-01                  , pde-loss 6.1145e+03, initc-loss 1.2819e+04                    bc_loss 7.2827e+01\n",
      "Epoch 41200, Training-Loss 2.1106e+00, Data-loss 2.2724e-01                  , pde-loss 5.8227e+03, initc-loss 1.2959e+04                    bc_loss 5.1712e+01\n",
      "Epoch 41210, Training-Loss 1.9715e+00, Data-loss 1.1451e-01                  , pde-loss 5.5998e+03, initc-loss 1.2923e+04                    bc_loss 4.6520e+01\n",
      "Epoch 41220, Training-Loss 1.9604e+00, Data-loss 7.5594e-02                  , pde-loss 5.9031e+03, initc-loss 1.2890e+04                    bc_loss 5.5061e+01\n",
      "Epoch 41230, Training-Loss 2.0682e+00, Data-loss 1.5819e-01                  , pde-loss 6.1912e+03, initc-loss 1.2890e+04                    bc_loss 1.9466e+01\n",
      "Epoch 41240, Training-Loss 2.0020e+00, Data-loss 1.1419e-01                  , pde-loss 5.9181e+03, initc-loss 1.2893e+04                    bc_loss 6.7584e+01\n",
      "Epoch 41250, Training-Loss 1.9137e+00, Data-loss 6.8047e-02                  , pde-loss 5.5813e+03, initc-loss 1.2807e+04                    bc_loss 6.8778e+01\n",
      "Epoch 41260, Training-Loss 1.9668e+00, Data-loss 8.4719e-02                  , pde-loss 5.5892e+03, initc-loss 1.2926e+04                    bc_loss 3.0535e+02\n",
      "Epoch 41270, Training-Loss 1.9985e+00, Data-loss 8.5017e-02                  , pde-loss 6.2119e+03, initc-loss 1.2898e+04                    bc_loss 2.5426e+01\n",
      "Epoch 41280, Training-Loss 1.9464e+00, Data-loss 6.6489e-02                  , pde-loss 5.8648e+03, initc-loss 1.2881e+04                    bc_loss 5.3965e+01\n",
      "Epoch 41290, Training-Loss 2.0904e+00, Data-loss 2.2198e-01                  , pde-loss 5.7466e+03, initc-loss 1.2868e+04                    bc_loss 6.9640e+01\n",
      "Epoch 41300, Training-Loss 1.9905e+00, Data-loss 2.0248e-01                  , pde-loss 5.0481e+03, initc-loss 1.2785e+04                    bc_loss 4.6492e+01\n",
      "Epoch 41310, Training-Loss 2.1022e+00, Data-loss 1.6910e-01                  , pde-loss 6.3388e+03, initc-loss 1.2812e+04                    bc_loss 1.8007e+02\n",
      "Epoch 41320, Training-Loss 2.0085e+00, Data-loss 8.9961e-02                  , pde-loss 6.2237e+03, initc-loss 1.2918e+04                    bc_loss 4.3742e+01\n",
      "Epoch 41330, Training-Loss 1.8534e+00, Data-loss 7.4995e-02                  , pde-loss 4.7666e+03, initc-loss 1.2947e+04                    bc_loss 7.0245e+01\n",
      "Epoch 41340, Training-Loss 2.0396e+00, Data-loss 9.4758e-02                  , pde-loss 6.5073e+03, initc-loss 1.2864e+04                    bc_loss 7.6804e+01\n",
      "Epoch 41350, Training-Loss 1.9348e+00, Data-loss 7.2680e-02                  , pde-loss 5.6425e+03, initc-loss 1.2942e+04                    bc_loss 3.6937e+01\n",
      "Epoch 41360, Training-Loss 1.9401e+00, Data-loss 1.1376e-01                  , pde-loss 5.3569e+03, initc-loss 1.2837e+04                    bc_loss 6.9623e+01\n",
      "Epoch 41370, Training-Loss 2.1698e+00, Data-loss 2.7178e-01                  , pde-loss 5.9785e+03, initc-loss 1.2922e+04                    bc_loss 7.9721e+01\n",
      "Epoch 41380, Training-Loss 1.8850e+00, Data-loss 7.1998e-02                  , pde-loss 5.0143e+03, initc-loss 1.2860e+04                    bc_loss 2.5574e+02\n",
      "Epoch 41390, Training-Loss 2.0621e+00, Data-loss 1.5293e-01                  , pde-loss 5.9506e+03, initc-loss 1.2863e+04                    bc_loss 2.7782e+02\n",
      "Epoch 41400, Training-Loss 1.9571e+00, Data-loss 7.1009e-02                  , pde-loss 5.9742e+03, initc-loss 1.2843e+04                    bc_loss 4.3352e+01\n",
      "Epoch 41410, Training-Loss 2.0357e+00, Data-loss 1.2831e-01                  , pde-loss 6.1060e+03, initc-loss 1.2901e+04                    bc_loss 6.6878e+01\n",
      "Epoch 41420, Training-Loss 1.9784e+00, Data-loss 1.3689e-01                  , pde-loss 5.4779e+03, initc-loss 1.2897e+04                    bc_loss 4.0139e+01\n",
      "Epoch 41430, Training-Loss 2.0018e+00, Data-loss 1.0420e-01                  , pde-loss 5.9875e+03, initc-loss 1.2876e+04                    bc_loss 1.1290e+02\n",
      "Epoch 41440, Training-Loss 1.9833e+00, Data-loss 7.4180e-02                  , pde-loss 5.9891e+03, initc-loss 1.2844e+04                    bc_loss 2.5796e+02\n",
      "Epoch 41450, Training-Loss 1.9519e+00, Data-loss 1.4151e-01                  , pde-loss 5.1856e+03, initc-loss 1.2899e+04                    bc_loss 1.8940e+01\n",
      "Epoch 41460, Training-Loss 2.0677e+00, Data-loss 1.2817e-01                  , pde-loss 6.5255e+03, initc-loss 1.2847e+04                    bc_loss 2.2741e+01\n",
      "Epoch 41470, Training-Loss 1.9866e+00, Data-loss 1.0586e-01                  , pde-loss 5.8938e+03, initc-loss 1.2879e+04                    bc_loss 3.4548e+01\n",
      "Epoch 41480, Training-Loss 1.9892e+00, Data-loss 8.5835e-02                  , pde-loss 6.0718e+03, initc-loss 1.2927e+04                    bc_loss 3.4554e+01\n",
      "Epoch 41490, Training-Loss 1.9297e+00, Data-loss 5.0803e-02                  , pde-loss 5.8392e+03, initc-loss 1.2909e+04                    bc_loss 4.1328e+01\n",
      "Epoch 41500, Training-Loss 2.1423e+00, Data-loss 1.7637e-01                  , pde-loss 6.5587e+03, initc-loss 1.2953e+04                    bc_loss 1.4703e+02\n",
      "Epoch 41510, Training-Loss 2.0597e+00, Data-loss 1.8964e-01                  , pde-loss 5.6703e+03, initc-loss 1.2924e+04                    bc_loss 1.0567e+02\n",
      "Epoch 41520, Training-Loss 1.9389e+00, Data-loss 6.0072e-02                  , pde-loss 5.7886e+03, initc-loss 1.2942e+04                    bc_loss 5.7190e+01\n",
      "Epoch 41530, Training-Loss 1.8526e+00, Data-loss 7.7830e-02                  , pde-loss 4.8526e+03, initc-loss 1.2880e+04                    bc_loss 1.4995e+01\n",
      "Epoch 41540, Training-Loss 1.9339e+00, Data-loss 9.3589e-02                  , pde-loss 5.4909e+03, initc-loss 1.2855e+04                    bc_loss 5.7761e+01\n",
      "Epoch 41550, Training-Loss 2.0183e+00, Data-loss 1.3351e-01                  , pde-loss 5.8875e+03, initc-loss 1.2881e+04                    bc_loss 7.9734e+01\n",
      "Epoch 41560, Training-Loss 2.0660e+00, Data-loss 1.8367e-01                  , pde-loss 5.8976e+03, initc-loss 1.2828e+04                    bc_loss 9.6768e+01\n",
      "Epoch 41570, Training-Loss 2.0669e+00, Data-loss 1.2686e-01                  , pde-loss 6.4940e+03, initc-loss 1.2882e+04                    bc_loss 2.4471e+01\n",
      "Epoch 41580, Training-Loss 2.0088e+00, Data-loss 8.7348e-02                  , pde-loss 6.3171e+03, initc-loss 1.2824e+04                    bc_loss 7.3080e+01\n",
      "Epoch 41590, Training-Loss 2.0385e+00, Data-loss 1.3194e-01                  , pde-loss 6.0950e+03, initc-loss 1.2934e+04                    bc_loss 3.6855e+01\n",
      "Epoch 41600, Training-Loss 2.0159e+00, Data-loss 1.5082e-01                  , pde-loss 5.7133e+03, initc-loss 1.2880e+04                    bc_loss 5.8164e+01\n",
      "Epoch 41610, Training-Loss 2.0228e+00, Data-loss 1.1875e-01                  , pde-loss 6.0736e+03, initc-loss 1.2947e+04                    bc_loss 1.9753e+01\n",
      "Epoch 41620, Training-Loss 1.9137e+00, Data-loss 1.0706e-01                  , pde-loss 5.0907e+03, initc-loss 1.2893e+04                    bc_loss 8.2328e+01\n",
      "Epoch 41630, Training-Loss 2.0315e+00, Data-loss 1.0643e-01                  , pde-loss 6.2583e+03, initc-loss 1.2873e+04                    bc_loss 1.1947e+02\n",
      "Epoch 41640, Training-Loss 1.9481e+00, Data-loss 7.2545e-02                  , pde-loss 5.7539e+03, initc-loss 1.2929e+04                    bc_loss 7.2761e+01\n",
      "Epoch 41650, Training-Loss 1.9344e+00, Data-loss 8.4122e-02                  , pde-loss 5.5114e+03, initc-loss 1.2880e+04                    bc_loss 1.1067e+02\n",
      "Epoch 41660, Training-Loss 2.0659e+00, Data-loss 1.6746e-01                  , pde-loss 6.0878e+03, initc-loss 1.2803e+04                    bc_loss 9.3176e+01\n",
      "Epoch 41670, Training-Loss 1.8855e+00, Data-loss 8.3108e-02                  , pde-loss 4.9352e+03, initc-loss 1.2942e+04                    bc_loss 1.4619e+02\n",
      "Epoch 41680, Training-Loss 1.9893e+00, Data-loss 7.1639e-02                  , pde-loss 6.0758e+03, initc-loss 1.2918e+04                    bc_loss 1.8259e+02\n",
      "Epoch 41690, Training-Loss 2.3252e+00, Data-loss 3.2313e-01                  , pde-loss 6.5902e+03, initc-loss 1.2836e+04                    bc_loss 5.9394e+02\n",
      "Epoch 41700, Training-Loss 2.0688e+00, Data-loss 1.1584e-01                  , pde-loss 6.5554e+03, initc-loss 1.2922e+04                    bc_loss 5.2285e+01\n",
      "Epoch 41710, Training-Loss 2.0009e+00, Data-loss 1.0824e-01                  , pde-loss 5.9639e+03, initc-loss 1.2852e+04                    bc_loss 1.1112e+02\n",
      "Epoch 41720, Training-Loss 2.1304e+00, Data-loss 2.8907e-01                  , pde-loss 5.2287e+03, initc-loss 1.2993e+04                    bc_loss 1.9221e+02\n",
      "Epoch 41730, Training-Loss 2.0747e+00, Data-loss 1.4338e-01                  , pde-loss 6.2044e+03, initc-loss 1.2906e+04                    bc_loss 2.0338e+02\n",
      "Epoch 41740, Training-Loss 2.0192e+00, Data-loss 1.6506e-01                  , pde-loss 5.5902e+03, initc-loss 1.2845e+04                    bc_loss 1.0547e+02\n",
      "Epoch 41750, Training-Loss 1.8413e+00, Data-loss 7.0521e-02                  , pde-loss 4.6759e+03, initc-loss 1.2896e+04                    bc_loss 1.3636e+02\n",
      "Epoch 41760, Training-Loss 1.9401e+00, Data-loss 1.0448e-01                  , pde-loss 5.4074e+03, initc-loss 1.2878e+04                    bc_loss 7.0757e+01\n",
      "Epoch 41770, Training-Loss 1.9676e+00, Data-loss 8.8960e-02                  , pde-loss 5.8802e+03, initc-loss 1.2878e+04                    bc_loss 2.8553e+01\n",
      "Epoch 41780, Training-Loss 1.9046e+00, Data-loss 8.1159e-02                  , pde-loss 5.3554e+03, initc-loss 1.2834e+04                    bc_loss 4.4742e+01\n",
      "Epoch 41790, Training-Loss 1.9518e+00, Data-loss 6.4394e-02                  , pde-loss 5.9666e+03, initc-loss 1.2865e+04                    bc_loss 4.2514e+01\n",
      "Epoch 41800, Training-Loss 2.0565e+00, Data-loss 1.7297e-01                  , pde-loss 5.7313e+03, initc-loss 1.2974e+04                    bc_loss 1.2994e+02\n",
      "Epoch 41810, Training-Loss 2.0014e+00, Data-loss 1.3327e-01                  , pde-loss 5.7665e+03, initc-loss 1.2849e+04                    bc_loss 6.5590e+01\n",
      "Epoch 41820, Training-Loss 1.9418e+00, Data-loss 7.8455e-02                  , pde-loss 5.7132e+03, initc-loss 1.2888e+04                    bc_loss 3.1854e+01\n",
      "Epoch 41830, Training-Loss 2.0739e+00, Data-loss 1.3113e-01                  , pde-loss 6.4485e+03, initc-loss 1.2951e+04                    bc_loss 2.8417e+01\n",
      "Epoch 41840, Training-Loss 1.9785e+00, Data-loss 9.5761e-02                  , pde-loss 5.8676e+03, initc-loss 1.2891e+04                    bc_loss 6.9111e+01\n",
      "Epoch 41850, Training-Loss 1.9712e+00, Data-loss 1.4769e-01                  , pde-loss 5.2517e+03, initc-loss 1.2929e+04                    bc_loss 5.4343e+01\n",
      "Epoch 41860, Training-Loss 1.9686e+00, Data-loss 1.3595e-01                  , pde-loss 5.3799e+03, initc-loss 1.2879e+04                    bc_loss 6.7032e+01\n",
      "Epoch 41870, Training-Loss 1.9631e+00, Data-loss 1.4847e-01                  , pde-loss 5.2926e+03, initc-loss 1.2799e+04                    bc_loss 5.4921e+01\n",
      "Epoch 41880, Training-Loss 1.9719e+00, Data-loss 7.0887e-02                  , pde-loss 5.8693e+03, initc-loss 1.2893e+04                    bc_loss 2.4715e+02\n",
      "Epoch 41890, Training-Loss 2.0027e+00, Data-loss 1.0842e-01                  , pde-loss 5.9965e+03, initc-loss 1.2883e+04                    bc_loss 6.2664e+01\n",
      "Epoch 41900, Training-Loss 2.0776e+00, Data-loss 1.5347e-01                  , pde-loss 6.2487e+03, initc-loss 1.2969e+04                    bc_loss 2.3972e+01\n",
      "Epoch 41910, Training-Loss 1.9769e+00, Data-loss 1.0183e-01                  , pde-loss 5.8328e+03, initc-loss 1.2900e+04                    bc_loss 1.7588e+01\n",
      "Epoch 41920, Training-Loss 2.0741e+00, Data-loss 9.4947e-02                  , pde-loss 6.7448e+03, initc-loss 1.2912e+04                    bc_loss 1.3435e+02\n",
      "Epoch 41930, Training-Loss 1.9875e+00, Data-loss 6.7229e-02                  , pde-loss 6.2429e+03, initc-loss 1.2917e+04                    bc_loss 4.3159e+01\n",
      "Epoch 41940, Training-Loss 1.9167e+00, Data-loss 1.2460e-01                  , pde-loss 4.9706e+03, initc-loss 1.2882e+04                    bc_loss 6.8824e+01\n",
      "Epoch 41950, Training-Loss 2.0694e+00, Data-loss 1.3521e-01                  , pde-loss 6.3425e+03, initc-loss 1.2971e+04                    bc_loss 2.8550e+01\n",
      "Epoch 41960, Training-Loss 2.0652e+00, Data-loss 1.2052e-01                  , pde-loss 6.5312e+03, initc-loss 1.2872e+04                    bc_loss 4.3957e+01\n",
      "Epoch 41970, Training-Loss 2.0131e+00, Data-loss 1.0471e-01                  , pde-loss 6.1338e+03, initc-loss 1.2915e+04                    bc_loss 3.4887e+01\n",
      "Epoch 41980, Training-Loss 2.0810e+00, Data-loss 1.4898e-01                  , pde-loss 6.2771e+03, initc-loss 1.2935e+04                    bc_loss 1.0748e+02\n",
      "Epoch 41990, Training-Loss 2.0215e+00, Data-loss 1.0544e-01                  , pde-loss 6.1744e+03, initc-loss 1.2913e+04                    bc_loss 7.3508e+01\n",
      "Epoch 42000, Training-Loss 1.9786e+00, Data-loss 8.6386e-02                  , pde-loss 5.9837e+03, initc-loss 1.2897e+04                    bc_loss 4.1391e+01\n",
      "Epoch 42010, Training-Loss 1.9078e+00, Data-loss 9.7069e-02                  , pde-loss 5.1470e+03, initc-loss 1.2943e+04                    bc_loss 1.7234e+01\n",
      "Epoch 42020, Training-Loss 1.9295e+00, Data-loss 1.0988e-01                  , pde-loss 5.2475e+03, initc-loss 1.2919e+04                    bc_loss 3.0310e+01\n",
      "Epoch 42030, Training-Loss 2.0291e+00, Data-loss 1.4207e-01                  , pde-loss 5.7554e+03, initc-loss 1.2843e+04                    bc_loss 2.7274e+02\n",
      "Epoch 42040, Training-Loss 1.9030e+00, Data-loss 1.0892e-01                  , pde-loss 5.0244e+03, initc-loss 1.2859e+04                    bc_loss 5.7665e+01\n",
      "Epoch 42050, Training-Loss 1.9675e+00, Data-loss 1.2362e-01                  , pde-loss 5.5616e+03, initc-loss 1.2854e+04                    bc_loss 2.3488e+01\n",
      "Epoch 42060, Training-Loss 1.9880e+00, Data-loss 9.3584e-02                  , pde-loss 5.8702e+03, initc-loss 1.2904e+04                    bc_loss 1.7080e+02\n",
      "Epoch 42070, Training-Loss 1.9426e+00, Data-loss 8.3255e-02                  , pde-loss 5.6357e+03, initc-loss 1.2891e+04                    bc_loss 6.7178e+01\n",
      "Epoch 42080, Training-Loss 1.9997e+00, Data-loss 1.0935e-01                  , pde-loss 5.7715e+03, initc-loss 1.2948e+04                    bc_loss 1.8404e+02\n",
      "Epoch 42090, Training-Loss 2.0161e+00, Data-loss 9.0036e-02                  , pde-loss 6.3225e+03, initc-loss 1.2882e+04                    bc_loss 5.6901e+01\n",
      "Epoch 42100, Training-Loss 2.0400e+00, Data-loss 1.6014e-01                  , pde-loss 5.7586e+03, initc-loss 1.2956e+04                    bc_loss 8.3602e+01\n",
      "Epoch 42110, Training-Loss 2.1939e+00, Data-loss 1.7351e-01                  , pde-loss 7.1304e+03, initc-loss 1.2930e+04                    bc_loss 1.4321e+02\n",
      "Epoch 42120, Training-Loss 1.9272e+00, Data-loss 1.1508e-01                  , pde-loss 5.2256e+03, initc-loss 1.2867e+04                    bc_loss 2.8003e+01\n",
      "Epoch 42130, Training-Loss 1.9429e+00, Data-loss 8.0302e-02                  , pde-loss 5.7314e+03, initc-loss 1.2873e+04                    bc_loss 2.1027e+01\n",
      "Epoch 42140, Training-Loss 2.0407e+00, Data-loss 1.4563e-01                  , pde-loss 5.9814e+03, initc-loss 1.2889e+04                    bc_loss 8.0655e+01\n",
      "Epoch 42150, Training-Loss 2.0716e+00, Data-loss 1.6921e-01                  , pde-loss 6.0445e+03, initc-loss 1.2897e+04                    bc_loss 8.2336e+01\n",
      "Epoch 42160, Training-Loss 2.0114e+00, Data-loss 1.2088e-01                  , pde-loss 5.6647e+03, initc-loss 1.2913e+04                    bc_loss 3.2795e+02\n",
      "Epoch 42170, Training-Loss 2.2435e+00, Data-loss 2.5778e-01                  , pde-loss 6.6189e+03, initc-loss 1.2963e+04                    bc_loss 2.7551e+02\n",
      "Epoch 42180, Training-Loss 1.9177e+00, Data-loss 5.7317e-02                  , pde-loss 5.5154e+03, initc-loss 1.2957e+04                    bc_loss 1.3172e+02\n",
      "Epoch 42190, Training-Loss 2.1841e+00, Data-loss 2.1984e-01                  , pde-loss 6.6585e+03, initc-loss 1.2884e+04                    bc_loss 1.0034e+02\n",
      "Epoch 42200, Training-Loss 1.9530e+00, Data-loss 8.1262e-02                  , pde-loss 5.7528e+03, initc-loss 1.2838e+04                    bc_loss 1.2665e+02\n",
      "Epoch 42210, Training-Loss 1.9711e+00, Data-loss 8.2345e-02                  , pde-loss 5.8638e+03, initc-loss 1.2991e+04                    bc_loss 3.3589e+01\n",
      "Epoch 42220, Training-Loss 2.0498e+00, Data-loss 1.4309e-01                  , pde-loss 6.1344e+03, initc-loss 1.2903e+04                    bc_loss 2.9640e+01\n",
      "Epoch 42230, Training-Loss 1.9115e+00, Data-loss 7.0321e-02                  , pde-loss 5.5606e+03, initc-loss 1.2819e+04                    bc_loss 3.1749e+01\n",
      "Epoch 42240, Training-Loss 1.9447e+00, Data-loss 6.6600e-02                  , pde-loss 5.8257e+03, initc-loss 1.2939e+04                    bc_loss 1.6407e+01\n",
      "Epoch 42250, Training-Loss 1.9469e+00, Data-loss 7.7349e-02                  , pde-loss 5.6950e+03, initc-loss 1.2861e+04                    bc_loss 1.3988e+02\n",
      "Epoch 42260, Training-Loss 1.9966e+00, Data-loss 1.4711e-01                  , pde-loss 5.5675e+03, initc-loss 1.2886e+04                    bc_loss 4.1929e+01\n",
      "Epoch 42270, Training-Loss 2.0212e+00, Data-loss 1.2725e-01                  , pde-loss 6.0827e+03, initc-loss 1.2795e+04                    bc_loss 6.1446e+01\n",
      "Epoch 42280, Training-Loss 1.9918e+00, Data-loss 1.1827e-01                  , pde-loss 5.5753e+03, initc-loss 1.2953e+04                    bc_loss 2.0750e+02\n",
      "Epoch 42290, Training-Loss 2.0128e+00, Data-loss 9.9196e-02                  , pde-loss 6.1593e+03, initc-loss 1.2901e+04                    bc_loss 7.5824e+01\n",
      "Epoch 42300, Training-Loss 1.9903e+00, Data-loss 1.1436e-01                  , pde-loss 5.7979e+03, initc-loss 1.2854e+04                    bc_loss 1.0707e+02\n",
      "Epoch 42310, Training-Loss 2.0585e+00, Data-loss 1.4831e-01                  , pde-loss 6.1499e+03, initc-loss 1.2861e+04                    bc_loss 9.1532e+01\n",
      "Epoch 42320, Training-Loss 1.8398e+00, Data-loss 7.7082e-02                  , pde-loss 4.7052e+03, initc-loss 1.2898e+04                    bc_loss 2.3974e+01\n",
      "Epoch 42330, Training-Loss 2.0532e+00, Data-loss 1.0553e-01                  , pde-loss 6.5535e+03, initc-loss 1.2859e+04                    bc_loss 6.3576e+01\n",
      "Epoch 42340, Training-Loss 1.9992e+00, Data-loss 1.2751e-01                  , pde-loss 5.7460e+03, initc-loss 1.2908e+04                    bc_loss 6.2604e+01\n",
      "Epoch 42350, Training-Loss 1.9234e+00, Data-loss 1.0967e-01                  , pde-loss 5.2335e+03, initc-loss 1.2888e+04                    bc_loss 1.5886e+01\n",
      "Epoch 42360, Training-Loss 1.9198e+00, Data-loss 6.7294e-02                  , pde-loss 5.5333e+03, initc-loss 1.2951e+04                    bc_loss 4.0555e+01\n",
      "Epoch 42370, Training-Loss 1.9442e+00, Data-loss 8.3922e-02                  , pde-loss 5.5829e+03, initc-loss 1.2864e+04                    bc_loss 1.5595e+02\n",
      "Epoch 42380, Training-Loss 1.9140e+00, Data-loss 1.1313e-01                  , pde-loss 5.0981e+03, initc-loss 1.2840e+04                    bc_loss 7.0014e+01\n",
      "Epoch 42390, Training-Loss 1.9270e+00, Data-loss 1.3880e-01                  , pde-loss 5.0174e+03, initc-loss 1.2802e+04                    bc_loss 6.2644e+01\n",
      "Epoch 42400, Training-Loss 1.9026e+00, Data-loss 6.4634e-02                  , pde-loss 5.4400e+03, initc-loss 1.2877e+04                    bc_loss 6.2279e+01\n",
      "Epoch 42410, Training-Loss 2.0308e+00, Data-loss 1.3733e-01                  , pde-loss 6.0348e+03, initc-loss 1.2869e+04                    bc_loss 3.0422e+01\n",
      "Epoch 42420, Training-Loss 1.9850e+00, Data-loss 7.4260e-02                  , pde-loss 6.2058e+03, initc-loss 1.2888e+04                    bc_loss 1.3026e+01\n",
      "Epoch 42430, Training-Loss 1.9560e+00, Data-loss 1.2025e-01                  , pde-loss 5.2828e+03, initc-loss 1.2903e+04                    bc_loss 1.7219e+02\n",
      "Epoch 42440, Training-Loss 1.9674e+00, Data-loss 1.1303e-01                  , pde-loss 5.5990e+03, initc-loss 1.2913e+04                    bc_loss 3.1748e+01\n",
      "Epoch 42450, Training-Loss 1.9666e+00, Data-loss 8.4082e-02                  , pde-loss 5.8568e+03, initc-loss 1.2904e+04                    bc_loss 6.4200e+01\n",
      "Epoch 42460, Training-Loss 1.9978e+00, Data-loss 9.0739e-02                  , pde-loss 6.1042e+03, initc-loss 1.2929e+04                    bc_loss 3.7688e+01\n",
      "Epoch 42470, Training-Loss 2.2349e+00, Data-loss 4.1879e-01                  , pde-loss 5.0138e+03, initc-loss 1.2840e+04                    bc_loss 3.0747e+02\n",
      "Epoch 42480, Training-Loss 2.0473e+00, Data-loss 1.8845e-01                  , pde-loss 5.6035e+03, initc-loss 1.2845e+04                    bc_loss 1.3996e+02\n",
      "Epoch 42490, Training-Loss 1.9788e+00, Data-loss 1.0695e-01                  , pde-loss 5.6839e+03, initc-loss 1.2986e+04                    bc_loss 4.8784e+01\n",
      "Epoch 42500, Training-Loss 1.9958e+00, Data-loss 1.3298e-01                  , pde-loss 5.7003e+03, initc-loss 1.2862e+04                    bc_loss 6.6747e+01\n",
      "Epoch 42510, Training-Loss 2.0788e+00, Data-loss 2.8314e-01                  , pde-loss 4.8441e+03, initc-loss 1.2821e+04                    bc_loss 2.9063e+02\n",
      "Epoch 42520, Training-Loss 2.0703e+00, Data-loss 8.9481e-02                  , pde-loss 6.6770e+03, initc-loss 1.2968e+04                    bc_loss 1.6275e+02\n",
      "Epoch 42530, Training-Loss 2.0443e+00, Data-loss 1.4082e-01                  , pde-loss 6.1402e+03, initc-loss 1.2842e+04                    bc_loss 5.2854e+01\n",
      "Epoch 42540, Training-Loss 2.0000e+00, Data-loss 8.7335e-02                  , pde-loss 6.1696e+03, initc-loss 1.2893e+04                    bc_loss 6.4484e+01\n",
      "Epoch 42550, Training-Loss 1.8669e+00, Data-loss 9.1927e-02                  , pde-loss 4.8861e+03, initc-loss 1.2823e+04                    bc_loss 4.0332e+01\n",
      "Epoch 42560, Training-Loss 1.9229e+00, Data-loss 7.8208e-02                  , pde-loss 5.5898e+03, initc-loss 1.2825e+04                    bc_loss 3.2017e+01\n",
      "Epoch 42570, Training-Loss 2.0320e+00, Data-loss 1.2547e-01                  , pde-loss 6.0624e+03, initc-loss 1.2988e+04                    bc_loss 1.5307e+01\n",
      "Epoch 42580, Training-Loss 1.8818e+00, Data-loss 6.4964e-02                  , pde-loss 5.2126e+03, initc-loss 1.2838e+04                    bc_loss 1.1810e+02\n",
      "Epoch 42590, Training-Loss 1.9545e+00, Data-loss 1.1599e-01                  , pde-loss 5.4690e+03, initc-loss 1.2865e+04                    bc_loss 5.1379e+01\n",
      "Epoch 42600, Training-Loss 1.9048e+00, Data-loss 8.6088e-02                  , pde-loss 5.3217e+03, initc-loss 1.2837e+04                    bc_loss 2.8388e+01\n",
      "Epoch 42610, Training-Loss 1.8814e+00, Data-loss 6.6229e-02                  , pde-loss 5.1452e+03, initc-loss 1.2924e+04                    bc_loss 8.2141e+01\n",
      "Epoch 42620, Training-Loss 1.9209e+00, Data-loss 6.5934e-02                  , pde-loss 5.6386e+03, initc-loss 1.2868e+04                    bc_loss 4.2246e+01\n",
      "Epoch 42630, Training-Loss 1.9955e+00, Data-loss 1.0747e-01                  , pde-loss 5.9065e+03, initc-loss 1.2945e+04                    bc_loss 2.9080e+01\n",
      "Epoch 42640, Training-Loss 1.8818e+00, Data-loss 5.9788e-02                  , pde-loss 5.2970e+03, initc-loss 1.2875e+04                    bc_loss 4.8042e+01\n",
      "Epoch 42650, Training-Loss 1.9448e+00, Data-loss 1.5845e-01                  , pde-loss 4.8668e+03, initc-loss 1.2972e+04                    bc_loss 2.4940e+01\n",
      "Epoch 42660, Training-Loss 2.0308e+00, Data-loss 8.3505e-02                  , pde-loss 6.4738e+03, initc-loss 1.2883e+04                    bc_loss 1.1595e+02\n",
      "Epoch 42670, Training-Loss 2.0501e+00, Data-loss 1.7174e-01                  , pde-loss 5.6610e+03, initc-loss 1.2889e+04                    bc_loss 2.3386e+02\n",
      "Epoch 42680, Training-Loss 2.0183e+00, Data-loss 1.3011e-01                  , pde-loss 5.8199e+03, initc-loss 1.3012e+04                    bc_loss 4.9831e+01\n",
      "Epoch 42690, Training-Loss 2.2115e+00, Data-loss 3.0109e-01                  , pde-loss 6.0266e+03, initc-loss 1.2889e+04                    bc_loss 1.8942e+02\n",
      "Epoch 42700, Training-Loss 2.0999e+00, Data-loss 1.4448e-01                  , pde-loss 6.4439e+03, initc-loss 1.2865e+04                    bc_loss 2.4512e+02\n",
      "Epoch 42710, Training-Loss 1.9703e+00, Data-loss 1.0783e-01                  , pde-loss 5.6040e+03, initc-loss 1.2940e+04                    bc_loss 8.0330e+01\n",
      "Epoch 42720, Training-Loss 1.9940e+00, Data-loss 1.7967e-01                  , pde-loss 5.2524e+03, initc-loss 1.2852e+04                    bc_loss 3.8424e+01\n",
      "Epoch 42730, Training-Loss 2.1123e+00, Data-loss 1.2684e-01                  , pde-loss 6.8239e+03, initc-loss 1.2823e+04                    bc_loss 2.0748e+02\n",
      "Epoch 42740, Training-Loss 2.1131e+00, Data-loss 1.9818e-01                  , pde-loss 6.1077e+03, initc-loss 1.2919e+04                    bc_loss 1.2276e+02\n",
      "Epoch 42750, Training-Loss 2.0672e+00, Data-loss 1.4784e-01                  , pde-loss 6.2172e+03, initc-loss 1.2950e+04                    bc_loss 2.6195e+01\n",
      "Epoch 42760, Training-Loss 2.0233e+00, Data-loss 1.3849e-01                  , pde-loss 5.7883e+03, initc-loss 1.2876e+04                    bc_loss 1.8310e+02\n",
      "Epoch 42770, Training-Loss 2.0694e+00, Data-loss 1.3239e-01                  , pde-loss 6.3527e+03, initc-loss 1.2905e+04                    bc_loss 1.1297e+02\n",
      "Epoch 42780, Training-Loss 1.9181e+00, Data-loss 7.0682e-02                  , pde-loss 5.5381e+03, initc-loss 1.2890e+04                    bc_loss 4.5430e+01\n",
      "Epoch 42790, Training-Loss 1.9193e+00, Data-loss 6.9405e-02                  , pde-loss 5.6304e+03, initc-loss 1.2858e+04                    bc_loss 1.1190e+01\n",
      "Epoch 42800, Training-Loss 2.2149e+00, Data-loss 3.0195e-01                  , pde-loss 6.1549e+03, initc-loss 1.2849e+04                    bc_loss 1.2582e+02\n",
      "Epoch 42810, Training-Loss 2.1779e+00, Data-loss 3.4055e-01                  , pde-loss 5.4803e+03, initc-loss 1.2829e+04                    bc_loss 6.4866e+01\n",
      "Epoch 42820, Training-Loss 1.8888e+00, Data-loss 4.6253e-02                  , pde-loss 5.4282e+03, initc-loss 1.2882e+04                    bc_loss 1.1582e+02\n",
      "Epoch 42830, Training-Loss 2.1800e+00, Data-loss 1.7200e-01                  , pde-loss 7.0284e+03, initc-loss 1.2942e+04                    bc_loss 1.0951e+02\n",
      "Epoch 42840, Training-Loss 2.0541e+00, Data-loss 9.5015e-02                  , pde-loss 6.6506e+03, initc-loss 1.2883e+04                    bc_loss 5.7314e+01\n",
      "Epoch 42850, Training-Loss 2.0566e+00, Data-loss 1.6684e-01                  , pde-loss 6.0232e+03, initc-loss 1.2838e+04                    bc_loss 3.6487e+01\n",
      "Epoch 42860, Training-Loss 1.9662e+00, Data-loss 1.2989e-01                  , pde-loss 5.3848e+03, initc-loss 1.2949e+04                    bc_loss 2.8619e+01\n",
      "Epoch 42870, Training-Loss 1.9595e+00, Data-loss 7.6202e-02                  , pde-loss 5.8958e+03, initc-loss 1.2909e+04                    bc_loss 2.8263e+01\n",
      "Epoch 42880, Training-Loss 1.9106e+00, Data-loss 8.8182e-02                  , pde-loss 5.3206e+03, initc-loss 1.2878e+04                    bc_loss 2.5525e+01\n",
      "Epoch 42890, Training-Loss 1.9150e+00, Data-loss 7.0545e-02                  , pde-loss 5.5693e+03, initc-loss 1.2835e+04                    bc_loss 3.9862e+01\n",
      "Epoch 42900, Training-Loss 1.8813e+00, Data-loss 4.5054e-02                  , pde-loss 5.3628e+03, initc-loss 1.2949e+04                    bc_loss 5.0964e+01\n",
      "Epoch 42910, Training-Loss 1.9398e+00, Data-loss 7.0300e-02                  , pde-loss 5.7181e+03, initc-loss 1.2842e+04                    bc_loss 1.3510e+02\n",
      "Epoch 42920, Training-Loss 1.9098e+00, Data-loss 6.2846e-02                  , pde-loss 5.3722e+03, initc-loss 1.2951e+04                    bc_loss 1.4604e+02\n",
      "Epoch 42930, Training-Loss 2.0015e+00, Data-loss 1.1806e-01                  , pde-loss 5.8334e+03, initc-loss 1.2954e+04                    bc_loss 4.6923e+01\n",
      "Epoch 42940, Training-Loss 1.9076e+00, Data-loss 8.2464e-02                  , pde-loss 5.3343e+03, initc-loss 1.2878e+04                    bc_loss 3.8711e+01\n",
      "Epoch 42950, Training-Loss 2.0879e+00, Data-loss 1.2545e-01                  , pde-loss 6.6877e+03, initc-loss 1.2904e+04                    bc_loss 3.2802e+01\n",
      "Epoch 42960, Training-Loss 2.0023e+00, Data-loss 1.2997e-01                  , pde-loss 5.7458e+03, initc-loss 1.2924e+04                    bc_loss 5.3328e+01\n",
      "Epoch 42970, Training-Loss 2.0161e+00, Data-loss 7.5494e-02                  , pde-loss 6.2535e+03, initc-loss 1.2916e+04                    bc_loss 2.3693e+02\n",
      "Epoch 42980, Training-Loss 2.0822e+00, Data-loss 9.6207e-02                  , pde-loss 6.8815e+03, initc-loss 1.2846e+04                    bc_loss 1.3264e+02\n",
      "Epoch 42990, Training-Loss 1.9691e+00, Data-loss 8.9687e-02                  , pde-loss 5.8516e+03, initc-loss 1.2881e+04                    bc_loss 6.1308e+01\n",
      "Epoch 43000, Training-Loss 2.1031e+00, Data-loss 2.1867e-01                  , pde-loss 5.8951e+03, initc-loss 1.2897e+04                    bc_loss 5.2471e+01\n",
      "Epoch 43010, Training-Loss 2.0908e+00, Data-loss 2.0225e-01                  , pde-loss 5.8305e+03, initc-loss 1.2983e+04                    bc_loss 7.1939e+01\n",
      "Epoch 43020, Training-Loss 2.0881e+00, Data-loss 1.4288e-01                  , pde-loss 6.5162e+03, initc-loss 1.2816e+04                    bc_loss 1.1964e+02\n",
      "Epoch 43030, Training-Loss 1.9674e+00, Data-loss 6.8543e-02                  , pde-loss 5.9580e+03, initc-loss 1.2913e+04                    bc_loss 1.1725e+02\n",
      "Epoch 43040, Training-Loss 1.9466e+00, Data-loss 9.3008e-02                  , pde-loss 5.5378e+03, initc-loss 1.2906e+04                    bc_loss 9.2305e+01\n",
      "Epoch 43050, Training-Loss 1.8937e+00, Data-loss 6.7378e-02                  , pde-loss 5.2877e+03, initc-loss 1.2924e+04                    bc_loss 5.2153e+01\n",
      "Epoch 43060, Training-Loss 2.0023e+00, Data-loss 8.3577e-02                  , pde-loss 6.2517e+03, initc-loss 1.2908e+04                    bc_loss 2.8392e+01\n",
      "Epoch 43070, Training-Loss 1.9776e+00, Data-loss 8.6265e-02                  , pde-loss 5.9362e+03, initc-loss 1.2906e+04                    bc_loss 7.1435e+01\n",
      "Epoch 43080, Training-Loss 1.9258e+00, Data-loss 6.0617e-02                  , pde-loss 5.7465e+03, initc-loss 1.2885e+04                    bc_loss 2.0126e+01\n",
      "Epoch 43090, Training-Loss 2.0316e+00, Data-loss 1.5750e-01                  , pde-loss 5.7773e+03, initc-loss 1.2840e+04                    bc_loss 1.2380e+02\n",
      "Epoch 43100, Training-Loss 2.1684e+00, Data-loss 2.6479e-01                  , pde-loss 5.9422e+03, initc-loss 1.2887e+04                    bc_loss 2.0668e+02\n",
      "Epoch 43110, Training-Loss 2.0445e+00, Data-loss 1.2942e-01                  , pde-loss 6.0024e+03, initc-loss 1.2927e+04                    bc_loss 2.2215e+02\n",
      "Epoch 43120, Training-Loss 2.1014e+00, Data-loss 1.5383e-01                  , pde-loss 6.4158e+03, initc-loss 1.2983e+04                    bc_loss 7.7546e+01\n",
      "Epoch 43130, Training-Loss 2.0943e+00, Data-loss 2.1768e-01                  , pde-loss 5.7168e+03, initc-loss 1.2801e+04                    bc_loss 2.4832e+02\n",
      "Epoch 43140, Training-Loss 1.9437e+00, Data-loss 8.6346e-02                  , pde-loss 5.6726e+03, initc-loss 1.2837e+04                    bc_loss 6.3692e+01\n",
      "Epoch 43150, Training-Loss 2.1776e+00, Data-loss 2.4466e-01                  , pde-loss 6.2689e+03, initc-loss 1.2896e+04                    bc_loss 1.6437e+02\n",
      "Epoch 43160, Training-Loss 1.9730e+00, Data-loss 1.4165e-01                  , pde-loss 5.3299e+03, initc-loss 1.2947e+04                    bc_loss 3.6883e+01\n",
      "Epoch 43170, Training-Loss 2.0082e+00, Data-loss 1.1368e-01                  , pde-loss 5.8219e+03, initc-loss 1.2908e+04                    bc_loss 2.1562e+02\n",
      "Epoch 43180, Training-Loss 2.0983e+00, Data-loss 2.6513e-01                  , pde-loss 5.2561e+03, initc-loss 1.2799e+04                    bc_loss 2.7661e+02\n",
      "Epoch 43190, Training-Loss 1.8975e+00, Data-loss 7.2848e-02                  , pde-loss 5.3107e+03, initc-loss 1.2867e+04                    bc_loss 6.9016e+01\n",
      "Epoch 43200, Training-Loss 1.8891e+00, Data-loss 4.1726e-02                  , pde-loss 5.5833e+03, initc-loss 1.2850e+04                    bc_loss 4.0942e+01\n",
      "Epoch 43210, Training-Loss 2.0251e+00, Data-loss 9.4267e-02                  , pde-loss 6.3750e+03, initc-loss 1.2870e+04                    bc_loss 6.2625e+01\n",
      "Epoch 43220, Training-Loss 1.9787e+00, Data-loss 1.2304e-01                  , pde-loss 5.6442e+03, initc-loss 1.2882e+04                    bc_loss 3.0838e+01\n",
      "Epoch 43230, Training-Loss 2.0575e+00, Data-loss 1.0588e-01                  , pde-loss 6.5958e+03, initc-loss 1.2846e+04                    bc_loss 7.5007e+01\n",
      "Epoch 43240, Training-Loss 1.9369e+00, Data-loss 4.2447e-02                  , pde-loss 6.0116e+03, initc-loss 1.2880e+04                    bc_loss 5.2434e+01\n",
      "Epoch 43250, Training-Loss 1.9067e+00, Data-loss 1.0294e-01                  , pde-loss 5.0278e+03, initc-loss 1.2920e+04                    bc_loss 9.0809e+01\n",
      "Epoch 43260, Training-Loss 1.8826e+00, Data-loss 5.9966e-02                  , pde-loss 5.2304e+03, initc-loss 1.2894e+04                    bc_loss 1.0282e+02\n",
      "Epoch 43270, Training-Loss 2.0907e+00, Data-loss 1.0768e-01                  , pde-loss 6.8579e+03, initc-loss 1.2880e+04                    bc_loss 9.1938e+01\n",
      "Epoch 43280, Training-Loss 2.0028e+00, Data-loss 9.0436e-02                  , pde-loss 6.1756e+03, initc-loss 1.2921e+04                    bc_loss 2.7231e+01\n",
      "Epoch 43290, Training-Loss 2.0850e+00, Data-loss 1.7363e-01                  , pde-loss 6.0545e+03, initc-loss 1.2966e+04                    bc_loss 9.2972e+01\n",
      "Epoch 43300, Training-Loss 1.9605e+00, Data-loss 6.7271e-02                  , pde-loss 5.8617e+03, initc-loss 1.2890e+04                    bc_loss 1.8088e+02\n",
      "Epoch 43310, Training-Loss 2.0914e+00, Data-loss 1.1555e-01                  , pde-loss 6.7644e+03, initc-loss 1.2861e+04                    bc_loss 1.3332e+02\n",
      "Epoch 43320, Training-Loss 1.9773e+00, Data-loss 7.6686e-02                  , pde-loss 6.0266e+03, initc-loss 1.2914e+04                    bc_loss 6.5794e+01\n",
      "Epoch 43330, Training-Loss 2.0680e+00, Data-loss 1.5209e-01                  , pde-loss 5.9498e+03, initc-loss 1.2986e+04                    bc_loss 2.2322e+02\n",
      "Epoch 43340, Training-Loss 1.8540e+00, Data-loss 5.2178e-02                  , pde-loss 5.1515e+03, initc-loss 1.2820e+04                    bc_loss 4.6334e+01\n",
      "Epoch 43350, Training-Loss 1.9491e+00, Data-loss 6.2831e-02                  , pde-loss 5.8736e+03, initc-loss 1.2922e+04                    bc_loss 6.7315e+01\n",
      "Epoch 43360, Training-Loss 2.0664e+00, Data-loss 2.0272e-01                  , pde-loss 5.6219e+03, initc-loss 1.2926e+04                    bc_loss 8.8999e+01\n",
      "Epoch 43370, Training-Loss 1.9692e+00, Data-loss 8.1046e-02                  , pde-loss 5.8543e+03, initc-loss 1.2882e+04                    bc_loss 1.4502e+02\n",
      "Epoch 43380, Training-Loss 2.0089e+00, Data-loss 1.4157e-01                  , pde-loss 5.6949e+03, initc-loss 1.2826e+04                    bc_loss 1.5264e+02\n",
      "Epoch 43390, Training-Loss 2.0325e+00, Data-loss 1.1123e-01                  , pde-loss 6.2157e+03, initc-loss 1.2951e+04                    bc_loss 4.5855e+01\n",
      "Epoch 43400, Training-Loss 1.9402e+00, Data-loss 7.4200e-02                  , pde-loss 5.7422e+03, initc-loss 1.2902e+04                    bc_loss 1.6181e+01\n",
      "Epoch 43410, Training-Loss 2.0275e+00, Data-loss 1.1481e-01                  , pde-loss 6.2597e+03, initc-loss 1.2842e+04                    bc_loss 2.5801e+01\n",
      "Epoch 43420, Training-Loss 2.0806e+00, Data-loss 9.8795e-02                  , pde-loss 6.6883e+03, initc-loss 1.2902e+04                    bc_loss 2.2710e+02\n",
      "Epoch 43430, Training-Loss 1.9814e+00, Data-loss 1.1606e-01                  , pde-loss 5.6007e+03, initc-loss 1.2988e+04                    bc_loss 6.4639e+01\n",
      "Epoch 43440, Training-Loss 2.1729e+00, Data-loss 2.4864e-01                  , pde-loss 6.2935e+03, initc-loss 1.2836e+04                    bc_loss 1.1269e+02\n",
      "Epoch 43450, Training-Loss 1.9943e+00, Data-loss 1.0734e-01                  , pde-loss 5.9379e+03, initc-loss 1.2912e+04                    bc_loss 1.9795e+01\n",
      "Epoch 43460, Training-Loss 1.9684e+00, Data-loss 7.3936e-02                  , pde-loss 6.0421e+03, initc-loss 1.2870e+04                    bc_loss 3.3215e+01\n",
      "Epoch 43470, Training-Loss 1.9542e+00, Data-loss 1.2540e-01                  , pde-loss 5.4016e+03, initc-loss 1.2851e+04                    bc_loss 3.4640e+01\n",
      "Epoch 43480, Training-Loss 1.9407e+00, Data-loss 6.8102e-02                  , pde-loss 5.7791e+03, initc-loss 1.2923e+04                    bc_loss 2.4572e+01\n",
      "Epoch 43490, Training-Loss 2.1200e+00, Data-loss 1.8447e-01                  , pde-loss 6.3428e+03, initc-loss 1.2801e+04                    bc_loss 2.1210e+02\n",
      "Epoch 43500, Training-Loss 1.8656e+00, Data-loss 5.8721e-02                  , pde-loss 5.2010e+03, initc-loss 1.2853e+04                    bc_loss 1.4894e+01\n",
      "Epoch 43510, Training-Loss 2.0180e+00, Data-loss 9.4013e-02                  , pde-loss 6.3102e+03, initc-loss 1.2851e+04                    bc_loss 7.9304e+01\n",
      "Epoch 43520, Training-Loss 1.9394e+00, Data-loss 9.9821e-02                  , pde-loss 5.4267e+03, initc-loss 1.2950e+04                    bc_loss 1.9198e+01\n",
      "Epoch 43530, Training-Loss 1.9953e+00, Data-loss 1.0038e-01                  , pde-loss 5.9020e+03, initc-loss 1.2957e+04                    bc_loss 9.0595e+01\n",
      "Epoch 43540, Training-Loss 1.9634e+00, Data-loss 9.0929e-02                  , pde-loss 5.7491e+03, initc-loss 1.2891e+04                    bc_loss 8.5219e+01\n",
      "Epoch 43550, Training-Loss 2.0460e+00, Data-loss 1.5082e-01                  , pde-loss 5.7026e+03, initc-loss 1.2853e+04                    bc_loss 3.9534e+02\n",
      "Epoch 43560, Training-Loss 1.8707e+00, Data-loss 5.8196e-02                  , pde-loss 5.1178e+03, initc-loss 1.2838e+04                    bc_loss 1.6944e+02\n",
      "Epoch 43570, Training-Loss 1.9051e+00, Data-loss 8.7682e-02                  , pde-loss 5.1797e+03, initc-loss 1.2922e+04                    bc_loss 7.2584e+01\n",
      "Epoch 43580, Training-Loss 1.9261e+00, Data-loss 1.1758e-01                  , pde-loss 5.0210e+03, initc-loss 1.2870e+04                    bc_loss 1.9475e+02\n",
      "Epoch 43590, Training-Loss 1.9414e+00, Data-loss 8.6259e-02                  , pde-loss 5.5105e+03, initc-loss 1.2920e+04                    bc_loss 1.2073e+02\n",
      "Epoch 43600, Training-Loss 2.0950e+00, Data-loss 1.7797e-01                  , pde-loss 6.1318e+03, initc-loss 1.2930e+04                    bc_loss 1.0787e+02\n",
      "Epoch 43610, Training-Loss 2.0716e+00, Data-loss 1.5327e-01                  , pde-loss 6.0984e+03, initc-loss 1.3002e+04                    bc_loss 8.2428e+01\n",
      "Epoch 43620, Training-Loss 2.0760e+00, Data-loss 1.8203e-01                  , pde-loss 5.8164e+03, initc-loss 1.2873e+04                    bc_loss 2.5080e+02\n",
      "Epoch 43630, Training-Loss 1.9992e+00, Data-loss 1.1892e-01                  , pde-loss 5.8912e+03, initc-loss 1.2846e+04                    bc_loss 6.5235e+01\n",
      "Epoch 43640, Training-Loss 2.0662e+00, Data-loss 1.5586e-01                  , pde-loss 6.2315e+03, initc-loss 1.2822e+04                    bc_loss 4.9087e+01\n",
      "Epoch 43650, Training-Loss 1.8929e+00, Data-loss 6.8518e-02                  , pde-loss 5.2540e+03, initc-loss 1.2973e+04                    bc_loss 1.6771e+01\n",
      "Epoch 43660, Training-Loss 1.9879e+00, Data-loss 8.2316e-02                  , pde-loss 6.1270e+03, initc-loss 1.2863e+04                    bc_loss 6.5436e+01\n",
      "Epoch 43670, Training-Loss 1.9388e+00, Data-loss 7.3227e-02                  , pde-loss 5.7725e+03, initc-loss 1.2836e+04                    bc_loss 4.7916e+01\n",
      "Epoch 43680, Training-Loss 1.9755e+00, Data-loss 1.1296e-01                  , pde-loss 5.6488e+03, initc-loss 1.2896e+04                    bc_loss 8.0124e+01\n",
      "Epoch 43690, Training-Loss 1.9157e+00, Data-loss 1.0887e-01                  , pde-loss 5.0732e+03, initc-loss 1.2884e+04                    bc_loss 1.1080e+02\n",
      "Epoch 43700, Training-Loss 2.1050e+00, Data-loss 1.8637e-01                  , pde-loss 6.1169e+03, initc-loss 1.2886e+04                    bc_loss 1.8362e+02\n",
      "Epoch 43710, Training-Loss 1.9709e+00, Data-loss 9.3620e-02                  , pde-loss 5.8499e+03, initc-loss 1.2854e+04                    bc_loss 6.9384e+01\n",
      "Epoch 43720, Training-Loss 1.9524e+00, Data-loss 1.0147e-01                  , pde-loss 5.6776e+03, initc-loss 1.2788e+04                    bc_loss 4.4341e+01\n",
      "Epoch 43730, Training-Loss 1.9999e+00, Data-loss 7.1800e-02                  , pde-loss 5.9971e+03, initc-loss 1.2950e+04                    bc_loss 3.3350e+02\n",
      "Epoch 43740, Training-Loss 1.9093e+00, Data-loss 5.8982e-02                  , pde-loss 5.5039e+03, initc-loss 1.2910e+04                    bc_loss 8.9275e+01\n",
      "Epoch 43750, Training-Loss 1.9021e+00, Data-loss 9.1751e-02                  , pde-loss 5.1340e+03, initc-loss 1.2921e+04                    bc_loss 4.7852e+01\n",
      "Epoch 43760, Training-Loss 1.9441e+00, Data-loss 7.6778e-02                  , pde-loss 5.8343e+03, initc-loss 1.2816e+04                    bc_loss 2.3342e+01\n",
      "Epoch 43770, Training-Loss 1.9727e+00, Data-loss 9.3797e-02                  , pde-loss 5.7648e+03, initc-loss 1.2946e+04                    bc_loss 7.8198e+01\n",
      "Epoch 43780, Training-Loss 1.8561e+00, Data-loss 6.8698e-02                  , pde-loss 4.8579e+03, initc-loss 1.2912e+04                    bc_loss 1.0400e+02\n",
      "Epoch 43790, Training-Loss 2.0273e+00, Data-loss 1.5718e-01                  , pde-loss 5.7087e+03, initc-loss 1.2845e+04                    bc_loss 1.4801e+02\n",
      "Epoch 43800, Training-Loss 1.9539e+00, Data-loss 1.4787e-01                  , pde-loss 5.0325e+03, initc-loss 1.2844e+04                    bc_loss 1.8401e+02\n",
      "Epoch 43810, Training-Loss 1.9580e+00, Data-loss 6.8441e-02                  , pde-loss 5.8508e+03, initc-loss 1.2934e+04                    bc_loss 1.1147e+02\n",
      "Epoch 43820, Training-Loss 1.9411e+00, Data-loss 8.7342e-02                  , pde-loss 5.5546e+03, initc-loss 1.2919e+04                    bc_loss 6.3870e+01\n",
      "Epoch 43830, Training-Loss 1.9439e+00, Data-loss 1.0339e-01                  , pde-loss 5.2925e+03, initc-loss 1.2855e+04                    bc_loss 2.5713e+02\n",
      "Epoch 43840, Training-Loss 2.0046e+00, Data-loss 1.3687e-01                  , pde-loss 5.6381e+03, initc-loss 1.2876e+04                    bc_loss 1.6298e+02\n",
      "Epoch 43850, Training-Loss 2.0282e+00, Data-loss 1.4452e-01                  , pde-loss 5.7372e+03, initc-loss 1.2918e+04                    bc_loss 1.8138e+02\n",
      "Epoch 43860, Training-Loss 2.1646e+00, Data-loss 2.9732e-01                  , pde-loss 5.8636e+03, initc-loss 1.2778e+04                    bc_loss 3.0609e+01\n",
      "Epoch 43870, Training-Loss 2.0208e+00, Data-loss 1.4505e-01                  , pde-loss 5.6766e+03, initc-loss 1.2958e+04                    bc_loss 1.2301e+02\n",
      "Epoch 43880, Training-Loss 2.0041e+00, Data-loss 8.0813e-02                  , pde-loss 6.0068e+03, initc-loss 1.2907e+04                    bc_loss 3.1905e+02\n",
      "Epoch 43890, Training-Loss 2.0779e+00, Data-loss 1.3822e-01                  , pde-loss 6.4909e+03, initc-loss 1.2813e+04                    bc_loss 9.2854e+01\n",
      "Epoch 43900, Training-Loss 2.0356e+00, Data-loss 1.6660e-01                  , pde-loss 5.6281e+03, initc-loss 1.2861e+04                    bc_loss 2.0128e+02\n",
      "Epoch 43910, Training-Loss 2.0234e+00, Data-loss 1.1835e-01                  , pde-loss 6.1075e+03, initc-loss 1.2920e+04                    bc_loss 2.2494e+01\n",
      "Epoch 43920, Training-Loss 2.0189e+00, Data-loss 9.8319e-02                  , pde-loss 6.2737e+03, initc-loss 1.2875e+04                    bc_loss 5.6925e+01\n",
      "Epoch 43930, Training-Loss 2.0288e+00, Data-loss 1.1592e-01                  , pde-loss 6.0340e+03, initc-loss 1.2884e+04                    bc_loss 2.1018e+02\n",
      "Epoch 43940, Training-Loss 2.0389e+00, Data-loss 1.1417e-01                  , pde-loss 6.1905e+03, initc-loss 1.2876e+04                    bc_loss 1.8121e+02\n",
      "Epoch 43950, Training-Loss 1.9424e+00, Data-loss 7.8508e-02                  , pde-loss 5.6547e+03, initc-loss 1.2870e+04                    bc_loss 1.1382e+02\n",
      "Epoch 43960, Training-Loss 1.9999e+00, Data-loss 9.8873e-02                  , pde-loss 6.0915e+03, initc-loss 1.2887e+04                    bc_loss 3.1326e+01\n",
      "Epoch 43970, Training-Loss 1.9409e+00, Data-loss 6.7162e-02                  , pde-loss 5.8235e+03, initc-loss 1.2837e+04                    bc_loss 7.6852e+01\n",
      "Epoch 43980, Training-Loss 1.9691e+00, Data-loss 7.0725e-02                  , pde-loss 6.0766e+03, initc-loss 1.2863e+04                    bc_loss 4.4137e+01\n",
      "Epoch 43990, Training-Loss 1.9090e+00, Data-loss 4.8876e-02                  , pde-loss 5.6588e+03, initc-loss 1.2897e+04                    bc_loss 4.5257e+01\n",
      "Epoch 44000, Training-Loss 1.9640e+00, Data-loss 7.6690e-02                  , pde-loss 5.9687e+03, initc-loss 1.2799e+04                    bc_loss 1.0512e+02\n",
      "Epoch 44010, Training-Loss 2.0047e+00, Data-loss 1.3946e-01                  , pde-loss 5.5348e+03, initc-loss 1.2974e+04                    bc_loss 1.4432e+02\n",
      "Epoch 44020, Training-Loss 1.9160e+00, Data-loss 7.4671e-02                  , pde-loss 5.4622e+03, initc-loss 1.2862e+04                    bc_loss 8.9764e+01\n",
      "Epoch 44030, Training-Loss 2.1368e+00, Data-loss 2.1564e-01                  , pde-loss 6.2912e+03, initc-loss 1.2819e+04                    bc_loss 1.0116e+02\n",
      "Epoch 44040, Training-Loss 2.0526e+00, Data-loss 1.2302e-01                  , pde-loss 6.3457e+03, initc-loss 1.2844e+04                    bc_loss 1.0625e+02\n",
      "Epoch 44050, Training-Loss 2.0433e+00, Data-loss 1.5441e-01                  , pde-loss 5.8421e+03, initc-loss 1.2970e+04                    bc_loss 7.6298e+01\n",
      "Epoch 44060, Training-Loss 1.9723e+00, Data-loss 8.7126e-02                  , pde-loss 5.9595e+03, initc-loss 1.2851e+04                    bc_loss 4.1934e+01\n",
      "Epoch 44070, Training-Loss 1.9437e+00, Data-loss 1.1815e-01                  , pde-loss 5.3774e+03, initc-loss 1.2848e+04                    bc_loss 2.9437e+01\n",
      "Epoch 44080, Training-Loss 2.0224e+00, Data-loss 9.6725e-02                  , pde-loss 5.9585e+03, initc-loss 1.2923e+04                    bc_loss 3.7591e+02\n",
      "Epoch 44090, Training-Loss 2.0653e+00, Data-loss 8.6716e-02                  , pde-loss 6.9016e+03, initc-loss 1.2838e+04                    bc_loss 4.6650e+01\n",
      "Epoch 44100, Training-Loss 1.9846e+00, Data-loss 7.7884e-02                  , pde-loss 6.0602e+03, initc-loss 1.2869e+04                    bc_loss 1.3853e+02\n",
      "Epoch 44110, Training-Loss 2.1278e+00, Data-loss 1.1513e-01                  , pde-loss 7.2498e+03, initc-loss 1.2843e+04                    bc_loss 3.4722e+01\n",
      "Epoch 44120, Training-Loss 1.9004e+00, Data-loss 6.6556e-02                  , pde-loss 5.4565e+03, initc-loss 1.2841e+04                    bc_loss 4.0918e+01\n",
      "Epoch 44130, Training-Loss 1.9364e+00, Data-loss 6.2682e-02                  , pde-loss 5.8308e+03, initc-loss 1.2860e+04                    bc_loss 4.6012e+01\n",
      "Epoch 44140, Training-Loss 1.9539e+00, Data-loss 6.6762e-02                  , pde-loss 5.8629e+03, initc-loss 1.2947e+04                    bc_loss 6.2102e+01\n",
      "Epoch 44150, Training-Loss 1.9354e+00, Data-loss 6.0171e-02                  , pde-loss 5.7929e+03, initc-loss 1.2905e+04                    bc_loss 5.4928e+01\n",
      "Epoch 44160, Training-Loss 2.0312e+00, Data-loss 1.0820e-01                  , pde-loss 6.2608e+03, initc-loss 1.2851e+04                    bc_loss 1.1817e+02\n",
      "Epoch 44170, Training-Loss 2.0029e+00, Data-loss 1.2858e-01                  , pde-loss 5.7099e+03, initc-loss 1.2970e+04                    bc_loss 6.3499e+01\n",
      "Epoch 44180, Training-Loss 1.9499e+00, Data-loss 8.0254e-02                  , pde-loss 5.7694e+03, initc-loss 1.2899e+04                    bc_loss 2.8099e+01\n",
      "Epoch 44190, Training-Loss 1.9213e+00, Data-loss 9.1671e-02                  , pde-loss 5.3080e+03, initc-loss 1.2898e+04                    bc_loss 8.9780e+01\n",
      "Epoch 44200, Training-Loss 1.9924e+00, Data-loss 1.6772e-01                  , pde-loss 5.2401e+03, initc-loss 1.2880e+04                    bc_loss 1.2594e+02\n",
      "Epoch 44210, Training-Loss 1.9118e+00, Data-loss 8.2741e-02                  , pde-loss 5.3821e+03, initc-loss 1.2832e+04                    bc_loss 7.6330e+01\n",
      "Epoch 44220, Training-Loss 1.9771e+00, Data-loss 1.0547e-01                  , pde-loss 5.4579e+03, initc-loss 1.2969e+04                    bc_loss 2.8932e+02\n",
      "Epoch 44230, Training-Loss 1.8424e+00, Data-loss 4.7894e-02                  , pde-loss 4.9471e+03, initc-loss 1.2883e+04                    bc_loss 1.1439e+02\n",
      "Epoch 44240, Training-Loss 1.9653e+00, Data-loss 9.1927e-02                  , pde-loss 5.8559e+03, initc-loss 1.2820e+04                    bc_loss 5.7644e+01\n",
      "Epoch 44250, Training-Loss 2.0965e+00, Data-loss 1.7397e-01                  , pde-loss 6.2558e+03, initc-loss 1.2900e+04                    bc_loss 7.0066e+01\n",
      "Epoch 44260, Training-Loss 2.0281e+00, Data-loss 1.2708e-01                  , pde-loss 5.7665e+03, initc-loss 1.2915e+04                    bc_loss 3.2858e+02\n",
      "Epoch 44270, Training-Loss 2.0583e+00, Data-loss 1.2707e-01                  , pde-loss 6.2578e+03, initc-loss 1.2890e+04                    bc_loss 1.6498e+02\n",
      "Epoch 44280, Training-Loss 1.8817e+00, Data-loss 5.5744e-02                  , pde-loss 5.3511e+03, initc-loss 1.2870e+04                    bc_loss 3.8587e+01\n",
      "Epoch 44290, Training-Loss 1.9417e+00, Data-loss 7.4160e-02                  , pde-loss 5.6641e+03, initc-loss 1.2927e+04                    bc_loss 8.4975e+01\n",
      "Epoch 44300, Training-Loss 2.0190e+00, Data-loss 8.4607e-02                  , pde-loss 6.4083e+03, initc-loss 1.2905e+04                    bc_loss 3.0870e+01\n",
      "Epoch 44310, Training-Loss 1.9872e+00, Data-loss 5.6016e-02                  , pde-loss 6.3284e+03, initc-loss 1.2943e+04                    bc_loss 4.0600e+01\n",
      "Epoch 44320, Training-Loss 1.9918e+00, Data-loss 1.1388e-01                  , pde-loss 5.8581e+03, initc-loss 1.2838e+04                    bc_loss 8.3274e+01\n",
      "Epoch 44330, Training-Loss 1.9181e+00, Data-loss 7.9242e-02                  , pde-loss 5.4712e+03, initc-loss 1.2871e+04                    bc_loss 4.6840e+01\n",
      "Epoch 44340, Training-Loss 1.9467e+00, Data-loss 6.7073e-02                  , pde-loss 5.8853e+03, initc-loss 1.2884e+04                    bc_loss 2.7202e+01\n",
      "Epoch 44350, Training-Loss 1.8831e+00, Data-loss 8.4370e-02                  , pde-loss 4.9823e+03, initc-loss 1.2910e+04                    bc_loss 9.5899e+01\n",
      "Epoch 44360, Training-Loss 1.9204e+00, Data-loss 5.6352e-02                  , pde-loss 5.7378e+03, initc-loss 1.2861e+04                    bc_loss 4.1644e+01\n",
      "Epoch 44370, Training-Loss 1.9443e+00, Data-loss 7.2844e-02                  , pde-loss 5.7599e+03, initc-loss 1.2909e+04                    bc_loss 4.4768e+01\n",
      "Epoch 44380, Training-Loss 1.9947e+00, Data-loss 1.4403e-01                  , pde-loss 5.3743e+03, initc-loss 1.2827e+04                    bc_loss 3.0477e+02\n",
      "Epoch 44390, Training-Loss 2.0504e+00, Data-loss 1.2746e-01                  , pde-loss 6.1950e+03, initc-loss 1.2848e+04                    bc_loss 1.8714e+02\n",
      "Epoch 44400, Training-Loss 1.9500e+00, Data-loss 6.3667e-02                  , pde-loss 5.8461e+03, initc-loss 1.2907e+04                    bc_loss 1.1035e+02\n",
      "Epoch 44410, Training-Loss 1.9462e+00, Data-loss 5.8522e-02                  , pde-loss 5.8826e+03, initc-loss 1.2914e+04                    bc_loss 7.9416e+01\n",
      "Epoch 44420, Training-Loss 1.9218e+00, Data-loss 5.7033e-02                  , pde-loss 5.7007e+03, initc-loss 1.2906e+04                    bc_loss 4.0916e+01\n",
      "Epoch 44430, Training-Loss 2.0341e+00, Data-loss 1.3215e-01                  , pde-loss 6.1217e+03, initc-loss 1.2838e+04                    bc_loss 6.0613e+01\n",
      "Epoch 44440, Training-Loss 1.9774e+00, Data-loss 7.2402e-02                  , pde-loss 6.1751e+03, initc-loss 1.2838e+04                    bc_loss 3.6985e+01\n",
      "Epoch 44450, Training-Loss 1.9238e+00, Data-loss 6.6630e-02                  , pde-loss 5.6508e+03, initc-loss 1.2876e+04                    bc_loss 4.4778e+01\n",
      "Epoch 44460, Training-Loss 1.9757e+00, Data-loss 5.8927e-02                  , pde-loss 6.3484e+03, initc-loss 1.2790e+04                    bc_loss 2.8735e+01\n",
      "Epoch 44470, Training-Loss 1.9905e+00, Data-loss 5.5363e-02                  , pde-loss 6.4135e+03, initc-loss 1.2886e+04                    bc_loss 5.2311e+01\n",
      "Epoch 44480, Training-Loss 1.9959e+00, Data-loss 6.0846e-02                  , pde-loss 6.3396e+03, initc-loss 1.2897e+04                    bc_loss 1.1444e+02\n",
      "Epoch 44490, Training-Loss 1.9757e+00, Data-loss 1.0461e-01                  , pde-loss 5.6048e+03, initc-loss 1.2885e+04                    bc_loss 2.2132e+02\n",
      "Epoch 44500, Training-Loss 1.9773e+00, Data-loss 6.1459e-02                  , pde-loss 6.1301e+03, initc-loss 1.2945e+04                    bc_loss 8.4191e+01\n",
      "Epoch 44510, Training-Loss 1.9785e+00, Data-loss 1.5284e-01                  , pde-loss 5.2631e+03, initc-loss 1.2928e+04                    bc_loss 6.5379e+01\n",
      "Epoch 44520, Training-Loss 2.0438e+00, Data-loss 1.4675e-01                  , pde-loss 6.0003e+03, initc-loss 1.2912e+04                    bc_loss 5.7721e+01\n",
      "Epoch 44530, Training-Loss 2.0617e+00, Data-loss 2.0753e-01                  , pde-loss 5.5361e+03, initc-loss 1.2854e+04                    bc_loss 1.5205e+02\n",
      "Epoch 44540, Training-Loss 1.8506e+00, Data-loss 4.0325e-02                  , pde-loss 5.0696e+03, initc-loss 1.2864e+04                    bc_loss 1.6944e+02\n",
      "Epoch 44550, Training-Loss 1.9707e+00, Data-loss 1.1492e-01                  , pde-loss 5.5720e+03, initc-loss 1.2902e+04                    bc_loss 8.3783e+01\n",
      "Epoch 44560, Training-Loss 2.0858e+00, Data-loss 1.8053e-01                  , pde-loss 5.9504e+03, initc-loss 1.2926e+04                    bc_loss 1.7658e+02\n",
      "Epoch 44570, Training-Loss 1.9675e+00, Data-loss 1.0063e-01                  , pde-loss 5.6012e+03, initc-loss 1.2926e+04                    bc_loss 1.4175e+02\n",
      "Epoch 44580, Training-Loss 1.9593e+00, Data-loss 6.5896e-02                  , pde-loss 5.9401e+03, initc-loss 1.2859e+04                    bc_loss 1.3487e+02\n",
      "Epoch 44590, Training-Loss 1.8879e+00, Data-loss 6.8989e-02                  , pde-loss 5.2767e+03, initc-loss 1.2887e+04                    bc_loss 2.5863e+01\n",
      "Epoch 44600, Training-Loss 2.0360e+00, Data-loss 1.5041e-01                  , pde-loss 5.7201e+03, initc-loss 1.2903e+04                    bc_loss 2.3234e+02\n",
      "Epoch 44610, Training-Loss 1.9865e+00, Data-loss 8.7449e-02                  , pde-loss 5.7606e+03, initc-loss 1.2867e+04                    bc_loss 3.6323e+02\n",
      "Epoch 44620, Training-Loss 1.9102e+00, Data-loss 1.0821e-01                  , pde-loss 5.1037e+03, initc-loss 1.2870e+04                    bc_loss 4.5960e+01\n",
      "Epoch 44630, Training-Loss 2.0574e+00, Data-loss 1.8802e-01                  , pde-loss 5.8285e+03, initc-loss 1.2798e+04                    bc_loss 6.7857e+01\n",
      "Epoch 44640, Training-Loss 2.0117e+00, Data-loss 1.5983e-01                  , pde-loss 5.3839e+03, initc-loss 1.2829e+04                    bc_loss 3.0576e+02\n",
      "Epoch 44650, Training-Loss 2.0110e+00, Data-loss 8.4576e-02                  , pde-loss 6.2656e+03, initc-loss 1.2899e+04                    bc_loss 9.9991e+01\n",
      "Epoch 44660, Training-Loss 2.0840e+00, Data-loss 1.5110e-01                  , pde-loss 6.2778e+03, initc-loss 1.2989e+04                    bc_loss 6.2678e+01\n",
      "Epoch 44670, Training-Loss 2.0384e+00, Data-loss 1.1710e-01                  , pde-loss 6.2293e+03, initc-loss 1.2922e+04                    bc_loss 6.1758e+01\n",
      "Epoch 44680, Training-Loss 2.0302e+00, Data-loss 1.1701e-01                  , pde-loss 6.1376e+03, initc-loss 1.2905e+04                    bc_loss 8.9269e+01\n",
      "Epoch 44690, Training-Loss 1.9217e+00, Data-loss 7.9182e-02                  , pde-loss 5.5768e+03, initc-loss 1.2823e+04                    bc_loss 2.5526e+01\n",
      "Epoch 44700, Training-Loss 1.9150e+00, Data-loss 5.0187e-02                  , pde-loss 5.6231e+03, initc-loss 1.2945e+04                    bc_loss 8.0083e+01\n",
      "Epoch 44710, Training-Loss 1.9857e+00, Data-loss 8.5643e-02                  , pde-loss 6.0381e+03, initc-loss 1.2898e+04                    bc_loss 6.4436e+01\n",
      "Epoch 44720, Training-Loss 1.8892e+00, Data-loss 7.6265e-02                  , pde-loss 5.2377e+03, initc-loss 1.2870e+04                    bc_loss 2.2126e+01\n",
      "Epoch 44730, Training-Loss 1.9318e+00, Data-loss 9.1051e-02                  , pde-loss 5.4848e+03, initc-loss 1.2898e+04                    bc_loss 2.5067e+01\n",
      "Epoch 44740, Training-Loss 2.0330e+00, Data-loss 1.1011e-01                  , pde-loss 6.1563e+03, initc-loss 1.2960e+04                    bc_loss 1.1271e+02\n",
      "Epoch 44750, Training-Loss 1.9957e+00, Data-loss 1.1880e-01                  , pde-loss 5.7672e+03, initc-loss 1.2869e+04                    bc_loss 1.3278e+02\n",
      "Epoch 44760, Training-Loss 2.0658e+00, Data-loss 1.6403e-01                  , pde-loss 6.0144e+03, initc-loss 1.2887e+04                    bc_loss 1.1670e+02\n",
      "Epoch 44770, Training-Loss 2.1344e+00, Data-loss 1.7188e-01                  , pde-loss 6.6176e+03, initc-loss 1.2880e+04                    bc_loss 1.2790e+02\n",
      "Epoch 44780, Training-Loss 2.0162e+00, Data-loss 7.5062e-02                  , pde-loss 6.3319e+03, initc-loss 1.2887e+04                    bc_loss 1.9235e+02\n",
      "Epoch 44790, Training-Loss 1.9421e+00, Data-loss 9.8927e-02                  , pde-loss 5.5713e+03, initc-loss 1.2818e+04                    bc_loss 4.2088e+01\n",
      "Epoch 44800, Training-Loss 1.9381e+00, Data-loss 7.6626e-02                  , pde-loss 5.7486e+03, initc-loss 1.2833e+04                    bc_loss 3.3342e+01\n",
      "Epoch 44810, Training-Loss 1.9483e+00, Data-loss 8.8824e-02                  , pde-loss 5.6923e+03, initc-loss 1.2845e+04                    bc_loss 5.7438e+01\n",
      "Epoch 44820, Training-Loss 2.1262e+00, Data-loss 1.3968e-01                  , pde-loss 6.8327e+03, initc-loss 1.2909e+04                    bc_loss 1.2350e+02\n",
      "Epoch 44830, Training-Loss 2.1510e+00, Data-loss 1.2286e-01                  , pde-loss 7.2331e+03, initc-loss 1.2911e+04                    bc_loss 1.3730e+02\n",
      "Epoch 44840, Training-Loss 1.8412e+00, Data-loss 4.6545e-02                  , pde-loss 4.8259e+03, initc-loss 1.2921e+04                    bc_loss 1.9959e+02\n",
      "Epoch 44850, Training-Loss 2.0293e+00, Data-loss 1.3380e-01                  , pde-loss 5.8010e+03, initc-loss 1.2905e+04                    bc_loss 2.4891e+02\n",
      "Epoch 44860, Training-Loss 1.9933e+00, Data-loss 9.7527e-02                  , pde-loss 6.0004e+03, initc-loss 1.2850e+04                    bc_loss 1.0662e+02\n",
      "Epoch 44870, Training-Loss 1.9706e+00, Data-loss 7.6757e-02                  , pde-loss 5.9780e+03, initc-loss 1.2863e+04                    bc_loss 9.7256e+01\n",
      "Epoch 44880, Training-Loss 1.9596e+00, Data-loss 9.5679e-02                  , pde-loss 5.7124e+03, initc-loss 1.2866e+04                    bc_loss 6.0986e+01\n",
      "Epoch 44890, Training-Loss 2.0419e+00, Data-loss 2.3032e-01                  , pde-loss 4.9947e+03, initc-loss 1.2838e+04                    bc_loss 2.8338e+02\n",
      "Epoch 44900, Training-Loss 2.1126e+00, Data-loss 1.8200e-01                  , pde-loss 6.2053e+03, initc-loss 1.2821e+04                    bc_loss 2.7971e+02\n",
      "Epoch 44910, Training-Loss 1.9504e+00, Data-loss 7.1541e-02                  , pde-loss 5.7330e+03, initc-loss 1.2853e+04                    bc_loss 2.0254e+02\n",
      "Epoch 44920, Training-Loss 1.9869e+00, Data-loss 1.4468e-01                  , pde-loss 5.3700e+03, initc-loss 1.3003e+04                    bc_loss 4.9232e+01\n",
      "Epoch 44930, Training-Loss 2.0661e+00, Data-loss 1.2555e-01                  , pde-loss 6.2059e+03, initc-loss 1.2962e+04                    bc_loss 2.3824e+02\n",
      "Epoch 44940, Training-Loss 1.8854e+00, Data-loss 4.6479e-02                  , pde-loss 5.4408e+03, initc-loss 1.2914e+04                    bc_loss 3.4597e+01\n",
      "Epoch 44950, Training-Loss 1.9358e+00, Data-loss 8.0945e-02                  , pde-loss 5.6253e+03, initc-loss 1.2906e+04                    bc_loss 1.7010e+01\n",
      "Epoch 44960, Training-Loss 1.9854e+00, Data-loss 6.8079e-02                  , pde-loss 6.2655e+03, initc-loss 1.2889e+04                    bc_loss 1.8308e+01\n",
      "Epoch 44970, Training-Loss 2.0475e+00, Data-loss 1.4599e-01                  , pde-loss 5.9807e+03, initc-loss 1.2942e+04                    bc_loss 9.2442e+01\n",
      "Epoch 44980, Training-Loss 1.9022e+00, Data-loss 6.0067e-02                  , pde-loss 5.4977e+03, initc-loss 1.2813e+04                    bc_loss 1.1047e+02\n",
      "Epoch 44990, Training-Loss 2.0558e+00, Data-loss 1.2781e-01                  , pde-loss 6.2149e+03, initc-loss 1.2915e+04                    bc_loss 1.5032e+02\n",
      "Epoch 45000, Training-Loss 2.0204e+00, Data-loss 1.5344e-01                  , pde-loss 5.7082e+03, initc-loss 1.2840e+04                    bc_loss 1.2085e+02\n",
      "Epoch 45010, Training-Loss 2.0012e+00, Data-loss 1.3409e-01                  , pde-loss 5.7251e+03, initc-loss 1.2878e+04                    bc_loss 6.7290e+01\n",
      "Epoch 45020, Training-Loss 2.0380e+00, Data-loss 8.0410e-02                  , pde-loss 6.4173e+03, initc-loss 1.2847e+04                    bc_loss 3.1158e+02\n",
      "Epoch 45030, Training-Loss 2.0468e+00, Data-loss 1.4298e-01                  , pde-loss 5.7826e+03, initc-loss 1.2881e+04                    bc_loss 3.7470e+02\n",
      "Epoch 45040, Training-Loss 2.0670e+00, Data-loss 1.3599e-01                  , pde-loss 6.2719e+03, initc-loss 1.2915e+04                    bc_loss 1.2300e+02\n",
      "Epoch 45050, Training-Loss 1.9330e+00, Data-loss 1.3181e-01                  , pde-loss 5.0195e+03, initc-loss 1.2877e+04                    bc_loss 1.1549e+02\n",
      "Epoch 45060, Training-Loss 1.8919e+00, Data-loss 8.1756e-02                  , pde-loss 5.1133e+03, initc-loss 1.2835e+04                    bc_loss 1.5379e+02\n",
      "Epoch 45070, Training-Loss 1.9982e+00, Data-loss 8.2149e-02                  , pde-loss 6.2296e+03, initc-loss 1.2884e+04                    bc_loss 4.6733e+01\n",
      "Epoch 45080, Training-Loss 1.9860e+00, Data-loss 1.1222e-01                  , pde-loss 5.6526e+03, initc-loss 1.2908e+04                    bc_loss 1.7772e+02\n",
      "Epoch 45090, Training-Loss 2.0170e+00, Data-loss 1.7193e-01                  , pde-loss 5.4597e+03, initc-loss 1.2799e+04                    bc_loss 1.9197e+02\n",
      "Epoch 45100, Training-Loss 2.0556e+00, Data-loss 1.1171e-01                  , pde-loss 6.2432e+03, initc-loss 1.2830e+04                    bc_loss 3.6585e+02\n",
      "Epoch 45110, Training-Loss 1.9705e+00, Data-loss 8.5199e-02                  , pde-loss 5.7964e+03, initc-loss 1.2954e+04                    bc_loss 1.0222e+02\n",
      "Epoch 45120, Training-Loss 1.9962e+00, Data-loss 1.0083e-01                  , pde-loss 6.0447e+03, initc-loss 1.2838e+04                    bc_loss 7.1506e+01\n",
      "Epoch 45130, Training-Loss 2.0111e+00, Data-loss 1.3681e-01                  , pde-loss 5.4715e+03, initc-loss 1.2934e+04                    bc_loss 3.3743e+02\n",
      "Epoch 45140, Training-Loss 2.3128e+00, Data-loss 3.9027e-01                  , pde-loss 5.6969e+03, initc-loss 1.3016e+04                    bc_loss 5.1239e+02\n",
      "Epoch 45150, Training-Loss 1.8483e+00, Data-loss 5.0826e-02                  , pde-loss 4.8959e+03, initc-loss 1.2992e+04                    bc_loss 8.6929e+01\n",
      "Epoch 45160, Training-Loss 1.9996e+00, Data-loss 1.0208e-01                  , pde-loss 5.9864e+03, initc-loss 1.2921e+04                    bc_loss 6.8486e+01\n",
      "Epoch 45170, Training-Loss 2.0850e+00, Data-loss 1.6655e-01                  , pde-loss 6.1613e+03, initc-loss 1.2982e+04                    bc_loss 4.1759e+01\n",
      "Epoch 45180, Training-Loss 1.9711e+00, Data-loss 1.0191e-01                  , pde-loss 5.7272e+03, initc-loss 1.2886e+04                    bc_loss 7.9012e+01\n",
      "Epoch 45190, Training-Loss 1.9472e+00, Data-loss 9.5158e-02                  , pde-loss 5.5280e+03, initc-loss 1.2913e+04                    bc_loss 7.9480e+01\n",
      "Epoch 45200, Training-Loss 1.9560e+00, Data-loss 8.3032e-02                  , pde-loss 5.7728e+03, initc-loss 1.2922e+04                    bc_loss 3.4671e+01\n",
      "Epoch 45210, Training-Loss 1.9252e+00, Data-loss 9.4713e-02                  , pde-loss 5.4416e+03, initc-loss 1.2829e+04                    bc_loss 3.3335e+01\n",
      "Epoch 45220, Training-Loss 1.9588e+00, Data-loss 1.1250e-01                  , pde-loss 5.4995e+03, initc-loss 1.2788e+04                    bc_loss 1.7556e+02\n",
      "Epoch 45230, Training-Loss 1.9860e+00, Data-loss 1.0707e-01                  , pde-loss 5.8391e+03, initc-loss 1.2900e+04                    bc_loss 4.9665e+01\n",
      "Epoch 45240, Training-Loss 1.9991e+00, Data-loss 7.4229e-02                  , pde-loss 6.3186e+03, initc-loss 1.2889e+04                    bc_loss 4.0259e+01\n",
      "Epoch 45250, Training-Loss 1.9302e+00, Data-loss 7.0954e-02                  , pde-loss 5.6178e+03, initc-loss 1.2907e+04                    bc_loss 6.8399e+01\n",
      "Epoch 45260, Training-Loss 1.9791e+00, Data-loss 8.2819e-02                  , pde-loss 6.0337e+03, initc-loss 1.2903e+04                    bc_loss 2.6720e+01\n",
      "Epoch 45270, Training-Loss 1.9500e+00, Data-loss 8.7252e-02                  , pde-loss 5.7305e+03, initc-loss 1.2882e+04                    bc_loss 1.5505e+01\n",
      "Epoch 45280, Training-Loss 1.8996e+00, Data-loss 8.0554e-02                  , pde-loss 5.3090e+03, initc-loss 1.2840e+04                    bc_loss 4.1800e+01\n",
      "Epoch 45290, Training-Loss 1.9678e+00, Data-loss 5.5486e-02                  , pde-loss 6.1147e+03, initc-loss 1.2917e+04                    bc_loss 9.0830e+01\n",
      "Epoch 45300, Training-Loss 1.9534e+00, Data-loss 6.2868e-02                  , pde-loss 5.9653e+03, initc-loss 1.2871e+04                    bc_loss 6.9077e+01\n",
      "Epoch 45310, Training-Loss 1.9120e+00, Data-loss 8.0058e-02                  , pde-loss 5.3531e+03, initc-loss 1.2876e+04                    bc_loss 9.0146e+01\n",
      "Epoch 45320, Training-Loss 1.9466e+00, Data-loss 9.9344e-02                  , pde-loss 5.6098e+03, initc-loss 1.2785e+04                    bc_loss 7.7250e+01\n",
      "Epoch 45330, Training-Loss 2.0699e+00, Data-loss 2.3329e-01                  , pde-loss 5.4888e+03, initc-loss 1.2869e+04                    bc_loss 7.8050e+00\n",
      "Epoch 45340, Training-Loss 2.0007e+00, Data-loss 8.5499e-02                  , pde-loss 6.2044e+03, initc-loss 1.2870e+04                    bc_loss 7.7433e+01\n",
      "Epoch 45350, Training-Loss 1.9834e+00, Data-loss 1.1368e-01                  , pde-loss 5.7433e+03, initc-loss 1.2892e+04                    bc_loss 6.1404e+01\n",
      "Epoch 45360, Training-Loss 1.9258e+00, Data-loss 6.7723e-02                  , pde-loss 5.4819e+03, initc-loss 1.2871e+04                    bc_loss 2.2732e+02\n",
      "Epoch 45370, Training-Loss 1.9344e+00, Data-loss 8.9576e-02                  , pde-loss 5.5805e+03, initc-loss 1.2832e+04                    bc_loss 3.5472e+01\n",
      "Epoch 45380, Training-Loss 1.9630e+00, Data-loss 1.0317e-01                  , pde-loss 5.6366e+03, initc-loss 1.2853e+04                    bc_loss 1.0925e+02\n",
      "Epoch 45390, Training-Loss 2.0083e+00, Data-loss 1.2545e-01                  , pde-loss 5.4933e+03, initc-loss 1.2886e+04                    bc_loss 4.4992e+02\n",
      "Epoch 45400, Training-Loss 2.1547e+00, Data-loss 3.2825e-01                  , pde-loss 5.3863e+03, initc-loss 1.2768e+04                    bc_loss 1.1028e+02\n",
      "Epoch 45410, Training-Loss 1.8825e+00, Data-loss 5.3945e-02                  , pde-loss 5.3766e+03, initc-loss 1.2861e+04                    bc_loss 4.7894e+01\n",
      "Epoch 45420, Training-Loss 2.0016e+00, Data-loss 7.6611e-02                  , pde-loss 6.3217e+03, initc-loss 1.2874e+04                    bc_loss 5.4211e+01\n",
      "Epoch 45430, Training-Loss 2.1198e+00, Data-loss 1.6039e-01                  , pde-loss 6.4817e+03, initc-loss 1.2918e+04                    bc_loss 1.9474e+02\n",
      "Epoch 45440, Training-Loss 2.0467e+00, Data-loss 1.6630e-01                  , pde-loss 5.8188e+03, initc-loss 1.2893e+04                    bc_loss 9.2660e+01\n",
      "Epoch 45450, Training-Loss 2.2163e+00, Data-loss 2.4423e-01                  , pde-loss 5.7703e+03, initc-loss 1.2800e+04                    bc_loss 1.1506e+03\n",
      "Epoch 45460, Training-Loss 2.0911e+00, Data-loss 1.6153e-01                  , pde-loss 6.3062e+03, initc-loss 1.2870e+04                    bc_loss 1.2019e+02\n",
      "Epoch 45470, Training-Loss 1.9079e+00, Data-loss 8.2885e-02                  , pde-loss 5.2886e+03, initc-loss 1.2917e+04                    bc_loss 4.4611e+01\n",
      "Epoch 45480, Training-Loss 2.0042e+00, Data-loss 1.1060e-01                  , pde-loss 5.9602e+03, initc-loss 1.2907e+04                    bc_loss 6.8989e+01\n",
      "Epoch 45490, Training-Loss 1.9484e+00, Data-loss 7.0658e-02                  , pde-loss 5.8914e+03, initc-loss 1.2854e+04                    bc_loss 3.2299e+01\n",
      "Epoch 45500, Training-Loss 1.8529e+00, Data-loss 5.8550e-02                  , pde-loss 4.9653e+03, initc-loss 1.2933e+04                    bc_loss 4.5077e+01\n",
      "Epoch 45510, Training-Loss 1.9363e+00, Data-loss 1.1887e-01                  , pde-loss 5.2132e+03, initc-loss 1.2916e+04                    bc_loss 4.5166e+01\n",
      "Epoch 45520, Training-Loss 1.9137e+00, Data-loss 8.3518e-02                  , pde-loss 5.2503e+03, initc-loss 1.2999e+04                    bc_loss 5.2118e+01\n",
      "Epoch 45530, Training-Loss 1.9648e+00, Data-loss 8.2685e-02                  , pde-loss 5.7436e+03, initc-loss 1.2860e+04                    bc_loss 2.1755e+02\n",
      "Epoch 45540, Training-Loss 1.9772e+00, Data-loss 8.8626e-02                  , pde-loss 5.8957e+03, initc-loss 1.2895e+04                    bc_loss 9.4398e+01\n",
      "Epoch 45550, Training-Loss 1.8857e+00, Data-loss 5.0299e-02                  , pde-loss 5.3986e+03, initc-loss 1.2928e+04                    bc_loss 2.7309e+01\n",
      "Epoch 45560, Training-Loss 1.9339e+00, Data-loss 7.2290e-02                  , pde-loss 5.7069e+03, initc-loss 1.2887e+04                    bc_loss 2.2768e+01\n",
      "Epoch 45570, Training-Loss 1.8980e+00, Data-loss 4.2396e-02                  , pde-loss 5.6185e+03, initc-loss 1.2875e+04                    bc_loss 6.2086e+01\n",
      "Epoch 45580, Training-Loss 1.8775e+00, Data-loss 4.8154e-02                  , pde-loss 5.2813e+03, initc-loss 1.2959e+04                    bc_loss 5.3816e+01\n",
      "Epoch 45590, Training-Loss 1.8793e+00, Data-loss 5.3593e-02                  , pde-loss 5.2125e+03, initc-loss 1.2917e+04                    bc_loss 1.2839e+02\n",
      "Epoch 45600, Training-Loss 2.0446e+00, Data-loss 5.0542e-02                  , pde-loss 6.9363e+03, initc-loss 1.2922e+04                    bc_loss 8.1978e+01\n",
      "Epoch 45610, Training-Loss 1.9186e+00, Data-loss 7.5388e-02                  , pde-loss 5.4081e+03, initc-loss 1.2956e+04                    bc_loss 6.8758e+01\n",
      "Epoch 45620, Training-Loss 1.9854e+00, Data-loss 8.3910e-02                  , pde-loss 6.0115e+03, initc-loss 1.2922e+04                    bc_loss 8.1045e+01\n",
      "Epoch 45630, Training-Loss 2.0452e+00, Data-loss 9.2740e-02                  , pde-loss 6.5496e+03, initc-loss 1.2918e+04                    bc_loss 5.7342e+01\n",
      "Epoch 45640, Training-Loss 1.9684e+00, Data-loss 4.8738e-02                  , pde-loss 6.2794e+03, initc-loss 1.2908e+04                    bc_loss 9.0030e+00\n",
      "Epoch 45650, Training-Loss 1.9657e+00, Data-loss 5.3620e-02                  , pde-loss 6.1835e+03, initc-loss 1.2884e+04                    bc_loss 5.3506e+01\n",
      "Epoch 45660, Training-Loss 1.9353e+00, Data-loss 9.3785e-02                  , pde-loss 5.3635e+03, initc-loss 1.2913e+04                    bc_loss 1.3837e+02\n",
      "Epoch 45670, Training-Loss 1.9700e+00, Data-loss 9.8684e-02                  , pde-loss 5.8200e+03, initc-loss 1.2841e+04                    bc_loss 5.2539e+01\n",
      "Epoch 45680, Training-Loss 1.9908e+00, Data-loss 1.1672e-01                  , pde-loss 5.6003e+03, initc-loss 1.2919e+04                    bc_loss 2.2146e+02\n",
      "Epoch 45690, Training-Loss 2.0248e+00, Data-loss 1.2837e-01                  , pde-loss 5.9309e+03, initc-loss 1.2917e+04                    bc_loss 1.1727e+02\n",
      "Epoch 45700, Training-Loss 1.8500e+00, Data-loss 7.5228e-02                  , pde-loss 4.7961e+03, initc-loss 1.2902e+04                    bc_loss 5.0373e+01\n",
      "Epoch 45710, Training-Loss 2.0294e+00, Data-loss 6.1389e-02                  , pde-loss 6.6919e+03, initc-loss 1.2838e+04                    bc_loss 1.5057e+02\n",
      "Epoch 45720, Training-Loss 1.9587e+00, Data-loss 8.7425e-02                  , pde-loss 5.7694e+03, initc-loss 1.2833e+04                    bc_loss 1.1050e+02\n",
      "Epoch 45730, Training-Loss 2.0815e+00, Data-loss 1.9835e-01                  , pde-loss 5.9388e+03, initc-loss 1.2818e+04                    bc_loss 7.5126e+01\n",
      "Epoch 45740, Training-Loss 1.9544e+00, Data-loss 9.4473e-02                  , pde-loss 5.6634e+03, initc-loss 1.2891e+04                    bc_loss 4.5038e+01\n",
      "Epoch 45750, Training-Loss 2.0285e+00, Data-loss 1.2428e-01                  , pde-loss 6.0840e+03, initc-loss 1.2878e+04                    bc_loss 8.0730e+01\n",
      "Epoch 45760, Training-Loss 1.9644e+00, Data-loss 9.2503e-02                  , pde-loss 5.8271e+03, initc-loss 1.2858e+04                    bc_loss 3.4301e+01\n",
      "Epoch 45770, Training-Loss 2.0033e+00, Data-loss 1.2999e-01                  , pde-loss 5.9001e+03, initc-loss 1.2761e+04                    bc_loss 7.2199e+01\n",
      "Epoch 45780, Training-Loss 2.1196e+00, Data-loss 3.3770e-01                  , pde-loss 4.8780e+03, initc-loss 1.2782e+04                    bc_loss 1.5842e+02\n",
      "Epoch 45790, Training-Loss 2.0119e+00, Data-loss 6.6844e-02                  , pde-loss 6.3008e+03, initc-loss 1.2919e+04                    bc_loss 2.3101e+02\n",
      "Epoch 45800, Training-Loss 2.0355e+00, Data-loss 1.0245e-01                  , pde-loss 6.4491e+03, initc-loss 1.2819e+04                    bc_loss 6.2004e+01\n",
      "Epoch 45810, Training-Loss 2.0342e+00, Data-loss 6.5093e-02                  , pde-loss 6.7857e+03, initc-loss 1.2875e+04                    bc_loss 3.0906e+01\n",
      "Epoch 45820, Training-Loss 1.9194e+00, Data-loss 8.0211e-02                  , pde-loss 5.4888e+03, initc-loss 1.2859e+04                    bc_loss 4.4330e+01\n",
      "Epoch 45830, Training-Loss 2.0593e+00, Data-loss 6.5375e-02                  , pde-loss 6.9950e+03, initc-loss 1.2860e+04                    bc_loss 8.3881e+01\n",
      "Epoch 45840, Training-Loss 1.9492e+00, Data-loss 1.0731e-01                  , pde-loss 5.4301e+03, initc-loss 1.2858e+04                    bc_loss 1.2998e+02\n",
      "Epoch 45850, Training-Loss 1.9997e+00, Data-loss 1.2010e-01                  , pde-loss 5.9073e+03, initc-loss 1.2864e+04                    bc_loss 2.3916e+01\n",
      "Epoch 45860, Training-Loss 1.9715e+00, Data-loss 1.2451e-01                  , pde-loss 5.2894e+03, initc-loss 1.2872e+04                    bc_loss 3.0791e+02\n",
      "Epoch 45870, Training-Loss 1.9005e+00, Data-loss 6.9670e-02                  , pde-loss 5.2804e+03, initc-loss 1.2957e+04                    bc_loss 7.0629e+01\n",
      "Epoch 45880, Training-Loss 1.9462e+00, Data-loss 8.7425e-02                  , pde-loss 5.6123e+03, initc-loss 1.2935e+04                    bc_loss 4.0963e+01\n",
      "Epoch 45890, Training-Loss 2.0933e+00, Data-loss 1.6870e-01                  , pde-loss 6.0168e+03, initc-loss 1.2888e+04                    bc_loss 3.4152e+02\n",
      "Epoch 45900, Training-Loss 1.9381e+00, Data-loss 5.4118e-02                  , pde-loss 5.8550e+03, initc-loss 1.2911e+04                    bc_loss 7.3762e+01\n",
      "Epoch 45910, Training-Loss 2.0595e+00, Data-loss 1.6665e-01                  , pde-loss 6.0520e+03, initc-loss 1.2816e+04                    bc_loss 5.9808e+01\n",
      "Epoch 45920, Training-Loss 1.9307e+00, Data-loss 1.0717e-01                  , pde-loss 5.3558e+03, initc-loss 1.2832e+04                    bc_loss 4.7674e+01\n",
      "Epoch 45930, Training-Loss 2.0486e+00, Data-loss 8.9177e-02                  , pde-loss 6.5108e+03, initc-loss 1.3020e+04                    bc_loss 6.2532e+01\n",
      "Epoch 45940, Training-Loss 2.2350e+00, Data-loss 2.2786e-01                  , pde-loss 7.0603e+03, initc-loss 1.2930e+04                    bc_loss 8.0921e+01\n",
      "Epoch 45950, Training-Loss 1.9635e+00, Data-loss 1.2262e-01                  , pde-loss 5.4456e+03, initc-loss 1.2904e+04                    bc_loss 5.8974e+01\n",
      "Epoch 45960, Training-Loss 1.9517e+00, Data-loss 4.8525e-02                  , pde-loss 6.1557e+03, initc-loss 1.2799e+04                    bc_loss 7.7613e+01\n",
      "Epoch 45970, Training-Loss 1.9793e+00, Data-loss 9.7973e-02                  , pde-loss 5.7986e+03, initc-loss 1.2923e+04                    bc_loss 9.1218e+01\n",
      "Epoch 45980, Training-Loss 1.9421e+00, Data-loss 6.8887e-02                  , pde-loss 5.7548e+03, initc-loss 1.2881e+04                    bc_loss 9.6421e+01\n",
      "Epoch 45990, Training-Loss 1.9230e+00, Data-loss 8.1733e-02                  , pde-loss 5.4018e+03, initc-loss 1.2893e+04                    bc_loss 1.1766e+02\n",
      "Epoch 46000, Training-Loss 2.0540e+00, Data-loss 1.8232e-01                  , pde-loss 5.7819e+03, initc-loss 1.2914e+04                    bc_loss 2.1236e+01\n",
      "Epoch 46010, Training-Loss 1.9983e+00, Data-loss 1.0435e-01                  , pde-loss 5.8505e+03, initc-loss 1.2842e+04                    bc_loss 2.4677e+02\n",
      "Epoch 46020, Training-Loss 1.8943e+00, Data-loss 5.5193e-02                  , pde-loss 5.4761e+03, initc-loss 1.2878e+04                    bc_loss 3.7777e+01\n",
      "Epoch 46030, Training-Loss 1.9499e+00, Data-loss 8.3700e-02                  , pde-loss 5.7229e+03, initc-loss 1.2891e+04                    bc_loss 4.8527e+01\n",
      "Epoch 46040, Training-Loss 1.9612e+00, Data-loss 7.2852e-02                  , pde-loss 5.9360e+03, initc-loss 1.2858e+04                    bc_loss 8.9072e+01\n",
      "Epoch 46050, Training-Loss 1.9342e+00, Data-loss 1.2114e-01                  , pde-loss 5.0585e+03, initc-loss 1.2918e+04                    bc_loss 1.5384e+02\n",
      "Epoch 46060, Training-Loss 1.9730e+00, Data-loss 1.0566e-01                  , pde-loss 5.7418e+03, initc-loss 1.2785e+04                    bc_loss 1.4716e+02\n",
      "Epoch 46070, Training-Loss 1.9276e+00, Data-loss 9.7872e-02                  , pde-loss 5.3521e+03, initc-loss 1.2908e+04                    bc_loss 3.7840e+01\n",
      "Epoch 46080, Training-Loss 2.0131e+00, Data-loss 1.3298e-01                  , pde-loss 5.8085e+03, initc-loss 1.2916e+04                    bc_loss 7.6666e+01\n",
      "Epoch 46090, Training-Loss 1.9632e+00, Data-loss 5.8669e-02                  , pde-loss 6.1234e+03, initc-loss 1.2874e+04                    bc_loss 4.8351e+01\n",
      "Epoch 46100, Training-Loss 1.9726e+00, Data-loss 1.4560e-01                  , pde-loss 5.2935e+03, initc-loss 1.2918e+04                    bc_loss 5.7717e+01\n",
      "Epoch 46110, Training-Loss 2.0614e+00, Data-loss 6.3678e-02                  , pde-loss 6.9199e+03, initc-loss 1.2987e+04                    bc_loss 7.0115e+01\n",
      "Epoch 46120, Training-Loss 1.9830e+00, Data-loss 9.7938e-02                  , pde-loss 5.8680e+03, initc-loss 1.2885e+04                    bc_loss 9.7732e+01\n",
      "Epoch 46130, Training-Loss 1.9528e+00, Data-loss 5.9277e-02                  , pde-loss 5.9973e+03, initc-loss 1.2866e+04                    bc_loss 7.1972e+01\n",
      "Epoch 46140, Training-Loss 1.9788e+00, Data-loss 7.2581e-02                  , pde-loss 6.1469e+03, initc-loss 1.2858e+04                    bc_loss 5.7238e+01\n",
      "Epoch 46150, Training-Loss 2.1005e+00, Data-loss 9.4058e-02                  , pde-loss 7.1177e+03, initc-loss 1.2912e+04                    bc_loss 3.3978e+01\n",
      "Epoch 46160, Training-Loss 1.9401e+00, Data-loss 1.2514e-01                  , pde-loss 5.1192e+03, initc-loss 1.2929e+04                    bc_loss 1.0142e+02\n",
      "Epoch 46170, Training-Loss 2.0806e+00, Data-loss 1.2821e-01                  , pde-loss 6.4549e+03, initc-loss 1.2926e+04                    bc_loss 1.4333e+02\n",
      "Epoch 46180, Training-Loss 2.0314e+00, Data-loss 1.3986e-01                  , pde-loss 5.7533e+03, initc-loss 1.2844e+04                    bc_loss 3.1769e+02\n",
      "Epoch 46190, Training-Loss 1.9882e+00, Data-loss 1.5557e-01                  , pde-loss 5.0470e+03, initc-loss 1.2890e+04                    bc_loss 3.8915e+02\n",
      "Epoch 46200, Training-Loss 1.8597e+00, Data-loss 7.9340e-02                  , pde-loss 4.9142e+03, initc-loss 1.2826e+04                    bc_loss 6.3566e+01\n",
      "Epoch 46210, Training-Loss 1.8819e+00, Data-loss 4.9451e-02                  , pde-loss 5.3337e+03, initc-loss 1.2870e+04                    bc_loss 1.1989e+02\n",
      "Epoch 46220, Training-Loss 2.0496e+00, Data-loss 8.8818e-02                  , pde-loss 6.6110e+03, initc-loss 1.2908e+04                    bc_loss 8.9214e+01\n",
      "Epoch 46230, Training-Loss 1.8775e+00, Data-loss 6.2976e-02                  , pde-loss 5.1223e+03, initc-loss 1.2856e+04                    bc_loss 1.6758e+02\n",
      "Epoch 46240, Training-Loss 2.0213e+00, Data-loss 1.5669e-01                  , pde-loss 5.6790e+03, initc-loss 1.2862e+04                    bc_loss 1.0507e+02\n",
      "Epoch 46250, Training-Loss 2.0009e+00, Data-loss 7.9033e-02                  , pde-loss 6.3248e+03, initc-loss 1.2849e+04                    bc_loss 4.5621e+01\n",
      "Epoch 46260, Training-Loss 1.9915e+00, Data-loss 1.4740e-01                  , pde-loss 5.4480e+03, initc-loss 1.2929e+04                    bc_loss 6.3923e+01\n",
      "Epoch 46270, Training-Loss 1.8968e+00, Data-loss 6.8583e-02                  , pde-loss 5.2203e+03, initc-loss 1.2875e+04                    bc_loss 1.8699e+02\n",
      "Epoch 46280, Training-Loss 2.0423e+00, Data-loss 1.5513e-01                  , pde-loss 5.7931e+03, initc-loss 1.2920e+04                    bc_loss 1.5923e+02\n",
      "Epoch 46290, Training-Loss 1.8890e+00, Data-loss 6.1462e-02                  , pde-loss 5.3402e+03, initc-loss 1.2890e+04                    bc_loss 4.5081e+01\n",
      "Epoch 46300, Training-Loss 1.9103e+00, Data-loss 7.7813e-02                  , pde-loss 5.4031e+03, initc-loss 1.2867e+04                    bc_loss 5.4206e+01\n",
      "Epoch 46310, Training-Loss 2.0272e+00, Data-loss 1.3546e-01                  , pde-loss 5.9666e+03, initc-loss 1.2859e+04                    bc_loss 9.1575e+01\n",
      "Epoch 46320, Training-Loss 1.9092e+00, Data-loss 7.1701e-02                  , pde-loss 5.4740e+03, initc-loss 1.2831e+04                    bc_loss 6.9795e+01\n",
      "Epoch 46330, Training-Loss 1.9131e+00, Data-loss 1.0703e-01                  , pde-loss 5.1130e+03, initc-loss 1.2869e+04                    bc_loss 7.9509e+01\n",
      "Epoch 46340, Training-Loss 1.8699e+00, Data-loss 7.9031e-02                  , pde-loss 4.9403e+03, initc-loss 1.2879e+04                    bc_loss 8.9641e+01\n",
      "Epoch 46350, Training-Loss 1.9487e+00, Data-loss 8.2392e-02                  , pde-loss 5.6884e+03, initc-loss 1.2919e+04                    bc_loss 5.5663e+01\n",
      "Epoch 46360, Training-Loss 1.9521e+00, Data-loss 8.9222e-02                  , pde-loss 5.6132e+03, initc-loss 1.2871e+04                    bc_loss 1.4487e+02\n",
      "Epoch 46370, Training-Loss 2.0753e+00, Data-loss 2.2046e-01                  , pde-loss 5.4946e+03, initc-loss 1.3006e+04                    bc_loss 4.7778e+01\n",
      "Epoch 46380, Training-Loss 2.0316e+00, Data-loss 1.3748e-01                  , pde-loss 5.9102e+03, initc-loss 1.2928e+04                    bc_loss 1.0304e+02\n",
      "Epoch 46390, Training-Loss 2.0124e+00, Data-loss 1.3373e-01                  , pde-loss 5.4158e+03, initc-loss 1.2956e+04                    bc_loss 4.1549e+02\n",
      "Epoch 46400, Training-Loss 1.9533e+00, Data-loss 7.3936e-02                  , pde-loss 5.7853e+03, initc-loss 1.2886e+04                    bc_loss 1.2330e+02\n",
      "Epoch 46410, Training-Loss 1.8489e+00, Data-loss 5.0752e-02                  , pde-loss 5.1309e+03, initc-loss 1.2823e+04                    bc_loss 2.7765e+01\n",
      "Epoch 46420, Training-Loss 1.9567e+00, Data-loss 1.1363e-01                  , pde-loss 5.4837e+03, initc-loss 1.2902e+04                    bc_loss 4.4445e+01\n",
      "Epoch 46430, Training-Loss 1.9835e+00, Data-loss 9.6884e-02                  , pde-loss 5.8536e+03, initc-loss 1.2888e+04                    bc_loss 1.2490e+02\n",
      "Epoch 46440, Training-Loss 1.9524e+00, Data-loss 8.1609e-02                  , pde-loss 5.7847e+03, initc-loss 1.2891e+04                    bc_loss 3.2328e+01\n",
      "Epoch 46450, Training-Loss 1.9677e+00, Data-loss 8.7500e-02                  , pde-loss 5.8014e+03, initc-loss 1.2890e+04                    bc_loss 1.1115e+02\n",
      "Epoch 46460, Training-Loss 2.0001e+00, Data-loss 1.1300e-01                  , pde-loss 5.8120e+03, initc-loss 1.2881e+04                    bc_loss 1.7784e+02\n",
      "Epoch 46470, Training-Loss 2.0290e+00, Data-loss 1.5997e-01                  , pde-loss 5.6607e+03, initc-loss 1.2820e+04                    bc_loss 2.0948e+02\n",
      "Epoch 46480, Training-Loss 2.1517e+00, Data-loss 2.4009e-01                  , pde-loss 6.0871e+03, initc-loss 1.2837e+04                    bc_loss 1.9159e+02\n",
      "Epoch 46490, Training-Loss 1.9717e+00, Data-loss 1.2535e-01                  , pde-loss 5.5913e+03, initc-loss 1.2831e+04                    bc_loss 4.2128e+01\n",
      "Epoch 46500, Training-Loss 2.0635e+00, Data-loss 1.4065e-01                  , pde-loss 6.2596e+03, initc-loss 1.2895e+04                    bc_loss 7.3882e+01\n",
      "Epoch 46510, Training-Loss 2.0940e+00, Data-loss 1.7574e-01                  , pde-loss 6.1053e+03, initc-loss 1.2967e+04                    bc_loss 1.1022e+02\n",
      "Epoch 46520, Training-Loss 1.8663e+00, Data-loss 8.3623e-02                  , pde-loss 4.7996e+03, initc-loss 1.2937e+04                    bc_loss 9.0435e+01\n",
      "Epoch 46530, Training-Loss 2.0623e+00, Data-loss 1.1995e-01                  , pde-loss 6.4422e+03, initc-loss 1.2876e+04                    bc_loss 1.0587e+02\n",
      "Epoch 46540, Training-Loss 2.3081e+00, Data-loss 2.7496e-01                  , pde-loss 7.2284e+03, initc-loss 1.2821e+04                    bc_loss 2.8216e+02\n",
      "Epoch 46550, Training-Loss 1.9781e+00, Data-loss 9.2281e-02                  , pde-loss 5.9194e+03, initc-loss 1.2871e+04                    bc_loss 6.8669e+01\n",
      "Epoch 46560, Training-Loss 1.9892e+00, Data-loss 7.5245e-02                  , pde-loss 6.2197e+03, initc-loss 1.2841e+04                    bc_loss 7.8138e+01\n",
      "Epoch 46570, Training-Loss 2.0882e+00, Data-loss 1.2245e-01                  , pde-loss 6.7054e+03, initc-loss 1.2897e+04                    bc_loss 5.5064e+01\n",
      "Epoch 46580, Training-Loss 2.0921e+00, Data-loss 1.4258e-01                  , pde-loss 6.4577e+03, initc-loss 1.2959e+04                    bc_loss 7.8583e+01\n",
      "Epoch 46590, Training-Loss 1.9600e+00, Data-loss 9.6459e-02                  , pde-loss 5.6089e+03, initc-loss 1.2938e+04                    bc_loss 8.8889e+01\n",
      "Epoch 46600, Training-Loss 1.8811e+00, Data-loss 7.3685e-02                  , pde-loss 5.0221e+03, initc-loss 1.2922e+04                    bc_loss 1.3000e+02\n",
      "Epoch 46610, Training-Loss 2.0311e+00, Data-loss 1.0936e-01                  , pde-loss 6.2596e+03, initc-loss 1.2921e+04                    bc_loss 3.6079e+01\n",
      "Epoch 46620, Training-Loss 1.9218e+00, Data-loss 5.4506e-02                  , pde-loss 5.7022e+03, initc-loss 1.2910e+04                    bc_loss 6.1595e+01\n",
      "Epoch 46630, Training-Loss 1.9180e+00, Data-loss 4.5064e-02                  , pde-loss 5.8408e+03, initc-loss 1.2869e+04                    bc_loss 2.0123e+01\n",
      "Epoch 46640, Training-Loss 1.9874e+00, Data-loss 7.6940e-02                  , pde-loss 6.1600e+03, initc-loss 1.2921e+04                    bc_loss 2.3769e+01\n",
      "Epoch 46650, Training-Loss 1.9952e+00, Data-loss 1.0706e-01                  , pde-loss 5.8099e+03, initc-loss 1.2956e+04                    bc_loss 1.1558e+02\n",
      "Epoch 46660, Training-Loss 1.9144e+00, Data-loss 4.2708e-02                  , pde-loss 5.6794e+03, initc-loss 1.2952e+04                    bc_loss 8.6108e+01\n",
      "Epoch 46670, Training-Loss 1.9943e+00, Data-loss 1.3903e-01                  , pde-loss 5.4591e+03, initc-loss 1.2849e+04                    bc_loss 2.4515e+02\n",
      "Epoch 46680, Training-Loss 2.0868e+00, Data-loss 1.8976e-01                  , pde-loss 6.0087e+03, initc-loss 1.2868e+04                    bc_loss 9.4248e+01\n",
      "Epoch 46690, Training-Loss 1.9177e+00, Data-loss 9.9897e-02                  , pde-loss 5.2025e+03, initc-loss 1.2936e+04                    bc_loss 3.9439e+01\n",
      "Epoch 46700, Training-Loss 1.9883e+00, Data-loss 1.2669e-01                  , pde-loss 5.3381e+03, initc-loss 1.2975e+04                    bc_loss 3.0271e+02\n",
      "Epoch 46710, Training-Loss 1.9263e+00, Data-loss 6.5490e-02                  , pde-loss 5.5448e+03, initc-loss 1.2930e+04                    bc_loss 1.3346e+02\n",
      "Epoch 46720, Training-Loss 2.0694e+00, Data-loss 1.5027e-01                  , pde-loss 6.3475e+03, initc-loss 1.2823e+04                    bc_loss 2.1101e+01\n",
      "Epoch 46730, Training-Loss 2.0419e+00, Data-loss 1.3760e-01                  , pde-loss 6.1874e+03, initc-loss 1.2809e+04                    bc_loss 4.5814e+01\n",
      "Epoch 46740, Training-Loss 1.8464e+00, Data-loss 5.5262e-02                  , pde-loss 4.9831e+03, initc-loss 1.2810e+04                    bc_loss 1.1843e+02\n",
      "Epoch 46750, Training-Loss 2.0973e+00, Data-loss 9.7455e-02                  , pde-loss 7.0646e+03, initc-loss 1.2855e+04                    bc_loss 7.8412e+01\n",
      "Epoch 46760, Training-Loss 2.1164e+00, Data-loss 1.5296e-01                  , pde-loss 6.4891e+03, initc-loss 1.2889e+04                    bc_loss 2.5687e+02\n",
      "Epoch 46770, Training-Loss 1.9691e+00, Data-loss 9.2459e-02                  , pde-loss 5.7591e+03, initc-loss 1.2940e+04                    bc_loss 6.7889e+01\n",
      "Epoch 46780, Training-Loss 2.0400e+00, Data-loss 1.1003e-01                  , pde-loss 6.1817e+03, initc-loss 1.2867e+04                    bc_loss 2.5049e+02\n",
      "Epoch 46790, Training-Loss 2.1687e+00, Data-loss 2.3682e-01                  , pde-loss 6.4249e+03, initc-loss 1.2817e+04                    bc_loss 7.7059e+01\n",
      "Epoch 46800, Training-Loss 1.9696e+00, Data-loss 9.2526e-02                  , pde-loss 5.6872e+03, initc-loss 1.2951e+04                    bc_loss 1.3323e+02\n",
      "Epoch 46810, Training-Loss 2.1020e+00, Data-loss 1.4655e-01                  , pde-loss 6.4222e+03, initc-loss 1.2855e+04                    bc_loss 2.7744e+02\n",
      "Epoch 46820, Training-Loss 2.0306e+00, Data-loss 6.0115e-02                  , pde-loss 6.6874e+03, initc-loss 1.2904e+04                    bc_loss 1.1363e+02\n",
      "Epoch 46830, Training-Loss 1.9008e+00, Data-loss 6.5651e-02                  , pde-loss 5.4016e+03, initc-loss 1.2881e+04                    bc_loss 6.9156e+01\n",
      "Epoch 46840, Training-Loss 1.9673e+00, Data-loss 5.6709e-02                  , pde-loss 6.1821e+03, initc-loss 1.2891e+04                    bc_loss 3.3110e+01\n",
      "Epoch 46850, Training-Loss 1.9849e+00, Data-loss 6.3771e-02                  , pde-loss 6.1799e+03, initc-loss 1.2864e+04                    bc_loss 1.6772e+02\n",
      "Epoch 46860, Training-Loss 2.0407e+00, Data-loss 1.4364e-01                  , pde-loss 5.8869e+03, initc-loss 1.2967e+04                    bc_loss 1.1620e+02\n",
      "Epoch 46870, Training-Loss 1.9565e+00, Data-loss 8.8714e-02                  , pde-loss 5.7648e+03, initc-loss 1.2880e+04                    bc_loss 3.2483e+01\n",
      "Epoch 46880, Training-Loss 2.1265e+00, Data-loss 1.9353e-01                  , pde-loss 6.4112e+03, initc-loss 1.2858e+04                    bc_loss 6.1121e+01\n",
      "Epoch 46890, Training-Loss 1.9149e+00, Data-loss 5.9044e-02                  , pde-loss 5.5094e+03, initc-loss 1.2883e+04                    bc_loss 1.6611e+02\n",
      "Epoch 46900, Training-Loss 1.8649e+00, Data-loss 6.6908e-02                  , pde-loss 4.9603e+03, initc-loss 1.2927e+04                    bc_loss 9.2404e+01\n",
      "Epoch 46910, Training-Loss 2.0156e+00, Data-loss 1.7072e-01                  , pde-loss 5.0317e+03, initc-loss 1.2811e+04                    bc_loss 6.0618e+02\n",
      "Epoch 46920, Training-Loss 2.0009e+00, Data-loss 8.9566e-02                  , pde-loss 6.0819e+03, initc-loss 1.2944e+04                    bc_loss 8.6969e+01\n",
      "Epoch 46930, Training-Loss 1.9302e+00, Data-loss 8.6235e-02                  , pde-loss 5.4416e+03, initc-loss 1.2939e+04                    bc_loss 5.8449e+01\n",
      "Epoch 46940, Training-Loss 2.0007e+00, Data-loss 6.7160e-02                  , pde-loss 6.3366e+03, initc-loss 1.2943e+04                    bc_loss 5.5642e+01\n",
      "Epoch 46950, Training-Loss 2.0026e+00, Data-loss 1.4372e-01                  , pde-loss 5.6418e+03, initc-loss 1.2900e+04                    bc_loss 4.6388e+01\n",
      "Epoch 46960, Training-Loss 2.0231e+00, Data-loss 7.4430e-02                  , pde-loss 6.4981e+03, initc-loss 1.2914e+04                    bc_loss 7.4613e+01\n",
      "Epoch 46970, Training-Loss 2.0724e+00, Data-loss 1.0845e-01                  , pde-loss 6.6208e+03, initc-loss 1.2885e+04                    bc_loss 1.3349e+02\n",
      "Epoch 46980, Training-Loss 2.0095e+00, Data-loss 1.1286e-01                  , pde-loss 6.0719e+03, initc-loss 1.2880e+04                    bc_loss 1.4941e+01\n",
      "Epoch 46990, Training-Loss 2.0309e+00, Data-loss 1.3434e-01                  , pde-loss 5.9248e+03, initc-loss 1.2919e+04                    bc_loss 1.2146e+02\n",
      "Epoch 47000, Training-Loss 1.8143e+00, Data-loss 4.7416e-02                  , pde-loss 4.7831e+03, initc-loss 1.2838e+04                    bc_loss 4.7932e+01\n",
      "Epoch 47010, Training-Loss 1.8749e+00, Data-loss 6.8735e-02                  , pde-loss 5.1193e+03, initc-loss 1.2879e+04                    bc_loss 6.3717e+01\n",
      "Epoch 47020, Training-Loss 1.9272e+00, Data-loss 9.1629e-02                  , pde-loss 5.4380e+03, initc-loss 1.2861e+04                    bc_loss 5.6868e+01\n",
      "Epoch 47030, Training-Loss 1.9839e+00, Data-loss 7.1620e-02                  , pde-loss 6.1362e+03, initc-loss 1.2886e+04                    bc_loss 9.9976e+01\n",
      "Epoch 47040, Training-Loss 1.9247e+00, Data-loss 8.2706e-02                  , pde-loss 5.5099e+03, initc-loss 1.2858e+04                    bc_loss 5.1896e+01\n",
      "Epoch 47050, Training-Loss 2.0208e+00, Data-loss 1.3098e-01                  , pde-loss 5.7278e+03, initc-loss 1.2922e+04                    bc_loss 2.4773e+02\n",
      "Epoch 47060, Training-Loss 1.9682e+00, Data-loss 7.4791e-02                  , pde-loss 5.9755e+03, initc-loss 1.2882e+04                    bc_loss 7.6473e+01\n",
      "Epoch 47070, Training-Loss 2.0022e+00, Data-loss 6.1755e-02                  , pde-loss 6.3505e+03, initc-loss 1.2872e+04                    bc_loss 1.8213e+02\n",
      "Epoch 47080, Training-Loss 1.9140e+00, Data-loss 5.2390e-02                  , pde-loss 5.7428e+03, initc-loss 1.2817e+04                    bc_loss 5.6629e+01\n",
      "Epoch 47090, Training-Loss 1.9010e+00, Data-loss 5.6603e-02                  , pde-loss 5.4593e+03, initc-loss 1.2920e+04                    bc_loss 6.4529e+01\n",
      "Epoch 47100, Training-Loss 1.9820e+00, Data-loss 8.7046e-02                  , pde-loss 6.0473e+03, initc-loss 1.2832e+04                    bc_loss 6.9866e+01\n",
      "Epoch 47110, Training-Loss 1.9597e+00, Data-loss 1.0868e-01                  , pde-loss 5.5713e+03, initc-loss 1.2890e+04                    bc_loss 4.7960e+01\n",
      "Epoch 47120, Training-Loss 1.8633e+00, Data-loss 5.8847e-02                  , pde-loss 5.1102e+03, initc-loss 1.2899e+04                    bc_loss 3.5512e+01\n",
      "Epoch 47130, Training-Loss 1.8642e+00, Data-loss 6.3753e-02                  , pde-loss 5.0533e+03, initc-loss 1.2916e+04                    bc_loss 3.4412e+01\n",
      "Epoch 47140, Training-Loss 1.9293e+00, Data-loss 8.7174e-02                  , pde-loss 5.5190e+03, initc-loss 1.2883e+04                    bc_loss 1.9451e+01\n",
      "Epoch 47150, Training-Loss 1.9336e+00, Data-loss 1.1024e-01                  , pde-loss 5.0893e+03, initc-loss 1.2886e+04                    bc_loss 2.5849e+02\n",
      "Epoch 47160, Training-Loss 1.9641e+00, Data-loss 9.5296e-02                  , pde-loss 5.6158e+03, initc-loss 1.2977e+04                    bc_loss 9.5302e+01\n",
      "Epoch 47170, Training-Loss 2.3335e+00, Data-loss 3.1986e-01                  , pde-loss 6.7123e+03, initc-loss 1.2956e+04                    bc_loss 4.6767e+02\n",
      "Epoch 47180, Training-Loss 2.1087e+00, Data-loss 1.5462e-01                  , pde-loss 6.4597e+03, initc-loss 1.2992e+04                    bc_loss 8.9538e+01\n",
      "Epoch 47190, Training-Loss 1.9380e+00, Data-loss 9.7239e-02                  , pde-loss 5.5620e+03, initc-loss 1.2817e+04                    bc_loss 2.8119e+01\n",
      "Epoch 47200, Training-Loss 1.8957e+00, Data-loss 9.7036e-02                  , pde-loss 4.9910e+03, initc-loss 1.2923e+04                    bc_loss 7.2218e+01\n",
      "Epoch 47210, Training-Loss 2.0272e+00, Data-loss 1.1147e-01                  , pde-loss 6.1546e+03, initc-loss 1.2870e+04                    bc_loss 1.3235e+02\n",
      "Epoch 47220, Training-Loss 2.2078e+00, Data-loss 2.5248e-01                  , pde-loss 6.3566e+03, initc-loss 1.2855e+04                    bc_loss 3.4129e+02\n",
      "Epoch 47230, Training-Loss 2.1282e+00, Data-loss 2.1286e-01                  , pde-loss 6.0702e+03, initc-loss 1.2837e+04                    bc_loss 2.4578e+02\n",
      "Epoch 47240, Training-Loss 1.9381e+00, Data-loss 1.0195e-01                  , pde-loss 5.3163e+03, initc-loss 1.2902e+04                    bc_loss 1.4321e+02\n",
      "Epoch 47250, Training-Loss 1.8898e+00, Data-loss 5.7143e-02                  , pde-loss 4.9214e+03, initc-loss 1.2902e+04                    bc_loss 5.0401e+02\n",
      "Epoch 47260, Training-Loss 2.0251e+00, Data-loss 1.3617e-01                  , pde-loss 6.0256e+03, initc-loss 1.2834e+04                    bc_loss 2.9767e+01\n",
      "Epoch 47270, Training-Loss 2.0123e+00, Data-loss 1.2604e-01                  , pde-loss 5.8522e+03, initc-loss 1.2964e+04                    bc_loss 4.5931e+01\n",
      "Epoch 47280, Training-Loss 1.9472e+00, Data-loss 1.1281e-01                  , pde-loss 5.4158e+03, initc-loss 1.2890e+04                    bc_loss 3.8323e+01\n",
      "Epoch 47290, Training-Loss 1.8904e+00, Data-loss 7.8146e-02                  , pde-loss 5.2123e+03, initc-loss 1.2824e+04                    bc_loss 8.6886e+01\n",
      "Epoch 47300, Training-Loss 1.8679e+00, Data-loss 5.7497e-02                  , pde-loss 5.0807e+03, initc-loss 1.2923e+04                    bc_loss 9.9633e+01\n",
      "Epoch 47310, Training-Loss 1.9268e+00, Data-loss 6.7935e-02                  , pde-loss 5.6482e+03, initc-loss 1.2824e+04                    bc_loss 1.1636e+02\n",
      "Epoch 47320, Training-Loss 2.0105e+00, Data-loss 1.5834e-01                  , pde-loss 5.5933e+03, initc-loss 1.2905e+04                    bc_loss 2.3169e+01\n",
      "Epoch 47330, Training-Loss 2.0030e+00, Data-loss 9.6195e-02                  , pde-loss 6.0860e+03, initc-loss 1.2920e+04                    bc_loss 6.1567e+01\n",
      "Epoch 47340, Training-Loss 1.9886e+00, Data-loss 1.0039e-01                  , pde-loss 5.9229e+03, initc-loss 1.2915e+04                    bc_loss 4.4519e+01\n",
      "Epoch 47350, Training-Loss 2.0276e+00, Data-loss 8.0799e-02                  , pde-loss 6.4492e+03, initc-loss 1.2904e+04                    bc_loss 1.1425e+02\n",
      "Epoch 47360, Training-Loss 1.9931e+00, Data-loss 1.0281e-01                  , pde-loss 5.8879e+03, initc-loss 1.2845e+04                    bc_loss 1.6990e+02\n",
      "Epoch 47370, Training-Loss 1.8903e+00, Data-loss 5.1715e-02                  , pde-loss 5.3952e+03, initc-loss 1.2876e+04                    bc_loss 1.1517e+02\n",
      "Epoch 47380, Training-Loss 1.8964e+00, Data-loss 5.6372e-02                  , pde-loss 5.4672e+03, initc-loss 1.2850e+04                    bc_loss 8.2686e+01\n",
      "Epoch 47390, Training-Loss 1.9578e+00, Data-loss 6.2697e-02                  , pde-loss 6.0156e+03, initc-loss 1.2890e+04                    bc_loss 4.5647e+01\n",
      "Epoch 47400, Training-Loss 1.7720e+00, Data-loss 3.5859e-02                  , pde-loss 4.5023e+03, initc-loss 1.2846e+04                    bc_loss 1.3169e+01\n",
      "Epoch 47410, Training-Loss 1.9558e+00, Data-loss 6.1514e-02                  , pde-loss 5.9973e+03, initc-loss 1.2835e+04                    bc_loss 1.1053e+02\n",
      "Epoch 47420, Training-Loss 1.8954e+00, Data-loss 5.1760e-02                  , pde-loss 5.5152e+03, initc-loss 1.2899e+04                    bc_loss 2.2167e+01\n",
      "Epoch 47430, Training-Loss 1.9445e+00, Data-loss 8.1528e-02                  , pde-loss 5.6627e+03, initc-loss 1.2912e+04                    bc_loss 5.5148e+01\n",
      "Epoch 47440, Training-Loss 1.9625e+00, Data-loss 8.8943e-02                  , pde-loss 5.7733e+03, initc-loss 1.2927e+04                    bc_loss 3.5112e+01\n",
      "Epoch 47450, Training-Loss 1.9262e+00, Data-loss 4.4942e-02                  , pde-loss 5.8855e+03, initc-loss 1.2895e+04                    bc_loss 3.1997e+01\n",
      "Epoch 47460, Training-Loss 2.0105e+00, Data-loss 5.6465e-02                  , pde-loss 6.5862e+03, initc-loss 1.2905e+04                    bc_loss 4.8939e+01\n",
      "Epoch 47470, Training-Loss 1.9345e+00, Data-loss 8.6969e-02                  , pde-loss 5.5768e+03, initc-loss 1.2847e+04                    bc_loss 5.1508e+01\n",
      "Epoch 47480, Training-Loss 1.9179e+00, Data-loss 1.4266e-01                  , pde-loss 4.8641e+03, initc-loss 1.2805e+04                    bc_loss 8.3478e+01\n",
      "Epoch 47490, Training-Loss 1.9754e+00, Data-loss 4.7608e-02                  , pde-loss 6.2525e+03, initc-loss 1.2902e+04                    bc_loss 1.2299e+02\n",
      "Epoch 47500, Training-Loss 2.1779e+00, Data-loss 2.5485e-01                  , pde-loss 5.9329e+03, initc-loss 1.3011e+04                    bc_loss 2.8676e+02\n",
      "Epoch 47510, Training-Loss 1.8872e+00, Data-loss 7.6653e-02                  , pde-loss 5.0957e+03, initc-loss 1.2971e+04                    bc_loss 3.8928e+01\n",
      "Epoch 47520, Training-Loss 2.1804e+00, Data-loss 2.4381e-01                  , pde-loss 6.3587e+03, initc-loss 1.2865e+04                    bc_loss 1.4248e+02\n",
      "Epoch 47530, Training-Loss 1.9345e+00, Data-loss 1.0103e-01                  , pde-loss 5.4621e+03, initc-loss 1.2840e+04                    bc_loss 3.3166e+01\n",
      "Epoch 47540, Training-Loss 1.9560e+00, Data-loss 6.8814e-02                  , pde-loss 5.8878e+03, initc-loss 1.2821e+04                    bc_loss 1.6270e+02\n",
      "Epoch 47550, Training-Loss 1.9344e+00, Data-loss 8.6702e-02                  , pde-loss 5.4602e+03, initc-loss 1.2869e+04                    bc_loss 1.4791e+02\n",
      "Epoch 47560, Training-Loss 1.9629e+00, Data-loss 1.0137e-01                  , pde-loss 5.5305e+03, initc-loss 1.2981e+04                    bc_loss 1.0371e+02\n",
      "Epoch 47570, Training-Loss 1.9583e+00, Data-loss 8.2504e-02                  , pde-loss 5.8405e+03, initc-loss 1.2880e+04                    bc_loss 3.6993e+01\n",
      "Epoch 47580, Training-Loss 2.0521e+00, Data-loss 1.4666e-01                  , pde-loss 6.0943e+03, initc-loss 1.2934e+04                    bc_loss 2.5954e+01\n",
      "Epoch 47590, Training-Loss 1.9218e+00, Data-loss 6.5010e-02                  , pde-loss 5.4143e+03, initc-loss 1.2908e+04                    bc_loss 2.4553e+02\n",
      "Epoch 47600, Training-Loss 1.9268e+00, Data-loss 9.1858e-02                  , pde-loss 5.3392e+03, initc-loss 1.2877e+04                    bc_loss 1.3319e+02\n",
      "Epoch 47610, Training-Loss 2.0109e+00, Data-loss 1.0871e-01                  , pde-loss 5.7246e+03, initc-loss 1.2912e+04                    bc_loss 3.8580e+02\n",
      "Epoch 47620, Training-Loss 1.9824e+00, Data-loss 1.2158e-01                  , pde-loss 5.5620e+03, initc-loss 1.2871e+04                    bc_loss 1.7608e+02\n",
      "Epoch 47630, Training-Loss 1.9908e+00, Data-loss 1.3106e-01                  , pde-loss 5.5954e+03, initc-loss 1.2900e+04                    bc_loss 1.0178e+02\n",
      "Epoch 47640, Training-Loss 1.9817e+00, Data-loss 6.6866e-02                  , pde-loss 6.2176e+03, initc-loss 1.2862e+04                    bc_loss 6.8790e+01\n",
      "Epoch 47650, Training-Loss 2.1046e+00, Data-loss 1.0501e-01                  , pde-loss 7.1184e+03, initc-loss 1.2863e+04                    bc_loss 1.5225e+01\n",
      "Epoch 47660, Training-Loss 1.9827e+00, Data-loss 7.0717e-02                  , pde-loss 6.2210e+03, initc-loss 1.2874e+04                    bc_loss 2.4799e+01\n",
      "Epoch 47670, Training-Loss 1.9994e+00, Data-loss 1.1237e-01                  , pde-loss 6.0331e+03, initc-loss 1.2815e+04                    bc_loss 2.1504e+01\n",
      "Epoch 47680, Training-Loss 1.8938e+00, Data-loss 5.8348e-02                  , pde-loss 5.3834e+03, initc-loss 1.2910e+04                    bc_loss 6.0614e+01\n",
      "Epoch 47690, Training-Loss 2.1707e+00, Data-loss 2.6698e-01                  , pde-loss 5.9031e+03, initc-loss 1.2960e+04                    bc_loss 1.7392e+02\n",
      "Epoch 47700, Training-Loss 1.9157e+00, Data-loss 5.6533e-02                  , pde-loss 5.6133e+03, initc-loss 1.2908e+04                    bc_loss 6.9921e+01\n",
      "Epoch 47710, Training-Loss 2.0327e+00, Data-loss 9.3738e-02                  , pde-loss 6.3761e+03, initc-loss 1.2827e+04                    bc_loss 1.8638e+02\n",
      "Epoch 47720, Training-Loss 2.1159e+00, Data-loss 1.1855e-01                  , pde-loss 7.1010e+03, initc-loss 1.2775e+04                    bc_loss 9.6987e+01\n",
      "Epoch 47730, Training-Loss 1.9770e+00, Data-loss 1.0744e-01                  , pde-loss 5.6627e+03, initc-loss 1.2957e+04                    bc_loss 7.6092e+01\n",
      "Epoch 47740, Training-Loss 1.9091e+00, Data-loss 4.9894e-02                  , pde-loss 5.5994e+03, initc-loss 1.2934e+04                    bc_loss 5.8816e+01\n",
      "Epoch 47750, Training-Loss 1.9318e+00, Data-loss 6.5471e-02                  , pde-loss 5.7662e+03, initc-loss 1.2870e+04                    bc_loss 2.7165e+01\n",
      "Epoch 47760, Training-Loss 1.8819e+00, Data-loss 6.8646e-02                  , pde-loss 5.2402e+03, initc-loss 1.2840e+04                    bc_loss 5.1889e+01\n",
      "Epoch 47770, Training-Loss 1.9391e+00, Data-loss 4.2427e-02                  , pde-loss 6.0567e+03, initc-loss 1.2883e+04                    bc_loss 2.7363e+01\n",
      "Epoch 47780, Training-Loss 1.9934e+00, Data-loss 6.9625e-02                  , pde-loss 6.2909e+03, initc-loss 1.2913e+04                    bc_loss 3.3676e+01\n",
      "Epoch 47790, Training-Loss 1.9629e+00, Data-loss 8.4813e-02                  , pde-loss 5.6226e+03, initc-loss 1.2942e+04                    bc_loss 2.1631e+02\n",
      "Epoch 47800, Training-Loss 2.0399e+00, Data-loss 6.2508e-02                  , pde-loss 6.8449e+03, initc-loss 1.2883e+04                    bc_loss 4.5785e+01\n",
      "Epoch 47810, Training-Loss 1.9610e+00, Data-loss 4.1346e-02                  , pde-loss 6.2795e+03, initc-loss 1.2825e+04                    bc_loss 9.1927e+01\n",
      "Epoch 47820, Training-Loss 1.9993e+00, Data-loss 8.4535e-02                  , pde-loss 6.0744e+03, initc-loss 1.2985e+04                    bc_loss 8.7738e+01\n",
      "Epoch 47830, Training-Loss 1.9550e+00, Data-loss 5.3596e-02                  , pde-loss 5.9478e+03, initc-loss 1.2875e+04                    bc_loss 1.9147e+02\n",
      "Epoch 47840, Training-Loss 1.9479e+00, Data-loss 5.1248e-02                  , pde-loss 5.9269e+03, initc-loss 1.2946e+04                    bc_loss 9.3412e+01\n",
      "Epoch 47850, Training-Loss 1.9118e+00, Data-loss 6.8992e-02                  , pde-loss 5.4894e+03, initc-loss 1.2857e+04                    bc_loss 8.0799e+01\n",
      "Epoch 47860, Training-Loss 2.0799e+00, Data-loss 7.8250e-02                  , pde-loss 7.0677e+03, initc-loss 1.2786e+04                    bc_loss 1.6269e+02\n",
      "Epoch 47870, Training-Loss 1.9662e+00, Data-loss 6.1608e-02                  , pde-loss 6.1237e+03, initc-loss 1.2855e+04                    bc_loss 6.7150e+01\n",
      "Epoch 47880, Training-Loss 1.9181e+00, Data-loss 6.1705e-02                  , pde-loss 5.5681e+03, initc-loss 1.2941e+04                    bc_loss 5.4709e+01\n",
      "Epoch 47890, Training-Loss 1.9252e+00, Data-loss 8.4611e-02                  , pde-loss 5.3596e+03, initc-loss 1.2953e+04                    bc_loss 9.3027e+01\n",
      "Epoch 47900, Training-Loss 1.9931e+00, Data-loss 7.7047e-02                  , pde-loss 6.1727e+03, initc-loss 1.2940e+04                    bc_loss 4.8244e+01\n",
      "Epoch 47910, Training-Loss 2.0120e+00, Data-loss 8.8588e-02                  , pde-loss 6.3148e+03, initc-loss 1.2879e+04                    bc_loss 4.0394e+01\n",
      "Epoch 47920, Training-Loss 1.8446e+00, Data-loss 6.0516e-02                  , pde-loss 4.8913e+03, initc-loss 1.2828e+04                    bc_loss 1.2228e+02\n",
      "Epoch 47930, Training-Loss 1.8215e+00, Data-loss 3.6353e-02                  , pde-loss 4.9506e+03, initc-loss 1.2876e+04                    bc_loss 2.4558e+01\n",
      "Epoch 47940, Training-Loss 1.9045e+00, Data-loss 7.5910e-02                  , pde-loss 5.3365e+03, initc-loss 1.2875e+04                    bc_loss 7.4496e+01\n",
      "Epoch 47950, Training-Loss 1.9666e+00, Data-loss 8.9415e-02                  , pde-loss 5.6334e+03, initc-loss 1.2999e+04                    bc_loss 1.3923e+02\n",
      "Epoch 47960, Training-Loss 1.9985e+00, Data-loss 4.8141e-02                  , pde-loss 6.5318e+03, initc-loss 1.2891e+04                    bc_loss 8.1407e+01\n",
      "Epoch 47970, Training-Loss 1.9790e+00, Data-loss 7.8275e-02                  , pde-loss 6.0992e+03, initc-loss 1.2843e+04                    bc_loss 6.5610e+01\n",
      "Epoch 47980, Training-Loss 1.9934e+00, Data-loss 9.4957e-02                  , pde-loss 6.1188e+03, initc-loss 1.2833e+04                    bc_loss 3.2696e+01\n",
      "Epoch 47990, Training-Loss 1.9111e+00, Data-loss 7.0269e-02                  , pde-loss 5.4075e+03, initc-loss 1.2881e+04                    bc_loss 1.2011e+02\n",
      "Epoch 48000, Training-Loss 1.7889e+00, Data-loss 4.7284e-02                  , pde-loss 4.5047e+03, initc-loss 1.2880e+04                    bc_loss 3.1682e+01\n",
      "Epoch 48010, Training-Loss 2.1261e+00, Data-loss 1.8559e-01                  , pde-loss 6.2942e+03, initc-loss 1.2924e+04                    bc_loss 1.8744e+02\n",
      "Epoch 48020, Training-Loss 2.0722e+00, Data-loss 6.5473e-02                  , pde-loss 7.1064e+03, initc-loss 1.2915e+04                    bc_loss 4.5427e+01\n",
      "Epoch 48030, Training-Loss 2.0927e+00, Data-loss 1.7394e-01                  , pde-loss 6.2232e+03, initc-loss 1.2873e+04                    bc_loss 9.0717e+01\n",
      "Epoch 48040, Training-Loss 1.9719e+00, Data-loss 6.9901e-02                  , pde-loss 5.9149e+03, initc-loss 1.2933e+04                    bc_loss 1.7198e+02\n",
      "Epoch 48050, Training-Loss 1.9452e+00, Data-loss 9.1357e-02                  , pde-loss 5.6869e+03, initc-loss 1.2828e+04                    bc_loss 2.3287e+01\n",
      "Epoch 48060, Training-Loss 1.9520e+00, Data-loss 8.1187e-02                  , pde-loss 5.7982e+03, initc-loss 1.2780e+04                    bc_loss 1.2932e+02\n",
      "Epoch 48070, Training-Loss 1.9423e+00, Data-loss 1.0741e-01                  , pde-loss 5.4112e+03, initc-loss 1.2841e+04                    bc_loss 9.6647e+01\n",
      "Epoch 48080, Training-Loss 1.9660e+00, Data-loss 9.9548e-02                  , pde-loss 5.6731e+03, initc-loss 1.2905e+04                    bc_loss 8.6076e+01\n",
      "Epoch 48090, Training-Loss 2.0108e+00, Data-loss 1.4476e-01                  , pde-loss 5.7191e+03, initc-loss 1.2922e+04                    bc_loss 1.9492e+01\n",
      "Epoch 48100, Training-Loss 1.8897e+00, Data-loss 5.9055e-02                  , pde-loss 5.3640e+03, initc-loss 1.2889e+04                    bc_loss 5.3128e+01\n",
      "Epoch 48110, Training-Loss 1.8939e+00, Data-loss 7.9754e-02                  , pde-loss 5.1150e+03, initc-loss 1.2931e+04                    bc_loss 9.5471e+01\n",
      "Epoch 48120, Training-Loss 1.9667e+00, Data-loss 7.2549e-02                  , pde-loss 6.0177e+03, initc-loss 1.2863e+04                    bc_loss 6.0174e+01\n",
      "Epoch 48130, Training-Loss 1.9713e+00, Data-loss 7.4861e-02                  , pde-loss 5.7731e+03, initc-loss 1.2933e+04                    bc_loss 2.5844e+02\n",
      "Epoch 48140, Training-Loss 1.9415e+00, Data-loss 1.4501e-01                  , pde-loss 5.1170e+03, initc-loss 1.2828e+04                    bc_loss 1.9794e+01\n",
      "Epoch 48150, Training-Loss 1.9241e+00, Data-loss 6.0805e-02                  , pde-loss 5.7587e+03, initc-loss 1.2799e+04                    bc_loss 7.5469e+01\n",
      "Epoch 48160, Training-Loss 1.9690e+00, Data-loss 6.6387e-02                  , pde-loss 5.9327e+03, initc-loss 1.2922e+04                    bc_loss 1.7200e+02\n",
      "Epoch 48170, Training-Loss 1.8854e+00, Data-loss 6.9898e-02                  , pde-loss 5.1331e+03, initc-loss 1.2949e+04                    bc_loss 7.2884e+01\n",
      "Epoch 48180, Training-Loss 1.9801e+00, Data-loss 6.6878e-02                  , pde-loss 6.0595e+03, initc-loss 1.2994e+04                    bc_loss 7.8650e+01\n",
      "Epoch 48190, Training-Loss 2.0204e+00, Data-loss 9.3705e-02                  , pde-loss 6.3160e+03, initc-loss 1.2851e+04                    bc_loss 1.0012e+02\n",
      "Epoch 48200, Training-Loss 1.9354e+00, Data-loss 6.0162e-02                  , pde-loss 5.8203e+03, initc-loss 1.2883e+04                    bc_loss 4.9339e+01\n",
      "Epoch 48210, Training-Loss 1.8021e+00, Data-loss 5.1297e-02                  , pde-loss 4.5675e+03, initc-loss 1.2886e+04                    bc_loss 5.5075e+01\n",
      "Epoch 48220, Training-Loss 1.9635e+00, Data-loss 7.1794e-02                  , pde-loss 6.0026e+03, initc-loss 1.2905e+04                    bc_loss 1.0056e+01\n",
      "Epoch 48230, Training-Loss 2.0007e+00, Data-loss 6.0036e-02                  , pde-loss 6.3567e+03, initc-loss 1.2893e+04                    bc_loss 1.5719e+02\n",
      "Epoch 48240, Training-Loss 2.0130e+00, Data-loss 6.1304e-02                  , pde-loss 6.6140e+03, initc-loss 1.2863e+04                    bc_loss 4.0293e+01\n",
      "Epoch 48250, Training-Loss 2.1435e+00, Data-loss 2.0691e-01                  , pde-loss 6.4198e+03, initc-loss 1.2897e+04                    bc_loss 4.8541e+01\n",
      "Epoch 48260, Training-Loss 1.9450e+00, Data-loss 5.1024e-02                  , pde-loss 5.7951e+03, initc-loss 1.2881e+04                    bc_loss 2.6433e+02\n",
      "Epoch 48270, Training-Loss 1.9297e+00, Data-loss 8.6245e-02                  , pde-loss 5.4450e+03, initc-loss 1.2880e+04                    bc_loss 1.0912e+02\n",
      "Epoch 48280, Training-Loss 1.9035e+00, Data-loss 8.8381e-02                  , pde-loss 5.1156e+03, initc-loss 1.2858e+04                    bc_loss 1.7709e+02\n",
      "Epoch 48290, Training-Loss 2.0180e+00, Data-loss 1.0189e-01                  , pde-loss 6.1595e+03, initc-loss 1.2906e+04                    bc_loss 9.4778e+01\n",
      "Epoch 48300, Training-Loss 2.0097e+00, Data-loss 6.6042e-02                  , pde-loss 6.5574e+03, initc-loss 1.2858e+04                    bc_loss 2.0741e+01\n",
      "Epoch 48310, Training-Loss 2.0880e+00, Data-loss 1.2600e-01                  , pde-loss 6.6657e+03, initc-loss 1.2880e+04                    bc_loss 7.4179e+01\n",
      "Epoch 48320, Training-Loss 1.9666e+00, Data-loss 6.4068e-02                  , pde-loss 6.0814e+03, initc-loss 1.2898e+04                    bc_loss 4.5762e+01\n",
      "Epoch 48330, Training-Loss 1.9430e+00, Data-loss 5.1589e-02                  , pde-loss 5.9287e+03, initc-loss 1.2943e+04                    bc_loss 4.1794e+01\n",
      "Epoch 48340, Training-Loss 1.9507e+00, Data-loss 5.7667e-02                  , pde-loss 5.9948e+03, initc-loss 1.2876e+04                    bc_loss 5.9659e+01\n",
      "Epoch 48350, Training-Loss 1.9001e+00, Data-loss 1.1056e-01                  , pde-loss 5.0035e+03, initc-loss 1.2863e+04                    bc_loss 2.8381e+01\n",
      "Epoch 48360, Training-Loss 1.9036e+00, Data-loss 5.6640e-02                  , pde-loss 5.4546e+03, initc-loss 1.2937e+04                    bc_loss 7.8030e+01\n",
      "Epoch 48370, Training-Loss 1.9761e+00, Data-loss 1.5749e-01                  , pde-loss 5.1973e+03, initc-loss 1.2961e+04                    bc_loss 2.7597e+01\n",
      "Epoch 48380, Training-Loss 1.9198e+00, Data-loss 5.9938e-02                  , pde-loss 5.5945e+03, initc-loss 1.2909e+04                    bc_loss 9.4869e+01\n",
      "Epoch 48390, Training-Loss 1.9459e+00, Data-loss 1.0805e-01                  , pde-loss 5.2903e+03, initc-loss 1.2919e+04                    bc_loss 1.6911e+02\n",
      "Epoch 48400, Training-Loss 2.0433e+00, Data-loss 1.4122e-01                  , pde-loss 6.1160e+03, initc-loss 1.2821e+04                    bc_loss 8.4276e+01\n",
      "Epoch 48410, Training-Loss 2.0141e+00, Data-loss 1.7509e-01                  , pde-loss 5.4478e+03, initc-loss 1.2733e+04                    bc_loss 2.0920e+02\n",
      "Epoch 48420, Training-Loss 2.0945e+00, Data-loss 1.2410e-01                  , pde-loss 6.3741e+03, initc-loss 1.2921e+04                    bc_loss 4.0914e+02\n",
      "Epoch 48430, Training-Loss 2.0294e+00, Data-loss 1.0205e-01                  , pde-loss 6.3168e+03, initc-loss 1.2862e+04                    bc_loss 9.4326e+01\n",
      "Epoch 48440, Training-Loss 2.1058e+00, Data-loss 2.0075e-01                  , pde-loss 5.9757e+03, initc-loss 1.2989e+04                    bc_loss 8.6064e+01\n",
      "Epoch 48450, Training-Loss 2.0931e+00, Data-loss 1.6490e-01                  , pde-loss 6.2334e+03, initc-loss 1.2924e+04                    bc_loss 1.2406e+02\n",
      "Epoch 48460, Training-Loss 1.9046e+00, Data-loss 4.1879e-02                  , pde-loss 5.5999e+03, initc-loss 1.2903e+04                    bc_loss 1.2451e+02\n",
      "Epoch 48470, Training-Loss 2.1836e+00, Data-loss 2.6819e-01                  , pde-loss 6.0444e+03, initc-loss 1.2894e+04                    bc_loss 2.1585e+02\n",
      "Epoch 48480, Training-Loss 2.1267e+00, Data-loss 1.6662e-01                  , pde-loss 6.2869e+03, initc-loss 1.2951e+04                    bc_loss 3.6308e+02\n",
      "Epoch 48490, Training-Loss 2.0721e+00, Data-loss 1.6262e-01                  , pde-loss 6.1405e+03, initc-loss 1.2831e+04                    bc_loss 1.2281e+02\n",
      "Epoch 48500, Training-Loss 1.9078e+00, Data-loss 5.5196e-02                  , pde-loss 5.5555e+03, initc-loss 1.2930e+04                    bc_loss 4.0270e+01\n",
      "Epoch 48510, Training-Loss 1.9934e+00, Data-loss 8.3210e-02                  , pde-loss 5.9345e+03, initc-loss 1.2911e+04                    bc_loss 2.5581e+02\n",
      "Epoch 48520, Training-Loss 1.9603e+00, Data-loss 7.8709e-02                  , pde-loss 5.8510e+03, initc-loss 1.2914e+04                    bc_loss 5.0257e+01\n",
      "Epoch 48530, Training-Loss 1.9258e+00, Data-loss 8.5811e-02                  , pde-loss 5.4383e+03, initc-loss 1.2874e+04                    bc_loss 8.7972e+01\n",
      "Epoch 48540, Training-Loss 1.9085e+00, Data-loss 5.5295e-02                  , pde-loss 5.4233e+03, initc-loss 1.2872e+04                    bc_loss 2.3693e+02\n",
      "Epoch 48550, Training-Loss 1.9306e+00, Data-loss 7.3263e-02                  , pde-loss 5.5442e+03, initc-loss 1.2901e+04                    bc_loss 1.2836e+02\n",
      "Epoch 48560, Training-Loss 1.8418e+00, Data-loss 4.0903e-02                  , pde-loss 5.0858e+03, initc-loss 1.2872e+04                    bc_loss 5.1193e+01\n",
      "Epoch 48570, Training-Loss 1.9427e+00, Data-loss 6.0583e-02                  , pde-loss 5.9134e+03, initc-loss 1.2879e+04                    bc_loss 2.9135e+01\n",
      "Epoch 48580, Training-Loss 1.8425e+00, Data-loss 4.3910e-02                  , pde-loss 5.0729e+03, initc-loss 1.2886e+04                    bc_loss 2.7147e+01\n",
      "Epoch 48590, Training-Loss 1.8981e+00, Data-loss 7.4649e-02                  , pde-loss 5.4211e+03, initc-loss 1.2757e+04                    bc_loss 5.6261e+01\n",
      "Epoch 48600, Training-Loss 1.9470e+00, Data-loss 4.9910e-02                  , pde-loss 5.9703e+03, initc-loss 1.2865e+04                    bc_loss 1.3628e+02\n",
      "Epoch 48610, Training-Loss 2.0840e+00, Data-loss 1.7421e-01                  , pde-loss 5.7235e+03, initc-loss 1.2882e+04                    bc_loss 4.9235e+02\n",
      "Epoch 48620, Training-Loss 1.9724e+00, Data-loss 7.0075e-02                  , pde-loss 6.0532e+03, initc-loss 1.2835e+04                    bc_loss 1.3456e+02\n",
      "Epoch 48630, Training-Loss 1.9413e+00, Data-loss 6.1770e-02                  , pde-loss 5.8726e+03, initc-loss 1.2896e+04                    bc_loss 2.7021e+01\n",
      "Epoch 48640, Training-Loss 2.0001e+00, Data-loss 4.9680e-02                  , pde-loss 6.5479e+03, initc-loss 1.2938e+04                    bc_loss 1.8256e+01\n",
      "Epoch 48650, Training-Loss 1.9460e+00, Data-loss 9.5997e-02                  , pde-loss 5.4242e+03, initc-loss 1.2889e+04                    bc_loss 1.8679e+02\n",
      "Epoch 48660, Training-Loss 1.9371e+00, Data-loss 6.3497e-02                  , pde-loss 5.6315e+03, initc-loss 1.2914e+04                    bc_loss 1.9100e+02\n",
      "Epoch 48670, Training-Loss 1.9944e+00, Data-loss 9.2903e-02                  , pde-loss 5.9400e+03, initc-loss 1.2931e+04                    bc_loss 1.4355e+02\n",
      "Epoch 48680, Training-Loss 1.9720e+00, Data-loss 7.3167e-02                  , pde-loss 5.9606e+03, initc-loss 1.2904e+04                    bc_loss 1.2382e+02\n",
      "Epoch 48690, Training-Loss 2.0487e+00, Data-loss 7.7802e-02                  , pde-loss 6.7317e+03, initc-loss 1.2884e+04                    bc_loss 9.3337e+01\n",
      "Epoch 48700, Training-Loss 1.9059e+00, Data-loss 8.8863e-02                  , pde-loss 5.3168e+03, initc-loss 1.2824e+04                    bc_loss 2.9149e+01\n",
      "Epoch 48710, Training-Loss 2.0521e+00, Data-loss 1.4848e-01                  , pde-loss 6.1842e+03, initc-loss 1.2835e+04                    bc_loss 1.6510e+01\n",
      "Epoch 48720, Training-Loss 2.0144e+00, Data-loss 1.0386e-01                  , pde-loss 5.9553e+03, initc-loss 1.2902e+04                    bc_loss 2.4764e+02\n",
      "Epoch 48730, Training-Loss 1.9921e+00, Data-loss 1.1041e-01                  , pde-loss 5.8037e+03, initc-loss 1.2962e+04                    bc_loss 5.0626e+01\n",
      "Epoch 48740, Training-Loss 2.1174e+00, Data-loss 2.3433e-01                  , pde-loss 5.8880e+03, initc-loss 1.2922e+04                    bc_loss 2.0780e+01\n",
      "Epoch 48750, Training-Loss 1.9895e+00, Data-loss 9.2311e-02                  , pde-loss 6.0734e+03, initc-loss 1.2876e+04                    bc_loss 2.2930e+01\n",
      "Epoch 48760, Training-Loss 1.9259e+00, Data-loss 1.2092e-01                  , pde-loss 5.1099e+03, initc-loss 1.2813e+04                    bc_loss 1.2735e+02\n",
      "Epoch 48770, Training-Loss 1.9911e+00, Data-loss 1.4266e-01                  , pde-loss 5.4873e+03, initc-loss 1.2830e+04                    bc_loss 1.6672e+02\n",
      "Epoch 48780, Training-Loss 1.9887e+00, Data-loss 1.2232e-01                  , pde-loss 5.6300e+03, initc-loss 1.2842e+04                    bc_loss 1.9176e+02\n",
      "Epoch 48790, Training-Loss 2.0508e+00, Data-loss 1.2497e-01                  , pde-loss 6.2194e+03, initc-loss 1.2869e+04                    bc_loss 1.7002e+02\n",
      "Epoch 48800, Training-Loss 2.6345e+00, Data-loss 4.1562e-01                  , pde-loss 6.0817e+03, initc-loss 1.3018e+04                    bc_loss 3.0894e+03\n",
      "Epoch 48810, Training-Loss 2.1154e+01, Data-loss 9.5277e+00                  , pde-loss 6.3669e+03, initc-loss 1.2769e+04                    bc_loss 9.7128e+04\n",
      "Epoch 48820, Training-Loss 9.2220e+00, Data-loss 5.2055e+00                  , pde-loss 5.1830e+03, initc-loss 1.2554e+04                    bc_loss 2.2428e+04\n",
      "Epoch 48830, Training-Loss 4.9613e+00, Data-loss 1.5001e+00                  , pde-loss 6.0710e+03, initc-loss 1.2897e+04                    bc_loss 1.5643e+04\n",
      "Epoch 48840, Training-Loss 3.3159e+00, Data-loss 1.0715e+00                  , pde-loss 5.6740e+03, initc-loss 1.3023e+04                    bc_loss 3.7464e+03\n",
      "Epoch 48850, Training-Loss 3.2594e+00, Data-loss 1.2015e+00                  , pde-loss 6.0142e+03, initc-loss 1.3002e+04                    bc_loss 1.5624e+03\n",
      "Epoch 48860, Training-Loss 2.2823e+00, Data-loss 3.6527e-01                  , pde-loss 5.3674e+03, initc-loss 1.2913e+04                    bc_loss 8.9005e+02\n",
      "Epoch 48870, Training-Loss 2.1388e+00, Data-loss 2.7056e-01                  , pde-loss 5.5444e+03, initc-loss 1.2872e+04                    bc_loss 2.6543e+02\n",
      "Epoch 48880, Training-Loss 2.0541e+00, Data-loss 1.8269e-01                  , pde-loss 5.5693e+03, initc-loss 1.2858e+04                    bc_loss 2.8734e+02\n",
      "Epoch 48890, Training-Loss 1.9554e+00, Data-loss 1.5085e-01                  , pde-loss 5.1132e+03, initc-loss 1.2867e+04                    bc_loss 6.4783e+01\n",
      "Epoch 48900, Training-Loss 2.0717e+00, Data-loss 1.3905e-01                  , pde-loss 6.3578e+03, initc-loss 1.2902e+04                    bc_loss 6.6909e+01\n",
      "Epoch 48910, Training-Loss 2.1356e+00, Data-loss 2.2463e-01                  , pde-loss 6.1126e+03, initc-loss 1.2926e+04                    bc_loss 7.0962e+01\n",
      "Epoch 48920, Training-Loss 2.0801e+00, Data-loss 1.8456e-01                  , pde-loss 5.9411e+03, initc-loss 1.2950e+04                    bc_loss 6.4654e+01\n",
      "Epoch 48930, Training-Loss 1.9726e+00, Data-loss 9.9136e-02                  , pde-loss 5.8086e+03, initc-loss 1.2855e+04                    bc_loss 7.0507e+01\n",
      "Epoch 48940, Training-Loss 1.9493e+00, Data-loss 8.8144e-02                  , pde-loss 5.6565e+03, initc-loss 1.2897e+04                    bc_loss 5.7892e+01\n",
      "Epoch 48950, Training-Loss 2.0189e+00, Data-loss 9.2956e-02                  , pde-loss 6.2569e+03, initc-loss 1.2924e+04                    bc_loss 7.8432e+01\n",
      "Epoch 48960, Training-Loss 2.0756e+00, Data-loss 1.2678e-01                  , pde-loss 6.4894e+03, initc-loss 1.2936e+04                    bc_loss 6.3448e+01\n",
      "Epoch 48970, Training-Loss 1.9566e+00, Data-loss 1.0636e-01                  , pde-loss 5.4986e+03, initc-loss 1.2931e+04                    bc_loss 7.2603e+01\n",
      "Epoch 48980, Training-Loss 2.0067e+00, Data-loss 1.0929e-01                  , pde-loss 5.9709e+03, initc-loss 1.2912e+04                    bc_loss 9.1921e+01\n",
      "Epoch 48990, Training-Loss 2.0713e+00, Data-loss 9.2041e-02                  , pde-loss 6.8297e+03, initc-loss 1.2905e+04                    bc_loss 5.7045e+01\n",
      "Epoch 49000, Training-Loss 1.9177e+00, Data-loss 6.6114e-02                  , pde-loss 5.6193e+03, initc-loss 1.2819e+04                    bc_loss 7.7698e+01\n",
      "Epoch 49010, Training-Loss 2.1133e+00, Data-loss 1.3530e-01                  , pde-loss 6.8934e+03, initc-loss 1.2827e+04                    bc_loss 6.0211e+01\n",
      "Epoch 49020, Training-Loss 1.9283e+00, Data-loss 5.8671e-02                  , pde-loss 5.8578e+03, initc-loss 1.2784e+04                    bc_loss 5.4165e+01\n",
      "Epoch 49030, Training-Loss 1.8902e+00, Data-loss 5.6443e-02                  , pde-loss 5.4022e+03, initc-loss 1.2889e+04                    bc_loss 4.6993e+01\n",
      "Epoch 49040, Training-Loss 1.9127e+00, Data-loss 4.8356e-02                  , pde-loss 5.7266e+03, initc-loss 1.2881e+04                    bc_loss 3.5180e+01\n",
      "Epoch 49050, Training-Loss 1.9111e+00, Data-loss 8.1803e-02                  , pde-loss 5.3452e+03, initc-loss 1.2891e+04                    bc_loss 5.6331e+01\n",
      "Epoch 49060, Training-Loss 2.0175e+00, Data-loss 1.1011e-01                  , pde-loss 6.1887e+03, initc-loss 1.2836e+04                    bc_loss 4.9251e+01\n",
      "Epoch 49070, Training-Loss 2.0594e+00, Data-loss 8.1659e-02                  , pde-loss 6.8539e+03, initc-loss 1.2884e+04                    bc_loss 3.9811e+01\n",
      "Epoch 49080, Training-Loss 1.8714e+00, Data-loss 8.1204e-02                  , pde-loss 4.9528e+03, initc-loss 1.2906e+04                    bc_loss 4.3084e+01\n",
      "Epoch 49090, Training-Loss 2.0344e+00, Data-loss 1.2985e-01                  , pde-loss 6.1542e+03, initc-loss 1.2844e+04                    bc_loss 4.7417e+01\n",
      "Epoch 49100, Training-Loss 1.9515e+00, Data-loss 6.1388e-02                  , pde-loss 5.9846e+03, initc-loss 1.2879e+04                    bc_loss 3.7469e+01\n",
      "Epoch 49110, Training-Loss 1.9381e+00, Data-loss 4.7395e-02                  , pde-loss 5.9825e+03, initc-loss 1.2886e+04                    bc_loss 3.8380e+01\n",
      "Epoch 49120, Training-Loss 1.9082e+00, Data-loss 5.3010e-02                  , pde-loss 5.6058e+03, initc-loss 1.2911e+04                    bc_loss 3.5190e+01\n",
      "Epoch 49130, Training-Loss 1.9627e+00, Data-loss 7.2489e-02                  , pde-loss 6.0045e+03, initc-loss 1.2855e+04                    bc_loss 4.3382e+01\n",
      "Epoch 49140, Training-Loss 1.9206e+00, Data-loss 6.2769e-02                  , pde-loss 5.6238e+03, initc-loss 1.2917e+04                    bc_loss 3.7558e+01\n",
      "Epoch 49150, Training-Loss 1.9251e+00, Data-loss 5.5975e-02                  , pde-loss 5.7186e+03, initc-loss 1.2938e+04                    bc_loss 3.4490e+01\n",
      "Epoch 49160, Training-Loss 1.9984e+00, Data-loss 7.0789e-02                  , pde-loss 6.3474e+03, initc-loss 1.2888e+04                    bc_loss 4.0576e+01\n",
      "Epoch 49170, Training-Loss 1.9238e+00, Data-loss 6.7175e-02                  , pde-loss 5.6653e+03, initc-loss 1.2869e+04                    bc_loss 3.1396e+01\n",
      "Epoch 49180, Training-Loss 2.0542e+00, Data-loss 1.2202e-01                  , pde-loss 6.3661e+03, initc-loss 1.2931e+04                    bc_loss 2.5120e+01\n",
      "Epoch 49190, Training-Loss 1.9437e+00, Data-loss 7.7705e-02                  , pde-loss 5.6922e+03, initc-loss 1.2916e+04                    bc_loss 5.1558e+01\n",
      "Epoch 49200, Training-Loss 1.9306e+00, Data-loss 6.4348e-02                  , pde-loss 5.7197e+03, initc-loss 1.2894e+04                    bc_loss 4.8586e+01\n",
      "Epoch 49210, Training-Loss 1.9532e+00, Data-loss 1.1540e-01                  , pde-loss 5.4410e+03, initc-loss 1.2904e+04                    bc_loss 3.2457e+01\n",
      "Epoch 49220, Training-Loss 1.9132e+00, Data-loss 6.1419e-02                  , pde-loss 5.6704e+03, initc-loss 1.2817e+04                    bc_loss 3.0210e+01\n",
      "Epoch 49230, Training-Loss 1.9197e+00, Data-loss 4.8719e-02                  , pde-loss 5.8050e+03, initc-loss 1.2869e+04                    bc_loss 3.5488e+01\n",
      "Epoch 49240, Training-Loss 1.8616e+00, Data-loss 5.9870e-02                  , pde-loss 5.1810e+03, initc-loss 1.2807e+04                    bc_loss 2.9882e+01\n",
      "Epoch 49250, Training-Loss 1.9052e+00, Data-loss 5.6060e-02                  , pde-loss 5.5961e+03, initc-loss 1.2856e+04                    bc_loss 3.9567e+01\n",
      "Epoch 49260, Training-Loss 1.8713e+00, Data-loss 8.8470e-02                  , pde-loss 4.9528e+03, initc-loss 1.2846e+04                    bc_loss 2.8951e+01\n",
      "Epoch 49270, Training-Loss 1.8839e+00, Data-loss 4.2268e-02                  , pde-loss 5.4598e+03, initc-loss 1.2924e+04                    bc_loss 3.2387e+01\n",
      "Epoch 49280, Training-Loss 1.8916e+00, Data-loss 5.3557e-02                  , pde-loss 5.4766e+03, initc-loss 1.2876e+04                    bc_loss 2.7822e+01\n",
      "Epoch 49290, Training-Loss 2.0228e+00, Data-loss 1.2773e-01                  , pde-loss 6.0391e+03, initc-loss 1.2884e+04                    bc_loss 2.7825e+01\n",
      "Epoch 49300, Training-Loss 1.9681e+00, Data-loss 1.0693e-01                  , pde-loss 5.6769e+03, initc-loss 1.2901e+04                    bc_loss 3.4323e+01\n",
      "Epoch 49310, Training-Loss 1.9567e+00, Data-loss 6.5293e-02                  , pde-loss 6.0434e+03, initc-loss 1.2847e+04                    bc_loss 2.3865e+01\n",
      "Epoch 49320, Training-Loss 1.9338e+00, Data-loss 5.9100e-02                  , pde-loss 5.7469e+03, initc-loss 1.2952e+04                    bc_loss 4.7784e+01\n",
      "Epoch 49330, Training-Loss 1.9413e+00, Data-loss 5.9420e-02                  , pde-loss 5.9169e+03, initc-loss 1.2877e+04                    bc_loss 2.4737e+01\n",
      "Epoch 49340, Training-Loss 2.0006e+00, Data-loss 5.2557e-02                  , pde-loss 6.5961e+03, initc-loss 1.2856e+04                    bc_loss 2.8604e+01\n",
      "Epoch 49350, Training-Loss 1.9727e+00, Data-loss 4.3172e-02                  , pde-loss 6.3409e+03, initc-loss 1.2927e+04                    bc_loss 2.6720e+01\n",
      "Epoch 49360, Training-Loss 1.9501e+00, Data-loss 5.2800e-02                  , pde-loss 6.0062e+03, initc-loss 1.2944e+04                    bc_loss 2.2535e+01\n",
      "Epoch 49370, Training-Loss 1.9536e+00, Data-loss 4.7764e-02                  , pde-loss 6.0896e+03, initc-loss 1.2946e+04                    bc_loss 2.2440e+01\n",
      "Epoch 49380, Training-Loss 1.8991e+00, Data-loss 5.2002e-02                  , pde-loss 5.5863e+03, initc-loss 1.2852e+04                    bc_loss 3.3066e+01\n",
      "Epoch 49390, Training-Loss 1.8829e+00, Data-loss 6.6275e-02                  , pde-loss 5.2659e+03, initc-loss 1.2876e+04                    bc_loss 2.5180e+01\n",
      "Epoch 49400, Training-Loss 1.9126e+00, Data-loss 3.8752e-02                  , pde-loss 5.7796e+03, initc-loss 1.2929e+04                    bc_loss 2.9620e+01\n",
      "Epoch 49410, Training-Loss 1.9771e+00, Data-loss 6.5514e-02                  , pde-loss 6.1231e+03, initc-loss 1.2950e+04                    bc_loss 4.2372e+01\n",
      "Epoch 49420, Training-Loss 2.0296e+00, Data-loss 1.0306e-01                  , pde-loss 6.3485e+03, initc-loss 1.2876e+04                    bc_loss 4.0476e+01\n",
      "Epoch 49430, Training-Loss 1.9610e+00, Data-loss 8.6337e-02                  , pde-loss 5.8647e+03, initc-loss 1.2803e+04                    bc_loss 7.9180e+01\n",
      "Epoch 49440, Training-Loss 2.0273e+00, Data-loss 8.6112e-02                  , pde-loss 6.5808e+03, initc-loss 1.2799e+04                    bc_loss 3.1910e+01\n",
      "Epoch 49450, Training-Loss 1.8195e+00, Data-loss 5.1376e-02                  , pde-loss 4.7338e+03, initc-loss 1.2914e+04                    bc_loss 3.3360e+01\n",
      "Epoch 49460, Training-Loss 1.9149e+00, Data-loss 4.8576e-02                  , pde-loss 5.7403e+03, initc-loss 1.2900e+04                    bc_loss 2.3366e+01\n",
      "Epoch 49470, Training-Loss 1.9071e+00, Data-loss 7.5840e-02                  , pde-loss 5.3778e+03, initc-loss 1.2909e+04                    bc_loss 2.5603e+01\n",
      "Epoch 49480, Training-Loss 1.8620e+00, Data-loss 4.1557e-02                  , pde-loss 5.3161e+03, initc-loss 1.2858e+04                    bc_loss 3.0388e+01\n",
      "Epoch 49490, Training-Loss 1.9276e+00, Data-loss 3.6995e-02                  , pde-loss 5.9729e+03, initc-loss 1.2913e+04                    bc_loss 2.1102e+01\n",
      "Epoch 49500, Training-Loss 1.9415e+00, Data-loss 7.2122e-02                  , pde-loss 5.8189e+03, initc-loss 1.2854e+04                    bc_loss 2.0883e+01\n",
      "Epoch 49510, Training-Loss 2.0256e+00, Data-loss 7.1960e-02                  , pde-loss 6.6197e+03, initc-loss 1.2892e+04                    bc_loss 2.4938e+01\n",
      "Epoch 49520, Training-Loss 1.9386e+00, Data-loss 5.1768e-02                  , pde-loss 5.9243e+03, initc-loss 1.2920e+04                    bc_loss 2.4188e+01\n",
      "Epoch 49530, Training-Loss 1.9135e+00, Data-loss 4.9987e-02                  , pde-loss 5.7258e+03, initc-loss 1.2894e+04                    bc_loss 1.6133e+01\n",
      "Epoch 49540, Training-Loss 1.9141e+00, Data-loss 5.5895e-02                  , pde-loss 5.6066e+03, initc-loss 1.2942e+04                    bc_loss 3.4126e+01\n",
      "Epoch 49550, Training-Loss 1.8838e+00, Data-loss 6.3529e-02                  , pde-loss 5.2477e+03, initc-loss 1.2938e+04                    bc_loss 1.6387e+01\n",
      "Epoch 49560, Training-Loss 1.8791e+00, Data-loss 3.6488e-02                  , pde-loss 5.5381e+03, initc-loss 1.2858e+04                    bc_loss 3.0351e+01\n",
      "Epoch 49570, Training-Loss 1.9021e+00, Data-loss 5.4132e-02                  , pde-loss 5.5882e+03, initc-loss 1.2874e+04                    bc_loss 1.7593e+01\n",
      "Epoch 49580, Training-Loss 1.9488e+00, Data-loss 6.2227e-02                  , pde-loss 5.8702e+03, initc-loss 1.2971e+04                    bc_loss 2.4246e+01\n",
      "Epoch 49590, Training-Loss 1.9569e+00, Data-loss 4.0090e-02                  , pde-loss 6.2556e+03, initc-loss 1.2887e+04                    bc_loss 2.5661e+01\n",
      "Epoch 49600, Training-Loss 1.9385e+00, Data-loss 5.0969e-02                  , pde-loss 5.9489e+03, initc-loss 1.2904e+04                    bc_loss 2.2569e+01\n",
      "Epoch 49610, Training-Loss 1.8803e+00, Data-loss 5.6799e-02                  , pde-loss 5.2542e+03, initc-loss 1.2965e+04                    bc_loss 1.5775e+01\n",
      "Epoch 49620, Training-Loss 1.8999e+00, Data-loss 4.6967e-02                  , pde-loss 5.6286e+03, initc-loss 1.2878e+04                    bc_loss 2.2733e+01\n",
      "Epoch 49630, Training-Loss 1.9118e+00, Data-loss 5.3189e-02                  , pde-loss 5.6223e+03, initc-loss 1.2947e+04                    bc_loss 1.6220e+01\n",
      "Epoch 49640, Training-Loss 1.8729e+00, Data-loss 4.7561e-02                  , pde-loss 5.3273e+03, initc-loss 1.2907e+04                    bc_loss 1.8811e+01\n",
      "Epoch 49650, Training-Loss 1.9027e+00, Data-loss 5.2820e-02                  , pde-loss 5.5945e+03, initc-loss 1.2889e+04                    bc_loss 1.5394e+01\n",
      "Epoch 49660, Training-Loss 1.9051e+00, Data-loss 6.8785e-02                  , pde-loss 5.4538e+03, initc-loss 1.2886e+04                    bc_loss 2.3306e+01\n",
      "Epoch 49670, Training-Loss 2.0521e+00, Data-loss 8.1687e-02                  , pde-loss 6.7642e+03, initc-loss 1.2898e+04                    bc_loss 4.1263e+01\n",
      "Epoch 49680, Training-Loss 2.0363e+00, Data-loss 8.0890e-02                  , pde-loss 6.5236e+03, initc-loss 1.3012e+04                    bc_loss 1.8039e+01\n",
      "Epoch 49690, Training-Loss 1.9508e+00, Data-loss 4.6282e-02                  , pde-loss 6.1442e+03, initc-loss 1.2889e+04                    bc_loss 1.2168e+01\n",
      "Epoch 49700, Training-Loss 1.9631e+00, Data-loss 4.9728e-02                  , pde-loss 6.1951e+03, initc-loss 1.2921e+04                    bc_loss 1.8131e+01\n",
      "Epoch 49710, Training-Loss 1.9054e+00, Data-loss 7.0106e-02                  , pde-loss 5.3582e+03, initc-loss 1.2980e+04                    bc_loss 1.4014e+01\n",
      "Epoch 49720, Training-Loss 1.8670e+00, Data-loss 4.5565e-02                  , pde-loss 5.3306e+03, initc-loss 1.2869e+04                    bc_loss 1.4552e+01\n",
      "Epoch 49730, Training-Loss 1.9710e+00, Data-loss 7.0940e-02                  , pde-loss 6.0427e+03, initc-loss 1.2934e+04                    bc_loss 2.3859e+01\n",
      "Epoch 49740, Training-Loss 2.0305e+00, Data-loss 1.6238e-01                  , pde-loss 5.7381e+03, initc-loss 1.2920e+04                    bc_loss 2.3109e+01\n",
      "Epoch 49750, Training-Loss 2.0061e+00, Data-loss 7.1832e-02                  , pde-loss 6.4147e+03, initc-loss 1.2903e+04                    bc_loss 2.4276e+01\n",
      "Epoch 49760, Training-Loss 1.9943e+00, Data-loss 6.5722e-02                  , pde-loss 6.4086e+03, initc-loss 1.2863e+04                    bc_loss 1.4558e+01\n",
      "Epoch 49770, Training-Loss 1.9596e+00, Data-loss 5.5105e-02                  , pde-loss 6.1467e+03, initc-loss 1.2880e+04                    bc_loss 1.8724e+01\n",
      "Epoch 49780, Training-Loss 2.0306e+00, Data-loss 2.0312e-01                  , pde-loss 5.3615e+03, initc-loss 1.2878e+04                    bc_loss 3.4578e+01\n",
      "Epoch 49790, Training-Loss 1.9770e+00, Data-loss 4.9204e-02                  , pde-loss 6.3628e+03, initc-loss 1.2895e+04                    bc_loss 2.0106e+01\n",
      "Epoch 49800, Training-Loss 1.9706e+00, Data-loss 1.1336e-01                  , pde-loss 5.6779e+03, initc-loss 1.2877e+04                    bc_loss 1.7110e+01\n",
      "Epoch 49810, Training-Loss 1.9251e+00, Data-loss 5.6676e-02                  , pde-loss 5.7860e+03, initc-loss 1.2880e+04                    bc_loss 1.7460e+01\n",
      "Epoch 49820, Training-Loss 2.0194e+00, Data-loss 5.6066e-02                  , pde-loss 6.7615e+03, initc-loss 1.2824e+04                    bc_loss 4.7590e+01\n",
      "Epoch 49830, Training-Loss 1.9187e+00, Data-loss 7.6526e-02                  , pde-loss 5.4412e+03, initc-loss 1.2950e+04                    bc_loss 3.0752e+01\n",
      "Epoch 49840, Training-Loss 1.9077e+00, Data-loss 6.3751e-02                  , pde-loss 5.5033e+03, initc-loss 1.2918e+04                    bc_loss 1.8905e+01\n",
      "Epoch 49850, Training-Loss 1.9651e+00, Data-loss 1.0103e-01                  , pde-loss 5.6838e+03, initc-loss 1.2929e+04                    bc_loss 2.7925e+01\n",
      "Epoch 49860, Training-Loss 2.0293e+00, Data-loss 7.2429e-02                  , pde-loss 6.5950e+03, initc-loss 1.2950e+04                    bc_loss 2.3759e+01\n",
      "Epoch 49870, Training-Loss 1.8565e+00, Data-loss 5.5731e-02                  , pde-loss 5.1299e+03, initc-loss 1.2862e+04                    bc_loss 1.5716e+01\n",
      "Epoch 49880, Training-Loss 1.9118e+00, Data-loss 7.5678e-02                  , pde-loss 5.5097e+03, initc-loss 1.2831e+04                    bc_loss 2.0300e+01\n",
      "Epoch 49890, Training-Loss 1.8866e+00, Data-loss 6.2219e-02                  , pde-loss 5.3113e+03, initc-loss 1.2893e+04                    bc_loss 3.9707e+01\n",
      "Epoch 49900, Training-Loss 2.0455e+00, Data-loss 9.4363e-02                  , pde-loss 6.6359e+03, initc-loss 1.2847e+04                    bc_loss 2.8146e+01\n",
      "Epoch 49910, Training-Loss 1.8949e+00, Data-loss 6.9889e-02                  , pde-loss 5.3535e+03, initc-loss 1.2876e+04                    bc_loss 2.0340e+01\n",
      "Epoch 49920, Training-Loss 1.9381e+00, Data-loss 4.1409e-02                  , pde-loss 5.9863e+03, initc-loss 1.2943e+04                    bc_loss 3.8138e+01\n",
      "Epoch 49930, Training-Loss 2.0641e+00, Data-loss 1.7100e-01                  , pde-loss 6.0631e+03, initc-loss 1.2849e+04                    bc_loss 1.8456e+01\n",
      "Epoch 49940, Training-Loss 1.9302e+00, Data-loss 3.9612e-02                  , pde-loss 6.0176e+03, initc-loss 1.2861e+04                    bc_loss 2.7211e+01\n",
      "Epoch 49950, Training-Loss 1.9455e+00, Data-loss 4.3521e-02                  , pde-loss 6.1023e+03, initc-loss 1.2883e+04                    bc_loss 3.4666e+01\n",
      "Epoch 49960, Training-Loss 1.8893e+00, Data-loss 5.5849e-02                  , pde-loss 5.4455e+03, initc-loss 1.2869e+04                    bc_loss 1.9191e+01\n",
      "Epoch 49970, Training-Loss 1.8700e+00, Data-loss 5.5275e-02                  , pde-loss 5.2639e+03, initc-loss 1.2861e+04                    bc_loss 2.2596e+01\n",
      "Epoch 49980, Training-Loss 1.9182e+00, Data-loss 7.4769e-02                  , pde-loss 5.5398e+03, initc-loss 1.2857e+04                    bc_loss 3.7664e+01\n",
      "Epoch 49990, Training-Loss 1.8898e+00, Data-loss 3.4764e-02                  , pde-loss 5.6366e+03, initc-loss 1.2897e+04                    bc_loss 1.7142e+01\n",
      "Epoch 50000, Test-Loss 3.9397e-02, Test-Accuracy 1.4704e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses, val_losses = training_loop(epochs, model, loss_fn_data, optimizer,train_loader)  # Train the model\n",
    " \n",
    "test_losses = test_loop(epochs, model, loss_fn_data, optimizer, train_loader, test_loader)  # Test the model\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_nn = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).cpu().detach().numpy() # Get the predictions from the model\n",
    "\n",
    "temp_nn = temp_nn.reshape(num_steps+1, num_points) # Reshape the predictions to a 2D array\n",
    "time_ss= np.linspace(0, time_end, num_steps+1)\n",
    "plt.figure\n",
    "plt.plot(time_ss, temp_nn[:,num_points//2], label='Predicted Temperature')\n",
    "plt.plot(time_ss, temperature_history[:,num_points//2], label='Actual Temperature')\n",
    "plt.xlabel('Time(s)')\n",
    "plt.ylabel('Temperature (K)')\n",
    "plt.title('Predicted vs Actual Temperature at x = 7.5mm')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31470, 50)\n",
      "Transposed Temperature History Shape: (31470, 50)\n",
      "Transposed Phi History Shape: (31470, 52)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n",
      "findfont: Font family 'Times New Roman' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming you have temperature_history and phi_history as lists of arrays\n",
    "temperature_history = np.array(t_hist)\n",
    "phi_history = np.array(phi_history)\n",
    "\n",
    "print(temperature_history.shape)\n",
    "\n",
    "# Check the new shape after transposing\n",
    "print(\"Transposed Temperature History Shape:\", temperature_history.shape)\n",
    "print(\"Transposed Phi History Shape:\", phi_history.shape)\n",
    "\n",
    "# Create a meshgrid for space and time coordinates\n",
    "space_coord, time_coord = np.meshgrid(np.arange(temperature_history.shape[1]), np.arange(temperature_history.shape[0]))\n",
    "\n",
    "time_coord = time_coord * dt \n",
    "# Create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Plot the temperature history on the left subplot\n",
    "im1 = ax1.pcolormesh(space_coord, time_coord, t_hist, cmap='viridis')\n",
    "ax1.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=16)\n",
    "ax1.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "ax1.set_title('Temperature Variation Over Time (Analytical)',fontname='Times New Roman', fontsize=20)\n",
    "fig.colorbar(im1, ax=ax1, label='Temperature')\n",
    "\n",
    "im2 = ax2.pcolormesh(space_coord, time_coord, temp_nn, cmap='viridis')\n",
    "ax2.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=16)\n",
    "ax2.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "ax2.set_title('Temperature Variation Over Time(PINN)',fontname='Times New Roman', fontsize=20)\n",
    "fig.colorbar(im2, ax=ax2, label='Temperature')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
