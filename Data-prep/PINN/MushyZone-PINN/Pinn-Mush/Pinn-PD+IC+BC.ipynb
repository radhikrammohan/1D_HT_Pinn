{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Three Phase Simulation of Alloys and PINN model development \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the simulation of 1D Phase change of aluminium alloy. There will be three phases (solid,liquid and mushy).   \n",
    "\n",
    "The approach used is finite difference method and the physics involved in heat conduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import csv\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "\n",
    "from pinn_loss import loss_fn_data, l1_regularization, pde_loss, boundary_loss, ic_loss, accuracy\n",
    "from Input_vec_gen import input_gen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the constants and inital geometric domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Material :- AL 380\n",
    "\n",
    "| Sr.No | Properties  | Symbol | Value  | Unit |Range(source) |\n",
    "|:---:|:---:|:---:|:---:|:---:|:--:|\n",
    "| 1  | Liquidus Density | $\\rho_{l}$  | 2300 | $kg/m^3$  |  2200-2400 (ASM handbook) |\n",
    "|  2 |  Solidus Density  |  $\\rho_{s}$  | 2500  |  $kg/m^3$  | 2400-2600 (ASM handbook) |\n",
    "|  3 |  Mushy Desnity |  $\\rho_{m}$  |  2400 | $kg/m^3$   |Increase linearly from liquid to solid (ASM handbook) |\n",
    "|  4 |  Liquidus Thermal Conductivity| $k_l$  |  70 | $W/m-K$  |60-80 (ASM handbook) |\n",
    "|  5 |  Solidus Thermal Conductivity | $k_s$  | 180  |  $W/m-K$ | 150-210(ASM handbook) |\n",
    "|  6 | Mushy Zone Thermal Conductivity | $k_m$  | 125  |  $W/m-K$ |Decrease linearly from liquid to solid (ASM handbook) |\n",
    "|  7 | Liquidus Specific Heat | $c_{pl}$  | 1190  | $J/kg-K$  | 1100 -1200 (ASM handbook)|\n",
    "|  8 | Solidus Specific Heat | $c_{ps}$  |  1100 |  $J/kg-K$  | 1100-1200 (ASM handbook)|\n",
    "|  9 | Mushy Zone Specific Heat |  $c_{pm}$ | 1175 | $J/kg-K$   |decrease lineraly from liquid to solid (ASM handbook)|\n",
    "|  10 | Latent Heat of Fusion | $L_{fusion}$  | 450e3  | $J/kg$ | (400-500)e3 (ASM handbook) |\n",
    "| 11 | Left Boundary Temperature |$BCT_{l}$|623 |$K$| (623-723) Nissan Data |\n",
    "|12 | Right Boundary Temperature | $BCT_{r}$|623 |$K$| (623-723) Nissan Data |\n",
    "|13| Freezing time | |60 |sec|||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_l = 3.394878564540885e-05, alpha_s = 3.686205086349929e-05, m_eff = 6.296953764744878e-06\n",
      "dx is 0.0003061224489795918\n",
      "dt is  0.0012711033647622566\n",
      "num_steps is 31469\n",
      "cfl is 0.0012711033647622566\n",
      "stability criteria satisfied\n"
     ]
    }
   ],
   "source": [
    "# Geometry\n",
    "length = 15.0e-3             # Length of the rod\n",
    "\n",
    "# Material properties\n",
    "rho = 2300.0                     # Density of AL380 (kg/m^3)\n",
    "rho_l = 2460.0                   # Density of AL380 (kg/m^3)\n",
    "rho_s = 2710.0                    # Density of AL380 (kg/m^3)\n",
    "rho_m = (rho_l + rho_s )/2       # Desnity in mushy zone is taken as average of liquid and solid density\n",
    "\n",
    "k = 104.0                       # W/m-K\n",
    "k_l = k                       # W/m-K\n",
    "k_s = 96.2                    # W/m-K\n",
    "k_m =  (k_l+k_s)/2                     # W/m-K\n",
    "k_mo = 41.5\n",
    "\n",
    "\n",
    "cp = 1245.3                      # Specific heat of aluminum (J/kg-K)\n",
    "cp_l = cp                      # Specific heat of aluminum (J/kg-K)\n",
    "cp_s = 963.0                 # Specific heat of aluminum (J/kg-K)\n",
    "cp_m =  (cp_l+cp_s)/2                 # Specific heat of mushy zone is taken as average of liquid and solid specific heat\n",
    "# cp_m = cp\n",
    "           # Thermal diffusivity\n",
    "alpha_l = k_l / (rho_l * cp_l) \n",
    "alpha_s = k_s / (rho_s*cp_s)\n",
    "alpha_m = k_m / (rho_m * cp_m)          #`Thermal diffusivity in mushy zone is taken as average of liquid and solid thermal diffusivity`\n",
    "\n",
    "\n",
    "#L_fusion = 3.9e3                 # J/kg\n",
    "L_fusion = 389.0e3               # J/kg  # Latent heat of fusion of aluminum\n",
    "         # Thermal diffusivity\n",
    "\n",
    "\n",
    "T_L = 574.4 +273.0                       #  K -Liquidus Temperature (615 c) AL 380\n",
    "T_S = 497.3 +273.0                     # K- Solidus Temperature (550 C)\n",
    "m_eff =(k_m/(rho_m*(cp_m + (L_fusion/(T_L-T_S)))))\n",
    "print (f\"alpha_l = {alpha_l}, alpha_s = {alpha_s}, m_eff = {m_eff}\")\n",
    "\n",
    "# htc = 10.0                   # W/m^2-K\n",
    "# q = htc*(919.0-723.0)\n",
    "# q = 10000.0\n",
    "\n",
    "\n",
    "num_points = 50                        # Number of spatial points\n",
    "dx = length / (num_points - 1)         # Distance between two spatial points\n",
    "print('dx is',dx)\n",
    "\n",
    "                                                              \n",
    "# Time Discretization  \n",
    "# \n",
    "time_end = 40        # seconds                         \n",
    "\n",
    "maxi = max(alpha_s,alpha_l,alpha_m)\n",
    "dt = abs(0.5*((dx**2) /maxi)) \n",
    "\n",
    "print('dt is ',dt)\n",
    "num_steps = round(time_end/dt)\n",
    "print('num_steps is',num_steps)\n",
    "cfl = 0.5 *(dx**2/max(alpha_l,alpha_s,alpha_m))\n",
    "print('cfl is',cfl)\n",
    "\n",
    "time_steps = np.linspace(0, time_end, num_steps + 1)\n",
    "step_coeff = dt / (dx ** 2)\n",
    "\n",
    "if dt <= cfl:\n",
    "    print('stability criteria satisfied')\n",
    "else:\n",
    "    print('stability criteria not satisfied')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial and Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_init = 919.0\n",
    "# Initial temperature and phase fields\n",
    "temperature = np.full(num_points+2, 919.0)            # Initial temperature of the rod with ghost points at both ends\n",
    "phase = np.zeros(num_points+2)*0.0                    # Initial phase of the rod with ghost points at both ends\n",
    "\n",
    "# Set boundary conditions\n",
    "# temperature[-1] = 919.0 \n",
    "phase[-1] = 1.0\n",
    "\n",
    "# temperature[0] = 919.0 #(40 C)\n",
    "phase[0] = 1.0\n",
    "\n",
    "# Store initial state in history\n",
    "temperature_history = [temperature.copy()]    # List to store temperature at each time step\n",
    "phi_history = [phase.copy()]                    # List to store phase at each time step\n",
    "temp_init = temperature.copy()                 # Initial temperature of the rod\n",
    "# print(temperature_history,phi_history)\n",
    "# Array to store temperature at midpoint over time\n",
    "midpoint_index = num_points // 2                          # Index of the midpoint\n",
    "\n",
    "midpoint_temperature_history = [temperature[midpoint_index]]            # List to store temperature at midpoint over time\n",
    "dm = 60.0e-3                                                            # die thickness in m\n",
    "\n",
    "# r_m =  (k_mo / dm) + (1/htc)\n",
    "\n",
    "t_surr = 500.0                                        # Surrounding temperature in K\n",
    "# t_surr = h()\n",
    "\n",
    "def kramp(temp,v1,v2,T_L,T_s):                                      # Function to calculate thermal conductivity in Mushy Zone\n",
    "        slope = (v1-v2)/(T_L-T_S)\n",
    "        if temp > T_L:\n",
    "            k_m = k_l\n",
    "        elif temp < T_S:\n",
    "            k_m = k_s\n",
    "        else:\n",
    "            k_m = k_s + slope*(temp-T_S)\n",
    "        return k_m\n",
    "\n",
    "def cp_ramp(temp,v1,v2,T_L,T_s):                                    # Function to calculate specific heat capacity in Mushy Zone\n",
    "    slope = (v1-v2)/(T_L-T_S)\n",
    "    if temp > T_L:\n",
    "        cp_m = cp_l\n",
    "    elif temp < T_S:\n",
    "        cp_m = cp_s\n",
    "    else:\n",
    "        cp_m = cp_s + slope*(temp-T_S)\n",
    "    return cp_m\n",
    "\n",
    "def rho_ramp(temp,v1,v2,T_L,T_s):                                       # Function to calculate density in Mushy Zone\n",
    "    slope = (v1-v2)/(T_L-T_S)\n",
    "    if temp > T_L:\n",
    "        rho_m = rho_l\n",
    "    elif temp < T_S:\n",
    "        rho_m = rho_s\n",
    "    else:\n",
    "        rho_m = rho_s + slope*(temp-T_S)\n",
    "    return rho_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the HT equation and phase change numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for m in range(1, num_steps+1):                                                                            # time loop\n",
    "    htc = 10.0                   # htc of Still air in W/m^2-K\n",
    "    q1 = htc*(temp_init[0]-t_surr)   # Heat flux at the left boundary\n",
    "    \n",
    "    # print(f\"q1 is {q1}\")\n",
    "    temperature[0] = temp_init[0] + alpha_l * step_coeff * ((2.0*temp_init[1]) - (2.0 * temp_init[0])-(2.0*dx*(q1)))  # Update boundary condition temperature\n",
    "    \n",
    "    q2 = htc*(temp_init[-1]-t_surr)                   # Heat flux at the right boundary\n",
    "    temperature[-1] = temp_init[-1] + alpha_l * step_coeff * ((2.0*temp_init[-2]) - (2.0 * temp_init[-1])-(2.0*dx*(q2)))  # Update boundary condition temperature\n",
    "    \n",
    "    for n in range(1,num_points+1):              # space loop, adjusted range\n",
    "       \n",
    "        if temperature[n] >= T_L:\n",
    "            temperature[n] += ((alpha_l * step_coeff) * (temp_init[n+1] - (2.0 * temp_init[n]) + temp_init[n-1]))\n",
    "            phase[n] = 0\n",
    "            \n",
    "            # print(f\" Time-Step{m},Spatial point{n},Temperature{temperature[n]}\")\n",
    "        elif T_S < temperature[n] < T_L:\n",
    "            \n",
    "            k_m = kramp(temperature[n],k_l,k_s,T_L,T_S)\n",
    "            cp_m = cp_ramp(temperature[n],cp_l,cp_s,T_L,T_S)\n",
    "            rho_m = rho_ramp(temperature[n],rho_l,rho_s,T_L,T_S)\n",
    "            m_eff =(k_m/(rho_m*(cp_m + (L_fusion/(T_L-T_S)))))\n",
    "            \n",
    "            temperature[n] += ((m_eff * step_coeff)* (temp_init[n+1] - (2.0 * temp_init[n]) + temp_init[n-1]))\n",
    "            \n",
    "            phase[n] = (T_L - temperature[n]) / (T_L - T_S)\n",
    "            # print(m,n,temperature[n],phase[n])\n",
    "         \n",
    "        elif temperature[n]<T_S:\n",
    "            temperature[n] += ((alpha_s * step_coeff) * (temp_init[n+1] - (2.0 * temp_init[n])+ temp_init[n-1]))\n",
    "            phase[n] = 1\n",
    "                     \n",
    "        else:\n",
    "            print(\"ERROR: should not be here\")\n",
    "\n",
    "     \n",
    "          \n",
    "    temperature = temperature.copy()                                                                # Update temperature\n",
    "    phase = phase.copy()                                                                            # Update phase\n",
    "    temp_init = temperature.copy()                                                                  # Update last time step temperature\n",
    "    temperature_history.append(temperature.copy())                                                  # Append the temperature history to add ghost points\n",
    "    phi_history.append(phase.copy())                                                                # Append the phase history to add ghost points\n",
    "    midpoint_temperature_history.append(temperature[midpoint_index])                                # Store midpoint temperature\n",
    "    \n",
    "    \n",
    "    # print(f\"Step {m}, Temperature: {temperature}\")\n",
    "    \n",
    "\n",
    "\n",
    "# print(midpoint_temperature_history)\n",
    "#print(phi_history)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot temperature history for debugging\n",
    "# temperature_history_1 = np.array(temperature_history)\n",
    "# print(temperature_history_1.shape)\n",
    "# time_ss= np.linspace(0, time_end, num_steps+1)\n",
    "# # print(time_ss.shape)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(time_ss, midpoint_temperature_history, label='Midpoint Temperature')\n",
    "# plt.axhline(y=T_L, color='r', linestyle='--', label='Liquidus Temperature')\n",
    "# plt.axhline(y=T_S, color='g', linestyle='--', label='Solidus Temperature')\n",
    "# plt.xlabel('Time(s)')\n",
    "# plt.ylabel('Temperature (K)')\n",
    "# plt.title('Temperature Distribution Over Time at x = 7.5mm') \n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data into Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_history = np.array(temperature_history)\n",
    "\n",
    "phi_history = np.array(phi_history)\n",
    "\n",
    "t_hist = np.array(temperature_history[:,1:-1])\n",
    "p_hist = np.array(phi_history[:,1:-1])\n",
    "\n",
    "t_hist_init = t_hist[0,:]\n",
    "t_hist_bc_l = t_hist[:,0]\n",
    "t_hist_bc_r = t_hist[:,-1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have temperature_history and phi_history as lists of arrays\n",
    "\n",
    "\n",
    "# # Check the new shape after transposing\n",
    "# print(\"Transposed Temperature History Shape:\", temperature_history.shape)\n",
    "# print(\"Transposed Phi History Shape:\", phi_history.shape)\n",
    "\n",
    "# # Create a meshgrid for space and time coordinates\n",
    "# space_coord, time_coord = np.meshgrid(np.arange(temperature_history.shape[1]), np.arange(temperature_history.shape[0]))\n",
    "\n",
    "# time_coord = time_coord * dt \n",
    "# # Create a figure with two subplots\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# # Plot the temperature history on the left subplot\n",
    "# im1 = ax1.pcolormesh(space_coord, time_coord, temperature_history, cmap='viridis')\n",
    "# ax1.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=16)\n",
    "# ax1.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "# ax1.set_title('Temperature Variation Over Time',fontname='Times New Roman', fontsize=20)\n",
    "# fig.colorbar(im1, ax=ax1, label='Temperature')\n",
    "\n",
    "# # Plot the phase history on the right subplot\n",
    "# im2 = ax2.pcolormesh(space_coord, time_coord, phi_history, cmap='viridis')\n",
    "# ax2.set_xlabel('Space Coordinate', fontname='Times New Roman', fontsize=18)\n",
    "# ax2.set_ylabel('Time',fontname='Times New Roman', fontsize=16)\n",
    "# ax2.set_title('Phase Variation Over Time',fontname='Times New Roman', fontsize=20)\n",
    "# fig.colorbar(im2, ax=ax2, label='Phase')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# #plot the main\n",
    "# fig, ax = plt.subplots(figsize=(14, 6))\n",
    "# im = ax.pcolormesh(space_coord, time_coord, Dim_ny, cmap='viridis')\n",
    "# ax.set_xlabel('Space Coordinate')\n",
    "# ax.set_ylabel('Time')\n",
    "# ax.set_title('Niyama Variation Over Time')\n",
    "# fig.colorbar(im, ax=ax, label='Main')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU/CPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check for gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (31470,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "space = np.linspace(0, length, num_points) # Spatial points\n",
    "time = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "print(space.shape,time.shape)\n",
    "\n",
    "sp_i = np.linspace(0, length, num_points) # Spatial points\n",
    "time_i = np.zeros(num_points) # Time points\n",
    "\n",
    "sp_b_l = np.zeros(num_steps+1) # Spatial points\n",
    "time_b_l = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "\n",
    "sp_b_r = np.ones(num_steps+1)*length # Spatial points\n",
    "time_b_r = np.linspace(0, time_end, num_steps+1) # Time points\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = input_gen(space,time,'mgrid')\n",
    "inputs_i = input_gen(sp_i,time_i,'scr')\n",
    "inputs_b_l = input_gen(sp_b_l,time_b_l,'scr')\n",
    "inputs_b_r = input_gen(sp_b_r,time_b_r,'scr')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1573500, 2) (50, 2) (31470, 2) (31470, 2)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape,inputs_i.shape,inputs_b_l.shape,inputs_b_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2])\n",
      "torch.Size([1573500, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "inputs = torch.tensor(inputs).float().to(device) # Convert the inputs to a tensor\n",
    "\n",
    "\n",
    "inputs_init = torch.tensor(inputs_i).float().to(device) # Convert the inputs to a tensor\n",
    "inputs_b_l = torch.tensor(inputs_b_l).float().to(device) # Convert the inputs to a tensor\n",
    "inputs_b_r = torch.tensor(inputs_b_r).float().to(device) # Convert the inputs to a tensor\n",
    "\n",
    "print(inputs_init.shape)\n",
    "# label/temp data\n",
    "temp_tr = torch.tensor(t_hist).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp = temp_tr.reshape(-1,1) # Reshape the temperature tensor to a column vector\n",
    "temp_inp_init = torch.tensor(t_hist_init).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp_bc_l = torch.tensor(t_hist_bc_l).float().to(device) # Convert the temperature history to a tensor\n",
    "temp_inp_bc_r = torch.tensor(t_hist_bc_r).float().to(device) # Convert the temperature history to a tensor\n",
    "print(temp_inp.shape)\n",
    "\n",
    "\n",
    "\n",
    "#Data Splitting\n",
    "\n",
    "# train_inputs, val_test_inputs, train_temp_inp, val_test_temp_inp = train_test_split(inputs, temp_inp, test_size=0.2, random_state=42)\n",
    "# val_inputs, test_inputs, val_temp_inp, test_temp_inp = train_test_split(val_test_inputs, val_test_temp_inp, test_size=0.8, random_state=42)\n",
    "\n",
    "train_inputs, test_inputs, train_temp_inp, test_temp_inp = train_test_split(inputs, temp_inp, test_size=0.2, random_state=42)\n",
    "train_inputs_init, test_inputs_init, train_temp_inp_init, test_temp_inp_init = train_test_split(inputs_init, temp_inp_init, test_size=0.2, random_state=42)\n",
    "train_inputs_bc_l, test_inputs_bc_l, train_temp_inp_bc_l, test_temp_inp_bc_l = train_test_split(inputs_b_l, temp_inp_bc_l, test_size=0.2, random_state=42)\n",
    "train_inputs_bc_r, test_inputs_bc_r, train_temp_inp_bc_r, test_temp_inp_bc_r = train_test_split(inputs_b_r, temp_inp_bc_r, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, temp_inp,transform=None, target_transform =None):\n",
    "        self.inputs = inputs\n",
    "        self.temp_inp = temp_inp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.temp_inp[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "  \n",
    "train_dataset = TensorDataset(train_inputs, train_temp_inp) # Create the training dataset\n",
    "# val_dataset = TensorDataset(val_inputs, val_temp_inp) # Create the validation dataset\n",
    "test_dataset = TensorDataset(test_inputs, test_temp_inp) # Create the test dataset\n",
    "\n",
    "train_dataset_init = TensorDataset(train_inputs_init, train_temp_inp_init) # Create the training dataset\n",
    "test_dataset_init = TensorDataset(test_inputs_init, test_temp_inp_init) # Create the test dataset\n",
    "train_dataset_bc_l = TensorDataset(train_inputs_bc_l, train_temp_inp_bc_l) # Create the training dataset\n",
    "test_dataset_bc_l = TensorDataset(test_inputs_bc_l, test_temp_inp_bc_l) # Create the test dataset\n",
    "train_dataset_bc_r = TensorDataset(train_inputs_bc_r, train_temp_inp_bc_r) # Create the training dataset\n",
    "test_dataset_bc_r = TensorDataset(test_inputs_bc_r, test_temp_inp_bc_r) # Create the test dataset\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "random_sampler_train = RandomSampler(train_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "# random_sampler_val = RandomSampler(val_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the validation dataset\n",
    "random_sampler_test = RandomSampler(test_dataset, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "\n",
    "random_sampler_train_init = RandomSampler(train_dataset_init, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_init = RandomSampler(test_dataset_init, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "random_sampler_train_bc_l = RandomSampler(train_dataset_bc_l, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_bc_l = RandomSampler(test_dataset_bc_l, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "random_sampler_train_bc_r = RandomSampler(train_dataset_bc_r, replacement=True, num_samples=batch_size) # Create a random sampler for the training dataset\n",
    "random_sampler_test_bc_r = RandomSampler(test_dataset_bc_r, replacement=True, num_samples=batch_size) # Create a random sampler for the test dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=random_sampler_train) # Create the training dataloader\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=random_sampler_val) # Create the validation dataloader\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, sampler=random_sampler_test) # Create the test dataloader\n",
    "\n",
    "train_loader_init = DataLoader(train_dataset_init, batch_size=batch_size, sampler=random_sampler_train_init) # Create the training dataloader\n",
    "test_loader_init = DataLoader(test_dataset_init, batch_size=batch_size, sampler=random_sampler_test_init) # Create the test dataloader\n",
    "train_loader_bc_l = DataLoader(train_dataset_bc_l, batch_size=batch_size, sampler=random_sampler_train_bc_l) # Create the training dataloader\n",
    "test_loader_bc_l = DataLoader(test_dataset_bc_l, batch_size=batch_size, sampler=random_sampler_test_bc_l) # Create the test dataloader\n",
    "train_loader_bc_r = DataLoader(train_dataset_bc_r, batch_size=batch_size, sampler=random_sampler_train_bc_r) # Create the training dataloader\n",
    "test_loader_bc_r = DataLoader(test_dataset_bc_r, batch_size=batch_size, sampler=random_sampler_test_bc_r) # Create the test dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Architecture Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the neural network architecture\n",
    "class Mushydata(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size): # This is the constructor\n",
    "        super(Mushydata, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t):                               # This is the forward pass\n",
    "        input_features = torch.cat([x, t], dim=1)          # Concatenate the input features\n",
    "        m = self.base(input_features)                                 # Pass through the third layer\n",
    "        return m                    # Return the output of the network\n",
    "\n",
    "\n",
    "# features = torch.rand(1, 2)\n",
    "# model = HeatPINN(2, 20, 1)\n",
    "# output = model(features[:, 0:1], features[:, 1:2])\n",
    "# print(output)\n",
    "\n",
    "\n",
    "# Loss function for data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamters Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 40\n",
    "learning_rate = 0.004\n",
    "epochs = 30000\n",
    "# alpha = 0.01  # Adjust this value based on your problem\n",
    "# boundary_value = 313.0\n",
    "# initial_value = init_temp\n",
    "# Initialize the model\n",
    "model = Mushydata(input_size=2, hidden_size=hidden_size,output_size=1).to(device)\n",
    "lambd = 0.1\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss List Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of train_loader is <class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(f\"Datatype of train_loader is {type(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_fn_data(u_pred, u_true):\n",
    "#     return nn.MSELoss()(u_pred, u_true)\n",
    "\n",
    "# def l1_regularization(model, lambd):\n",
    "#     l1_reg = sum(param.abs().sum() for param in model.parameters())\n",
    "#     return l1_reg * lambd\n",
    "\n",
    "# def pde_loss(u_pred,x,t):\n",
    "#     # u_pred.requires_grad = True\n",
    "#     x.requires_grad = True\n",
    "#     t.requires_grad = True\n",
    "    \n",
    "#     u_pred = model(x,t).requires_grad_()\n",
    "#     u_t = torch.autograd.grad(u_pred, t, \n",
    "#                                 torch.ones_like(u_pred).to(device),\n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused=True,\n",
    "#                                 )[0] # Calculate the first time derivative\n",
    "#     if u_t is None:\n",
    "#         raise RuntimeError(\"u_t is None\")\n",
    "\n",
    "#     u_x = torch.autograd.grad(u_pred, \n",
    "#                                 x, \n",
    "#                                 torch.ones_like(u_pred).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused =True)[0] # Calculate the first space derivative\n",
    "            \n",
    "#     u_xx = torch.autograd.grad(u_x, \n",
    "#                                 x, \n",
    "#                                 torch.ones_like(u_x).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused=True)[0] \n",
    "    \n",
    "#     T_S_tensor = torch.tensor(T_S, device=device)\n",
    "#     T_L_tensor = torch.tensor(T_L, device=device)\n",
    "    \n",
    "#     k_m = torch.where((u_pred >= T_S_tensor) * (u_pred <= T_L_tensor),\\\n",
    "#                        kramp(u_pred, k_l,k_s,T_L,T_S),torch.tensor(0.0,device=device))\n",
    "#     cp_m = torch.where(u_pred >= T_S_tensor * u_pred <= T_L_tensor, cp_ramp((u_pred), cp_l,cp_s,T_L,T_S))\n",
    "#     rho_m = torch.where(u_pred >= T_S_tensor * u_pred <= T_L_tensor, rho_ramp((u_pred), rho_l,rho_s,T_L,T_S))\n",
    "#     m_eff = (k_m / (rho_m * (cp_m + (L_fusion / (T_L - T_S)))))\n",
    "\n",
    "#     alpha_T = torch.where(u_pred >= T_L_tensor, alpha_l, torch.where(u_pred<=T_S_tensor,alpha_s ,m_eff))\n",
    "#     alpha_T = 1\n",
    "#     residual = u_t - alpha_T * u_xx\n",
    "\n",
    "#     return nn.MSELoss()(residual,torch.zeros_like(residual))\n",
    "\n",
    "# def boundary_loss(u_pred,x,t,t_surr):\n",
    "    \n",
    "#     u_x = torch.autograd.grad(u_pred,x, \n",
    "#                                 torch.ones_like(u_pred).to(device), \n",
    "#                                 create_graph=True,\n",
    "#                                 allow_unused =True)[0] # Calculate the first space derivative\n",
    "#     t_surr_t = torch.tensor(t_surr, device=device)\n",
    "#     res_l = u_x -(htc* (u_pred-t_surr_t))\n",
    "   \n",
    "\n",
    "#     return nn.MSELoss()(res_l,torch.zeros_like(res_l))\n",
    "\n",
    "# def ic_loss(u_pred):\n",
    "#     temp_init_tsr = torch.tensor(temp_init[1:-1],device=device)\n",
    "#     ic = u_pred -temp_init_tsr\n",
    "#     return nn.MSELoss()(ic,torch.zeros_like(ic))\n",
    "\n",
    "def accuracy(u_pred, u_true):\n",
    "    return torch.mean(torch.abs(u_pred - u_true) / u_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation and Testing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, model, loss_fn_data, optimizer, train_dataloader,):\n",
    "    train_losses = []  # Initialize the list to store the training losses\n",
    "    val_losses = []    # Initialize the list to store the validation losses\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()                                                                           # Set the model to training mode\n",
    "        train_loss = 0                                                                              # Initialize the training loss\n",
    "        train_accuracy = 0\n",
    "        for (batch,batch_init,batch_left,batch_right) in \\\n",
    "             zip (train_dataloader,train_loader_init,train_loader_bc_l,train_inputs_bc_r):                                                          # Loop through the training dataloader\n",
    "            inputs, temp_inp= batch                                                             # Get the inputs and the true values\n",
    "            inputs_init, temp_inp_init= batch_init                                                             # Get the inputs and the true values \n",
    "            inputs_left, temp_inp_left= batch_left                                                             # Get the inputs and the true values\n",
    "            inputs_right, temp_inp_right= batch_right                                                             # Get the inputs and the true values\n",
    "\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)                             # Move the inputs and true values to the GPU\n",
    "            inputs_init, temp_inp_init= inputs_init.to(device), temp_inp_init.to(device)                             # Move the inputs and true values to the GPU\n",
    "            inputs_left, temp_inp_left= inputs_left.to(device), temp_inp_left.to(device)                             # Move the inputs and true values to the GPU\n",
    "            inputs_right, temp_inp_right= inputs_right.to(device), temp_inp_right.to(device)                             # Move the inputs and true values to the GPU\n",
    "\n",
    "            optimizer.zero_grad()                                                                    # Zero the gradients\n",
    "            \n",
    "            # Forward pass\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).to(device)                       # Get the predictions\n",
    "            u_initl = model(inputs_init[:,0].unsqueeze(1), inputs_init[:,1].unsqueeze(1)).to(device)                       # Get the predictions\n",
    "            \n",
    "            u_left = model(inputs_b_l[:,0].unsqueeze(1), inputs_b_l[:,1].unsqueeze(1)).to(device)               # Left boundary of the temperature\n",
    "            u_right = model(inputs_b_r[:,0].unsqueeze(1), inputs_b_r[:,1].unsqueeze(1)).to(device)             # Right boundary of the temperature\n",
    "\n",
    "            # Loss calculation\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp)                                              # Calculate the data loss\n",
    "            \n",
    "            pd_loss = pde_loss(model,inputs[:,0].unsqueeze(1),inputs[:,1].unsqueeze(1))             # Calculate the PDE loss\n",
    "            # pd_loss = 0\n",
    "            \n",
    "            initc_loss = ic_loss(u_initl) \n",
    "            # initc_loss =0                                                      # Calculate initial condition loss\n",
    "            \n",
    "            bc_loss_left = boundary_loss(model,inputs_b_l[:,0].unsqueeze(1),inputs_b_l[:,1].unsqueeze(1),t_surr) # Calculate the left boundary condition loss\n",
    "            bc_loss_right = boundary_loss(model,inputs_b_r[:,0].unsqueeze(1),inputs_b_r[:,1].unsqueeze(1),t_surr) # Calculate the right boundary condition loss\n",
    "            bc_loss = bc_loss_left + bc_loss_right\n",
    "            # l1_regularization_loss = l1_regularization(model, lambda_l1)                      # Calculate the L1 regularization loss\n",
    "            # loss = data_loss  + pd_loss + initc_loss + bc_loss                                              # Calculate the total loss\n",
    "            loss = data_loss + pd_loss + initc_loss + bc_loss\n",
    "            train_accuracy += accuracy(u_pred, temp_inp)                                                              # Calculate the total loss\n",
    "            # Backpropagation\n",
    "            loss.backward(retain_graph=True)                                                        # Backpropagate the gradients\n",
    "            \n",
    "            optimizer.step()                                                                           # Update the weights\n",
    "            \n",
    "            train_loss += loss.item()                                                           # Add the loss to the training set loss                 \n",
    "\n",
    "        \n",
    "\n",
    "        # model.eval()\n",
    "        # test_loss = 0\n",
    "        # test_accuracy = 0\n",
    "        # with torch.no_grad():   \n",
    "        #     for batch in test_dataloader:\n",
    "        #         inputs, temp_inp= batch\n",
    "        #         inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "        #         u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "        #         data_loss = loss_fn_data(u_pred, temp_inp)\n",
    "        #         # l1_regularization_loss = l1_regularization(model, lambd)\n",
    "        #         # loss = data_loss  + l1_regularization_loss\n",
    "        #         loss = data_loss\n",
    "        #         test_accuracy = accuracy(u_pred, temp_inp)\n",
    "        #         test_loss += loss.item()\n",
    "        #     test_losses.append(test_loss)\n",
    "\n",
    "        train_losses.append(train_loss)                                                   # Append the training loss to the list of training losses\n",
    "        \n",
    "        # if epoch % 10 == 0:\n",
    "        #     print(f\"Epoch {epoch}, Training-Loss {train_loss:.4e}\")\n",
    "        \n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Training-Loss {train_loss:.4e}, Data-loss {data_loss:.4e}\\\n",
    "                  , pde-loss {pd_loss:.4e}, initc-loss {initc_loss:.4e}\\\n",
    "                    bc_loss {bc_loss:.4e}\") \n",
    "\n",
    "    return train_losses, val_losses                                                             # Return the training and validation losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(epochs, model, loss_fn_data, optimizer, train_dataloader, test_dataloader):\n",
    "      \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    with torch.no_grad():   \n",
    "        for batch in test_dataloader:\n",
    "            inputs, temp_inp= batch\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp)\n",
    "            # l1_regularization_loss = l1_regularization(model, lambd)\n",
    "            # loss = data_loss  + l1_regularization_loss\n",
    "            loss = data_loss\n",
    "            test_accuracy = accuracy(u_pred, temp_inp)\n",
    "            test_loss += loss.item()\n",
    "        test_losses.append(test_loss)\n",
    "    if epochs % 10 == 0:\n",
    "        print(f\"Epoch {epochs}, Test-Loss {test_loss:.4e}, Test-Accuracy {test_accuracy:.4e}\")      \n",
    "    return test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Button "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Training-Loss 5.1526e+07, Data-loss 6.6002e+05                  , pde-loss 4.0399e-02, initc-loss 8.4476e+05                    bc_loss 5.0021e+07\n",
      "Epoch 10, Training-Loss 5.1338e+07, Data-loss 6.5971e+05                  , pde-loss 4.0380e-02, initc-loss 8.4323e+05                    bc_loss 4.9835e+07\n",
      "Epoch 20, Training-Loss 5.1155e+07, Data-loss 6.5529e+05                  , pde-loss 1.0491e-01, initc-loss 8.4171e+05                    bc_loss 4.9658e+07\n",
      "Epoch 30, Training-Loss 5.0956e+07, Data-loss 6.5302e+05                  , pde-loss 2.0972e-01, initc-loss 8.4000e+05                    bc_loss 4.9463e+07\n",
      "Epoch 40, Training-Loss 5.0719e+07, Data-loss 6.4554e+05                  , pde-loss 2.8612e-01, initc-loss 8.3797e+05                    bc_loss 4.9236e+07\n",
      "Epoch 50, Training-Loss 5.0444e+07, Data-loss 6.4457e+05                  , pde-loss 1.2738e+00, initc-loss 8.3556e+05                    bc_loss 4.8964e+07\n",
      "Epoch 60, Training-Loss 5.0123e+07, Data-loss 6.5243e+05                  , pde-loss 9.5243e-01, initc-loss 8.3263e+05                    bc_loss 4.8638e+07\n",
      "Epoch 70, Training-Loss 4.9719e+07, Data-loss 6.3487e+05                  , pde-loss 2.1552e+00, initc-loss 8.2918e+05                    bc_loss 4.8255e+07\n",
      "Epoch 80, Training-Loss 4.9257e+07, Data-loss 6.2406e+05                  , pde-loss 2.3382e+00, initc-loss 8.2519e+05                    bc_loss 4.7807e+07\n",
      "Epoch 90, Training-Loss 4.8756e+07, Data-loss 6.3904e+05                  , pde-loss 4.5887e+00, initc-loss 8.2060e+05                    bc_loss 4.7296e+07\n",
      "Epoch 100, Training-Loss 4.8162e+07, Data-loss 6.2219e+05                  , pde-loss 8.3335e+00, initc-loss 8.1510e+05                    bc_loss 4.6725e+07\n",
      "Epoch 110, Training-Loss 4.7493e+07, Data-loss 6.2314e+05                  , pde-loss 6.6319e+00, initc-loss 8.0949e+05                    bc_loss 4.6060e+07\n",
      "Epoch 120, Training-Loss 4.6744e+07, Data-loss 6.0984e+05                  , pde-loss 2.0203e+01, initc-loss 8.0290e+05                    bc_loss 4.5331e+07\n",
      "Epoch 130, Training-Loss 4.5926e+07, Data-loss 6.0690e+05                  , pde-loss 3.6492e+01, initc-loss 7.9538e+05                    bc_loss 4.4523e+07\n",
      "Epoch 140, Training-Loss 4.5054e+07, Data-loss 6.0526e+05                  , pde-loss 5.4812e+01, initc-loss 7.8729e+05                    bc_loss 4.3662e+07\n",
      "Epoch 150, Training-Loss 4.4098e+07, Data-loss 6.0386e+05                  , pde-loss 6.0062e+01, initc-loss 7.7828e+05                    bc_loss 4.2716e+07\n",
      "Epoch 160, Training-Loss 4.3145e+07, Data-loss 5.8393e+05                  , pde-loss 7.7968e+01, initc-loss 7.6903e+05                    bc_loss 4.1792e+07\n",
      "Epoch 170, Training-Loss 4.2018e+07, Data-loss 5.8455e+05                  , pde-loss 5.3591e+01, initc-loss 7.5902e+05                    bc_loss 4.0674e+07\n",
      "Epoch 180, Training-Loss 4.0875e+07, Data-loss 5.7388e+05                  , pde-loss 2.4285e+02, initc-loss 7.4833e+05                    bc_loss 3.9553e+07\n",
      "Epoch 190, Training-Loss 3.9673e+07, Data-loss 5.5673e+05                  , pde-loss 1.5182e+02, initc-loss 7.3730e+05                    bc_loss 3.8379e+07\n",
      "Epoch 200, Training-Loss 3.8490e+07, Data-loss 5.5808e+05                  , pde-loss 4.8591e+02, initc-loss 7.2642e+05                    bc_loss 3.7205e+07\n",
      "Epoch 210, Training-Loss 3.7220e+07, Data-loss 5.4477e+05                  , pde-loss 4.8898e+02, initc-loss 7.1348e+05                    bc_loss 3.5962e+07\n",
      "Epoch 220, Training-Loss 3.5920e+07, Data-loss 5.2685e+05                  , pde-loss 6.9945e+02, initc-loss 7.0046e+05                    bc_loss 3.4692e+07\n",
      "Epoch 230, Training-Loss 3.4589e+07, Data-loss 5.1135e+05                  , pde-loss 1.6820e+03, initc-loss 6.8787e+05                    bc_loss 3.3388e+07\n",
      "Epoch 240, Training-Loss 3.3281e+07, Data-loss 5.0195e+05                  , pde-loss 1.4946e+03, initc-loss 6.7448e+05                    bc_loss 3.2103e+07\n",
      "Epoch 250, Training-Loss 3.1884e+07, Data-loss 4.9404e+05                  , pde-loss 1.7359e+03, initc-loss 6.6085e+05                    bc_loss 3.0727e+07\n",
      "Epoch 260, Training-Loss 3.0590e+07, Data-loss 4.8293e+05                  , pde-loss 9.8045e+02, initc-loss 6.4694e+05                    bc_loss 2.9460e+07\n",
      "Epoch 270, Training-Loss 2.9449e+07, Data-loss 4.7906e+05                  , pde-loss 1.0823e+03, initc-loss 6.4016e+05                    bc_loss 2.8328e+07\n",
      "Epoch 280, Training-Loss 2.7957e+07, Data-loss 4.5034e+05                  , pde-loss 3.2714e+03, initc-loss 6.2956e+05                    bc_loss 2.6874e+07\n",
      "Epoch 290, Training-Loss 2.6532e+07, Data-loss 4.4551e+05                  , pde-loss 1.4875e+03, initc-loss 6.1064e+05                    bc_loss 2.5475e+07\n",
      "Epoch 300, Training-Loss 2.5126e+07, Data-loss 4.4042e+05                  , pde-loss 2.2104e+03, initc-loss 5.9435e+05                    bc_loss 2.4089e+07\n",
      "Epoch 310, Training-Loss 2.3720e+07, Data-loss 4.1200e+05                  , pde-loss 3.4927e+03, initc-loss 5.8067e+05                    bc_loss 2.2724e+07\n",
      "Epoch 320, Training-Loss 2.2358e+07, Data-loss 4.0763e+05                  , pde-loss 6.2080e+03, initc-loss 5.6383e+05                    bc_loss 2.1381e+07\n",
      "Epoch 330, Training-Loss 2.1014e+07, Data-loss 4.0568e+05                  , pde-loss 2.5235e+03, initc-loss 5.4913e+05                    bc_loss 2.0057e+07\n",
      "Epoch 340, Training-Loss 1.9669e+07, Data-loss 3.9054e+05                  , pde-loss 4.9355e+03, initc-loss 5.3353e+05                    bc_loss 1.8740e+07\n",
      "Epoch 350, Training-Loss 1.8511e+07, Data-loss 3.7460e+05                  , pde-loss 6.8533e+03, initc-loss 5.1736e+05                    bc_loss 1.7612e+07\n",
      "Epoch 360, Training-Loss 1.7159e+07, Data-loss 3.6139e+05                  , pde-loss 6.5553e+03, initc-loss 5.0206e+05                    bc_loss 1.6289e+07\n",
      "Epoch 370, Training-Loss 1.6052e+07, Data-loss 3.4626e+05                  , pde-loss 4.3564e+03, initc-loss 4.8787e+05                    bc_loss 1.5214e+07\n",
      "Epoch 380, Training-Loss 1.4768e+07, Data-loss 3.3719e+05                  , pde-loss 9.2212e+03, initc-loss 4.7297e+05                    bc_loss 1.3948e+07\n",
      "Epoch 390, Training-Loss 1.3618e+07, Data-loss 3.2620e+05                  , pde-loss 2.4262e+04, initc-loss 4.5785e+05                    bc_loss 1.2810e+07\n",
      "Epoch 400, Training-Loss 1.2675e+07, Data-loss 3.0864e+05                  , pde-loss 1.5916e+04, initc-loss 4.4465e+05                    bc_loss 1.1905e+07\n",
      "Epoch 410, Training-Loss 1.1631e+07, Data-loss 3.0416e+05                  , pde-loss 4.5334e+04, initc-loss 4.2967e+05                    bc_loss 1.0852e+07\n",
      "Epoch 420, Training-Loss 1.0590e+07, Data-loss 2.9742e+05                  , pde-loss 1.7384e+04, initc-loss 4.1652e+05                    bc_loss 9.8582e+06\n",
      "Epoch 430, Training-Loss 9.6171e+06, Data-loss 2.8826e+05                  , pde-loss 1.7950e+04, initc-loss 4.0380e+05                    bc_loss 8.9071e+06\n",
      "Epoch 440, Training-Loss 8.8762e+06, Data-loss 2.7744e+05                  , pde-loss 1.2802e+04, initc-loss 3.9161e+05                    bc_loss 8.1943e+06\n",
      "Epoch 450, Training-Loss 8.0039e+06, Data-loss 2.5322e+05                  , pde-loss 3.8774e+04, initc-loss 3.7856e+05                    bc_loss 7.3334e+06\n",
      "Epoch 460, Training-Loss 7.1536e+06, Data-loss 2.4760e+05                  , pde-loss 6.8986e+03, initc-loss 3.6575e+05                    bc_loss 6.5333e+06\n",
      "Epoch 470, Training-Loss 6.4701e+06, Data-loss 2.4772e+05                  , pde-loss 1.0193e+04, initc-loss 3.5404e+05                    bc_loss 5.8582e+06\n",
      "Epoch 480, Training-Loss 5.8372e+06, Data-loss 2.4401e+05                  , pde-loss 2.3484e+04, initc-loss 3.5273e+05                    bc_loss 5.2170e+06\n",
      "Epoch 490, Training-Loss 5.2154e+06, Data-loss 2.2465e+05                  , pde-loss 1.8327e+04, initc-loss 3.3410e+05                    bc_loss 4.6383e+06\n",
      "Epoch 500, Training-Loss 4.8235e+06, Data-loss 2.1351e+05                  , pde-loss 3.9371e+04, initc-loss 3.2579e+05                    bc_loss 4.2448e+06\n",
      "Epoch 510, Training-Loss 4.2508e+06, Data-loss 2.0699e+05                  , pde-loss 2.4248e+04, initc-loss 3.1308e+05                    bc_loss 3.7065e+06\n",
      "Epoch 520, Training-Loss 3.7441e+06, Data-loss 1.9890e+05                  , pde-loss 1.4263e+04, initc-loss 3.0349e+05                    bc_loss 3.2274e+06\n",
      "Epoch 530, Training-Loss 3.3012e+06, Data-loss 1.9075e+05                  , pde-loss 2.1839e+04, initc-loss 2.9529e+05                    bc_loss 2.7933e+06\n",
      "Epoch 540, Training-Loss 3.1074e+06, Data-loss 1.9324e+05                  , pde-loss 4.2114e+04, initc-loss 2.8998e+05                    bc_loss 2.5821e+06\n",
      "Epoch 550, Training-Loss 2.7162e+06, Data-loss 1.8342e+05                  , pde-loss 1.5922e+04, initc-loss 2.8218e+05                    bc_loss 2.2347e+06\n",
      "Epoch 560, Training-Loss 2.3360e+06, Data-loss 1.7103e+05                  , pde-loss 1.5960e+04, initc-loss 2.7534e+05                    bc_loss 1.8736e+06\n",
      "Epoch 570, Training-Loss 2.0864e+06, Data-loss 1.6823e+05                  , pde-loss 7.3529e+04, initc-loss 2.6547e+05                    bc_loss 1.5792e+06\n",
      "Epoch 580, Training-Loss 1.7796e+06, Data-loss 1.6134e+05                  , pde-loss 2.5630e+04, initc-loss 2.5797e+05                    bc_loss 1.3347e+06\n",
      "Epoch 590, Training-Loss 1.5583e+06, Data-loss 1.5825e+05                  , pde-loss 1.6011e+04, initc-loss 2.5206e+05                    bc_loss 1.1320e+06\n",
      "Epoch 600, Training-Loss 1.4023e+06, Data-loss 1.5436e+05                  , pde-loss 4.0388e+04, initc-loss 2.4720e+05                    bc_loss 9.6032e+05\n",
      "Epoch 610, Training-Loss 1.2928e+06, Data-loss 1.4804e+05                  , pde-loss 4.8782e+04, initc-loss 2.4114e+05                    bc_loss 8.5489e+05\n",
      "Epoch 620, Training-Loss 1.1402e+06, Data-loss 1.5133e+05                  , pde-loss 4.5798e+04, initc-loss 2.3386e+05                    bc_loss 7.0917e+05\n",
      "Epoch 630, Training-Loss 9.7059e+05, Data-loss 1.3824e+05                  , pde-loss 1.3435e+04, initc-loss 2.3324e+05                    bc_loss 5.8567e+05\n",
      "Epoch 640, Training-Loss 8.9999e+05, Data-loss 1.3214e+05                  , pde-loss 5.7315e+04, initc-loss 2.2797e+05                    bc_loss 4.8256e+05\n",
      "Epoch 650, Training-Loss 8.1880e+05, Data-loss 1.3168e+05                  , pde-loss 1.8548e+04, initc-loss 2.2161e+05                    bc_loss 4.4696e+05\n",
      "Epoch 660, Training-Loss 7.7652e+05, Data-loss 1.3071e+05                  , pde-loss 3.2455e+04, initc-loss 2.2034e+05                    bc_loss 3.9301e+05\n",
      "Epoch 670, Training-Loss 6.9289e+05, Data-loss 1.2676e+05                  , pde-loss 3.3120e+04, initc-loss 2.1684e+05                    bc_loss 3.1618e+05\n",
      "Epoch 680, Training-Loss 6.5711e+05, Data-loss 1.2532e+05                  , pde-loss 2.4454e+04, initc-loss 2.1263e+05                    bc_loss 2.9470e+05\n",
      "Epoch 690, Training-Loss 6.1921e+05, Data-loss 1.2409e+05                  , pde-loss 2.6798e+04, initc-loss 2.0920e+05                    bc_loss 2.5913e+05\n",
      "Epoch 700, Training-Loss 5.4369e+05, Data-loss 1.2345e+05                  , pde-loss 2.1455e+04, initc-loss 2.0794e+05                    bc_loss 1.9084e+05\n",
      "Epoch 710, Training-Loss 4.9621e+05, Data-loss 1.1588e+05                  , pde-loss 3.2219e+04, initc-loss 2.0562e+05                    bc_loss 1.4248e+05\n",
      "Epoch 720, Training-Loss 4.3648e+05, Data-loss 1.1039e+05                  , pde-loss 1.8336e+04, initc-loss 2.0023e+05                    bc_loss 1.0753e+05\n",
      "Epoch 730, Training-Loss 4.3510e+05, Data-loss 1.1888e+05                  , pde-loss 3.3791e+04, initc-loss 2.0153e+05                    bc_loss 8.0896e+04\n",
      "Epoch 740, Training-Loss 3.9842e+05, Data-loss 1.1077e+05                  , pde-loss 2.6332e+04, initc-loss 1.9999e+05                    bc_loss 6.1336e+04\n",
      "Epoch 750, Training-Loss 3.7075e+05, Data-loss 1.1818e+05                  , pde-loss 1.5151e+04, initc-loss 1.9156e+05                    bc_loss 4.5851e+04\n",
      "Epoch 760, Training-Loss 3.5698e+05, Data-loss 1.1246e+05                  , pde-loss 1.6524e+04, initc-loss 1.9145e+05                    bc_loss 3.6548e+04\n",
      "Epoch 770, Training-Loss 3.6949e+05, Data-loss 1.1796e+05                  , pde-loss 2.8673e+04, initc-loss 1.9603e+05                    bc_loss 2.6827e+04\n",
      "Epoch 780, Training-Loss 3.3196e+05, Data-loss 1.0748e+05                  , pde-loss 1.5984e+04, initc-loss 1.8806e+05                    bc_loss 2.0428e+04\n",
      "Epoch 790, Training-Loss 3.2813e+05, Data-loss 1.0693e+05                  , pde-loss 1.8909e+04, initc-loss 1.8714e+05                    bc_loss 1.5147e+04\n",
      "Epoch 800, Training-Loss 3.1421e+05, Data-loss 1.0666e+05                  , pde-loss 7.8367e+03, initc-loss 1.8877e+05                    bc_loss 1.0936e+04\n",
      "Epoch 810, Training-Loss 3.3019e+05, Data-loss 1.0818e+05                  , pde-loss 2.5253e+04, initc-loss 1.8857e+05                    bc_loss 8.1864e+03\n",
      "Epoch 820, Training-Loss 3.2680e+05, Data-loss 1.0726e+05                  , pde-loss 2.6880e+04, initc-loss 1.8641e+05                    bc_loss 6.2491e+03\n",
      "Epoch 830, Training-Loss 3.0558e+05, Data-loss 1.0125e+05                  , pde-loss 9.7658e+03, initc-loss 1.8954e+05                    bc_loss 5.0150e+03\n",
      "Epoch 840, Training-Loss 3.2113e+05, Data-loss 1.0251e+05                  , pde-loss 2.9815e+04, initc-loss 1.8501e+05                    bc_loss 3.7986e+03\n",
      "Epoch 850, Training-Loss 3.0593e+05, Data-loss 1.0201e+05                  , pde-loss 1.5811e+04, initc-loss 1.8503e+05                    bc_loss 3.0735e+03\n",
      "Epoch 860, Training-Loss 3.0617e+05, Data-loss 1.0400e+05                  , pde-loss 1.5618e+04, initc-loss 1.8381e+05                    bc_loss 2.7362e+03\n",
      "Epoch 870, Training-Loss 3.0784e+05, Data-loss 1.0140e+05                  , pde-loss 1.9846e+04, initc-loss 1.8393e+05                    bc_loss 2.6659e+03\n",
      "Epoch 880, Training-Loss 3.3013e+05, Data-loss 1.0535e+05                  , pde-loss 3.9281e+04, initc-loss 1.8318e+05                    bc_loss 2.3202e+03\n",
      "Epoch 890, Training-Loss 2.9876e+05, Data-loss 1.0261e+05                  , pde-loss 1.1753e+04, initc-loss 1.8211e+05                    bc_loss 2.2921e+03\n",
      "Epoch 900, Training-Loss 2.9904e+05, Data-loss 1.0094e+05                  , pde-loss 1.3304e+04, initc-loss 1.8250e+05                    bc_loss 2.2894e+03\n",
      "Epoch 910, Training-Loss 2.8968e+05, Data-loss 9.9578e+04                  , pde-loss 7.8299e+03, initc-loss 1.8004e+05                    bc_loss 2.2319e+03\n",
      "Epoch 920, Training-Loss 3.0673e+05, Data-loss 1.0364e+05                  , pde-loss 2.1355e+04, initc-loss 1.7968e+05                    bc_loss 2.0512e+03\n",
      "Epoch 930, Training-Loss 3.1185e+05, Data-loss 1.0219e+05                  , pde-loss 2.7143e+04, initc-loss 1.8054e+05                    bc_loss 1.9719e+03\n",
      "Epoch 940, Training-Loss 2.9952e+05, Data-loss 9.9619e+04                  , pde-loss 1.5148e+04, initc-loss 1.8274e+05                    bc_loss 2.0032e+03\n",
      "Epoch 950, Training-Loss 2.9643e+05, Data-loss 9.9786e+04                  , pde-loss 1.4894e+04, initc-loss 1.7966e+05                    bc_loss 2.0871e+03\n",
      "Epoch 960, Training-Loss 2.9264e+05, Data-loss 1.0033e+05                  , pde-loss 1.0933e+04, initc-loss 1.7918e+05                    bc_loss 2.1906e+03\n",
      "Epoch 970, Training-Loss 2.8955e+05, Data-loss 9.9986e+04                  , pde-loss 8.4241e+03, initc-loss 1.7889e+05                    bc_loss 2.2544e+03\n",
      "Epoch 980, Training-Loss 2.8907e+05, Data-loss 9.9366e+04                  , pde-loss 6.8387e+03, initc-loss 1.8060e+05                    bc_loss 2.2691e+03\n",
      "Epoch 990, Training-Loss 2.9633e+05, Data-loss 9.9842e+04                  , pde-loss 1.4837e+04, initc-loss 1.7948e+05                    bc_loss 2.1667e+03\n",
      "Epoch 1000, Training-Loss 3.0211e+05, Data-loss 9.8674e+04                  , pde-loss 1.8124e+04, initc-loss 1.8307e+05                    bc_loss 2.2424e+03\n",
      "Epoch 1010, Training-Loss 3.0018e+05, Data-loss 9.8597e+04                  , pde-loss 1.9214e+04, initc-loss 1.8023e+05                    bc_loss 2.1360e+03\n",
      "Epoch 1020, Training-Loss 2.9123e+05, Data-loss 9.6673e+04                  , pde-loss 1.0963e+04, initc-loss 1.8153e+05                    bc_loss 2.0655e+03\n",
      "Epoch 1030, Training-Loss 2.8605e+05, Data-loss 9.7389e+04                  , pde-loss 7.3633e+03, initc-loss 1.7916e+05                    bc_loss 2.1385e+03\n",
      "Epoch 1040, Training-Loss 2.9021e+05, Data-loss 9.6389e+04                  , pde-loss 8.9076e+03, initc-loss 1.7993e+05                    bc_loss 4.9796e+03\n",
      "Epoch 1050, Training-Loss 2.8591e+05, Data-loss 9.3465e+04                  , pde-loss 9.3619e+03, initc-loss 1.8047e+05                    bc_loss 2.6149e+03\n",
      "Epoch 1060, Training-Loss 2.9288e+05, Data-loss 9.5910e+04                  , pde-loss 1.7922e+04, initc-loss 1.7682e+05                    bc_loss 2.2326e+03\n",
      "Epoch 1070, Training-Loss 2.8531e+05, Data-loss 9.7532e+04                  , pde-loss 8.1486e+03, initc-loss 1.7750e+05                    bc_loss 2.1284e+03\n",
      "Epoch 1080, Training-Loss 2.8762e+05, Data-loss 9.6071e+04                  , pde-loss 1.1692e+04, initc-loss 1.7783e+05                    bc_loss 2.0258e+03\n",
      "Epoch 1090, Training-Loss 2.8429e+05, Data-loss 9.6113e+04                  , pde-loss 8.9488e+03, initc-loss 1.7704e+05                    bc_loss 2.1942e+03\n",
      "Epoch 1100, Training-Loss 2.8399e+05, Data-loss 9.6096e+04                  , pde-loss 7.8910e+03, initc-loss 1.7777e+05                    bc_loss 2.2350e+03\n",
      "Epoch 1110, Training-Loss 3.0626e+05, Data-loss 1.0028e+05                  , pde-loss 2.4964e+04, initc-loss 1.7876e+05                    bc_loss 2.2597e+03\n",
      "Epoch 1120, Training-Loss 2.8414e+05, Data-loss 9.5913e+04                  , pde-loss 8.3139e+03, initc-loss 1.7766e+05                    bc_loss 2.2502e+03\n",
      "Epoch 1130, Training-Loss 2.9025e+05, Data-loss 9.6643e+04                  , pde-loss 1.5633e+04, initc-loss 1.7579e+05                    bc_loss 2.1868e+03\n",
      "Epoch 1140, Training-Loss 2.8318e+05, Data-loss 9.6462e+04                  , pde-loss 8.4052e+03, initc-loss 1.7614e+05                    bc_loss 2.1770e+03\n",
      "Epoch 1150, Training-Loss 2.8335e+05, Data-loss 9.3277e+04                  , pde-loss 1.2619e+04, initc-loss 1.7538e+05                    bc_loss 2.0769e+03\n",
      "Epoch 1160, Training-Loss 2.8825e+05, Data-loss 9.5848e+04                  , pde-loss 1.4316e+04, initc-loss 1.7593e+05                    bc_loss 2.1542e+03\n",
      "Epoch 1170, Training-Loss 2.9100e+05, Data-loss 9.9931e+04                  , pde-loss 1.2341e+04, initc-loss 1.7624e+05                    bc_loss 2.4786e+03\n",
      "Epoch 1180, Training-Loss 2.8196e+05, Data-loss 9.5584e+04                  , pde-loss 9.6669e+03, initc-loss 1.7393e+05                    bc_loss 2.7697e+03\n",
      "Epoch 1190, Training-Loss 2.7677e+05, Data-loss 9.5017e+04                  , pde-loss 4.5652e+03, initc-loss 1.7396e+05                    bc_loss 3.2311e+03\n",
      "Epoch 1200, Training-Loss 2.7959e+05, Data-loss 9.6688e+04                  , pde-loss 6.4086e+03, initc-loss 1.7392e+05                    bc_loss 2.5749e+03\n",
      "Epoch 1210, Training-Loss 2.8374e+05, Data-loss 9.5820e+04                  , pde-loss 9.9214e+03, initc-loss 1.7559e+05                    bc_loss 2.4114e+03\n",
      "Epoch 1220, Training-Loss 2.8703e+05, Data-loss 9.6646e+04                  , pde-loss 8.3098e+03, initc-loss 1.7315e+05                    bc_loss 8.9286e+03\n",
      "Epoch 1230, Training-Loss 2.8498e+05, Data-loss 9.5615e+04                  , pde-loss 1.0150e+04, initc-loss 1.7593e+05                    bc_loss 3.2781e+03\n",
      "Epoch 1240, Training-Loss 2.7853e+05, Data-loss 9.6317e+04                  , pde-loss 6.7051e+03, initc-loss 1.7324e+05                    bc_loss 2.2638e+03\n",
      "Epoch 1250, Training-Loss 2.8328e+05, Data-loss 9.5831e+04                  , pde-loss 1.0837e+04, initc-loss 1.7348e+05                    bc_loss 3.1302e+03\n",
      "Epoch 1260, Training-Loss 2.8579e+05, Data-loss 9.7820e+04                  , pde-loss 1.1915e+04, initc-loss 1.7347e+05                    bc_loss 2.5821e+03\n",
      "Epoch 1270, Training-Loss 2.7772e+05, Data-loss 9.2930e+04                  , pde-loss 9.0326e+03, initc-loss 1.7260e+05                    bc_loss 3.1573e+03\n",
      "Epoch 1280, Training-Loss 2.8034e+05, Data-loss 9.8654e+04                  , pde-loss 7.0404e+03, initc-loss 1.7208e+05                    bc_loss 2.5716e+03\n",
      "Epoch 1290, Training-Loss 2.7829e+05, Data-loss 9.3688e+04                  , pde-loss 7.6077e+03, initc-loss 1.7481e+05                    bc_loss 2.1902e+03\n",
      "Epoch 1300, Training-Loss 2.7652e+05, Data-loss 9.4056e+04                  , pde-loss 6.3715e+03, initc-loss 1.7214e+05                    bc_loss 3.9512e+03\n",
      "Epoch 1310, Training-Loss 2.8028e+05, Data-loss 9.4259e+04                  , pde-loss 8.7282e+03, initc-loss 1.7494e+05                    bc_loss 2.3496e+03\n",
      "Epoch 1320, Training-Loss 2.7061e+05, Data-loss 9.1830e+04                  , pde-loss 3.8969e+03, initc-loss 1.7177e+05                    bc_loss 3.1051e+03\n",
      "Epoch 1330, Training-Loss 2.7439e+05, Data-loss 9.3923e+04                  , pde-loss 5.7866e+03, initc-loss 1.7190e+05                    bc_loss 2.7779e+03\n",
      "Epoch 1340, Training-Loss 2.7910e+05, Data-loss 9.5595e+04                  , pde-loss 1.0783e+04, initc-loss 1.6944e+05                    bc_loss 3.2755e+03\n",
      "Epoch 1350, Training-Loss 2.7804e+05, Data-loss 9.3455e+04                  , pde-loss 1.0647e+04, initc-loss 1.7133e+05                    bc_loss 2.6033e+03\n",
      "Epoch 1360, Training-Loss 2.7459e+05, Data-loss 9.2248e+04                  , pde-loss 7.6671e+03, initc-loss 1.7155e+05                    bc_loss 3.1280e+03\n",
      "Epoch 1370, Training-Loss 2.8603e+05, Data-loss 9.5452e+04                  , pde-loss 1.2819e+04, initc-loss 1.7172e+05                    bc_loss 6.0343e+03\n",
      "Epoch 1380, Training-Loss 2.8592e+05, Data-loss 9.5407e+04                  , pde-loss 1.5260e+04, initc-loss 1.7096e+05                    bc_loss 4.2938e+03\n",
      "Epoch 1390, Training-Loss 2.7579e+05, Data-loss 9.5555e+04                  , pde-loss 7.7871e+03, initc-loss 1.6971e+05                    bc_loss 2.7416e+03\n",
      "Epoch 1400, Training-Loss 2.7459e+05, Data-loss 9.5070e+04                  , pde-loss 7.2009e+03, initc-loss 1.7012e+05                    bc_loss 2.2050e+03\n",
      "Epoch 1410, Training-Loss 2.7400e+05, Data-loss 9.4441e+04                  , pde-loss 5.6424e+03, initc-loss 1.7130e+05                    bc_loss 2.6131e+03\n",
      "Epoch 1420, Training-Loss 2.7514e+05, Data-loss 9.6218e+04                  , pde-loss 6.8713e+03, initc-loss 1.6954e+05                    bc_loss 2.5113e+03\n",
      "Epoch 1430, Training-Loss 2.6878e+05, Data-loss 9.1362e+04                  , pde-loss 7.0710e+03, initc-loss 1.6755e+05                    bc_loss 2.7974e+03\n",
      "Epoch 1440, Training-Loss 2.7026e+05, Data-loss 8.9757e+04                  , pde-loss 4.0847e+03, initc-loss 1.6759e+05                    bc_loss 8.8231e+03\n",
      "Epoch 1450, Training-Loss 2.6775e+05, Data-loss 8.9146e+04                  , pde-loss 7.8526e+03, initc-loss 1.6650e+05                    bc_loss 4.2471e+03\n",
      "Epoch 1460, Training-Loss 2.6718e+05, Data-loss 8.9663e+04                  , pde-loss 6.5968e+03, initc-loss 1.6749e+05                    bc_loss 3.4349e+03\n",
      "Epoch 1470, Training-Loss 2.6093e+05, Data-loss 8.7284e+04                  , pde-loss 3.6076e+03, initc-loss 1.6774e+05                    bc_loss 2.2970e+03\n",
      "Epoch 1480, Training-Loss 2.6486e+05, Data-loss 8.8760e+04                  , pde-loss 6.4669e+03, initc-loss 1.6738e+05                    bc_loss 2.2532e+03\n",
      "Epoch 1490, Training-Loss 2.6209e+05, Data-loss 8.9120e+04                  , pde-loss 4.6779e+03, initc-loss 1.6588e+05                    bc_loss 2.4189e+03\n",
      "Epoch 1500, Training-Loss 2.6951e+05, Data-loss 9.3925e+04                  , pde-loss 6.3632e+03, initc-loss 1.6688e+05                    bc_loss 2.3416e+03\n",
      "Epoch 1510, Training-Loss 2.6548e+05, Data-loss 9.0077e+04                  , pde-loss 7.6100e+03, initc-loss 1.6576e+05                    bc_loss 2.0397e+03\n",
      "Epoch 1520, Training-Loss 2.6457e+05, Data-loss 8.9663e+04                  , pde-loss 4.2439e+03, initc-loss 1.6853e+05                    bc_loss 2.1346e+03\n",
      "Epoch 1530, Training-Loss 2.6617e+05, Data-loss 8.9211e+04                  , pde-loss 6.6392e+03, initc-loss 1.6740e+05                    bc_loss 2.9227e+03\n",
      "Epoch 1540, Training-Loss 2.7592e+05, Data-loss 9.2113e+04                  , pde-loss 1.5165e+04, initc-loss 1.6553e+05                    bc_loss 3.1112e+03\n",
      "Epoch 1550, Training-Loss 2.6974e+05, Data-loss 9.1383e+04                  , pde-loss 7.9889e+03, initc-loss 1.6739e+05                    bc_loss 2.9800e+03\n",
      "Epoch 1560, Training-Loss 2.6283e+05, Data-loss 8.9855e+04                  , pde-loss 5.2386e+03, initc-loss 1.6472e+05                    bc_loss 3.0096e+03\n",
      "Epoch 1570, Training-Loss 2.7047e+05, Data-loss 9.1448e+04                  , pde-loss 9.4879e+03, initc-loss 1.6454e+05                    bc_loss 4.9890e+03\n",
      "Epoch 1580, Training-Loss 2.7070e+05, Data-loss 8.6105e+04                  , pde-loss 6.9031e+03, initc-loss 1.6420e+05                    bc_loss 1.3491e+04\n",
      "Epoch 1590, Training-Loss 2.6915e+05, Data-loss 8.8455e+04                  , pde-loss 8.2901e+03, initc-loss 1.6429e+05                    bc_loss 8.1103e+03\n",
      "Epoch 1600, Training-Loss 2.6506e+05, Data-loss 8.7868e+04                  , pde-loss 6.1636e+03, initc-loss 1.6783e+05                    bc_loss 3.1967e+03\n",
      "Epoch 1610, Training-Loss 2.6163e+05, Data-loss 8.9692e+04                  , pde-loss 4.3913e+03, initc-loss 1.6468e+05                    bc_loss 2.8676e+03\n",
      "Epoch 1620, Training-Loss 2.6687e+05, Data-loss 9.1848e+04                  , pde-loss 8.6769e+03, initc-loss 1.6372e+05                    bc_loss 2.6207e+03\n",
      "Epoch 1630, Training-Loss 2.5576e+05, Data-loss 8.6602e+04                  , pde-loss 3.5770e+03, initc-loss 1.6271e+05                    bc_loss 2.8712e+03\n",
      "Epoch 1640, Training-Loss 2.5856e+05, Data-loss 8.8180e+04                  , pde-loss 3.9587e+03, initc-loss 1.6357e+05                    bc_loss 2.8553e+03\n",
      "Epoch 1650, Training-Loss 2.6005e+05, Data-loss 9.1781e+04                  , pde-loss 4.2378e+03, initc-loss 1.6137e+05                    bc_loss 2.6599e+03\n",
      "Epoch 1660, Training-Loss 2.5537e+05, Data-loss 8.3414e+04                  , pde-loss 5.0528e+03, initc-loss 1.6365e+05                    bc_loss 3.2528e+03\n",
      "Epoch 1670, Training-Loss 2.6777e+05, Data-loss 9.0674e+04                  , pde-loss 1.1443e+04, initc-loss 1.6260e+05                    bc_loss 3.0546e+03\n",
      "Epoch 1680, Training-Loss 2.6066e+05, Data-loss 8.9857e+04                  , pde-loss 7.7284e+03, initc-loss 1.6039e+05                    bc_loss 2.6818e+03\n",
      "Epoch 1690, Training-Loss 2.5938e+05, Data-loss 8.9609e+04                  , pde-loss 6.3937e+03, initc-loss 1.6087e+05                    bc_loss 2.5037e+03\n",
      "Epoch 1700, Training-Loss 2.5833e+05, Data-loss 8.8251e+04                  , pde-loss 4.4583e+03, initc-loss 1.6236e+05                    bc_loss 3.2548e+03\n",
      "Epoch 1710, Training-Loss 2.5415e+05, Data-loss 8.7275e+04                  , pde-loss 5.1917e+03, initc-loss 1.5958e+05                    bc_loss 2.1069e+03\n",
      "Epoch 1720, Training-Loss 2.5273e+05, Data-loss 8.3941e+04                  , pde-loss 7.5461e+03, initc-loss 1.5826e+05                    bc_loss 2.9864e+03\n",
      "Epoch 1730, Training-Loss 2.5637e+05, Data-loss 8.7480e+04                  , pde-loss 4.7447e+03, initc-loss 1.6087e+05                    bc_loss 3.2760e+03\n",
      "Epoch 1740, Training-Loss 2.5281e+05, Data-loss 8.6564e+04                  , pde-loss 4.3875e+03, initc-loss 1.5858e+05                    bc_loss 3.2784e+03\n",
      "Epoch 1750, Training-Loss 2.5884e+05, Data-loss 8.7703e+04                  , pde-loss 6.1594e+03, initc-loss 1.5932e+05                    bc_loss 5.6597e+03\n",
      "Epoch 1760, Training-Loss 2.4958e+05, Data-loss 8.4431e+04                  , pde-loss 3.8570e+03, initc-loss 1.5907e+05                    bc_loss 2.2170e+03\n",
      "Epoch 1770, Training-Loss 2.5198e+05, Data-loss 8.8336e+04                  , pde-loss 3.7502e+03, initc-loss 1.5736e+05                    bc_loss 2.5321e+03\n",
      "Epoch 1780, Training-Loss 2.5389e+05, Data-loss 8.5892e+04                  , pde-loss 5.0390e+03, initc-loss 1.5944e+05                    bc_loss 3.5158e+03\n",
      "Epoch 1790, Training-Loss 2.5753e+05, Data-loss 8.8013e+04                  , pde-loss 8.0646e+03, initc-loss 1.5870e+05                    bc_loss 2.7520e+03\n",
      "Epoch 1800, Training-Loss 2.4640e+05, Data-loss 8.1415e+04                  , pde-loss 3.0011e+03, initc-loss 1.5730e+05                    bc_loss 4.6910e+03\n",
      "Epoch 1810, Training-Loss 2.4921e+05, Data-loss 8.3068e+04                  , pde-loss 4.4729e+03, initc-loss 1.5915e+05                    bc_loss 2.5207e+03\n",
      "Epoch 1820, Training-Loss 2.4962e+05, Data-loss 8.4272e+04                  , pde-loss 7.6406e+03, initc-loss 1.5558e+05                    bc_loss 2.1277e+03\n",
      "Epoch 1830, Training-Loss 2.4570e+05, Data-loss 8.3049e+04                  , pde-loss 5.0697e+03, initc-loss 1.5481e+05                    bc_loss 2.7697e+03\n",
      "Epoch 1840, Training-Loss 2.5198e+05, Data-loss 8.7820e+04                  , pde-loss 4.7263e+03, initc-loss 1.5679e+05                    bc_loss 2.6395e+03\n",
      "Epoch 1850, Training-Loss 2.5068e+05, Data-loss 8.5723e+04                  , pde-loss 7.1604e+03, initc-loss 1.5585e+05                    bc_loss 1.9476e+03\n",
      "Epoch 1860, Training-Loss 2.4991e+05, Data-loss 8.5001e+04                  , pde-loss 3.1539e+03, initc-loss 1.5698e+05                    bc_loss 4.7827e+03\n",
      "Epoch 1870, Training-Loss 2.4735e+05, Data-loss 8.4196e+04                  , pde-loss 3.3381e+03, initc-loss 1.5531e+05                    bc_loss 4.5089e+03\n",
      "Epoch 1880, Training-Loss 2.4670e+05, Data-loss 8.2205e+04                  , pde-loss 4.4275e+03, initc-loss 1.5731e+05                    bc_loss 2.7510e+03\n",
      "Epoch 1890, Training-Loss 2.4122e+05, Data-loss 8.1429e+04                  , pde-loss 3.5495e+03, initc-loss 1.5439e+05                    bc_loss 1.8449e+03\n",
      "Epoch 1900, Training-Loss 2.4188e+05, Data-loss 8.2258e+04                  , pde-loss 4.7995e+03, initc-loss 1.5232e+05                    bc_loss 2.5067e+03\n",
      "Epoch 1910, Training-Loss 2.4542e+05, Data-loss 8.2522e+04                  , pde-loss 5.6466e+03, initc-loss 1.5495e+05                    bc_loss 2.2935e+03\n",
      "Epoch 1920, Training-Loss 2.3921e+05, Data-loss 7.9702e+04                  , pde-loss 3.3716e+03, initc-loss 1.5339e+05                    bc_loss 2.7469e+03\n",
      "Epoch 1930, Training-Loss 2.4162e+05, Data-loss 8.2384e+04                  , pde-loss 3.2667e+03, initc-loss 1.5207e+05                    bc_loss 3.9008e+03\n",
      "Epoch 1940, Training-Loss 2.5249e+05, Data-loss 8.0182e+04                  , pde-loss 4.0886e+03, initc-loss 1.5281e+05                    bc_loss 1.5408e+04\n",
      "Epoch 1950, Training-Loss 2.4430e+05, Data-loss 8.3647e+04                  , pde-loss 3.2575e+03, initc-loss 1.5194e+05                    bc_loss 5.4544e+03\n",
      "Epoch 1960, Training-Loss 2.4391e+05, Data-loss 8.2766e+04                  , pde-loss 6.6703e+03, initc-loss 1.5101e+05                    bc_loss 3.4666e+03\n",
      "Epoch 1970, Training-Loss 2.3622e+05, Data-loss 7.7259e+04                  , pde-loss 3.5127e+03, initc-loss 1.5234e+05                    bc_loss 3.1051e+03\n",
      "Epoch 1980, Training-Loss 2.4125e+05, Data-loss 8.2135e+04                  , pde-loss 5.6996e+03, initc-loss 1.5070e+05                    bc_loss 2.7121e+03\n",
      "Epoch 1990, Training-Loss 2.3551e+05, Data-loss 7.7226e+04                  , pde-loss 2.3895e+03, initc-loss 1.5188e+05                    bc_loss 4.0188e+03\n",
      "Epoch 2000, Training-Loss 2.3687e+05, Data-loss 8.1323e+04                  , pde-loss 4.0447e+03, initc-loss 1.4836e+05                    bc_loss 3.1465e+03\n",
      "Epoch 2010, Training-Loss 2.3327e+05, Data-loss 7.7333e+04                  , pde-loss 4.5979e+03, initc-loss 1.4953e+05                    bc_loss 1.8123e+03\n",
      "Epoch 2020, Training-Loss 2.4169e+05, Data-loss 8.4230e+04                  , pde-loss 7.8912e+03, initc-loss 1.4792e+05                    bc_loss 1.6483e+03\n",
      "Epoch 2030, Training-Loss 2.4017e+05, Data-loss 7.8973e+04                  , pde-loss 6.8900e+03, initc-loss 1.5058e+05                    bc_loss 3.7299e+03\n",
      "Epoch 2040, Training-Loss 2.4413e+05, Data-loss 8.3179e+04                  , pde-loss 8.0164e+03, initc-loss 1.4818e+05                    bc_loss 4.7560e+03\n",
      "Epoch 2050, Training-Loss 2.3236e+05, Data-loss 7.7684e+04                  , pde-loss 3.8155e+03, initc-loss 1.4777e+05                    bc_loss 3.0917e+03\n",
      "Epoch 2060, Training-Loss 2.3551e+05, Data-loss 7.7659e+04                  , pde-loss 6.4017e+03, initc-loss 1.4809e+05                    bc_loss 3.3593e+03\n",
      "Epoch 2070, Training-Loss 2.2654e+05, Data-loss 7.3481e+04                  , pde-loss 2.2201e+03, initc-loss 1.4817e+05                    bc_loss 2.6669e+03\n",
      "Epoch 2080, Training-Loss 2.3034e+05, Data-loss 7.6291e+04                  , pde-loss 5.7692e+03, initc-loss 1.4553e+05                    bc_loss 2.7547e+03\n",
      "Epoch 2090, Training-Loss 2.3107e+05, Data-loss 7.8650e+04                  , pde-loss 4.1571e+03, initc-loss 1.4584e+05                    bc_loss 2.4295e+03\n",
      "Epoch 2100, Training-Loss 2.2783e+05, Data-loss 7.4200e+04                  , pde-loss 3.6489e+03, initc-loss 1.4759e+05                    bc_loss 2.3890e+03\n",
      "Epoch 2110, Training-Loss 2.2319e+05, Data-loss 7.5085e+04                  , pde-loss 2.0503e+03, initc-loss 1.4376e+05                    bc_loss 2.3007e+03\n",
      "Epoch 2120, Training-Loss 2.2862e+05, Data-loss 7.7177e+04                  , pde-loss 4.4385e+03, initc-loss 1.4445e+05                    bc_loss 2.5519e+03\n",
      "Epoch 2130, Training-Loss 2.2439e+05, Data-loss 7.2782e+04                  , pde-loss 4.6862e+03, initc-loss 1.4419e+05                    bc_loss 2.7259e+03\n",
      "Epoch 2140, Training-Loss 2.2306e+05, Data-loss 7.4711e+04                  , pde-loss 3.7142e+03, initc-loss 1.4222e+05                    bc_loss 2.4231e+03\n",
      "Epoch 2150, Training-Loss 2.2766e+05, Data-loss 7.7053e+04                  , pde-loss 5.6130e+03, initc-loss 1.4036e+05                    bc_loss 4.6372e+03\n",
      "Epoch 2160, Training-Loss 2.2823e+05, Data-loss 7.5499e+04                  , pde-loss 5.4301e+03, initc-loss 1.4101e+05                    bc_loss 6.2907e+03\n",
      "Epoch 2170, Training-Loss 2.2323e+05, Data-loss 7.3048e+04                  , pde-loss 3.5328e+03, initc-loss 1.4054e+05                    bc_loss 6.1053e+03\n",
      "Epoch 2180, Training-Loss 2.2013e+05, Data-loss 7.1611e+04                  , pde-loss 3.3388e+03, initc-loss 1.4128e+05                    bc_loss 3.8998e+03\n",
      "Epoch 2190, Training-Loss 2.2351e+05, Data-loss 7.5940e+04                  , pde-loss 4.1919e+03, initc-loss 1.4020e+05                    bc_loss 3.1764e+03\n",
      "Epoch 2200, Training-Loss 2.1596e+05, Data-loss 7.1016e+04                  , pde-loss 1.7724e+03, initc-loss 1.3990e+05                    bc_loss 3.2703e+03\n",
      "Epoch 2210, Training-Loss 2.1725e+05, Data-loss 6.9193e+04                  , pde-loss 3.9649e+03, initc-loss 1.4130e+05                    bc_loss 2.7881e+03\n",
      "Epoch 2220, Training-Loss 2.1581e+05, Data-loss 7.0408e+04                  , pde-loss 3.7468e+03, initc-loss 1.3760e+05                    bc_loss 4.0544e+03\n",
      "Epoch 2230, Training-Loss 2.1763e+05, Data-loss 7.3105e+04                  , pde-loss 2.3591e+03, initc-loss 1.3751e+05                    bc_loss 4.6608e+03\n",
      "Epoch 2240, Training-Loss 2.1820e+05, Data-loss 6.8343e+04                  , pde-loss 3.7276e+03, initc-loss 1.3937e+05                    bc_loss 6.7588e+03\n",
      "Epoch 2250, Training-Loss 2.2016e+05, Data-loss 7.2250e+04                  , pde-loss 5.0132e+03, initc-loss 1.3869e+05                    bc_loss 4.2043e+03\n",
      "Epoch 2260, Training-Loss 2.2485e+05, Data-loss 7.0559e+04                  , pde-loss 1.1500e+04, initc-loss 1.3709e+05                    bc_loss 5.6961e+03\n",
      "Epoch 2270, Training-Loss 2.1933e+05, Data-loss 6.9130e+04                  , pde-loss 9.0280e+03, initc-loss 1.3622e+05                    bc_loss 4.9568e+03\n",
      "Epoch 2280, Training-Loss 2.1088e+05, Data-loss 7.1485e+04                  , pde-loss 1.3093e+03, initc-loss 1.3600e+05                    bc_loss 2.0781e+03\n",
      "Epoch 2290, Training-Loss 2.1008e+05, Data-loss 6.9457e+04                  , pde-loss 3.3051e+03, initc-loss 1.3517e+05                    bc_loss 2.1507e+03\n",
      "Epoch 2300, Training-Loss 2.0885e+05, Data-loss 6.9340e+04                  , pde-loss 1.8285e+03, initc-loss 1.3502e+05                    bc_loss 2.6610e+03\n",
      "Epoch 2310, Training-Loss 2.0662e+05, Data-loss 6.6695e+04                  , pde-loss 3.0669e+03, initc-loss 1.3464e+05                    bc_loss 2.2212e+03\n",
      "Epoch 2320, Training-Loss 2.1563e+05, Data-loss 7.0352e+04                  , pde-loss 7.4624e+03, initc-loss 1.3556e+05                    bc_loss 2.2587e+03\n",
      "Epoch 2330, Training-Loss 2.0771e+05, Data-loss 6.8923e+04                  , pde-loss 2.8716e+03, initc-loss 1.3326e+05                    bc_loss 2.6601e+03\n",
      "Epoch 2340, Training-Loss 2.1002e+05, Data-loss 6.8882e+04                  , pde-loss 4.9842e+03, initc-loss 1.3249e+05                    bc_loss 3.6660e+03\n",
      "Epoch 2350, Training-Loss 2.0673e+05, Data-loss 6.9095e+04                  , pde-loss 1.4636e+03, initc-loss 1.3448e+05                    bc_loss 1.6928e+03\n",
      "Epoch 2360, Training-Loss 2.0221e+05, Data-loss 6.4394e+04                  , pde-loss 2.4778e+03, initc-loss 1.3249e+05                    bc_loss 2.8459e+03\n",
      "Epoch 2370, Training-Loss 2.0641e+05, Data-loss 6.8836e+04                  , pde-loss 4.9612e+03, initc-loss 1.3100e+05                    bc_loss 1.6188e+03\n",
      "Epoch 2380, Training-Loss 2.0466e+05, Data-loss 6.8424e+04                  , pde-loss 4.1371e+03, initc-loss 1.3050e+05                    bc_loss 1.5955e+03\n",
      "Epoch 2390, Training-Loss 2.0687e+05, Data-loss 6.6510e+04                  , pde-loss 8.9258e+03, initc-loss 1.2984e+05                    bc_loss 1.5956e+03\n",
      "Epoch 2400, Training-Loss 2.0091e+05, Data-loss 6.5565e+04                  , pde-loss 1.0646e+03, initc-loss 1.3055e+05                    bc_loss 3.7335e+03\n",
      "Epoch 2410, Training-Loss 1.9679e+05, Data-loss 6.5137e+04                  , pde-loss 1.2964e+03, initc-loss 1.2781e+05                    bc_loss 2.5471e+03\n",
      "Epoch 2420, Training-Loss 1.9738e+05, Data-loss 6.3970e+04                  , pde-loss 1.8045e+03, initc-loss 1.2921e+05                    bc_loss 2.3981e+03\n",
      "Epoch 2430, Training-Loss 2.0055e+05, Data-loss 6.4538e+04                  , pde-loss 6.2773e+03, initc-loss 1.2792e+05                    bc_loss 1.8160e+03\n",
      "Epoch 2440, Training-Loss 1.9375e+05, Data-loss 6.1620e+04                  , pde-loss 1.4457e+03, initc-loss 1.2900e+05                    bc_loss 1.6876e+03\n",
      "Epoch 2450, Training-Loss 1.9459e+05, Data-loss 6.3743e+04                  , pde-loss 2.0778e+03, initc-loss 1.2735e+05                    bc_loss 1.4177e+03\n",
      "Epoch 2460, Training-Loss 1.9393e+05, Data-loss 6.3182e+04                  , pde-loss 2.9756e+03, initc-loss 1.2595e+05                    bc_loss 1.8262e+03\n",
      "Epoch 2470, Training-Loss 1.9622e+05, Data-loss 6.4829e+04                  , pde-loss 1.7377e+03, initc-loss 1.2688e+05                    bc_loss 2.7693e+03\n",
      "Epoch 2480, Training-Loss 2.0077e+05, Data-loss 6.5062e+04                  , pde-loss 7.0210e+03, initc-loss 1.2667e+05                    bc_loss 2.0183e+03\n",
      "Epoch 2490, Training-Loss 1.9357e+05, Data-loss 6.3381e+04                  , pde-loss 2.6480e+03, initc-loss 1.2488e+05                    bc_loss 2.6601e+03\n",
      "Epoch 2500, Training-Loss 1.9727e+05, Data-loss 6.3675e+04                  , pde-loss 3.5620e+03, initc-loss 1.2458e+05                    bc_loss 5.4587e+03\n",
      "Epoch 2510, Training-Loss 1.9287e+05, Data-loss 6.3372e+04                  , pde-loss 2.6626e+03, initc-loss 1.2280e+05                    bc_loss 4.0389e+03\n",
      "Epoch 2520, Training-Loss 2.0196e+05, Data-loss 6.3107e+04                  , pde-loss 7.4810e+03, initc-loss 1.2542e+05                    bc_loss 5.9511e+03\n",
      "Epoch 2530, Training-Loss 1.9376e+05, Data-loss 6.0619e+04                  , pde-loss 4.0825e+03, initc-loss 1.2618e+05                    bc_loss 2.8882e+03\n",
      "Epoch 2540, Training-Loss 1.9209e+05, Data-loss 6.2278e+04                  , pde-loss 1.1608e+03, initc-loss 1.2396e+05                    bc_loss 4.6923e+03\n",
      "Epoch 2550, Training-Loss 1.8799e+05, Data-loss 6.0646e+04                  , pde-loss 1.7733e+03, initc-loss 1.2038e+05                    bc_loss 5.1970e+03\n",
      "Epoch 2560, Training-Loss 1.8457e+05, Data-loss 5.8371e+04                  , pde-loss 1.5479e+03, initc-loss 1.2235e+05                    bc_loss 2.3104e+03\n",
      "Epoch 2570, Training-Loss 1.9028e+05, Data-loss 5.8841e+04                  , pde-loss 3.0563e+03, initc-loss 1.2321e+05                    bc_loss 5.1723e+03\n",
      "Epoch 2580, Training-Loss 1.8433e+05, Data-loss 5.6521e+04                  , pde-loss 1.8389e+03, initc-loss 1.2137e+05                    bc_loss 4.6030e+03\n",
      "Epoch 2590, Training-Loss 1.8515e+05, Data-loss 5.6878e+04                  , pde-loss 4.2463e+03, initc-loss 1.2022e+05                    bc_loss 3.8025e+03\n",
      "Epoch 2600, Training-Loss 1.8801e+05, Data-loss 6.2049e+04                  , pde-loss 3.5019e+03, initc-loss 1.1911e+05                    bc_loss 3.3592e+03\n",
      "Epoch 2610, Training-Loss 1.8720e+05, Data-loss 5.9627e+04                  , pde-loss 3.1806e+03, initc-loss 1.2106e+05                    bc_loss 3.3400e+03\n",
      "Epoch 2620, Training-Loss 1.7797e+05, Data-loss 5.4973e+04                  , pde-loss 3.2689e+03, initc-loss 1.1788e+05                    bc_loss 1.8433e+03\n",
      "Epoch 2630, Training-Loss 1.8231e+05, Data-loss 6.0136e+04                  , pde-loss 1.7230e+03, initc-loss 1.1758e+05                    bc_loss 2.8730e+03\n",
      "Epoch 2640, Training-Loss 1.8429e+05, Data-loss 5.8108e+04                  , pde-loss 4.1781e+03, initc-loss 1.1919e+05                    bc_loss 2.8186e+03\n",
      "Epoch 2650, Training-Loss 1.7828e+05, Data-loss 5.3521e+04                  , pde-loss 2.6644e+03, initc-loss 1.1894e+05                    bc_loss 3.1475e+03\n",
      "Epoch 2660, Training-Loss 1.8329e+05, Data-loss 5.8305e+04                  , pde-loss 3.8875e+03, initc-loss 1.1769e+05                    bc_loss 3.4043e+03\n",
      "Epoch 2670, Training-Loss 1.7739e+05, Data-loss 5.4480e+04                  , pde-loss 4.6554e+03, initc-loss 1.1457e+05                    bc_loss 3.6847e+03\n",
      "Epoch 2680, Training-Loss 1.7814e+05, Data-loss 5.6390e+04                  , pde-loss 1.4697e+03, initc-loss 1.1665e+05                    bc_loss 3.6307e+03\n",
      "Epoch 2690, Training-Loss 1.7415e+05, Data-loss 5.4411e+04                  , pde-loss 1.9884e+03, initc-loss 1.1483e+05                    bc_loss 2.9155e+03\n",
      "Epoch 2700, Training-Loss 1.7475e+05, Data-loss 5.5732e+04                  , pde-loss 1.3657e+03, initc-loss 1.1382e+05                    bc_loss 3.8359e+03\n",
      "Epoch 2710, Training-Loss 1.8634e+05, Data-loss 5.8972e+04                  , pde-loss 6.6740e+03, initc-loss 1.1524e+05                    bc_loss 5.4543e+03\n",
      "Epoch 2720, Training-Loss 1.7478e+05, Data-loss 5.5482e+04                  , pde-loss 2.7237e+03, initc-loss 1.1330e+05                    bc_loss 3.2728e+03\n",
      "Epoch 2730, Training-Loss 1.9468e+05, Data-loss 5.9928e+04                  , pde-loss 5.8935e+03, initc-loss 1.1452e+05                    bc_loss 1.4341e+04\n",
      "Epoch 2740, Training-Loss 1.7535e+05, Data-loss 5.1598e+04                  , pde-loss 9.6899e+02, initc-loss 1.1373e+05                    bc_loss 9.0471e+03\n",
      "Epoch 2750, Training-Loss 1.7953e+05, Data-loss 5.6535e+04                  , pde-loss 2.7838e+03, initc-loss 1.1256e+05                    bc_loss 7.6433e+03\n",
      "Epoch 2760, Training-Loss 1.8055e+05, Data-loss 5.5938e+04                  , pde-loss 4.0974e+03, initc-loss 1.1375e+05                    bc_loss 6.7603e+03\n",
      "Epoch 2770, Training-Loss 1.7566e+05, Data-loss 5.5829e+04                  , pde-loss 2.4066e+03, initc-loss 1.1304e+05                    bc_loss 4.3780e+03\n",
      "Epoch 2780, Training-Loss 1.7319e+05, Data-loss 5.4625e+04                  , pde-loss 1.6301e+03, initc-loss 1.1266e+05                    bc_loss 4.2748e+03\n",
      "Epoch 2790, Training-Loss 1.6999e+05, Data-loss 5.2829e+04                  , pde-loss 2.1972e+03, initc-loss 1.1234e+05                    bc_loss 2.6243e+03\n",
      "Epoch 2800, Training-Loss 1.7373e+05, Data-loss 5.1963e+04                  , pde-loss 4.0181e+03, initc-loss 1.1246e+05                    bc_loss 5.2882e+03\n",
      "Epoch 2810, Training-Loss 1.7018e+05, Data-loss 5.3423e+04                  , pde-loss 2.2897e+03, initc-loss 1.1087e+05                    bc_loss 3.5963e+03\n",
      "Epoch 2820, Training-Loss 1.7280e+05, Data-loss 5.2456e+04                  , pde-loss 5.5050e+03, initc-loss 1.1106e+05                    bc_loss 3.7762e+03\n",
      "Epoch 2830, Training-Loss 1.6834e+05, Data-loss 5.0267e+04                  , pde-loss 7.2421e+02, initc-loss 1.1315e+05                    bc_loss 4.2041e+03\n",
      "Epoch 2840, Training-Loss 1.7374e+05, Data-loss 5.1929e+04                  , pde-loss 4.0386e+03, initc-loss 1.0910e+05                    bc_loss 8.6754e+03\n",
      "Epoch 2850, Training-Loss 1.7770e+05, Data-loss 5.5854e+04                  , pde-loss 4.6603e+03, initc-loss 1.0936e+05                    bc_loss 7.8202e+03\n",
      "Epoch 2860, Training-Loss 1.7336e+05, Data-loss 5.5349e+04                  , pde-loss 3.3391e+03, initc-loss 1.0952e+05                    bc_loss 5.1512e+03\n",
      "Epoch 2870, Training-Loss 1.7277e+05, Data-loss 5.4741e+04                  , pde-loss 2.6731e+03, initc-loss 1.1048e+05                    bc_loss 4.8745e+03\n",
      "Epoch 2880, Training-Loss 1.6574e+05, Data-loss 5.0821e+04                  , pde-loss 1.5188e+03, initc-loss 1.1049e+05                    bc_loss 2.9007e+03\n",
      "Epoch 2890, Training-Loss 1.6354e+05, Data-loss 5.0590e+04                  , pde-loss 1.4049e+03, initc-loss 1.0908e+05                    bc_loss 2.4588e+03\n",
      "Epoch 2900, Training-Loss 1.6415e+05, Data-loss 5.0675e+04                  , pde-loss 2.4581e+03, initc-loss 1.0871e+05                    bc_loss 2.3078e+03\n",
      "Epoch 2910, Training-Loss 1.6646e+05, Data-loss 5.0848e+04                  , pde-loss 3.1040e+03, initc-loss 1.0916e+05                    bc_loss 3.3529e+03\n",
      "Epoch 2920, Training-Loss 1.6749e+05, Data-loss 4.9985e+04                  , pde-loss 6.0581e+03, initc-loss 1.0869e+05                    bc_loss 2.7609e+03\n",
      "Epoch 2930, Training-Loss 1.6417e+05, Data-loss 5.1081e+04                  , pde-loss 2.8730e+03, initc-loss 1.0647e+05                    bc_loss 3.7498e+03\n",
      "Epoch 2940, Training-Loss 1.6009e+05, Data-loss 4.6759e+04                  , pde-loss 3.7104e+03, initc-loss 1.0458e+05                    bc_loss 5.0450e+03\n",
      "Epoch 2950, Training-Loss 1.6578e+05, Data-loss 4.9270e+04                  , pde-loss 2.1178e+03, initc-loss 1.0596e+05                    bc_loss 8.4298e+03\n",
      "Epoch 2960, Training-Loss 1.6530e+05, Data-loss 4.9877e+04                  , pde-loss 4.5559e+03, initc-loss 1.0692e+05                    bc_loss 3.9490e+03\n",
      "Epoch 2970, Training-Loss 1.5985e+05, Data-loss 4.8698e+04                  , pde-loss 2.5789e+03, initc-loss 1.0608e+05                    bc_loss 2.5018e+03\n",
      "Epoch 2980, Training-Loss 1.5681e+05, Data-loss 4.5046e+04                  , pde-loss 2.2093e+03, initc-loss 1.0616e+05                    bc_loss 3.3968e+03\n",
      "Epoch 2990, Training-Loss 1.6264e+05, Data-loss 4.7984e+04                  , pde-loss 3.2021e+03, initc-loss 1.0551e+05                    bc_loss 5.9356e+03\n",
      "Epoch 3000, Training-Loss 1.5981e+05, Data-loss 5.0489e+04                  , pde-loss 2.4429e+03, initc-loss 1.0385e+05                    bc_loss 3.0274e+03\n",
      "Epoch 3010, Training-Loss 1.6145e+05, Data-loss 4.8207e+04                  , pde-loss 3.5850e+03, initc-loss 1.0259e+05                    bc_loss 7.0659e+03\n",
      "Epoch 3020, Training-Loss 1.6102e+05, Data-loss 4.8781e+04                  , pde-loss 3.5156e+03, initc-loss 1.0293e+05                    bc_loss 5.7961e+03\n",
      "Epoch 3030, Training-Loss 1.5891e+05, Data-loss 4.7574e+04                  , pde-loss 1.0588e+03, initc-loss 1.0371e+05                    bc_loss 6.5697e+03\n",
      "Epoch 3040, Training-Loss 1.5968e+05, Data-loss 4.9372e+04                  , pde-loss 3.1481e+03, initc-loss 1.0046e+05                    bc_loss 6.6985e+03\n",
      "Epoch 3050, Training-Loss 1.5956e+05, Data-loss 4.6998e+04                  , pde-loss 3.0289e+03, initc-loss 1.0211e+05                    bc_loss 7.4231e+03\n",
      "Epoch 3060, Training-Loss 1.5825e+05, Data-loss 4.4727e+04                  , pde-loss 3.2381e+03, initc-loss 1.0218e+05                    bc_loss 8.1038e+03\n",
      "Epoch 3070, Training-Loss 1.6443e+05, Data-loss 4.5994e+04                  , pde-loss 1.4233e+03, initc-loss 1.0179e+05                    bc_loss 1.5216e+04\n",
      "Epoch 3080, Training-Loss 1.5515e+05, Data-loss 4.4938e+04                  , pde-loss 1.8002e+03, initc-loss 1.0078e+05                    bc_loss 7.6245e+03\n",
      "Epoch 3090, Training-Loss 1.5691e+05, Data-loss 4.7306e+04                  , pde-loss 2.8136e+03, initc-loss 1.0166e+05                    bc_loss 5.1309e+03\n",
      "Epoch 3100, Training-Loss 1.5686e+05, Data-loss 4.5302e+04                  , pde-loss 2.2755e+03, initc-loss 1.0060e+05                    bc_loss 8.6804e+03\n",
      "Epoch 3110, Training-Loss 1.5428e+05, Data-loss 4.4493e+04                  , pde-loss 2.4921e+03, initc-loss 1.0127e+05                    bc_loss 6.0276e+03\n",
      "Epoch 3120, Training-Loss 1.4916e+05, Data-loss 4.5757e+04                  , pde-loss 1.2589e+03, initc-loss 9.9095e+04                    bc_loss 3.0480e+03\n",
      "Epoch 3130, Training-Loss 1.5175e+05, Data-loss 4.5754e+04                  , pde-loss 1.6253e+03, initc-loss 9.9077e+04                    bc_loss 5.2980e+03\n",
      "Epoch 3140, Training-Loss 1.4668e+05, Data-loss 4.1994e+04                  , pde-loss 2.1739e+03, initc-loss 9.8035e+04                    bc_loss 4.4749e+03\n",
      "Epoch 3150, Training-Loss 1.5796e+05, Data-loss 4.5055e+04                  , pde-loss 2.1806e+03, initc-loss 9.9826e+04                    bc_loss 1.0903e+04\n",
      "Epoch 3160, Training-Loss 1.5066e+05, Data-loss 4.3893e+04                  , pde-loss 1.0735e+03, initc-loss 9.7628e+04                    bc_loss 8.0688e+03\n",
      "Epoch 3170, Training-Loss 1.4633e+05, Data-loss 4.1468e+04                  , pde-loss 1.6505e+03, initc-loss 9.7636e+04                    bc_loss 5.5723e+03\n",
      "Epoch 3180, Training-Loss 1.4674e+05, Data-loss 4.1159e+04                  , pde-loss 1.1663e+03, initc-loss 9.9511e+04                    bc_loss 4.9062e+03\n",
      "Epoch 3190, Training-Loss 1.5325e+05, Data-loss 4.3201e+04                  , pde-loss 2.0222e+03, initc-loss 9.8021e+04                    bc_loss 1.0003e+04\n",
      "Epoch 3200, Training-Loss 1.4849e+05, Data-loss 4.0687e+04                  , pde-loss 2.7192e+03, initc-loss 9.8382e+04                    bc_loss 6.7048e+03\n",
      "Epoch 3210, Training-Loss 1.5075e+05, Data-loss 4.4394e+04                  , pde-loss 1.1717e+03, initc-loss 9.6807e+04                    bc_loss 8.3826e+03\n",
      "Epoch 3220, Training-Loss 1.4921e+05, Data-loss 4.3742e+04                  , pde-loss 2.1852e+03, initc-loss 9.8043e+04                    bc_loss 5.2364e+03\n",
      "Epoch 3230, Training-Loss 1.5093e+05, Data-loss 4.4071e+04                  , pde-loss 4.6497e+03, initc-loss 9.6734e+04                    bc_loss 5.4779e+03\n",
      "Epoch 3240, Training-Loss 1.4642e+05, Data-loss 4.2668e+04                  , pde-loss 2.6604e+03, initc-loss 9.7689e+04                    bc_loss 3.3981e+03\n",
      "Epoch 3250, Training-Loss 1.4984e+05, Data-loss 4.3195e+04                  , pde-loss 2.2093e+03, initc-loss 9.6645e+04                    bc_loss 7.7871e+03\n",
      "Epoch 3260, Training-Loss 1.4661e+05, Data-loss 4.5434e+04                  , pde-loss 1.7982e+03, initc-loss 9.5664e+04                    bc_loss 3.7182e+03\n",
      "Epoch 3270, Training-Loss 1.4742e+05, Data-loss 4.1955e+04                  , pde-loss 3.1226e+03, initc-loss 9.6338e+04                    bc_loss 6.0098e+03\n",
      "Epoch 3280, Training-Loss 1.5485e+05, Data-loss 4.4651e+04                  , pde-loss 2.7441e+03, initc-loss 9.8175e+04                    bc_loss 9.2780e+03\n",
      "Epoch 3290, Training-Loss 1.5003e+05, Data-loss 3.9808e+04                  , pde-loss 3.5475e+03, initc-loss 9.6293e+04                    bc_loss 1.0385e+04\n",
      "Epoch 3300, Training-Loss 1.5174e+05, Data-loss 4.2987e+04                  , pde-loss 2.3981e+03, initc-loss 9.6885e+04                    bc_loss 9.4672e+03\n",
      "Epoch 3310, Training-Loss 1.4545e+05, Data-loss 3.9967e+04                  , pde-loss 1.1036e+03, initc-loss 9.5455e+04                    bc_loss 8.9274e+03\n",
      "Epoch 3320, Training-Loss 1.5052e+05, Data-loss 4.0218e+04                  , pde-loss 1.0286e+03, initc-loss 9.5461e+04                    bc_loss 1.3809e+04\n",
      "Epoch 3330, Training-Loss 1.5804e+05, Data-loss 4.2625e+04                  , pde-loss 3.0705e+03, initc-loss 9.8829e+04                    bc_loss 1.3511e+04\n",
      "Epoch 3340, Training-Loss 1.5380e+05, Data-loss 4.3176e+04                  , pde-loss 2.6642e+03, initc-loss 9.5604e+04                    bc_loss 1.2356e+04\n",
      "Epoch 3350, Training-Loss 1.5978e+05, Data-loss 4.4792e+04                  , pde-loss 3.3578e+03, initc-loss 9.4431e+04                    bc_loss 1.7194e+04\n",
      "Epoch 3360, Training-Loss 1.4840e+05, Data-loss 4.3367e+04                  , pde-loss 1.2514e+03, initc-loss 9.4775e+04                    bc_loss 9.0071e+03\n",
      "Epoch 3370, Training-Loss 1.4302e+05, Data-loss 4.1144e+04                  , pde-loss 8.6272e+02, initc-loss 9.4180e+04                    bc_loss 6.8315e+03\n",
      "Epoch 3380, Training-Loss 1.4102e+05, Data-loss 4.0210e+04                  , pde-loss 1.0546e+03, initc-loss 9.4762e+04                    bc_loss 4.9907e+03\n",
      "Epoch 3390, Training-Loss 1.4061e+05, Data-loss 3.9180e+04                  , pde-loss 2.1757e+03, initc-loss 9.5005e+04                    bc_loss 4.2528e+03\n",
      "Epoch 3400, Training-Loss 1.4596e+05, Data-loss 4.1782e+04                  , pde-loss 1.9619e+03, initc-loss 9.4367e+04                    bc_loss 7.8502e+03\n",
      "Epoch 3410, Training-Loss 1.4540e+05, Data-loss 3.9415e+04                  , pde-loss 1.4275e+03, initc-loss 9.4027e+04                    bc_loss 1.0534e+04\n",
      "Epoch 3420, Training-Loss 1.4993e+05, Data-loss 4.1016e+04                  , pde-loss 4.4725e+03, initc-loss 9.6962e+04                    bc_loss 7.4762e+03\n",
      "Epoch 3430, Training-Loss 1.4962e+05, Data-loss 4.0454e+04                  , pde-loss 2.6184e+03, initc-loss 9.4401e+04                    bc_loss 1.2144e+04\n",
      "Epoch 3440, Training-Loss 1.6760e+05, Data-loss 4.0896e+04                  , pde-loss 3.5024e+03, initc-loss 9.2846e+04                    bc_loss 3.0360e+04\n",
      "Epoch 3450, Training-Loss 1.5952e+05, Data-loss 3.9732e+04                  , pde-loss 9.6612e+02, initc-loss 9.4972e+04                    bc_loss 2.3848e+04\n",
      "Epoch 3460, Training-Loss 1.5123e+05, Data-loss 4.4044e+04                  , pde-loss 2.5301e+03, initc-loss 9.7075e+04                    bc_loss 7.5800e+03\n",
      "Epoch 3470, Training-Loss 1.6465e+05, Data-loss 4.1221e+04                  , pde-loss 3.6908e+03, initc-loss 9.6953e+04                    bc_loss 2.2783e+04\n",
      "Epoch 3480, Training-Loss 1.5661e+05, Data-loss 4.4508e+04                  , pde-loss 2.8353e+03, initc-loss 9.8758e+04                    bc_loss 1.0513e+04\n",
      "Epoch 3490, Training-Loss 1.4563e+05, Data-loss 4.1222e+04                  , pde-loss 1.4980e+03, initc-loss 9.6408e+04                    bc_loss 6.5032e+03\n",
      "Epoch 3500, Training-Loss 1.5005e+05, Data-loss 4.4917e+04                  , pde-loss 3.4618e+03, initc-loss 9.6263e+04                    bc_loss 5.4104e+03\n",
      "Epoch 3510, Training-Loss 1.4642e+05, Data-loss 4.2233e+04                  , pde-loss 3.1048e+03, initc-loss 9.5399e+04                    bc_loss 5.6850e+03\n",
      "Epoch 3520, Training-Loss 1.4700e+05, Data-loss 4.2834e+04                  , pde-loss 3.0219e+03, initc-loss 9.4680e+04                    bc_loss 6.4607e+03\n",
      "Epoch 3530, Training-Loss 1.4635e+05, Data-loss 3.8464e+04                  , pde-loss 1.5755e+03, initc-loss 9.4305e+04                    bc_loss 1.2010e+04\n",
      "Epoch 3540, Training-Loss 1.5409e+05, Data-loss 4.0504e+04                  , pde-loss 2.5659e+03, initc-loss 9.3368e+04                    bc_loss 1.7654e+04\n",
      "Epoch 3550, Training-Loss 1.6162e+05, Data-loss 4.0053e+04                  , pde-loss 2.3797e+03, initc-loss 9.5887e+04                    bc_loss 2.3300e+04\n",
      "Epoch 3560, Training-Loss 1.7699e+05, Data-loss 4.4394e+04                  , pde-loss 3.2746e+03, initc-loss 9.7768e+04                    bc_loss 3.1555e+04\n",
      "Epoch 3570, Training-Loss 1.5514e+05, Data-loss 4.5053e+04                  , pde-loss 2.5919e+03, initc-loss 9.7502e+04                    bc_loss 9.9978e+03\n",
      "Epoch 3580, Training-Loss 1.5156e+05, Data-loss 4.2667e+04                  , pde-loss 2.9208e+03, initc-loss 9.5938e+04                    bc_loss 1.0035e+04\n",
      "Epoch 3590, Training-Loss 1.4558e+05, Data-loss 4.0708e+04                  , pde-loss 2.7644e+03, initc-loss 9.4241e+04                    bc_loss 7.8675e+03\n",
      "Epoch 3600, Training-Loss 1.4281e+05, Data-loss 4.1212e+04                  , pde-loss 1.0349e+03, initc-loss 9.5438e+04                    bc_loss 5.1294e+03\n",
      "Epoch 3610, Training-Loss 1.4199e+05, Data-loss 3.9058e+04                  , pde-loss 1.8926e+03, initc-loss 9.5235e+04                    bc_loss 5.8082e+03\n",
      "Epoch 3620, Training-Loss 1.4107e+05, Data-loss 3.9361e+04                  , pde-loss 1.9316e+03, initc-loss 9.5229e+04                    bc_loss 4.5450e+03\n",
      "Epoch 3630, Training-Loss 1.4360e+05, Data-loss 4.1953e+04                  , pde-loss 2.3880e+03, initc-loss 9.4047e+04                    bc_loss 5.2115e+03\n",
      "Epoch 3640, Training-Loss 1.3665e+05, Data-loss 3.9754e+04                  , pde-loss 1.2343e+03, initc-loss 9.1932e+04                    bc_loss 3.7339e+03\n",
      "Epoch 3650, Training-Loss 1.4380e+05, Data-loss 3.8898e+04                  , pde-loss 1.3179e+03, initc-loss 9.4150e+04                    bc_loss 9.4331e+03\n",
      "Epoch 3660, Training-Loss 1.5527e+05, Data-loss 3.9546e+04                  , pde-loss 1.7447e+03, initc-loss 9.2737e+04                    bc_loss 2.1245e+04\n",
      "Epoch 3670, Training-Loss 1.5060e+05, Data-loss 3.8853e+04                  , pde-loss 1.1435e+03, initc-loss 9.2485e+04                    bc_loss 1.8121e+04\n",
      "Epoch 3680, Training-Loss 1.4857e+05, Data-loss 4.2077e+04                  , pde-loss 2.6264e+03, initc-loss 9.2597e+04                    bc_loss 1.1267e+04\n",
      "Epoch 3690, Training-Loss 1.4638e+05, Data-loss 3.7842e+04                  , pde-loss 2.5501e+03, initc-loss 9.3647e+04                    bc_loss 1.2343e+04\n",
      "Epoch 3700, Training-Loss 1.4108e+05, Data-loss 3.9513e+04                  , pde-loss 2.7124e+03, initc-loss 9.2075e+04                    bc_loss 6.7832e+03\n",
      "Epoch 3710, Training-Loss 1.4182e+05, Data-loss 4.1623e+04                  , pde-loss 1.9773e+03, initc-loss 9.1435e+04                    bc_loss 6.7827e+03\n",
      "Epoch 3720, Training-Loss 1.3709e+05, Data-loss 4.0134e+04                  , pde-loss 1.8591e+03, initc-loss 9.1573e+04                    bc_loss 3.5264e+03\n",
      "Epoch 3730, Training-Loss 1.4085e+05, Data-loss 4.0618e+04                  , pde-loss 1.8666e+03, initc-loss 9.0637e+04                    bc_loss 7.7324e+03\n",
      "Epoch 3740, Training-Loss 1.5716e+05, Data-loss 4.0121e+04                  , pde-loss 3.2240e+03, initc-loss 9.2256e+04                    bc_loss 2.1555e+04\n",
      "Epoch 3750, Training-Loss 1.7008e+05, Data-loss 4.2878e+04                  , pde-loss 1.6442e+03, initc-loss 9.3779e+04                    bc_loss 3.1774e+04\n",
      "Epoch 3760, Training-Loss 1.5126e+05, Data-loss 4.2087e+04                  , pde-loss 2.5532e+03, initc-loss 9.7734e+04                    bc_loss 8.8813e+03\n",
      "Epoch 3770, Training-Loss 1.4230e+05, Data-loss 3.9738e+04                  , pde-loss 2.4741e+03, initc-loss 9.4568e+04                    bc_loss 5.5230e+03\n",
      "Epoch 3780, Training-Loss 1.3839e+05, Data-loss 3.8178e+04                  , pde-loss 2.0703e+03, initc-loss 9.3148e+04                    bc_loss 4.9897e+03\n",
      "Epoch 3790, Training-Loss 1.4501e+05, Data-loss 4.3364e+04                  , pde-loss 2.9825e+03, initc-loss 9.3982e+04                    bc_loss 4.6870e+03\n",
      "Epoch 3800, Training-Loss 1.3767e+05, Data-loss 3.9236e+04                  , pde-loss 2.3659e+03, initc-loss 9.0731e+04                    bc_loss 5.3383e+03\n",
      "Epoch 3810, Training-Loss 1.4456e+05, Data-loss 4.0758e+04                  , pde-loss 8.8990e+02, initc-loss 9.2306e+04                    bc_loss 1.0604e+04\n",
      "Epoch 3820, Training-Loss 1.4812e+05, Data-loss 4.1084e+04                  , pde-loss 3.1590e+03, initc-loss 9.2002e+04                    bc_loss 1.1879e+04\n",
      "Epoch 3830, Training-Loss 1.4105e+05, Data-loss 4.1683e+04                  , pde-loss 1.7727e+03, initc-loss 9.2348e+04                    bc_loss 5.2445e+03\n",
      "Epoch 3840, Training-Loss 1.4624e+05, Data-loss 4.1012e+04                  , pde-loss 1.6741e+03, initc-loss 9.3900e+04                    bc_loss 9.6499e+03\n",
      "Epoch 3850, Training-Loss 1.4028e+05, Data-loss 3.9929e+04                  , pde-loss 1.2293e+03, initc-loss 9.1358e+04                    bc_loss 7.7684e+03\n",
      "Epoch 3860, Training-Loss 1.4646e+05, Data-loss 4.0363e+04                  , pde-loss 2.0158e+03, initc-loss 9.1306e+04                    bc_loss 1.2779e+04\n",
      "Epoch 3870, Training-Loss 1.5498e+05, Data-loss 3.9739e+04                  , pde-loss 2.4457e+03, initc-loss 9.3672e+04                    bc_loss 1.9125e+04\n",
      "Epoch 3880, Training-Loss 1.4373e+05, Data-loss 4.0272e+04                  , pde-loss 1.3901e+03, initc-loss 9.4667e+04                    bc_loss 7.4029e+03\n",
      "Epoch 3890, Training-Loss 1.4581e+05, Data-loss 4.1271e+04                  , pde-loss 2.8683e+03, initc-loss 9.3263e+04                    bc_loss 8.4044e+03\n",
      "Epoch 3900, Training-Loss 1.3827e+05, Data-loss 3.9952e+04                  , pde-loss 1.7057e+03, initc-loss 9.0422e+04                    bc_loss 6.1881e+03\n",
      "Epoch 3910, Training-Loss 1.3370e+05, Data-loss 3.6008e+04                  , pde-loss 1.0209e+03, initc-loss 9.0672e+04                    bc_loss 5.9989e+03\n",
      "Epoch 3920, Training-Loss 1.4683e+05, Data-loss 3.9290e+04                  , pde-loss 2.2555e+03, initc-loss 9.1178e+04                    bc_loss 1.4101e+04\n",
      "Epoch 3930, Training-Loss 1.5145e+05, Data-loss 3.9604e+04                  , pde-loss 1.1068e+03, initc-loss 9.0288e+04                    bc_loss 2.0451e+04\n",
      "Epoch 3940, Training-Loss 1.4065e+05, Data-loss 3.9657e+04                  , pde-loss 2.2061e+03, initc-loss 9.1650e+04                    bc_loss 7.1337e+03\n",
      "Epoch 3950, Training-Loss 1.5309e+05, Data-loss 4.1493e+04                  , pde-loss 2.0814e+03, initc-loss 9.2369e+04                    bc_loss 1.7143e+04\n",
      "Epoch 3960, Training-Loss 1.4462e+05, Data-loss 4.1283e+04                  , pde-loss 3.0795e+03, initc-loss 9.0675e+04                    bc_loss 9.5813e+03\n",
      "Epoch 3970, Training-Loss 1.3575e+05, Data-loss 3.5876e+04                  , pde-loss 1.4942e+03, initc-loss 9.2086e+04                    bc_loss 6.2915e+03\n",
      "Epoch 3980, Training-Loss 1.3888e+05, Data-loss 3.9916e+04                  , pde-loss 2.0618e+03, initc-loss 8.8433e+04                    bc_loss 8.4736e+03\n",
      "Epoch 3990, Training-Loss 1.4039e+05, Data-loss 3.9316e+04                  , pde-loss 1.9315e+03, initc-loss 9.1290e+04                    bc_loss 7.8508e+03\n",
      "Epoch 4000, Training-Loss 1.3434e+05, Data-loss 3.7833e+04                  , pde-loss 2.1198e+03, initc-loss 9.0693e+04                    bc_loss 3.6985e+03\n",
      "Epoch 4010, Training-Loss 1.3171e+05, Data-loss 3.8405e+04                  , pde-loss 1.3238e+03, initc-loss 8.9111e+04                    bc_loss 2.8717e+03\n",
      "Epoch 4020, Training-Loss 1.3533e+05, Data-loss 3.7172e+04                  , pde-loss 1.6893e+03, initc-loss 8.9243e+04                    bc_loss 7.2266e+03\n",
      "Epoch 4030, Training-Loss 1.3782e+05, Data-loss 3.8781e+04                  , pde-loss 1.4004e+03, initc-loss 8.8824e+04                    bc_loss 8.8141e+03\n",
      "Epoch 4040, Training-Loss 1.3408e+05, Data-loss 3.5935e+04                  , pde-loss 1.2634e+03, initc-loss 8.9494e+04                    bc_loss 7.3874e+03\n",
      "Epoch 4050, Training-Loss 1.3577e+05, Data-loss 3.7591e+04                  , pde-loss 1.8929e+03, initc-loss 8.8979e+04                    bc_loss 7.3083e+03\n",
      "Epoch 4060, Training-Loss 1.3257e+05, Data-loss 3.6877e+04                  , pde-loss 1.7356e+03, initc-loss 8.8463e+04                    bc_loss 5.5000e+03\n",
      "Epoch 4070, Training-Loss 1.3514e+05, Data-loss 3.5581e+04                  , pde-loss 3.3360e+03, initc-loss 9.0716e+04                    bc_loss 5.5091e+03\n",
      "Epoch 4080, Training-Loss 1.4101e+05, Data-loss 3.9201e+04                  , pde-loss 4.7877e+03, initc-loss 8.8872e+04                    bc_loss 8.1451e+03\n",
      "Epoch 4090, Training-Loss 1.3959e+05, Data-loss 3.9676e+04                  , pde-loss 1.3561e+03, initc-loss 8.9779e+04                    bc_loss 8.7769e+03\n",
      "Epoch 4100, Training-Loss 1.3587e+05, Data-loss 3.6693e+04                  , pde-loss 1.6596e+03, initc-loss 8.9089e+04                    bc_loss 8.4281e+03\n",
      "Epoch 4110, Training-Loss 1.4070e+05, Data-loss 3.9218e+04                  , pde-loss 2.9274e+03, initc-loss 9.0415e+04                    bc_loss 8.1430e+03\n",
      "Epoch 4120, Training-Loss 1.3197e+05, Data-loss 3.6566e+04                  , pde-loss 1.9084e+03, initc-loss 8.8481e+04                    bc_loss 5.0112e+03\n",
      "Epoch 4130, Training-Loss 1.3030e+05, Data-loss 3.5550e+04                  , pde-loss 2.4504e+03, initc-loss 8.8074e+04                    bc_loss 4.2303e+03\n",
      "Epoch 4140, Training-Loss 1.3040e+05, Data-loss 3.6262e+04                  , pde-loss 1.2290e+03, initc-loss 8.9456e+04                    bc_loss 3.4500e+03\n",
      "Epoch 4150, Training-Loss 1.3425e+05, Data-loss 3.8723e+04                  , pde-loss 1.4919e+03, initc-loss 8.8494e+04                    bc_loss 5.5433e+03\n",
      "Epoch 4160, Training-Loss 1.3576e+05, Data-loss 3.7815e+04                  , pde-loss 2.3553e+03, initc-loss 8.9466e+04                    bc_loss 6.1235e+03\n",
      "Epoch 4170, Training-Loss 1.3058e+05, Data-loss 3.5326e+04                  , pde-loss 1.4293e+03, initc-loss 8.9246e+04                    bc_loss 4.5745e+03\n",
      "Epoch 4180, Training-Loss 1.3233e+05, Data-loss 3.7358e+04                  , pde-loss 2.1588e+03, initc-loss 8.8228e+04                    bc_loss 4.5858e+03\n",
      "Epoch 4190, Training-Loss 1.3219e+05, Data-loss 3.7719e+04                  , pde-loss 1.4997e+03, initc-loss 8.7343e+04                    bc_loss 5.6283e+03\n",
      "Epoch 4200, Training-Loss 1.3249e+05, Data-loss 3.7438e+04                  , pde-loss 1.2030e+03, initc-loss 8.7845e+04                    bc_loss 5.9999e+03\n",
      "Epoch 4210, Training-Loss 1.3748e+05, Data-loss 4.0063e+04                  , pde-loss 2.6879e+03, initc-loss 8.7850e+04                    bc_loss 6.8841e+03\n",
      "Epoch 4220, Training-Loss 1.3382e+05, Data-loss 4.0147e+04                  , pde-loss 1.9325e+03, initc-loss 8.6912e+04                    bc_loss 4.8278e+03\n",
      "Epoch 4230, Training-Loss 1.3605e+05, Data-loss 3.8185e+04                  , pde-loss 2.4064e+03, initc-loss 8.8407e+04                    bc_loss 7.0489e+03\n",
      "Epoch 4240, Training-Loss 1.2738e+05, Data-loss 3.3763e+04                  , pde-loss 9.5730e+02, initc-loss 8.6402e+04                    bc_loss 6.2581e+03\n",
      "Epoch 4250, Training-Loss 1.3035e+05, Data-loss 3.7825e+04                  , pde-loss 1.5223e+03, initc-loss 8.6031e+04                    bc_loss 4.9667e+03\n",
      "Epoch 4260, Training-Loss 1.2982e+05, Data-loss 3.6119e+04                  , pde-loss 1.6611e+03, initc-loss 8.6339e+04                    bc_loss 5.7025e+03\n",
      "Epoch 4270, Training-Loss 1.3718e+05, Data-loss 3.6842e+04                  , pde-loss 2.5337e+03, initc-loss 8.7792e+04                    bc_loss 1.0017e+04\n",
      "Epoch 4280, Training-Loss 1.3093e+05, Data-loss 3.7423e+04                  , pde-loss 1.6277e+03, initc-loss 8.8974e+04                    bc_loss 2.9109e+03\n",
      "Epoch 4290, Training-Loss 1.3368e+05, Data-loss 3.8214e+04                  , pde-loss 1.3437e+03, initc-loss 8.6380e+04                    bc_loss 7.7470e+03\n",
      "Epoch 4300, Training-Loss 1.2938e+05, Data-loss 3.4952e+04                  , pde-loss 1.4416e+03, initc-loss 8.6490e+04                    bc_loss 6.4971e+03\n",
      "Epoch 4310, Training-Loss 1.2347e+05, Data-loss 3.3161e+04                  , pde-loss 9.1696e+02, initc-loss 8.5971e+04                    bc_loss 3.4235e+03\n",
      "Epoch 4320, Training-Loss 1.2722e+05, Data-loss 3.5166e+04                  , pde-loss 1.9375e+03, initc-loss 8.5898e+04                    bc_loss 4.2230e+03\n",
      "Epoch 4330, Training-Loss 1.3080e+05, Data-loss 3.6357e+04                  , pde-loss 1.6224e+03, initc-loss 8.7116e+04                    bc_loss 5.7086e+03\n",
      "Epoch 4340, Training-Loss 1.2739e+05, Data-loss 3.5051e+04                  , pde-loss 1.2052e+03, initc-loss 8.6583e+04                    bc_loss 4.5488e+03\n",
      "Epoch 4350, Training-Loss 1.2764e+05, Data-loss 3.7274e+04                  , pde-loss 1.4676e+03, initc-loss 8.4844e+04                    bc_loss 4.0565e+03\n",
      "Epoch 4360, Training-Loss 1.2719e+05, Data-loss 3.4481e+04                  , pde-loss 6.4416e+02, initc-loss 8.5787e+04                    bc_loss 6.2781e+03\n",
      "Epoch 4370, Training-Loss 1.2846e+05, Data-loss 3.6823e+04                  , pde-loss 1.3296e+03, initc-loss 8.5231e+04                    bc_loss 5.0737e+03\n",
      "Epoch 4380, Training-Loss 1.3043e+05, Data-loss 3.5936e+04                  , pde-loss 1.8490e+03, initc-loss 8.5015e+04                    bc_loss 7.6297e+03\n",
      "Epoch 4390, Training-Loss 1.2715e+05, Data-loss 3.4337e+04                  , pde-loss 7.0854e+02, initc-loss 8.5635e+04                    bc_loss 6.4671e+03\n",
      "Epoch 4400, Training-Loss 1.2914e+05, Data-loss 3.4350e+04                  , pde-loss 1.8713e+03, initc-loss 8.6299e+04                    bc_loss 6.6152e+03\n",
      "Epoch 4410, Training-Loss 1.2864e+05, Data-loss 3.5030e+04                  , pde-loss 2.3668e+03, initc-loss 8.6011e+04                    bc_loss 5.2308e+03\n",
      "Epoch 4420, Training-Loss 1.3117e+05, Data-loss 3.7096e+04                  , pde-loss 2.5509e+03, initc-loss 8.6325e+04                    bc_loss 5.1996e+03\n",
      "Epoch 4430, Training-Loss 1.2620e+05, Data-loss 3.5491e+04                  , pde-loss 1.0536e+03, initc-loss 8.5046e+04                    bc_loss 4.6119e+03\n",
      "Epoch 4440, Training-Loss 1.2711e+05, Data-loss 3.6893e+04                  , pde-loss 1.9348e+03, initc-loss 8.4629e+04                    bc_loss 3.6482e+03\n",
      "Epoch 4450, Training-Loss 1.2342e+05, Data-loss 3.4529e+04                  , pde-loss 1.5629e+03, initc-loss 8.4714e+04                    bc_loss 2.6139e+03\n",
      "Epoch 4460, Training-Loss 1.2503e+05, Data-loss 3.3848e+04                  , pde-loss 6.9606e+02, initc-loss 8.5078e+04                    bc_loss 5.4125e+03\n",
      "Epoch 4470, Training-Loss 1.2615e+05, Data-loss 3.3132e+04                  , pde-loss 1.5198e+03, initc-loss 8.3752e+04                    bc_loss 7.7499e+03\n",
      "Epoch 4480, Training-Loss 1.2836e+05, Data-loss 3.4950e+04                  , pde-loss 1.1616e+03, initc-loss 8.5504e+04                    bc_loss 6.7459e+03\n",
      "Epoch 4490, Training-Loss 1.2899e+05, Data-loss 3.6537e+04                  , pde-loss 1.5892e+03, initc-loss 8.5752e+04                    bc_loss 5.1152e+03\n",
      "Epoch 4500, Training-Loss 1.2176e+05, Data-loss 3.3253e+04                  , pde-loss 7.7932e+02, initc-loss 8.3894e+04                    bc_loss 3.8332e+03\n",
      "Epoch 4510, Training-Loss 1.2531e+05, Data-loss 3.4194e+04                  , pde-loss 1.2723e+03, initc-loss 8.5264e+04                    bc_loss 4.5802e+03\n",
      "Epoch 4520, Training-Loss 1.2776e+05, Data-loss 3.6437e+04                  , pde-loss 3.3068e+03, initc-loss 8.3097e+04                    bc_loss 4.9222e+03\n",
      "Epoch 4530, Training-Loss 1.2286e+05, Data-loss 3.3113e+04                  , pde-loss 1.0494e+03, initc-loss 8.4155e+04                    bc_loss 4.5430e+03\n",
      "Epoch 4540, Training-Loss 1.2844e+05, Data-loss 3.4394e+04                  , pde-loss 2.5359e+03, initc-loss 8.3315e+04                    bc_loss 8.1994e+03\n",
      "Epoch 4550, Training-Loss 1.2821e+05, Data-loss 3.4814e+04                  , pde-loss 3.1195e+03, initc-loss 8.3612e+04                    bc_loss 6.6666e+03\n",
      "Epoch 4560, Training-Loss 1.3194e+05, Data-loss 3.7479e+04                  , pde-loss 1.8275e+03, initc-loss 8.4329e+04                    bc_loss 8.3062e+03\n",
      "Epoch 4570, Training-Loss 1.2315e+05, Data-loss 3.4164e+04                  , pde-loss 2.4562e+03, initc-loss 8.3253e+04                    bc_loss 3.2724e+03\n",
      "Epoch 4580, Training-Loss 1.2172e+05, Data-loss 3.3749e+04                  , pde-loss 1.4967e+03, initc-loss 8.2157e+04                    bc_loss 4.3135e+03\n",
      "Epoch 4590, Training-Loss 1.2738e+05, Data-loss 3.4414e+04                  , pde-loss 1.2211e+03, initc-loss 8.3233e+04                    bc_loss 8.5154e+03\n",
      "Epoch 4600, Training-Loss 1.2330e+05, Data-loss 3.4072e+04                  , pde-loss 1.6929e+03, initc-loss 8.2943e+04                    bc_loss 4.5920e+03\n",
      "Epoch 4610, Training-Loss 1.1800e+05, Data-loss 3.0522e+04                  , pde-loss 8.9762e+02, initc-loss 8.2985e+04                    bc_loss 3.5928e+03\n",
      "Epoch 4620, Training-Loss 1.2086e+05, Data-loss 3.4446e+04                  , pde-loss 1.3938e+03, initc-loss 8.0936e+04                    bc_loss 4.0843e+03\n",
      "Epoch 4630, Training-Loss 1.2459e+05, Data-loss 3.5534e+04                  , pde-loss 1.4083e+03, initc-loss 8.2721e+04                    bc_loss 4.9254e+03\n",
      "Epoch 4640, Training-Loss 1.2846e+05, Data-loss 3.2938e+04                  , pde-loss 1.7633e+03, initc-loss 8.3519e+04                    bc_loss 1.0235e+04\n",
      "Epoch 4650, Training-Loss 1.2313e+05, Data-loss 3.1307e+04                  , pde-loss 1.4350e+03, initc-loss 8.4145e+04                    bc_loss 6.2402e+03\n",
      "Epoch 4660, Training-Loss 1.3020e+05, Data-loss 3.4408e+04                  , pde-loss 3.6769e+03, initc-loss 8.3501e+04                    bc_loss 8.6116e+03\n",
      "Epoch 4670, Training-Loss 1.2729e+05, Data-loss 3.4475e+04                  , pde-loss 1.1002e+03, initc-loss 8.4859e+04                    bc_loss 6.8527e+03\n",
      "Epoch 4680, Training-Loss 1.3025e+05, Data-loss 3.5939e+04                  , pde-loss 1.9525e+03, initc-loss 8.2248e+04                    bc_loss 1.0106e+04\n",
      "Epoch 4690, Training-Loss 1.2394e+05, Data-loss 3.2866e+04                  , pde-loss 1.4358e+03, initc-loss 8.2966e+04                    bc_loss 6.6763e+03\n",
      "Epoch 4700, Training-Loss 1.1988e+05, Data-loss 3.3304e+04                  , pde-loss 1.0567e+03, initc-loss 8.2138e+04                    bc_loss 3.3776e+03\n",
      "Epoch 4710, Training-Loss 1.2431e+05, Data-loss 3.5640e+04                  , pde-loss 1.4621e+03, initc-loss 8.1984e+04                    bc_loss 5.2241e+03\n",
      "Epoch 4720, Training-Loss 1.2495e+05, Data-loss 3.5597e+04                  , pde-loss 2.0259e+03, initc-loss 8.1497e+04                    bc_loss 5.8332e+03\n",
      "Epoch 4730, Training-Loss 1.2212e+05, Data-loss 3.3262e+04                  , pde-loss 1.5403e+03, initc-loss 8.2459e+04                    bc_loss 4.8545e+03\n",
      "Epoch 4740, Training-Loss 1.2243e+05, Data-loss 3.1464e+04                  , pde-loss 1.1554e+03, initc-loss 8.2147e+04                    bc_loss 7.6676e+03\n",
      "Epoch 4750, Training-Loss 1.2411e+05, Data-loss 3.4879e+04                  , pde-loss 1.3410e+03, initc-loss 8.1728e+04                    bc_loss 6.1605e+03\n",
      "Epoch 4760, Training-Loss 1.1860e+05, Data-loss 3.1638e+04                  , pde-loss 1.8328e+03, initc-loss 8.0355e+04                    bc_loss 4.7736e+03\n",
      "Epoch 4770, Training-Loss 1.1999e+05, Data-loss 3.2387e+04                  , pde-loss 7.6682e+02, initc-loss 8.2890e+04                    bc_loss 3.9451e+03\n",
      "Epoch 4780, Training-Loss 1.2279e+05, Data-loss 3.3431e+04                  , pde-loss 1.6219e+03, initc-loss 8.1487e+04                    bc_loss 6.2486e+03\n",
      "Epoch 4790, Training-Loss 1.2055e+05, Data-loss 3.1280e+04                  , pde-loss 9.4048e+02, initc-loss 8.0749e+04                    bc_loss 7.5813e+03\n",
      "Epoch 4800, Training-Loss 1.2014e+05, Data-loss 3.2630e+04                  , pde-loss 1.5453e+03, initc-loss 8.0573e+04                    bc_loss 5.3893e+03\n",
      "Epoch 4810, Training-Loss 1.1947e+05, Data-loss 3.1843e+04                  , pde-loss 2.0432e+03, initc-loss 8.0687e+04                    bc_loss 4.8971e+03\n",
      "Epoch 4820, Training-Loss 1.2434e+05, Data-loss 3.2817e+04                  , pde-loss 1.8042e+03, initc-loss 7.9561e+04                    bc_loss 1.0160e+04\n",
      "Epoch 4830, Training-Loss 1.2524e+05, Data-loss 3.2226e+04                  , pde-loss 1.7546e+03, initc-loss 8.1217e+04                    bc_loss 1.0044e+04\n",
      "Epoch 4840, Training-Loss 1.1900e+05, Data-loss 3.2750e+04                  , pde-loss 1.1125e+03, initc-loss 7.9634e+04                    bc_loss 5.5012e+03\n",
      "Epoch 4850, Training-Loss 1.1899e+05, Data-loss 3.2834e+04                  , pde-loss 7.9459e+02, initc-loss 8.0897e+04                    bc_loss 4.4659e+03\n",
      "Epoch 4860, Training-Loss 1.1617e+05, Data-loss 3.0376e+04                  , pde-loss 1.7552e+03, initc-loss 7.9936e+04                    bc_loss 4.0994e+03\n",
      "Epoch 4870, Training-Loss 1.2312e+05, Data-loss 3.5003e+04                  , pde-loss 2.1947e+03, initc-loss 7.8475e+04                    bc_loss 7.4456e+03\n",
      "Epoch 4880, Training-Loss 1.2898e+05, Data-loss 3.3486e+04                  , pde-loss 2.3607e+03, initc-loss 8.0128e+04                    bc_loss 1.3009e+04\n",
      "Epoch 4890, Training-Loss 1.2536e+05, Data-loss 3.5517e+04                  , pde-loss 2.3060e+03, initc-loss 8.0363e+04                    bc_loss 7.1711e+03\n",
      "Epoch 4900, Training-Loss 1.2507e+05, Data-loss 3.1854e+04                  , pde-loss 1.0132e+03, initc-loss 8.0480e+04                    bc_loss 1.1723e+04\n",
      "Epoch 4910, Training-Loss 1.2045e+05, Data-loss 3.3500e+04                  , pde-loss 1.7925e+03, initc-loss 8.0224e+04                    bc_loss 4.9318e+03\n",
      "Epoch 4920, Training-Loss 1.1546e+05, Data-loss 3.0128e+04                  , pde-loss 1.1615e+03, initc-loss 7.9903e+04                    bc_loss 4.2677e+03\n",
      "Epoch 4930, Training-Loss 1.2541e+05, Data-loss 3.5059e+04                  , pde-loss 2.9911e+03, initc-loss 8.0321e+04                    bc_loss 7.0428e+03\n",
      "Epoch 4940, Training-Loss 1.1966e+05, Data-loss 3.2749e+04                  , pde-loss 1.3919e+03, initc-loss 7.8266e+04                    bc_loss 7.2493e+03\n",
      "Epoch 4950, Training-Loss 1.1848e+05, Data-loss 3.1368e+04                  , pde-loss 1.0967e+03, initc-loss 7.9982e+04                    bc_loss 6.0322e+03\n",
      "Epoch 4960, Training-Loss 1.1856e+05, Data-loss 3.0913e+04                  , pde-loss 1.0193e+03, initc-loss 8.1516e+04                    bc_loss 5.1157e+03\n",
      "Epoch 4970, Training-Loss 1.2086e+05, Data-loss 3.1454e+04                  , pde-loss 1.8245e+03, initc-loss 8.1272e+04                    bc_loss 6.3102e+03\n",
      "Epoch 4980, Training-Loss 1.2837e+05, Data-loss 3.2744e+04                  , pde-loss 1.2259e+03, initc-loss 8.0110e+04                    bc_loss 1.4289e+04\n",
      "Epoch 4990, Training-Loss 1.2632e+05, Data-loss 3.3217e+04                  , pde-loss 1.3346e+03, initc-loss 7.8430e+04                    bc_loss 1.3336e+04\n",
      "Epoch 5000, Training-Loss 2.4899e+05, Data-loss 3.4039e+04                  , pde-loss 2.2182e+03, initc-loss 8.0680e+04                    bc_loss 1.3205e+05\n",
      "Epoch 5010, Training-Loss 1.3780e+05, Data-loss 3.5610e+04                  , pde-loss 3.7934e+03, initc-loss 8.3628e+04                    bc_loss 1.4765e+04\n",
      "Epoch 5020, Training-Loss 1.2816e+05, Data-loss 3.5693e+04                  , pde-loss 1.6763e+03, initc-loss 8.3079e+04                    bc_loss 7.7152e+03\n",
      "Epoch 5030, Training-Loss 1.2735e+05, Data-loss 3.5122e+04                  , pde-loss 2.1026e+03, initc-loss 8.3285e+04                    bc_loss 6.8428e+03\n",
      "Epoch 5040, Training-Loss 1.2572e+05, Data-loss 3.3389e+04                  , pde-loss 3.1746e+03, initc-loss 8.4570e+04                    bc_loss 4.5838e+03\n",
      "Epoch 5050, Training-Loss 1.2323e+05, Data-loss 3.3470e+04                  , pde-loss 3.6593e+03, initc-loss 8.1722e+04                    bc_loss 4.3785e+03\n",
      "Epoch 5060, Training-Loss 1.2577e+05, Data-loss 3.7999e+04                  , pde-loss 1.5355e+03, initc-loss 8.1392e+04                    bc_loss 4.8386e+03\n",
      "Epoch 5070, Training-Loss 1.1862e+05, Data-loss 3.2422e+04                  , pde-loss 1.3674e+03, initc-loss 7.9400e+04                    bc_loss 5.4352e+03\n",
      "Epoch 5080, Training-Loss 1.1749e+05, Data-loss 3.0299e+04                  , pde-loss 1.2446e+03, initc-loss 7.9822e+04                    bc_loss 6.1239e+03\n",
      "Epoch 5090, Training-Loss 1.1786e+05, Data-loss 3.3430e+04                  , pde-loss 1.3486e+03, initc-loss 7.9024e+04                    bc_loss 4.0523e+03\n",
      "Epoch 5100, Training-Loss 1.2117e+05, Data-loss 3.2086e+04                  , pde-loss 1.3733e+03, initc-loss 8.0653e+04                    bc_loss 7.0590e+03\n",
      "Epoch 5110, Training-Loss 1.1775e+05, Data-loss 3.0350e+04                  , pde-loss 2.2938e+03, initc-loss 7.7338e+04                    bc_loss 7.7653e+03\n",
      "Epoch 5120, Training-Loss 1.2001e+05, Data-loss 3.1942e+04                  , pde-loss 1.4853e+03, initc-loss 7.9086e+04                    bc_loss 7.4974e+03\n",
      "Epoch 5130, Training-Loss 1.1406e+05, Data-loss 3.1192e+04                  , pde-loss 8.0469e+02, initc-loss 7.7677e+04                    bc_loss 4.3905e+03\n",
      "Epoch 5140, Training-Loss 1.1763e+05, Data-loss 3.0242e+04                  , pde-loss 2.2888e+03, initc-loss 7.9618e+04                    bc_loss 5.4815e+03\n",
      "Epoch 5150, Training-Loss 1.1631e+05, Data-loss 3.1898e+04                  , pde-loss 5.8486e+02, initc-loss 7.9669e+04                    bc_loss 4.1634e+03\n",
      "Epoch 5160, Training-Loss 1.1821e+05, Data-loss 3.2476e+04                  , pde-loss 1.3140e+03, initc-loss 7.9039e+04                    bc_loss 5.3773e+03\n",
      "Epoch 5170, Training-Loss 1.1895e+05, Data-loss 3.2387e+04                  , pde-loss 1.3391e+03, initc-loss 7.7169e+04                    bc_loss 8.0516e+03\n",
      "Epoch 5180, Training-Loss 1.1731e+05, Data-loss 3.1731e+04                  , pde-loss 1.3484e+03, initc-loss 7.7591e+04                    bc_loss 6.6393e+03\n",
      "Epoch 5190, Training-Loss 1.1669e+05, Data-loss 3.0253e+04                  , pde-loss 1.9736e+03, initc-loss 7.9051e+04                    bc_loss 5.4153e+03\n",
      "Epoch 5200, Training-Loss 1.1554e+05, Data-loss 3.1006e+04                  , pde-loss 1.6418e+03, initc-loss 7.8283e+04                    bc_loss 4.6054e+03\n",
      "Epoch 5210, Training-Loss 1.1831e+05, Data-loss 3.1837e+04                  , pde-loss 1.2099e+03, initc-loss 7.7784e+04                    bc_loss 7.4832e+03\n",
      "Epoch 5220, Training-Loss 1.2536e+05, Data-loss 3.0368e+04                  , pde-loss 7.5211e+02, initc-loss 7.9130e+04                    bc_loss 1.5107e+04\n",
      "Epoch 5230, Training-Loss 1.2866e+05, Data-loss 3.3440e+04                  , pde-loss 1.2831e+03, initc-loss 7.8361e+04                    bc_loss 1.5580e+04\n",
      "Epoch 5240, Training-Loss 1.1607e+05, Data-loss 2.9620e+04                  , pde-loss 9.1189e+02, initc-loss 7.7854e+04                    bc_loss 7.6883e+03\n",
      "Epoch 5250, Training-Loss 1.1889e+05, Data-loss 3.2132e+04                  , pde-loss 1.4345e+03, initc-loss 7.9334e+04                    bc_loss 5.9888e+03\n",
      "Epoch 5260, Training-Loss 1.1811e+05, Data-loss 3.2043e+04                  , pde-loss 1.6111e+03, initc-loss 8.0292e+04                    bc_loss 4.1601e+03\n",
      "Epoch 5270, Training-Loss 1.1358e+05, Data-loss 3.1353e+04                  , pde-loss 1.7833e+03, initc-loss 7.7812e+04                    bc_loss 2.6358e+03\n",
      "Epoch 5280, Training-Loss 1.1918e+05, Data-loss 3.2029e+04                  , pde-loss 1.8503e+03, initc-loss 7.7647e+04                    bc_loss 7.6557e+03\n",
      "Epoch 5290, Training-Loss 1.1838e+05, Data-loss 3.0752e+04                  , pde-loss 1.5315e+03, initc-loss 7.7835e+04                    bc_loss 8.2648e+03\n",
      "Epoch 5300, Training-Loss 1.2374e+05, Data-loss 3.2057e+04                  , pde-loss 1.9039e+03, initc-loss 7.6897e+04                    bc_loss 1.2880e+04\n",
      "Epoch 5310, Training-Loss 1.1813e+05, Data-loss 3.0526e+04                  , pde-loss 2.2740e+03, initc-loss 7.8151e+04                    bc_loss 7.1750e+03\n",
      "Epoch 5320, Training-Loss 1.2331e+05, Data-loss 3.3388e+04                  , pde-loss 3.0247e+03, initc-loss 7.8373e+04                    bc_loss 8.5294e+03\n",
      "Epoch 5330, Training-Loss 1.1775e+05, Data-loss 3.2631e+04                  , pde-loss 1.8280e+03, initc-loss 7.8066e+04                    bc_loss 5.2270e+03\n",
      "Epoch 5340, Training-Loss 1.1957e+05, Data-loss 3.0708e+04                  , pde-loss 1.6054e+03, initc-loss 7.9876e+04                    bc_loss 7.3773e+03\n",
      "Epoch 5350, Training-Loss 1.1955e+05, Data-loss 3.2744e+04                  , pde-loss 2.1544e+03, initc-loss 7.7279e+04                    bc_loss 7.3767e+03\n",
      "Epoch 5360, Training-Loss 1.1384e+05, Data-loss 2.9941e+04                  , pde-loss 1.3569e+03, initc-loss 7.6339e+04                    bc_loss 6.1991e+03\n",
      "Epoch 5370, Training-Loss 1.0927e+05, Data-loss 2.7559e+04                  , pde-loss 1.5839e+03, initc-loss 7.5398e+04                    bc_loss 4.7335e+03\n",
      "Epoch 5380, Training-Loss 1.1373e+05, Data-loss 2.9312e+04                  , pde-loss 1.1954e+03, initc-loss 7.6472e+04                    bc_loss 6.7529e+03\n",
      "Epoch 5390, Training-Loss 1.1692e+05, Data-loss 3.1264e+04                  , pde-loss 9.4452e+02, initc-loss 7.5609e+04                    bc_loss 9.1022e+03\n",
      "Epoch 5400, Training-Loss 1.1041e+05, Data-loss 2.9580e+04                  , pde-loss 1.2625e+03, initc-loss 7.3995e+04                    bc_loss 5.5694e+03\n",
      "Epoch 5410, Training-Loss 1.1374e+05, Data-loss 3.0373e+04                  , pde-loss 1.5945e+03, initc-loss 7.7249e+04                    bc_loss 4.5265e+03\n",
      "Epoch 5420, Training-Loss 1.1507e+05, Data-loss 2.8623e+04                  , pde-loss 1.4619e+03, initc-loss 7.4303e+04                    bc_loss 1.0679e+04\n",
      "Epoch 5430, Training-Loss 1.1393e+05, Data-loss 3.1234e+04                  , pde-loss 1.6607e+03, initc-loss 7.4513e+04                    bc_loss 6.5254e+03\n",
      "Epoch 5440, Training-Loss 1.1435e+05, Data-loss 2.9105e+04                  , pde-loss 2.2509e+03, initc-loss 7.6707e+04                    bc_loss 6.2907e+03\n",
      "Epoch 5450, Training-Loss 1.0956e+05, Data-loss 2.8586e+04                  , pde-loss 1.1735e+03, initc-loss 7.5194e+04                    bc_loss 4.6081e+03\n",
      "Epoch 5460, Training-Loss 1.1316e+05, Data-loss 3.1022e+04                  , pde-loss 1.6480e+03, initc-loss 7.5124e+04                    bc_loss 5.3669e+03\n",
      "Epoch 5470, Training-Loss 1.1573e+05, Data-loss 3.0486e+04                  , pde-loss 2.2860e+03, initc-loss 7.5413e+04                    bc_loss 7.5480e+03\n",
      "Epoch 5480, Training-Loss 1.2011e+05, Data-loss 2.8220e+04                  , pde-loss 1.8409e+03, initc-loss 7.4463e+04                    bc_loss 1.5588e+04\n",
      "Epoch 5490, Training-Loss 1.1430e+05, Data-loss 2.8423e+04                  , pde-loss 1.2722e+03, initc-loss 7.5635e+04                    bc_loss 8.9715e+03\n",
      "Epoch 5500, Training-Loss 1.1701e+05, Data-loss 2.9411e+04                  , pde-loss 2.3675e+03, initc-loss 7.5887e+04                    bc_loss 9.3447e+03\n",
      "Epoch 5510, Training-Loss 1.1347e+05, Data-loss 2.8799e+04                  , pde-loss 1.6309e+03, initc-loss 7.6329e+04                    bc_loss 6.7163e+03\n",
      "Epoch 5520, Training-Loss 1.1931e+05, Data-loss 3.0050e+04                  , pde-loss 1.2623e+03, initc-loss 7.7589e+04                    bc_loss 1.0409e+04\n",
      "Epoch 5530, Training-Loss 1.1853e+05, Data-loss 3.1616e+04                  , pde-loss 1.2379e+03, initc-loss 7.8105e+04                    bc_loss 7.5736e+03\n",
      "Epoch 5540, Training-Loss 1.1232e+05, Data-loss 3.0464e+04                  , pde-loss 1.0231e+03, initc-loss 7.5305e+04                    bc_loss 5.5269e+03\n",
      "Epoch 5550, Training-Loss 1.1267e+05, Data-loss 3.0973e+04                  , pde-loss 1.6907e+03, initc-loss 7.4838e+04                    bc_loss 5.1686e+03\n",
      "Epoch 5560, Training-Loss 1.0816e+05, Data-loss 2.6950e+04                  , pde-loss 6.2989e+02, initc-loss 7.5378e+04                    bc_loss 5.2008e+03\n",
      "Epoch 5570, Training-Loss 1.0752e+05, Data-loss 2.7239e+04                  , pde-loss 9.1910e+02, initc-loss 7.5416e+04                    bc_loss 3.9434e+03\n",
      "Epoch 5580, Training-Loss 1.1240e+05, Data-loss 2.9437e+04                  , pde-loss 1.5290e+03, initc-loss 7.3740e+04                    bc_loss 7.6965e+03\n",
      "Epoch 5590, Training-Loss 1.1537e+05, Data-loss 2.8569e+04                  , pde-loss 1.6100e+03, initc-loss 7.2869e+04                    bc_loss 1.2323e+04\n",
      "Epoch 5600, Training-Loss 1.1820e+05, Data-loss 2.8908e+04                  , pde-loss 1.6221e+03, initc-loss 7.4075e+04                    bc_loss 1.3596e+04\n",
      "Epoch 5610, Training-Loss 1.1323e+05, Data-loss 3.0423e+04                  , pde-loss 9.2921e+02, initc-loss 7.4430e+04                    bc_loss 7.4477e+03\n",
      "Epoch 5620, Training-Loss 1.1005e+05, Data-loss 2.8613e+04                  , pde-loss 1.4834e+03, initc-loss 7.4722e+04                    bc_loss 5.2335e+03\n",
      "Epoch 5630, Training-Loss 1.0978e+05, Data-loss 2.7229e+04                  , pde-loss 7.4262e+02, initc-loss 7.5048e+04                    bc_loss 6.7623e+03\n",
      "Epoch 5640, Training-Loss 1.1033e+05, Data-loss 2.6885e+04                  , pde-loss 1.4233e+03, initc-loss 7.4886e+04                    bc_loss 7.1388e+03\n",
      "Epoch 5650, Training-Loss 1.1501e+05, Data-loss 3.0638e+04                  , pde-loss 1.4657e+03, initc-loss 7.5041e+04                    bc_loss 7.8695e+03\n",
      "Epoch 5660, Training-Loss 1.0914e+05, Data-loss 2.9531e+04                  , pde-loss 1.0838e+03, initc-loss 7.4008e+04                    bc_loss 4.5129e+03\n",
      "Epoch 5670, Training-Loss 1.1207e+05, Data-loss 2.9725e+04                  , pde-loss 2.1715e+03, initc-loss 7.6850e+04                    bc_loss 3.3257e+03\n",
      "Epoch 5680, Training-Loss 1.0630e+05, Data-loss 2.9518e+04                  , pde-loss 1.4291e+03, initc-loss 7.2207e+04                    bc_loss 3.1451e+03\n",
      "Epoch 5690, Training-Loss 1.0502e+05, Data-loss 2.6944e+04                  , pde-loss 9.6470e+02, initc-loss 7.1791e+04                    bc_loss 5.3159e+03\n",
      "Epoch 5700, Training-Loss 1.0426e+05, Data-loss 2.6201e+04                  , pde-loss 9.8763e+02, initc-loss 7.2097e+04                    bc_loss 4.9742e+03\n",
      "Epoch 5710, Training-Loss 1.0683e+05, Data-loss 2.7292e+04                  , pde-loss 1.2464e+03, initc-loss 7.1497e+04                    bc_loss 6.7947e+03\n",
      "Epoch 5720, Training-Loss 1.0702e+05, Data-loss 2.6899e+04                  , pde-loss 1.9396e+03, initc-loss 7.1805e+04                    bc_loss 6.3721e+03\n",
      "Epoch 5730, Training-Loss 1.0607e+05, Data-loss 2.7299e+04                  , pde-loss 1.2767e+03, initc-loss 7.2900e+04                    bc_loss 4.5964e+03\n",
      "Epoch 5740, Training-Loss 1.1345e+05, Data-loss 2.7808e+04                  , pde-loss 1.3027e+03, initc-loss 7.3197e+04                    bc_loss 1.1147e+04\n",
      "Epoch 5750, Training-Loss 1.1945e+05, Data-loss 2.9014e+04                  , pde-loss 1.4124e+03, initc-loss 7.3217e+04                    bc_loss 1.5808e+04\n",
      "Epoch 5760, Training-Loss 1.1159e+05, Data-loss 2.7380e+04                  , pde-loss 1.4765e+03, initc-loss 7.4694e+04                    bc_loss 8.0449e+03\n",
      "Epoch 5770, Training-Loss 1.0954e+05, Data-loss 2.7720e+04                  , pde-loss 1.4479e+03, initc-loss 7.4864e+04                    bc_loss 5.5124e+03\n",
      "Epoch 5780, Training-Loss 1.0678e+05, Data-loss 2.5994e+04                  , pde-loss 7.8521e+02, initc-loss 7.3213e+04                    bc_loss 6.7909e+03\n",
      "Epoch 5790, Training-Loss 1.0438e+05, Data-loss 2.7231e+04                  , pde-loss 8.1651e+02, initc-loss 7.1969e+04                    bc_loss 4.3629e+03\n",
      "Epoch 5800, Training-Loss 1.0617e+05, Data-loss 2.6348e+04                  , pde-loss 8.1721e+02, initc-loss 7.2560e+04                    bc_loss 6.4446e+03\n",
      "Epoch 5810, Training-Loss 1.1296e+05, Data-loss 2.9072e+04                  , pde-loss 1.4770e+03, initc-loss 7.1936e+04                    bc_loss 1.0471e+04\n",
      "Epoch 5820, Training-Loss 1.0830e+05, Data-loss 2.9128e+04                  , pde-loss 1.0269e+03, initc-loss 7.1032e+04                    bc_loss 7.1087e+03\n",
      "Epoch 5830, Training-Loss 1.1464e+05, Data-loss 2.9183e+04                  , pde-loss 2.2726e+03, initc-loss 7.2029e+04                    bc_loss 1.1156e+04\n",
      "Epoch 5840, Training-Loss 1.1136e+05, Data-loss 2.7470e+04                  , pde-loss 1.0683e+03, initc-loss 7.3171e+04                    bc_loss 9.6521e+03\n",
      "Epoch 5850, Training-Loss 1.1027e+05, Data-loss 2.8887e+04                  , pde-loss 1.2485e+03, initc-loss 7.2599e+04                    bc_loss 7.5365e+03\n",
      "Epoch 5860, Training-Loss 1.1118e+05, Data-loss 2.6813e+04                  , pde-loss 1.7150e+03, initc-loss 7.3721e+04                    bc_loss 8.9302e+03\n",
      "Epoch 5870, Training-Loss 1.1663e+05, Data-loss 3.0541e+04                  , pde-loss 1.3018e+03, initc-loss 7.1795e+04                    bc_loss 1.2988e+04\n",
      "Epoch 5880, Training-Loss 1.1668e+05, Data-loss 2.8747e+04                  , pde-loss 1.3922e+03, initc-loss 7.3373e+04                    bc_loss 1.3169e+04\n",
      "Epoch 5890, Training-Loss 1.1599e+05, Data-loss 2.8117e+04                  , pde-loss 1.3185e+03, initc-loss 7.4042e+04                    bc_loss 1.2513e+04\n",
      "Epoch 5900, Training-Loss 1.1035e+05, Data-loss 2.9116e+04                  , pde-loss 1.7603e+03, initc-loss 7.4995e+04                    bc_loss 4.4789e+03\n",
      "Epoch 5910, Training-Loss 1.0377e+05, Data-loss 2.4723e+04                  , pde-loss 9.1904e+02, initc-loss 7.3726e+04                    bc_loss 4.4057e+03\n",
      "Epoch 5920, Training-Loss 1.0713e+05, Data-loss 2.9115e+04                  , pde-loss 1.6473e+03, initc-loss 7.1072e+04                    bc_loss 5.2936e+03\n",
      "Epoch 5930, Training-Loss 1.0742e+05, Data-loss 2.8064e+04                  , pde-loss 8.3314e+02, initc-loss 7.1524e+04                    bc_loss 7.0015e+03\n",
      "Epoch 5940, Training-Loss 1.0786e+05, Data-loss 2.6518e+04                  , pde-loss 1.8332e+03, initc-loss 7.0666e+04                    bc_loss 8.8464e+03\n",
      "Epoch 5950, Training-Loss 1.0141e+05, Data-loss 2.5569e+04                  , pde-loss 1.0684e+03, initc-loss 7.0235e+04                    bc_loss 4.5361e+03\n",
      "Epoch 5960, Training-Loss 1.0377e+05, Data-loss 2.7414e+04                  , pde-loss 1.3147e+03, initc-loss 6.9458e+04                    bc_loss 5.5875e+03\n",
      "Epoch 5970, Training-Loss 1.1000e+05, Data-loss 2.6494e+04                  , pde-loss 2.0604e+03, initc-loss 7.1529e+04                    bc_loss 9.9143e+03\n",
      "Epoch 5980, Training-Loss 1.0520e+05, Data-loss 2.5100e+04                  , pde-loss 1.2619e+03, initc-loss 7.2217e+04                    bc_loss 6.6256e+03\n",
      "Epoch 5990, Training-Loss 1.1086e+05, Data-loss 2.8641e+04                  , pde-loss 1.8245e+03, initc-loss 7.2866e+04                    bc_loss 7.5260e+03\n",
      "Epoch 6000, Training-Loss 1.0378e+05, Data-loss 2.7076e+04                  , pde-loss 1.0150e+03, initc-loss 7.0138e+04                    bc_loss 5.5511e+03\n",
      "Epoch 6010, Training-Loss 1.0896e+05, Data-loss 2.8450e+04                  , pde-loss 8.1352e+02, initc-loss 7.0845e+04                    bc_loss 8.8486e+03\n",
      "Epoch 6020, Training-Loss 1.0265e+05, Data-loss 2.4766e+04                  , pde-loss 1.2216e+03, initc-loss 7.0457e+04                    bc_loss 6.2042e+03\n",
      "Epoch 6030, Training-Loss 1.0487e+05, Data-loss 2.5746e+04                  , pde-loss 1.1493e+03, initc-loss 7.0136e+04                    bc_loss 7.8345e+03\n",
      "Epoch 6040, Training-Loss 1.0380e+05, Data-loss 2.7400e+04                  , pde-loss 1.0919e+03, initc-loss 7.0599e+04                    bc_loss 4.7078e+03\n",
      "Epoch 6050, Training-Loss 1.0630e+05, Data-loss 2.6162e+04                  , pde-loss 6.5762e+02, initc-loss 7.2383e+04                    bc_loss 7.1013e+03\n",
      "Epoch 6060, Training-Loss 1.0499e+05, Data-loss 2.6467e+04                  , pde-loss 8.3618e+02, initc-loss 6.9680e+04                    bc_loss 8.0054e+03\n",
      "Epoch 6070, Training-Loss 1.0537e+05, Data-loss 2.6444e+04                  , pde-loss 2.2449e+03, initc-loss 6.9190e+04                    bc_loss 7.4944e+03\n",
      "Epoch 6080, Training-Loss 1.0881e+05, Data-loss 2.6281e+04                  , pde-loss 1.2750e+03, initc-loss 7.0979e+04                    bc_loss 1.0277e+04\n",
      "Epoch 6090, Training-Loss 1.0928e+05, Data-loss 2.6987e+04                  , pde-loss 9.9166e+02, initc-loss 7.0504e+04                    bc_loss 1.0796e+04\n",
      "Epoch 6100, Training-Loss 1.0536e+05, Data-loss 2.8747e+04                  , pde-loss 1.1828e+03, initc-loss 6.9958e+04                    bc_loss 5.4739e+03\n",
      "Epoch 6110, Training-Loss 1.0779e+05, Data-loss 2.5059e+04                  , pde-loss 1.4692e+03, initc-loss 7.0101e+04                    bc_loss 1.1160e+04\n",
      "Epoch 6120, Training-Loss 1.0955e+05, Data-loss 2.5771e+04                  , pde-loss 1.5242e+03, initc-loss 6.9234e+04                    bc_loss 1.3024e+04\n",
      "Epoch 6130, Training-Loss 1.0362e+05, Data-loss 2.6028e+04                  , pde-loss 1.0778e+03, initc-loss 6.9482e+04                    bc_loss 7.0352e+03\n",
      "Epoch 6140, Training-Loss 1.0690e+05, Data-loss 2.5194e+04                  , pde-loss 1.5138e+03, initc-loss 7.1454e+04                    bc_loss 8.7371e+03\n",
      "Epoch 6150, Training-Loss 1.0436e+05, Data-loss 2.7872e+04                  , pde-loss 9.8244e+02, initc-loss 7.1261e+04                    bc_loss 4.2406e+03\n",
      "Epoch 6160, Training-Loss 1.0095e+05, Data-loss 2.3387e+04                  , pde-loss 7.9289e+02, initc-loss 6.9772e+04                    bc_loss 7.0026e+03\n",
      "Epoch 6170, Training-Loss 1.0565e+05, Data-loss 2.6948e+04                  , pde-loss 1.7266e+03, initc-loss 6.8938e+04                    bc_loss 8.0413e+03\n",
      "Epoch 6180, Training-Loss 1.0846e+05, Data-loss 2.6470e+04                  , pde-loss 9.8583e+02, initc-loss 6.9414e+04                    bc_loss 1.1585e+04\n",
      "Epoch 6190, Training-Loss 1.0623e+05, Data-loss 2.5919e+04                  , pde-loss 1.0211e+03, initc-loss 6.9196e+04                    bc_loss 1.0099e+04\n",
      "Epoch 6200, Training-Loss 1.0891e+05, Data-loss 2.7430e+04                  , pde-loss 2.7337e+03, initc-loss 7.0913e+04                    bc_loss 7.8311e+03\n",
      "Epoch 6210, Training-Loss 1.0665e+05, Data-loss 2.5625e+04                  , pde-loss 1.3017e+03, initc-loss 6.9602e+04                    bc_loss 1.0118e+04\n",
      "Epoch 6220, Training-Loss 1.0599e+05, Data-loss 2.7717e+04                  , pde-loss 1.2503e+03, initc-loss 7.0024e+04                    bc_loss 6.9996e+03\n",
      "Epoch 6230, Training-Loss 1.0193e+05, Data-loss 2.5726e+04                  , pde-loss 1.9730e+03, initc-loss 6.8698e+04                    bc_loss 5.5310e+03\n",
      "Epoch 6240, Training-Loss 9.9023e+04, Data-loss 2.5969e+04                  , pde-loss 1.2097e+03, initc-loss 6.8501e+04                    bc_loss 3.3441e+03\n",
      "Epoch 6250, Training-Loss 9.8702e+04, Data-loss 2.5004e+04                  , pde-loss 1.4732e+03, initc-loss 6.6722e+04                    bc_loss 5.5031e+03\n",
      "Epoch 6260, Training-Loss 1.0888e+05, Data-loss 2.4068e+04                  , pde-loss 8.4072e+02, initc-loss 6.9292e+04                    bc_loss 1.4684e+04\n",
      "Epoch 6270, Training-Loss 1.0849e+05, Data-loss 2.4439e+04                  , pde-loss 7.7919e+02, initc-loss 6.8741e+04                    bc_loss 1.4531e+04\n",
      "Epoch 6280, Training-Loss 1.1831e+05, Data-loss 2.8681e+04                  , pde-loss 1.5573e+03, initc-loss 6.8990e+04                    bc_loss 1.9084e+04\n",
      "Epoch 6290, Training-Loss 1.2975e+05, Data-loss 2.6950e+04                  , pde-loss 1.0113e+03, initc-loss 7.3118e+04                    bc_loss 2.8666e+04\n",
      "Epoch 6300, Training-Loss 1.0967e+05, Data-loss 2.6028e+04                  , pde-loss 1.0738e+03, initc-loss 7.1234e+04                    bc_loss 1.1336e+04\n",
      "Epoch 6310, Training-Loss 1.0393e+05, Data-loss 2.6641e+04                  , pde-loss 1.2871e+03, initc-loss 7.0253e+04                    bc_loss 5.7448e+03\n",
      "Epoch 6320, Training-Loss 1.0240e+05, Data-loss 2.5265e+04                  , pde-loss 2.1945e+03, initc-loss 6.8027e+04                    bc_loss 6.9113e+03\n",
      "Epoch 6330, Training-Loss 1.0591e+05, Data-loss 2.6338e+04                  , pde-loss 1.9278e+03, initc-loss 6.7558e+04                    bc_loss 1.0090e+04\n",
      "Epoch 6340, Training-Loss 1.0008e+05, Data-loss 2.4423e+04                  , pde-loss 1.0290e+03, initc-loss 6.7996e+04                    bc_loss 6.6273e+03\n",
      "Epoch 6350, Training-Loss 9.7300e+04, Data-loss 2.4030e+04                  , pde-loss 9.1325e+02, initc-loss 6.8958e+04                    bc_loss 3.3985e+03\n",
      "Epoch 6360, Training-Loss 1.0153e+05, Data-loss 2.5489e+04                  , pde-loss 2.0469e+03, initc-loss 6.8355e+04                    bc_loss 5.6340e+03\n",
      "Epoch 6370, Training-Loss 1.0330e+05, Data-loss 2.3539e+04                  , pde-loss 7.9152e+02, initc-loss 6.6296e+04                    bc_loss 1.2676e+04\n",
      "Epoch 6380, Training-Loss 1.0203e+05, Data-loss 2.2529e+04                  , pde-loss 1.0913e+03, initc-loss 6.7789e+04                    bc_loss 1.0621e+04\n",
      "Epoch 6390, Training-Loss 1.0496e+05, Data-loss 2.5322e+04                  , pde-loss 1.0999e+03, initc-loss 6.7164e+04                    bc_loss 1.1371e+04\n",
      "Epoch 6400, Training-Loss 1.0340e+05, Data-loss 2.4213e+04                  , pde-loss 1.1349e+03, initc-loss 6.9015e+04                    bc_loss 9.0383e+03\n",
      "Epoch 6410, Training-Loss 1.0567e+05, Data-loss 2.3773e+04                  , pde-loss 9.5594e+02, initc-loss 6.8296e+04                    bc_loss 1.2641e+04\n",
      "Epoch 6420, Training-Loss 1.0738e+05, Data-loss 2.6355e+04                  , pde-loss 1.1208e+03, initc-loss 6.9886e+04                    bc_loss 1.0017e+04\n",
      "Epoch 6430, Training-Loss 9.9860e+04, Data-loss 2.5521e+04                  , pde-loss 1.0850e+03, initc-loss 6.7599e+04                    bc_loss 5.6552e+03\n",
      "Epoch 6440, Training-Loss 1.0632e+05, Data-loss 2.5329e+04                  , pde-loss 1.1281e+03, initc-loss 6.7656e+04                    bc_loss 1.2204e+04\n",
      "Epoch 6450, Training-Loss 1.0403e+05, Data-loss 2.6889e+04                  , pde-loss 1.7802e+03, initc-loss 6.8291e+04                    bc_loss 7.0651e+03\n",
      "Epoch 6460, Training-Loss 9.9239e+04, Data-loss 2.6229e+04                  , pde-loss 1.0083e+03, initc-loss 6.6578e+04                    bc_loss 5.4226e+03\n",
      "Epoch 6470, Training-Loss 1.0346e+05, Data-loss 2.3636e+04                  , pde-loss 8.4275e+02, initc-loss 6.6313e+04                    bc_loss 1.2664e+04\n",
      "Epoch 6480, Training-Loss 1.0685e+05, Data-loss 2.3072e+04                  , pde-loss 1.6133e+03, initc-loss 6.6534e+04                    bc_loss 1.5631e+04\n",
      "Epoch 6490, Training-Loss 1.0033e+05, Data-loss 2.5089e+04                  , pde-loss 7.3580e+02, initc-loss 6.5846e+04                    bc_loss 8.6545e+03\n",
      "Epoch 6500, Training-Loss 1.0510e+05, Data-loss 2.4756e+04                  , pde-loss 9.8138e+02, initc-loss 6.7993e+04                    bc_loss 1.1365e+04\n",
      "Epoch 6510, Training-Loss 1.0846e+05, Data-loss 2.6544e+04                  , pde-loss 3.3526e+03, initc-loss 6.9199e+04                    bc_loss 9.3622e+03\n",
      "Epoch 6520, Training-Loss 9.9032e+04, Data-loss 2.4218e+04                  , pde-loss 1.5809e+03, initc-loss 6.7438e+04                    bc_loss 5.7950e+03\n",
      "Epoch 6530, Training-Loss 1.0008e+05, Data-loss 2.5016e+04                  , pde-loss 1.6016e+03, initc-loss 6.5989e+04                    bc_loss 7.4730e+03\n",
      "Epoch 6540, Training-Loss 1.0706e+05, Data-loss 2.5249e+04                  , pde-loss 1.1667e+03, initc-loss 6.7224e+04                    bc_loss 1.3420e+04\n",
      "Epoch 6550, Training-Loss 1.0088e+05, Data-loss 2.3978e+04                  , pde-loss 1.8019e+03, initc-loss 6.6502e+04                    bc_loss 8.5958e+03\n",
      "Epoch 6560, Training-Loss 9.7222e+04, Data-loss 2.4818e+04                  , pde-loss 1.2011e+03, initc-loss 6.6094e+04                    bc_loss 5.1095e+03\n",
      "Epoch 6570, Training-Loss 9.8833e+04, Data-loss 2.6244e+04                  , pde-loss 2.3329e+03, initc-loss 6.5465e+04                    bc_loss 4.7906e+03\n",
      "Epoch 6580, Training-Loss 9.4698e+04, Data-loss 2.3472e+04                  , pde-loss 1.4247e+03, initc-loss 6.5631e+04                    bc_loss 4.1711e+03\n",
      "Epoch 6590, Training-Loss 9.1813e+04, Data-loss 2.2003e+04                  , pde-loss 1.1904e+03, initc-loss 6.4580e+04                    bc_loss 4.0397e+03\n",
      "Epoch 6600, Training-Loss 9.4907e+04, Data-loss 2.2934e+04                  , pde-loss 1.6239e+03, initc-loss 6.4999e+04                    bc_loss 5.3500e+03\n",
      "Epoch 6610, Training-Loss 1.0293e+05, Data-loss 2.3670e+04                  , pde-loss 1.0828e+03, initc-loss 6.4375e+04                    bc_loss 1.3802e+04\n",
      "Epoch 6620, Training-Loss 1.0914e+05, Data-loss 2.4766e+04                  , pde-loss 1.4331e+03, initc-loss 6.5063e+04                    bc_loss 1.7880e+04\n",
      "Epoch 6630, Training-Loss 1.0662e+05, Data-loss 2.5675e+04                  , pde-loss 1.2968e+03, initc-loss 6.8122e+04                    bc_loss 1.1526e+04\n",
      "Epoch 6640, Training-Loss 9.8031e+04, Data-loss 2.5081e+04                  , pde-loss 6.9031e+02, initc-loss 6.6004e+04                    bc_loss 6.2564e+03\n",
      "Epoch 6650, Training-Loss 9.6479e+04, Data-loss 2.3991e+04                  , pde-loss 1.5767e+03, initc-loss 6.5110e+04                    bc_loss 5.8020e+03\n",
      "Epoch 6660, Training-Loss 9.3538e+04, Data-loss 2.3003e+04                  , pde-loss 9.5069e+02, initc-loss 6.4851e+04                    bc_loss 4.7330e+03\n",
      "Epoch 6670, Training-Loss 1.0015e+05, Data-loss 2.1095e+04                  , pde-loss 1.0911e+03, initc-loss 6.3595e+04                    bc_loss 1.4369e+04\n",
      "Epoch 6680, Training-Loss 1.0687e+05, Data-loss 2.4393e+04                  , pde-loss 1.0105e+03, initc-loss 6.3931e+04                    bc_loss 1.7539e+04\n",
      "Epoch 6690, Training-Loss 1.0908e+05, Data-loss 2.4143e+04                  , pde-loss 2.2326e+03, initc-loss 6.7214e+04                    bc_loss 1.5489e+04\n",
      "Epoch 6700, Training-Loss 9.7620e+04, Data-loss 2.4842e+04                  , pde-loss 1.5355e+03, initc-loss 6.8513e+04                    bc_loss 2.7291e+03\n",
      "Epoch 6710, Training-Loss 9.5626e+04, Data-loss 2.5732e+04                  , pde-loss 1.1388e+03, initc-loss 6.5497e+04                    bc_loss 3.2585e+03\n",
      "Epoch 6720, Training-Loss 9.3220e+04, Data-loss 2.3579e+04                  , pde-loss 1.7649e+03, initc-loss 6.2935e+04                    bc_loss 4.9408e+03\n",
      "Epoch 6730, Training-Loss 9.3747e+04, Data-loss 2.3419e+04                  , pde-loss 1.6164e+03, initc-loss 6.1957e+04                    bc_loss 6.7546e+03\n",
      "Epoch 6740, Training-Loss 9.2281e+04, Data-loss 2.3148e+04                  , pde-loss 1.2514e+03, initc-loss 6.2942e+04                    bc_loss 4.9393e+03\n",
      "Epoch 6750, Training-Loss 9.9734e+04, Data-loss 2.2936e+04                  , pde-loss 1.4701e+03, initc-loss 6.2184e+04                    bc_loss 1.3143e+04\n",
      "Epoch 6760, Training-Loss 9.7933e+04, Data-loss 2.2488e+04                  , pde-loss 1.0936e+03, initc-loss 6.3168e+04                    bc_loss 1.1183e+04\n",
      "Epoch 6770, Training-Loss 9.7059e+04, Data-loss 2.5046e+04                  , pde-loss 2.9277e+03, initc-loss 6.5005e+04                    bc_loss 4.0805e+03\n",
      "Epoch 6780, Training-Loss 1.0454e+05, Data-loss 2.2582e+04                  , pde-loss 1.3975e+03, initc-loss 6.3185e+04                    bc_loss 1.7378e+04\n",
      "Epoch 6790, Training-Loss 9.5635e+04, Data-loss 2.4717e+04                  , pde-loss 1.2986e+03, initc-loss 6.3548e+04                    bc_loss 6.0720e+03\n",
      "Epoch 6800, Training-Loss 9.2414e+04, Data-loss 2.2774e+04                  , pde-loss 1.3484e+03, initc-loss 6.3910e+04                    bc_loss 4.3824e+03\n",
      "Epoch 6810, Training-Loss 9.2798e+04, Data-loss 2.2641e+04                  , pde-loss 8.0050e+02, initc-loss 6.3072e+04                    bc_loss 6.2847e+03\n",
      "Epoch 6820, Training-Loss 9.2792e+04, Data-loss 2.4561e+04                  , pde-loss 1.0792e+03, initc-loss 6.1923e+04                    bc_loss 5.2294e+03\n",
      "Epoch 6830, Training-Loss 9.5957e+04, Data-loss 2.1343e+04                  , pde-loss 1.3097e+03, initc-loss 6.1597e+04                    bc_loss 1.1706e+04\n",
      "Epoch 6840, Training-Loss 9.8428e+04, Data-loss 2.4460e+04                  , pde-loss 1.6585e+03, initc-loss 6.2870e+04                    bc_loss 9.4405e+03\n",
      "Epoch 6850, Training-Loss 9.2589e+04, Data-loss 2.3819e+04                  , pde-loss 1.5779e+03, initc-loss 6.3262e+04                    bc_loss 3.9306e+03\n",
      "Epoch 6860, Training-Loss 8.9896e+04, Data-loss 2.0883e+04                  , pde-loss 9.9563e+02, initc-loss 6.2494e+04                    bc_loss 5.5236e+03\n",
      "Epoch 6870, Training-Loss 9.2724e+04, Data-loss 2.0854e+04                  , pde-loss 2.4092e+03, initc-loss 6.2696e+04                    bc_loss 6.7650e+03\n",
      "Epoch 6880, Training-Loss 9.5049e+04, Data-loss 1.9930e+04                  , pde-loss 1.0640e+03, initc-loss 6.3033e+04                    bc_loss 1.1022e+04\n",
      "Epoch 6890, Training-Loss 9.6625e+04, Data-loss 2.2589e+04                  , pde-loss 1.3327e+03, initc-loss 6.3836e+04                    bc_loss 8.8669e+03\n",
      "Epoch 6900, Training-Loss 1.0017e+05, Data-loss 2.1027e+04                  , pde-loss 1.2073e+03, initc-loss 6.3426e+04                    bc_loss 1.4507e+04\n",
      "Epoch 6910, Training-Loss 1.0099e+05, Data-loss 2.2774e+04                  , pde-loss 1.5003e+03, initc-loss 6.2631e+04                    bc_loss 1.4081e+04\n",
      "Epoch 6920, Training-Loss 9.2050e+04, Data-loss 2.1611e+04                  , pde-loss 1.2071e+03, initc-loss 6.2900e+04                    bc_loss 6.3319e+03\n",
      "Epoch 6930, Training-Loss 9.2878e+04, Data-loss 2.0861e+04                  , pde-loss 1.3117e+03, initc-loss 6.2245e+04                    bc_loss 8.4600e+03\n",
      "Epoch 6940, Training-Loss 1.0095e+05, Data-loss 2.1987e+04                  , pde-loss 1.1648e+03, initc-loss 6.2813e+04                    bc_loss 1.4983e+04\n",
      "Epoch 6950, Training-Loss 9.1988e+04, Data-loss 2.1142e+04                  , pde-loss 7.4565e+02, initc-loss 6.2480e+04                    bc_loss 7.6203e+03\n",
      "Epoch 6960, Training-Loss 9.7011e+04, Data-loss 2.3859e+04                  , pde-loss 2.3534e+03, initc-loss 6.1834e+04                    bc_loss 8.9643e+03\n",
      "Epoch 6970, Training-Loss 9.1381e+04, Data-loss 2.2127e+04                  , pde-loss 1.4346e+03, initc-loss 6.1015e+04                    bc_loss 6.8038e+03\n",
      "Epoch 6980, Training-Loss 9.2085e+04, Data-loss 2.0291e+04                  , pde-loss 1.4473e+03, initc-loss 5.9687e+04                    bc_loss 1.0660e+04\n",
      "Epoch 6990, Training-Loss 9.3752e+04, Data-loss 2.1521e+04                  , pde-loss 1.7296e+03, initc-loss 6.1419e+04                    bc_loss 9.0828e+03\n",
      "Epoch 7000, Training-Loss 9.2983e+04, Data-loss 2.4067e+04                  , pde-loss 1.4817e+03, initc-loss 6.1007e+04                    bc_loss 6.4273e+03\n",
      "Epoch 7010, Training-Loss 9.2037e+04, Data-loss 2.2554e+04                  , pde-loss 1.4000e+03, initc-loss 6.0513e+04                    bc_loss 7.5706e+03\n",
      "Epoch 7020, Training-Loss 8.6075e+04, Data-loss 2.1495e+04                  , pde-loss 7.6501e+02, initc-loss 5.9790e+04                    bc_loss 4.0255e+03\n",
      "Epoch 7030, Training-Loss 9.3024e+04, Data-loss 1.7736e+04                  , pde-loss 1.0089e+03, initc-loss 5.8934e+04                    bc_loss 1.5345e+04\n",
      "Epoch 7040, Training-Loss 9.4884e+04, Data-loss 2.0171e+04                  , pde-loss 1.0875e+03, initc-loss 6.0622e+04                    bc_loss 1.3003e+04\n",
      "Epoch 7050, Training-Loss 9.0714e+04, Data-loss 1.9867e+04                  , pde-loss 1.4470e+03, initc-loss 6.1545e+04                    bc_loss 7.8553e+03\n",
      "Epoch 7060, Training-Loss 9.7850e+04, Data-loss 2.4681e+04                  , pde-loss 2.2109e+03, initc-loss 6.1529e+04                    bc_loss 9.4296e+03\n",
      "Epoch 7070, Training-Loss 9.9600e+04, Data-loss 2.2572e+04                  , pde-loss 1.1817e+03, initc-loss 6.2929e+04                    bc_loss 1.2917e+04\n",
      "Epoch 7080, Training-Loss 9.3388e+04, Data-loss 2.1701e+04                  , pde-loss 1.4842e+03, initc-loss 6.0496e+04                    bc_loss 9.7062e+03\n",
      "Epoch 7090, Training-Loss 9.2370e+04, Data-loss 2.1528e+04                  , pde-loss 1.4348e+03, initc-loss 6.0134e+04                    bc_loss 9.2729e+03\n",
      "Epoch 7100, Training-Loss 8.9207e+04, Data-loss 2.1145e+04                  , pde-loss 1.1821e+03, initc-loss 5.9966e+04                    bc_loss 6.9133e+03\n",
      "Epoch 7110, Training-Loss 9.7044e+04, Data-loss 1.9420e+04                  , pde-loss 1.2046e+03, initc-loss 5.9853e+04                    bc_loss 1.6566e+04\n",
      "Epoch 7120, Training-Loss 9.5380e+04, Data-loss 1.9419e+04                  , pde-loss 1.1651e+03, initc-loss 5.9556e+04                    bc_loss 1.5240e+04\n",
      "Epoch 7130, Training-Loss 1.0313e+05, Data-loss 2.4395e+04                  , pde-loss 1.4929e+03, initc-loss 6.0668e+04                    bc_loss 1.6570e+04\n",
      "Epoch 7140, Training-Loss 9.5032e+04, Data-loss 2.1611e+04                  , pde-loss 1.2919e+03, initc-loss 6.2268e+04                    bc_loss 9.8612e+03\n",
      "Epoch 7150, Training-Loss 9.2047e+04, Data-loss 2.1794e+04                  , pde-loss 1.8198e+03, initc-loss 6.2588e+04                    bc_loss 5.8456e+03\n",
      "Epoch 7160, Training-Loss 8.8603e+04, Data-loss 1.9150e+04                  , pde-loss 1.4199e+03, initc-loss 6.0519e+04                    bc_loss 7.5133e+03\n",
      "Epoch 7170, Training-Loss 9.5966e+04, Data-loss 2.0203e+04                  , pde-loss 2.1009e+03, initc-loss 5.9707e+04                    bc_loss 1.3956e+04\n",
      "Epoch 7180, Training-Loss 9.4180e+04, Data-loss 1.9736e+04                  , pde-loss 1.1609e+03, initc-loss 5.9330e+04                    bc_loss 1.3953e+04\n",
      "Epoch 7190, Training-Loss 9.1128e+04, Data-loss 2.0746e+04                  , pde-loss 1.2070e+03, initc-loss 6.1596e+04                    bc_loss 7.5790e+03\n",
      "Epoch 7200, Training-Loss 9.2472e+04, Data-loss 2.1058e+04                  , pde-loss 1.0022e+03, initc-loss 6.0636e+04                    bc_loss 9.7749e+03\n",
      "Epoch 7210, Training-Loss 1.0934e+05, Data-loss 2.2500e+04                  , pde-loss 1.7610e+03, initc-loss 6.2908e+04                    bc_loss 2.2171e+04\n",
      "Epoch 7220, Training-Loss 9.6567e+04, Data-loss 2.1508e+04                  , pde-loss 1.7097e+03, initc-loss 6.1481e+04                    bc_loss 1.1868e+04\n",
      "Epoch 7230, Training-Loss 9.2172e+04, Data-loss 2.4260e+04                  , pde-loss 1.6508e+03, initc-loss 6.2534e+04                    bc_loss 3.7271e+03\n",
      "Epoch 7240, Training-Loss 8.6390e+04, Data-loss 2.0823e+04                  , pde-loss 2.6844e+03, initc-loss 5.9486e+04                    bc_loss 3.3964e+03\n",
      "Epoch 7250, Training-Loss 8.6218e+04, Data-loss 2.1028e+04                  , pde-loss 2.0292e+03, initc-loss 5.8624e+04                    bc_loss 4.5363e+03\n",
      "Epoch 7260, Training-Loss 8.1677e+04, Data-loss 1.8218e+04                  , pde-loss 1.1599e+03, initc-loss 5.8809e+04                    bc_loss 3.4897e+03\n",
      "Epoch 7270, Training-Loss 7.9797e+04, Data-loss 1.9245e+04                  , pde-loss 1.1599e+03, initc-loss 5.6143e+04                    bc_loss 3.2490e+03\n",
      "Epoch 7280, Training-Loss 8.0757e+04, Data-loss 1.9092e+04                  , pde-loss 1.2593e+03, initc-loss 5.7108e+04                    bc_loss 3.2979e+03\n",
      "Epoch 7290, Training-Loss 8.1241e+04, Data-loss 1.9475e+04                  , pde-loss 1.6931e+03, initc-loss 5.5359e+04                    bc_loss 4.7140e+03\n",
      "Epoch 7300, Training-Loss 7.8427e+04, Data-loss 1.7134e+04                  , pde-loss 1.3521e+03, initc-loss 5.5300e+04                    bc_loss 4.6408e+03\n",
      "Epoch 7310, Training-Loss 8.2018e+04, Data-loss 1.8460e+04                  , pde-loss 1.3684e+03, initc-loss 5.6074e+04                    bc_loss 6.1146e+03\n",
      "Epoch 7320, Training-Loss 8.7429e+04, Data-loss 1.8038e+04                  , pde-loss 1.3540e+03, initc-loss 5.6252e+04                    bc_loss 1.1785e+04\n",
      "Epoch 7330, Training-Loss 8.7191e+04, Data-loss 1.9308e+04                  , pde-loss 1.5410e+03, initc-loss 5.7850e+04                    bc_loss 8.4913e+03\n",
      "Epoch 7340, Training-Loss 8.8543e+04, Data-loss 1.8741e+04                  , pde-loss 9.8038e+02, initc-loss 5.6133e+04                    bc_loss 1.2688e+04\n",
      "Epoch 7350, Training-Loss 8.8078e+04, Data-loss 2.0681e+04                  , pde-loss 1.1791e+03, initc-loss 5.8070e+04                    bc_loss 8.1473e+03\n",
      "Epoch 7360, Training-Loss 8.7915e+04, Data-loss 1.9679e+04                  , pde-loss 2.3068e+03, initc-loss 5.8521e+04                    bc_loss 7.4093e+03\n",
      "Epoch 7370, Training-Loss 8.7021e+04, Data-loss 2.0421e+04                  , pde-loss 1.3477e+03, initc-loss 5.8597e+04                    bc_loss 6.6555e+03\n",
      "Epoch 7380, Training-Loss 8.5963e+04, Data-loss 2.1858e+04                  , pde-loss 1.4538e+03, initc-loss 5.8169e+04                    bc_loss 4.4821e+03\n",
      "Epoch 7390, Training-Loss 8.6062e+04, Data-loss 1.8887e+04                  , pde-loss 1.4817e+03, initc-loss 5.7018e+04                    bc_loss 8.6763e+03\n",
      "Epoch 7400, Training-Loss 8.2110e+04, Data-loss 1.9035e+04                  , pde-loss 2.9726e+03, initc-loss 5.5350e+04                    bc_loss 4.7521e+03\n",
      "Epoch 7410, Training-Loss 7.9389e+04, Data-loss 1.7729e+04                  , pde-loss 1.7191e+03, initc-loss 5.5284e+04                    bc_loss 4.6574e+03\n",
      "Epoch 7420, Training-Loss 8.1207e+04, Data-loss 1.8918e+04                  , pde-loss 1.7342e+03, initc-loss 5.5263e+04                    bc_loss 5.2921e+03\n",
      "Epoch 7430, Training-Loss 7.8727e+04, Data-loss 1.8327e+04                  , pde-loss 1.5837e+03, initc-loss 5.4645e+04                    bc_loss 4.1717e+03\n",
      "Epoch 7440, Training-Loss 7.7487e+04, Data-loss 1.8620e+04                  , pde-loss 1.0570e+03, initc-loss 5.3665e+04                    bc_loss 4.1445e+03\n",
      "Epoch 7450, Training-Loss 8.3433e+04, Data-loss 1.8397e+04                  , pde-loss 2.6249e+03, initc-loss 5.4612e+04                    bc_loss 7.7988e+03\n",
      "Epoch 7460, Training-Loss 7.8883e+04, Data-loss 1.7254e+04                  , pde-loss 1.3352e+03, initc-loss 5.4788e+04                    bc_loss 5.5057e+03\n",
      "Epoch 7470, Training-Loss 7.8562e+04, Data-loss 1.8288e+04                  , pde-loss 1.0371e+03, initc-loss 5.4421e+04                    bc_loss 4.8159e+03\n",
      "Epoch 7480, Training-Loss 8.0200e+04, Data-loss 1.7166e+04                  , pde-loss 1.0057e+03, initc-loss 5.3686e+04                    bc_loss 8.3426e+03\n",
      "Epoch 7490, Training-Loss 7.6583e+04, Data-loss 1.5996e+04                  , pde-loss 1.0734e+03, initc-loss 5.4896e+04                    bc_loss 4.6169e+03\n",
      "Epoch 7500, Training-Loss 8.0763e+04, Data-loss 1.6322e+04                  , pde-loss 9.3824e+02, initc-loss 5.4214e+04                    bc_loss 9.2895e+03\n",
      "Epoch 7510, Training-Loss 8.4251e+04, Data-loss 1.9327e+04                  , pde-loss 1.1781e+03, initc-loss 5.5336e+04                    bc_loss 8.4102e+03\n",
      "Epoch 7520, Training-Loss 7.8769e+04, Data-loss 1.7725e+04                  , pde-loss 6.8064e+02, initc-loss 5.5519e+04                    bc_loss 4.8437e+03\n",
      "Epoch 7530, Training-Loss 8.3550e+04, Data-loss 1.9513e+04                  , pde-loss 1.5210e+03, initc-loss 5.4702e+04                    bc_loss 7.8130e+03\n",
      "Epoch 7540, Training-Loss 8.2913e+04, Data-loss 1.8150e+04                  , pde-loss 7.8636e+02, initc-loss 5.5263e+04                    bc_loss 8.7139e+03\n",
      "Epoch 7550, Training-Loss 7.8112e+04, Data-loss 1.7367e+04                  , pde-loss 1.3831e+03, initc-loss 5.3916e+04                    bc_loss 5.4462e+03\n",
      "Epoch 7560, Training-Loss 7.8613e+04, Data-loss 1.7030e+04                  , pde-loss 1.8777e+03, initc-loss 5.3298e+04                    bc_loss 6.4075e+03\n",
      "Epoch 7570, Training-Loss 7.7955e+04, Data-loss 1.6632e+04                  , pde-loss 1.7066e+03, initc-loss 5.2891e+04                    bc_loss 6.7249e+03\n",
      "Epoch 7580, Training-Loss 8.0821e+04, Data-loss 1.7478e+04                  , pde-loss 1.0290e+03, initc-loss 5.3265e+04                    bc_loss 9.0488e+03\n",
      "Epoch 7590, Training-Loss 8.1213e+04, Data-loss 1.7117e+04                  , pde-loss 1.4194e+03, initc-loss 5.4756e+04                    bc_loss 7.9204e+03\n",
      "Epoch 7600, Training-Loss 7.6281e+04, Data-loss 1.6907e+04                  , pde-loss 1.2566e+03, initc-loss 5.4348e+04                    bc_loss 3.7702e+03\n",
      "Epoch 7610, Training-Loss 7.6284e+04, Data-loss 1.7486e+04                  , pde-loss 9.5011e+02, initc-loss 5.3596e+04                    bc_loss 4.2515e+03\n",
      "Epoch 7620, Training-Loss 7.3972e+04, Data-loss 1.6192e+04                  , pde-loss 9.3578e+02, initc-loss 5.2911e+04                    bc_loss 3.9331e+03\n",
      "Epoch 7630, Training-Loss 7.4295e+04, Data-loss 1.6024e+04                  , pde-loss 1.4154e+03, initc-loss 5.2712e+04                    bc_loss 4.1442e+03\n",
      "Epoch 7640, Training-Loss 7.8031e+04, Data-loss 1.9563e+04                  , pde-loss 1.8708e+03, initc-loss 5.1715e+04                    bc_loss 4.8826e+03\n",
      "Epoch 7650, Training-Loss 7.8194e+04, Data-loss 1.8481e+04                  , pde-loss 1.3625e+03, initc-loss 5.2183e+04                    bc_loss 6.1681e+03\n",
      "Epoch 7660, Training-Loss 7.9176e+04, Data-loss 1.8321e+04                  , pde-loss 2.1845e+03, initc-loss 5.1496e+04                    bc_loss 7.1746e+03\n",
      "Epoch 7670, Training-Loss 8.1412e+04, Data-loss 1.6911e+04                  , pde-loss 1.1507e+03, initc-loss 5.3346e+04                    bc_loss 1.0004e+04\n",
      "Epoch 7680, Training-Loss 7.7009e+04, Data-loss 1.5989e+04                  , pde-loss 1.0588e+03, initc-loss 5.3356e+04                    bc_loss 6.6061e+03\n",
      "Epoch 7690, Training-Loss 7.6620e+04, Data-loss 1.7440e+04                  , pde-loss 1.5917e+03, initc-loss 5.4153e+04                    bc_loss 3.4348e+03\n",
      "Epoch 7700, Training-Loss 7.6419e+04, Data-loss 1.7424e+04                  , pde-loss 2.1141e+03, initc-loss 5.1979e+04                    bc_loss 4.9020e+03\n",
      "Epoch 7710, Training-Loss 7.6128e+04, Data-loss 1.5652e+04                  , pde-loss 1.4580e+03, initc-loss 5.0853e+04                    bc_loss 8.1649e+03\n",
      "Epoch 7720, Training-Loss 7.8798e+04, Data-loss 1.8563e+04                  , pde-loss 2.8766e+03, initc-loss 5.1978e+04                    bc_loss 5.3804e+03\n",
      "Epoch 7730, Training-Loss 7.5605e+04, Data-loss 1.6271e+04                  , pde-loss 1.6065e+03, initc-loss 5.1826e+04                    bc_loss 5.9020e+03\n",
      "Epoch 7740, Training-Loss 7.4845e+04, Data-loss 1.5316e+04                  , pde-loss 8.4490e+02, initc-loss 5.2273e+04                    bc_loss 6.4124e+03\n",
      "Epoch 7750, Training-Loss 7.4039e+04, Data-loss 1.6245e+04                  , pde-loss 1.8151e+03, initc-loss 5.1583e+04                    bc_loss 4.3960e+03\n",
      "Epoch 7760, Training-Loss 7.5958e+04, Data-loss 1.5434e+04                  , pde-loss 1.0649e+03, initc-loss 5.1091e+04                    bc_loss 8.3677e+03\n",
      "Epoch 7770, Training-Loss 7.4893e+04, Data-loss 1.4371e+04                  , pde-loss 1.0467e+03, initc-loss 5.2382e+04                    bc_loss 7.0931e+03\n",
      "Epoch 7780, Training-Loss 7.5817e+04, Data-loss 1.6506e+04                  , pde-loss 8.8689e+02, initc-loss 5.2972e+04                    bc_loss 5.4515e+03\n",
      "Epoch 7790, Training-Loss 7.5094e+04, Data-loss 1.5586e+04                  , pde-loss 1.4663e+03, initc-loss 5.2005e+04                    bc_loss 6.0370e+03\n",
      "Epoch 7800, Training-Loss 7.7110e+04, Data-loss 1.5240e+04                  , pde-loss 8.4728e+02, initc-loss 5.2602e+04                    bc_loss 8.4210e+03\n",
      "Epoch 7810, Training-Loss 7.6352e+04, Data-loss 1.5581e+04                  , pde-loss 1.0225e+03, initc-loss 5.1753e+04                    bc_loss 7.9956e+03\n",
      "Epoch 7820, Training-Loss 7.8871e+04, Data-loss 1.9246e+04                  , pde-loss 1.7342e+03, initc-loss 5.2251e+04                    bc_loss 5.6399e+03\n",
      "Epoch 7830, Training-Loss 7.9205e+04, Data-loss 1.7461e+04                  , pde-loss 1.5322e+03, initc-loss 5.2244e+04                    bc_loss 7.9684e+03\n",
      "Epoch 7840, Training-Loss 8.0620e+04, Data-loss 1.6692e+04                  , pde-loss 1.6551e+03, initc-loss 5.3217e+04                    bc_loss 9.0564e+03\n",
      "Epoch 7850, Training-Loss 7.8370e+04, Data-loss 1.7913e+04                  , pde-loss 1.8768e+03, initc-loss 5.1330e+04                    bc_loss 7.2502e+03\n",
      "Epoch 7860, Training-Loss 7.4463e+04, Data-loss 1.5776e+04                  , pde-loss 1.9159e+03, initc-loss 5.0974e+04                    bc_loss 5.7969e+03\n",
      "Epoch 7870, Training-Loss 7.9218e+04, Data-loss 1.7719e+04                  , pde-loss 3.3966e+03, initc-loss 5.1045e+04                    bc_loss 7.0575e+03\n",
      "Epoch 7880, Training-Loss 7.6985e+04, Data-loss 1.8022e+04                  , pde-loss 1.7583e+03, initc-loss 5.0364e+04                    bc_loss 6.8412e+03\n",
      "Epoch 7890, Training-Loss 7.3255e+04, Data-loss 1.5158e+04                  , pde-loss 1.0407e+03, initc-loss 5.0018e+04                    bc_loss 7.0381e+03\n",
      "Epoch 7900, Training-Loss 7.6075e+04, Data-loss 1.7057e+04                  , pde-loss 2.4811e+03, initc-loss 5.0786e+04                    bc_loss 5.7503e+03\n",
      "Epoch 7910, Training-Loss 7.3530e+04, Data-loss 1.6432e+04                  , pde-loss 1.4334e+03, initc-loss 5.0847e+04                    bc_loss 4.8179e+03\n",
      "Epoch 7920, Training-Loss 7.2891e+04, Data-loss 1.6434e+04                  , pde-loss 1.7351e+03, initc-loss 4.9935e+04                    bc_loss 4.7872e+03\n",
      "Epoch 7930, Training-Loss 7.3870e+04, Data-loss 1.6385e+04                  , pde-loss 2.8288e+03, initc-loss 4.9194e+04                    bc_loss 5.4617e+03\n",
      "Epoch 7940, Training-Loss 7.1901e+04, Data-loss 1.4634e+04                  , pde-loss 1.4533e+03, initc-loss 5.1170e+04                    bc_loss 4.6441e+03\n",
      "Epoch 7950, Training-Loss 7.0445e+04, Data-loss 1.2996e+04                  , pde-loss 1.0603e+03, initc-loss 4.8722e+04                    bc_loss 7.6672e+03\n",
      "Epoch 7960, Training-Loss 7.4143e+04, Data-loss 1.4477e+04                  , pde-loss 1.4535e+03, initc-loss 4.9158e+04                    bc_loss 9.0545e+03\n",
      "Epoch 7970, Training-Loss 8.7397e+04, Data-loss 1.5879e+04                  , pde-loss 1.2866e+03, initc-loss 5.2417e+04                    bc_loss 1.7814e+04\n",
      "Epoch 7980, Training-Loss 7.3994e+04, Data-loss 1.6986e+04                  , pde-loss 1.0597e+03, initc-loss 5.0204e+04                    bc_loss 5.7435e+03\n",
      "Epoch 7990, Training-Loss 7.4620e+04, Data-loss 1.6328e+04                  , pde-loss 1.6228e+03, initc-loss 5.1343e+04                    bc_loss 5.3253e+03\n",
      "Epoch 8000, Training-Loss 7.3546e+04, Data-loss 1.6218e+04                  , pde-loss 1.9335e+03, initc-loss 5.0674e+04                    bc_loss 4.7209e+03\n",
      "Epoch 8010, Training-Loss 7.0642e+04, Data-loss 1.5296e+04                  , pde-loss 1.8888e+03, initc-loss 4.9475e+04                    bc_loss 3.9820e+03\n",
      "Epoch 8020, Training-Loss 6.9591e+04, Data-loss 1.5856e+04                  , pde-loss 1.1003e+03, initc-loss 4.9163e+04                    bc_loss 3.4717e+03\n",
      "Epoch 8030, Training-Loss 7.5536e+04, Data-loss 1.5762e+04                  , pde-loss 2.3873e+03, initc-loss 4.8408e+04                    bc_loss 8.9787e+03\n",
      "Epoch 8040, Training-Loss 7.0884e+04, Data-loss 1.4232e+04                  , pde-loss 1.3397e+03, initc-loss 5.0082e+04                    bc_loss 5.2302e+03\n",
      "Epoch 8050, Training-Loss 7.1248e+04, Data-loss 1.5081e+04                  , pde-loss 1.7883e+03, initc-loss 5.0204e+04                    bc_loss 4.1748e+03\n",
      "Epoch 8060, Training-Loss 7.2412e+04, Data-loss 1.6029e+04                  , pde-loss 2.2223e+03, initc-loss 4.9596e+04                    bc_loss 4.5642e+03\n",
      "Epoch 8070, Training-Loss 7.2146e+04, Data-loss 1.3816e+04                  , pde-loss 1.3772e+03, initc-loss 5.2083e+04                    bc_loss 4.8697e+03\n",
      "Epoch 8080, Training-Loss 7.0937e+04, Data-loss 1.5343e+04                  , pde-loss 1.2679e+03, initc-loss 4.8980e+04                    bc_loss 5.3458e+03\n",
      "Epoch 8090, Training-Loss 6.7796e+04, Data-loss 1.4490e+04                  , pde-loss 8.5850e+02, initc-loss 4.8263e+04                    bc_loss 4.1841e+03\n",
      "Epoch 8100, Training-Loss 6.7081e+04, Data-loss 1.4705e+04                  , pde-loss 1.1147e+03, initc-loss 4.7702e+04                    bc_loss 3.5592e+03\n",
      "Epoch 8110, Training-Loss 6.7636e+04, Data-loss 1.3592e+04                  , pde-loss 1.2995e+03, initc-loss 4.9165e+04                    bc_loss 3.5799e+03\n",
      "Epoch 8120, Training-Loss 6.9888e+04, Data-loss 1.4951e+04                  , pde-loss 2.3767e+03, initc-loss 4.9354e+04                    bc_loss 3.2074e+03\n",
      "Epoch 8130, Training-Loss 6.5234e+04, Data-loss 1.3665e+04                  , pde-loss 1.2215e+03, initc-loss 4.6515e+04                    bc_loss 3.8326e+03\n",
      "Epoch 8140, Training-Loss 6.6879e+04, Data-loss 1.3221e+04                  , pde-loss 1.4609e+03, initc-loss 4.6996e+04                    bc_loss 5.2016e+03\n",
      "Epoch 8150, Training-Loss 6.6109e+04, Data-loss 1.4373e+04                  , pde-loss 1.9367e+03, initc-loss 4.6551e+04                    bc_loss 3.2479e+03\n",
      "Epoch 8160, Training-Loss 7.8227e+04, Data-loss 1.5140e+04                  , pde-loss 9.7704e+02, initc-loss 4.7541e+04                    bc_loss 1.4569e+04\n",
      "Epoch 8170, Training-Loss 7.4291e+04, Data-loss 1.4418e+04                  , pde-loss 1.3744e+03, initc-loss 4.9598e+04                    bc_loss 8.9011e+03\n",
      "Epoch 8180, Training-Loss 7.1956e+04, Data-loss 1.4789e+04                  , pde-loss 1.4472e+03, initc-loss 4.8371e+04                    bc_loss 7.3489e+03\n",
      "Epoch 8190, Training-Loss 7.2820e+04, Data-loss 1.3758e+04                  , pde-loss 1.1325e+03, initc-loss 4.9251e+04                    bc_loss 8.6780e+03\n",
      "Epoch 8200, Training-Loss 7.2824e+04, Data-loss 1.5901e+04                  , pde-loss 2.7820e+03, initc-loss 4.9044e+04                    bc_loss 5.0974e+03\n",
      "Epoch 8210, Training-Loss 6.7552e+04, Data-loss 1.3638e+04                  , pde-loss 1.4213e+03, initc-loss 4.7942e+04                    bc_loss 4.5505e+03\n",
      "Epoch 8220, Training-Loss 6.8988e+04, Data-loss 1.4698e+04                  , pde-loss 1.9488e+03, initc-loss 4.7468e+04                    bc_loss 4.8732e+03\n",
      "Epoch 8230, Training-Loss 7.0228e+04, Data-loss 1.5604e+04                  , pde-loss 2.1731e+03, initc-loss 4.5738e+04                    bc_loss 6.7125e+03\n",
      "Epoch 8240, Training-Loss 7.1359e+04, Data-loss 1.3719e+04                  , pde-loss 1.1375e+03, initc-loss 4.6730e+04                    bc_loss 9.7722e+03\n",
      "Epoch 8250, Training-Loss 7.4508e+04, Data-loss 1.5318e+04                  , pde-loss 1.6822e+03, initc-loss 4.7764e+04                    bc_loss 9.7443e+03\n",
      "Epoch 8260, Training-Loss 7.1033e+04, Data-loss 1.5111e+04                  , pde-loss 1.7106e+03, initc-loss 4.8333e+04                    bc_loss 5.8785e+03\n",
      "Epoch 8270, Training-Loss 6.8078e+04, Data-loss 1.4371e+04                  , pde-loss 1.4694e+03, initc-loss 4.7426e+04                    bc_loss 4.8119e+03\n",
      "Epoch 8280, Training-Loss 7.0987e+04, Data-loss 1.3475e+04                  , pde-loss 1.5137e+03, initc-loss 4.8604e+04                    bc_loss 7.3942e+03\n",
      "Epoch 8290, Training-Loss 6.9949e+04, Data-loss 1.2996e+04                  , pde-loss 1.2540e+03, initc-loss 4.6030e+04                    bc_loss 9.6693e+03\n",
      "Epoch 8300, Training-Loss 6.6813e+04, Data-loss 1.3755e+04                  , pde-loss 1.1934e+03, initc-loss 4.7379e+04                    bc_loss 4.4852e+03\n",
      "Epoch 8310, Training-Loss 6.7276e+04, Data-loss 1.4630e+04                  , pde-loss 1.5695e+03, initc-loss 4.7746e+04                    bc_loss 3.3300e+03\n",
      "Epoch 8320, Training-Loss 6.4202e+04, Data-loss 1.2822e+04                  , pde-loss 1.2433e+03, initc-loss 4.6553e+04                    bc_loss 3.5834e+03\n",
      "Epoch 8330, Training-Loss 6.7729e+04, Data-loss 1.3127e+04                  , pde-loss 1.6029e+03, initc-loss 4.6654e+04                    bc_loss 6.3446e+03\n",
      "Epoch 8340, Training-Loss 6.7310e+04, Data-loss 1.2484e+04                  , pde-loss 1.4223e+03, initc-loss 4.6406e+04                    bc_loss 6.9972e+03\n",
      "Epoch 8350, Training-Loss 6.5556e+04, Data-loss 1.4050e+04                  , pde-loss 1.1949e+03, initc-loss 4.5576e+04                    bc_loss 4.7348e+03\n",
      "Epoch 8360, Training-Loss 6.9293e+04, Data-loss 1.5056e+04                  , pde-loss 1.5002e+03, initc-loss 4.7183e+04                    bc_loss 5.5533e+03\n",
      "Epoch 8370, Training-Loss 6.6361e+04, Data-loss 1.3039e+04                  , pde-loss 1.2962e+03, initc-loss 4.5691e+04                    bc_loss 6.3354e+03\n",
      "Epoch 8380, Training-Loss 6.8056e+04, Data-loss 1.2429e+04                  , pde-loss 1.0694e+03, initc-loss 4.7086e+04                    bc_loss 7.4718e+03\n",
      "Epoch 8390, Training-Loss 6.6141e+04, Data-loss 1.4289e+04                  , pde-loss 1.3448e+03, initc-loss 4.5837e+04                    bc_loss 4.6695e+03\n",
      "Epoch 8400, Training-Loss 6.7789e+04, Data-loss 1.5184e+04                  , pde-loss 1.6837e+03, initc-loss 4.6096e+04                    bc_loss 4.8254e+03\n",
      "Epoch 8410, Training-Loss 6.5027e+04, Data-loss 1.3113e+04                  , pde-loss 1.2403e+03, initc-loss 4.5177e+04                    bc_loss 5.4966e+03\n",
      "Epoch 8420, Training-Loss 6.8199e+04, Data-loss 1.3268e+04                  , pde-loss 8.4921e+02, initc-loss 4.5723e+04                    bc_loss 8.3593e+03\n",
      "Epoch 8430, Training-Loss 7.2157e+04, Data-loss 1.5297e+04                  , pde-loss 1.7486e+03, initc-loss 4.6223e+04                    bc_loss 8.8891e+03\n",
      "Epoch 8440, Training-Loss 7.1773e+04, Data-loss 1.4585e+04                  , pde-loss 1.4514e+03, initc-loss 4.8348e+04                    bc_loss 7.3881e+03\n",
      "Epoch 8450, Training-Loss 6.7341e+04, Data-loss 1.3761e+04                  , pde-loss 1.2050e+03, initc-loss 4.8773e+04                    bc_loss 3.6023e+03\n",
      "Epoch 8460, Training-Loss 6.5296e+04, Data-loss 1.3564e+04                  , pde-loss 1.5833e+03, initc-loss 4.6273e+04                    bc_loss 3.8756e+03\n",
      "Epoch 8470, Training-Loss 6.7348e+04, Data-loss 1.3553e+04                  , pde-loss 1.6849e+03, initc-loss 4.6408e+04                    bc_loss 5.7028e+03\n",
      "Epoch 8480, Training-Loss 6.8043e+04, Data-loss 1.3691e+04                  , pde-loss 1.5095e+03, initc-loss 4.6215e+04                    bc_loss 6.6277e+03\n",
      "Epoch 8490, Training-Loss 6.9597e+04, Data-loss 1.3094e+04                  , pde-loss 1.1361e+03, initc-loss 4.6609e+04                    bc_loss 8.7576e+03\n",
      "Epoch 8500, Training-Loss 6.7278e+04, Data-loss 1.2715e+04                  , pde-loss 1.3981e+03, initc-loss 4.6473e+04                    bc_loss 6.6923e+03\n",
      "Epoch 8510, Training-Loss 9.4624e+04, Data-loss 1.3897e+04                  , pde-loss 1.3277e+03, initc-loss 4.9295e+04                    bc_loss 3.0105e+04\n",
      "Epoch 8520, Training-Loss 9.5317e+04, Data-loss 1.9837e+04                  , pde-loss 1.3835e+03, initc-loss 5.4491e+04                    bc_loss 1.9605e+04\n",
      "Epoch 8530, Training-Loss 7.9573e+04, Data-loss 1.7846e+04                  , pde-loss 1.7574e+03, initc-loss 5.4570e+04                    bc_loss 5.3996e+03\n",
      "Epoch 8540, Training-Loss 7.8084e+04, Data-loss 1.6878e+04                  , pde-loss 1.3298e+03, initc-loss 5.3941e+04                    bc_loss 5.9356e+03\n",
      "Epoch 8550, Training-Loss 7.6089e+04, Data-loss 1.7732e+04                  , pde-loss 3.1475e+03, initc-loss 5.1734e+04                    bc_loss 3.4758e+03\n",
      "Epoch 8560, Training-Loss 6.9505e+04, Data-loss 1.5102e+04                  , pde-loss 1.2900e+03, initc-loss 4.9018e+04                    bc_loss 4.0946e+03\n",
      "Epoch 8570, Training-Loss 6.9250e+04, Data-loss 1.4654e+04                  , pde-loss 1.4647e+03, initc-loss 4.8588e+04                    bc_loss 4.5436e+03\n",
      "Epoch 8580, Training-Loss 7.0017e+04, Data-loss 1.3847e+04                  , pde-loss 1.7124e+03, initc-loss 4.8242e+04                    bc_loss 6.2161e+03\n",
      "Epoch 8590, Training-Loss 7.5247e+04, Data-loss 1.4906e+04                  , pde-loss 1.8096e+03, initc-loss 4.6116e+04                    bc_loss 1.2415e+04\n",
      "Epoch 8600, Training-Loss 6.9514e+04, Data-loss 1.3024e+04                  , pde-loss 1.3991e+03, initc-loss 4.6965e+04                    bc_loss 8.1260e+03\n",
      "Epoch 8610, Training-Loss 6.8438e+04, Data-loss 1.3719e+04                  , pde-loss 1.8277e+03, initc-loss 4.6218e+04                    bc_loss 6.6742e+03\n",
      "Epoch 8620, Training-Loss 6.4077e+04, Data-loss 1.2224e+04                  , pde-loss 1.7727e+03, initc-loss 4.6058e+04                    bc_loss 4.0225e+03\n",
      "Epoch 8630, Training-Loss 6.3925e+04, Data-loss 1.2936e+04                  , pde-loss 1.3257e+03, initc-loss 4.6005e+04                    bc_loss 3.6576e+03\n",
      "Epoch 8640, Training-Loss 6.2454e+04, Data-loss 1.2125e+04                  , pde-loss 8.3131e+02, initc-loss 4.4426e+04                    bc_loss 5.0707e+03\n",
      "Epoch 8650, Training-Loss 6.4639e+04, Data-loss 1.2696e+04                  , pde-loss 1.9013e+03, initc-loss 4.5408e+04                    bc_loss 4.6335e+03\n",
      "Epoch 8660, Training-Loss 6.7229e+04, Data-loss 1.3724e+04                  , pde-loss 1.3561e+03, initc-loss 4.5567e+04                    bc_loss 6.5805e+03\n",
      "Epoch 8670, Training-Loss 6.9968e+04, Data-loss 1.5094e+04                  , pde-loss 1.6181e+03, initc-loss 4.6890e+04                    bc_loss 6.3661e+03\n",
      "Epoch 8680, Training-Loss 7.1787e+04, Data-loss 1.4437e+04                  , pde-loss 1.3620e+03, initc-loss 4.5346e+04                    bc_loss 1.0642e+04\n",
      "Epoch 8690, Training-Loss 7.4061e+04, Data-loss 1.4784e+04                  , pde-loss 2.5070e+03, initc-loss 4.7111e+04                    bc_loss 9.6585e+03\n",
      "Epoch 8700, Training-Loss 7.6223e+04, Data-loss 1.5882e+04                  , pde-loss 1.4158e+03, initc-loss 4.6792e+04                    bc_loss 1.2133e+04\n",
      "Epoch 8710, Training-Loss 6.9728e+04, Data-loss 1.2902e+04                  , pde-loss 1.7471e+03, initc-loss 4.6288e+04                    bc_loss 8.7905e+03\n",
      "Epoch 8720, Training-Loss 6.9217e+04, Data-loss 1.2998e+04                  , pde-loss 1.2365e+03, initc-loss 4.7589e+04                    bc_loss 7.3933e+03\n",
      "Epoch 8730, Training-Loss 6.7498e+04, Data-loss 1.2771e+04                  , pde-loss 1.5149e+03, initc-loss 4.6464e+04                    bc_loss 6.7472e+03\n",
      "Epoch 8740, Training-Loss 6.8378e+04, Data-loss 1.3374e+04                  , pde-loss 1.1402e+03, initc-loss 4.6728e+04                    bc_loss 7.1358e+03\n",
      "Epoch 8750, Training-Loss 6.5624e+04, Data-loss 1.3214e+04                  , pde-loss 1.2969e+03, initc-loss 4.6148e+04                    bc_loss 4.9648e+03\n",
      "Epoch 8760, Training-Loss 6.8798e+04, Data-loss 1.4260e+04                  , pde-loss 1.5538e+03, initc-loss 4.6372e+04                    bc_loss 6.6122e+03\n",
      "Epoch 8770, Training-Loss 6.7078e+04, Data-loss 1.2261e+04                  , pde-loss 1.3113e+03, initc-loss 4.4754e+04                    bc_loss 8.7514e+03\n",
      "Epoch 8780, Training-Loss 6.5333e+04, Data-loss 1.2140e+04                  , pde-loss 1.0983e+03, initc-loss 4.5019e+04                    bc_loss 7.0759e+03\n",
      "Epoch 8790, Training-Loss 6.4622e+04, Data-loss 1.2022e+04                  , pde-loss 1.4853e+03, initc-loss 4.3861e+04                    bc_loss 7.2541e+03\n",
      "Epoch 8800, Training-Loss 6.6109e+04, Data-loss 1.3471e+04                  , pde-loss 1.3878e+03, initc-loss 4.5827e+04                    bc_loss 5.4231e+03\n",
      "Epoch 8810, Training-Loss 6.6836e+04, Data-loss 1.2926e+04                  , pde-loss 1.4832e+03, initc-loss 4.3488e+04                    bc_loss 8.9391e+03\n",
      "Epoch 8820, Training-Loss 6.7403e+04, Data-loss 1.1913e+04                  , pde-loss 1.2811e+03, initc-loss 4.3456e+04                    bc_loss 1.0753e+04\n",
      "Epoch 8830, Training-Loss 6.4845e+04, Data-loss 1.0960e+04                  , pde-loss 1.3551e+03, initc-loss 4.4565e+04                    bc_loss 7.9652e+03\n",
      "Epoch 8840, Training-Loss 6.6996e+04, Data-loss 1.2187e+04                  , pde-loss 1.2745e+03, initc-loss 4.4707e+04                    bc_loss 8.8272e+03\n",
      "Epoch 8850, Training-Loss 7.0579e+04, Data-loss 1.5572e+04                  , pde-loss 2.1034e+03, initc-loss 4.7705e+04                    bc_loss 5.1982e+03\n",
      "Epoch 8860, Training-Loss 6.4302e+04, Data-loss 1.2613e+04                  , pde-loss 1.6788e+03, initc-loss 4.5971e+04                    bc_loss 4.0405e+03\n",
      "Epoch 8870, Training-Loss 7.3507e+04, Data-loss 1.3824e+04                  , pde-loss 1.6474e+03, initc-loss 4.4288e+04                    bc_loss 1.3747e+04\n",
      "Epoch 8880, Training-Loss 7.4584e+04, Data-loss 1.3079e+04                  , pde-loss 1.6195e+03, initc-loss 4.6491e+04                    bc_loss 1.3396e+04\n",
      "Epoch 8890, Training-Loss 6.9221e+04, Data-loss 1.1767e+04                  , pde-loss 1.1094e+03, initc-loss 4.6574e+04                    bc_loss 9.7712e+03\n",
      "Epoch 8900, Training-Loss 7.1755e+04, Data-loss 1.5889e+04                  , pde-loss 2.1770e+03, initc-loss 4.6655e+04                    bc_loss 7.0338e+03\n",
      "Epoch 8910, Training-Loss 6.5147e+04, Data-loss 1.2656e+04                  , pde-loss 1.2477e+03, initc-loss 4.5058e+04                    bc_loss 6.1863e+03\n",
      "Epoch 8920, Training-Loss 6.6820e+04, Data-loss 1.3882e+04                  , pde-loss 1.7869e+03, initc-loss 4.5005e+04                    bc_loss 6.1461e+03\n",
      "Epoch 8930, Training-Loss 6.4862e+04, Data-loss 1.2890e+04                  , pde-loss 1.2142e+03, initc-loss 4.3713e+04                    bc_loss 7.0446e+03\n",
      "Epoch 8940, Training-Loss 6.2354e+04, Data-loss 1.1723e+04                  , pde-loss 2.0214e+03, initc-loss 4.3451e+04                    bc_loss 5.1577e+03\n",
      "Epoch 8950, Training-Loss 6.1439e+04, Data-loss 1.1477e+04                  , pde-loss 9.9983e+02, initc-loss 4.3836e+04                    bc_loss 5.1265e+03\n",
      "Epoch 8960, Training-Loss 6.4499e+04, Data-loss 1.0403e+04                  , pde-loss 1.1596e+03, initc-loss 4.4291e+04                    bc_loss 8.6461e+03\n",
      "Epoch 8970, Training-Loss 6.0376e+04, Data-loss 1.1971e+04                  , pde-loss 1.9196e+03, initc-loss 4.3123e+04                    bc_loss 3.3627e+03\n",
      "Epoch 8980, Training-Loss 6.3466e+04, Data-loss 1.2469e+04                  , pde-loss 1.1238e+03, initc-loss 4.4214e+04                    bc_loss 5.6586e+03\n",
      "Epoch 8990, Training-Loss 6.7896e+04, Data-loss 1.4652e+04                  , pde-loss 2.1987e+03, initc-loss 4.3473e+04                    bc_loss 7.5721e+03\n",
      "Epoch 9000, Training-Loss 6.2676e+04, Data-loss 1.2230e+04                  , pde-loss 1.9530e+03, initc-loss 4.3733e+04                    bc_loss 4.7607e+03\n",
      "Epoch 9010, Training-Loss 6.1675e+04, Data-loss 1.1836e+04                  , pde-loss 1.3278e+03, initc-loss 4.2011e+04                    bc_loss 6.5008e+03\n",
      "Epoch 9020, Training-Loss 6.2745e+04, Data-loss 1.1366e+04                  , pde-loss 1.1338e+03, initc-loss 4.3317e+04                    bc_loss 6.9280e+03\n",
      "Epoch 9030, Training-Loss 6.3807e+04, Data-loss 1.1283e+04                  , pde-loss 1.5817e+03, initc-loss 4.3464e+04                    bc_loss 7.4781e+03\n",
      "Epoch 9040, Training-Loss 5.9796e+04, Data-loss 1.1903e+04                  , pde-loss 1.0606e+03, initc-loss 4.2408e+04                    bc_loss 4.4236e+03\n",
      "Epoch 9050, Training-Loss 6.9179e+04, Data-loss 1.2189e+04                  , pde-loss 1.4109e+03, initc-loss 4.3014e+04                    bc_loss 1.2565e+04\n",
      "Epoch 9060, Training-Loss 6.9035e+04, Data-loss 1.2469e+04                  , pde-loss 1.0681e+03, initc-loss 4.3477e+04                    bc_loss 1.2021e+04\n",
      "Epoch 9070, Training-Loss 6.6647e+04, Data-loss 1.1884e+04                  , pde-loss 2.0387e+03, initc-loss 4.3438e+04                    bc_loss 9.2860e+03\n",
      "Epoch 9080, Training-Loss 6.6653e+04, Data-loss 1.3335e+04                  , pde-loss 1.3359e+03, initc-loss 4.4620e+04                    bc_loss 7.3623e+03\n",
      "Epoch 9090, Training-Loss 6.5546e+04, Data-loss 1.3387e+04                  , pde-loss 1.1147e+03, initc-loss 4.4508e+04                    bc_loss 6.5364e+03\n",
      "Epoch 9100, Training-Loss 7.2958e+04, Data-loss 1.2918e+04                  , pde-loss 1.6321e+03, initc-loss 4.5315e+04                    bc_loss 1.3093e+04\n",
      "Epoch 9110, Training-Loss 7.4721e+04, Data-loss 1.2650e+04                  , pde-loss 1.8384e+03, initc-loss 4.4302e+04                    bc_loss 1.5930e+04\n",
      "Epoch 9120, Training-Loss 6.4751e+04, Data-loss 1.3057e+04                  , pde-loss 2.4040e+03, initc-loss 4.4628e+04                    bc_loss 4.6610e+03\n",
      "Epoch 9130, Training-Loss 6.0619e+04, Data-loss 1.0935e+04                  , pde-loss 1.2501e+03, initc-loss 4.2519e+04                    bc_loss 5.9142e+03\n",
      "Epoch 9140, Training-Loss 7.8710e+04, Data-loss 1.4144e+04                  , pde-loss 1.1686e+03, initc-loss 4.3230e+04                    bc_loss 2.0168e+04\n",
      "Epoch 9150, Training-Loss 6.7485e+04, Data-loss 1.4095e+04                  , pde-loss 9.3057e+02, initc-loss 4.4558e+04                    bc_loss 7.9009e+03\n",
      "Epoch 9160, Training-Loss 7.2601e+04, Data-loss 1.2668e+04                  , pde-loss 1.3856e+03, initc-loss 4.6564e+04                    bc_loss 1.1984e+04\n",
      "Epoch 9170, Training-Loss 6.2096e+04, Data-loss 1.2812e+04                  , pde-loss 1.3693e+03, initc-loss 4.4279e+04                    bc_loss 3.6363e+03\n",
      "Epoch 9180, Training-Loss 6.1736e+04, Data-loss 1.2292e+04                  , pde-loss 1.0315e+03, initc-loss 4.3273e+04                    bc_loss 5.1394e+03\n",
      "Epoch 9190, Training-Loss 6.2511e+04, Data-loss 1.1250e+04                  , pde-loss 1.5477e+03, initc-loss 4.1505e+04                    bc_loss 8.2071e+03\n",
      "Epoch 9200, Training-Loss 7.7558e+04, Data-loss 1.2663e+04                  , pde-loss 1.4607e+03, initc-loss 4.2488e+04                    bc_loss 2.0946e+04\n",
      "Epoch 9210, Training-Loss 7.9752e+04, Data-loss 1.3443e+04                  , pde-loss 1.8762e+03, initc-loss 4.6090e+04                    bc_loss 1.8343e+04\n",
      "Epoch 9220, Training-Loss 8.0043e+04, Data-loss 1.5598e+04                  , pde-loss 2.3126e+03, initc-loss 4.7975e+04                    bc_loss 1.4157e+04\n",
      "Epoch 9230, Training-Loss 7.1331e+04, Data-loss 1.6343e+04                  , pde-loss 1.1744e+03, initc-loss 4.6126e+04                    bc_loss 7.6870e+03\n",
      "Epoch 9240, Training-Loss 6.5929e+04, Data-loss 1.2790e+04                  , pde-loss 1.4546e+03, initc-loss 4.6307e+04                    bc_loss 5.3779e+03\n",
      "Epoch 9250, Training-Loss 7.2170e+04, Data-loss 1.6386e+04                  , pde-loss 1.4981e+03, initc-loss 4.4980e+04                    bc_loss 9.3065e+03\n",
      "Epoch 9260, Training-Loss 6.4097e+04, Data-loss 1.0458e+04                  , pde-loss 1.5489e+03, initc-loss 4.4521e+04                    bc_loss 7.5697e+03\n",
      "Epoch 9270, Training-Loss 6.2736e+04, Data-loss 1.3298e+04                  , pde-loss 2.6987e+03, initc-loss 4.1744e+04                    bc_loss 4.9962e+03\n",
      "Epoch 9280, Training-Loss 6.4384e+04, Data-loss 1.2515e+04                  , pde-loss 1.4880e+03, initc-loss 4.3435e+04                    bc_loss 6.9467e+03\n",
      "Epoch 9290, Training-Loss 6.8451e+04, Data-loss 1.2749e+04                  , pde-loss 1.3825e+03, initc-loss 4.2770e+04                    bc_loss 1.1549e+04\n",
      "Epoch 9300, Training-Loss 7.0615e+04, Data-loss 1.3280e+04                  , pde-loss 1.3972e+03, initc-loss 4.2685e+04                    bc_loss 1.3252e+04\n",
      "Epoch 9310, Training-Loss 6.7247e+04, Data-loss 1.3505e+04                  , pde-loss 1.8143e+03, initc-loss 4.4201e+04                    bc_loss 7.7270e+03\n",
      "Epoch 9320, Training-Loss 6.4469e+04, Data-loss 1.3080e+04                  , pde-loss 1.1270e+03, initc-loss 4.5410e+04                    bc_loss 4.8522e+03\n",
      "Epoch 9330, Training-Loss 6.3175e+04, Data-loss 1.1982e+04                  , pde-loss 1.2837e+03, initc-loss 4.3635e+04                    bc_loss 6.2737e+03\n",
      "Epoch 9340, Training-Loss 6.2088e+04, Data-loss 1.1696e+04                  , pde-loss 8.1191e+02, initc-loss 4.1424e+04                    bc_loss 8.1553e+03\n",
      "Epoch 9350, Training-Loss 5.9386e+04, Data-loss 1.0582e+04                  , pde-loss 1.1182e+03, initc-loss 4.1409e+04                    bc_loss 6.2760e+03\n",
      "Epoch 9360, Training-Loss 6.2567e+04, Data-loss 1.1447e+04                  , pde-loss 1.5175e+03, initc-loss 4.1118e+04                    bc_loss 8.4843e+03\n",
      "Epoch 9370, Training-Loss 6.2483e+04, Data-loss 1.1004e+04                  , pde-loss 1.8360e+03, initc-loss 4.3061e+04                    bc_loss 6.5819e+03\n",
      "Epoch 9380, Training-Loss 6.8917e+04, Data-loss 1.3329e+04                  , pde-loss 1.5465e+03, initc-loss 4.4663e+04                    bc_loss 9.3785e+03\n",
      "Epoch 9390, Training-Loss 6.7481e+04, Data-loss 1.1838e+04                  , pde-loss 1.1502e+03, initc-loss 4.3589e+04                    bc_loss 1.0903e+04\n",
      "Epoch 9400, Training-Loss 6.3280e+04, Data-loss 1.1388e+04                  , pde-loss 1.1056e+03, initc-loss 4.3188e+04                    bc_loss 7.5988e+03\n",
      "Epoch 9410, Training-Loss 6.2526e+04, Data-loss 1.2243e+04                  , pde-loss 1.3224e+03, initc-loss 4.2225e+04                    bc_loss 6.7356e+03\n",
      "Epoch 9420, Training-Loss 5.8819e+04, Data-loss 1.1409e+04                  , pde-loss 1.1784e+03, initc-loss 4.1463e+04                    bc_loss 4.7684e+03\n",
      "Epoch 9430, Training-Loss 6.6908e+04, Data-loss 1.2991e+04                  , pde-loss 2.1331e+03, initc-loss 4.1723e+04                    bc_loss 1.0061e+04\n",
      "Epoch 9440, Training-Loss 7.3116e+04, Data-loss 1.3004e+04                  , pde-loss 1.7122e+03, initc-loss 4.2422e+04                    bc_loss 1.5978e+04\n",
      "Epoch 9450, Training-Loss 6.9024e+04, Data-loss 1.0976e+04                  , pde-loss 1.4706e+03, initc-loss 4.4007e+04                    bc_loss 1.2571e+04\n",
      "Epoch 9460, Training-Loss 6.6333e+04, Data-loss 1.3356e+04                  , pde-loss 1.4841e+03, initc-loss 4.3772e+04                    bc_loss 7.7211e+03\n",
      "Epoch 9470, Training-Loss 6.1279e+04, Data-loss 1.1318e+04                  , pde-loss 1.6112e+03, initc-loss 4.2691e+04                    bc_loss 5.6583e+03\n",
      "Epoch 9480, Training-Loss 6.3497e+04, Data-loss 1.3762e+04                  , pde-loss 1.8112e+03, initc-loss 4.2093e+04                    bc_loss 5.8309e+03\n",
      "Epoch 9490, Training-Loss 7.1572e+04, Data-loss 1.2899e+04                  , pde-loss 1.6507e+03, initc-loss 4.2255e+04                    bc_loss 1.4767e+04\n",
      "Epoch 9500, Training-Loss 7.6282e+04, Data-loss 1.2136e+04                  , pde-loss 1.0567e+03, initc-loss 4.4232e+04                    bc_loss 1.8857e+04\n",
      "Epoch 9510, Training-Loss 8.4900e+04, Data-loss 1.5480e+04                  , pde-loss 2.7026e+03, initc-loss 4.9751e+04                    bc_loss 1.6966e+04\n",
      "Epoch 9520, Training-Loss 8.0762e+04, Data-loss 1.8157e+04                  , pde-loss 1.9271e+03, initc-loss 5.3209e+04                    bc_loss 7.4695e+03\n",
      "Epoch 9530, Training-Loss 7.4043e+04, Data-loss 1.6938e+04                  , pde-loss 1.1661e+03, initc-loss 5.1095e+04                    bc_loss 4.8447e+03\n",
      "Epoch 9540, Training-Loss 6.8085e+04, Data-loss 1.3384e+04                  , pde-loss 1.1368e+03, initc-loss 4.8360e+04                    bc_loss 5.2038e+03\n",
      "Epoch 9550, Training-Loss 6.5621e+04, Data-loss 1.3845e+04                  , pde-loss 1.6336e+03, initc-loss 4.6168e+04                    bc_loss 3.9747e+03\n",
      "Epoch 9560, Training-Loss 6.5095e+04, Data-loss 1.3152e+04                  , pde-loss 1.7197e+03, initc-loss 4.4856e+04                    bc_loss 5.3676e+03\n",
      "Epoch 9570, Training-Loss 6.5696e+04, Data-loss 1.5726e+04                  , pde-loss 1.4100e+03, initc-loss 4.3794e+04                    bc_loss 4.7657e+03\n",
      "Epoch 9580, Training-Loss 6.8597e+04, Data-loss 1.1057e+04                  , pde-loss 2.0681e+03, initc-loss 4.2297e+04                    bc_loss 1.3175e+04\n",
      "Epoch 9590, Training-Loss 6.4222e+04, Data-loss 1.1375e+04                  , pde-loss 1.9203e+03, initc-loss 4.4015e+04                    bc_loss 6.9117e+03\n",
      "Epoch 9600, Training-Loss 6.8358e+04, Data-loss 1.2870e+04                  , pde-loss 1.7816e+03, initc-loss 4.3376e+04                    bc_loss 1.0330e+04\n",
      "Epoch 9610, Training-Loss 6.4972e+04, Data-loss 1.1108e+04                  , pde-loss 1.2242e+03, initc-loss 4.2897e+04                    bc_loss 9.7430e+03\n",
      "Epoch 9620, Training-Loss 7.1552e+04, Data-loss 1.2566e+04                  , pde-loss 1.7374e+03, initc-loss 4.3640e+04                    bc_loss 1.3608e+04\n",
      "Epoch 9630, Training-Loss 7.0716e+04, Data-loss 1.2376e+04                  , pde-loss 1.3297e+03, initc-loss 4.4901e+04                    bc_loss 1.2109e+04\n",
      "Epoch 9640, Training-Loss 6.4298e+04, Data-loss 1.2469e+04                  , pde-loss 2.1403e+03, initc-loss 4.4524e+04                    bc_loss 5.1652e+03\n",
      "Epoch 9650, Training-Loss 6.3164e+04, Data-loss 1.1636e+04                  , pde-loss 1.4505e+03, initc-loss 4.2741e+04                    bc_loss 7.3364e+03\n",
      "Epoch 9660, Training-Loss 6.4284e+04, Data-loss 1.2414e+04                  , pde-loss 1.3778e+03, initc-loss 4.1425e+04                    bc_loss 9.0682e+03\n",
      "Epoch 9670, Training-Loss 6.5501e+04, Data-loss 1.3029e+04                  , pde-loss 2.4433e+03, initc-loss 4.3153e+04                    bc_loss 6.8751e+03\n",
      "Epoch 9680, Training-Loss 6.4836e+04, Data-loss 1.2890e+04                  , pde-loss 8.8500e+02, initc-loss 4.4005e+04                    bc_loss 7.0559e+03\n",
      "Epoch 9690, Training-Loss 6.3763e+04, Data-loss 1.3839e+04                  , pde-loss 3.6816e+03, initc-loss 4.2335e+04                    bc_loss 3.9080e+03\n",
      "Epoch 9700, Training-Loss 6.2925e+04, Data-loss 1.2959e+04                  , pde-loss 1.2028e+03, initc-loss 4.1879e+04                    bc_loss 6.8842e+03\n",
      "Epoch 9710, Training-Loss 6.9747e+04, Data-loss 1.2038e+04                  , pde-loss 1.1738e+03, initc-loss 4.2089e+04                    bc_loss 1.4446e+04\n",
      "Epoch 9720, Training-Loss 7.2939e+04, Data-loss 1.4066e+04                  , pde-loss 2.3448e+03, initc-loss 4.5067e+04                    bc_loss 1.1460e+04\n",
      "Epoch 9730, Training-Loss 6.5834e+04, Data-loss 1.2259e+04                  , pde-loss 2.2495e+03, initc-loss 4.5337e+04                    bc_loss 5.9890e+03\n",
      "Epoch 9740, Training-Loss 6.0373e+04, Data-loss 1.1894e+04                  , pde-loss 1.8460e+03, initc-loss 4.2254e+04                    bc_loss 4.3786e+03\n",
      "Epoch 9750, Training-Loss 6.1399e+04, Data-loss 1.2729e+04                  , pde-loss 1.6794e+03, initc-loss 4.2375e+04                    bc_loss 4.6146e+03\n",
      "Epoch 9760, Training-Loss 5.9919e+04, Data-loss 1.2238e+04                  , pde-loss 2.0183e+03, initc-loss 4.0560e+04                    bc_loss 5.1034e+03\n",
      "Epoch 9770, Training-Loss 6.3373e+04, Data-loss 1.1146e+04                  , pde-loss 1.5337e+03, initc-loss 4.2970e+04                    bc_loss 7.7237e+03\n",
      "Epoch 9780, Training-Loss 5.8446e+04, Data-loss 1.0288e+04                  , pde-loss 1.0895e+03, initc-loss 4.0836e+04                    bc_loss 6.2322e+03\n",
      "Epoch 9790, Training-Loss 5.7107e+04, Data-loss 1.0332e+04                  , pde-loss 1.4021e+03, initc-loss 4.0614e+04                    bc_loss 4.7585e+03\n",
      "Epoch 9800, Training-Loss 6.0873e+04, Data-loss 1.2191e+04                  , pde-loss 1.4952e+03, initc-loss 4.0280e+04                    bc_loss 6.9063e+03\n",
      "Epoch 9810, Training-Loss 6.1933e+04, Data-loss 1.0188e+04                  , pde-loss 1.1455e+03, initc-loss 4.0547e+04                    bc_loss 1.0052e+04\n",
      "Epoch 9820, Training-Loss 5.9241e+04, Data-loss 1.0829e+04                  , pde-loss 1.6476e+03, initc-loss 4.0944e+04                    bc_loss 5.8195e+03\n",
      "Epoch 9830, Training-Loss 5.5624e+04, Data-loss 1.0025e+04                  , pde-loss 1.6407e+03, initc-loss 4.0063e+04                    bc_loss 3.8961e+03\n",
      "Epoch 9840, Training-Loss 5.5938e+04, Data-loss 1.0158e+04                  , pde-loss 2.3351e+03, initc-loss 3.9670e+04                    bc_loss 3.7756e+03\n",
      "Epoch 9850, Training-Loss 5.2898e+04, Data-loss 9.4159e+03                  , pde-loss 1.5330e+03, initc-loss 3.7768e+04                    bc_loss 4.1810e+03\n",
      "Epoch 9860, Training-Loss 5.5630e+04, Data-loss 9.7086e+03                  , pde-loss 1.4818e+03, initc-loss 3.8282e+04                    bc_loss 6.1567e+03\n",
      "Epoch 9870, Training-Loss 5.4811e+04, Data-loss 9.7329e+03                  , pde-loss 1.3577e+03, initc-loss 3.7685e+04                    bc_loss 6.0350e+03\n",
      "Epoch 9880, Training-Loss 6.1098e+04, Data-loss 1.1059e+04                  , pde-loss 1.8712e+03, initc-loss 3.8810e+04                    bc_loss 9.3586e+03\n",
      "Epoch 9890, Training-Loss 6.9731e+04, Data-loss 1.0600e+04                  , pde-loss 2.0655e+03, initc-loss 3.9576e+04                    bc_loss 1.7489e+04\n",
      "Epoch 9900, Training-Loss 6.0841e+04, Data-loss 1.1390e+04                  , pde-loss 1.4551e+03, initc-loss 4.0461e+04                    bc_loss 7.5347e+03\n",
      "Epoch 9910, Training-Loss 6.1915e+04, Data-loss 1.1282e+04                  , pde-loss 2.1190e+03, initc-loss 4.2538e+04                    bc_loss 5.9754e+03\n",
      "Epoch 9920, Training-Loss 6.8213e+04, Data-loss 1.1728e+04                  , pde-loss 1.8692e+03, initc-loss 4.0568e+04                    bc_loss 1.4047e+04\n",
      "Epoch 9930, Training-Loss 6.4238e+04, Data-loss 1.0719e+04                  , pde-loss 1.7133e+03, initc-loss 4.0932e+04                    bc_loss 1.0874e+04\n",
      "Epoch 9940, Training-Loss 5.7670e+04, Data-loss 1.0179e+04                  , pde-loss 1.6404e+03, initc-loss 4.1075e+04                    bc_loss 4.7746e+03\n",
      "Epoch 9950, Training-Loss 5.9652e+04, Data-loss 1.0936e+04                  , pde-loss 1.9452e+03, initc-loss 4.0530e+04                    bc_loss 6.2417e+03\n",
      "Epoch 9960, Training-Loss 5.6915e+04, Data-loss 1.0082e+04                  , pde-loss 1.5542e+03, initc-loss 3.8993e+04                    bc_loss 6.2850e+03\n",
      "Epoch 9970, Training-Loss 6.1965e+04, Data-loss 1.1002e+04                  , pde-loss 1.0828e+03, initc-loss 4.1481e+04                    bc_loss 8.4000e+03\n",
      "Epoch 9980, Training-Loss 8.2996e+04, Data-loss 1.2238e+04                  , pde-loss 2.5315e+03, initc-loss 3.9556e+04                    bc_loss 2.8670e+04\n",
      "Epoch 9990, Training-Loss 6.8521e+04, Data-loss 1.2413e+04                  , pde-loss 2.2658e+03, initc-loss 4.3095e+04                    bc_loss 1.0748e+04\n",
      "Epoch 10000, Training-Loss 6.3733e+04, Data-loss 1.3115e+04                  , pde-loss 1.9833e+03, initc-loss 4.3662e+04                    bc_loss 4.9734e+03\n",
      "Epoch 10010, Training-Loss 5.9941e+04, Data-loss 1.1933e+04                  , pde-loss 2.5243e+03, initc-loss 4.2048e+04                    bc_loss 3.4352e+03\n",
      "Epoch 10020, Training-Loss 6.0651e+04, Data-loss 1.2560e+04                  , pde-loss 1.7344e+03, initc-loss 4.1574e+04                    bc_loss 4.7828e+03\n",
      "Epoch 10030, Training-Loss 5.7609e+04, Data-loss 9.7425e+03                  , pde-loss 1.6435e+03, initc-loss 3.9941e+04                    bc_loss 6.2824e+03\n",
      "Epoch 10040, Training-Loss 6.4000e+04, Data-loss 1.0390e+04                  , pde-loss 1.8218e+03, initc-loss 3.8711e+04                    bc_loss 1.3077e+04\n",
      "Epoch 10050, Training-Loss 6.1331e+04, Data-loss 1.0613e+04                  , pde-loss 1.6007e+03, initc-loss 3.9935e+04                    bc_loss 9.1821e+03\n",
      "Epoch 10060, Training-Loss 6.1068e+04, Data-loss 1.1638e+04                  , pde-loss 1.6995e+03, initc-loss 3.9618e+04                    bc_loss 8.1124e+03\n",
      "Epoch 10070, Training-Loss 6.0490e+04, Data-loss 1.0928e+04                  , pde-loss 1.0300e+03, initc-loss 3.9716e+04                    bc_loss 8.8165e+03\n",
      "Epoch 10080, Training-Loss 6.4257e+04, Data-loss 1.2255e+04                  , pde-loss 1.5412e+03, initc-loss 3.9720e+04                    bc_loss 1.0741e+04\n",
      "Epoch 10090, Training-Loss 6.4677e+04, Data-loss 1.2957e+04                  , pde-loss 2.4350e+03, initc-loss 4.1708e+04                    bc_loss 7.5765e+03\n",
      "Epoch 10100, Training-Loss 5.9275e+04, Data-loss 1.1322e+04                  , pde-loss 1.4820e+03, initc-loss 3.9461e+04                    bc_loss 7.0099e+03\n",
      "Epoch 10110, Training-Loss 5.5814e+04, Data-loss 1.0523e+04                  , pde-loss 2.1462e+03, initc-loss 3.8583e+04                    bc_loss 4.5622e+03\n",
      "Epoch 10120, Training-Loss 5.4523e+04, Data-loss 9.4806e+03                  , pde-loss 1.2204e+03, initc-loss 3.9761e+04                    bc_loss 4.0610e+03\n",
      "Epoch 10130, Training-Loss 5.4890e+04, Data-loss 9.9430e+03                  , pde-loss 1.1892e+03, initc-loss 3.8341e+04                    bc_loss 5.4159e+03\n",
      "Epoch 10140, Training-Loss 5.8174e+04, Data-loss 8.6331e+03                  , pde-loss 2.4126e+03, initc-loss 3.8317e+04                    bc_loss 8.8109e+03\n",
      "Epoch 10150, Training-Loss 6.1287e+04, Data-loss 1.1983e+04                  , pde-loss 2.3318e+03, initc-loss 3.9448e+04                    bc_loss 7.5251e+03\n",
      "Epoch 10160, Training-Loss 6.3699e+04, Data-loss 9.5229e+03                  , pde-loss 1.4549e+03, initc-loss 3.8761e+04                    bc_loss 1.3960e+04\n",
      "Epoch 10170, Training-Loss 6.6067e+04, Data-loss 1.1704e+04                  , pde-loss 1.8551e+03, initc-loss 4.1369e+04                    bc_loss 1.1139e+04\n",
      "Epoch 10180, Training-Loss 6.2223e+04, Data-loss 1.1916e+04                  , pde-loss 1.9794e+03, initc-loss 4.3095e+04                    bc_loss 5.2325e+03\n",
      "Epoch 10190, Training-Loss 6.0995e+04, Data-loss 1.0411e+04                  , pde-loss 1.9156e+03, initc-loss 4.1574e+04                    bc_loss 7.0941e+03\n",
      "Epoch 10200, Training-Loss 6.2144e+04, Data-loss 1.0525e+04                  , pde-loss 1.7633e+03, initc-loss 4.1155e+04                    bc_loss 8.7002e+03\n",
      "Epoch 10210, Training-Loss 5.6228e+04, Data-loss 1.0786e+04                  , pde-loss 1.5533e+03, initc-loss 3.8632e+04                    bc_loss 5.2563e+03\n",
      "Epoch 10220, Training-Loss 5.5909e+04, Data-loss 1.0169e+04                  , pde-loss 1.4848e+03, initc-loss 3.8221e+04                    bc_loss 6.0340e+03\n",
      "Epoch 10230, Training-Loss 6.7176e+04, Data-loss 9.4763e+03                  , pde-loss 1.1461e+03, initc-loss 3.8823e+04                    bc_loss 1.7731e+04\n",
      "Epoch 10240, Training-Loss 8.5409e+04, Data-loss 9.9724e+03                  , pde-loss 1.0053e+03, initc-loss 4.2190e+04                    bc_loss 3.2241e+04\n",
      "Epoch 10250, Training-Loss 7.1316e+04, Data-loss 1.2661e+04                  , pde-loss 1.5544e+03, initc-loss 4.5139e+04                    bc_loss 1.1962e+04\n",
      "Epoch 10260, Training-Loss 7.1982e+04, Data-loss 1.4149e+04                  , pde-loss 2.2463e+03, initc-loss 4.6245e+04                    bc_loss 9.3416e+03\n",
      "Epoch 10270, Training-Loss 6.1931e+04, Data-loss 1.1050e+04                  , pde-loss 1.2384e+03, initc-loss 4.3404e+04                    bc_loss 6.2393e+03\n",
      "Epoch 10280, Training-Loss 5.8656e+04, Data-loss 1.1825e+04                  , pde-loss 2.6137e+03, initc-loss 3.9877e+04                    bc_loss 4.3405e+03\n",
      "Epoch 10290, Training-Loss 6.1439e+04, Data-loss 9.2460e+03                  , pde-loss 1.2323e+03, initc-loss 3.7850e+04                    bc_loss 1.3111e+04\n",
      "Epoch 10300, Training-Loss 5.8285e+04, Data-loss 1.0284e+04                  , pde-loss 1.9481e+03, initc-loss 3.8335e+04                    bc_loss 7.7173e+03\n",
      "Epoch 10310, Training-Loss 5.8094e+04, Data-loss 1.1387e+04                  , pde-loss 1.7144e+03, initc-loss 3.8290e+04                    bc_loss 6.7027e+03\n",
      "Epoch 10320, Training-Loss 6.0596e+04, Data-loss 9.4471e+03                  , pde-loss 1.7535e+03, initc-loss 3.7676e+04                    bc_loss 1.1720e+04\n",
      "Epoch 10330, Training-Loss 5.5828e+04, Data-loss 1.0471e+04                  , pde-loss 1.1278e+03, initc-loss 3.7852e+04                    bc_loss 6.3764e+03\n",
      "Epoch 10340, Training-Loss 6.0828e+04, Data-loss 1.3107e+04                  , pde-loss 1.7822e+03, initc-loss 3.8498e+04                    bc_loss 7.4404e+03\n",
      "Epoch 10350, Training-Loss 6.0391e+04, Data-loss 1.0851e+04                  , pde-loss 1.1620e+03, initc-loss 3.9281e+04                    bc_loss 9.0961e+03\n",
      "Epoch 10360, Training-Loss 6.1911e+04, Data-loss 1.0742e+04                  , pde-loss 3.0666e+03, initc-loss 3.8914e+04                    bc_loss 9.1879e+03\n",
      "Epoch 10370, Training-Loss 5.6872e+04, Data-loss 1.0271e+04                  , pde-loss 1.7907e+03, initc-loss 3.8299e+04                    bc_loss 6.5104e+03\n",
      "Epoch 10380, Training-Loss 6.8335e+04, Data-loss 1.0663e+04                  , pde-loss 1.0121e+03, initc-loss 3.7165e+04                    bc_loss 1.9495e+04\n",
      "Epoch 10390, Training-Loss 6.0326e+04, Data-loss 1.1536e+04                  , pde-loss 1.9186e+03, initc-loss 3.9171e+04                    bc_loss 7.7005e+03\n",
      "Epoch 10400, Training-Loss 7.6970e+04, Data-loss 1.1887e+04                  , pde-loss 1.4318e+03, initc-loss 4.0374e+04                    bc_loss 2.3276e+04\n",
      "Epoch 10410, Training-Loss 6.0487e+04, Data-loss 1.1532e+04                  , pde-loss 1.5140e+03, initc-loss 4.2074e+04                    bc_loss 5.3674e+03\n",
      "Epoch 10420, Training-Loss 6.0166e+04, Data-loss 1.1219e+04                  , pde-loss 1.6014e+03, initc-loss 4.0158e+04                    bc_loss 7.1866e+03\n",
      "Epoch 10430, Training-Loss 5.8121e+04, Data-loss 1.1228e+04                  , pde-loss 1.2482e+03, initc-loss 3.9224e+04                    bc_loss 6.4206e+03\n",
      "Epoch 10440, Training-Loss 5.6040e+04, Data-loss 9.1967e+03                  , pde-loss 1.6590e+03, initc-loss 3.8523e+04                    bc_loss 6.6615e+03\n",
      "Epoch 10450, Training-Loss 5.6700e+04, Data-loss 9.9121e+03                  , pde-loss 1.9599e+03, initc-loss 3.7488e+04                    bc_loss 7.3406e+03\n",
      "Epoch 10460, Training-Loss 7.9396e+04, Data-loss 1.1827e+04                  , pde-loss 1.6845e+03, initc-loss 3.8812e+04                    bc_loss 2.7072e+04\n",
      "Epoch 10470, Training-Loss 7.7480e+04, Data-loss 1.4794e+04                  , pde-loss 2.6148e+03, initc-loss 4.2456e+04                    bc_loss 1.7615e+04\n",
      "Epoch 10480, Training-Loss 6.9368e+04, Data-loss 1.6186e+04                  , pde-loss 2.2337e+03, initc-loss 4.2780e+04                    bc_loss 8.1681e+03\n",
      "Epoch 10490, Training-Loss 6.1839e+04, Data-loss 1.2951e+04                  , pde-loss 1.4310e+03, initc-loss 4.3734e+04                    bc_loss 3.7232e+03\n",
      "Epoch 10500, Training-Loss 5.7994e+04, Data-loss 9.7232e+03                  , pde-loss 2.5641e+03, initc-loss 4.0775e+04                    bc_loss 4.9309e+03\n",
      "Epoch 10510, Training-Loss 5.7286e+04, Data-loss 1.2185e+04                  , pde-loss 2.2917e+03, initc-loss 3.8287e+04                    bc_loss 4.5226e+03\n",
      "Epoch 10520, Training-Loss 5.6009e+04, Data-loss 9.3725e+03                  , pde-loss 1.6177e+03, initc-loss 3.8696e+04                    bc_loss 6.3229e+03\n",
      "Epoch 10530, Training-Loss 5.7270e+04, Data-loss 1.0881e+04                  , pde-loss 1.3894e+03, initc-loss 3.8035e+04                    bc_loss 6.9639e+03\n",
      "Epoch 10540, Training-Loss 6.1598e+04, Data-loss 9.9062e+03                  , pde-loss 1.1200e+03, initc-loss 3.6937e+04                    bc_loss 1.3635e+04\n",
      "Epoch 10550, Training-Loss 6.6783e+04, Data-loss 1.0408e+04                  , pde-loss 1.1842e+03, initc-loss 3.8045e+04                    bc_loss 1.7145e+04\n",
      "Epoch 10560, Training-Loss 6.3720e+04, Data-loss 9.5620e+03                  , pde-loss 1.9140e+03, initc-loss 3.9036e+04                    bc_loss 1.3208e+04\n",
      "Epoch 10570, Training-Loss 5.7785e+04, Data-loss 1.0811e+04                  , pde-loss 1.7810e+03, initc-loss 4.0028e+04                    bc_loss 5.1652e+03\n",
      "Epoch 10580, Training-Loss 5.4657e+04, Data-loss 9.7462e+03                  , pde-loss 1.5756e+03, initc-loss 3.8191e+04                    bc_loss 5.1449e+03\n",
      "Epoch 10590, Training-Loss 5.2713e+04, Data-loss 9.6107e+03                  , pde-loss 1.3249e+03, initc-loss 3.7042e+04                    bc_loss 4.7357e+03\n",
      "Epoch 10600, Training-Loss 5.8277e+04, Data-loss 1.0561e+04                  , pde-loss 1.6901e+03, initc-loss 3.7761e+04                    bc_loss 8.2649e+03\n",
      "Epoch 10610, Training-Loss 5.7361e+04, Data-loss 9.7366e+03                  , pde-loss 1.2140e+03, initc-loss 3.7270e+04                    bc_loss 9.1414e+03\n",
      "Epoch 10620, Training-Loss 6.0244e+04, Data-loss 1.1706e+04                  , pde-loss 3.9758e+03, initc-loss 3.9593e+04                    bc_loss 4.9698e+03\n",
      "Epoch 10630, Training-Loss 5.8873e+04, Data-loss 1.0944e+04                  , pde-loss 1.5444e+03, initc-loss 4.0452e+04                    bc_loss 5.9324e+03\n",
      "Epoch 10640, Training-Loss 5.6951e+04, Data-loss 1.1363e+04                  , pde-loss 2.3811e+03, initc-loss 3.8214e+04                    bc_loss 4.9921e+03\n",
      "Epoch 10650, Training-Loss 5.2740e+04, Data-loss 8.0660e+03                  , pde-loss 1.3896e+03, initc-loss 3.6538e+04                    bc_loss 6.7467e+03\n",
      "Epoch 10660, Training-Loss 5.8131e+04, Data-loss 8.9045e+03                  , pde-loss 2.9792e+03, initc-loss 3.7713e+04                    bc_loss 8.5336e+03\n",
      "Epoch 10670, Training-Loss 5.4928e+04, Data-loss 9.7566e+03                  , pde-loss 1.2669e+03, initc-loss 3.7139e+04                    bc_loss 6.7663e+03\n",
      "Epoch 10680, Training-Loss 5.6333e+04, Data-loss 9.3735e+03                  , pde-loss 1.2476e+03, initc-loss 3.9095e+04                    bc_loss 6.6163e+03\n",
      "Epoch 10690, Training-Loss 5.7639e+04, Data-loss 1.1252e+04                  , pde-loss 1.5169e+03, initc-loss 3.7426e+04                    bc_loss 7.4444e+03\n",
      "Epoch 10700, Training-Loss 5.8792e+04, Data-loss 9.8926e+03                  , pde-loss 1.5550e+03, initc-loss 3.7533e+04                    bc_loss 9.8113e+03\n",
      "Epoch 10710, Training-Loss 5.8260e+04, Data-loss 1.0201e+04                  , pde-loss 1.6313e+03, initc-loss 3.9881e+04                    bc_loss 6.5469e+03\n",
      "Epoch 10720, Training-Loss 5.3061e+04, Data-loss 8.6292e+03                  , pde-loss 1.1994e+03, initc-loss 3.8909e+04                    bc_loss 4.3236e+03\n",
      "Epoch 10730, Training-Loss 5.3819e+04, Data-loss 9.7440e+03                  , pde-loss 1.4250e+03, initc-loss 3.7444e+04                    bc_loss 5.2055e+03\n",
      "Epoch 10740, Training-Loss 5.4718e+04, Data-loss 9.5530e+03                  , pde-loss 2.0382e+03, initc-loss 3.5774e+04                    bc_loss 7.3523e+03\n",
      "Epoch 10750, Training-Loss 5.1891e+04, Data-loss 8.4303e+03                  , pde-loss 1.1772e+03, initc-loss 3.7359e+04                    bc_loss 4.9240e+03\n",
      "Epoch 10760, Training-Loss 5.6178e+04, Data-loss 1.1272e+04                  , pde-loss 1.6209e+03, initc-loss 3.7837e+04                    bc_loss 5.4479e+03\n",
      "Epoch 10770, Training-Loss 5.4723e+04, Data-loss 1.0652e+04                  , pde-loss 1.5055e+03, initc-loss 3.6980e+04                    bc_loss 5.5858e+03\n",
      "Epoch 10780, Training-Loss 5.4655e+04, Data-loss 8.6578e+03                  , pde-loss 1.4264e+03, initc-loss 3.8660e+04                    bc_loss 5.9110e+03\n",
      "Epoch 10790, Training-Loss 5.4322e+04, Data-loss 1.1394e+04                  , pde-loss 1.9206e+03, initc-loss 3.7017e+04                    bc_loss 3.9900e+03\n",
      "Epoch 10800, Training-Loss 5.6409e+04, Data-loss 9.4022e+03                  , pde-loss 1.9273e+03, initc-loss 3.6923e+04                    bc_loss 8.1562e+03\n",
      "Epoch 10810, Training-Loss 5.1926e+04, Data-loss 8.4168e+03                  , pde-loss 1.5140e+03, initc-loss 3.8581e+04                    bc_loss 3.4148e+03\n",
      "Epoch 10820, Training-Loss 4.9199e+04, Data-loss 7.8917e+03                  , pde-loss 1.7889e+03, initc-loss 3.5251e+04                    bc_loss 4.2672e+03\n",
      "Epoch 10830, Training-Loss 5.6271e+04, Data-loss 8.2549e+03                  , pde-loss 1.4813e+03, initc-loss 3.5696e+04                    bc_loss 1.0839e+04\n",
      "Epoch 10840, Training-Loss 5.6782e+04, Data-loss 8.7806e+03                  , pde-loss 1.8813e+03, initc-loss 3.6902e+04                    bc_loss 9.2183e+03\n",
      "Epoch 10850, Training-Loss 5.5449e+04, Data-loss 1.0654e+04                  , pde-loss 2.5553e+03, initc-loss 3.7559e+04                    bc_loss 4.6799e+03\n",
      "Epoch 10860, Training-Loss 5.2728e+04, Data-loss 9.1494e+03                  , pde-loss 1.7268e+03, initc-loss 3.7409e+04                    bc_loss 4.4424e+03\n",
      "Epoch 10870, Training-Loss 5.0572e+04, Data-loss 7.3845e+03                  , pde-loss 1.3193e+03, initc-loss 3.7069e+04                    bc_loss 4.7989e+03\n",
      "Epoch 10880, Training-Loss 5.0391e+04, Data-loss 7.9574e+03                  , pde-loss 1.9941e+03, initc-loss 3.5709e+04                    bc_loss 4.7300e+03\n",
      "Epoch 10890, Training-Loss 5.2728e+04, Data-loss 9.3662e+03                  , pde-loss 2.7922e+03, initc-loss 3.6319e+04                    bc_loss 4.2505e+03\n",
      "Epoch 10900, Training-Loss 5.4676e+04, Data-loss 8.0530e+03                  , pde-loss 1.3075e+03, initc-loss 3.6735e+04                    bc_loss 8.5809e+03\n",
      "Epoch 10910, Training-Loss 5.7505e+04, Data-loss 9.3027e+03                  , pde-loss 1.7520e+03, initc-loss 3.8153e+04                    bc_loss 8.2974e+03\n",
      "Epoch 10920, Training-Loss 5.4244e+04, Data-loss 9.5392e+03                  , pde-loss 1.3255e+03, initc-loss 3.7813e+04                    bc_loss 5.5663e+03\n",
      "Epoch 10930, Training-Loss 5.2265e+04, Data-loss 1.0253e+04                  , pde-loss 1.3414e+03, initc-loss 3.7451e+04                    bc_loss 3.2191e+03\n",
      "Epoch 10940, Training-Loss 5.3331e+04, Data-loss 9.0184e+03                  , pde-loss 1.9793e+03, initc-loss 3.6504e+04                    bc_loss 5.8292e+03\n",
      "Epoch 10950, Training-Loss 6.1415e+04, Data-loss 9.4579e+03                  , pde-loss 2.1310e+03, initc-loss 3.5567e+04                    bc_loss 1.4259e+04\n",
      "Epoch 10960, Training-Loss 5.8684e+04, Data-loss 9.9775e+03                  , pde-loss 2.6182e+03, initc-loss 3.8157e+04                    bc_loss 7.9315e+03\n",
      "Epoch 10970, Training-Loss 5.8860e+04, Data-loss 8.6226e+03                  , pde-loss 1.4622e+03, initc-loss 3.8105e+04                    bc_loss 1.0670e+04\n",
      "Epoch 10980, Training-Loss 6.3737e+04, Data-loss 1.0586e+04                  , pde-loss 1.9640e+03, initc-loss 3.6540e+04                    bc_loss 1.4647e+04\n",
      "Epoch 10990, Training-Loss 5.9333e+04, Data-loss 9.9238e+03                  , pde-loss 2.0907e+03, initc-loss 3.6997e+04                    bc_loss 1.0321e+04\n",
      "Epoch 11000, Training-Loss 5.7310e+04, Data-loss 1.0522e+04                  , pde-loss 8.8042e+02, initc-loss 3.8595e+04                    bc_loss 7.3120e+03\n",
      "Epoch 11010, Training-Loss 5.3251e+04, Data-loss 1.0038e+04                  , pde-loss 1.4573e+03, initc-loss 3.7842e+04                    bc_loss 3.9137e+03\n",
      "Epoch 11020, Training-Loss 5.0116e+04, Data-loss 7.6195e+03                  , pde-loss 1.4044e+03, initc-loss 3.6702e+04                    bc_loss 4.3905e+03\n",
      "Epoch 11030, Training-Loss 5.1816e+04, Data-loss 9.0143e+03                  , pde-loss 1.4735e+03, initc-loss 3.6819e+04                    bc_loss 4.5095e+03\n",
      "Epoch 11040, Training-Loss 5.5877e+04, Data-loss 8.9981e+03                  , pde-loss 1.8990e+03, initc-loss 3.5386e+04                    bc_loss 9.5937e+03\n",
      "Epoch 11050, Training-Loss 5.6930e+04, Data-loss 9.4316e+03                  , pde-loss 1.3920e+03, initc-loss 3.5788e+04                    bc_loss 1.0319e+04\n",
      "Epoch 11060, Training-Loss 5.3891e+04, Data-loss 8.4592e+03                  , pde-loss 1.8820e+03, initc-loss 3.7094e+04                    bc_loss 6.4560e+03\n",
      "Epoch 11070, Training-Loss 5.4637e+04, Data-loss 9.9140e+03                  , pde-loss 2.3067e+03, initc-loss 3.6725e+04                    bc_loss 5.6912e+03\n",
      "Epoch 11080, Training-Loss 6.0507e+04, Data-loss 8.8672e+03                  , pde-loss 2.3116e+03, initc-loss 3.6199e+04                    bc_loss 1.3129e+04\n",
      "Epoch 11090, Training-Loss 5.2847e+04, Data-loss 9.1366e+03                  , pde-loss 1.5719e+03, initc-loss 3.7558e+04                    bc_loss 4.5798e+03\n",
      "Epoch 11100, Training-Loss 5.7800e+04, Data-loss 8.7743e+03                  , pde-loss 2.1433e+03, initc-loss 3.6161e+04                    bc_loss 1.0722e+04\n",
      "Epoch 11110, Training-Loss 5.3548e+04, Data-loss 8.9455e+03                  , pde-loss 1.2378e+03, initc-loss 3.7714e+04                    bc_loss 5.6515e+03\n",
      "Epoch 11120, Training-Loss 6.7924e+04, Data-loss 1.0482e+04                  , pde-loss 3.0816e+03, initc-loss 3.8654e+04                    bc_loss 1.5706e+04\n",
      "Epoch 11130, Training-Loss 5.7786e+04, Data-loss 1.1309e+04                  , pde-loss 1.9149e+03, initc-loss 3.8406e+04                    bc_loss 6.1556e+03\n",
      "Epoch 11140, Training-Loss 5.2307e+04, Data-loss 9.3557e+03                  , pde-loss 1.3445e+03, initc-loss 3.7944e+04                    bc_loss 3.6623e+03\n",
      "Epoch 11150, Training-Loss 5.2249e+04, Data-loss 1.0442e+04                  , pde-loss 1.8036e+03, initc-loss 3.5866e+04                    bc_loss 4.1363e+03\n",
      "Epoch 11160, Training-Loss 5.1048e+04, Data-loss 9.2498e+03                  , pde-loss 2.5892e+03, initc-loss 3.5413e+04                    bc_loss 3.7966e+03\n",
      "Epoch 11170, Training-Loss 5.7463e+04, Data-loss 9.9409e+03                  , pde-loss 1.9541e+03, initc-loss 3.4263e+04                    bc_loss 1.1305e+04\n",
      "Epoch 11180, Training-Loss 4.9245e+04, Data-loss 7.9133e+03                  , pde-loss 1.5087e+03, initc-loss 3.4836e+04                    bc_loss 4.9874e+03\n",
      "Epoch 11190, Training-Loss 5.3653e+04, Data-loss 8.9715e+03                  , pde-loss 1.6896e+03, initc-loss 3.5120e+04                    bc_loss 7.8721e+03\n",
      "Epoch 11200, Training-Loss 5.7625e+04, Data-loss 8.1484e+03                  , pde-loss 1.8350e+03, initc-loss 3.4945e+04                    bc_loss 1.2697e+04\n",
      "Epoch 11210, Training-Loss 5.8804e+04, Data-loss 8.6935e+03                  , pde-loss 1.7281e+03, initc-loss 3.5170e+04                    bc_loss 1.3213e+04\n",
      "Epoch 11220, Training-Loss 5.6831e+04, Data-loss 9.3947e+03                  , pde-loss 2.2314e+03, initc-loss 3.6110e+04                    bc_loss 9.0952e+03\n",
      "Epoch 11230, Training-Loss 5.7150e+04, Data-loss 1.0229e+04                  , pde-loss 2.1092e+03, initc-loss 3.6578e+04                    bc_loss 8.2336e+03\n",
      "Epoch 11240, Training-Loss 5.5603e+04, Data-loss 8.2476e+03                  , pde-loss 1.4724e+03, initc-loss 3.8376e+04                    bc_loss 7.5067e+03\n",
      "Epoch 11250, Training-Loss 5.0823e+04, Data-loss 9.0482e+03                  , pde-loss 2.4806e+03, initc-loss 3.4685e+04                    bc_loss 4.6092e+03\n",
      "Epoch 11260, Training-Loss 5.7072e+04, Data-loss 8.0882e+03                  , pde-loss 1.7575e+03, initc-loss 3.5738e+04                    bc_loss 1.1488e+04\n",
      "Epoch 11270, Training-Loss 5.2175e+04, Data-loss 8.8157e+03                  , pde-loss 2.4251e+03, initc-loss 3.5382e+04                    bc_loss 5.5520e+03\n",
      "Epoch 11280, Training-Loss 5.9624e+04, Data-loss 8.2618e+03                  , pde-loss 2.0954e+03, initc-loss 3.4319e+04                    bc_loss 1.4948e+04\n",
      "Epoch 11290, Training-Loss 5.8978e+04, Data-loss 8.1342e+03                  , pde-loss 1.2738e+03, initc-loss 3.5635e+04                    bc_loss 1.3935e+04\n",
      "Epoch 11300, Training-Loss 5.1936e+04, Data-loss 9.5435e+03                  , pde-loss 1.5619e+03, initc-loss 3.5962e+04                    bc_loss 4.8686e+03\n",
      "Epoch 11310, Training-Loss 5.0441e+04, Data-loss 7.7660e+03                  , pde-loss 1.7010e+03, initc-loss 3.4755e+04                    bc_loss 6.2187e+03\n",
      "Epoch 11320, Training-Loss 5.1222e+04, Data-loss 8.8076e+03                  , pde-loss 2.3121e+03, initc-loss 3.4718e+04                    bc_loss 5.3846e+03\n",
      "Epoch 11330, Training-Loss 5.0740e+04, Data-loss 8.1423e+03                  , pde-loss 2.7037e+03, initc-loss 3.4264e+04                    bc_loss 5.6304e+03\n",
      "Epoch 11340, Training-Loss 4.9716e+04, Data-loss 8.7221e+03                  , pde-loss 1.7089e+03, initc-loss 3.3822e+04                    bc_loss 5.4626e+03\n",
      "Epoch 11350, Training-Loss 4.7862e+04, Data-loss 7.4738e+03                  , pde-loss 1.1389e+03, initc-loss 3.3569e+04                    bc_loss 5.6804e+03\n",
      "Epoch 11360, Training-Loss 5.2144e+04, Data-loss 7.1453e+03                  , pde-loss 1.4459e+03, initc-loss 3.3588e+04                    bc_loss 9.9651e+03\n",
      "Epoch 11370, Training-Loss 5.4496e+04, Data-loss 8.3235e+03                  , pde-loss 1.3315e+03, initc-loss 3.4162e+04                    bc_loss 1.0678e+04\n",
      "Epoch 11380, Training-Loss 6.0572e+04, Data-loss 8.2004e+03                  , pde-loss 1.3154e+03, initc-loss 3.4526e+04                    bc_loss 1.6530e+04\n",
      "Epoch 11390, Training-Loss 5.7852e+04, Data-loss 9.1396e+03                  , pde-loss 1.8391e+03, initc-loss 3.6392e+04                    bc_loss 1.0482e+04\n",
      "Epoch 11400, Training-Loss 5.3922e+04, Data-loss 8.6967e+03                  , pde-loss 2.5159e+03, initc-loss 3.6033e+04                    bc_loss 6.6768e+03\n",
      "Epoch 11410, Training-Loss 5.6025e+04, Data-loss 9.5003e+03                  , pde-loss 1.1970e+03, initc-loss 3.5110e+04                    bc_loss 1.0218e+04\n",
      "Epoch 11420, Training-Loss 5.5409e+04, Data-loss 7.9619e+03                  , pde-loss 1.4344e+03, initc-loss 3.5947e+04                    bc_loss 1.0066e+04\n",
      "Epoch 11430, Training-Loss 5.2017e+04, Data-loss 9.8778e+03                  , pde-loss 2.7587e+03, initc-loss 3.4366e+04                    bc_loss 5.0146e+03\n",
      "Epoch 11440, Training-Loss 4.8749e+04, Data-loss 8.4701e+03                  , pde-loss 1.5812e+03, initc-loss 3.4350e+04                    bc_loss 4.3474e+03\n",
      "Epoch 11450, Training-Loss 5.3451e+04, Data-loss 8.0033e+03                  , pde-loss 1.2526e+03, initc-loss 3.3053e+04                    bc_loss 1.1142e+04\n",
      "Epoch 11460, Training-Loss 5.9193e+04, Data-loss 8.2962e+03                  , pde-loss 1.8763e+03, initc-loss 3.5896e+04                    bc_loss 1.3125e+04\n",
      "Epoch 11470, Training-Loss 5.5958e+04, Data-loss 8.4872e+03                  , pde-loss 1.2731e+03, initc-loss 3.5838e+04                    bc_loss 1.0360e+04\n",
      "Epoch 11480, Training-Loss 5.6312e+04, Data-loss 1.0706e+04                  , pde-loss 1.4490e+03, initc-loss 3.8523e+04                    bc_loss 5.6348e+03\n",
      "Epoch 11490, Training-Loss 4.9073e+04, Data-loss 8.4464e+03                  , pde-loss 9.8737e+02, initc-loss 3.5703e+04                    bc_loss 3.9362e+03\n",
      "Epoch 11500, Training-Loss 4.8499e+04, Data-loss 7.6951e+03                  , pde-loss 1.0578e+03, initc-loss 3.4466e+04                    bc_loss 5.2793e+03\n",
      "Epoch 11510, Training-Loss 4.7157e+04, Data-loss 7.0705e+03                  , pde-loss 1.3347e+03, initc-loss 3.3034e+04                    bc_loss 5.7172e+03\n",
      "Epoch 11520, Training-Loss 4.9114e+04, Data-loss 7.4508e+03                  , pde-loss 9.9258e+02, initc-loss 3.3022e+04                    bc_loss 7.6480e+03\n",
      "Epoch 11530, Training-Loss 5.3332e+04, Data-loss 9.1659e+03                  , pde-loss 1.1626e+03, initc-loss 3.4759e+04                    bc_loss 8.2451e+03\n",
      "Epoch 11540, Training-Loss 4.9326e+04, Data-loss 8.1083e+03                  , pde-loss 1.3411e+03, initc-loss 3.3999e+04                    bc_loss 5.8773e+03\n",
      "Epoch 11550, Training-Loss 4.4998e+04, Data-loss 6.5425e+03                  , pde-loss 1.0516e+03, initc-loss 3.2492e+04                    bc_loss 4.9113e+03\n",
      "Epoch 11560, Training-Loss 5.1667e+04, Data-loss 7.6992e+03                  , pde-loss 8.9777e+02, initc-loss 3.3827e+04                    bc_loss 9.2431e+03\n",
      "Epoch 11570, Training-Loss 4.8509e+04, Data-loss 8.6337e+03                  , pde-loss 1.5758e+03, initc-loss 3.3781e+04                    bc_loss 4.5184e+03\n",
      "Epoch 11580, Training-Loss 4.8703e+04, Data-loss 7.2608e+03                  , pde-loss 1.0363e+03, initc-loss 3.2708e+04                    bc_loss 7.6971e+03\n",
      "Epoch 11590, Training-Loss 4.8545e+04, Data-loss 8.0040e+03                  , pde-loss 1.1934e+03, initc-loss 3.3238e+04                    bc_loss 6.1096e+03\n",
      "Epoch 11600, Training-Loss 5.1444e+04, Data-loss 8.1146e+03                  , pde-loss 8.5677e+02, initc-loss 3.3802e+04                    bc_loss 8.6706e+03\n",
      "Epoch 11610, Training-Loss 4.9687e+04, Data-loss 8.4402e+03                  , pde-loss 1.5469e+03, initc-loss 3.2847e+04                    bc_loss 6.8529e+03\n",
      "Epoch 11620, Training-Loss 5.0289e+04, Data-loss 8.6109e+03                  , pde-loss 1.0460e+03, initc-loss 3.4293e+04                    bc_loss 6.3383e+03\n",
      "Epoch 11630, Training-Loss 4.7092e+04, Data-loss 8.0804e+03                  , pde-loss 1.4366e+03, initc-loss 3.3050e+04                    bc_loss 4.5252e+03\n",
      "Epoch 11640, Training-Loss 4.7100e+04, Data-loss 8.0680e+03                  , pde-loss 1.3172e+03, initc-loss 3.2255e+04                    bc_loss 5.4603e+03\n",
      "Epoch 11650, Training-Loss 5.6039e+04, Data-loss 8.1660e+03                  , pde-loss 1.4168e+03, initc-loss 3.4545e+04                    bc_loss 1.1911e+04\n",
      "Epoch 11660, Training-Loss 6.1784e+04, Data-loss 9.1156e+03                  , pde-loss 1.0611e+03, initc-loss 3.6907e+04                    bc_loss 1.4701e+04\n",
      "Epoch 11670, Training-Loss 5.9758e+04, Data-loss 7.8843e+03                  , pde-loss 1.7003e+03, initc-loss 3.8444e+04                    bc_loss 1.1729e+04\n",
      "Epoch 11680, Training-Loss 5.5313e+04, Data-loss 1.0458e+04                  , pde-loss 7.9199e+02, initc-loss 3.7349e+04                    bc_loss 6.7139e+03\n",
      "Epoch 11690, Training-Loss 5.2648e+04, Data-loss 8.7375e+03                  , pde-loss 2.0119e+03, initc-loss 3.6162e+04                    bc_loss 5.7360e+03\n",
      "Epoch 11700, Training-Loss 5.0736e+04, Data-loss 8.2909e+03                  , pde-loss 1.8779e+03, initc-loss 3.4145e+04                    bc_loss 6.4225e+03\n",
      "Epoch 11710, Training-Loss 6.0463e+04, Data-loss 8.4466e+03                  , pde-loss 1.2158e+03, initc-loss 3.4057e+04                    bc_loss 1.6743e+04\n",
      "Epoch 11720, Training-Loss 5.7807e+04, Data-loss 7.6281e+03                  , pde-loss 1.1290e+03, initc-loss 3.5176e+04                    bc_loss 1.3874e+04\n",
      "Epoch 11730, Training-Loss 5.8489e+04, Data-loss 8.6164e+03                  , pde-loss 2.1028e+03, initc-loss 3.7781e+04                    bc_loss 9.9896e+03\n",
      "Epoch 11740, Training-Loss 5.4022e+04, Data-loss 8.9072e+03                  , pde-loss 1.9297e+03, initc-loss 3.4894e+04                    bc_loss 8.2919e+03\n",
      "Epoch 11750, Training-Loss 4.8573e+04, Data-loss 7.4078e+03                  , pde-loss 1.0734e+03, initc-loss 3.4108e+04                    bc_loss 5.9837e+03\n",
      "Epoch 11760, Training-Loss 4.9084e+04, Data-loss 8.1361e+03                  , pde-loss 1.6696e+03, initc-loss 3.3811e+04                    bc_loss 5.4676e+03\n",
      "Epoch 11770, Training-Loss 4.6839e+04, Data-loss 6.8838e+03                  , pde-loss 1.3370e+03, initc-loss 3.3745e+04                    bc_loss 4.8732e+03\n",
      "Epoch 11780, Training-Loss 5.5272e+04, Data-loss 8.4853e+03                  , pde-loss 1.1454e+03, initc-loss 3.2788e+04                    bc_loss 1.2853e+04\n",
      "Epoch 11790, Training-Loss 5.2995e+04, Data-loss 7.3068e+03                  , pde-loss 1.1755e+03, initc-loss 3.3802e+04                    bc_loss 1.0711e+04\n",
      "Epoch 11800, Training-Loss 5.1651e+04, Data-loss 7.4141e+03                  , pde-loss 1.1949e+03, initc-loss 3.4966e+04                    bc_loss 8.0755e+03\n",
      "Epoch 11810, Training-Loss 5.0865e+04, Data-loss 6.4498e+03                  , pde-loss 9.4970e+02, initc-loss 3.3756e+04                    bc_loss 9.7099e+03\n",
      "Epoch 11820, Training-Loss 5.2454e+04, Data-loss 7.7016e+03                  , pde-loss 1.1294e+03, initc-loss 3.3224e+04                    bc_loss 1.0398e+04\n",
      "Epoch 11830, Training-Loss 5.0555e+04, Data-loss 8.3746e+03                  , pde-loss 1.2396e+03, initc-loss 3.4007e+04                    bc_loss 6.9330e+03\n",
      "Epoch 11840, Training-Loss 5.1360e+04, Data-loss 7.2321e+03                  , pde-loss 1.2377e+03, initc-loss 3.3141e+04                    bc_loss 9.7494e+03\n",
      "Epoch 11850, Training-Loss 5.3995e+04, Data-loss 7.7856e+03                  , pde-loss 1.1603e+03, initc-loss 3.2992e+04                    bc_loss 1.2057e+04\n",
      "Epoch 11860, Training-Loss 6.3966e+04, Data-loss 8.2568e+03                  , pde-loss 1.6413e+03, initc-loss 3.4709e+04                    bc_loss 1.9359e+04\n",
      "Epoch 11870, Training-Loss 6.0672e+04, Data-loss 1.0571e+04                  , pde-loss 1.7081e+03, initc-loss 3.8621e+04                    bc_loss 9.7716e+03\n",
      "Epoch 11880, Training-Loss 5.1989e+04, Data-loss 9.2469e+03                  , pde-loss 1.3570e+03, initc-loss 3.5352e+04                    bc_loss 6.0335e+03\n",
      "Epoch 11890, Training-Loss 4.6140e+04, Data-loss 7.6417e+03                  , pde-loss 1.0163e+03, initc-loss 3.3860e+04                    bc_loss 3.6222e+03\n",
      "Epoch 11900, Training-Loss 4.6018e+04, Data-loss 6.6316e+03                  , pde-loss 9.3913e+02, initc-loss 3.4187e+04                    bc_loss 4.2606e+03\n",
      "Epoch 11910, Training-Loss 4.9077e+04, Data-loss 8.0845e+03                  , pde-loss 1.6865e+03, initc-loss 3.3562e+04                    bc_loss 5.7439e+03\n",
      "Epoch 11920, Training-Loss 4.6580e+04, Data-loss 7.3598e+03                  , pde-loss 9.3616e+02, initc-loss 3.3561e+04                    bc_loss 4.7234e+03\n",
      "Epoch 11930, Training-Loss 4.8031e+04, Data-loss 6.8862e+03                  , pde-loss 2.1754e+03, initc-loss 3.1492e+04                    bc_loss 7.4772e+03\n",
      "Epoch 11940, Training-Loss 4.9762e+04, Data-loss 7.8589e+03                  , pde-loss 1.4684e+03, initc-loss 3.2749e+04                    bc_loss 7.6852e+03\n",
      "Epoch 11950, Training-Loss 4.8378e+04, Data-loss 7.3628e+03                  , pde-loss 1.6522e+03, initc-loss 3.2538e+04                    bc_loss 6.8255e+03\n",
      "Epoch 11960, Training-Loss 4.8575e+04, Data-loss 7.9367e+03                  , pde-loss 1.2786e+03, initc-loss 3.3263e+04                    bc_loss 6.0973e+03\n",
      "Epoch 11970, Training-Loss 4.9451e+04, Data-loss 7.3001e+03                  , pde-loss 1.7106e+03, initc-loss 3.3234e+04                    bc_loss 7.2063e+03\n",
      "Epoch 11980, Training-Loss 4.9576e+04, Data-loss 8.4656e+03                  , pde-loss 1.1308e+03, initc-loss 3.3475e+04                    bc_loss 6.5045e+03\n",
      "Epoch 11990, Training-Loss 4.8241e+04, Data-loss 7.4712e+03                  , pde-loss 7.3686e+02, initc-loss 3.5752e+04                    bc_loss 4.2816e+03\n",
      "Epoch 12000, Training-Loss 4.6306e+04, Data-loss 6.1193e+03                  , pde-loss 8.8268e+02, initc-loss 3.3661e+04                    bc_loss 5.6429e+03\n",
      "Epoch 12010, Training-Loss 4.9232e+04, Data-loss 8.2873e+03                  , pde-loss 1.4344e+03, initc-loss 3.2385e+04                    bc_loss 7.1257e+03\n",
      "Epoch 12020, Training-Loss 5.2098e+04, Data-loss 8.9773e+03                  , pde-loss 1.3916e+03, initc-loss 3.2459e+04                    bc_loss 9.2704e+03\n",
      "Epoch 12030, Training-Loss 5.3822e+04, Data-loss 6.7919e+03                  , pde-loss 1.4918e+03, initc-loss 3.2428e+04                    bc_loss 1.3110e+04\n",
      "Epoch 12040, Training-Loss 5.1233e+04, Data-loss 6.9692e+03                  , pde-loss 1.1349e+03, initc-loss 3.2658e+04                    bc_loss 1.0470e+04\n",
      "Epoch 12050, Training-Loss 5.4452e+04, Data-loss 7.1947e+03                  , pde-loss 1.2208e+03, initc-loss 3.3121e+04                    bc_loss 1.2916e+04\n",
      "Epoch 12060, Training-Loss 5.3601e+04, Data-loss 8.5544e+03                  , pde-loss 1.6599e+03, initc-loss 3.3676e+04                    bc_loss 9.7115e+03\n",
      "Epoch 12070, Training-Loss 5.1981e+04, Data-loss 8.6007e+03                  , pde-loss 2.3998e+03, initc-loss 3.4943e+04                    bc_loss 6.0371e+03\n",
      "Epoch 12080, Training-Loss 4.7496e+04, Data-loss 7.4139e+03                  , pde-loss 1.1043e+03, initc-loss 3.4173e+04                    bc_loss 4.8046e+03\n",
      "Epoch 12090, Training-Loss 4.4427e+04, Data-loss 7.1001e+03                  , pde-loss 1.0358e+03, initc-loss 3.1771e+04                    bc_loss 4.5199e+03\n",
      "Epoch 12100, Training-Loss 4.5345e+04, Data-loss 7.8147e+03                  , pde-loss 7.6672e+02, initc-loss 3.2031e+04                    bc_loss 4.7322e+03\n",
      "Epoch 12110, Training-Loss 4.3504e+04, Data-loss 5.9513e+03                  , pde-loss 8.1737e+02, initc-loss 3.1648e+04                    bc_loss 5.0878e+03\n",
      "Epoch 12120, Training-Loss 4.4060e+04, Data-loss 7.3096e+03                  , pde-loss 1.6541e+03, initc-loss 3.1163e+04                    bc_loss 3.9334e+03\n",
      "Epoch 12130, Training-Loss 4.9091e+04, Data-loss 6.7303e+03                  , pde-loss 1.6709e+03, initc-loss 3.3180e+04                    bc_loss 7.5099e+03\n",
      "Epoch 12140, Training-Loss 4.7989e+04, Data-loss 6.7803e+03                  , pde-loss 8.8686e+02, initc-loss 3.1164e+04                    bc_loss 9.1576e+03\n",
      "Epoch 12150, Training-Loss 5.7677e+04, Data-loss 6.8991e+03                  , pde-loss 1.2631e+03, initc-loss 3.1621e+04                    bc_loss 1.7893e+04\n",
      "Epoch 12160, Training-Loss 5.2547e+04, Data-loss 7.3981e+03                  , pde-loss 1.2259e+03, initc-loss 3.3195e+04                    bc_loss 1.0728e+04\n",
      "Epoch 12170, Training-Loss 4.7324e+04, Data-loss 6.7620e+03                  , pde-loss 2.4113e+03, initc-loss 3.3851e+04                    bc_loss 4.2988e+03\n",
      "Epoch 12180, Training-Loss 4.6526e+04, Data-loss 8.1466e+03                  , pde-loss 1.2537e+03, initc-loss 3.2475e+04                    bc_loss 4.6506e+03\n",
      "Epoch 12190, Training-Loss 4.6805e+04, Data-loss 6.5612e+03                  , pde-loss 7.5176e+02, initc-loss 3.2711e+04                    bc_loss 6.7810e+03\n",
      "Epoch 12200, Training-Loss 4.6391e+04, Data-loss 7.5809e+03                  , pde-loss 2.4115e+03, initc-loss 3.1089e+04                    bc_loss 5.3095e+03\n",
      "Epoch 12210, Training-Loss 4.8690e+04, Data-loss 7.0729e+03                  , pde-loss 1.3113e+03, initc-loss 3.1073e+04                    bc_loss 9.2331e+03\n",
      "Epoch 12220, Training-Loss 4.9448e+04, Data-loss 8.6977e+03                  , pde-loss 2.6635e+03, initc-loss 3.1514e+04                    bc_loss 6.5724e+03\n",
      "Epoch 12230, Training-Loss 5.0563e+04, Data-loss 7.1195e+03                  , pde-loss 6.2703e+02, initc-loss 3.2280e+04                    bc_loss 1.0537e+04\n",
      "Epoch 12240, Training-Loss 4.6466e+04, Data-loss 6.3111e+03                  , pde-loss 1.8660e+03, initc-loss 3.3266e+04                    bc_loss 5.0239e+03\n",
      "Epoch 12250, Training-Loss 4.9183e+04, Data-loss 7.7534e+03                  , pde-loss 1.4317e+03, initc-loss 3.2626e+04                    bc_loss 7.3721e+03\n",
      "Epoch 12260, Training-Loss 5.1511e+04, Data-loss 8.5996e+03                  , pde-loss 1.9013e+03, initc-loss 3.1174e+04                    bc_loss 9.8362e+03\n",
      "Epoch 12270, Training-Loss 5.2164e+04, Data-loss 7.4080e+03                  , pde-loss 2.4859e+03, initc-loss 3.1682e+04                    bc_loss 1.0589e+04\n",
      "Epoch 12280, Training-Loss 4.9837e+04, Data-loss 7.3524e+03                  , pde-loss 1.5435e+03, initc-loss 3.2417e+04                    bc_loss 8.5239e+03\n",
      "Epoch 12290, Training-Loss 4.8047e+04, Data-loss 7.0329e+03                  , pde-loss 1.2041e+03, initc-loss 3.2198e+04                    bc_loss 7.6127e+03\n",
      "Epoch 12300, Training-Loss 4.7721e+04, Data-loss 7.1784e+03                  , pde-loss 1.1615e+03, initc-loss 3.2445e+04                    bc_loss 6.9365e+03\n",
      "Epoch 12310, Training-Loss 4.4762e+04, Data-loss 6.5334e+03                  , pde-loss 1.5386e+03, initc-loss 3.1679e+04                    bc_loss 5.0105e+03\n",
      "Epoch 12320, Training-Loss 4.4090e+04, Data-loss 6.4220e+03                  , pde-loss 1.1911e+03, initc-loss 3.1588e+04                    bc_loss 4.8889e+03\n",
      "Epoch 12330, Training-Loss 3.9697e+04, Data-loss 5.5965e+03                  , pde-loss 1.0753e+03, initc-loss 2.9437e+04                    bc_loss 3.5886e+03\n",
      "Epoch 12340, Training-Loss 4.1280e+04, Data-loss 5.4764e+03                  , pde-loss 1.2640e+03, initc-loss 2.8963e+04                    bc_loss 5.5773e+03\n",
      "Epoch 12350, Training-Loss 4.5227e+04, Data-loss 6.4026e+03                  , pde-loss 1.9771e+03, initc-loss 3.0240e+04                    bc_loss 6.6070e+03\n",
      "Epoch 12360, Training-Loss 4.8241e+04, Data-loss 7.5187e+03                  , pde-loss 1.6761e+03, initc-loss 3.0688e+04                    bc_loss 8.3580e+03\n",
      "Epoch 12370, Training-Loss 4.2393e+04, Data-loss 6.5544e+03                  , pde-loss 1.2039e+03, initc-loss 3.0463e+04                    bc_loss 4.1722e+03\n",
      "Epoch 12380, Training-Loss 4.5033e+04, Data-loss 5.3117e+03                  , pde-loss 8.9834e+02, initc-loss 3.0348e+04                    bc_loss 8.4750e+03\n",
      "Epoch 12390, Training-Loss 4.7132e+04, Data-loss 6.4774e+03                  , pde-loss 1.6215e+03, initc-loss 3.1040e+04                    bc_loss 7.9938e+03\n",
      "Epoch 12400, Training-Loss 5.1937e+04, Data-loss 7.3666e+03                  , pde-loss 1.9030e+03, initc-loss 3.3336e+04                    bc_loss 9.3319e+03\n",
      "Epoch 12410, Training-Loss 4.6613e+04, Data-loss 6.0670e+03                  , pde-loss 1.5781e+03, initc-loss 3.2254e+04                    bc_loss 6.7132e+03\n",
      "Epoch 12420, Training-Loss 4.2791e+04, Data-loss 6.7361e+03                  , pde-loss 7.9603e+02, initc-loss 3.0979e+04                    bc_loss 4.2793e+03\n",
      "Epoch 12430, Training-Loss 4.1636e+04, Data-loss 5.8007e+03                  , pde-loss 8.8393e+02, initc-loss 3.0165e+04                    bc_loss 4.7863e+03\n",
      "Epoch 12440, Training-Loss 4.9533e+04, Data-loss 5.4012e+03                  , pde-loss 8.4856e+02, initc-loss 2.9648e+04                    bc_loss 1.3635e+04\n",
      "Epoch 12450, Training-Loss 4.4858e+04, Data-loss 5.6079e+03                  , pde-loss 1.3308e+03, initc-loss 3.0825e+04                    bc_loss 7.0944e+03\n",
      "Epoch 12460, Training-Loss 4.2362e+04, Data-loss 6.0391e+03                  , pde-loss 1.2160e+03, initc-loss 3.0354e+04                    bc_loss 4.7526e+03\n",
      "Epoch 12470, Training-Loss 4.1030e+04, Data-loss 5.4984e+03                  , pde-loss 1.9528e+03, initc-loss 2.9577e+04                    bc_loss 4.0013e+03\n",
      "Epoch 12480, Training-Loss 4.3820e+04, Data-loss 6.2066e+03                  , pde-loss 1.6323e+03, initc-loss 2.8965e+04                    bc_loss 7.0154e+03\n",
      "Epoch 12490, Training-Loss 4.7836e+04, Data-loss 5.9004e+03                  , pde-loss 1.3839e+03, initc-loss 3.2225e+04                    bc_loss 8.3268e+03\n",
      "Epoch 12500, Training-Loss 4.8786e+04, Data-loss 7.9227e+03                  , pde-loss 1.3796e+03, initc-loss 3.3189e+04                    bc_loss 6.2952e+03\n",
      "Epoch 12510, Training-Loss 4.6357e+04, Data-loss 5.7706e+03                  , pde-loss 1.0280e+03, initc-loss 3.3440e+04                    bc_loss 6.1189e+03\n",
      "Epoch 12520, Training-Loss 4.3255e+04, Data-loss 5.7412e+03                  , pde-loss 1.0586e+03, initc-loss 3.0275e+04                    bc_loss 6.1803e+03\n",
      "Epoch 12530, Training-Loss 4.8000e+04, Data-loss 6.0252e+03                  , pde-loss 1.7025e+03, initc-loss 2.9396e+04                    bc_loss 1.0876e+04\n",
      "Epoch 12540, Training-Loss 5.0943e+04, Data-loss 6.9509e+03                  , pde-loss 9.7063e+02, initc-loss 3.1055e+04                    bc_loss 1.1966e+04\n",
      "Epoch 12550, Training-Loss 5.1664e+04, Data-loss 7.4738e+03                  , pde-loss 9.4615e+02, initc-loss 3.4794e+04                    bc_loss 8.4493e+03\n",
      "Epoch 12560, Training-Loss 4.7445e+04, Data-loss 6.5944e+03                  , pde-loss 1.0891e+03, initc-loss 3.3904e+04                    bc_loss 5.8569e+03\n",
      "Epoch 12570, Training-Loss 4.3645e+04, Data-loss 7.0100e+03                  , pde-loss 9.5236e+02, initc-loss 3.0888e+04                    bc_loss 4.7943e+03\n",
      "Epoch 12580, Training-Loss 4.3682e+04, Data-loss 6.7010e+03                  , pde-loss 1.4367e+03, initc-loss 3.0334e+04                    bc_loss 5.2097e+03\n",
      "Epoch 12590, Training-Loss 4.7205e+04, Data-loss 7.1176e+03                  , pde-loss 1.2825e+03, initc-loss 3.1024e+04                    bc_loss 7.7813e+03\n",
      "Epoch 12600, Training-Loss 4.9164e+04, Data-loss 6.0963e+03                  , pde-loss 1.0630e+03, initc-loss 3.1369e+04                    bc_loss 1.0637e+04\n",
      "Epoch 12610, Training-Loss 4.6991e+04, Data-loss 7.0910e+03                  , pde-loss 1.6824e+03, initc-loss 3.1629e+04                    bc_loss 6.5888e+03\n",
      "Epoch 12620, Training-Loss 4.7234e+04, Data-loss 6.7692e+03                  , pde-loss 8.1964e+02, initc-loss 3.1542e+04                    bc_loss 8.1031e+03\n",
      "Epoch 12630, Training-Loss 4.5614e+04, Data-loss 6.2406e+03                  , pde-loss 7.5171e+02, initc-loss 3.0673e+04                    bc_loss 7.9482e+03\n",
      "Epoch 12640, Training-Loss 4.6617e+04, Data-loss 6.6712e+03                  , pde-loss 1.4478e+03, initc-loss 3.1408e+04                    bc_loss 7.0899e+03\n",
      "Epoch 12650, Training-Loss 4.5916e+04, Data-loss 7.1948e+03                  , pde-loss 1.5794e+03, initc-loss 3.0516e+04                    bc_loss 6.6262e+03\n",
      "Epoch 12660, Training-Loss 5.1078e+04, Data-loss 8.4800e+03                  , pde-loss 1.6757e+03, initc-loss 3.1575e+04                    bc_loss 9.3473e+03\n",
      "Epoch 12670, Training-Loss 4.5742e+04, Data-loss 7.7636e+03                  , pde-loss 1.2097e+03, initc-loss 3.0805e+04                    bc_loss 5.9641e+03\n",
      "Epoch 12680, Training-Loss 4.2253e+04, Data-loss 7.0967e+03                  , pde-loss 9.7352e+02, initc-loss 3.0754e+04                    bc_loss 3.4287e+03\n",
      "Epoch 12690, Training-Loss 4.3665e+04, Data-loss 6.9667e+03                  , pde-loss 9.7285e+02, initc-loss 2.9963e+04                    bc_loss 5.7630e+03\n",
      "Epoch 12700, Training-Loss 5.0149e+04, Data-loss 6.9490e+03                  , pde-loss 9.9917e+02, initc-loss 2.9929e+04                    bc_loss 1.2272e+04\n",
      "Epoch 12710, Training-Loss 4.5952e+04, Data-loss 6.2149e+03                  , pde-loss 9.8445e+02, initc-loss 3.1025e+04                    bc_loss 7.7274e+03\n",
      "Epoch 12720, Training-Loss 4.5744e+04, Data-loss 5.5587e+03                  , pde-loss 9.9553e+02, initc-loss 3.1150e+04                    bc_loss 8.0398e+03\n",
      "Epoch 12730, Training-Loss 4.3991e+04, Data-loss 6.3151e+03                  , pde-loss 1.8272e+03, initc-loss 3.0251e+04                    bc_loss 5.5979e+03\n",
      "Epoch 12740, Training-Loss 4.8994e+04, Data-loss 7.6156e+03                  , pde-loss 1.2010e+03, initc-loss 2.9368e+04                    bc_loss 1.0809e+04\n",
      "Epoch 12750, Training-Loss 4.8521e+04, Data-loss 8.1250e+03                  , pde-loss 1.6012e+03, initc-loss 3.1636e+04                    bc_loss 7.1591e+03\n",
      "Epoch 12760, Training-Loss 4.6417e+04, Data-loss 5.6221e+03                  , pde-loss 8.9678e+02, initc-loss 2.9532e+04                    bc_loss 1.0366e+04\n",
      "Epoch 12770, Training-Loss 5.7462e+04, Data-loss 7.6400e+03                  , pde-loss 1.4457e+03, initc-loss 3.0066e+04                    bc_loss 1.8310e+04\n",
      "Epoch 12780, Training-Loss 5.1742e+04, Data-loss 7.4533e+03                  , pde-loss 1.2554e+03, initc-loss 3.2224e+04                    bc_loss 1.0809e+04\n",
      "Epoch 12790, Training-Loss 5.1287e+04, Data-loss 7.0379e+03                  , pde-loss 1.5723e+03, initc-loss 3.2385e+04                    bc_loss 1.0292e+04\n",
      "Epoch 12800, Training-Loss 4.9854e+04, Data-loss 6.9063e+03                  , pde-loss 1.1709e+03, initc-loss 3.1013e+04                    bc_loss 1.0765e+04\n",
      "Epoch 12810, Training-Loss 4.9492e+04, Data-loss 7.1236e+03                  , pde-loss 1.1487e+03, initc-loss 3.2371e+04                    bc_loss 8.8497e+03\n",
      "Epoch 12820, Training-Loss 4.7631e+04, Data-loss 6.6235e+03                  , pde-loss 1.7937e+03, initc-loss 3.0804e+04                    bc_loss 8.4095e+03\n",
      "Epoch 12830, Training-Loss 4.6332e+04, Data-loss 7.0718e+03                  , pde-loss 1.6661e+03, initc-loss 3.0389e+04                    bc_loss 7.2046e+03\n",
      "Epoch 12840, Training-Loss 4.5506e+04, Data-loss 6.2388e+03                  , pde-loss 6.3363e+02, initc-loss 3.2143e+04                    bc_loss 6.4902e+03\n",
      "Epoch 12850, Training-Loss 4.1156e+04, Data-loss 6.1415e+03                  , pde-loss 1.0273e+03, initc-loss 2.8863e+04                    bc_loss 5.1240e+03\n",
      "Epoch 12860, Training-Loss 4.1600e+04, Data-loss 6.4545e+03                  , pde-loss 7.6203e+02, initc-loss 2.9641e+04                    bc_loss 4.7422e+03\n",
      "Epoch 12870, Training-Loss 4.4016e+04, Data-loss 6.3755e+03                  , pde-loss 1.6855e+03, initc-loss 2.9500e+04                    bc_loss 6.4552e+03\n",
      "Epoch 12880, Training-Loss 5.1531e+04, Data-loss 5.4745e+03                  , pde-loss 1.0895e+03, initc-loss 3.0397e+04                    bc_loss 1.4570e+04\n",
      "Epoch 12890, Training-Loss 4.8507e+04, Data-loss 7.5765e+03                  , pde-loss 6.5469e+02, initc-loss 3.2272e+04                    bc_loss 8.0036e+03\n",
      "Epoch 12900, Training-Loss 4.6103e+04, Data-loss 7.1291e+03                  , pde-loss 1.9719e+03, initc-loss 3.0691e+04                    bc_loss 6.3108e+03\n",
      "Epoch 12910, Training-Loss 4.6524e+04, Data-loss 9.4643e+03                  , pde-loss 2.8051e+03, initc-loss 2.9050e+04                    bc_loss 5.2039e+03\n",
      "Epoch 12920, Training-Loss 4.5256e+04, Data-loss 6.4197e+03                  , pde-loss 1.6233e+03, initc-loss 2.9452e+04                    bc_loss 7.7605e+03\n",
      "Epoch 12930, Training-Loss 5.0362e+04, Data-loss 7.3013e+03                  , pde-loss 2.6173e+03, initc-loss 3.1509e+04                    bc_loss 8.9345e+03\n",
      "Epoch 12940, Training-Loss 5.1288e+04, Data-loss 7.5776e+03                  , pde-loss 1.7778e+03, initc-loss 3.1823e+04                    bc_loss 1.0109e+04\n",
      "Epoch 12950, Training-Loss 4.8746e+04, Data-loss 6.2330e+03                  , pde-loss 1.4153e+03, initc-loss 3.3857e+04                    bc_loss 7.2406e+03\n",
      "Epoch 12960, Training-Loss 4.4244e+04, Data-loss 7.2710e+03                  , pde-loss 1.2656e+03, initc-loss 3.1281e+04                    bc_loss 4.4256e+03\n",
      "Epoch 12970, Training-Loss 4.2313e+04, Data-loss 7.7449e+03                  , pde-loss 1.5312e+03, initc-loss 2.9302e+04                    bc_loss 3.7349e+03\n",
      "Epoch 12980, Training-Loss 4.2337e+04, Data-loss 6.0384e+03                  , pde-loss 1.6275e+03, initc-loss 3.0091e+04                    bc_loss 4.5805e+03\n",
      "Epoch 12990, Training-Loss 4.5702e+04, Data-loss 6.7925e+03                  , pde-loss 1.6141e+03, initc-loss 2.9885e+04                    bc_loss 7.4108e+03\n",
      "Epoch 13000, Training-Loss 4.2525e+04, Data-loss 6.1215e+03                  , pde-loss 1.1493e+03, initc-loss 2.8497e+04                    bc_loss 6.7574e+03\n",
      "Epoch 13010, Training-Loss 4.5547e+04, Data-loss 6.5325e+03                  , pde-loss 7.1179e+02, initc-loss 3.0182e+04                    bc_loss 8.1208e+03\n",
      "Epoch 13020, Training-Loss 4.3968e+04, Data-loss 5.6422e+03                  , pde-loss 1.3672e+03, initc-loss 2.9432e+04                    bc_loss 7.5272e+03\n",
      "Epoch 13030, Training-Loss 4.6706e+04, Data-loss 7.0081e+03                  , pde-loss 1.5691e+03, initc-loss 2.8840e+04                    bc_loss 9.2888e+03\n",
      "Epoch 13040, Training-Loss 5.0809e+04, Data-loss 5.9305e+03                  , pde-loss 7.5981e+02, initc-loss 2.9384e+04                    bc_loss 1.4735e+04\n",
      "Epoch 13050, Training-Loss 4.6188e+04, Data-loss 6.7061e+03                  , pde-loss 8.9795e+02, initc-loss 3.0569e+04                    bc_loss 8.0150e+03\n",
      "Epoch 13060, Training-Loss 4.5906e+04, Data-loss 6.9037e+03                  , pde-loss 1.2717e+03, initc-loss 3.0494e+04                    bc_loss 7.2369e+03\n",
      "Epoch 13070, Training-Loss 4.6134e+04, Data-loss 7.1121e+03                  , pde-loss 1.3373e+03, initc-loss 2.9826e+04                    bc_loss 7.8591e+03\n",
      "Epoch 13080, Training-Loss 4.6968e+04, Data-loss 6.6371e+03                  , pde-loss 1.4950e+03, initc-loss 2.9218e+04                    bc_loss 9.6178e+03\n",
      "Epoch 13090, Training-Loss 4.3446e+04, Data-loss 6.0400e+03                  , pde-loss 1.2960e+03, initc-loss 2.9482e+04                    bc_loss 6.6278e+03\n",
      "Epoch 13100, Training-Loss 4.9083e+04, Data-loss 6.4196e+03                  , pde-loss 9.9679e+02, initc-loss 2.9592e+04                    bc_loss 1.2074e+04\n",
      "Epoch 13110, Training-Loss 4.2106e+04, Data-loss 6.7967e+03                  , pde-loss 9.2924e+02, initc-loss 2.9909e+04                    bc_loss 4.4709e+03\n",
      "Epoch 13120, Training-Loss 4.5509e+04, Data-loss 6.0965e+03                  , pde-loss 3.1191e+03, initc-loss 2.9832e+04                    bc_loss 6.4609e+03\n",
      "Epoch 13130, Training-Loss 4.3600e+04, Data-loss 5.0418e+03                  , pde-loss 6.4912e+02, initc-loss 2.9927e+04                    bc_loss 7.9814e+03\n",
      "Epoch 13140, Training-Loss 4.8105e+04, Data-loss 6.8861e+03                  , pde-loss 1.6268e+03, initc-loss 2.8784e+04                    bc_loss 1.0809e+04\n",
      "Epoch 13150, Training-Loss 5.8485e+04, Data-loss 7.2935e+03                  , pde-loss 1.6195e+03, initc-loss 3.0272e+04                    bc_loss 1.9300e+04\n",
      "Epoch 13160, Training-Loss 5.7195e+04, Data-loss 7.9611e+03                  , pde-loss 1.3733e+03, initc-loss 3.3400e+04                    bc_loss 1.4460e+04\n",
      "Epoch 13170, Training-Loss 5.6149e+04, Data-loss 6.0543e+03                  , pde-loss 9.4976e+02, initc-loss 3.2097e+04                    bc_loss 1.7048e+04\n",
      "Epoch 13180, Training-Loss 4.8822e+04, Data-loss 9.2796e+03                  , pde-loss 1.7028e+03, initc-loss 3.1954e+04                    bc_loss 5.8859e+03\n",
      "Epoch 13190, Training-Loss 4.6032e+04, Data-loss 7.9827e+03                  , pde-loss 1.7295e+03, initc-loss 3.1453e+04                    bc_loss 4.8670e+03\n",
      "Epoch 13200, Training-Loss 4.0887e+04, Data-loss 5.5586e+03                  , pde-loss 8.9868e+02, initc-loss 2.9650e+04                    bc_loss 4.7801e+03\n",
      "Epoch 13210, Training-Loss 4.8203e+04, Data-loss 7.4629e+03                  , pde-loss 2.0712e+03, initc-loss 2.8487e+04                    bc_loss 1.0183e+04\n",
      "Epoch 13220, Training-Loss 4.5069e+04, Data-loss 7.8592e+03                  , pde-loss 1.4395e+03, initc-loss 2.8978e+04                    bc_loss 6.7921e+03\n",
      "Epoch 13230, Training-Loss 4.0230e+04, Data-loss 5.8618e+03                  , pde-loss 1.0791e+03, initc-loss 2.8977e+04                    bc_loss 4.3117e+03\n",
      "Epoch 13240, Training-Loss 4.5581e+04, Data-loss 6.5878e+03                  , pde-loss 1.3067e+03, initc-loss 2.8846e+04                    bc_loss 8.8404e+03\n",
      "Epoch 13250, Training-Loss 5.3831e+04, Data-loss 5.6182e+03                  , pde-loss 1.3827e+03, initc-loss 2.9676e+04                    bc_loss 1.7154e+04\n",
      "Epoch 13260, Training-Loss 4.4407e+04, Data-loss 5.6485e+03                  , pde-loss 1.5910e+03, initc-loss 3.0345e+04                    bc_loss 6.8222e+03\n",
      "Epoch 13270, Training-Loss 4.4630e+04, Data-loss 6.1574e+03                  , pde-loss 1.5245e+03, initc-loss 3.0370e+04                    bc_loss 6.5776e+03\n",
      "Epoch 13280, Training-Loss 5.7684e+04, Data-loss 6.3185e+03                  , pde-loss 9.4761e+02, initc-loss 3.0239e+04                    bc_loss 2.0179e+04\n",
      "Epoch 13290, Training-Loss 4.4433e+04, Data-loss 6.7208e+03                  , pde-loss 8.8627e+02, initc-loss 3.1066e+04                    bc_loss 5.7601e+03\n",
      "Epoch 13300, Training-Loss 6.1489e+04, Data-loss 8.0434e+03                  , pde-loss 1.4236e+03, initc-loss 3.0978e+04                    bc_loss 2.1044e+04\n",
      "Epoch 13310, Training-Loss 4.8338e+04, Data-loss 7.4611e+03                  , pde-loss 1.2156e+03, initc-loss 3.1698e+04                    bc_loss 7.9639e+03\n",
      "Epoch 13320, Training-Loss 4.6008e+04, Data-loss 7.5464e+03                  , pde-loss 9.9930e+02, initc-loss 3.1607e+04                    bc_loss 5.8554e+03\n",
      "Epoch 13330, Training-Loss 4.3099e+04, Data-loss 5.2940e+03                  , pde-loss 9.8174e+02, initc-loss 2.9835e+04                    bc_loss 6.9886e+03\n",
      "Epoch 13340, Training-Loss 4.1652e+04, Data-loss 6.6739e+03                  , pde-loss 1.4917e+03, initc-loss 2.8979e+04                    bc_loss 4.5079e+03\n",
      "Epoch 13350, Training-Loss 4.4769e+04, Data-loss 5.8520e+03                  , pde-loss 1.6723e+03, initc-loss 2.9133e+04                    bc_loss 8.1112e+03\n",
      "Epoch 13360, Training-Loss 4.6733e+04, Data-loss 6.4963e+03                  , pde-loss 1.2179e+03, initc-loss 2.9316e+04                    bc_loss 9.7026e+03\n",
      "Epoch 13370, Training-Loss 4.9068e+04, Data-loss 5.1164e+03                  , pde-loss 8.1939e+02, initc-loss 2.9861e+04                    bc_loss 1.3272e+04\n",
      "Epoch 13380, Training-Loss 5.2890e+04, Data-loss 7.7761e+03                  , pde-loss 1.8518e+03, initc-loss 3.0237e+04                    bc_loss 1.3025e+04\n",
      "Epoch 13390, Training-Loss 4.9798e+04, Data-loss 6.8617e+03                  , pde-loss 9.7425e+02, initc-loss 3.1136e+04                    bc_loss 1.0826e+04\n",
      "Epoch 13400, Training-Loss 4.4482e+04, Data-loss 7.8954e+03                  , pde-loss 1.6843e+03, initc-loss 2.9552e+04                    bc_loss 5.3506e+03\n",
      "Epoch 13410, Training-Loss 4.0567e+04, Data-loss 5.5738e+03                  , pde-loss 1.4378e+03, initc-loss 2.9017e+04                    bc_loss 4.5376e+03\n",
      "Epoch 13420, Training-Loss 3.9066e+04, Data-loss 6.0608e+03                  , pde-loss 1.3357e+03, initc-loss 2.8059e+04                    bc_loss 3.6108e+03\n",
      "Epoch 13430, Training-Loss 3.9460e+04, Data-loss 5.4317e+03                  , pde-loss 1.3223e+03, initc-loss 2.7650e+04                    bc_loss 5.0561e+03\n",
      "Epoch 13440, Training-Loss 4.2860e+04, Data-loss 6.3715e+03                  , pde-loss 8.3420e+02, initc-loss 2.8356e+04                    bc_loss 7.2986e+03\n",
      "Epoch 13450, Training-Loss 4.4281e+04, Data-loss 5.2634e+03                  , pde-loss 2.4315e+03, initc-loss 2.7521e+04                    bc_loss 9.0649e+03\n",
      "Epoch 13460, Training-Loss 4.4088e+04, Data-loss 5.8201e+03                  , pde-loss 1.2029e+03, initc-loss 2.9735e+04                    bc_loss 7.3307e+03\n",
      "Epoch 13470, Training-Loss 4.4218e+04, Data-loss 6.4878e+03                  , pde-loss 1.1821e+03, initc-loss 2.9913e+04                    bc_loss 6.6352e+03\n",
      "Epoch 13480, Training-Loss 4.1676e+04, Data-loss 5.5438e+03                  , pde-loss 1.2465e+03, initc-loss 2.9475e+04                    bc_loss 5.4115e+03\n",
      "Epoch 13490, Training-Loss 4.0240e+04, Data-loss 5.8861e+03                  , pde-loss 1.3797e+03, initc-loss 2.7566e+04                    bc_loss 5.4079e+03\n",
      "Epoch 13500, Training-Loss 4.3736e+04, Data-loss 6.4392e+03                  , pde-loss 1.3250e+03, initc-loss 2.7917e+04                    bc_loss 8.0550e+03\n",
      "Epoch 13510, Training-Loss 4.3814e+04, Data-loss 6.1672e+03                  , pde-loss 8.9243e+02, initc-loss 2.8820e+04                    bc_loss 7.9341e+03\n",
      "Epoch 13520, Training-Loss 4.2615e+04, Data-loss 5.0070e+03                  , pde-loss 9.5112e+02, initc-loss 2.9277e+04                    bc_loss 7.3799e+03\n",
      "Epoch 13530, Training-Loss 4.5810e+04, Data-loss 5.8651e+03                  , pde-loss 6.8172e+02, initc-loss 2.8663e+04                    bc_loss 1.0601e+04\n",
      "Epoch 13540, Training-Loss 4.8775e+04, Data-loss 5.5637e+03                  , pde-loss 1.2555e+03, initc-loss 2.9044e+04                    bc_loss 1.2911e+04\n",
      "Epoch 13550, Training-Loss 4.5610e+04, Data-loss 7.1830e+03                  , pde-loss 1.1256e+03, initc-loss 3.0125e+04                    bc_loss 7.1759e+03\n",
      "Epoch 13560, Training-Loss 4.6481e+04, Data-loss 6.4760e+03                  , pde-loss 1.1336e+03, initc-loss 3.0250e+04                    bc_loss 8.6213e+03\n",
      "Epoch 13570, Training-Loss 4.2694e+04, Data-loss 6.4738e+03                  , pde-loss 1.3974e+03, initc-loss 3.0341e+04                    bc_loss 4.4816e+03\n",
      "Epoch 13580, Training-Loss 3.9993e+04, Data-loss 5.5933e+03                  , pde-loss 1.1550e+03, initc-loss 2.9032e+04                    bc_loss 4.2127e+03\n",
      "Epoch 13590, Training-Loss 3.9131e+04, Data-loss 6.1737e+03                  , pde-loss 1.3303e+03, initc-loss 2.7818e+04                    bc_loss 3.8089e+03\n",
      "Epoch 13600, Training-Loss 3.9461e+04, Data-loss 5.3918e+03                  , pde-loss 8.4228e+02, initc-loss 2.7987e+04                    bc_loss 5.2404e+03\n",
      "Epoch 13610, Training-Loss 4.0086e+04, Data-loss 4.5025e+03                  , pde-loss 7.5090e+02, initc-loss 2.8287e+04                    bc_loss 6.5459e+03\n",
      "Epoch 13620, Training-Loss 4.7353e+04, Data-loss 5.9156e+03                  , pde-loss 6.8233e+02, initc-loss 2.8260e+04                    bc_loss 1.2495e+04\n",
      "Epoch 13630, Training-Loss 4.1390e+04, Data-loss 6.2175e+03                  , pde-loss 9.3522e+02, initc-loss 2.9154e+04                    bc_loss 5.0831e+03\n",
      "Epoch 13640, Training-Loss 4.3452e+04, Data-loss 6.4907e+03                  , pde-loss 1.0464e+03, initc-loss 2.8332e+04                    bc_loss 7.5829e+03\n",
      "Epoch 13650, Training-Loss 4.4361e+04, Data-loss 7.1045e+03                  , pde-loss 1.4149e+03, initc-loss 2.7951e+04                    bc_loss 7.8900e+03\n",
      "Epoch 13660, Training-Loss 4.8967e+04, Data-loss 6.0318e+03                  , pde-loss 1.8550e+03, initc-loss 2.9540e+04                    bc_loss 1.1540e+04\n",
      "Epoch 13670, Training-Loss 5.4524e+04, Data-loss 6.7700e+03                  , pde-loss 1.3104e+03, initc-loss 3.0314e+04                    bc_loss 1.6130e+04\n",
      "Epoch 13680, Training-Loss 4.5984e+04, Data-loss 6.1015e+03                  , pde-loss 1.2029e+03, initc-loss 2.9294e+04                    bc_loss 9.3861e+03\n",
      "Epoch 13690, Training-Loss 4.5002e+04, Data-loss 4.8552e+03                  , pde-loss 8.4755e+02, initc-loss 3.0073e+04                    bc_loss 9.2264e+03\n",
      "Epoch 13700, Training-Loss 4.6444e+04, Data-loss 6.7850e+03                  , pde-loss 1.7221e+03, initc-loss 3.0913e+04                    bc_loss 7.0243e+03\n",
      "Epoch 13710, Training-Loss 4.4685e+04, Data-loss 6.4861e+03                  , pde-loss 1.0086e+03, initc-loss 2.9020e+04                    bc_loss 8.1698e+03\n",
      "Epoch 13720, Training-Loss 4.4013e+04, Data-loss 5.8255e+03                  , pde-loss 9.7967e+02, initc-loss 3.0016e+04                    bc_loss 7.1919e+03\n",
      "Epoch 13730, Training-Loss 4.1362e+04, Data-loss 5.0961e+03                  , pde-loss 1.2400e+03, initc-loss 2.8348e+04                    bc_loss 6.6778e+03\n",
      "Epoch 13740, Training-Loss 3.8751e+04, Data-loss 5.3545e+03                  , pde-loss 1.4264e+03, initc-loss 2.8018e+04                    bc_loss 3.9519e+03\n",
      "Epoch 13750, Training-Loss 3.7782e+04, Data-loss 5.0192e+03                  , pde-loss 1.8169e+03, initc-loss 2.8308e+04                    bc_loss 2.6379e+03\n",
      "Epoch 13760, Training-Loss 4.1684e+04, Data-loss 6.5751e+03                  , pde-loss 7.5325e+02, initc-loss 2.7839e+04                    bc_loss 6.5171e+03\n",
      "Epoch 13770, Training-Loss 3.9049e+04, Data-loss 4.6709e+03                  , pde-loss 1.2208e+03, initc-loss 2.7656e+04                    bc_loss 5.5006e+03\n",
      "Epoch 13780, Training-Loss 3.9064e+04, Data-loss 5.5404e+03                  , pde-loss 1.0262e+03, initc-loss 2.8301e+04                    bc_loss 4.1960e+03\n",
      "Epoch 13790, Training-Loss 3.5283e+04, Data-loss 3.8099e+03                  , pde-loss 6.6286e+02, initc-loss 2.6957e+04                    bc_loss 3.8527e+03\n",
      "Epoch 13800, Training-Loss 3.6266e+04, Data-loss 4.5509e+03                  , pde-loss 1.0280e+03, initc-loss 2.6851e+04                    bc_loss 3.8358e+03\n",
      "Epoch 13810, Training-Loss 5.6495e+04, Data-loss 6.3762e+03                  , pde-loss 1.2931e+03, initc-loss 2.8191e+04                    bc_loss 2.0634e+04\n",
      "Epoch 13820, Training-Loss 4.2800e+04, Data-loss 4.3609e+03                  , pde-loss 9.6241e+02, initc-loss 2.9960e+04                    bc_loss 7.5168e+03\n",
      "Epoch 13830, Training-Loss 5.2736e+04, Data-loss 7.7632e+03                  , pde-loss 1.7139e+03, initc-loss 3.1860e+04                    bc_loss 1.1399e+04\n",
      "Epoch 13840, Training-Loss 4.9519e+04, Data-loss 7.8654e+03                  , pde-loss 1.0681e+03, initc-loss 3.1441e+04                    bc_loss 9.1442e+03\n",
      "Epoch 13850, Training-Loss 4.2022e+04, Data-loss 6.0280e+03                  , pde-loss 1.3583e+03, initc-loss 2.9511e+04                    bc_loss 5.1241e+03\n",
      "Epoch 13860, Training-Loss 4.2275e+04, Data-loss 6.5193e+03                  , pde-loss 1.7663e+03, initc-loss 2.8712e+04                    bc_loss 5.2774e+03\n",
      "Epoch 13870, Training-Loss 4.4143e+04, Data-loss 5.3121e+03                  , pde-loss 1.1622e+03, initc-loss 2.7576e+04                    bc_loss 1.0093e+04\n",
      "Epoch 13880, Training-Loss 4.2023e+04, Data-loss 6.5113e+03                  , pde-loss 1.2659e+03, initc-loss 2.8435e+04                    bc_loss 5.8106e+03\n",
      "Epoch 13890, Training-Loss 4.4092e+04, Data-loss 5.6575e+03                  , pde-loss 1.6548e+03, initc-loss 2.8794e+04                    bc_loss 7.9855e+03\n",
      "Epoch 13900, Training-Loss 4.2334e+04, Data-loss 5.5589e+03                  , pde-loss 1.1414e+03, initc-loss 2.7726e+04                    bc_loss 7.9074e+03\n",
      "Epoch 13910, Training-Loss 4.1400e+04, Data-loss 4.3217e+03                  , pde-loss 9.6606e+02, initc-loss 2.6888e+04                    bc_loss 9.2251e+03\n",
      "Epoch 13920, Training-Loss 4.1379e+04, Data-loss 6.2940e+03                  , pde-loss 1.4924e+03, initc-loss 2.7396e+04                    bc_loss 6.1970e+03\n",
      "Epoch 13930, Training-Loss 4.4330e+04, Data-loss 6.5573e+03                  , pde-loss 1.8364e+03, initc-loss 2.7821e+04                    bc_loss 8.1154e+03\n",
      "Epoch 13940, Training-Loss 4.6286e+04, Data-loss 6.6656e+03                  , pde-loss 8.7764e+02, initc-loss 2.7346e+04                    bc_loss 1.1397e+04\n",
      "Epoch 13950, Training-Loss 4.0334e+04, Data-loss 5.8163e+03                  , pde-loss 1.5118e+03, initc-loss 2.7076e+04                    bc_loss 5.9292e+03\n",
      "Epoch 13960, Training-Loss 4.0581e+04, Data-loss 4.6453e+03                  , pde-loss 1.1646e+03, initc-loss 2.7140e+04                    bc_loss 7.6308e+03\n",
      "Epoch 13970, Training-Loss 4.3641e+04, Data-loss 6.2476e+03                  , pde-loss 1.5146e+03, initc-loss 2.7345e+04                    bc_loss 8.5339e+03\n",
      "Epoch 13980, Training-Loss 3.9163e+04, Data-loss 5.7009e+03                  , pde-loss 1.4926e+03, initc-loss 2.6537e+04                    bc_loss 5.4323e+03\n",
      "Epoch 13990, Training-Loss 3.9943e+04, Data-loss 6.6742e+03                  , pde-loss 1.0660e+03, initc-loss 2.7659e+04                    bc_loss 4.5439e+03\n",
      "Epoch 14000, Training-Loss 3.8710e+04, Data-loss 5.2110e+03                  , pde-loss 7.6475e+02, initc-loss 2.5998e+04                    bc_loss 6.7365e+03\n",
      "Epoch 14010, Training-Loss 3.6901e+04, Data-loss 4.5707e+03                  , pde-loss 1.2874e+03, initc-loss 2.6440e+04                    bc_loss 4.6034e+03\n",
      "Epoch 14020, Training-Loss 3.5945e+04, Data-loss 4.3197e+03                  , pde-loss 1.1789e+03, initc-loss 2.6359e+04                    bc_loss 4.0876e+03\n",
      "Epoch 14030, Training-Loss 3.7064e+04, Data-loss 5.3323e+03                  , pde-loss 1.4628e+03, initc-loss 2.4575e+04                    bc_loss 5.6938e+03\n",
      "Epoch 14040, Training-Loss 4.0330e+04, Data-loss 5.2495e+03                  , pde-loss 9.7193e+02, initc-loss 2.6252e+04                    bc_loss 7.8569e+03\n",
      "Epoch 14050, Training-Loss 3.9165e+04, Data-loss 5.0829e+03                  , pde-loss 8.1225e+02, initc-loss 2.6349e+04                    bc_loss 6.9201e+03\n",
      "Epoch 14060, Training-Loss 3.6234e+04, Data-loss 4.8814e+03                  , pde-loss 7.9477e+02, initc-loss 2.6412e+04                    bc_loss 4.1462e+03\n",
      "Epoch 14070, Training-Loss 3.6150e+04, Data-loss 4.8070e+03                  , pde-loss 1.4983e+03, initc-loss 2.5453e+04                    bc_loss 4.3909e+03\n",
      "Epoch 14080, Training-Loss 3.9499e+04, Data-loss 5.2396e+03                  , pde-loss 1.1630e+03, initc-loss 2.5968e+04                    bc_loss 7.1289e+03\n",
      "Epoch 14090, Training-Loss 4.0265e+04, Data-loss 5.2498e+03                  , pde-loss 8.6803e+02, initc-loss 2.5168e+04                    bc_loss 8.9792e+03\n",
      "Epoch 14100, Training-Loss 4.1236e+04, Data-loss 4.7870e+03                  , pde-loss 6.5985e+02, initc-loss 2.7344e+04                    bc_loss 8.4442e+03\n",
      "Epoch 14110, Training-Loss 3.5575e+04, Data-loss 5.0168e+03                  , pde-loss 8.0886e+02, initc-loss 2.5941e+04                    bc_loss 3.8088e+03\n",
      "Epoch 14120, Training-Loss 3.9348e+04, Data-loss 5.5901e+03                  , pde-loss 8.8994e+02, initc-loss 2.6870e+04                    bc_loss 5.9978e+03\n",
      "Epoch 14130, Training-Loss 3.8939e+04, Data-loss 3.6203e+03                  , pde-loss 8.5277e+02, initc-loss 2.5054e+04                    bc_loss 9.4122e+03\n",
      "Epoch 14140, Training-Loss 4.2609e+04, Data-loss 4.8162e+03                  , pde-loss 1.2611e+03, initc-loss 2.6346e+04                    bc_loss 1.0185e+04\n",
      "Epoch 14150, Training-Loss 3.9866e+04, Data-loss 5.4892e+03                  , pde-loss 1.3917e+03, initc-loss 2.7194e+04                    bc_loss 5.7912e+03\n",
      "Epoch 14160, Training-Loss 3.8490e+04, Data-loss 5.6427e+03                  , pde-loss 9.5816e+02, initc-loss 2.7273e+04                    bc_loss 4.6165e+03\n",
      "Epoch 14170, Training-Loss 3.6515e+04, Data-loss 4.8683e+03                  , pde-loss 1.1280e+03, initc-loss 2.6365e+04                    bc_loss 4.1532e+03\n",
      "Epoch 14180, Training-Loss 3.7846e+04, Data-loss 4.5880e+03                  , pde-loss 6.9056e+02, initc-loss 2.4365e+04                    bc_loss 8.2026e+03\n",
      "Epoch 14190, Training-Loss 3.8170e+04, Data-loss 4.1473e+03                  , pde-loss 8.9164e+02, initc-loss 2.5152e+04                    bc_loss 7.9793e+03\n",
      "Epoch 14200, Training-Loss 4.3201e+04, Data-loss 4.4472e+03                  , pde-loss 1.5668e+03, initc-loss 2.6006e+04                    bc_loss 1.1181e+04\n",
      "Epoch 14210, Training-Loss 4.0689e+04, Data-loss 4.6293e+03                  , pde-loss 6.9580e+02, initc-loss 2.6768e+04                    bc_loss 8.5954e+03\n",
      "Epoch 14220, Training-Loss 4.4302e+04, Data-loss 5.5520e+03                  , pde-loss 7.2437e+02, initc-loss 2.6312e+04                    bc_loss 1.1714e+04\n",
      "Epoch 14230, Training-Loss 4.8182e+04, Data-loss 7.4046e+03                  , pde-loss 1.5154e+03, initc-loss 2.9156e+04                    bc_loss 1.0106e+04\n",
      "Epoch 14240, Training-Loss 4.0051e+04, Data-loss 6.1055e+03                  , pde-loss 1.1516e+03, initc-loss 2.7471e+04                    bc_loss 5.3237e+03\n",
      "Epoch 14250, Training-Loss 3.8678e+04, Data-loss 6.0928e+03                  , pde-loss 8.1967e+02, initc-loss 2.6975e+04                    bc_loss 4.7913e+03\n",
      "Epoch 14260, Training-Loss 3.7763e+04, Data-loss 5.6691e+03                  , pde-loss 1.1787e+03, initc-loss 2.6240e+04                    bc_loss 4.6753e+03\n",
      "Epoch 14270, Training-Loss 3.7291e+04, Data-loss 5.2834e+03                  , pde-loss 7.1102e+02, initc-loss 2.6861e+04                    bc_loss 4.4357e+03\n",
      "Epoch 14280, Training-Loss 3.6048e+04, Data-loss 4.1771e+03                  , pde-loss 7.5004e+02, initc-loss 2.5829e+04                    bc_loss 5.2915e+03\n",
      "Epoch 14290, Training-Loss 3.5504e+04, Data-loss 5.0018e+03                  , pde-loss 1.4423e+03, initc-loss 2.6037e+04                    bc_loss 3.0234e+03\n",
      "Epoch 14300, Training-Loss 3.6145e+04, Data-loss 4.8929e+03                  , pde-loss 1.8934e+03, initc-loss 2.5092e+04                    bc_loss 4.2667e+03\n",
      "Epoch 14310, Training-Loss 3.5824e+04, Data-loss 3.9741e+03                  , pde-loss 4.8245e+02, initc-loss 2.5632e+04                    bc_loss 5.7350e+03\n",
      "Epoch 14320, Training-Loss 3.5984e+04, Data-loss 3.7710e+03                  , pde-loss 7.0860e+02, initc-loss 2.4301e+04                    bc_loss 7.2034e+03\n",
      "Epoch 14330, Training-Loss 3.7676e+04, Data-loss 4.4057e+03                  , pde-loss 1.2302e+03, initc-loss 2.5995e+04                    bc_loss 6.0450e+03\n",
      "Epoch 14340, Training-Loss 4.0857e+04, Data-loss 5.7613e+03                  , pde-loss 1.5342e+03, initc-loss 2.5302e+04                    bc_loss 8.2594e+03\n",
      "Epoch 14350, Training-Loss 4.2219e+04, Data-loss 5.1093e+03                  , pde-loss 1.3709e+03, initc-loss 2.6817e+04                    bc_loss 8.9216e+03\n",
      "Epoch 14360, Training-Loss 3.9471e+04, Data-loss 5.7817e+03                  , pde-loss 1.7986e+03, initc-loss 2.5772e+04                    bc_loss 6.1185e+03\n",
      "Epoch 14370, Training-Loss 4.2300e+04, Data-loss 5.1730e+03                  , pde-loss 1.4393e+03, initc-loss 2.5904e+04                    bc_loss 9.7836e+03\n",
      "Epoch 14380, Training-Loss 3.8641e+04, Data-loss 4.6666e+03                  , pde-loss 1.0824e+03, initc-loss 2.6177e+04                    bc_loss 6.7155e+03\n",
      "Epoch 14390, Training-Loss 4.0363e+04, Data-loss 4.2883e+03                  , pde-loss 7.9490e+02, initc-loss 2.6040e+04                    bc_loss 9.2395e+03\n",
      "Epoch 14400, Training-Loss 4.1588e+04, Data-loss 4.5621e+03                  , pde-loss 2.0810e+03, initc-loss 2.6533e+04                    bc_loss 8.4118e+03\n",
      "Epoch 14410, Training-Loss 3.8891e+04, Data-loss 4.9639e+03                  , pde-loss 9.3140e+02, initc-loss 2.5980e+04                    bc_loss 7.0160e+03\n",
      "Epoch 14420, Training-Loss 3.9448e+04, Data-loss 4.2909e+03                  , pde-loss 7.8808e+02, initc-loss 2.4417e+04                    bc_loss 9.9516e+03\n",
      "Epoch 14430, Training-Loss 4.0313e+04, Data-loss 4.0268e+03                  , pde-loss 8.9511e+02, initc-loss 2.4511e+04                    bc_loss 1.0880e+04\n",
      "Epoch 14440, Training-Loss 3.9565e+04, Data-loss 3.7206e+03                  , pde-loss 1.0045e+03, initc-loss 2.4890e+04                    bc_loss 9.9504e+03\n",
      "Epoch 14450, Training-Loss 3.9666e+04, Data-loss 5.5039e+03                  , pde-loss 1.2994e+03, initc-loss 2.5102e+04                    bc_loss 7.7599e+03\n",
      "Epoch 14460, Training-Loss 3.8559e+04, Data-loss 5.6647e+03                  , pde-loss 1.6916e+03, initc-loss 2.5361e+04                    bc_loss 5.8411e+03\n",
      "Epoch 14470, Training-Loss 3.7567e+04, Data-loss 3.8007e+03                  , pde-loss 8.5831e+02, initc-loss 2.5900e+04                    bc_loss 7.0085e+03\n",
      "Epoch 14480, Training-Loss 4.0467e+04, Data-loss 4.1654e+03                  , pde-loss 1.3862e+03, initc-loss 2.5108e+04                    bc_loss 9.8076e+03\n",
      "Epoch 14490, Training-Loss 3.6475e+04, Data-loss 4.3940e+03                  , pde-loss 1.1112e+03, initc-loss 2.4371e+04                    bc_loss 6.5995e+03\n",
      "Epoch 14500, Training-Loss 4.0286e+04, Data-loss 6.4120e+03                  , pde-loss 1.3633e+03, initc-loss 2.4982e+04                    bc_loss 7.5288e+03\n",
      "Epoch 14510, Training-Loss 3.6244e+04, Data-loss 4.0040e+03                  , pde-loss 9.5444e+02, initc-loss 2.6211e+04                    bc_loss 5.0749e+03\n",
      "Epoch 14520, Training-Loss 3.4513e+04, Data-loss 4.6523e+03                  , pde-loss 6.8376e+02, initc-loss 2.5113e+04                    bc_loss 4.0644e+03\n",
      "Epoch 14530, Training-Loss 3.2965e+04, Data-loss 3.9399e+03                  , pde-loss 9.0049e+02, initc-loss 2.5007e+04                    bc_loss 3.1181e+03\n",
      "Epoch 14540, Training-Loss 3.4184e+04, Data-loss 4.1839e+03                  , pde-loss 1.0604e+03, initc-loss 2.2679e+04                    bc_loss 6.2603e+03\n",
      "Epoch 14550, Training-Loss 3.7248e+04, Data-loss 3.5334e+03                  , pde-loss 8.0840e+02, initc-loss 2.4437e+04                    bc_loss 8.4692e+03\n",
      "Epoch 14560, Training-Loss 3.5758e+04, Data-loss 3.8835e+03                  , pde-loss 8.5907e+02, initc-loss 2.4890e+04                    bc_loss 6.1247e+03\n",
      "Epoch 14570, Training-Loss 3.4935e+04, Data-loss 4.6971e+03                  , pde-loss 1.3205e+03, initc-loss 2.4093e+04                    bc_loss 4.8241e+03\n",
      "Epoch 14580, Training-Loss 3.8146e+04, Data-loss 6.0602e+03                  , pde-loss 1.2758e+03, initc-loss 2.4019e+04                    bc_loss 6.7915e+03\n",
      "Epoch 14590, Training-Loss 3.1823e+04, Data-loss 4.2170e+03                  , pde-loss 1.2938e+03, initc-loss 2.3450e+04                    bc_loss 2.8615e+03\n",
      "Epoch 14600, Training-Loss 3.6134e+04, Data-loss 5.6222e+03                  , pde-loss 1.9068e+03, initc-loss 2.3308e+04                    bc_loss 5.2968e+03\n",
      "Epoch 14610, Training-Loss 3.2345e+04, Data-loss 3.6799e+03                  , pde-loss 1.1959e+03, initc-loss 2.2974e+04                    bc_loss 4.4949e+03\n",
      "Epoch 14620, Training-Loss 3.5288e+04, Data-loss 3.3528e+03                  , pde-loss 1.2353e+03, initc-loss 2.3959e+04                    bc_loss 6.7407e+03\n",
      "Epoch 14630, Training-Loss 3.8090e+04, Data-loss 3.4388e+03                  , pde-loss 9.7323e+02, initc-loss 2.3718e+04                    bc_loss 9.9609e+03\n",
      "Epoch 14640, Training-Loss 4.2088e+04, Data-loss 3.0687e+03                  , pde-loss 1.0519e+03, initc-loss 2.4744e+04                    bc_loss 1.3223e+04\n",
      "Epoch 14650, Training-Loss 4.3212e+04, Data-loss 7.2375e+03                  , pde-loss 1.7083e+03, initc-loss 2.5758e+04                    bc_loss 8.5078e+03\n",
      "Epoch 14660, Training-Loss 4.2868e+04, Data-loss 5.5322e+03                  , pde-loss 8.6209e+02, initc-loss 2.7631e+04                    bc_loss 8.8432e+03\n",
      "Epoch 14670, Training-Loss 3.7760e+04, Data-loss 4.7376e+03                  , pde-loss 9.2617e+02, initc-loss 2.7098e+04                    bc_loss 4.9975e+03\n",
      "Epoch 14680, Training-Loss 3.7215e+04, Data-loss 3.8251e+03                  , pde-loss 1.4573e+03, initc-loss 2.6594e+04                    bc_loss 5.3385e+03\n",
      "Epoch 14690, Training-Loss 3.3205e+04, Data-loss 3.5517e+03                  , pde-loss 8.3155e+02, initc-loss 2.3893e+04                    bc_loss 4.9295e+03\n",
      "Epoch 14700, Training-Loss 3.2379e+04, Data-loss 3.4094e+03                  , pde-loss 8.9202e+02, initc-loss 2.3790e+04                    bc_loss 4.2873e+03\n",
      "Epoch 14710, Training-Loss 3.1084e+04, Data-loss 3.4710e+03                  , pde-loss 7.3013e+02, initc-loss 2.2478e+04                    bc_loss 4.4052e+03\n",
      "Epoch 14720, Training-Loss 3.2954e+04, Data-loss 3.5203e+03                  , pde-loss 6.2670e+02, initc-loss 2.3851e+04                    bc_loss 4.9557e+03\n",
      "Epoch 14730, Training-Loss 4.0293e+04, Data-loss 3.9424e+03                  , pde-loss 1.0303e+03, initc-loss 2.4883e+04                    bc_loss 1.0437e+04\n",
      "Epoch 14740, Training-Loss 3.6187e+04, Data-loss 4.6771e+03                  , pde-loss 1.0270e+03, initc-loss 2.5125e+04                    bc_loss 5.3574e+03\n",
      "Epoch 14750, Training-Loss 3.7543e+04, Data-loss 4.9530e+03                  , pde-loss 1.1263e+03, initc-loss 2.4296e+04                    bc_loss 7.1684e+03\n",
      "Epoch 14760, Training-Loss 3.5117e+04, Data-loss 3.9348e+03                  , pde-loss 1.0197e+03, initc-loss 2.4560e+04                    bc_loss 5.6033e+03\n",
      "Epoch 14770, Training-Loss 3.4214e+04, Data-loss 3.9977e+03                  , pde-loss 1.2312e+03, initc-loss 2.3317e+04                    bc_loss 5.6682e+03\n",
      "Epoch 14780, Training-Loss 3.3381e+04, Data-loss 3.7206e+03                  , pde-loss 8.6588e+02, initc-loss 2.3392e+04                    bc_loss 5.4022e+03\n",
      "Epoch 14790, Training-Loss 3.9138e+04, Data-loss 5.4928e+03                  , pde-loss 2.1267e+03, initc-loss 2.4527e+04                    bc_loss 6.9914e+03\n",
      "Epoch 14800, Training-Loss 3.6467e+04, Data-loss 4.0808e+03                  , pde-loss 9.8421e+02, initc-loss 2.6255e+04                    bc_loss 5.1469e+03\n",
      "Epoch 14810, Training-Loss 3.3587e+04, Data-loss 3.7414e+03                  , pde-loss 1.8449e+03, initc-loss 2.3082e+04                    bc_loss 4.9184e+03\n",
      "Epoch 14820, Training-Loss 3.3197e+04, Data-loss 2.7110e+03                  , pde-loss 1.1941e+03, initc-loss 2.2928e+04                    bc_loss 6.3641e+03\n",
      "Epoch 14830, Training-Loss 3.8894e+04, Data-loss 3.4227e+03                  , pde-loss 9.2408e+02, initc-loss 2.2407e+04                    bc_loss 1.2141e+04\n",
      "Epoch 14840, Training-Loss 4.4064e+04, Data-loss 5.0207e+03                  , pde-loss 1.9212e+03, initc-loss 2.4570e+04                    bc_loss 1.2553e+04\n",
      "Epoch 14850, Training-Loss 3.7551e+04, Data-loss 4.6891e+03                  , pde-loss 1.4321e+03, initc-loss 2.6360e+04                    bc_loss 5.0692e+03\n",
      "Epoch 14860, Training-Loss 3.5086e+04, Data-loss 4.7110e+03                  , pde-loss 1.7149e+03, initc-loss 2.5505e+04                    bc_loss 3.1551e+03\n",
      "Epoch 14870, Training-Loss 3.4913e+04, Data-loss 4.1910e+03                  , pde-loss 1.6857e+03, initc-loss 2.3393e+04                    bc_loss 5.6436e+03\n",
      "Epoch 14880, Training-Loss 3.8872e+04, Data-loss 3.6357e+03                  , pde-loss 1.1228e+03, initc-loss 2.3621e+04                    bc_loss 1.0492e+04\n",
      "Epoch 14890, Training-Loss 4.0026e+04, Data-loss 5.7881e+03                  , pde-loss 8.1292e+02, initc-loss 2.3920e+04                    bc_loss 9.5052e+03\n",
      "Epoch 14900, Training-Loss 4.0903e+04, Data-loss 4.4635e+03                  , pde-loss 1.4479e+03, initc-loss 2.7158e+04                    bc_loss 7.8331e+03\n",
      "Epoch 14910, Training-Loss 3.3748e+04, Data-loss 3.7159e+03                  , pde-loss 6.7776e+02, initc-loss 2.5212e+04                    bc_loss 4.1419e+03\n",
      "Epoch 14920, Training-Loss 3.1330e+04, Data-loss 3.9288e+03                  , pde-loss 1.1791e+03, initc-loss 2.3450e+04                    bc_loss 2.7727e+03\n",
      "Epoch 14930, Training-Loss 3.0674e+04, Data-loss 3.5428e+03                  , pde-loss 1.2880e+03, initc-loss 2.1943e+04                    bc_loss 3.8998e+03\n",
      "Epoch 14940, Training-Loss 3.3270e+04, Data-loss 3.5867e+03                  , pde-loss 1.2741e+03, initc-loss 2.2278e+04                    bc_loss 6.1309e+03\n",
      "Epoch 14950, Training-Loss 3.2331e+04, Data-loss 3.7168e+03                  , pde-loss 8.9038e+02, initc-loss 2.3025e+04                    bc_loss 4.6993e+03\n",
      "Epoch 14960, Training-Loss 3.1123e+04, Data-loss 3.7570e+03                  , pde-loss 1.5593e+03, initc-loss 2.2767e+04                    bc_loss 3.0393e+03\n",
      "Epoch 14970, Training-Loss 3.1200e+04, Data-loss 3.8551e+03                  , pde-loss 8.9321e+02, initc-loss 2.1880e+04                    bc_loss 4.5717e+03\n",
      "Epoch 14980, Training-Loss 3.4488e+04, Data-loss 3.3661e+03                  , pde-loss 6.5114e+02, initc-loss 2.4987e+04                    bc_loss 5.4838e+03\n",
      "Epoch 14990, Training-Loss 3.6962e+04, Data-loss 3.0461e+03                  , pde-loss 1.0405e+03, initc-loss 2.4326e+04                    bc_loss 8.5486e+03\n",
      "Epoch 15000, Training-Loss 3.4442e+04, Data-loss 3.4475e+03                  , pde-loss 1.2044e+03, initc-loss 2.4256e+04                    bc_loss 5.5342e+03\n",
      "Epoch 15010, Training-Loss 3.8427e+04, Data-loss 4.1444e+03                  , pde-loss 9.0682e+02, initc-loss 2.4325e+04                    bc_loss 9.0506e+03\n",
      "Epoch 15020, Training-Loss 3.6410e+04, Data-loss 3.2949e+03                  , pde-loss 1.0162e+03, initc-loss 2.4154e+04                    bc_loss 7.9443e+03\n",
      "Epoch 15030, Training-Loss 3.6428e+04, Data-loss 3.1164e+03                  , pde-loss 6.5490e+02, initc-loss 2.4353e+04                    bc_loss 8.3035e+03\n",
      "Epoch 15040, Training-Loss 3.5565e+04, Data-loss 5.0566e+03                  , pde-loss 7.9925e+02, initc-loss 2.4674e+04                    bc_loss 5.0345e+03\n",
      "Epoch 15050, Training-Loss 3.5524e+04, Data-loss 4.9108e+03                  , pde-loss 1.7243e+03, initc-loss 2.3919e+04                    bc_loss 4.9699e+03\n",
      "Epoch 15060, Training-Loss 3.5380e+04, Data-loss 3.4911e+03                  , pde-loss 1.4510e+03, initc-loss 2.2939e+04                    bc_loss 7.4983e+03\n",
      "Epoch 15070, Training-Loss 3.5142e+04, Data-loss 3.5446e+03                  , pde-loss 1.1225e+03, initc-loss 2.3390e+04                    bc_loss 7.0843e+03\n",
      "Epoch 15080, Training-Loss 3.7561e+04, Data-loss 3.8452e+03                  , pde-loss 7.5094e+02, initc-loss 2.3700e+04                    bc_loss 9.2643e+03\n",
      "Epoch 15090, Training-Loss 3.9356e+04, Data-loss 5.0493e+03                  , pde-loss 1.9466e+03, initc-loss 2.4010e+04                    bc_loss 8.3502e+03\n",
      "Epoch 15100, Training-Loss 3.7963e+04, Data-loss 4.5584e+03                  , pde-loss 1.4236e+03, initc-loss 2.4446e+04                    bc_loss 7.5353e+03\n",
      "Epoch 15110, Training-Loss 3.2663e+04, Data-loss 3.2961e+03                  , pde-loss 9.5359e+02, initc-loss 2.3366e+04                    bc_loss 5.0472e+03\n",
      "Epoch 15120, Training-Loss 3.4759e+04, Data-loss 4.0677e+03                  , pde-loss 8.4580e+02, initc-loss 2.2517e+04                    bc_loss 7.3282e+03\n",
      "Epoch 15130, Training-Loss 3.5630e+04, Data-loss 3.9908e+03                  , pde-loss 1.2345e+03, initc-loss 2.2685e+04                    bc_loss 7.7194e+03\n",
      "Epoch 15140, Training-Loss 3.8437e+04, Data-loss 4.2428e+03                  , pde-loss 1.8500e+03, initc-loss 2.6050e+04                    bc_loss 6.2946e+03\n",
      "Epoch 15150, Training-Loss 3.2234e+04, Data-loss 3.4018e+03                  , pde-loss 8.1868e+02, initc-loss 2.3608e+04                    bc_loss 4.4055e+03\n",
      "Epoch 15160, Training-Loss 3.1333e+04, Data-loss 2.7804e+03                  , pde-loss 1.2393e+03, initc-loss 2.2026e+04                    bc_loss 5.2874e+03\n",
      "Epoch 15170, Training-Loss 3.2934e+04, Data-loss 3.9016e+03                  , pde-loss 1.3519e+03, initc-loss 2.2151e+04                    bc_loss 5.5288e+03\n",
      "Epoch 15180, Training-Loss 3.2138e+04, Data-loss 3.7984e+03                  , pde-loss 7.7615e+02, initc-loss 2.2070e+04                    bc_loss 5.4942e+03\n",
      "Epoch 15190, Training-Loss 3.1949e+04, Data-loss 3.7255e+03                  , pde-loss 1.1865e+03, initc-loss 2.2297e+04                    bc_loss 4.7402e+03\n",
      "Epoch 15200, Training-Loss 3.1612e+04, Data-loss 4.5706e+03                  , pde-loss 1.0648e+03, initc-loss 2.2396e+04                    bc_loss 3.5801e+03\n",
      "Epoch 15210, Training-Loss 3.2185e+04, Data-loss 3.3469e+03                  , pde-loss 1.0649e+03, initc-loss 2.1064e+04                    bc_loss 6.7089e+03\n",
      "Epoch 15220, Training-Loss 3.7928e+04, Data-loss 3.4871e+03                  , pde-loss 1.3059e+03, initc-loss 2.3608e+04                    bc_loss 9.5270e+03\n",
      "Epoch 15230, Training-Loss 3.2569e+04, Data-loss 4.1614e+03                  , pde-loss 1.6408e+03, initc-loss 2.2546e+04                    bc_loss 4.2205e+03\n",
      "Epoch 15240, Training-Loss 3.3629e+04, Data-loss 2.7555e+03                  , pde-loss 8.9621e+02, initc-loss 2.2454e+04                    bc_loss 7.5229e+03\n",
      "Epoch 15250, Training-Loss 3.1252e+04, Data-loss 3.4092e+03                  , pde-loss 9.4431e+02, initc-loss 2.2264e+04                    bc_loss 4.6343e+03\n",
      "Epoch 15260, Training-Loss 3.3213e+04, Data-loss 4.0429e+03                  , pde-loss 1.1063e+03, initc-loss 2.1738e+04                    bc_loss 6.3267e+03\n",
      "Epoch 15270, Training-Loss 3.4375e+04, Data-loss 4.3689e+03                  , pde-loss 1.5333e+03, initc-loss 2.2035e+04                    bc_loss 6.4387e+03\n",
      "Epoch 15280, Training-Loss 2.7874e+04, Data-loss 2.6383e+03                  , pde-loss 6.2382e+02, initc-loss 2.0832e+04                    bc_loss 3.7797e+03\n",
      "Epoch 15290, Training-Loss 3.0638e+04, Data-loss 3.1475e+03                  , pde-loss 8.8323e+02, initc-loss 2.1082e+04                    bc_loss 5.5252e+03\n",
      "Epoch 15300, Training-Loss 3.5535e+04, Data-loss 3.3071e+03                  , pde-loss 1.3504e+03, initc-loss 2.1600e+04                    bc_loss 9.2775e+03\n",
      "Epoch 15310, Training-Loss 3.7364e+04, Data-loss 3.9312e+03                  , pde-loss 1.2025e+03, initc-loss 2.4004e+04                    bc_loss 8.2262e+03\n",
      "Epoch 15320, Training-Loss 4.0448e+04, Data-loss 5.9470e+03                  , pde-loss 1.3292e+03, initc-loss 2.5055e+04                    bc_loss 8.1163e+03\n",
      "Epoch 15330, Training-Loss 3.5362e+04, Data-loss 5.1677e+03                  , pde-loss 1.0275e+03, initc-loss 2.3510e+04                    bc_loss 5.6566e+03\n",
      "Epoch 15340, Training-Loss 3.3662e+04, Data-loss 4.5544e+03                  , pde-loss 1.6150e+03, initc-loss 2.3370e+04                    bc_loss 4.1226e+03\n",
      "Epoch 15350, Training-Loss 3.3231e+04, Data-loss 3.9193e+03                  , pde-loss 1.0762e+03, initc-loss 2.2196e+04                    bc_loss 6.0400e+03\n",
      "Epoch 15360, Training-Loss 2.9186e+04, Data-loss 3.2216e+03                  , pde-loss 6.7009e+02, initc-loss 2.0924e+04                    bc_loss 4.3699e+03\n",
      "Epoch 15370, Training-Loss 3.1773e+04, Data-loss 4.1081e+03                  , pde-loss 1.1591e+03, initc-loss 2.1144e+04                    bc_loss 5.3619e+03\n",
      "Epoch 15380, Training-Loss 3.2084e+04, Data-loss 3.6064e+03                  , pde-loss 1.1499e+03, initc-loss 2.2165e+04                    bc_loss 5.1633e+03\n",
      "Epoch 15390, Training-Loss 3.1085e+04, Data-loss 3.2320e+03                  , pde-loss 1.3178e+03, initc-loss 2.0753e+04                    bc_loss 5.7823e+03\n",
      "Epoch 15400, Training-Loss 2.9003e+04, Data-loss 2.5626e+03                  , pde-loss 1.0215e+03, initc-loss 2.1531e+04                    bc_loss 3.8887e+03\n",
      "Epoch 15410, Training-Loss 3.0114e+04, Data-loss 3.7685e+03                  , pde-loss 1.2381e+03, initc-loss 2.1389e+04                    bc_loss 3.7177e+03\n",
      "Epoch 15420, Training-Loss 2.8893e+04, Data-loss 2.5239e+03                  , pde-loss 7.6914e+02, initc-loss 2.1159e+04                    bc_loss 4.4411e+03\n",
      "Epoch 15430, Training-Loss 3.3007e+04, Data-loss 4.4536e+03                  , pde-loss 1.2379e+03, initc-loss 2.0875e+04                    bc_loss 6.4396e+03\n",
      "Epoch 15440, Training-Loss 3.1590e+04, Data-loss 2.7935e+03                  , pde-loss 6.9315e+02, initc-loss 2.1081e+04                    bc_loss 7.0227e+03\n",
      "Epoch 15450, Training-Loss 3.7590e+04, Data-loss 3.5859e+03                  , pde-loss 1.0713e+03, initc-loss 2.3203e+04                    bc_loss 9.7294e+03\n",
      "Epoch 15460, Training-Loss 3.4223e+04, Data-loss 3.7097e+03                  , pde-loss 1.1597e+03, initc-loss 2.2377e+04                    bc_loss 6.9766e+03\n",
      "Epoch 15470, Training-Loss 3.5334e+04, Data-loss 3.4632e+03                  , pde-loss 8.2677e+02, initc-loss 2.2627e+04                    bc_loss 8.4171e+03\n",
      "Epoch 15480, Training-Loss 3.5522e+04, Data-loss 3.8886e+03                  , pde-loss 1.0071e+03, initc-loss 2.4897e+04                    bc_loss 5.7292e+03\n",
      "Epoch 15490, Training-Loss 2.9298e+04, Data-loss 2.9495e+03                  , pde-loss 1.1774e+03, initc-loss 2.1238e+04                    bc_loss 3.9329e+03\n",
      "Epoch 15500, Training-Loss 3.3608e+04, Data-loss 5.0448e+03                  , pde-loss 1.1805e+03, initc-loss 2.2360e+04                    bc_loss 5.0220e+03\n",
      "Epoch 15510, Training-Loss 2.8453e+04, Data-loss 2.7197e+03                  , pde-loss 1.4498e+03, initc-loss 2.0596e+04                    bc_loss 3.6874e+03\n",
      "Epoch 15520, Training-Loss 2.8823e+04, Data-loss 3.8718e+03                  , pde-loss 2.0306e+03, initc-loss 2.0553e+04                    bc_loss 2.3679e+03\n",
      "Epoch 15530, Training-Loss 2.7968e+04, Data-loss 3.2493e+03                  , pde-loss 8.4350e+02, initc-loss 2.0447e+04                    bc_loss 3.4282e+03\n",
      "Epoch 15540, Training-Loss 3.2426e+04, Data-loss 2.8717e+03                  , pde-loss 7.7378e+02, initc-loss 2.0916e+04                    bc_loss 7.8647e+03\n",
      "Epoch 15550, Training-Loss 3.8429e+04, Data-loss 3.6028e+03                  , pde-loss 9.6834e+02, initc-loss 2.4436e+04                    bc_loss 9.4212e+03\n",
      "Epoch 15560, Training-Loss 3.0771e+04, Data-loss 2.9055e+03                  , pde-loss 1.0163e+03, initc-loss 2.1481e+04                    bc_loss 5.3682e+03\n",
      "Epoch 15570, Training-Loss 3.1653e+04, Data-loss 3.6081e+03                  , pde-loss 6.7732e+02, initc-loss 2.0799e+04                    bc_loss 6.5684e+03\n",
      "Epoch 15580, Training-Loss 3.4808e+04, Data-loss 3.5047e+03                  , pde-loss 2.5998e+03, initc-loss 2.1093e+04                    bc_loss 7.6096e+03\n",
      "Epoch 15590, Training-Loss 3.1638e+04, Data-loss 2.5986e+03                  , pde-loss 8.2210e+02, initc-loss 2.4270e+04                    bc_loss 3.9474e+03\n",
      "Epoch 15600, Training-Loss 2.8512e+04, Data-loss 2.4444e+03                  , pde-loss 9.9711e+02, initc-loss 2.1004e+04                    bc_loss 4.0667e+03\n",
      "Epoch 15610, Training-Loss 3.1082e+04, Data-loss 3.5783e+03                  , pde-loss 1.6839e+03, initc-loss 2.0749e+04                    bc_loss 5.0709e+03\n",
      "Epoch 15620, Training-Loss 2.8297e+04, Data-loss 2.2401e+03                  , pde-loss 6.4865e+02, initc-loss 1.9104e+04                    bc_loss 6.3038e+03\n",
      "Epoch 15630, Training-Loss 3.1761e+04, Data-loss 2.8099e+03                  , pde-loss 1.4774e+03, initc-loss 2.0103e+04                    bc_loss 7.3704e+03\n",
      "Epoch 15640, Training-Loss 3.0264e+04, Data-loss 2.0325e+03                  , pde-loss 9.4463e+02, initc-loss 2.1139e+04                    bc_loss 6.1484e+03\n",
      "Epoch 15650, Training-Loss 2.9030e+04, Data-loss 2.5722e+03                  , pde-loss 1.0115e+03, initc-loss 2.0718e+04                    bc_loss 4.7284e+03\n",
      "Epoch 15660, Training-Loss 2.8857e+04, Data-loss 2.8754e+03                  , pde-loss 1.2652e+03, initc-loss 2.0295e+04                    bc_loss 4.4220e+03\n",
      "Epoch 15670, Training-Loss 2.8503e+04, Data-loss 2.1292e+03                  , pde-loss 1.1293e+03, initc-loss 1.9553e+04                    bc_loss 5.6917e+03\n",
      "Epoch 15680, Training-Loss 3.4522e+04, Data-loss 2.2558e+03                  , pde-loss 9.2510e+02, initc-loss 2.0422e+04                    bc_loss 1.0919e+04\n",
      "Epoch 15690, Training-Loss 3.6838e+04, Data-loss 3.5069e+03                  , pde-loss 1.1574e+03, initc-loss 2.2592e+04                    bc_loss 9.5812e+03\n",
      "Epoch 15700, Training-Loss 3.3167e+04, Data-loss 3.2477e+03                  , pde-loss 1.1083e+03, initc-loss 2.2707e+04                    bc_loss 6.1037e+03\n",
      "Epoch 15710, Training-Loss 2.8893e+04, Data-loss 2.4013e+03                  , pde-loss 8.4803e+02, initc-loss 2.0602e+04                    bc_loss 5.0418e+03\n",
      "Epoch 15720, Training-Loss 2.7700e+04, Data-loss 2.7263e+03                  , pde-loss 1.1747e+03, initc-loss 2.0277e+04                    bc_loss 3.5224e+03\n",
      "Epoch 15730, Training-Loss 3.0026e+04, Data-loss 2.7757e+03                  , pde-loss 9.4361e+02, initc-loss 1.9703e+04                    bc_loss 6.6041e+03\n",
      "Epoch 15740, Training-Loss 3.0635e+04, Data-loss 3.1776e+03                  , pde-loss 1.1291e+03, initc-loss 1.9328e+04                    bc_loss 7.0009e+03\n",
      "Epoch 15750, Training-Loss 2.7795e+04, Data-loss 2.1852e+03                  , pde-loss 7.6188e+02, initc-loss 1.9624e+04                    bc_loss 5.2240e+03\n",
      "Epoch 15760, Training-Loss 2.6673e+04, Data-loss 2.8111e+03                  , pde-loss 9.3528e+02, initc-loss 1.9379e+04                    bc_loss 3.5476e+03\n",
      "Epoch 15770, Training-Loss 2.6584e+04, Data-loss 3.0413e+03                  , pde-loss 1.4917e+03, initc-loss 1.8838e+04                    bc_loss 3.2125e+03\n",
      "Epoch 15780, Training-Loss 2.7985e+04, Data-loss 1.8023e+03                  , pde-loss 1.3371e+03, initc-loss 1.9658e+04                    bc_loss 5.1877e+03\n",
      "Epoch 15790, Training-Loss 2.7181e+04, Data-loss 1.8644e+03                  , pde-loss 8.6915e+02, initc-loss 1.8893e+04                    bc_loss 5.5549e+03\n",
      "Epoch 15800, Training-Loss 2.8660e+04, Data-loss 2.5134e+03                  , pde-loss 7.8465e+02, initc-loss 1.9021e+04                    bc_loss 6.3413e+03\n",
      "Epoch 15810, Training-Loss 2.9332e+04, Data-loss 2.6316e+03                  , pde-loss 9.1697e+02, initc-loss 2.0592e+04                    bc_loss 5.1916e+03\n",
      "Epoch 15820, Training-Loss 2.9377e+04, Data-loss 2.3458e+03                  , pde-loss 9.1622e+02, initc-loss 2.1622e+04                    bc_loss 4.4925e+03\n",
      "Epoch 15830, Training-Loss 3.0665e+04, Data-loss 2.1106e+03                  , pde-loss 1.0765e+03, initc-loss 1.9353e+04                    bc_loss 8.1254e+03\n",
      "Epoch 15840, Training-Loss 3.2180e+04, Data-loss 2.1514e+03                  , pde-loss 1.0127e+03, initc-loss 1.9049e+04                    bc_loss 9.9673e+03\n",
      "Epoch 15850, Training-Loss 3.1712e+04, Data-loss 3.3153e+03                  , pde-loss 2.7186e+03, initc-loss 2.1295e+04                    bc_loss 4.3833e+03\n",
      "Epoch 15860, Training-Loss 3.0065e+04, Data-loss 3.5044e+03                  , pde-loss 9.1475e+02, initc-loss 2.0663e+04                    bc_loss 4.9834e+03\n",
      "Epoch 15870, Training-Loss 2.7618e+04, Data-loss 2.4870e+03                  , pde-loss 6.9471e+02, initc-loss 2.0099e+04                    bc_loss 4.3374e+03\n",
      "Epoch 15880, Training-Loss 2.8193e+04, Data-loss 2.0978e+03                  , pde-loss 8.7371e+02, initc-loss 1.9180e+04                    bc_loss 6.0417e+03\n",
      "Epoch 15890, Training-Loss 2.6002e+04, Data-loss 2.4223e+03                  , pde-loss 1.1804e+03, initc-loss 1.8218e+04                    bc_loss 4.1817e+03\n",
      "Epoch 15900, Training-Loss 3.3239e+04, Data-loss 2.5722e+03                  , pde-loss 9.5222e+02, initc-loss 1.9494e+04                    bc_loss 1.0221e+04\n",
      "Epoch 15910, Training-Loss 3.3017e+04, Data-loss 3.4195e+03                  , pde-loss 8.0785e+02, initc-loss 2.0190e+04                    bc_loss 8.5990e+03\n",
      "Epoch 15920, Training-Loss 2.8365e+04, Data-loss 2.9471e+03                  , pde-loss 7.4605e+02, initc-loss 2.0102e+04                    bc_loss 4.5703e+03\n",
      "Epoch 15930, Training-Loss 3.2044e+04, Data-loss 3.1419e+03                  , pde-loss 1.2274e+03, initc-loss 1.9984e+04                    bc_loss 7.6914e+03\n",
      "Epoch 15940, Training-Loss 3.0715e+04, Data-loss 3.5122e+03                  , pde-loss 1.2848e+03, initc-loss 1.9402e+04                    bc_loss 6.5168e+03\n",
      "Epoch 15950, Training-Loss 3.3838e+04, Data-loss 3.1954e+03                  , pde-loss 2.2152e+03, initc-loss 2.1166e+04                    bc_loss 7.2621e+03\n",
      "Epoch 15960, Training-Loss 2.9195e+04, Data-loss 2.6041e+03                  , pde-loss 1.1001e+03, initc-loss 2.0650e+04                    bc_loss 4.8407e+03\n",
      "Epoch 15970, Training-Loss 3.1367e+04, Data-loss 2.7880e+03                  , pde-loss 1.0221e+03, initc-loss 1.9805e+04                    bc_loss 7.7515e+03\n",
      "Epoch 15980, Training-Loss 3.0173e+04, Data-loss 2.6064e+03                  , pde-loss 1.0634e+03, initc-loss 1.9641e+04                    bc_loss 6.8623e+03\n",
      "Epoch 15990, Training-Loss 2.7645e+04, Data-loss 2.1338e+03                  , pde-loss 7.9708e+02, initc-loss 1.9841e+04                    bc_loss 4.8728e+03\n",
      "Epoch 16000, Training-Loss 2.9934e+04, Data-loss 3.0551e+03                  , pde-loss 1.3587e+03, initc-loss 2.0186e+04                    bc_loss 5.3343e+03\n",
      "Epoch 16010, Training-Loss 3.4401e+04, Data-loss 2.4229e+03                  , pde-loss 1.1585e+03, initc-loss 1.9747e+04                    bc_loss 1.1073e+04\n",
      "Epoch 16020, Training-Loss 3.8033e+04, Data-loss 3.3372e+03                  , pde-loss 8.9500e+02, initc-loss 2.0571e+04                    bc_loss 1.3230e+04\n",
      "Epoch 16030, Training-Loss 3.1404e+04, Data-loss 4.4530e+03                  , pde-loss 8.3589e+02, initc-loss 2.1792e+04                    bc_loss 4.3231e+03\n",
      "Epoch 16040, Training-Loss 3.2201e+04, Data-loss 3.5126e+03                  , pde-loss 1.0515e+03, initc-loss 2.1630e+04                    bc_loss 6.0068e+03\n",
      "Epoch 16050, Training-Loss 4.1037e+04, Data-loss 2.3501e+03                  , pde-loss 8.5154e+02, initc-loss 2.0319e+04                    bc_loss 1.7517e+04\n",
      "Epoch 16060, Training-Loss 4.0965e+04, Data-loss 3.2424e+03                  , pde-loss 2.1046e+03, initc-loss 2.0527e+04                    bc_loss 1.5091e+04\n",
      "Epoch 16070, Training-Loss 4.3990e+04, Data-loss 4.2306e+03                  , pde-loss 1.2462e+03, initc-loss 2.1746e+04                    bc_loss 1.6767e+04\n",
      "Epoch 16080, Training-Loss 3.5073e+04, Data-loss 2.7753e+03                  , pde-loss 1.1406e+03, initc-loss 2.1752e+04                    bc_loss 9.4050e+03\n",
      "Epoch 16090, Training-Loss 3.3747e+04, Data-loss 3.0249e+03                  , pde-loss 8.4011e+02, initc-loss 2.4092e+04                    bc_loss 5.7900e+03\n",
      "Epoch 16100, Training-Loss 3.6668e+04, Data-loss 3.6564e+03                  , pde-loss 1.4923e+03, initc-loss 2.1289e+04                    bc_loss 1.0230e+04\n",
      "Epoch 16110, Training-Loss 3.3731e+04, Data-loss 2.6534e+03                  , pde-loss 8.5417e+02, initc-loss 2.0377e+04                    bc_loss 9.8460e+03\n",
      "Epoch 16120, Training-Loss 3.1785e+04, Data-loss 3.1624e+03                  , pde-loss 1.0694e+03, initc-loss 1.9359e+04                    bc_loss 8.1942e+03\n",
      "Epoch 16130, Training-Loss 3.0206e+04, Data-loss 2.9604e+03                  , pde-loss 2.0892e+03, initc-loss 2.0030e+04                    bc_loss 5.1263e+03\n",
      "Epoch 16140, Training-Loss 3.1520e+04, Data-loss 3.0968e+03                  , pde-loss 1.0212e+03, initc-loss 1.9733e+04                    bc_loss 7.6698e+03\n",
      "Epoch 16150, Training-Loss 2.9558e+04, Data-loss 2.5283e+03                  , pde-loss 1.1025e+03, initc-loss 1.9891e+04                    bc_loss 6.0364e+03\n",
      "Epoch 16160, Training-Loss 2.7201e+04, Data-loss 2.3234e+03                  , pde-loss 1.4698e+03, initc-loss 1.7952e+04                    bc_loss 5.4562e+03\n",
      "Epoch 16170, Training-Loss 2.7728e+04, Data-loss 2.8462e+03                  , pde-loss 9.3355e+02, initc-loss 1.8080e+04                    bc_loss 5.8678e+03\n",
      "Epoch 16180, Training-Loss 2.8256e+04, Data-loss 3.1035e+03                  , pde-loss 1.1020e+03, initc-loss 1.7704e+04                    bc_loss 6.3468e+03\n",
      "Epoch 16190, Training-Loss 3.9423e+04, Data-loss 3.1122e+03                  , pde-loss 1.5015e+03, initc-loss 1.8637e+04                    bc_loss 1.6172e+04\n",
      "Epoch 16200, Training-Loss 3.7319e+04, Data-loss 3.3463e+03                  , pde-loss 1.4220e+03, initc-loss 2.1784e+04                    bc_loss 1.0767e+04\n",
      "Epoch 16210, Training-Loss 3.7258e+04, Data-loss 4.8788e+03                  , pde-loss 1.3441e+03, initc-loss 2.3397e+04                    bc_loss 7.6378e+03\n",
      "Epoch 16220, Training-Loss 3.5392e+04, Data-loss 4.6364e+03                  , pde-loss 2.2854e+03, initc-loss 2.3429e+04                    bc_loss 5.0422e+03\n",
      "Epoch 16230, Training-Loss 2.8492e+04, Data-loss 2.7832e+03                  , pde-loss 1.1849e+03, initc-loss 2.1103e+04                    bc_loss 3.4210e+03\n",
      "Epoch 16240, Training-Loss 2.8342e+04, Data-loss 3.6416e+03                  , pde-loss 9.7935e+02, initc-loss 2.0545e+04                    bc_loss 3.1760e+03\n",
      "Epoch 16250, Training-Loss 2.5779e+04, Data-loss 2.9191e+03                  , pde-loss 8.6152e+02, initc-loss 1.9263e+04                    bc_loss 2.7347e+03\n",
      "Epoch 16260, Training-Loss 2.5902e+04, Data-loss 2.0564e+03                  , pde-loss 1.0035e+03, initc-loss 1.8277e+04                    bc_loss 4.5651e+03\n",
      "Epoch 16270, Training-Loss 3.0737e+04, Data-loss 3.5431e+03                  , pde-loss 2.5378e+03, initc-loss 1.9886e+04                    bc_loss 4.7703e+03\n",
      "Epoch 16280, Training-Loss 2.7015e+04, Data-loss 2.0450e+03                  , pde-loss 1.0663e+03, initc-loss 1.8182e+04                    bc_loss 5.7217e+03\n",
      "Epoch 16290, Training-Loss 2.8421e+04, Data-loss 2.4453e+03                  , pde-loss 7.9238e+02, initc-loss 1.9079e+04                    bc_loss 6.1044e+03\n",
      "Epoch 16300, Training-Loss 2.8896e+04, Data-loss 2.4359e+03                  , pde-loss 7.6243e+02, initc-loss 1.9486e+04                    bc_loss 6.2118e+03\n",
      "Epoch 16310, Training-Loss 2.9698e+04, Data-loss 2.1949e+03                  , pde-loss 8.7318e+02, initc-loss 1.9018e+04                    bc_loss 7.6115e+03\n",
      "Epoch 16320, Training-Loss 3.0082e+04, Data-loss 3.4672e+03                  , pde-loss 1.2489e+03, initc-loss 1.7214e+04                    bc_loss 8.1520e+03\n",
      "Epoch 16330, Training-Loss 3.3044e+04, Data-loss 2.2809e+03                  , pde-loss 1.0558e+03, initc-loss 1.8665e+04                    bc_loss 1.1042e+04\n",
      "Epoch 16340, Training-Loss 3.1138e+04, Data-loss 2.5276e+03                  , pde-loss 1.8392e+03, initc-loss 1.9547e+04                    bc_loss 7.2247e+03\n",
      "Epoch 16350, Training-Loss 2.9956e+04, Data-loss 2.9128e+03                  , pde-loss 1.4023e+03, initc-loss 1.9642e+04                    bc_loss 5.9981e+03\n",
      "Epoch 16360, Training-Loss 2.6711e+04, Data-loss 2.0622e+03                  , pde-loss 9.3541e+02, initc-loss 1.9004e+04                    bc_loss 4.7092e+03\n",
      "Epoch 16370, Training-Loss 2.8313e+04, Data-loss 3.0832e+03                  , pde-loss 1.1446e+03, initc-loss 1.8771e+04                    bc_loss 5.3143e+03\n",
      "Epoch 16380, Training-Loss 3.1011e+04, Data-loss 2.7567e+03                  , pde-loss 1.5137e+03, initc-loss 1.8562e+04                    bc_loss 8.1777e+03\n",
      "Epoch 16390, Training-Loss 2.7295e+04, Data-loss 2.3807e+03                  , pde-loss 1.9278e+03, initc-loss 1.7660e+04                    bc_loss 5.3269e+03\n",
      "Epoch 16400, Training-Loss 2.6106e+04, Data-loss 2.3868e+03                  , pde-loss 1.8235e+03, initc-loss 1.8694e+04                    bc_loss 3.2012e+03\n",
      "Epoch 16410, Training-Loss 2.5252e+04, Data-loss 2.6225e+03                  , pde-loss 9.7750e+02, initc-loss 1.8269e+04                    bc_loss 3.3827e+03\n",
      "Epoch 16420, Training-Loss 2.8323e+04, Data-loss 2.4162e+03                  , pde-loss 1.7607e+03, initc-loss 1.8257e+04                    bc_loss 5.8887e+03\n",
      "Epoch 16430, Training-Loss 3.0412e+04, Data-loss 1.8944e+03                  , pde-loss 9.3182e+02, initc-loss 1.9123e+04                    bc_loss 8.4632e+03\n",
      "Epoch 16440, Training-Loss 2.8023e+04, Data-loss 2.8450e+03                  , pde-loss 1.1541e+03, initc-loss 1.8065e+04                    bc_loss 5.9595e+03\n",
      "Epoch 16450, Training-Loss 2.7191e+04, Data-loss 2.4837e+03                  , pde-loss 7.7898e+02, initc-loss 1.7755e+04                    bc_loss 6.1731e+03\n",
      "Epoch 16460, Training-Loss 2.6433e+04, Data-loss 1.9512e+03                  , pde-loss 1.5110e+03, initc-loss 1.7473e+04                    bc_loss 5.4979e+03\n",
      "Epoch 16470, Training-Loss 2.9800e+04, Data-loss 2.1008e+03                  , pde-loss 1.1075e+03, initc-loss 1.8784e+04                    bc_loss 7.8077e+03\n",
      "Epoch 16480, Training-Loss 2.8439e+04, Data-loss 2.5904e+03                  , pde-loss 1.3271e+03, initc-loss 1.8812e+04                    bc_loss 5.7101e+03\n",
      "Epoch 16490, Training-Loss 3.3202e+04, Data-loss 2.1129e+03                  , pde-loss 9.7497e+02, initc-loss 1.8288e+04                    bc_loss 1.1826e+04\n",
      "Epoch 16500, Training-Loss 3.0627e+04, Data-loss 2.5550e+03                  , pde-loss 7.4562e+02, initc-loss 1.8264e+04                    bc_loss 9.0619e+03\n",
      "Epoch 16510, Training-Loss 3.5145e+04, Data-loss 2.7602e+03                  , pde-loss 8.1912e+02, initc-loss 1.9496e+04                    bc_loss 1.2070e+04\n",
      "Epoch 16520, Training-Loss 3.5317e+04, Data-loss 3.7496e+03                  , pde-loss 1.7620e+03, initc-loss 2.1135e+04                    bc_loss 8.6698e+03\n",
      "Epoch 16530, Training-Loss 3.5954e+04, Data-loss 3.3522e+03                  , pde-loss 8.9725e+02, initc-loss 1.9192e+04                    bc_loss 1.2513e+04\n",
      "Epoch 16540, Training-Loss 3.4013e+04, Data-loss 3.2494e+03                  , pde-loss 1.7565e+03, initc-loss 1.9817e+04                    bc_loss 9.1902e+03\n",
      "Epoch 16550, Training-Loss 3.1402e+04, Data-loss 3.8017e+03                  , pde-loss 1.8215e+03, initc-loss 1.9684e+04                    bc_loss 6.0948e+03\n",
      "Epoch 16560, Training-Loss 3.0090e+04, Data-loss 3.1525e+03                  , pde-loss 1.2879e+03, initc-loss 1.9631e+04                    bc_loss 6.0176e+03\n",
      "Epoch 16570, Training-Loss 2.8994e+04, Data-loss 1.8898e+03                  , pde-loss 1.1841e+03, initc-loss 1.9552e+04                    bc_loss 6.3676e+03\n",
      "Epoch 16580, Training-Loss 2.9145e+04, Data-loss 2.3777e+03                  , pde-loss 8.4541e+02, initc-loss 1.8109e+04                    bc_loss 7.8131e+03\n",
      "Epoch 16590, Training-Loss 2.9641e+04, Data-loss 2.1708e+03                  , pde-loss 1.2869e+03, initc-loss 1.8402e+04                    bc_loss 7.7816e+03\n",
      "Epoch 16600, Training-Loss 2.7506e+04, Data-loss 1.9795e+03                  , pde-loss 1.5096e+03, initc-loss 1.8151e+04                    bc_loss 5.8664e+03\n",
      "Epoch 16610, Training-Loss 2.7671e+04, Data-loss 1.9238e+03                  , pde-loss 9.9287e+02, initc-loss 1.8163e+04                    bc_loss 6.5909e+03\n",
      "Epoch 16620, Training-Loss 2.6570e+04, Data-loss 2.3201e+03                  , pde-loss 9.3872e+02, initc-loss 1.7203e+04                    bc_loss 6.1085e+03\n",
      "Epoch 16630, Training-Loss 2.7876e+04, Data-loss 3.0582e+03                  , pde-loss 1.7539e+03, initc-loss 1.7847e+04                    bc_loss 5.2164e+03\n",
      "Epoch 16640, Training-Loss 2.7628e+04, Data-loss 1.7741e+03                  , pde-loss 1.6075e+03, initc-loss 1.7509e+04                    bc_loss 6.7378e+03\n",
      "Epoch 16650, Training-Loss 2.9700e+04, Data-loss 1.9300e+03                  , pde-loss 1.1889e+03, initc-loss 1.8461e+04                    bc_loss 8.1193e+03\n",
      "Epoch 16660, Training-Loss 3.8025e+04, Data-loss 2.1139e+03                  , pde-loss 1.4405e+03, initc-loss 1.9037e+04                    bc_loss 1.5433e+04\n",
      "Epoch 16670, Training-Loss 3.0449e+04, Data-loss 3.5605e+03                  , pde-loss 1.2871e+03, initc-loss 1.8540e+04                    bc_loss 7.0617e+03\n",
      "Epoch 16680, Training-Loss 3.2017e+04, Data-loss 2.9631e+03                  , pde-loss 1.1768e+03, initc-loss 1.9691e+04                    bc_loss 8.1861e+03\n",
      "Epoch 16690, Training-Loss 3.5782e+04, Data-loss 3.0498e+03                  , pde-loss 1.1648e+03, initc-loss 1.9242e+04                    bc_loss 1.2325e+04\n",
      "Epoch 16700, Training-Loss 3.3433e+04, Data-loss 3.3682e+03                  , pde-loss 1.2157e+03, initc-loss 1.9857e+04                    bc_loss 8.9923e+03\n",
      "Epoch 16710, Training-Loss 2.9820e+04, Data-loss 3.2434e+03                  , pde-loss 1.2650e+03, initc-loss 1.9136e+04                    bc_loss 6.1757e+03\n",
      "Epoch 16720, Training-Loss 3.2499e+04, Data-loss 2.8884e+03                  , pde-loss 1.2655e+03, initc-loss 1.8709e+04                    bc_loss 9.6360e+03\n",
      "Epoch 16730, Training-Loss 2.7384e+04, Data-loss 3.0660e+03                  , pde-loss 1.0872e+03, initc-loss 1.9138e+04                    bc_loss 4.0929e+03\n",
      "Epoch 16740, Training-Loss 2.5423e+04, Data-loss 2.2767e+03                  , pde-loss 1.4274e+03, initc-loss 1.8699e+04                    bc_loss 3.0197e+03\n",
      "Epoch 16750, Training-Loss 2.5782e+04, Data-loss 2.0362e+03                  , pde-loss 1.4166e+03, initc-loss 1.8238e+04                    bc_loss 4.0908e+03\n",
      "Epoch 16760, Training-Loss 3.5839e+04, Data-loss 2.3518e+03                  , pde-loss 9.8859e+02, initc-loss 1.7533e+04                    bc_loss 1.4965e+04\n",
      "Epoch 16770, Training-Loss 3.6398e+04, Data-loss 2.9940e+03                  , pde-loss 9.9390e+02, initc-loss 2.1031e+04                    bc_loss 1.1379e+04\n",
      "Epoch 16780, Training-Loss 3.5422e+04, Data-loss 3.4906e+03                  , pde-loss 1.0855e+03, initc-loss 2.1978e+04                    bc_loss 8.8680e+03\n",
      "Epoch 16790, Training-Loss 3.2594e+04, Data-loss 3.4593e+03                  , pde-loss 7.8053e+02, initc-loss 2.2621e+04                    bc_loss 5.7333e+03\n",
      "Epoch 16800, Training-Loss 2.7947e+04, Data-loss 2.5527e+03                  , pde-loss 9.3313e+02, initc-loss 2.1597e+04                    bc_loss 2.8644e+03\n",
      "Epoch 16810, Training-Loss 2.7704e+04, Data-loss 4.2655e+03                  , pde-loss 1.5576e+03, initc-loss 1.9715e+04                    bc_loss 2.1660e+03\n",
      "Epoch 16820, Training-Loss 2.4176e+04, Data-loss 1.5533e+03                  , pde-loss 8.8354e+02, initc-loss 1.8917e+04                    bc_loss 2.8229e+03\n",
      "Epoch 16830, Training-Loss 2.5484e+04, Data-loss 2.1181e+03                  , pde-loss 1.0607e+03, initc-loss 1.9470e+04                    bc_loss 2.8352e+03\n",
      "Epoch 16840, Training-Loss 2.4114e+04, Data-loss 2.0182e+03                  , pde-loss 8.3301e+02, initc-loss 1.6614e+04                    bc_loss 4.6486e+03\n",
      "Epoch 16850, Training-Loss 2.7014e+04, Data-loss 1.7949e+03                  , pde-loss 1.1439e+03, initc-loss 1.7021e+04                    bc_loss 7.0548e+03\n",
      "Epoch 16860, Training-Loss 2.6269e+04, Data-loss 2.3353e+03                  , pde-loss 1.1644e+03, initc-loss 1.7890e+04                    bc_loss 4.8790e+03\n",
      "Epoch 16870, Training-Loss 2.8982e+04, Data-loss 1.7896e+03                  , pde-loss 8.3762e+02, initc-loss 1.8065e+04                    bc_loss 8.2897e+03\n",
      "Epoch 16880, Training-Loss 2.7790e+04, Data-loss 2.7247e+03                  , pde-loss 1.2645e+03, initc-loss 1.8185e+04                    bc_loss 5.6164e+03\n",
      "Epoch 16890, Training-Loss 2.8929e+04, Data-loss 2.0049e+03                  , pde-loss 6.8374e+02, initc-loss 1.7553e+04                    bc_loss 8.6872e+03\n",
      "Epoch 16900, Training-Loss 3.0417e+04, Data-loss 2.3569e+03                  , pde-loss 1.2506e+03, initc-loss 1.8071e+04                    bc_loss 8.7380e+03\n",
      "Epoch 16910, Training-Loss 4.2298e+04, Data-loss 2.3342e+03                  , pde-loss 1.6347e+03, initc-loss 1.9969e+04                    bc_loss 1.8360e+04\n",
      "Epoch 16920, Training-Loss 3.0392e+04, Data-loss 2.4540e+03                  , pde-loss 1.1426e+03, initc-loss 1.9028e+04                    bc_loss 7.7680e+03\n",
      "Epoch 16930, Training-Loss 3.0307e+04, Data-loss 2.4796e+03                  , pde-loss 1.4062e+03, initc-loss 2.0387e+04                    bc_loss 6.0341e+03\n",
      "Epoch 16940, Training-Loss 3.0752e+04, Data-loss 3.4525e+03                  , pde-loss 3.3463e+03, initc-loss 1.9070e+04                    bc_loss 4.8834e+03\n",
      "Epoch 16950, Training-Loss 2.5436e+04, Data-loss 2.8419e+03                  , pde-loss 1.7082e+03, initc-loss 1.8194e+04                    bc_loss 2.6922e+03\n",
      "Epoch 16960, Training-Loss 2.5031e+04, Data-loss 2.5017e+03                  , pde-loss 1.1198e+03, initc-loss 1.6751e+04                    bc_loss 4.6587e+03\n",
      "Epoch 16970, Training-Loss 2.4507e+04, Data-loss 1.8996e+03                  , pde-loss 9.5124e+02, initc-loss 1.6493e+04                    bc_loss 5.1630e+03\n",
      "Epoch 16980, Training-Loss 2.9307e+04, Data-loss 1.7059e+03                  , pde-loss 1.1599e+03, initc-loss 1.7176e+04                    bc_loss 9.2652e+03\n",
      "Epoch 16990, Training-Loss 3.0078e+04, Data-loss 1.8787e+03                  , pde-loss 1.1426e+03, initc-loss 1.9347e+04                    bc_loss 7.7097e+03\n",
      "Epoch 17000, Training-Loss 3.5831e+04, Data-loss 3.2114e+03                  , pde-loss 1.4265e+03, initc-loss 1.8525e+04                    bc_loss 1.2668e+04\n",
      "Epoch 17010, Training-Loss 3.6816e+04, Data-loss 3.6236e+03                  , pde-loss 1.9204e+03, initc-loss 1.9110e+04                    bc_loss 1.2162e+04\n",
      "Epoch 17020, Training-Loss 3.3088e+04, Data-loss 3.5123e+03                  , pde-loss 1.6198e+03, initc-loss 1.9981e+04                    bc_loss 7.9749e+03\n",
      "Epoch 17030, Training-Loss 3.0014e+04, Data-loss 3.8676e+03                  , pde-loss 1.9057e+03, initc-loss 1.9609e+04                    bc_loss 4.6318e+03\n",
      "Epoch 17040, Training-Loss 2.7074e+04, Data-loss 2.3363e+03                  , pde-loss 8.6975e+02, initc-loss 1.8363e+04                    bc_loss 5.5048e+03\n",
      "Epoch 17050, Training-Loss 2.6140e+04, Data-loss 2.1081e+03                  , pde-loss 1.3803e+03, initc-loss 1.6895e+04                    bc_loss 5.7563e+03\n",
      "Epoch 17060, Training-Loss 2.4652e+04, Data-loss 2.0288e+03                  , pde-loss 8.7472e+02, initc-loss 1.7162e+04                    bc_loss 4.5868e+03\n",
      "Epoch 17070, Training-Loss 2.4741e+04, Data-loss 2.9612e+03                  , pde-loss 1.1906e+03, initc-loss 1.7422e+04                    bc_loss 3.1673e+03\n",
      "Epoch 17080, Training-Loss 2.7134e+04, Data-loss 1.3924e+03                  , pde-loss 1.0846e+03, initc-loss 1.9136e+04                    bc_loss 5.5213e+03\n",
      "Epoch 17090, Training-Loss 2.4525e+04, Data-loss 1.5021e+03                  , pde-loss 1.7837e+03, initc-loss 1.7262e+04                    bc_loss 3.9775e+03\n",
      "Epoch 17100, Training-Loss 2.9111e+04, Data-loss 2.2360e+03                  , pde-loss 1.4185e+03, initc-loss 1.7490e+04                    bc_loss 7.9668e+03\n",
      "Epoch 17110, Training-Loss 2.7788e+04, Data-loss 2.3886e+03                  , pde-loss 1.1148e+03, initc-loss 1.6729e+04                    bc_loss 7.5555e+03\n",
      "Epoch 17120, Training-Loss 2.9178e+04, Data-loss 2.5012e+03                  , pde-loss 1.1635e+03, initc-loss 1.7076e+04                    bc_loss 8.4368e+03\n",
      "Epoch 17130, Training-Loss 3.2779e+04, Data-loss 2.7268e+03                  , pde-loss 7.6241e+02, initc-loss 1.8611e+04                    bc_loss 1.0679e+04\n",
      "Epoch 17140, Training-Loss 3.0285e+04, Data-loss 2.6460e+03                  , pde-loss 1.2010e+03, initc-loss 1.9769e+04                    bc_loss 6.6683e+03\n",
      "Epoch 17150, Training-Loss 2.9993e+04, Data-loss 2.8950e+03                  , pde-loss 1.2198e+03, initc-loss 1.8564e+04                    bc_loss 7.3139e+03\n",
      "Epoch 17160, Training-Loss 3.0386e+04, Data-loss 2.7149e+03                  , pde-loss 1.3753e+03, initc-loss 1.8973e+04                    bc_loss 7.3230e+03\n",
      "Epoch 17170, Training-Loss 2.5989e+04, Data-loss 1.9957e+03                  , pde-loss 1.2176e+03, initc-loss 1.8445e+04                    bc_loss 4.3303e+03\n",
      "Epoch 17180, Training-Loss 2.9801e+04, Data-loss 3.9681e+03                  , pde-loss 1.9192e+03, initc-loss 1.7288e+04                    bc_loss 6.6252e+03\n",
      "Epoch 17190, Training-Loss 3.1318e+04, Data-loss 3.8440e+03                  , pde-loss 1.5183e+03, initc-loss 1.8664e+04                    bc_loss 7.2912e+03\n",
      "Epoch 17200, Training-Loss 2.9887e+04, Data-loss 2.1790e+03                  , pde-loss 1.9727e+03, initc-loss 1.8653e+04                    bc_loss 7.0823e+03\n",
      "Epoch 17210, Training-Loss 2.9083e+04, Data-loss 2.5342e+03                  , pde-loss 8.7227e+02, initc-loss 1.8126e+04                    bc_loss 7.5506e+03\n",
      "Epoch 17220, Training-Loss 2.9700e+04, Data-loss 2.4578e+03                  , pde-loss 1.0581e+03, initc-loss 1.8704e+04                    bc_loss 7.4798e+03\n",
      "Epoch 17230, Training-Loss 2.7858e+04, Data-loss 2.3360e+03                  , pde-loss 1.4287e+03, initc-loss 1.8855e+04                    bc_loss 5.2382e+03\n",
      "Epoch 17240, Training-Loss 2.7659e+04, Data-loss 2.9759e+03                  , pde-loss 1.2206e+03, initc-loss 1.7178e+04                    bc_loss 6.2843e+03\n",
      "Epoch 17250, Training-Loss 3.1808e+04, Data-loss 2.1734e+03                  , pde-loss 8.8723e+02, initc-loss 1.8517e+04                    bc_loss 1.0230e+04\n",
      "Epoch 17260, Training-Loss 3.1239e+04, Data-loss 2.2622e+03                  , pde-loss 1.3504e+03, initc-loss 1.7328e+04                    bc_loss 1.0298e+04\n",
      "Epoch 17270, Training-Loss 2.8815e+04, Data-loss 2.9784e+03                  , pde-loss 1.1729e+03, initc-loss 1.8673e+04                    bc_loss 5.9904e+03\n",
      "Epoch 17280, Training-Loss 2.8631e+04, Data-loss 2.3063e+03                  , pde-loss 6.8556e+02, initc-loss 1.9206e+04                    bc_loss 6.4331e+03\n",
      "Epoch 17290, Training-Loss 2.8246e+04, Data-loss 1.9826e+03                  , pde-loss 2.1249e+03, initc-loss 1.8470e+04                    bc_loss 5.6687e+03\n",
      "Epoch 17300, Training-Loss 2.6917e+04, Data-loss 2.5140e+03                  , pde-loss 8.2122e+02, initc-loss 1.6922e+04                    bc_loss 6.6600e+03\n",
      "Epoch 17310, Training-Loss 3.1945e+04, Data-loss 2.6284e+03                  , pde-loss 2.2391e+03, initc-loss 1.7433e+04                    bc_loss 9.6448e+03\n",
      "Epoch 17320, Training-Loss 3.1221e+04, Data-loss 1.7569e+03                  , pde-loss 1.0352e+03, initc-loss 1.9981e+04                    bc_loss 8.4479e+03\n",
      "Epoch 17330, Training-Loss 3.0487e+04, Data-loss 2.8190e+03                  , pde-loss 1.3389e+03, initc-loss 2.0317e+04                    bc_loss 6.0119e+03\n",
      "Epoch 17340, Training-Loss 2.8697e+04, Data-loss 2.9071e+03                  , pde-loss 1.2073e+03, initc-loss 2.0444e+04                    bc_loss 4.1385e+03\n",
      "Epoch 17350, Training-Loss 2.4937e+04, Data-loss 1.7040e+03                  , pde-loss 1.2436e+03, initc-loss 1.7966e+04                    bc_loss 4.0241e+03\n",
      "Epoch 17360, Training-Loss 2.5846e+04, Data-loss 2.2162e+03                  , pde-loss 1.7469e+03, initc-loss 1.6918e+04                    bc_loss 4.9654e+03\n",
      "Epoch 17370, Training-Loss 2.4250e+04, Data-loss 1.7682e+03                  , pde-loss 1.7164e+03, initc-loss 1.6012e+04                    bc_loss 4.7533e+03\n",
      "Epoch 17380, Training-Loss 2.9520e+04, Data-loss 2.0094e+03                  , pde-loss 9.0715e+02, initc-loss 1.6748e+04                    bc_loss 9.8553e+03\n",
      "Epoch 17390, Training-Loss 3.0568e+04, Data-loss 2.7169e+03                  , pde-loss 1.3351e+03, initc-loss 1.7791e+04                    bc_loss 8.7251e+03\n",
      "Epoch 17400, Training-Loss 2.6161e+04, Data-loss 2.1252e+03                  , pde-loss 9.1817e+02, initc-loss 1.8331e+04                    bc_loss 4.7866e+03\n",
      "Epoch 17410, Training-Loss 2.5907e+04, Data-loss 2.0184e+03                  , pde-loss 1.2013e+03, initc-loss 1.7858e+04                    bc_loss 4.8292e+03\n",
      "Epoch 17420, Training-Loss 2.5454e+04, Data-loss 1.6442e+03                  , pde-loss 1.6202e+03, initc-loss 1.7830e+04                    bc_loss 4.3599e+03\n",
      "Epoch 17430, Training-Loss 2.7412e+04, Data-loss 3.7594e+03                  , pde-loss 2.4149e+03, initc-loss 1.6866e+04                    bc_loss 4.3717e+03\n",
      "Epoch 17440, Training-Loss 3.0708e+04, Data-loss 2.3762e+03                  , pde-loss 1.3313e+03, initc-loss 1.8487e+04                    bc_loss 8.5140e+03\n",
      "Epoch 17450, Training-Loss 3.6666e+04, Data-loss 1.6462e+03                  , pde-loss 5.2409e+02, initc-loss 1.6517e+04                    bc_loss 1.7979e+04\n",
      "Epoch 17460, Training-Loss 3.1195e+04, Data-loss 2.3872e+03                  , pde-loss 1.2155e+03, initc-loss 1.8916e+04                    bc_loss 8.6759e+03\n",
      "Epoch 17470, Training-Loss 3.3770e+04, Data-loss 3.3360e+03                  , pde-loss 1.5342e+03, initc-loss 1.9556e+04                    bc_loss 9.3433e+03\n",
      "Epoch 17480, Training-Loss 3.1680e+04, Data-loss 2.8289e+03                  , pde-loss 7.5501e+02, initc-loss 2.0283e+04                    bc_loss 7.8136e+03\n",
      "Epoch 17490, Training-Loss 3.5802e+04, Data-loss 3.9818e+03                  , pde-loss 2.9651e+03, initc-loss 2.0208e+04                    bc_loss 8.6474e+03\n",
      "Epoch 17500, Training-Loss 3.1358e+04, Data-loss 2.9629e+03                  , pde-loss 9.3853e+02, initc-loss 1.9758e+04                    bc_loss 7.6980e+03\n",
      "Epoch 17510, Training-Loss 3.1147e+04, Data-loss 3.6917e+03                  , pde-loss 1.1147e+03, initc-loss 1.9852e+04                    bc_loss 6.4883e+03\n",
      "Epoch 17520, Training-Loss 2.8135e+04, Data-loss 2.1462e+03                  , pde-loss 7.6212e+02, initc-loss 1.9607e+04                    bc_loss 5.6198e+03\n",
      "Epoch 17530, Training-Loss 2.6353e+04, Data-loss 3.4000e+03                  , pde-loss 1.9603e+03, initc-loss 1.8171e+04                    bc_loss 2.8216e+03\n",
      "Epoch 17540, Training-Loss 2.5743e+04, Data-loss 2.1102e+03                  , pde-loss 1.9954e+03, initc-loss 1.8127e+04                    bc_loss 3.5104e+03\n",
      "Epoch 17550, Training-Loss 2.8932e+04, Data-loss 2.5956e+03                  , pde-loss 1.0128e+03, initc-loss 1.7393e+04                    bc_loss 7.9309e+03\n",
      "Epoch 17560, Training-Loss 4.9069e+04, Data-loss 2.3978e+03                  , pde-loss 7.6882e+02, initc-loss 1.8771e+04                    bc_loss 2.7131e+04\n",
      "Epoch 17570, Training-Loss 4.7393e+04, Data-loss 3.5231e+03                  , pde-loss 1.2025e+03, initc-loss 2.5264e+04                    bc_loss 1.7403e+04\n",
      "Epoch 17580, Training-Loss 3.9451e+04, Data-loss 4.7148e+03                  , pde-loss 8.3893e+02, initc-loss 2.3435e+04                    bc_loss 1.0462e+04\n",
      "Epoch 17590, Training-Loss 3.7893e+04, Data-loss 4.9324e+03                  , pde-loss 2.2979e+03, initc-loss 2.3787e+04                    bc_loss 6.8763e+03\n",
      "Epoch 17600, Training-Loss 2.9400e+04, Data-loss 2.8197e+03                  , pde-loss 1.2967e+03, initc-loss 2.0262e+04                    bc_loss 5.0211e+03\n",
      "Epoch 17610, Training-Loss 2.7991e+04, Data-loss 2.4207e+03                  , pde-loss 1.8274e+03, initc-loss 2.0302e+04                    bc_loss 3.4412e+03\n",
      "Epoch 17620, Training-Loss 2.5253e+04, Data-loss 2.2195e+03                  , pde-loss 1.0447e+03, initc-loss 1.8417e+04                    bc_loss 3.5715e+03\n",
      "Epoch 17630, Training-Loss 3.1709e+04, Data-loss 2.2927e+03                  , pde-loss 9.6728e+02, initc-loss 1.8765e+04                    bc_loss 9.6835e+03\n",
      "Epoch 17640, Training-Loss 3.4838e+04, Data-loss 2.4295e+03                  , pde-loss 7.7128e+02, initc-loss 1.7690e+04                    bc_loss 1.3947e+04\n",
      "Epoch 17650, Training-Loss 3.6848e+04, Data-loss 2.6734e+03                  , pde-loss 1.2329e+03, initc-loss 2.1565e+04                    bc_loss 1.1376e+04\n",
      "Epoch 17660, Training-Loss 5.4875e+04, Data-loss 4.2432e+03                  , pde-loss 1.9322e+03, initc-loss 1.9536e+04                    bc_loss 2.9164e+04\n",
      "Epoch 17670, Training-Loss 8.5599e+04, Data-loss 3.6200e+03                  , pde-loss 1.2239e+03, initc-loss 2.3430e+04                    bc_loss 5.7325e+04\n",
      "Epoch 17680, Training-Loss 5.6320e+04, Data-loss 4.9780e+03                  , pde-loss 2.8294e+03, initc-loss 2.5511e+04                    bc_loss 2.3001e+04\n",
      "Epoch 17690, Training-Loss 5.1431e+04, Data-loss 6.0878e+03                  , pde-loss 3.4167e+03, initc-loss 2.6152e+04                    bc_loss 1.5775e+04\n",
      "Epoch 17700, Training-Loss 4.8597e+04, Data-loss 5.4399e+03                  , pde-loss 1.2788e+03, initc-loss 2.5234e+04                    bc_loss 1.6644e+04\n",
      "Epoch 17710, Training-Loss 3.6895e+04, Data-loss 5.1290e+03                  , pde-loss 1.4352e+03, initc-loss 2.4457e+04                    bc_loss 5.8739e+03\n",
      "Epoch 17720, Training-Loss 3.5614e+04, Data-loss 4.1190e+03                  , pde-loss 1.5705e+03, initc-loss 2.2034e+04                    bc_loss 7.8901e+03\n",
      "Epoch 17730, Training-Loss 2.9853e+04, Data-loss 4.0939e+03                  , pde-loss 1.0236e+03, initc-loss 2.0157e+04                    bc_loss 4.5788e+03\n",
      "Epoch 17740, Training-Loss 2.9656e+04, Data-loss 3.1487e+03                  , pde-loss 1.5924e+03, initc-loss 2.0746e+04                    bc_loss 4.1689e+03\n",
      "Epoch 17750, Training-Loss 2.9181e+04, Data-loss 3.2024e+03                  , pde-loss 1.3022e+03, initc-loss 2.0519e+04                    bc_loss 4.1575e+03\n",
      "Epoch 17760, Training-Loss 2.7596e+04, Data-loss 2.3103e+03                  , pde-loss 2.2898e+03, initc-loss 1.7625e+04                    bc_loss 5.3712e+03\n",
      "Epoch 17770, Training-Loss 3.2439e+04, Data-loss 2.3259e+03                  , pde-loss 1.5938e+03, initc-loss 1.9352e+04                    bc_loss 9.1671e+03\n",
      "Epoch 17780, Training-Loss 2.6129e+04, Data-loss 2.4988e+03                  , pde-loss 1.0508e+03, initc-loss 1.7457e+04                    bc_loss 5.1222e+03\n",
      "Epoch 17790, Training-Loss 2.8803e+04, Data-loss 3.0911e+03                  , pde-loss 1.0031e+03, initc-loss 1.8393e+04                    bc_loss 6.3158e+03\n",
      "Epoch 17800, Training-Loss 2.8084e+04, Data-loss 2.8054e+03                  , pde-loss 1.6051e+03, initc-loss 1.8230e+04                    bc_loss 5.4433e+03\n",
      "Epoch 17810, Training-Loss 2.7283e+04, Data-loss 2.5663e+03                  , pde-loss 1.5841e+03, initc-loss 1.8976e+04                    bc_loss 4.1570e+03\n",
      "Epoch 17820, Training-Loss 2.5945e+04, Data-loss 1.2734e+03                  , pde-loss 1.4023e+03, initc-loss 1.6738e+04                    bc_loss 6.5310e+03\n",
      "Epoch 17830, Training-Loss 2.6156e+04, Data-loss 1.3442e+03                  , pde-loss 1.2172e+03, initc-loss 1.7227e+04                    bc_loss 6.3669e+03\n",
      "Epoch 17840, Training-Loss 3.1173e+04, Data-loss 2.3890e+03                  , pde-loss 1.1499e+03, initc-loss 1.6621e+04                    bc_loss 1.1013e+04\n",
      "Epoch 17850, Training-Loss 3.8894e+04, Data-loss 2.5866e+03                  , pde-loss 1.0768e+03, initc-loss 1.9120e+04                    bc_loss 1.6111e+04\n",
      "Epoch 17860, Training-Loss 4.3014e+04, Data-loss 4.4382e+03                  , pde-loss 2.4197e+03, initc-loss 2.1508e+04                    bc_loss 1.4648e+04\n",
      "Epoch 17870, Training-Loss 3.6643e+04, Data-loss 4.1455e+03                  , pde-loss 1.8763e+03, initc-loss 2.1277e+04                    bc_loss 9.3443e+03\n",
      "Epoch 17880, Training-Loss 3.7853e+04, Data-loss 2.9726e+03                  , pde-loss 1.3392e+03, initc-loss 2.0566e+04                    bc_loss 1.2975e+04\n",
      "Epoch 17890, Training-Loss 3.0222e+04, Data-loss 2.3803e+03                  , pde-loss 1.2961e+03, initc-loss 2.0347e+04                    bc_loss 6.1995e+03\n",
      "Epoch 17900, Training-Loss 2.9808e+04, Data-loss 3.0065e+03                  , pde-loss 1.2213e+03, initc-loss 1.9771e+04                    bc_loss 5.8086e+03\n",
      "Epoch 17910, Training-Loss 2.5994e+04, Data-loss 2.0719e+03                  , pde-loss 9.6533e+02, initc-loss 1.7893e+04                    bc_loss 5.0636e+03\n",
      "Epoch 17920, Training-Loss 2.5646e+04, Data-loss 1.8695e+03                  , pde-loss 1.1388e+03, initc-loss 1.7799e+04                    bc_loss 4.8393e+03\n",
      "Epoch 17930, Training-Loss 2.6409e+04, Data-loss 2.1323e+03                  , pde-loss 9.1073e+02, initc-loss 1.6071e+04                    bc_loss 7.2948e+03\n",
      "Epoch 17940, Training-Loss 3.3963e+04, Data-loss 2.2297e+03                  , pde-loss 1.1328e+03, initc-loss 1.7004e+04                    bc_loss 1.3597e+04\n",
      "Epoch 17950, Training-Loss 3.2788e+04, Data-loss 2.4331e+03                  , pde-loss 9.1068e+02, initc-loss 1.8713e+04                    bc_loss 1.0731e+04\n",
      "Epoch 17960, Training-Loss 2.5301e+04, Data-loss 1.4701e+03                  , pde-loss 9.3892e+02, initc-loss 1.7539e+04                    bc_loss 5.3530e+03\n",
      "Epoch 17970, Training-Loss 3.2661e+04, Data-loss 1.3806e+03                  , pde-loss 1.0085e+03, initc-loss 1.7792e+04                    bc_loss 1.2480e+04\n",
      "Epoch 17980, Training-Loss 3.6294e+04, Data-loss 2.1249e+03                  , pde-loss 1.5798e+03, initc-loss 1.7920e+04                    bc_loss 1.4669e+04\n",
      "Epoch 17990, Training-Loss 3.3322e+04, Data-loss 2.1090e+03                  , pde-loss 1.3519e+03, initc-loss 1.8369e+04                    bc_loss 1.1492e+04\n",
      "Epoch 18000, Training-Loss 3.1155e+04, Data-loss 2.1782e+03                  , pde-loss 1.1090e+03, initc-loss 1.9330e+04                    bc_loss 8.5374e+03\n",
      "Epoch 18010, Training-Loss 2.9206e+04, Data-loss 3.0345e+03                  , pde-loss 1.2228e+03, initc-loss 1.9224e+04                    bc_loss 5.7243e+03\n",
      "Epoch 18020, Training-Loss 3.4419e+04, Data-loss 2.4861e+03                  , pde-loss 8.6085e+02, initc-loss 1.7977e+04                    bc_loss 1.3095e+04\n",
      "Epoch 18030, Training-Loss 3.1751e+04, Data-loss 2.0071e+03                  , pde-loss 7.6246e+02, initc-loss 1.6648e+04                    bc_loss 1.2334e+04\n",
      "Epoch 18040, Training-Loss 4.1140e+04, Data-loss 2.1942e+03                  , pde-loss 1.5513e+03, initc-loss 1.8607e+04                    bc_loss 1.8788e+04\n",
      "Epoch 18050, Training-Loss 6.7596e+04, Data-loss 3.8124e+03                  , pde-loss 1.4903e+03, initc-loss 2.0736e+04                    bc_loss 4.1557e+04\n",
      "Epoch 18060, Training-Loss 3.6925e+04, Data-loss 2.9090e+03                  , pde-loss 1.1289e+03, initc-loss 2.0348e+04                    bc_loss 1.2540e+04\n",
      "Epoch 18070, Training-Loss 2.7562e+04, Data-loss 2.8181e+03                  , pde-loss 8.7836e+02, initc-loss 1.9127e+04                    bc_loss 4.7387e+03\n",
      "Epoch 18080, Training-Loss 2.9170e+04, Data-loss 3.3823e+03                  , pde-loss 8.4117e+02, initc-loss 2.1983e+04                    bc_loss 2.9632e+03\n",
      "Epoch 18090, Training-Loss 2.4303e+04, Data-loss 2.8956e+03                  , pde-loss 6.1101e+02, initc-loss 1.7733e+04                    bc_loss 3.0631e+03\n",
      "Epoch 18100, Training-Loss 2.4937e+04, Data-loss 3.1750e+03                  , pde-loss 2.3802e+03, initc-loss 1.6474e+04                    bc_loss 2.9085e+03\n",
      "Epoch 18110, Training-Loss 2.2223e+04, Data-loss 1.7829e+03                  , pde-loss 7.0505e+02, initc-loss 1.7097e+04                    bc_loss 2.6385e+03\n",
      "Epoch 18120, Training-Loss 3.2536e+04, Data-loss 2.3291e+03                  , pde-loss 1.2181e+03, initc-loss 1.6378e+04                    bc_loss 1.2611e+04\n",
      "Epoch 18130, Training-Loss 6.1150e+04, Data-loss 1.8491e+03                  , pde-loss 1.7102e+03, initc-loss 1.7648e+04                    bc_loss 3.9943e+04\n",
      "Epoch 18140, Training-Loss 5.0282e+04, Data-loss 3.1475e+03                  , pde-loss 1.2764e+03, initc-loss 2.0697e+04                    bc_loss 2.5161e+04\n",
      "Epoch 18150, Training-Loss 4.3765e+04, Data-loss 5.0905e+03                  , pde-loss 1.3006e+03, initc-loss 2.2803e+04                    bc_loss 1.4571e+04\n",
      "Epoch 18160, Training-Loss 4.0286e+04, Data-loss 3.9541e+03                  , pde-loss 1.5032e+03, initc-loss 2.3003e+04                    bc_loss 1.1825e+04\n",
      "Epoch 18170, Training-Loss 3.7305e+04, Data-loss 4.9992e+03                  , pde-loss 1.4885e+03, initc-loss 2.1431e+04                    bc_loss 9.3863e+03\n",
      "Epoch 18180, Training-Loss 3.0877e+04, Data-loss 3.4677e+03                  , pde-loss 1.1539e+03, initc-loss 2.2807e+04                    bc_loss 3.4489e+03\n",
      "Epoch 18190, Training-Loss 2.6455e+04, Data-loss 1.9581e+03                  , pde-loss 1.1720e+03, initc-loss 1.9279e+04                    bc_loss 4.0454e+03\n",
      "Epoch 18200, Training-Loss 2.4579e+04, Data-loss 2.1269e+03                  , pde-loss 1.0138e+03, initc-loss 1.8381e+04                    bc_loss 3.0566e+03\n",
      "Epoch 18210, Training-Loss 2.5488e+04, Data-loss 2.2578e+03                  , pde-loss 1.4527e+03, initc-loss 1.8702e+04                    bc_loss 3.0747e+03\n",
      "Epoch 18220, Training-Loss 2.7297e+04, Data-loss 2.3638e+03                  , pde-loss 1.0191e+03, initc-loss 1.7272e+04                    bc_loss 6.6414e+03\n",
      "Epoch 18230, Training-Loss 3.1733e+04, Data-loss 1.9362e+03                  , pde-loss 9.2955e+02, initc-loss 1.6405e+04                    bc_loss 1.2463e+04\n",
      "Epoch 18240, Training-Loss 5.4911e+04, Data-loss 3.1524e+03                  , pde-loss 1.9412e+03, initc-loss 1.8246e+04                    bc_loss 3.1572e+04\n",
      "Epoch 18250, Training-Loss 3.9676e+04, Data-loss 3.1872e+03                  , pde-loss 7.2665e+02, initc-loss 2.1330e+04                    bc_loss 1.4432e+04\n",
      "Epoch 18260, Training-Loss 3.5180e+04, Data-loss 3.9497e+03                  , pde-loss 1.1356e+03, initc-loss 2.3257e+04                    bc_loss 6.8383e+03\n",
      "Epoch 18270, Training-Loss 3.1801e+04, Data-loss 3.9068e+03                  , pde-loss 8.5155e+02, initc-loss 2.1052e+04                    bc_loss 5.9904e+03\n",
      "Epoch 18280, Training-Loss 3.3369e+04, Data-loss 3.3727e+03                  , pde-loss 3.6820e+03, initc-loss 2.1248e+04                    bc_loss 5.0664e+03\n",
      "Epoch 18290, Training-Loss 2.7659e+04, Data-loss 3.1673e+03                  , pde-loss 1.2844e+03, initc-loss 1.9371e+04                    bc_loss 3.8369e+03\n",
      "Epoch 18300, Training-Loss 2.7927e+04, Data-loss 1.9986e+03                  , pde-loss 1.8684e+03, initc-loss 1.9334e+04                    bc_loss 4.7258e+03\n",
      "Epoch 18310, Training-Loss 2.7808e+04, Data-loss 1.5731e+03                  , pde-loss 1.1054e+03, initc-loss 1.7891e+04                    bc_loss 7.2381e+03\n",
      "Epoch 18320, Training-Loss 2.6723e+04, Data-loss 2.6361e+03                  , pde-loss 7.3191e+02, initc-loss 1.7369e+04                    bc_loss 5.9863e+03\n",
      "Epoch 18330, Training-Loss 2.8101e+04, Data-loss 3.9077e+03                  , pde-loss 2.8212e+03, initc-loss 1.6255e+04                    bc_loss 5.1165e+03\n",
      "Epoch 18340, Training-Loss 2.7350e+04, Data-loss 2.0329e+03                  , pde-loss 9.9155e+02, initc-loss 1.5929e+04                    bc_loss 8.3959e+03\n",
      "Epoch 18350, Training-Loss 2.6969e+04, Data-loss 2.2852e+03                  , pde-loss 1.0321e+03, initc-loss 1.6623e+04                    bc_loss 7.0292e+03\n",
      "Epoch 18360, Training-Loss 3.0331e+04, Data-loss 1.4911e+03                  , pde-loss 6.7042e+02, initc-loss 1.8230e+04                    bc_loss 9.9401e+03\n",
      "Epoch 18370, Training-Loss 3.0799e+04, Data-loss 2.0597e+03                  , pde-loss 1.0889e+03, initc-loss 1.7489e+04                    bc_loss 1.0161e+04\n",
      "Epoch 18380, Training-Loss 3.9599e+04, Data-loss 2.7198e+03                  , pde-loss 7.2827e+02, initc-loss 1.8863e+04                    bc_loss 1.7288e+04\n",
      "Epoch 18390, Training-Loss 3.5099e+04, Data-loss 3.1994e+03                  , pde-loss 9.8729e+02, initc-loss 1.8106e+04                    bc_loss 1.2806e+04\n",
      "Epoch 18400, Training-Loss 2.7729e+04, Data-loss 2.2959e+03                  , pde-loss 9.7850e+02, initc-loss 1.9018e+04                    bc_loss 5.4367e+03\n",
      "Epoch 18410, Training-Loss 2.5488e+04, Data-loss 2.0631e+03                  , pde-loss 1.0579e+03, initc-loss 1.8177e+04                    bc_loss 4.1903e+03\n",
      "Epoch 18420, Training-Loss 2.5295e+04, Data-loss 2.0146e+03                  , pde-loss 1.3425e+03, initc-loss 1.8275e+04                    bc_loss 3.6624e+03\n",
      "Epoch 18430, Training-Loss 2.4735e+04, Data-loss 1.8551e+03                  , pde-loss 7.7839e+02, initc-loss 1.7044e+04                    bc_loss 5.0574e+03\n",
      "Epoch 18440, Training-Loss 2.3121e+04, Data-loss 1.7241e+03                  , pde-loss 1.0191e+03, initc-loss 1.6094e+04                    bc_loss 4.2847e+03\n",
      "Epoch 18450, Training-Loss 2.9847e+04, Data-loss 2.4148e+03                  , pde-loss 3.4043e+03, initc-loss 1.5252e+04                    bc_loss 8.7757e+03\n",
      "Epoch 18460, Training-Loss 2.3316e+04, Data-loss 1.9378e+03                  , pde-loss 7.5717e+02, initc-loss 1.6394e+04                    bc_loss 4.2274e+03\n",
      "Epoch 18470, Training-Loss 2.2547e+04, Data-loss 1.7450e+03                  , pde-loss 6.7409e+02, initc-loss 1.6053e+04                    bc_loss 4.0751e+03\n",
      "Epoch 18480, Training-Loss 2.2810e+04, Data-loss 1.6224e+03                  , pde-loss 8.1406e+02, initc-loss 1.6324e+04                    bc_loss 4.0491e+03\n",
      "Epoch 18490, Training-Loss 2.8702e+04, Data-loss 2.9308e+03                  , pde-loss 2.7637e+03, initc-loss 1.6089e+04                    bc_loss 6.9185e+03\n",
      "Epoch 18500, Training-Loss 3.0155e+04, Data-loss 1.7684e+03                  , pde-loss 9.9411e+02, initc-loss 1.6527e+04                    bc_loss 1.0866e+04\n",
      "Epoch 18510, Training-Loss 4.1672e+04, Data-loss 2.1699e+03                  , pde-loss 1.3432e+03, initc-loss 1.6828e+04                    bc_loss 2.1332e+04\n",
      "Epoch 18520, Training-Loss 4.1163e+04, Data-loss 2.2755e+03                  , pde-loss 9.7204e+02, initc-loss 1.8703e+04                    bc_loss 1.9212e+04\n",
      "Epoch 18530, Training-Loss 4.3858e+04, Data-loss 3.1030e+03                  , pde-loss 7.7699e+02, initc-loss 1.8872e+04                    bc_loss 2.1106e+04\n",
      "Epoch 18540, Training-Loss 2.9107e+04, Data-loss 2.3900e+03                  , pde-loss 1.0006e+03, initc-loss 1.9071e+04                    bc_loss 6.6451e+03\n",
      "Epoch 18550, Training-Loss 2.8681e+04, Data-loss 2.5044e+03                  , pde-loss 9.7264e+02, initc-loss 1.9176e+04                    bc_loss 6.0272e+03\n",
      "Epoch 18560, Training-Loss 2.6870e+04, Data-loss 2.5825e+03                  , pde-loss 1.1469e+03, initc-loss 1.7991e+04                    bc_loss 5.1494e+03\n",
      "Epoch 18570, Training-Loss 2.8857e+04, Data-loss 3.8325e+03                  , pde-loss 3.0142e+03, initc-loss 1.7541e+04                    bc_loss 4.4695e+03\n",
      "Epoch 18580, Training-Loss 2.6780e+04, Data-loss 2.8800e+03                  , pde-loss 1.2673e+03, initc-loss 1.7829e+04                    bc_loss 4.8036e+03\n",
      "Epoch 18590, Training-Loss 2.4397e+04, Data-loss 2.9684e+03                  , pde-loss 8.9400e+02, initc-loss 1.7327e+04                    bc_loss 3.2069e+03\n",
      "Epoch 18600, Training-Loss 2.4093e+04, Data-loss 3.7951e+03                  , pde-loss 2.2064e+03, initc-loss 1.6050e+04                    bc_loss 2.0410e+03\n",
      "Epoch 18610, Training-Loss 2.3655e+04, Data-loss 1.5388e+03                  , pde-loss 9.2798e+02, initc-loss 1.5255e+04                    bc_loss 5.9330e+03\n",
      "Epoch 18620, Training-Loss 2.1758e+04, Data-loss 1.4412e+03                  , pde-loss 6.4110e+02, initc-loss 1.5883e+04                    bc_loss 3.7927e+03\n",
      "Epoch 18630, Training-Loss 2.9232e+04, Data-loss 1.6674e+03                  , pde-loss 1.0531e+03, initc-loss 1.5901e+04                    bc_loss 1.0610e+04\n",
      "Epoch 18640, Training-Loss 3.3519e+04, Data-loss 2.7702e+03                  , pde-loss 1.1775e+03, initc-loss 1.8543e+04                    bc_loss 1.1028e+04\n",
      "Epoch 18650, Training-Loss 3.4589e+04, Data-loss 2.6993e+03                  , pde-loss 1.1486e+03, initc-loss 1.8715e+04                    bc_loss 1.2026e+04\n",
      "Epoch 18660, Training-Loss 3.2670e+04, Data-loss 3.2402e+03                  , pde-loss 9.4048e+02, initc-loss 1.9295e+04                    bc_loss 9.1951e+03\n",
      "Epoch 18670, Training-Loss 2.5281e+04, Data-loss 2.1943e+03                  , pde-loss 1.1587e+03, initc-loss 1.7862e+04                    bc_loss 4.0656e+03\n",
      "Epoch 18680, Training-Loss 2.4106e+04, Data-loss 2.4272e+03                  , pde-loss 1.6142e+03, initc-loss 1.6468e+04                    bc_loss 3.5964e+03\n",
      "Epoch 18690, Training-Loss 2.3878e+04, Data-loss 1.8583e+03                  , pde-loss 9.2133e+02, initc-loss 1.5938e+04                    bc_loss 5.1611e+03\n",
      "Epoch 18700, Training-Loss 2.6664e+04, Data-loss 1.4622e+03                  , pde-loss 1.1518e+03, initc-loss 1.6524e+04                    bc_loss 7.5262e+03\n",
      "Epoch 18710, Training-Loss 2.6118e+04, Data-loss 1.8618e+03                  , pde-loss 1.0722e+03, initc-loss 1.7480e+04                    bc_loss 5.7039e+03\n",
      "Epoch 18720, Training-Loss 2.6441e+04, Data-loss 2.3008e+03                  , pde-loss 1.9635e+03, initc-loss 1.7631e+04                    bc_loss 4.5459e+03\n",
      "Epoch 18730, Training-Loss 2.3282e+04, Data-loss 1.4860e+03                  , pde-loss 9.0711e+02, initc-loss 1.5538e+04                    bc_loss 5.3509e+03\n",
      "Epoch 18740, Training-Loss 2.2722e+04, Data-loss 1.9228e+03                  , pde-loss 1.3120e+03, initc-loss 1.5466e+04                    bc_loss 4.0216e+03\n",
      "Epoch 18750, Training-Loss 2.3438e+04, Data-loss 1.1792e+03                  , pde-loss 7.1448e+02, initc-loss 1.6179e+04                    bc_loss 5.3654e+03\n",
      "Epoch 18760, Training-Loss 3.2657e+04, Data-loss 1.8149e+03                  , pde-loss 8.9352e+02, initc-loss 1.6529e+04                    bc_loss 1.3420e+04\n",
      "Epoch 18770, Training-Loss 3.3911e+04, Data-loss 2.7100e+03                  , pde-loss 1.3135e+03, initc-loss 1.9143e+04                    bc_loss 1.0745e+04\n",
      "Epoch 18780, Training-Loss 3.4590e+04, Data-loss 2.7695e+03                  , pde-loss 1.0739e+03, initc-loss 1.8916e+04                    bc_loss 1.1830e+04\n",
      "Epoch 18790, Training-Loss 2.6800e+04, Data-loss 2.4560e+03                  , pde-loss 1.0812e+03, initc-loss 1.8376e+04                    bc_loss 4.8870e+03\n",
      "Epoch 18800, Training-Loss 2.7459e+04, Data-loss 2.5998e+03                  , pde-loss 1.1418e+03, initc-loss 1.7856e+04                    bc_loss 5.8612e+03\n",
      "Epoch 18810, Training-Loss 2.3416e+04, Data-loss 1.7172e+03                  , pde-loss 9.8431e+02, initc-loss 1.7457e+04                    bc_loss 3.2569e+03\n",
      "Epoch 18820, Training-Loss 2.3420e+04, Data-loss 2.2181e+03                  , pde-loss 1.3677e+03, initc-loss 1.5810e+04                    bc_loss 4.0241e+03\n",
      "Epoch 18830, Training-Loss 2.2736e+04, Data-loss 1.6572e+03                  , pde-loss 9.6594e+02, initc-loss 1.5436e+04                    bc_loss 4.6775e+03\n",
      "Epoch 18840, Training-Loss 2.2958e+04, Data-loss 1.5631e+03                  , pde-loss 6.9255e+02, initc-loss 1.5640e+04                    bc_loss 5.0620e+03\n",
      "Epoch 18850, Training-Loss 2.9144e+04, Data-loss 1.6732e+03                  , pde-loss 1.0862e+03, initc-loss 1.5587e+04                    bc_loss 1.0798e+04\n",
      "Epoch 18860, Training-Loss 3.4498e+04, Data-loss 3.0765e+03                  , pde-loss 1.3301e+03, initc-loss 1.6509e+04                    bc_loss 1.3582e+04\n",
      "Epoch 18870, Training-Loss 3.3836e+04, Data-loss 2.2034e+03                  , pde-loss 1.4582e+03, initc-loss 1.8383e+04                    bc_loss 1.1791e+04\n",
      "Epoch 18880, Training-Loss 3.1894e+04, Data-loss 3.3491e+03                  , pde-loss 2.1512e+03, initc-loss 1.7649e+04                    bc_loss 8.7450e+03\n",
      "Epoch 18890, Training-Loss 3.2149e+04, Data-loss 2.1397e+03                  , pde-loss 1.0253e+03, initc-loss 1.8289e+04                    bc_loss 1.0695e+04\n",
      "Epoch 18900, Training-Loss 3.6004e+04, Data-loss 3.9919e+03                  , pde-loss 1.9319e+03, initc-loss 1.8933e+04                    bc_loss 1.1148e+04\n",
      "Epoch 18910, Training-Loss 2.7878e+04, Data-loss 2.7863e+03                  , pde-loss 1.7260e+03, initc-loss 1.8664e+04                    bc_loss 4.7010e+03\n",
      "Epoch 18920, Training-Loss 2.6359e+04, Data-loss 1.7407e+03                  , pde-loss 8.5758e+02, initc-loss 1.8034e+04                    bc_loss 5.7268e+03\n",
      "Epoch 18930, Training-Loss 2.3058e+04, Data-loss 1.4103e+03                  , pde-loss 8.6552e+02, initc-loss 1.7124e+04                    bc_loss 3.6578e+03\n",
      "Epoch 18940, Training-Loss 2.9535e+04, Data-loss 2.1150e+03                  , pde-loss 1.2073e+03, initc-loss 1.8277e+04                    bc_loss 7.9361e+03\n",
      "Epoch 18950, Training-Loss 3.2957e+04, Data-loss 1.4523e+03                  , pde-loss 9.9278e+02, initc-loss 1.7567e+04                    bc_loss 1.2945e+04\n",
      "Epoch 18960, Training-Loss 2.7833e+04, Data-loss 1.9678e+03                  , pde-loss 8.4607e+02, initc-loss 1.8207e+04                    bc_loss 6.8125e+03\n",
      "Epoch 18970, Training-Loss 2.8848e+04, Data-loss 2.1976e+03                  , pde-loss 1.5434e+03, initc-loss 1.6816e+04                    bc_loss 8.2913e+03\n",
      "Epoch 18980, Training-Loss 2.8309e+04, Data-loss 2.6077e+03                  , pde-loss 1.2106e+03, initc-loss 1.6943e+04                    bc_loss 7.5480e+03\n",
      "Epoch 18990, Training-Loss 2.7910e+04, Data-loss 3.4227e+03                  , pde-loss 9.8018e+02, initc-loss 1.6606e+04                    bc_loss 6.9019e+03\n",
      "Epoch 19000, Training-Loss 3.0595e+04, Data-loss 2.5388e+03                  , pde-loss 1.0522e+03, initc-loss 1.6159e+04                    bc_loss 1.0846e+04\n",
      "Epoch 19010, Training-Loss 2.8234e+04, Data-loss 1.5084e+03                  , pde-loss 1.1177e+03, initc-loss 1.9111e+04                    bc_loss 6.4965e+03\n",
      "Epoch 19020, Training-Loss 2.7074e+04, Data-loss 1.8516e+03                  , pde-loss 1.0621e+03, initc-loss 1.7277e+04                    bc_loss 6.8838e+03\n",
      "Epoch 19030, Training-Loss 2.7833e+04, Data-loss 5.0639e+03                  , pde-loss 1.2731e+03, initc-loss 1.5943e+04                    bc_loss 5.5531e+03\n",
      "Epoch 19040, Training-Loss 2.4755e+04, Data-loss 2.3419e+03                  , pde-loss 9.1537e+02, initc-loss 1.6731e+04                    bc_loss 4.7668e+03\n",
      "Epoch 19050, Training-Loss 2.7942e+04, Data-loss 1.6081e+03                  , pde-loss 2.2262e+03, initc-loss 1.5742e+04                    bc_loss 8.3647e+03\n",
      "Epoch 19060, Training-Loss 2.5994e+04, Data-loss 1.4555e+03                  , pde-loss 8.5646e+02, initc-loss 1.5839e+04                    bc_loss 7.8425e+03\n",
      "Epoch 19070, Training-Loss 3.0667e+04, Data-loss 1.6824e+03                  , pde-loss 1.0420e+03, initc-loss 2.0756e+04                    bc_loss 7.1868e+03\n",
      "Epoch 19080, Training-Loss 2.5632e+04, Data-loss 1.9849e+03                  , pde-loss 8.8349e+02, initc-loss 1.6425e+04                    bc_loss 6.3390e+03\n",
      "Epoch 19090, Training-Loss 2.5330e+04, Data-loss 1.2992e+03                  , pde-loss 1.0167e+03, initc-loss 1.5831e+04                    bc_loss 7.1839e+03\n",
      "Epoch 19100, Training-Loss 2.6044e+04, Data-loss 3.1036e+03                  , pde-loss 1.2574e+03, initc-loss 1.6818e+04                    bc_loss 4.8645e+03\n",
      "Epoch 19110, Training-Loss 2.6497e+04, Data-loss 2.1779e+03                  , pde-loss 1.1613e+03, initc-loss 1.6014e+04                    bc_loss 7.1433e+03\n",
      "Epoch 19120, Training-Loss 2.4443e+04, Data-loss 1.7874e+03                  , pde-loss 8.1105e+02, initc-loss 1.5485e+04                    bc_loss 6.3596e+03\n",
      "Epoch 19130, Training-Loss 2.3609e+04, Data-loss 1.7452e+03                  , pde-loss 9.7792e+02, initc-loss 1.5330e+04                    bc_loss 5.5558e+03\n",
      "Epoch 19140, Training-Loss 2.3036e+04, Data-loss 1.0632e+03                  , pde-loss 1.1785e+03, initc-loss 1.5874e+04                    bc_loss 4.9204e+03\n",
      "Epoch 19150, Training-Loss 2.4122e+04, Data-loss 1.3084e+03                  , pde-loss 1.0126e+03, initc-loss 1.7025e+04                    bc_loss 4.7757e+03\n",
      "Epoch 19160, Training-Loss 2.4943e+04, Data-loss 2.4272e+03                  , pde-loss 1.4540e+03, initc-loss 1.5883e+04                    bc_loss 5.1781e+03\n",
      "Epoch 19170, Training-Loss 2.4414e+04, Data-loss 1.8139e+03                  , pde-loss 1.2077e+03, initc-loss 1.6097e+04                    bc_loss 5.2958e+03\n",
      "Epoch 19180, Training-Loss 2.7359e+04, Data-loss 2.8209e+03                  , pde-loss 1.5492e+03, initc-loss 1.5396e+04                    bc_loss 7.5927e+03\n",
      "Epoch 19190, Training-Loss 2.4179e+04, Data-loss 1.7958e+03                  , pde-loss 1.1126e+03, initc-loss 1.5377e+04                    bc_loss 5.8936e+03\n",
      "Epoch 19200, Training-Loss 3.7508e+04, Data-loss 2.0351e+03                  , pde-loss 1.2007e+03, initc-loss 1.6679e+04                    bc_loss 1.7593e+04\n",
      "Epoch 19210, Training-Loss 3.5378e+04, Data-loss 4.7286e+03                  , pde-loss 2.6176e+03, initc-loss 1.8854e+04                    bc_loss 9.1776e+03\n",
      "Epoch 19220, Training-Loss 4.7690e+04, Data-loss 4.6094e+03                  , pde-loss 1.8180e+03, initc-loss 2.0916e+04                    bc_loss 2.0347e+04\n",
      "Epoch 19230, Training-Loss 3.4725e+04, Data-loss 3.6060e+03                  , pde-loss 1.2918e+03, initc-loss 1.8475e+04                    bc_loss 1.1353e+04\n",
      "Epoch 19240, Training-Loss 2.9794e+04, Data-loss 1.7850e+03                  , pde-loss 9.3259e+02, initc-loss 1.7309e+04                    bc_loss 9.7674e+03\n",
      "Epoch 19250, Training-Loss 3.3238e+04, Data-loss 2.2149e+03                  , pde-loss 8.4709e+02, initc-loss 1.7796e+04                    bc_loss 1.2381e+04\n",
      "Epoch 19260, Training-Loss 2.7597e+04, Data-loss 2.1852e+03                  , pde-loss 7.0059e+02, initc-loss 1.8996e+04                    bc_loss 5.7152e+03\n",
      "Epoch 19270, Training-Loss 3.0350e+04, Data-loss 1.9839e+03                  , pde-loss 8.8697e+02, initc-loss 1.7718e+04                    bc_loss 9.7607e+03\n",
      "Epoch 19280, Training-Loss 3.5009e+04, Data-loss 3.3751e+03                  , pde-loss 1.6115e+03, initc-loss 1.6818e+04                    bc_loss 1.3204e+04\n",
      "Epoch 19290, Training-Loss 3.4626e+04, Data-loss 2.2095e+03                  , pde-loss 7.8900e+02, initc-loss 1.7740e+04                    bc_loss 1.3888e+04\n",
      "Epoch 19300, Training-Loss 3.7974e+04, Data-loss 1.9359e+03                  , pde-loss 8.6596e+02, initc-loss 1.9171e+04                    bc_loss 1.6001e+04\n",
      "Epoch 19310, Training-Loss 3.9131e+04, Data-loss 2.9255e+03                  , pde-loss 1.7563e+03, initc-loss 1.9963e+04                    bc_loss 1.4487e+04\n",
      "Epoch 19320, Training-Loss 3.4923e+04, Data-loss 2.9996e+03                  , pde-loss 2.3680e+03, initc-loss 1.9653e+04                    bc_loss 9.9024e+03\n",
      "Epoch 19330, Training-Loss 2.8639e+04, Data-loss 3.0990e+03                  , pde-loss 1.0884e+03, initc-loss 1.8969e+04                    bc_loss 5.4819e+03\n",
      "Epoch 19340, Training-Loss 2.5864e+04, Data-loss 1.7338e+03                  , pde-loss 6.1097e+02, initc-loss 1.7875e+04                    bc_loss 5.6446e+03\n",
      "Epoch 19350, Training-Loss 2.9106e+04, Data-loss 2.0422e+03                  , pde-loss 1.0138e+03, initc-loss 1.7715e+04                    bc_loss 8.3354e+03\n",
      "Epoch 19360, Training-Loss 2.6755e+04, Data-loss 2.2653e+03                  , pde-loss 1.2227e+03, initc-loss 1.6217e+04                    bc_loss 7.0503e+03\n",
      "Epoch 19370, Training-Loss 3.3549e+04, Data-loss 1.6916e+03                  , pde-loss 1.3484e+03, initc-loss 1.7714e+04                    bc_loss 1.2795e+04\n",
      "Epoch 19380, Training-Loss 3.7331e+04, Data-loss 2.2379e+03                  , pde-loss 1.2077e+03, initc-loss 1.8947e+04                    bc_loss 1.4938e+04\n",
      "Epoch 19390, Training-Loss 6.5231e+04, Data-loss 3.2532e+03                  , pde-loss 1.1517e+03, initc-loss 1.8410e+04                    bc_loss 4.2416e+04\n",
      "Epoch 19400, Training-Loss 3.9117e+04, Data-loss 2.6892e+03                  , pde-loss 1.6709e+03, initc-loss 1.9098e+04                    bc_loss 1.5659e+04\n",
      "Epoch 19410, Training-Loss 3.3261e+04, Data-loss 3.4282e+03                  , pde-loss 1.1539e+03, initc-loss 2.0803e+04                    bc_loss 7.8753e+03\n",
      "Epoch 19420, Training-Loss 3.9220e+04, Data-loss 2.8407e+03                  , pde-loss 1.4396e+03, initc-loss 1.8805e+04                    bc_loss 1.6135e+04\n",
      "Epoch 19430, Training-Loss 3.2272e+04, Data-loss 2.0744e+03                  , pde-loss 1.1197e+03, initc-loss 1.8424e+04                    bc_loss 1.0654e+04\n",
      "Epoch 19440, Training-Loss 3.1299e+04, Data-loss 1.8204e+03                  , pde-loss 8.2941e+02, initc-loss 1.7783e+04                    bc_loss 1.0866e+04\n",
      "Epoch 19450, Training-Loss 3.8324e+04, Data-loss 4.6529e+03                  , pde-loss 3.9515e+03, initc-loss 1.8927e+04                    bc_loss 1.0792e+04\n",
      "Epoch 19460, Training-Loss 2.9827e+04, Data-loss 2.4425e+03                  , pde-loss 2.0163e+03, initc-loss 1.7620e+04                    bc_loss 7.7481e+03\n",
      "Epoch 19470, Training-Loss 5.2667e+04, Data-loss 2.2661e+03                  , pde-loss 1.5727e+03, initc-loss 1.7942e+04                    bc_loss 3.0886e+04\n",
      "Epoch 19480, Training-Loss 6.0686e+04, Data-loss 4.2233e+03                  , pde-loss 1.0693e+03, initc-loss 1.9167e+04                    bc_loss 3.6226e+04\n",
      "Epoch 19490, Training-Loss 3.9401e+04, Data-loss 3.1575e+03                  , pde-loss 1.1885e+03, initc-loss 2.1296e+04                    bc_loss 1.3758e+04\n",
      "Epoch 19500, Training-Loss 3.6779e+04, Data-loss 5.5883e+03                  , pde-loss 2.0814e+03, initc-loss 2.1356e+04                    bc_loss 7.7529e+03\n",
      "Epoch 19510, Training-Loss 2.9859e+04, Data-loss 2.8561e+03                  , pde-loss 1.3898e+03, initc-loss 2.0070e+04                    bc_loss 5.5430e+03\n",
      "Epoch 19520, Training-Loss 2.6445e+04, Data-loss 1.7360e+03                  , pde-loss 8.8943e+02, initc-loss 1.9493e+04                    bc_loss 4.3267e+03\n",
      "Epoch 19530, Training-Loss 2.6086e+04, Data-loss 2.6197e+03                  , pde-loss 9.2483e+02, initc-loss 1.8335e+04                    bc_loss 4.2060e+03\n",
      "Epoch 19540, Training-Loss 2.4549e+04, Data-loss 1.6586e+03                  , pde-loss 1.1119e+03, initc-loss 1.7859e+04                    bc_loss 3.9197e+03\n",
      "Epoch 19550, Training-Loss 2.4277e+04, Data-loss 1.6872e+03                  , pde-loss 7.9467e+02, initc-loss 1.7576e+04                    bc_loss 4.2189e+03\n",
      "Epoch 19560, Training-Loss 2.8729e+04, Data-loss 3.9573e+03                  , pde-loss 1.2027e+03, initc-loss 1.6123e+04                    bc_loss 7.4460e+03\n",
      "Epoch 19570, Training-Loss 2.6016e+04, Data-loss 1.7782e+03                  , pde-loss 6.3825e+02, initc-loss 1.7143e+04                    bc_loss 6.4567e+03\n",
      "Epoch 19580, Training-Loss 2.5690e+04, Data-loss 1.7503e+03                  , pde-loss 9.5297e+02, initc-loss 1.7291e+04                    bc_loss 5.6956e+03\n",
      "Epoch 19590, Training-Loss 2.6537e+04, Data-loss 2.3858e+03                  , pde-loss 2.1100e+03, initc-loss 1.7468e+04                    bc_loss 4.5727e+03\n",
      "Epoch 19600, Training-Loss 3.9532e+04, Data-loss 3.0927e+03                  , pde-loss 3.6637e+03, initc-loss 1.6916e+04                    bc_loss 1.5860e+04\n",
      "Epoch 19610, Training-Loss 3.6708e+04, Data-loss 1.9425e+03                  , pde-loss 6.6609e+02, initc-loss 1.8605e+04                    bc_loss 1.5495e+04\n",
      "Epoch 19620, Training-Loss 3.3714e+04, Data-loss 2.5076e+03                  , pde-loss 8.3705e+02, initc-loss 1.8880e+04                    bc_loss 1.1489e+04\n",
      "Epoch 19630, Training-Loss 2.6606e+04, Data-loss 2.0126e+03                  , pde-loss 6.7830e+02, initc-loss 1.9146e+04                    bc_loss 4.7695e+03\n",
      "Epoch 19640, Training-Loss 2.5174e+04, Data-loss 1.2596e+03                  , pde-loss 8.8557e+02, initc-loss 1.6528e+04                    bc_loss 6.5010e+03\n",
      "Epoch 19650, Training-Loss 3.9755e+04, Data-loss 1.6547e+03                  , pde-loss 1.0027e+03, initc-loss 1.8075e+04                    bc_loss 1.9023e+04\n",
      "Epoch 19660, Training-Loss 3.8983e+04, Data-loss 1.7110e+03                  , pde-loss 9.1058e+02, initc-loss 1.7462e+04                    bc_loss 1.8900e+04\n",
      "Epoch 19670, Training-Loss 4.2070e+04, Data-loss 3.4092e+03                  , pde-loss 1.4616e+03, initc-loss 1.9431e+04                    bc_loss 1.7767e+04\n",
      "Epoch 19680, Training-Loss 3.3530e+04, Data-loss 3.0519e+03                  , pde-loss 1.4208e+03, initc-loss 2.0961e+04                    bc_loss 8.0963e+03\n",
      "Epoch 19690, Training-Loss 3.0470e+04, Data-loss 2.5431e+03                  , pde-loss 1.1416e+03, initc-loss 1.8879e+04                    bc_loss 7.9068e+03\n",
      "Epoch 19700, Training-Loss 2.5826e+04, Data-loss 2.1064e+03                  , pde-loss 9.8565e+02, initc-loss 1.7673e+04                    bc_loss 5.0611e+03\n",
      "Epoch 19710, Training-Loss 2.8896e+04, Data-loss 2.4236e+03                  , pde-loss 1.2462e+03, initc-loss 1.7986e+04                    bc_loss 7.2395e+03\n",
      "Epoch 19720, Training-Loss 2.4348e+04, Data-loss 1.8759e+03                  , pde-loss 6.7272e+02, initc-loss 1.7971e+04                    bc_loss 3.8284e+03\n",
      "Epoch 19730, Training-Loss 2.4721e+04, Data-loss 1.9336e+03                  , pde-loss 1.4079e+03, initc-loss 1.6950e+04                    bc_loss 4.4297e+03\n",
      "Epoch 19740, Training-Loss 2.1217e+04, Data-loss 1.4957e+03                  , pde-loss 9.8556e+02, initc-loss 1.5151e+04                    bc_loss 3.5853e+03\n",
      "Epoch 19750, Training-Loss 2.5377e+04, Data-loss 1.7993e+03                  , pde-loss 1.3324e+03, initc-loss 1.5609e+04                    bc_loss 6.6364e+03\n",
      "Epoch 19760, Training-Loss 3.2206e+04, Data-loss 1.5024e+03                  , pde-loss 8.7335e+02, initc-loss 1.4696e+04                    bc_loss 1.5134e+04\n",
      "Epoch 19770, Training-Loss 2.5241e+04, Data-loss 1.9447e+03                  , pde-loss 1.3971e+03, initc-loss 1.6062e+04                    bc_loss 5.8375e+03\n",
      "Epoch 19780, Training-Loss 4.1883e+04, Data-loss 2.9159e+03                  , pde-loss 1.1103e+03, initc-loss 1.8733e+04                    bc_loss 1.9124e+04\n",
      "Epoch 19790, Training-Loss 3.8669e+04, Data-loss 1.8486e+03                  , pde-loss 1.3802e+03, initc-loss 1.7799e+04                    bc_loss 1.7642e+04\n",
      "Epoch 19800, Training-Loss 3.1740e+04, Data-loss 2.9651e+03                  , pde-loss 1.0839e+03, initc-loss 1.8704e+04                    bc_loss 8.9861e+03\n",
      "Epoch 19810, Training-Loss 2.6479e+04, Data-loss 2.2184e+03                  , pde-loss 1.0311e+03, initc-loss 1.8053e+04                    bc_loss 5.1766e+03\n",
      "Epoch 19820, Training-Loss 2.6744e+04, Data-loss 3.2986e+03                  , pde-loss 1.4227e+03, initc-loss 1.7396e+04                    bc_loss 4.6263e+03\n",
      "Epoch 19830, Training-Loss 2.1664e+04, Data-loss 1.4288e+03                  , pde-loss 1.1594e+03, initc-loss 1.6553e+04                    bc_loss 2.5238e+03\n",
      "Epoch 19840, Training-Loss 2.1492e+04, Data-loss 1.1792e+03                  , pde-loss 6.7795e+02, initc-loss 1.5788e+04                    bc_loss 3.8468e+03\n",
      "Epoch 19850, Training-Loss 2.2839e+04, Data-loss 1.6878e+03                  , pde-loss 1.1787e+03, initc-loss 1.4603e+04                    bc_loss 5.3691e+03\n",
      "Epoch 19860, Training-Loss 2.7450e+04, Data-loss 1.2380e+03                  , pde-loss 7.3304e+02, initc-loss 1.5278e+04                    bc_loss 1.0201e+04\n",
      "Epoch 19870, Training-Loss 2.6974e+04, Data-loss 1.8166e+03                  , pde-loss 9.4574e+02, initc-loss 1.6603e+04                    bc_loss 7.6096e+03\n",
      "Epoch 19880, Training-Loss 4.2587e+04, Data-loss 2.2692e+03                  , pde-loss 8.8151e+02, initc-loss 1.6957e+04                    bc_loss 2.2479e+04\n",
      "Epoch 19890, Training-Loss 8.9847e+04, Data-loss 2.6914e+03                  , pde-loss 1.9378e+03, initc-loss 1.8210e+04                    bc_loss 6.7008e+04\n",
      "Epoch 19900, Training-Loss 4.7041e+04, Data-loss 3.6885e+03                  , pde-loss 1.0575e+03, initc-loss 2.1959e+04                    bc_loss 2.0336e+04\n",
      "Epoch 19910, Training-Loss 3.8172e+04, Data-loss 3.8791e+03                  , pde-loss 2.0122e+03, initc-loss 2.4649e+04                    bc_loss 7.6311e+03\n",
      "Epoch 19920, Training-Loss 3.5618e+04, Data-loss 5.1044e+03                  , pde-loss 1.8418e+03, initc-loss 2.3025e+04                    bc_loss 5.6470e+03\n",
      "Epoch 19930, Training-Loss 2.9289e+04, Data-loss 3.2740e+03                  , pde-loss 1.1054e+03, initc-loss 2.0835e+04                    bc_loss 4.0750e+03\n",
      "Epoch 19940, Training-Loss 2.9843e+04, Data-loss 3.8139e+03                  , pde-loss 1.4849e+03, initc-loss 2.1691e+04                    bc_loss 2.8533e+03\n",
      "Epoch 19950, Training-Loss 2.4574e+04, Data-loss 2.1815e+03                  , pde-loss 9.6102e+02, initc-loss 1.8804e+04                    bc_loss 2.6276e+03\n",
      "Epoch 19960, Training-Loss 2.2593e+04, Data-loss 2.2349e+03                  , pde-loss 1.6224e+03, initc-loss 1.7086e+04                    bc_loss 1.6488e+03\n",
      "Epoch 19970, Training-Loss 2.4520e+04, Data-loss 1.8496e+03                  , pde-loss 1.4291e+03, initc-loss 1.7772e+04                    bc_loss 3.4693e+03\n",
      "Epoch 19980, Training-Loss 2.7627e+04, Data-loss 3.2034e+03                  , pde-loss 1.8541e+03, initc-loss 1.6535e+04                    bc_loss 6.0346e+03\n",
      "Epoch 19990, Training-Loss 3.9021e+04, Data-loss 2.0573e+03                  , pde-loss 1.2167e+03, initc-loss 1.6572e+04                    bc_loss 1.9175e+04\n",
      "Epoch 20000, Training-Loss 3.0840e+04, Data-loss 2.4206e+03                  , pde-loss 1.2558e+03, initc-loss 1.6895e+04                    bc_loss 1.0268e+04\n",
      "Epoch 20010, Training-Loss 2.9105e+04, Data-loss 1.8989e+03                  , pde-loss 1.0886e+03, initc-loss 1.7229e+04                    bc_loss 8.8882e+03\n",
      "Epoch 20020, Training-Loss 3.3591e+04, Data-loss 2.7940e+03                  , pde-loss 9.4213e+02, initc-loss 1.7475e+04                    bc_loss 1.2380e+04\n",
      "Epoch 20030, Training-Loss 3.8600e+04, Data-loss 3.2111e+03                  , pde-loss 2.1775e+03, initc-loss 1.8112e+04                    bc_loss 1.5099e+04\n",
      "Epoch 20040, Training-Loss 3.5573e+04, Data-loss 2.6633e+03                  , pde-loss 1.3804e+03, initc-loss 1.8040e+04                    bc_loss 1.3489e+04\n",
      "Epoch 20050, Training-Loss 3.7803e+04, Data-loss 3.7008e+03                  , pde-loss 2.3035e+03, initc-loss 1.9745e+04                    bc_loss 1.2054e+04\n",
      "Epoch 20060, Training-Loss 2.7750e+04, Data-loss 2.4030e+03                  , pde-loss 1.0756e+03, initc-loss 1.7941e+04                    bc_loss 6.3303e+03\n",
      "Epoch 20070, Training-Loss 2.5798e+04, Data-loss 2.3581e+03                  , pde-loss 1.0780e+03, initc-loss 1.8036e+04                    bc_loss 4.3262e+03\n",
      "Epoch 20080, Training-Loss 2.4309e+04, Data-loss 2.6599e+03                  , pde-loss 1.2070e+03, initc-loss 1.7388e+04                    bc_loss 3.0539e+03\n",
      "Epoch 20090, Training-Loss 2.2071e+04, Data-loss 1.8231e+03                  , pde-loss 1.0509e+03, initc-loss 1.6443e+04                    bc_loss 2.7540e+03\n",
      "Epoch 20100, Training-Loss 2.2531e+04, Data-loss 1.5526e+03                  , pde-loss 1.3643e+03, initc-loss 1.6565e+04                    bc_loss 3.0488e+03\n",
      "Epoch 20110, Training-Loss 2.4179e+04, Data-loss 1.5014e+03                  , pde-loss 1.0767e+03, initc-loss 1.4792e+04                    bc_loss 6.8096e+03\n",
      "Epoch 20120, Training-Loss 2.7756e+04, Data-loss 1.9254e+03                  , pde-loss 1.2287e+03, initc-loss 1.5403e+04                    bc_loss 9.1994e+03\n",
      "Epoch 20130, Training-Loss 2.4522e+04, Data-loss 1.6491e+03                  , pde-loss 1.0159e+03, initc-loss 1.6378e+04                    bc_loss 5.4788e+03\n",
      "Epoch 20140, Training-Loss 4.2077e+04, Data-loss 1.9116e+03                  , pde-loss 8.9778e+02, initc-loss 1.6587e+04                    bc_loss 2.2681e+04\n",
      "Epoch 20150, Training-Loss 4.9710e+04, Data-loss 2.8477e+03                  , pde-loss 2.1170e+03, initc-loss 1.9905e+04                    bc_loss 2.4841e+04\n",
      "Epoch 20160, Training-Loss 4.7681e+04, Data-loss 3.6987e+03                  , pde-loss 8.9160e+02, initc-loss 2.1229e+04                    bc_loss 2.1861e+04\n",
      "Epoch 20170, Training-Loss 3.4756e+04, Data-loss 3.2211e+03                  , pde-loss 9.0394e+02, initc-loss 2.1668e+04                    bc_loss 8.9629e+03\n",
      "Epoch 20180, Training-Loss 3.3005e+04, Data-loss 3.1304e+03                  , pde-loss 1.1425e+03, initc-loss 2.2101e+04                    bc_loss 6.6314e+03\n",
      "Epoch 20190, Training-Loss 2.8724e+04, Data-loss 3.5697e+03                  , pde-loss 1.0192e+03, initc-loss 1.9041e+04                    bc_loss 5.0942e+03\n",
      "Epoch 20200, Training-Loss 2.6684e+04, Data-loss 1.8463e+03                  , pde-loss 8.4570e+02, initc-loss 1.9769e+04                    bc_loss 4.2238e+03\n",
      "Epoch 20210, Training-Loss 2.4208e+04, Data-loss 1.7867e+03                  , pde-loss 1.0179e+03, initc-loss 1.7912e+04                    bc_loss 3.4919e+03\n",
      "Epoch 20220, Training-Loss 2.2460e+04, Data-loss 1.8523e+03                  , pde-loss 7.9687e+02, initc-loss 1.6655e+04                    bc_loss 3.1550e+03\n",
      "Epoch 20230, Training-Loss 2.4992e+04, Data-loss 2.1037e+03                  , pde-loss 1.0257e+03, initc-loss 1.6729e+04                    bc_loss 5.1331e+03\n",
      "Epoch 20240, Training-Loss 2.0773e+04, Data-loss 1.7939e+03                  , pde-loss 7.7457e+02, initc-loss 1.5799e+04                    bc_loss 2.4051e+03\n",
      "Epoch 20250, Training-Loss 2.0402e+04, Data-loss 1.3477e+03                  , pde-loss 8.0469e+02, initc-loss 1.5417e+04                    bc_loss 2.8327e+03\n",
      "Epoch 20260, Training-Loss 2.1894e+04, Data-loss 2.6229e+03                  , pde-loss 1.0064e+03, initc-loss 1.5388e+04                    bc_loss 2.8765e+03\n",
      "Epoch 20270, Training-Loss 2.6969e+04, Data-loss 1.1483e+03                  , pde-loss 7.0497e+02, initc-loss 1.5980e+04                    bc_loss 9.1360e+03\n",
      "Epoch 20280, Training-Loss 2.6602e+04, Data-loss 1.3733e+03                  , pde-loss 8.6547e+02, initc-loss 1.7137e+04                    bc_loss 7.2269e+03\n",
      "Epoch 20290, Training-Loss 2.9085e+04, Data-loss 2.3770e+03                  , pde-loss 1.3214e+03, initc-loss 1.5688e+04                    bc_loss 9.6993e+03\n",
      "Epoch 20300, Training-Loss 2.5363e+04, Data-loss 1.8657e+03                  , pde-loss 7.9303e+02, initc-loss 1.6831e+04                    bc_loss 5.8741e+03\n",
      "Epoch 20310, Training-Loss 2.1103e+04, Data-loss 1.2863e+03                  , pde-loss 7.3271e+02, initc-loss 1.6230e+04                    bc_loss 2.8532e+03\n",
      "Epoch 20320, Training-Loss 2.0316e+04, Data-loss 1.3017e+03                  , pde-loss 1.2289e+03, initc-loss 1.5444e+04                    bc_loss 2.3414e+03\n",
      "Epoch 20330, Training-Loss 2.0595e+04, Data-loss 1.6622e+03                  , pde-loss 1.6338e+03, initc-loss 1.5227e+04                    bc_loss 2.0719e+03\n",
      "Epoch 20340, Training-Loss 2.0401e+04, Data-loss 1.6228e+03                  , pde-loss 1.1594e+03, initc-loss 1.4333e+04                    bc_loss 3.2862e+03\n",
      "Epoch 20350, Training-Loss 2.7296e+04, Data-loss 1.1587e+03                  , pde-loss 1.1951e+03, initc-loss 1.4302e+04                    bc_loss 1.0641e+04\n",
      "Epoch 20360, Training-Loss 2.7504e+04, Data-loss 1.4383e+03                  , pde-loss 6.1033e+02, initc-loss 1.6008e+04                    bc_loss 9.4475e+03\n",
      "Epoch 20370, Training-Loss 2.7848e+04, Data-loss 1.8008e+03                  , pde-loss 1.5049e+03, initc-loss 1.7347e+04                    bc_loss 7.1960e+03\n",
      "Epoch 20380, Training-Loss 2.4961e+04, Data-loss 2.4876e+03                  , pde-loss 6.5364e+02, initc-loss 1.7464e+04                    bc_loss 4.3554e+03\n",
      "Epoch 20390, Training-Loss 2.4945e+04, Data-loss 1.1358e+03                  , pde-loss 1.1810e+03, initc-loss 1.6001e+04                    bc_loss 6.6273e+03\n",
      "Epoch 20400, Training-Loss 2.2590e+04, Data-loss 1.4323e+03                  , pde-loss 9.0354e+02, initc-loss 1.5046e+04                    bc_loss 5.2083e+03\n",
      "Epoch 20410, Training-Loss 2.3605e+04, Data-loss 1.7104e+03                  , pde-loss 5.9441e+02, initc-loss 1.5572e+04                    bc_loss 5.7283e+03\n",
      "Epoch 20420, Training-Loss 3.9422e+04, Data-loss 1.5617e+03                  , pde-loss 1.9570e+03, initc-loss 1.5277e+04                    bc_loss 2.0627e+04\n",
      "Epoch 20430, Training-Loss 3.9414e+04, Data-loss 2.5299e+03                  , pde-loss 9.5886e+02, initc-loss 1.8370e+04                    bc_loss 1.7555e+04\n",
      "Epoch 20440, Training-Loss 4.1116e+04, Data-loss 3.5424e+03                  , pde-loss 1.1647e+03, initc-loss 1.8985e+04                    bc_loss 1.7423e+04\n",
      "Epoch 20450, Training-Loss 3.6110e+04, Data-loss 2.4882e+03                  , pde-loss 1.0339e+03, initc-loss 1.7886e+04                    bc_loss 1.4703e+04\n",
      "Epoch 20460, Training-Loss 3.6824e+04, Data-loss 3.7587e+03                  , pde-loss 1.3537e+03, initc-loss 1.8544e+04                    bc_loss 1.3168e+04\n",
      "Epoch 20470, Training-Loss 3.3044e+04, Data-loss 3.2449e+03                  , pde-loss 1.2001e+03, initc-loss 2.0148e+04                    bc_loss 8.4514e+03\n",
      "Epoch 20480, Training-Loss 2.7082e+04, Data-loss 2.6029e+03                  , pde-loss 1.3646e+03, initc-loss 1.9357e+04                    bc_loss 3.7575e+03\n",
      "Epoch 20490, Training-Loss 2.9244e+04, Data-loss 2.7591e+03                  , pde-loss 6.5965e+02, initc-loss 1.7101e+04                    bc_loss 8.7241e+03\n",
      "Epoch 20500, Training-Loss 3.0724e+04, Data-loss 2.1875e+03                  , pde-loss 1.2356e+03, initc-loss 1.8343e+04                    bc_loss 8.9578e+03\n",
      "Epoch 20510, Training-Loss 2.5052e+04, Data-loss 2.1678e+03                  , pde-loss 1.2903e+03, initc-loss 1.7042e+04                    bc_loss 4.5517e+03\n",
      "Epoch 20520, Training-Loss 3.9226e+04, Data-loss 1.5620e+03                  , pde-loss 1.0843e+03, initc-loss 1.7595e+04                    bc_loss 1.8985e+04\n",
      "Epoch 20530, Training-Loss 8.3056e+04, Data-loss 2.8575e+03                  , pde-loss 2.5407e+03, initc-loss 1.7175e+04                    bc_loss 6.0483e+04\n",
      "Epoch 20540, Training-Loss 3.9745e+04, Data-loss 2.5812e+03                  , pde-loss 1.1416e+03, initc-loss 1.7984e+04                    bc_loss 1.8039e+04\n",
      "Epoch 20550, Training-Loss 4.8091e+04, Data-loss 2.8997e+03                  , pde-loss 9.9711e+02, initc-loss 1.9103e+04                    bc_loss 2.5092e+04\n",
      "Epoch 20560, Training-Loss 5.9076e+04, Data-loss 2.0594e+03                  , pde-loss 1.6409e+03, initc-loss 2.1731e+04                    bc_loss 3.3645e+04\n",
      "Epoch 20570, Training-Loss 4.0580e+04, Data-loss 2.8417e+03                  , pde-loss 9.8106e+02, initc-loss 2.0230e+04                    bc_loss 1.6528e+04\n",
      "Epoch 20580, Training-Loss 3.5167e+04, Data-loss 3.6483e+03                  , pde-loss 1.5403e+03, initc-loss 2.1158e+04                    bc_loss 8.8213e+03\n",
      "Epoch 20590, Training-Loss 4.0165e+04, Data-loss 2.9013e+03                  , pde-loss 7.5276e+02, initc-loss 2.0547e+04                    bc_loss 1.5964e+04\n",
      "Epoch 20600, Training-Loss 4.2645e+04, Data-loss 3.6611e+03                  , pde-loss 1.3305e+03, initc-loss 1.7952e+04                    bc_loss 1.9702e+04\n",
      "Epoch 20610, Training-Loss 3.0990e+04, Data-loss 2.7030e+03                  , pde-loss 1.4610e+03, initc-loss 1.9028e+04                    bc_loss 7.7979e+03\n",
      "Epoch 20620, Training-Loss 2.6705e+04, Data-loss 1.9541e+03                  , pde-loss 8.5571e+02, initc-loss 1.8848e+04                    bc_loss 5.0472e+03\n",
      "Epoch 20630, Training-Loss 2.4795e+04, Data-loss 2.5052e+03                  , pde-loss 1.3151e+03, initc-loss 1.7335e+04                    bc_loss 3.6399e+03\n",
      "Epoch 20640, Training-Loss 2.1257e+04, Data-loss 1.3414e+03                  , pde-loss 8.6105e+02, initc-loss 1.5929e+04                    bc_loss 3.1250e+03\n",
      "Epoch 20650, Training-Loss 3.0141e+04, Data-loss 1.6517e+03                  , pde-loss 1.1128e+03, initc-loss 1.5179e+04                    bc_loss 1.2198e+04\n",
      "Epoch 20660, Training-Loss 2.4240e+04, Data-loss 1.2761e+03                  , pde-loss 9.2521e+02, initc-loss 1.6318e+04                    bc_loss 5.7202e+03\n",
      "Epoch 20670, Training-Loss 2.3472e+04, Data-loss 1.2961e+03                  , pde-loss 1.0084e+03, initc-loss 1.6296e+04                    bc_loss 4.8720e+03\n",
      "Epoch 20680, Training-Loss 2.2635e+04, Data-loss 1.4881e+03                  , pde-loss 1.3966e+03, initc-loss 1.5584e+04                    bc_loss 4.1664e+03\n",
      "Epoch 20690, Training-Loss 2.0956e+04, Data-loss 1.6536e+03                  , pde-loss 9.2254e+02, initc-loss 1.5164e+04                    bc_loss 3.2154e+03\n",
      "Epoch 20700, Training-Loss 2.8674e+04, Data-loss 1.8902e+03                  , pde-loss 1.3520e+03, initc-loss 1.5231e+04                    bc_loss 1.0200e+04\n",
      "Epoch 20710, Training-Loss 3.1033e+04, Data-loss 1.7299e+03                  , pde-loss 1.7172e+03, initc-loss 1.5575e+04                    bc_loss 1.2011e+04\n",
      "Epoch 20720, Training-Loss 4.4470e+04, Data-loss 1.7135e+03                  , pde-loss 1.1293e+03, initc-loss 1.6078e+04                    bc_loss 2.5549e+04\n",
      "Epoch 20730, Training-Loss 3.4447e+04, Data-loss 2.3920e+03                  , pde-loss 1.0950e+03, initc-loss 1.8923e+04                    bc_loss 1.2037e+04\n",
      "Epoch 20740, Training-Loss 3.1749e+04, Data-loss 2.4803e+03                  , pde-loss 1.0987e+03, initc-loss 1.8006e+04                    bc_loss 1.0165e+04\n",
      "Epoch 20750, Training-Loss 2.9486e+04, Data-loss 2.5932e+03                  , pde-loss 9.1348e+02, initc-loss 1.8092e+04                    bc_loss 7.8866e+03\n",
      "Epoch 20760, Training-Loss 3.2440e+04, Data-loss 2.4834e+03                  , pde-loss 1.5907e+03, initc-loss 2.0280e+04                    bc_loss 8.0860e+03\n",
      "Epoch 20770, Training-Loss 4.3982e+04, Data-loss 2.1040e+03                  , pde-loss 1.2086e+03, initc-loss 1.8211e+04                    bc_loss 2.2459e+04\n",
      "Epoch 20780, Training-Loss 3.8092e+04, Data-loss 2.0064e+03                  , pde-loss 6.7764e+02, initc-loss 1.8170e+04                    bc_loss 1.7238e+04\n",
      "Epoch 20790, Training-Loss 4.1067e+04, Data-loss 2.0676e+03                  , pde-loss 5.6373e+02, initc-loss 2.0186e+04                    bc_loss 1.8249e+04\n",
      "Epoch 20800, Training-Loss 4.1711e+04, Data-loss 2.4766e+03                  , pde-loss 1.2080e+03, initc-loss 2.0929e+04                    bc_loss 1.7098e+04\n",
      "Epoch 20810, Training-Loss 4.3328e+04, Data-loss 4.7326e+03                  , pde-loss 2.6098e+03, initc-loss 2.0225e+04                    bc_loss 1.5761e+04\n",
      "Epoch 20820, Training-Loss 3.1033e+04, Data-loss 1.9605e+03                  , pde-loss 6.4258e+02, initc-loss 1.9025e+04                    bc_loss 9.4055e+03\n",
      "Epoch 20830, Training-Loss 3.0911e+04, Data-loss 3.2299e+03                  , pde-loss 1.6105e+03, initc-loss 1.8962e+04                    bc_loss 7.1083e+03\n",
      "Epoch 20840, Training-Loss 2.7908e+04, Data-loss 2.4814e+03                  , pde-loss 1.1036e+03, initc-loss 1.7103e+04                    bc_loss 7.2196e+03\n",
      "Epoch 20850, Training-Loss 2.7595e+04, Data-loss 2.4849e+03                  , pde-loss 1.2279e+03, initc-loss 1.6607e+04                    bc_loss 7.2749e+03\n",
      "Epoch 20860, Training-Loss 2.6647e+04, Data-loss 2.1598e+03                  , pde-loss 1.4877e+03, initc-loss 1.5970e+04                    bc_loss 7.0296e+03\n",
      "Epoch 20870, Training-Loss 2.6258e+04, Data-loss 2.1862e+03                  , pde-loss 9.7882e+02, initc-loss 1.6799e+04                    bc_loss 6.2945e+03\n",
      "Epoch 20880, Training-Loss 3.1302e+04, Data-loss 1.9011e+03                  , pde-loss 1.3995e+03, initc-loss 1.9470e+04                    bc_loss 8.5316e+03\n",
      "Epoch 20890, Training-Loss 2.6376e+04, Data-loss 2.7025e+03                  , pde-loss 1.1038e+03, initc-loss 1.6752e+04                    bc_loss 5.8170e+03\n",
      "Epoch 20900, Training-Loss 2.4904e+04, Data-loss 2.5565e+03                  , pde-loss 1.2774e+03, initc-loss 1.6997e+04                    bc_loss 4.0732e+03\n",
      "Epoch 20910, Training-Loss 2.4383e+04, Data-loss 2.2804e+03                  , pde-loss 1.1529e+03, initc-loss 1.6281e+04                    bc_loss 4.6685e+03\n",
      "Epoch 20920, Training-Loss 2.4164e+04, Data-loss 1.8666e+03                  , pde-loss 8.1797e+02, initc-loss 1.6042e+04                    bc_loss 5.4368e+03\n",
      "Epoch 20930, Training-Loss 3.3424e+04, Data-loss 2.3538e+03                  , pde-loss 8.7408e+02, initc-loss 1.7449e+04                    bc_loss 1.2747e+04\n",
      "Epoch 20940, Training-Loss 4.6877e+04, Data-loss 1.3729e+03                  , pde-loss 1.3690e+03, initc-loss 1.6119e+04                    bc_loss 2.8016e+04\n",
      "Epoch 20950, Training-Loss 9.8492e+04, Data-loss 2.2837e+03                  , pde-loss 1.5967e+03, initc-loss 2.0123e+04                    bc_loss 7.4489e+04\n",
      "Epoch 20960, Training-Loss 6.0485e+04, Data-loss 3.3274e+03                  , pde-loss 1.4622e+03, initc-loss 2.3770e+04                    bc_loss 3.1925e+04\n",
      "Epoch 20970, Training-Loss 4.9307e+04, Data-loss 5.6532e+03                  , pde-loss 1.7162e+03, initc-loss 2.3516e+04                    bc_loss 1.8422e+04\n",
      "Epoch 20980, Training-Loss 3.6567e+04, Data-loss 4.2175e+03                  , pde-loss 1.6671e+03, initc-loss 2.3929e+04                    bc_loss 6.7536e+03\n",
      "Epoch 20990, Training-Loss 3.1674e+04, Data-loss 3.6793e+03                  , pde-loss 1.3500e+03, initc-loss 2.2051e+04                    bc_loss 4.5933e+03\n",
      "Epoch 21000, Training-Loss 2.9046e+04, Data-loss 3.0729e+03                  , pde-loss 7.9335e+02, initc-loss 2.0687e+04                    bc_loss 4.4934e+03\n",
      "Epoch 21010, Training-Loss 2.6940e+04, Data-loss 3.6938e+03                  , pde-loss 8.2084e+02, initc-loss 1.9318e+04                    bc_loss 3.1076e+03\n",
      "Epoch 21020, Training-Loss 2.9482e+04, Data-loss 3.9032e+03                  , pde-loss 1.4977e+03, initc-loss 2.1073e+04                    bc_loss 3.0083e+03\n",
      "Epoch 21030, Training-Loss 2.3929e+04, Data-loss 2.1927e+03                  , pde-loss 1.5319e+03, initc-loss 1.6666e+04                    bc_loss 3.5383e+03\n",
      "Epoch 21040, Training-Loss 2.9796e+04, Data-loss 2.2075e+03                  , pde-loss 8.7667e+02, initc-loss 1.8249e+04                    bc_loss 8.4635e+03\n",
      "Epoch 21050, Training-Loss 3.4437e+04, Data-loss 2.9675e+03                  , pde-loss 1.4256e+03, initc-loss 1.8338e+04                    bc_loss 1.1706e+04\n",
      "Epoch 21060, Training-Loss 2.7475e+04, Data-loss 2.4870e+03                  , pde-loss 1.5038e+03, initc-loss 1.7727e+04                    bc_loss 5.7564e+03\n",
      "Epoch 21070, Training-Loss 2.6968e+04, Data-loss 2.3824e+03                  , pde-loss 1.4689e+03, initc-loss 1.8197e+04                    bc_loss 4.9200e+03\n",
      "Epoch 21080, Training-Loss 2.4308e+04, Data-loss 1.5531e+03                  , pde-loss 1.0579e+03, initc-loss 1.6862e+04                    bc_loss 4.8348e+03\n",
      "Epoch 21090, Training-Loss 2.5726e+04, Data-loss 2.0124e+03                  , pde-loss 8.4141e+02, initc-loss 1.6453e+04                    bc_loss 6.4192e+03\n",
      "Epoch 21100, Training-Loss 2.5953e+04, Data-loss 1.8997e+03                  , pde-loss 1.1873e+03, initc-loss 1.6295e+04                    bc_loss 6.5711e+03\n",
      "Epoch 21110, Training-Loss 2.3680e+04, Data-loss 2.0585e+03                  , pde-loss 1.1566e+03, initc-loss 1.6035e+04                    bc_loss 4.4295e+03\n",
      "Epoch 21120, Training-Loss 2.1562e+04, Data-loss 1.8107e+03                  , pde-loss 9.1180e+02, initc-loss 1.5882e+04                    bc_loss 2.9570e+03\n",
      "Epoch 21130, Training-Loss 2.0753e+04, Data-loss 1.4472e+03                  , pde-loss 8.9731e+02, initc-loss 1.5030e+04                    bc_loss 3.3779e+03\n",
      "Epoch 21140, Training-Loss 2.3016e+04, Data-loss 1.4221e+03                  , pde-loss 1.4578e+03, initc-loss 1.4706e+04                    bc_loss 5.4296e+03\n",
      "Epoch 21150, Training-Loss 2.4899e+04, Data-loss 1.8869e+03                  , pde-loss 1.2607e+03, initc-loss 1.4853e+04                    bc_loss 6.8988e+03\n",
      "Epoch 21160, Training-Loss 3.1222e+04, Data-loss 1.1898e+03                  , pde-loss 1.0585e+03, initc-loss 1.6485e+04                    bc_loss 1.2488e+04\n",
      "Epoch 21170, Training-Loss 4.1926e+04, Data-loss 1.7814e+03                  , pde-loss 1.1470e+03, initc-loss 1.5994e+04                    bc_loss 2.3004e+04\n",
      "Epoch 21180, Training-Loss 3.4682e+04, Data-loss 3.6331e+03                  , pde-loss 2.4597e+03, initc-loss 1.7404e+04                    bc_loss 1.1185e+04\n",
      "Epoch 21190, Training-Loss 3.1859e+04, Data-loss 2.2855e+03                  , pde-loss 1.0744e+03, initc-loss 1.8278e+04                    bc_loss 1.0221e+04\n",
      "Epoch 21200, Training-Loss 2.8748e+04, Data-loss 2.5886e+03                  , pde-loss 1.4913e+03, initc-loss 1.7944e+04                    bc_loss 6.7234e+03\n",
      "Epoch 21210, Training-Loss 3.2513e+04, Data-loss 2.7182e+03                  , pde-loss 1.8545e+03, initc-loss 2.1200e+04                    bc_loss 6.7400e+03\n",
      "Epoch 21220, Training-Loss 3.6106e+04, Data-loss 2.7356e+03                  , pde-loss 1.9933e+03, initc-loss 1.7148e+04                    bc_loss 1.4229e+04\n",
      "Epoch 21230, Training-Loss 7.9235e+04, Data-loss 1.6486e+03                  , pde-loss 1.1652e+03, initc-loss 1.7333e+04                    bc_loss 5.9088e+04\n",
      "Epoch 21240, Training-Loss 6.4604e+04, Data-loss 4.1588e+03                  , pde-loss 1.2856e+03, initc-loss 2.0395e+04                    bc_loss 3.8764e+04\n",
      "Epoch 21250, Training-Loss 4.0472e+04, Data-loss 3.5271e+03                  , pde-loss 1.0789e+03, initc-loss 2.1816e+04                    bc_loss 1.4050e+04\n",
      "Epoch 21260, Training-Loss 3.2813e+04, Data-loss 3.1051e+03                  , pde-loss 1.7447e+03, initc-loss 2.2064e+04                    bc_loss 5.8995e+03\n",
      "Epoch 21270, Training-Loss 2.9872e+04, Data-loss 3.9266e+03                  , pde-loss 1.6547e+03, initc-loss 2.1288e+04                    bc_loss 3.0027e+03\n",
      "Epoch 21280, Training-Loss 2.5106e+04, Data-loss 2.8977e+03                  , pde-loss 9.4654e+02, initc-loss 1.9267e+04                    bc_loss 1.9950e+03\n",
      "Epoch 21290, Training-Loss 2.2849e+04, Data-loss 2.2481e+03                  , pde-loss 1.2781e+03, initc-loss 1.7227e+04                    bc_loss 2.0963e+03\n",
      "Epoch 21300, Training-Loss 2.1728e+04, Data-loss 1.8218e+03                  , pde-loss 1.0145e+03, initc-loss 1.6255e+04                    bc_loss 2.6364e+03\n",
      "Epoch 21310, Training-Loss 2.2369e+04, Data-loss 1.8526e+03                  , pde-loss 8.8199e+02, initc-loss 1.6510e+04                    bc_loss 3.1243e+03\n",
      "Epoch 21320, Training-Loss 2.1299e+04, Data-loss 1.7705e+03                  , pde-loss 9.8490e+02, initc-loss 1.4904e+04                    bc_loss 3.6398e+03\n",
      "Epoch 21330, Training-Loss 2.5111e+04, Data-loss 1.3724e+03                  , pde-loss 7.2882e+02, initc-loss 1.5663e+04                    bc_loss 7.3471e+03\n",
      "Epoch 21340, Training-Loss 4.6650e+04, Data-loss 1.6512e+03                  , pde-loss 7.4058e+02, initc-loss 1.6585e+04                    bc_loss 2.7673e+04\n",
      "Epoch 21350, Training-Loss 3.3534e+04, Data-loss 3.0096e+03                  , pde-loss 1.4969e+03, initc-loss 1.7295e+04                    bc_loss 1.1733e+04\n",
      "Epoch 21360, Training-Loss 3.0090e+04, Data-loss 2.7190e+03                  , pde-loss 1.3134e+03, initc-loss 1.7055e+04                    bc_loss 9.0026e+03\n",
      "Epoch 21370, Training-Loss 2.5431e+04, Data-loss 2.2618e+03                  , pde-loss 9.8501e+02, initc-loss 1.7506e+04                    bc_loss 4.6776e+03\n",
      "Epoch 21380, Training-Loss 2.3614e+04, Data-loss 1.9679e+03                  , pde-loss 1.0469e+03, initc-loss 1.6632e+04                    bc_loss 3.9666e+03\n",
      "Epoch 21390, Training-Loss 2.4216e+04, Data-loss 1.9670e+03                  , pde-loss 1.6760e+03, initc-loss 1.6260e+04                    bc_loss 4.3130e+03\n",
      "Epoch 21400, Training-Loss 2.0277e+04, Data-loss 1.0056e+03                  , pde-loss 7.2696e+02, initc-loss 1.4020e+04                    bc_loss 4.5245e+03\n",
      "Epoch 21410, Training-Loss 2.2002e+04, Data-loss 1.7353e+03                  , pde-loss 1.3998e+03, initc-loss 1.4839e+04                    bc_loss 4.0277e+03\n",
      "Epoch 21420, Training-Loss 2.5360e+04, Data-loss 1.3717e+03                  , pde-loss 8.1709e+02, initc-loss 1.4326e+04                    bc_loss 8.8443e+03\n",
      "Epoch 21430, Training-Loss 2.9871e+04, Data-loss 2.2963e+03                  , pde-loss 8.8606e+02, initc-loss 1.5914e+04                    bc_loss 1.0775e+04\n",
      "Epoch 21440, Training-Loss 3.1788e+04, Data-loss 1.6850e+03                  , pde-loss 1.0300e+03, initc-loss 1.6227e+04                    bc_loss 1.2845e+04\n",
      "Epoch 21450, Training-Loss 2.4466e+04, Data-loss 1.9157e+03                  , pde-loss 6.9596e+02, initc-loss 1.5870e+04                    bc_loss 5.9842e+03\n",
      "Epoch 21460, Training-Loss 2.8655e+04, Data-loss 1.8017e+03                  , pde-loss 1.4797e+03, initc-loss 1.7719e+04                    bc_loss 7.6549e+03\n",
      "Epoch 21470, Training-Loss 2.2273e+04, Data-loss 1.1959e+03                  , pde-loss 7.0629e+02, initc-loss 1.6102e+04                    bc_loss 4.2695e+03\n",
      "Epoch 21480, Training-Loss 2.9097e+04, Data-loss 2.2066e+03                  , pde-loss 1.0860e+03, initc-loss 1.6349e+04                    bc_loss 9.4561e+03\n",
      "Epoch 21490, Training-Loss 2.8988e+04, Data-loss 2.6101e+03                  , pde-loss 1.4868e+03, initc-loss 1.8013e+04                    bc_loss 6.8780e+03\n",
      "Epoch 21500, Training-Loss 2.6011e+04, Data-loss 1.7473e+03                  , pde-loss 1.2156e+03, initc-loss 1.7360e+04                    bc_loss 5.6885e+03\n",
      "Epoch 21510, Training-Loss 2.2835e+04, Data-loss 1.6973e+03                  , pde-loss 1.0879e+03, initc-loss 1.5470e+04                    bc_loss 4.5795e+03\n",
      "Epoch 21520, Training-Loss 2.5815e+04, Data-loss 3.0271e+03                  , pde-loss 2.6239e+03, initc-loss 1.5447e+04                    bc_loss 4.7179e+03\n",
      "Epoch 21530, Training-Loss 2.2841e+04, Data-loss 1.7624e+03                  , pde-loss 1.1700e+03, initc-loss 1.5332e+04                    bc_loss 4.5760e+03\n",
      "Epoch 21540, Training-Loss 2.6855e+04, Data-loss 1.4203e+03                  , pde-loss 9.5131e+02, initc-loss 1.4697e+04                    bc_loss 9.7860e+03\n",
      "Epoch 21550, Training-Loss 2.3519e+04, Data-loss 1.4030e+03                  , pde-loss 4.6485e+02, initc-loss 1.4881e+04                    bc_loss 6.7702e+03\n",
      "Epoch 21560, Training-Loss 2.1674e+04, Data-loss 1.7165e+03                  , pde-loss 1.3494e+03, initc-loss 1.4672e+04                    bc_loss 3.9356e+03\n",
      "Epoch 21570, Training-Loss 3.1795e+04, Data-loss 1.7168e+03                  , pde-loss 1.7394e+03, initc-loss 1.4839e+04                    bc_loss 1.3500e+04\n",
      "Epoch 21580, Training-Loss 2.9748e+04, Data-loss 1.4429e+03                  , pde-loss 7.0834e+02, initc-loss 1.6042e+04                    bc_loss 1.1555e+04\n",
      "Epoch 21590, Training-Loss 3.5222e+04, Data-loss 1.4394e+03                  , pde-loss 1.3532e+03, initc-loss 1.6030e+04                    bc_loss 1.6399e+04\n",
      "Epoch 21600, Training-Loss 3.2154e+04, Data-loss 1.8478e+03                  , pde-loss 8.3570e+02, initc-loss 1.7779e+04                    bc_loss 1.1691e+04\n",
      "Epoch 21610, Training-Loss 2.5822e+04, Data-loss 2.5745e+03                  , pde-loss 1.9913e+03, initc-loss 1.6013e+04                    bc_loss 5.2435e+03\n",
      "Epoch 21620, Training-Loss 2.4070e+04, Data-loss 2.2777e+03                  , pde-loss 5.1621e+02, initc-loss 1.7713e+04                    bc_loss 3.5629e+03\n",
      "Epoch 21630, Training-Loss 1.9970e+04, Data-loss 1.6425e+03                  , pde-loss 1.1125e+03, initc-loss 1.4607e+04                    bc_loss 2.6081e+03\n",
      "Epoch 21640, Training-Loss 2.6391e+04, Data-loss 1.4156e+03                  , pde-loss 9.3600e+02, initc-loss 1.4857e+04                    bc_loss 9.1816e+03\n",
      "Epoch 21650, Training-Loss 2.2294e+04, Data-loss 1.3610e+03                  , pde-loss 6.8328e+02, initc-loss 1.4875e+04                    bc_loss 5.3744e+03\n",
      "Epoch 21660, Training-Loss 3.3729e+04, Data-loss 3.6169e+03                  , pde-loss 2.6238e+03, initc-loss 1.4785e+04                    bc_loss 1.2704e+04\n",
      "Epoch 21670, Training-Loss 5.1687e+04, Data-loss 2.0916e+03                  , pde-loss 1.1029e+03, initc-loss 1.6449e+04                    bc_loss 3.2044e+04\n",
      "Epoch 21680, Training-Loss 3.1357e+04, Data-loss 2.0592e+03                  , pde-loss 1.0409e+03, initc-loss 1.7771e+04                    bc_loss 1.0486e+04\n",
      "Epoch 21690, Training-Loss 2.9101e+04, Data-loss 1.8141e+03                  , pde-loss 1.3052e+03, initc-loss 1.8153e+04                    bc_loss 7.8283e+03\n",
      "Epoch 21700, Training-Loss 2.7060e+04, Data-loss 2.8162e+03                  , pde-loss 1.5744e+03, initc-loss 1.7118e+04                    bc_loss 5.5508e+03\n",
      "Epoch 21710, Training-Loss 2.2281e+04, Data-loss 1.9902e+03                  , pde-loss 8.6691e+02, initc-loss 1.6918e+04                    bc_loss 2.5062e+03\n",
      "Epoch 21720, Training-Loss 2.1780e+04, Data-loss 1.6646e+03                  , pde-loss 1.0924e+03, initc-loss 1.6282e+04                    bc_loss 2.7412e+03\n",
      "Epoch 21730, Training-Loss 1.9915e+04, Data-loss 1.6171e+03                  , pde-loss 7.3591e+02, initc-loss 1.4704e+04                    bc_loss 2.8583e+03\n",
      "Epoch 21740, Training-Loss 2.0612e+04, Data-loss 1.3184e+03                  , pde-loss 9.5616e+02, initc-loss 1.3797e+04                    bc_loss 4.5402e+03\n",
      "Epoch 21750, Training-Loss 2.3913e+04, Data-loss 9.1293e+02                  , pde-loss 1.1953e+03, initc-loss 1.7038e+04                    bc_loss 4.7670e+03\n",
      "Epoch 21760, Training-Loss 2.4339e+04, Data-loss 1.3090e+03                  , pde-loss 6.3686e+02, initc-loss 1.3523e+04                    bc_loss 8.8702e+03\n",
      "Epoch 21770, Training-Loss 2.5457e+04, Data-loss 1.6861e+03                  , pde-loss 1.4446e+03, initc-loss 1.3879e+04                    bc_loss 8.4476e+03\n",
      "Epoch 21780, Training-Loss 2.8331e+04, Data-loss 2.1466e+03                  , pde-loss 1.1094e+03, initc-loss 1.5578e+04                    bc_loss 9.4977e+03\n",
      "Epoch 21790, Training-Loss 2.6743e+04, Data-loss 1.8660e+03                  , pde-loss 9.8102e+02, initc-loss 1.5825e+04                    bc_loss 8.0707e+03\n",
      "Epoch 21800, Training-Loss 2.5625e+04, Data-loss 1.6460e+03                  , pde-loss 1.0766e+03, initc-loss 1.5477e+04                    bc_loss 7.4257e+03\n",
      "Epoch 21810, Training-Loss 2.2807e+04, Data-loss 1.9144e+03                  , pde-loss 1.2742e+03, initc-loss 1.5185e+04                    bc_loss 4.4333e+03\n",
      "Epoch 21820, Training-Loss 2.1642e+04, Data-loss 1.2218e+03                  , pde-loss 8.4893e+02, initc-loss 1.4464e+04                    bc_loss 5.1079e+03\n",
      "Epoch 21830, Training-Loss 2.3528e+04, Data-loss 1.4705e+03                  , pde-loss 1.3705e+03, initc-loss 1.4934e+04                    bc_loss 5.7525e+03\n",
      "Epoch 21840, Training-Loss 1.9417e+04, Data-loss 9.9084e+02                  , pde-loss 6.8037e+02, initc-loss 1.4290e+04                    bc_loss 3.4553e+03\n",
      "Epoch 21850, Training-Loss 1.8881e+04, Data-loss 8.7980e+02                  , pde-loss 8.1539e+02, initc-loss 1.4218e+04                    bc_loss 2.9683e+03\n",
      "Epoch 21860, Training-Loss 1.9427e+04, Data-loss 1.2758e+03                  , pde-loss 6.3444e+02, initc-loss 1.3358e+04                    bc_loss 4.1589e+03\n",
      "Epoch 21870, Training-Loss 3.7376e+04, Data-loss 2.1199e+03                  , pde-loss 1.1664e+03, initc-loss 1.4012e+04                    bc_loss 2.0077e+04\n",
      "Epoch 21880, Training-Loss 2.5772e+04, Data-loss 1.4740e+03                  , pde-loss 7.0213e+02, initc-loss 1.4668e+04                    bc_loss 8.9280e+03\n",
      "Epoch 21890, Training-Loss 2.7267e+04, Data-loss 2.4045e+03                  , pde-loss 1.0199e+03, initc-loss 1.5180e+04                    bc_loss 8.6621e+03\n",
      "Epoch 21900, Training-Loss 2.7435e+04, Data-loss 1.8762e+03                  , pde-loss 1.0737e+03, initc-loss 1.5170e+04                    bc_loss 9.3156e+03\n",
      "Epoch 21910, Training-Loss 2.1994e+04, Data-loss 1.6301e+03                  , pde-loss 7.3371e+02, initc-loss 1.5326e+04                    bc_loss 4.3040e+03\n",
      "Epoch 21920, Training-Loss 2.2423e+04, Data-loss 2.5686e+03                  , pde-loss 2.3040e+03, initc-loss 1.4372e+04                    bc_loss 3.1785e+03\n",
      "Epoch 21930, Training-Loss 2.0174e+04, Data-loss 1.5356e+03                  , pde-loss 8.8225e+02, initc-loss 1.5183e+04                    bc_loss 2.5734e+03\n",
      "Epoch 21940, Training-Loss 1.9085e+04, Data-loss 9.7285e+02                  , pde-loss 1.0094e+03, initc-loss 1.3710e+04                    bc_loss 3.3921e+03\n",
      "Epoch 21950, Training-Loss 2.2324e+04, Data-loss 9.7990e+02                  , pde-loss 9.7146e+02, initc-loss 1.2540e+04                    bc_loss 7.8328e+03\n",
      "Epoch 21960, Training-Loss 2.4617e+04, Data-loss 1.7190e+03                  , pde-loss 5.7382e+02, initc-loss 1.3979e+04                    bc_loss 8.3455e+03\n",
      "Epoch 21970, Training-Loss 2.0688e+04, Data-loss 1.1978e+03                  , pde-loss 1.1159e+03, initc-loss 1.4365e+04                    bc_loss 4.0089e+03\n",
      "Epoch 21980, Training-Loss 2.1486e+04, Data-loss 1.5189e+03                  , pde-loss 7.8494e+02, initc-loss 1.4414e+04                    bc_loss 4.7682e+03\n",
      "Epoch 21990, Training-Loss 2.2297e+04, Data-loss 1.5177e+03                  , pde-loss 1.0860e+03, initc-loss 1.5237e+04                    bc_loss 4.4564e+03\n",
      "Epoch 22000, Training-Loss 2.3934e+04, Data-loss 3.4660e+03                  , pde-loss 1.9579e+03, initc-loss 1.4878e+04                    bc_loss 3.6328e+03\n",
      "Epoch 22010, Training-Loss 1.9054e+04, Data-loss 1.3886e+03                  , pde-loss 9.2331e+02, initc-loss 1.3602e+04                    bc_loss 3.1396e+03\n",
      "Epoch 22020, Training-Loss 1.9970e+04, Data-loss 1.4440e+03                  , pde-loss 9.1435e+02, initc-loss 1.3140e+04                    bc_loss 4.4712e+03\n",
      "Epoch 22030, Training-Loss 2.0090e+04, Data-loss 8.7204e+02                  , pde-loss 8.4072e+02, initc-loss 1.3811e+04                    bc_loss 4.5659e+03\n",
      "Epoch 22040, Training-Loss 2.4080e+04, Data-loss 1.2476e+03                  , pde-loss 8.0501e+02, initc-loss 1.3608e+04                    bc_loss 8.4200e+03\n",
      "Epoch 22050, Training-Loss 2.5110e+04, Data-loss 1.1714e+03                  , pde-loss 8.8048e+02, initc-loss 1.3763e+04                    bc_loss 9.2958e+03\n",
      "Epoch 22060, Training-Loss 3.2085e+04, Data-loss 1.1513e+03                  , pde-loss 7.2675e+02, initc-loss 1.5166e+04                    bc_loss 1.5041e+04\n",
      "Epoch 22070, Training-Loss 2.8049e+04, Data-loss 2.7301e+03                  , pde-loss 1.6520e+03, initc-loss 1.5674e+04                    bc_loss 7.9937e+03\n",
      "Epoch 22080, Training-Loss 2.5139e+04, Data-loss 2.2199e+03                  , pde-loss 1.2297e+03, initc-loss 1.5964e+04                    bc_loss 5.7255e+03\n",
      "Epoch 22090, Training-Loss 2.5154e+04, Data-loss 1.5040e+03                  , pde-loss 7.2023e+02, initc-loss 1.6728e+04                    bc_loss 6.2018e+03\n",
      "Epoch 22100, Training-Loss 2.3211e+04, Data-loss 2.3111e+03                  , pde-loss 7.2580e+02, initc-loss 1.6356e+04                    bc_loss 3.8185e+03\n",
      "Epoch 22110, Training-Loss 1.9297e+04, Data-loss 9.5794e+02                  , pde-loss 7.2281e+02, initc-loss 1.4596e+04                    bc_loss 3.0197e+03\n",
      "Epoch 22120, Training-Loss 1.9554e+04, Data-loss 1.2815e+03                  , pde-loss 1.0586e+03, initc-loss 1.4084e+04                    bc_loss 3.1297e+03\n",
      "Epoch 22130, Training-Loss 2.0952e+04, Data-loss 8.3009e+02                  , pde-loss 7.2544e+02, initc-loss 1.3870e+04                    bc_loss 5.5260e+03\n",
      "Epoch 22140, Training-Loss 4.2332e+04, Data-loss 1.4754e+03                  , pde-loss 1.4612e+03, initc-loss 1.3919e+04                    bc_loss 2.5476e+04\n",
      "Epoch 22150, Training-Loss 3.1004e+04, Data-loss 1.7372e+03                  , pde-loss 1.6381e+03, initc-loss 1.6235e+04                    bc_loss 1.1393e+04\n",
      "Epoch 22160, Training-Loss 2.9302e+04, Data-loss 2.1940e+03                  , pde-loss 8.7157e+02, initc-loss 1.7167e+04                    bc_loss 9.0698e+03\n",
      "Epoch 22170, Training-Loss 2.6656e+04, Data-loss 1.6105e+03                  , pde-loss 9.8846e+02, initc-loss 1.6025e+04                    bc_loss 8.0318e+03\n",
      "Epoch 22180, Training-Loss 2.5552e+04, Data-loss 2.0665e+03                  , pde-loss 8.4685e+02, initc-loss 1.6323e+04                    bc_loss 6.3158e+03\n",
      "Epoch 22190, Training-Loss 2.5983e+04, Data-loss 1.2836e+03                  , pde-loss 9.4103e+02, initc-loss 1.4581e+04                    bc_loss 9.1770e+03\n",
      "Epoch 22200, Training-Loss 2.4326e+04, Data-loss 1.6851e+03                  , pde-loss 7.5205e+02, initc-loss 1.4439e+04                    bc_loss 7.4496e+03\n",
      "Epoch 22210, Training-Loss 2.0829e+04, Data-loss 1.1358e+03                  , pde-loss 1.4478e+03, initc-loss 1.4913e+04                    bc_loss 3.3321e+03\n",
      "Epoch 22220, Training-Loss 2.4865e+04, Data-loss 1.7586e+03                  , pde-loss 1.3443e+03, initc-loss 1.4586e+04                    bc_loss 7.1755e+03\n",
      "Epoch 22230, Training-Loss 2.7150e+04, Data-loss 1.2632e+03                  , pde-loss 1.0400e+03, initc-loss 1.3993e+04                    bc_loss 1.0854e+04\n",
      "Epoch 22240, Training-Loss 5.3321e+04, Data-loss 1.6013e+03                  , pde-loss 8.5184e+02, initc-loss 1.5494e+04                    bc_loss 3.5374e+04\n",
      "Epoch 22250, Training-Loss 4.9981e+04, Data-loss 3.0246e+03                  , pde-loss 1.6252e+03, initc-loss 1.7851e+04                    bc_loss 2.7480e+04\n",
      "Epoch 22260, Training-Loss 4.0279e+04, Data-loss 2.8917e+03                  , pde-loss 1.7394e+03, initc-loss 1.8079e+04                    bc_loss 1.7569e+04\n",
      "Epoch 22270, Training-Loss 3.1897e+04, Data-loss 1.3823e+03                  , pde-loss 1.1219e+03, initc-loss 1.7032e+04                    bc_loss 1.2361e+04\n",
      "Epoch 22280, Training-Loss 2.7925e+04, Data-loss 1.7902e+03                  , pde-loss 1.2378e+03, initc-loss 1.6881e+04                    bc_loss 8.0162e+03\n",
      "Epoch 22290, Training-Loss 2.7769e+04, Data-loss 2.0252e+03                  , pde-loss 8.9568e+02, initc-loss 1.7888e+04                    bc_loss 6.9600e+03\n",
      "Epoch 22300, Training-Loss 2.8933e+04, Data-loss 1.2709e+03                  , pde-loss 1.7665e+03, initc-loss 1.5271e+04                    bc_loss 1.0625e+04\n",
      "Epoch 22310, Training-Loss 3.5034e+04, Data-loss 1.3654e+03                  , pde-loss 1.0054e+03, initc-loss 1.5685e+04                    bc_loss 1.6979e+04\n",
      "Epoch 22320, Training-Loss 3.9283e+04, Data-loss 1.7957e+03                  , pde-loss 1.0824e+03, initc-loss 1.5506e+04                    bc_loss 2.0898e+04\n",
      "Epoch 22330, Training-Loss 3.5273e+04, Data-loss 2.0607e+03                  , pde-loss 1.1709e+03, initc-loss 1.6330e+04                    bc_loss 1.5712e+04\n",
      "Epoch 22340, Training-Loss 3.2846e+04, Data-loss 2.1851e+03                  , pde-loss 7.9687e+02, initc-loss 1.6856e+04                    bc_loss 1.3008e+04\n",
      "Epoch 22350, Training-Loss 2.7835e+04, Data-loss 2.3744e+03                  , pde-loss 8.4116e+02, initc-loss 1.5938e+04                    bc_loss 8.6816e+03\n",
      "Epoch 22360, Training-Loss 2.4804e+04, Data-loss 1.7231e+03                  , pde-loss 1.1517e+03, initc-loss 1.7359e+04                    bc_loss 4.5699e+03\n",
      "Epoch 22370, Training-Loss 2.3783e+04, Data-loss 1.6550e+03                  , pde-loss 1.0100e+03, initc-loss 1.6492e+04                    bc_loss 4.6263e+03\n",
      "Epoch 22380, Training-Loss 2.3261e+04, Data-loss 1.2280e+03                  , pde-loss 1.4215e+03, initc-loss 1.6726e+04                    bc_loss 3.8864e+03\n",
      "Epoch 22390, Training-Loss 2.5321e+04, Data-loss 2.1458e+03                  , pde-loss 1.1757e+03, initc-loss 1.6692e+04                    bc_loss 5.3071e+03\n",
      "Epoch 22400, Training-Loss 2.4282e+04, Data-loss 1.7802e+03                  , pde-loss 8.4329e+02, initc-loss 1.4137e+04                    bc_loss 7.5217e+03\n",
      "Epoch 22410, Training-Loss 2.2669e+04, Data-loss 1.5780e+03                  , pde-loss 1.1357e+03, initc-loss 1.4654e+04                    bc_loss 5.3013e+03\n",
      "Epoch 22420, Training-Loss 1.9809e+04, Data-loss 1.1204e+03                  , pde-loss 7.8777e+02, initc-loss 1.3817e+04                    bc_loss 4.0840e+03\n",
      "Epoch 22430, Training-Loss 1.7923e+04, Data-loss 8.4853e+02                  , pde-loss 5.2375e+02, initc-loss 1.3848e+04                    bc_loss 2.7033e+03\n",
      "Epoch 22440, Training-Loss 1.8567e+04, Data-loss 1.2450e+03                  , pde-loss 1.0617e+03, initc-loss 1.2540e+04                    bc_loss 3.7200e+03\n",
      "Epoch 22450, Training-Loss 2.0054e+04, Data-loss 9.1962e+02                  , pde-loss 6.8315e+02, initc-loss 1.2642e+04                    bc_loss 5.8092e+03\n",
      "Epoch 22460, Training-Loss 3.1259e+04, Data-loss 1.2441e+03                  , pde-loss 8.0532e+02, initc-loss 1.2891e+04                    bc_loss 1.6318e+04\n",
      "Epoch 22470, Training-Loss 2.9320e+04, Data-loss 1.7730e+03                  , pde-loss 7.6565e+02, initc-loss 1.4417e+04                    bc_loss 1.2364e+04\n",
      "Epoch 22480, Training-Loss 3.9853e+04, Data-loss 1.5132e+03                  , pde-loss 9.0459e+02, initc-loss 1.5010e+04                    bc_loss 2.2426e+04\n",
      "Epoch 22490, Training-Loss 3.6702e+04, Data-loss 2.7762e+03                  , pde-loss 1.2702e+03, initc-loss 1.6973e+04                    bc_loss 1.5682e+04\n",
      "Epoch 22500, Training-Loss 2.3840e+04, Data-loss 2.2845e+03                  , pde-loss 1.2250e+03, initc-loss 1.6338e+04                    bc_loss 3.9930e+03\n",
      "Epoch 22510, Training-Loss 2.3552e+04, Data-loss 2.8203e+03                  , pde-loss 2.5095e+03, initc-loss 1.5082e+04                    bc_loss 3.1397e+03\n",
      "Epoch 22520, Training-Loss 2.2984e+04, Data-loss 2.4616e+03                  , pde-loss 8.9400e+02, initc-loss 1.5189e+04                    bc_loss 4.4402e+03\n",
      "Epoch 22530, Training-Loss 2.1395e+04, Data-loss 1.3934e+03                  , pde-loss 1.0575e+03, initc-loss 1.4529e+04                    bc_loss 4.4153e+03\n",
      "Epoch 22540, Training-Loss 2.1627e+04, Data-loss 1.5560e+03                  , pde-loss 1.3572e+03, initc-loss 1.4670e+04                    bc_loss 4.0445e+03\n",
      "Epoch 22550, Training-Loss 2.2416e+04, Data-loss 9.7934e+02                  , pde-loss 2.0538e+03, initc-loss 1.3301e+04                    bc_loss 6.0813e+03\n",
      "Epoch 22560, Training-Loss 2.2568e+04, Data-loss 1.2883e+03                  , pde-loss 9.3393e+02, initc-loss 1.3773e+04                    bc_loss 6.5732e+03\n",
      "Epoch 22570, Training-Loss 2.9908e+04, Data-loss 9.6240e+02                  , pde-loss 1.0079e+03, initc-loss 1.5405e+04                    bc_loss 1.2534e+04\n",
      "Epoch 22580, Training-Loss 5.0104e+04, Data-loss 1.5663e+03                  , pde-loss 7.3701e+02, initc-loss 1.5039e+04                    bc_loss 3.2762e+04\n",
      "Epoch 22590, Training-Loss 4.0766e+04, Data-loss 2.5547e+03                  , pde-loss 8.8007e+02, initc-loss 1.7847e+04                    bc_loss 1.9484e+04\n",
      "Epoch 22600, Training-Loss 3.2634e+04, Data-loss 2.4236e+03                  , pde-loss 2.4644e+03, initc-loss 1.8057e+04                    bc_loss 9.6890e+03\n",
      "Epoch 22610, Training-Loss 2.9036e+04, Data-loss 1.6156e+03                  , pde-loss 9.9296e+02, initc-loss 1.7765e+04                    bc_loss 8.6626e+03\n",
      "Epoch 22620, Training-Loss 2.7394e+04, Data-loss 2.7881e+03                  , pde-loss 1.1850e+03, initc-loss 1.7613e+04                    bc_loss 5.8081e+03\n",
      "Epoch 22630, Training-Loss 2.2629e+04, Data-loss 1.7693e+03                  , pde-loss 9.7035e+02, initc-loss 1.6254e+04                    bc_loss 3.6346e+03\n",
      "Epoch 22640, Training-Loss 2.3027e+04, Data-loss 2.2318e+03                  , pde-loss 1.7052e+03, initc-loss 1.4915e+04                    bc_loss 4.1750e+03\n",
      "Epoch 22650, Training-Loss 2.1268e+04, Data-loss 1.4593e+03                  , pde-loss 7.5506e+02, initc-loss 1.4413e+04                    bc_loss 4.6397e+03\n",
      "Epoch 22660, Training-Loss 2.0605e+04, Data-loss 1.0082e+03                  , pde-loss 8.4977e+02, initc-loss 1.4426e+04                    bc_loss 4.3214e+03\n",
      "Epoch 22670, Training-Loss 1.9319e+04, Data-loss 1.3811e+03                  , pde-loss 7.7197e+02, initc-loss 1.4001e+04                    bc_loss 3.1651e+03\n",
      "Epoch 22680, Training-Loss 1.8030e+04, Data-loss 1.4020e+03                  , pde-loss 7.6313e+02, initc-loss 1.3405e+04                    bc_loss 2.4594e+03\n",
      "Epoch 22690, Training-Loss 2.3112e+04, Data-loss 9.7366e+02                  , pde-loss 5.5494e+02, initc-loss 1.3157e+04                    bc_loss 8.4269e+03\n",
      "Epoch 22700, Training-Loss 5.2134e+04, Data-loss 1.2586e+03                  , pde-loss 1.2091e+03, initc-loss 1.5757e+04                    bc_loss 3.3909e+04\n",
      "Epoch 22710, Training-Loss 4.5507e+04, Data-loss 2.7950e+03                  , pde-loss 1.0968e+03, initc-loss 1.7063e+04                    bc_loss 2.4552e+04\n",
      "Epoch 22720, Training-Loss 2.9304e+04, Data-loss 2.6896e+03                  , pde-loss 1.2866e+03, initc-loss 1.7817e+04                    bc_loss 7.5108e+03\n",
      "Epoch 22730, Training-Loss 2.6223e+04, Data-loss 2.4144e+03                  , pde-loss 9.0546e+02, initc-loss 1.5845e+04                    bc_loss 7.0583e+03\n",
      "Epoch 22740, Training-Loss 2.3562e+04, Data-loss 1.8431e+03                  , pde-loss 1.0649e+03, initc-loss 1.5458e+04                    bc_loss 5.1962e+03\n",
      "Epoch 22750, Training-Loss 2.1360e+04, Data-loss 1.7252e+03                  , pde-loss 1.1117e+03, initc-loss 1.5256e+04                    bc_loss 3.2674e+03\n",
      "Epoch 22760, Training-Loss 1.9315e+04, Data-loss 1.3987e+03                  , pde-loss 9.2677e+02, initc-loss 1.4342e+04                    bc_loss 2.6470e+03\n",
      "Epoch 22770, Training-Loss 1.9422e+04, Data-loss 1.0783e+03                  , pde-loss 1.3232e+03, initc-loss 1.4362e+04                    bc_loss 2.6584e+03\n",
      "Epoch 22780, Training-Loss 1.8698e+04, Data-loss 1.1699e+03                  , pde-loss 1.0661e+03, initc-loss 1.2915e+04                    bc_loss 3.5466e+03\n",
      "Epoch 22790, Training-Loss 2.4300e+04, Data-loss 8.3572e+02                  , pde-loss 8.1374e+02, initc-loss 1.3321e+04                    bc_loss 9.3298e+03\n",
      "Epoch 22800, Training-Loss 2.3897e+04, Data-loss 9.5474e+02                  , pde-loss 7.8990e+02, initc-loss 1.3189e+04                    bc_loss 8.9635e+03\n",
      "Epoch 22810, Training-Loss 3.2516e+04, Data-loss 1.3917e+03                  , pde-loss 1.4428e+03, initc-loss 1.4694e+04                    bc_loss 1.4988e+04\n",
      "Epoch 22820, Training-Loss 2.7581e+04, Data-loss 2.1459e+03                  , pde-loss 1.0693e+03, initc-loss 1.6694e+04                    bc_loss 7.6717e+03\n",
      "Epoch 22830, Training-Loss 2.7265e+04, Data-loss 2.1436e+03                  , pde-loss 9.5462e+02, initc-loss 1.8253e+04                    bc_loss 5.9143e+03\n",
      "Epoch 22840, Training-Loss 2.9200e+04, Data-loss 3.0421e+03                  , pde-loss 2.8959e+03, initc-loss 1.7079e+04                    bc_loss 6.1832e+03\n",
      "Epoch 22850, Training-Loss 2.4699e+04, Data-loss 2.6183e+03                  , pde-loss 1.9204e+03, initc-loss 1.5438e+04                    bc_loss 4.7219e+03\n",
      "Epoch 22860, Training-Loss 2.2339e+04, Data-loss 1.5542e+03                  , pde-loss 1.3879e+03, initc-loss 1.4324e+04                    bc_loss 5.0723e+03\n",
      "Epoch 22870, Training-Loss 2.0311e+04, Data-loss 1.1258e+03                  , pde-loss 1.0537e+03, initc-loss 1.4231e+04                    bc_loss 3.8998e+03\n",
      "Epoch 22880, Training-Loss 2.0262e+04, Data-loss 1.1983e+03                  , pde-loss 8.5734e+02, initc-loss 1.3439e+04                    bc_loss 4.7668e+03\n",
      "Epoch 22890, Training-Loss 2.2438e+04, Data-loss 1.7039e+03                  , pde-loss 1.1864e+03, initc-loss 1.3594e+04                    bc_loss 5.9532e+03\n",
      "Epoch 22900, Training-Loss 2.6196e+04, Data-loss 1.8312e+03                  , pde-loss 9.1387e+02, initc-loss 1.4736e+04                    bc_loss 8.7146e+03\n",
      "Epoch 22910, Training-Loss 2.7216e+04, Data-loss 7.9494e+02                  , pde-loss 5.1298e+02, initc-loss 1.4134e+04                    bc_loss 1.1775e+04\n",
      "Epoch 22920, Training-Loss 3.7935e+04, Data-loss 2.8610e+03                  , pde-loss 1.8996e+03, initc-loss 1.4220e+04                    bc_loss 1.8954e+04\n",
      "Epoch 22930, Training-Loss 2.8211e+04, Data-loss 1.8608e+03                  , pde-loss 1.3194e+03, initc-loss 1.5217e+04                    bc_loss 9.8144e+03\n",
      "Epoch 22940, Training-Loss 2.3025e+04, Data-loss 1.9628e+03                  , pde-loss 1.1174e+03, initc-loss 1.4580e+04                    bc_loss 5.3644e+03\n",
      "Epoch 22950, Training-Loss 2.1337e+04, Data-loss 1.3520e+03                  , pde-loss 7.1449e+02, initc-loss 1.4663e+04                    bc_loss 4.6073e+03\n",
      "Epoch 22960, Training-Loss 1.9098e+04, Data-loss 1.0458e+03                  , pde-loss 1.1976e+03, initc-loss 1.4071e+04                    bc_loss 2.7841e+03\n",
      "Epoch 22970, Training-Loss 1.9068e+04, Data-loss 9.0384e+02                  , pde-loss 7.6278e+02, initc-loss 1.4558e+04                    bc_loss 2.8434e+03\n",
      "Epoch 22980, Training-Loss 1.9395e+04, Data-loss 2.0409e+03                  , pde-loss 1.6893e+03, initc-loss 1.2393e+04                    bc_loss 3.2718e+03\n",
      "Epoch 22990, Training-Loss 2.2172e+04, Data-loss 1.1961e+03                  , pde-loss 8.9107e+02, initc-loss 1.4229e+04                    bc_loss 5.8550e+03\n",
      "Epoch 23000, Training-Loss 2.6204e+04, Data-loss 1.1577e+03                  , pde-loss 9.4614e+02, initc-loss 1.2259e+04                    bc_loss 1.1841e+04\n",
      "Epoch 23010, Training-Loss 2.5163e+04, Data-loss 1.5828e+03                  , pde-loss 1.2129e+03, initc-loss 1.3670e+04                    bc_loss 8.6969e+03\n",
      "Epoch 23020, Training-Loss 2.3816e+04, Data-loss 1.8257e+03                  , pde-loss 1.0600e+03, initc-loss 1.4739e+04                    bc_loss 6.1916e+03\n",
      "Epoch 23030, Training-Loss 2.3725e+04, Data-loss 1.8010e+03                  , pde-loss 1.3244e+03, initc-loss 1.4194e+04                    bc_loss 6.4057e+03\n",
      "Epoch 23040, Training-Loss 2.9922e+04, Data-loss 1.3589e+03                  , pde-loss 7.4789e+02, initc-loss 1.5162e+04                    bc_loss 1.2654e+04\n",
      "Epoch 23050, Training-Loss 2.1658e+04, Data-loss 1.5488e+03                  , pde-loss 1.1269e+03, initc-loss 1.4223e+04                    bc_loss 4.7591e+03\n",
      "Epoch 23060, Training-Loss 1.9314e+04, Data-loss 1.1399e+03                  , pde-loss 8.4467e+02, initc-loss 1.4254e+04                    bc_loss 3.0750e+03\n",
      "Epoch 23070, Training-Loss 2.3813e+04, Data-loss 1.2897e+03                  , pde-loss 1.0422e+03, initc-loss 1.3469e+04                    bc_loss 8.0122e+03\n",
      "Epoch 23080, Training-Loss 2.1615e+04, Data-loss 1.1212e+03                  , pde-loss 1.1219e+03, initc-loss 1.4581e+04                    bc_loss 4.7912e+03\n",
      "Epoch 23090, Training-Loss 2.1115e+04, Data-loss 1.1693e+03                  , pde-loss 1.1180e+03, initc-loss 1.4215e+04                    bc_loss 4.6135e+03\n",
      "Epoch 23100, Training-Loss 2.6652e+04, Data-loss 1.8529e+03                  , pde-loss 1.2665e+03, initc-loss 1.4607e+04                    bc_loss 8.9255e+03\n",
      "Epoch 23110, Training-Loss 2.6029e+04, Data-loss 2.1984e+03                  , pde-loss 1.9466e+03, initc-loss 1.4584e+04                    bc_loss 7.3003e+03\n",
      "Epoch 23120, Training-Loss 2.2939e+04, Data-loss 1.1420e+03                  , pde-loss 1.1755e+03, initc-loss 1.4904e+04                    bc_loss 5.7175e+03\n",
      "Epoch 23130, Training-Loss 2.0582e+04, Data-loss 1.0049e+03                  , pde-loss 7.0460e+02, initc-loss 1.3952e+04                    bc_loss 4.9207e+03\n",
      "Epoch 23140, Training-Loss 2.3871e+04, Data-loss 8.6003e+02                  , pde-loss 1.2908e+03, initc-loss 1.5984e+04                    bc_loss 5.7357e+03\n",
      "Epoch 23150, Training-Loss 2.0447e+04, Data-loss 9.2619e+02                  , pde-loss 8.3047e+02, initc-loss 1.3195e+04                    bc_loss 5.4945e+03\n",
      "Epoch 23160, Training-Loss 3.3274e+04, Data-loss 1.7337e+03                  , pde-loss 1.3916e+03, initc-loss 1.5813e+04                    bc_loss 1.4336e+04\n",
      "Epoch 23170, Training-Loss 2.7115e+04, Data-loss 1.6012e+03                  , pde-loss 1.0982e+03, initc-loss 1.5755e+04                    bc_loss 8.6602e+03\n",
      "Epoch 23180, Training-Loss 2.9164e+04, Data-loss 2.1596e+03                  , pde-loss 1.0225e+03, initc-loss 1.7650e+04                    bc_loss 8.3325e+03\n",
      "Epoch 23190, Training-Loss 2.5575e+04, Data-loss 1.8289e+03                  , pde-loss 1.6175e+03, initc-loss 1.6558e+04                    bc_loss 5.5701e+03\n",
      "Epoch 23200, Training-Loss 2.2764e+04, Data-loss 1.2057e+03                  , pde-loss 7.6351e+02, initc-loss 1.5391e+04                    bc_loss 5.4040e+03\n",
      "Epoch 23210, Training-Loss 2.4742e+04, Data-loss 2.6719e+03                  , pde-loss 2.2043e+03, initc-loss 1.4935e+04                    bc_loss 4.9312e+03\n",
      "Epoch 23220, Training-Loss 2.2345e+04, Data-loss 1.3838e+03                  , pde-loss 1.1188e+03, initc-loss 1.4837e+04                    bc_loss 5.0056e+03\n",
      "Epoch 23230, Training-Loss 1.8411e+04, Data-loss 1.2424e+03                  , pde-loss 8.9023e+02, initc-loss 1.3419e+04                    bc_loss 2.8591e+03\n",
      "Epoch 23240, Training-Loss 1.9874e+04, Data-loss 8.2901e+02                  , pde-loss 9.4421e+02, initc-loss 1.2310e+04                    bc_loss 5.7909e+03\n",
      "Epoch 23250, Training-Loss 2.7170e+04, Data-loss 1.5610e+03                  , pde-loss 1.5909e+03, initc-loss 1.2950e+04                    bc_loss 1.1068e+04\n",
      "Epoch 23260, Training-Loss 3.0834e+04, Data-loss 1.5945e+03                  , pde-loss 1.0219e+03, initc-loss 1.3669e+04                    bc_loss 1.4549e+04\n",
      "Epoch 23270, Training-Loss 3.4081e+04, Data-loss 1.6831e+03                  , pde-loss 9.6310e+02, initc-loss 1.4163e+04                    bc_loss 1.7272e+04\n",
      "Epoch 23280, Training-Loss 2.6017e+04, Data-loss 1.5144e+03                  , pde-loss 6.9296e+02, initc-loss 1.7840e+04                    bc_loss 5.9697e+03\n",
      "Epoch 23290, Training-Loss 2.4568e+04, Data-loss 1.9565e+03                  , pde-loss 1.7332e+03, initc-loss 1.6093e+04                    bc_loss 4.7857e+03\n",
      "Epoch 23300, Training-Loss 2.1284e+04, Data-loss 1.5031e+03                  , pde-loss 7.2584e+02, initc-loss 1.5200e+04                    bc_loss 3.8557e+03\n",
      "Epoch 23310, Training-Loss 2.0043e+04, Data-loss 1.2252e+03                  , pde-loss 9.9809e+02, initc-loss 1.5208e+04                    bc_loss 2.6117e+03\n",
      "Epoch 23320, Training-Loss 1.7259e+04, Data-loss 9.9507e+02                  , pde-loss 1.2724e+03, initc-loss 1.3427e+04                    bc_loss 1.5646e+03\n",
      "Epoch 23330, Training-Loss 1.7249e+04, Data-loss 1.1628e+03                  , pde-loss 6.6416e+02, initc-loss 1.3186e+04                    bc_loss 2.2359e+03\n",
      "Epoch 23340, Training-Loss 1.8199e+04, Data-loss 1.6326e+03                  , pde-loss 1.0878e+03, initc-loss 1.2029e+04                    bc_loss 3.4495e+03\n",
      "Epoch 23350, Training-Loss 1.9151e+04, Data-loss 8.0234e+02                  , pde-loss 7.9004e+02, initc-loss 1.3369e+04                    bc_loss 4.1890e+03\n",
      "Epoch 23360, Training-Loss 2.4995e+04, Data-loss 1.7251e+03                  , pde-loss 1.2202e+03, initc-loss 1.3742e+04                    bc_loss 8.3077e+03\n",
      "Epoch 23370, Training-Loss 2.9881e+04, Data-loss 1.8835e+03                  , pde-loss 1.6611e+03, initc-loss 1.4540e+04                    bc_loss 1.1796e+04\n",
      "Epoch 23380, Training-Loss 2.5584e+04, Data-loss 2.1564e+03                  , pde-loss 1.7336e+03, initc-loss 1.4552e+04                    bc_loss 7.1416e+03\n",
      "Epoch 23390, Training-Loss 2.5032e+04, Data-loss 1.7396e+03                  , pde-loss 1.1579e+03, initc-loss 1.4789e+04                    bc_loss 7.3448e+03\n",
      "Epoch 23400, Training-Loss 2.1672e+04, Data-loss 1.5921e+03                  , pde-loss 1.3858e+03, initc-loss 1.4672e+04                    bc_loss 4.0219e+03\n",
      "Epoch 23410, Training-Loss 2.0671e+04, Data-loss 1.3638e+03                  , pde-loss 9.6232e+02, initc-loss 1.4022e+04                    bc_loss 4.3237e+03\n",
      "Epoch 23420, Training-Loss 2.2232e+04, Data-loss 2.5525e+03                  , pde-loss 1.7330e+03, initc-loss 1.3448e+04                    bc_loss 4.4989e+03\n",
      "Epoch 23430, Training-Loss 2.3059e+04, Data-loss 8.7204e+02                  , pde-loss 8.5877e+02, initc-loss 1.4946e+04                    bc_loss 6.3826e+03\n",
      "Epoch 23440, Training-Loss 2.2601e+04, Data-loss 1.0518e+03                  , pde-loss 9.6308e+02, initc-loss 1.3429e+04                    bc_loss 7.1563e+03\n",
      "Epoch 23450, Training-Loss 2.8431e+04, Data-loss 1.3526e+03                  , pde-loss 6.6059e+02, initc-loss 1.3840e+04                    bc_loss 1.2578e+04\n",
      "Epoch 23460, Training-Loss 2.7695e+04, Data-loss 1.9400e+03                  , pde-loss 9.9689e+02, initc-loss 1.5144e+04                    bc_loss 9.6139e+03\n",
      "Epoch 23470, Training-Loss 2.9119e+04, Data-loss 1.9860e+03                  , pde-loss 9.1609e+02, initc-loss 1.5824e+04                    bc_loss 1.0393e+04\n",
      "Epoch 23480, Training-Loss 2.4083e+04, Data-loss 1.5329e+03                  , pde-loss 7.6967e+02, initc-loss 1.5152e+04                    bc_loss 6.6290e+03\n",
      "Epoch 23490, Training-Loss 2.6875e+04, Data-loss 1.6095e+03                  , pde-loss 1.2673e+03, initc-loss 1.6702e+04                    bc_loss 7.2958e+03\n",
      "Epoch 23500, Training-Loss 2.2748e+04, Data-loss 9.4022e+02                  , pde-loss 6.9705e+02, initc-loss 1.3230e+04                    bc_loss 7.8813e+03\n",
      "Epoch 23510, Training-Loss 2.3763e+04, Data-loss 1.5806e+03                  , pde-loss 8.1386e+02, initc-loss 1.3994e+04                    bc_loss 7.3744e+03\n",
      "Epoch 23520, Training-Loss 2.5489e+04, Data-loss 8.2391e+02                  , pde-loss 8.3020e+02, initc-loss 1.7085e+04                    bc_loss 6.7492e+03\n",
      "Epoch 23530, Training-Loss 2.4426e+04, Data-loss 1.5418e+03                  , pde-loss 1.4045e+03, initc-loss 1.4746e+04                    bc_loss 6.7341e+03\n",
      "Epoch 23540, Training-Loss 2.4289e+04, Data-loss 8.8982e+02                  , pde-loss 1.0397e+03, initc-loss 1.2977e+04                    bc_loss 9.3833e+03\n",
      "Epoch 23550, Training-Loss 2.7042e+04, Data-loss 1.9263e+03                  , pde-loss 1.0254e+03, initc-loss 1.4022e+04                    bc_loss 1.0068e+04\n",
      "Epoch 23560, Training-Loss 2.9893e+04, Data-loss 1.9279e+03                  , pde-loss 1.3614e+03, initc-loss 1.5339e+04                    bc_loss 1.1265e+04\n",
      "Epoch 23570, Training-Loss 3.7692e+04, Data-loss 2.6640e+03                  , pde-loss 9.2957e+02, initc-loss 1.6670e+04                    bc_loss 1.7429e+04\n",
      "Epoch 23580, Training-Loss 4.6405e+04, Data-loss 2.3025e+03                  , pde-loss 1.3035e+03, initc-loss 1.8083e+04                    bc_loss 2.4716e+04\n",
      "Epoch 23590, Training-Loss 5.3206e+04, Data-loss 4.0591e+03                  , pde-loss 2.7540e+03, initc-loss 1.8580e+04                    bc_loss 2.7813e+04\n",
      "Epoch 23600, Training-Loss 3.1199e+04, Data-loss 2.0502e+03                  , pde-loss 1.3196e+03, initc-loss 1.6515e+04                    bc_loss 1.1315e+04\n",
      "Epoch 23610, Training-Loss 3.1342e+04, Data-loss 2.1901e+03                  , pde-loss 1.3464e+03, initc-loss 1.7121e+04                    bc_loss 1.0685e+04\n",
      "Epoch 23620, Training-Loss 2.3620e+04, Data-loss 1.7389e+03                  , pde-loss 2.2234e+03, initc-loss 1.6111e+04                    bc_loss 3.5467e+03\n",
      "Epoch 23630, Training-Loss 2.3446e+04, Data-loss 1.8811e+03                  , pde-loss 1.1659e+03, initc-loss 1.5374e+04                    bc_loss 5.0253e+03\n",
      "Epoch 23640, Training-Loss 2.7360e+04, Data-loss 3.2785e+03                  , pde-loss 1.1567e+03, initc-loss 1.5319e+04                    bc_loss 7.6057e+03\n",
      "Epoch 23650, Training-Loss 2.7681e+04, Data-loss 1.8824e+03                  , pde-loss 1.3699e+03, initc-loss 1.4602e+04                    bc_loss 9.8264e+03\n",
      "Epoch 23660, Training-Loss 3.1075e+04, Data-loss 1.4573e+03                  , pde-loss 1.0710e+03, initc-loss 1.4731e+04                    bc_loss 1.3816e+04\n",
      "Epoch 23670, Training-Loss 3.0495e+04, Data-loss 1.5219e+03                  , pde-loss 1.1207e+03, initc-loss 1.6080e+04                    bc_loss 1.1772e+04\n",
      "Epoch 23680, Training-Loss 2.9641e+04, Data-loss 2.1751e+03                  , pde-loss 1.9459e+03, initc-loss 1.5662e+04                    bc_loss 9.8584e+03\n",
      "Epoch 23690, Training-Loss 2.6915e+04, Data-loss 1.9763e+03                  , pde-loss 8.3079e+02, initc-loss 1.4914e+04                    bc_loss 9.1931e+03\n",
      "Epoch 23700, Training-Loss 4.5157e+04, Data-loss 4.3198e+03                  , pde-loss 3.2410e+03, initc-loss 1.5289e+04                    bc_loss 2.2307e+04\n",
      "Epoch 23710, Training-Loss 3.2065e+04, Data-loss 2.2480e+03                  , pde-loss 7.9588e+02, initc-loss 1.6394e+04                    bc_loss 1.2627e+04\n",
      "Epoch 23720, Training-Loss 4.6168e+04, Data-loss 3.9812e+03                  , pde-loss 1.5976e+03, initc-loss 1.9061e+04                    bc_loss 2.1529e+04\n",
      "Epoch 23730, Training-Loss 5.0225e+04, Data-loss 5.2222e+03                  , pde-loss 1.2444e+03, initc-loss 2.1378e+04                    bc_loss 2.2381e+04\n",
      "Epoch 23740, Training-Loss 3.4252e+04, Data-loss 3.2688e+03                  , pde-loss 7.1565e+02, initc-loss 2.0789e+04                    bc_loss 9.4786e+03\n",
      "Epoch 23750, Training-Loss 2.7555e+04, Data-loss 3.4737e+03                  , pde-loss 1.0448e+03, initc-loss 1.9317e+04                    bc_loss 3.7202e+03\n",
      "Epoch 23760, Training-Loss 2.7409e+04, Data-loss 3.2923e+03                  , pde-loss 1.7585e+03, initc-loss 1.9779e+04                    bc_loss 2.5792e+03\n",
      "Epoch 23770, Training-Loss 2.1692e+04, Data-loss 1.7676e+03                  , pde-loss 8.2843e+02, initc-loss 1.6653e+04                    bc_loss 2.4427e+03\n",
      "Epoch 23780, Training-Loss 1.9398e+04, Data-loss 1.4953e+03                  , pde-loss 8.3902e+02, initc-loss 1.5527e+04                    bc_loss 1.5362e+03\n",
      "Epoch 23790, Training-Loss 1.9386e+04, Data-loss 1.4314e+03                  , pde-loss 1.2594e+03, initc-loss 1.4892e+04                    bc_loss 1.8032e+03\n",
      "Epoch 23800, Training-Loss 2.4662e+04, Data-loss 1.6164e+03                  , pde-loss 9.1585e+02, initc-loss 1.4737e+04                    bc_loss 7.3923e+03\n",
      "Epoch 23810, Training-Loss 2.5027e+04, Data-loss 1.7182e+03                  , pde-loss 1.4301e+03, initc-loss 1.5820e+04                    bc_loss 6.0585e+03\n",
      "Epoch 23820, Training-Loss 2.7176e+04, Data-loss 1.3210e+03                  , pde-loss 1.0905e+03, initc-loss 1.5157e+04                    bc_loss 9.6077e+03\n",
      "Epoch 23830, Training-Loss 4.1187e+04, Data-loss 2.4927e+03                  , pde-loss 1.1683e+03, initc-loss 1.4325e+04                    bc_loss 2.3201e+04\n",
      "Epoch 23840, Training-Loss 2.5269e+04, Data-loss 1.8572e+03                  , pde-loss 9.9683e+02, initc-loss 1.5951e+04                    bc_loss 6.4635e+03\n",
      "Epoch 23850, Training-Loss 2.6911e+04, Data-loss 1.3557e+03                  , pde-loss 1.3343e+03, initc-loss 1.6766e+04                    bc_loss 7.4555e+03\n",
      "Epoch 23860, Training-Loss 2.3229e+04, Data-loss 1.9779e+03                  , pde-loss 1.0381e+03, initc-loss 1.5683e+04                    bc_loss 4.5297e+03\n",
      "Epoch 23870, Training-Loss 2.4044e+04, Data-loss 1.7759e+03                  , pde-loss 8.5310e+02, initc-loss 1.5299e+04                    bc_loss 6.1159e+03\n",
      "Epoch 23880, Training-Loss 2.4436e+04, Data-loss 1.6862e+03                  , pde-loss 9.4533e+02, initc-loss 1.6745e+04                    bc_loss 5.0591e+03\n",
      "Epoch 23890, Training-Loss 3.3351e+04, Data-loss 1.6555e+03                  , pde-loss 9.4869e+02, initc-loss 1.5236e+04                    bc_loss 1.5511e+04\n",
      "Epoch 23900, Training-Loss 2.6188e+04, Data-loss 1.7462e+03                  , pde-loss 1.2480e+03, initc-loss 1.4263e+04                    bc_loss 8.9305e+03\n",
      "Epoch 23910, Training-Loss 3.1246e+04, Data-loss 1.6845e+03                  , pde-loss 9.7082e+02, initc-loss 1.5187e+04                    bc_loss 1.3404e+04\n",
      "Epoch 23920, Training-Loss 3.0605e+04, Data-loss 3.3835e+03                  , pde-loss 9.5211e+02, initc-loss 1.7537e+04                    bc_loss 8.7326e+03\n",
      "Epoch 23930, Training-Loss 2.4284e+04, Data-loss 2.0518e+03                  , pde-loss 9.8842e+02, initc-loss 1.6469e+04                    bc_loss 4.7749e+03\n",
      "Epoch 23940, Training-Loss 2.1925e+04, Data-loss 2.2272e+03                  , pde-loss 7.1173e+02, initc-loss 1.5799e+04                    bc_loss 3.1877e+03\n",
      "Epoch 23950, Training-Loss 2.1916e+04, Data-loss 1.3588e+03                  , pde-loss 8.9272e+02, initc-loss 1.6028e+04                    bc_loss 3.6363e+03\n",
      "Epoch 23960, Training-Loss 3.1520e+04, Data-loss 2.2254e+03                  , pde-loss 1.9284e+03, initc-loss 1.4360e+04                    bc_loss 1.3005e+04\n",
      "Epoch 23970, Training-Loss 2.0330e+04, Data-loss 1.0475e+03                  , pde-loss 6.8547e+02, initc-loss 1.4672e+04                    bc_loss 3.9247e+03\n",
      "Epoch 23980, Training-Loss 2.7358e+04, Data-loss 1.7100e+03                  , pde-loss 1.4971e+03, initc-loss 1.4432e+04                    bc_loss 9.7182e+03\n",
      "Epoch 23990, Training-Loss 3.2149e+04, Data-loss 1.6883e+03                  , pde-loss 1.0314e+03, initc-loss 1.7377e+04                    bc_loss 1.2053e+04\n",
      "Epoch 24000, Training-Loss 3.1059e+04, Data-loss 2.3418e+03                  , pde-loss 1.0118e+03, initc-loss 1.6607e+04                    bc_loss 1.1099e+04\n",
      "Epoch 24010, Training-Loss 2.8822e+04, Data-loss 1.7421e+03                  , pde-loss 8.7826e+02, initc-loss 1.7708e+04                    bc_loss 8.4938e+03\n",
      "Epoch 24020, Training-Loss 2.8831e+04, Data-loss 4.1653e+03                  , pde-loss 2.6257e+03, initc-loss 1.5405e+04                    bc_loss 6.6351e+03\n",
      "Epoch 24030, Training-Loss 2.1923e+04, Data-loss 1.3380e+03                  , pde-loss 8.3396e+02, initc-loss 1.5428e+04                    bc_loss 4.3233e+03\n",
      "Epoch 24040, Training-Loss 2.2563e+04, Data-loss 1.8042e+03                  , pde-loss 1.5759e+03, initc-loss 1.4514e+04                    bc_loss 4.6691e+03\n",
      "Epoch 24050, Training-Loss 2.7773e+04, Data-loss 1.6271e+03                  , pde-loss 8.2450e+02, initc-loss 1.4826e+04                    bc_loss 1.0495e+04\n",
      "Epoch 24060, Training-Loss 2.2608e+04, Data-loss 2.5368e+03                  , pde-loss 1.2691e+03, initc-loss 1.5746e+04                    bc_loss 3.0555e+03\n",
      "Epoch 24070, Training-Loss 2.2428e+04, Data-loss 1.5469e+03                  , pde-loss 7.9055e+02, initc-loss 1.5739e+04                    bc_loss 4.3515e+03\n",
      "Epoch 24080, Training-Loss 2.5246e+04, Data-loss 1.1330e+03                  , pde-loss 7.1846e+02, initc-loss 1.7277e+04                    bc_loss 6.1174e+03\n",
      "Epoch 24090, Training-Loss 1.9853e+04, Data-loss 1.2068e+03                  , pde-loss 9.8670e+02, initc-loss 1.5115e+04                    bc_loss 2.5445e+03\n",
      "Epoch 24100, Training-Loss 1.8538e+04, Data-loss 1.2397e+03                  , pde-loss 7.9780e+02, initc-loss 1.4139e+04                    bc_loss 2.3618e+03\n",
      "Epoch 24110, Training-Loss 1.8722e+04, Data-loss 1.2290e+03                  , pde-loss 7.4688e+02, initc-loss 1.3550e+04                    bc_loss 3.1965e+03\n",
      "Epoch 24120, Training-Loss 2.4181e+04, Data-loss 1.1035e+03                  , pde-loss 7.0492e+02, initc-loss 1.4166e+04                    bc_loss 8.2067e+03\n",
      "Epoch 24130, Training-Loss 2.4226e+04, Data-loss 1.3501e+03                  , pde-loss 1.2216e+03, initc-loss 1.3413e+04                    bc_loss 8.2407e+03\n",
      "Epoch 24140, Training-Loss 2.2010e+04, Data-loss 9.0249e+02                  , pde-loss 8.0394e+02, initc-loss 1.4254e+04                    bc_loss 6.0491e+03\n",
      "Epoch 24150, Training-Loss 2.0122e+04, Data-loss 1.1771e+03                  , pde-loss 9.8069e+02, initc-loss 1.4414e+04                    bc_loss 3.5507e+03\n",
      "Epoch 24160, Training-Loss 1.8809e+04, Data-loss 1.8231e+03                  , pde-loss 1.3381e+03, initc-loss 1.3010e+04                    bc_loss 2.6380e+03\n",
      "Epoch 24170, Training-Loss 1.7406e+04, Data-loss 8.7691e+02                  , pde-loss 6.1609e+02, initc-loss 1.3034e+04                    bc_loss 2.8792e+03\n",
      "Epoch 24180, Training-Loss 2.0144e+04, Data-loss 1.4727e+03                  , pde-loss 1.2093e+03, initc-loss 1.3154e+04                    bc_loss 4.3075e+03\n",
      "Epoch 24190, Training-Loss 1.9647e+04, Data-loss 1.0671e+03                  , pde-loss 7.7738e+02, initc-loss 1.2662e+04                    bc_loss 5.1396e+03\n",
      "Epoch 24200, Training-Loss 1.9497e+04, Data-loss 8.7404e+02                  , pde-loss 9.5333e+02, initc-loss 1.2308e+04                    bc_loss 5.3622e+03\n",
      "Epoch 24210, Training-Loss 2.2018e+04, Data-loss 1.1115e+03                  , pde-loss 1.0433e+03, initc-loss 1.3875e+04                    bc_loss 5.9881e+03\n",
      "Epoch 24220, Training-Loss 2.2886e+04, Data-loss 2.0801e+03                  , pde-loss 8.6147e+02, initc-loss 1.3553e+04                    bc_loss 6.3912e+03\n",
      "Epoch 24230, Training-Loss 2.7073e+04, Data-loss 1.5008e+03                  , pde-loss 7.2887e+02, initc-loss 1.3268e+04                    bc_loss 1.1575e+04\n",
      "Epoch 24240, Training-Loss 3.1567e+04, Data-loss 1.7758e+03                  , pde-loss 1.2583e+03, initc-loss 1.4035e+04                    bc_loss 1.4498e+04\n",
      "Epoch 24250, Training-Loss 3.0532e+04, Data-loss 1.6294e+03                  , pde-loss 6.2978e+02, initc-loss 1.5087e+04                    bc_loss 1.3186e+04\n",
      "Epoch 24260, Training-Loss 2.5067e+04, Data-loss 2.7376e+03                  , pde-loss 1.4273e+03, initc-loss 1.5128e+04                    bc_loss 5.7740e+03\n",
      "Epoch 24270, Training-Loss 2.5499e+04, Data-loss 1.9171e+03                  , pde-loss 7.3484e+02, initc-loss 1.5259e+04                    bc_loss 7.5877e+03\n",
      "Epoch 24280, Training-Loss 2.3672e+04, Data-loss 2.6574e+03                  , pde-loss 1.0621e+03, initc-loss 1.4714e+04                    bc_loss 5.2381e+03\n",
      "Epoch 24290, Training-Loss 2.3218e+04, Data-loss 1.5692e+03                  , pde-loss 8.7854e+02, initc-loss 1.4582e+04                    bc_loss 6.1890e+03\n",
      "Epoch 24300, Training-Loss 3.1375e+04, Data-loss 2.7913e+03                  , pde-loss 3.0253e+03, initc-loss 1.6450e+04                    bc_loss 9.1083e+03\n",
      "Epoch 24310, Training-Loss 2.6640e+04, Data-loss 1.7119e+03                  , pde-loss 7.9374e+02, initc-loss 1.4839e+04                    bc_loss 9.2957e+03\n",
      "Epoch 24320, Training-Loss 1.8764e+04, Data-loss 1.2113e+03                  , pde-loss 8.6659e+02, initc-loss 1.2727e+04                    bc_loss 3.9595e+03\n",
      "Epoch 24330, Training-Loss 2.0081e+04, Data-loss 1.5018e+03                  , pde-loss 9.3632e+02, initc-loss 1.3498e+04                    bc_loss 4.1444e+03\n",
      "Epoch 24340, Training-Loss 2.1433e+04, Data-loss 1.1918e+03                  , pde-loss 2.0178e+03, initc-loss 1.4041e+04                    bc_loss 4.1823e+03\n",
      "Epoch 24350, Training-Loss 2.8896e+04, Data-loss 1.7440e+03                  , pde-loss 1.1563e+03, initc-loss 1.3022e+04                    bc_loss 1.2974e+04\n",
      "Epoch 24360, Training-Loss 2.5483e+04, Data-loss 1.4318e+03                  , pde-loss 8.3650e+02, initc-loss 1.4538e+04                    bc_loss 8.6758e+03\n",
      "Epoch 24370, Training-Loss 2.2757e+04, Data-loss 1.8831e+03                  , pde-loss 1.5411e+03, initc-loss 1.5108e+04                    bc_loss 4.2242e+03\n",
      "Epoch 24380, Training-Loss 2.0415e+04, Data-loss 1.5706e+03                  , pde-loss 1.7377e+03, initc-loss 1.3954e+04                    bc_loss 3.1527e+03\n",
      "Epoch 24390, Training-Loss 1.9622e+04, Data-loss 1.0073e+03                  , pde-loss 1.2130e+03, initc-loss 1.3912e+04                    bc_loss 3.4901e+03\n",
      "Epoch 24400, Training-Loss 2.0149e+04, Data-loss 1.3789e+03                  , pde-loss 1.0220e+03, initc-loss 1.3362e+04                    bc_loss 4.3868e+03\n",
      "Epoch 24410, Training-Loss 2.0916e+04, Data-loss 1.3261e+03                  , pde-loss 7.4235e+02, initc-loss 1.3610e+04                    bc_loss 5.2373e+03\n",
      "Epoch 24420, Training-Loss 3.0874e+04, Data-loss 2.5210e+03                  , pde-loss 1.2171e+03, initc-loss 1.3257e+04                    bc_loss 1.3879e+04\n",
      "Epoch 24430, Training-Loss 5.6614e+04, Data-loss 2.1716e+03                  , pde-loss 1.1881e+03, initc-loss 1.4324e+04                    bc_loss 3.8931e+04\n",
      "Epoch 24440, Training-Loss 4.2518e+04, Data-loss 2.9891e+03                  , pde-loss 1.1576e+03, initc-loss 1.7748e+04                    bc_loss 2.0624e+04\n",
      "Epoch 24450, Training-Loss 3.6736e+04, Data-loss 3.2853e+03                  , pde-loss 1.2351e+03, initc-loss 1.7644e+04                    bc_loss 1.4571e+04\n",
      "Epoch 24460, Training-Loss 3.0774e+04, Data-loss 3.1464e+03                  , pde-loss 1.1990e+03, initc-loss 1.8194e+04                    bc_loss 8.2347e+03\n",
      "Epoch 24470, Training-Loss 2.8686e+04, Data-loss 3.1428e+03                  , pde-loss 1.0652e+03, initc-loss 1.9995e+04                    bc_loss 4.4824e+03\n",
      "Epoch 24480, Training-Loss 2.5288e+04, Data-loss 1.9981e+03                  , pde-loss 1.1161e+03, initc-loss 1.7207e+04                    bc_loss 4.9670e+03\n",
      "Epoch 24490, Training-Loss 2.4889e+04, Data-loss 1.7646e+03                  , pde-loss 1.3069e+03, initc-loss 1.4475e+04                    bc_loss 7.3422e+03\n",
      "Epoch 24500, Training-Loss 3.0423e+04, Data-loss 1.8807e+03                  , pde-loss 7.7030e+02, initc-loss 1.6578e+04                    bc_loss 1.1194e+04\n",
      "Epoch 24510, Training-Loss 3.2162e+04, Data-loss 1.4089e+03                  , pde-loss 1.1031e+03, initc-loss 1.5874e+04                    bc_loss 1.3776e+04\n",
      "Epoch 24520, Training-Loss 3.1212e+04, Data-loss 2.2899e+03                  , pde-loss 1.0444e+03, initc-loss 1.6133e+04                    bc_loss 1.1744e+04\n",
      "Epoch 24530, Training-Loss 3.1261e+04, Data-loss 1.9530e+03                  , pde-loss 1.1973e+03, initc-loss 1.5585e+04                    bc_loss 1.2526e+04\n",
      "Epoch 24540, Training-Loss 2.8395e+04, Data-loss 2.8573e+03                  , pde-loss 1.7305e+03, initc-loss 1.6236e+04                    bc_loss 7.5717e+03\n",
      "Epoch 24550, Training-Loss 2.7188e+04, Data-loss 2.4298e+03                  , pde-loss 1.4286e+03, initc-loss 1.4134e+04                    bc_loss 9.1955e+03\n",
      "Epoch 24560, Training-Loss 3.8091e+04, Data-loss 1.6658e+03                  , pde-loss 1.5625e+03, initc-loss 1.5007e+04                    bc_loss 1.9855e+04\n",
      "Epoch 24570, Training-Loss 3.5558e+04, Data-loss 2.1899e+03                  , pde-loss 1.1501e+03, initc-loss 1.5738e+04                    bc_loss 1.6480e+04\n",
      "Epoch 24580, Training-Loss 2.6188e+04, Data-loss 2.5352e+03                  , pde-loss 2.0535e+03, initc-loss 1.6344e+04                    bc_loss 5.2549e+03\n",
      "Epoch 24590, Training-Loss 2.1367e+04, Data-loss 1.3780e+03                  , pde-loss 1.1025e+03, initc-loss 1.5881e+04                    bc_loss 3.0055e+03\n",
      "Epoch 24600, Training-Loss 2.1237e+04, Data-loss 1.6976e+03                  , pde-loss 1.6226e+03, initc-loss 1.4647e+04                    bc_loss 3.2699e+03\n",
      "Epoch 24610, Training-Loss 2.1144e+04, Data-loss 1.3543e+03                  , pde-loss 1.2978e+03, initc-loss 1.4317e+04                    bc_loss 4.1751e+03\n",
      "Epoch 24620, Training-Loss 2.2155e+04, Data-loss 1.4194e+03                  , pde-loss 8.6872e+02, initc-loss 1.3737e+04                    bc_loss 6.1293e+03\n",
      "Epoch 24630, Training-Loss 2.4191e+04, Data-loss 1.5327e+03                  , pde-loss 1.2925e+03, initc-loss 1.4497e+04                    bc_loss 6.8685e+03\n",
      "Epoch 24640, Training-Loss 4.8711e+04, Data-loss 1.7009e+03                  , pde-loss 1.0371e+03, initc-loss 1.4883e+04                    bc_loss 3.1090e+04\n",
      "Epoch 24650, Training-Loss 2.8669e+04, Data-loss 2.4419e+03                  , pde-loss 8.6859e+02, initc-loss 1.4780e+04                    bc_loss 1.0579e+04\n",
      "Epoch 24660, Training-Loss 3.9208e+04, Data-loss 2.0932e+03                  , pde-loss 1.2300e+03, initc-loss 1.7400e+04                    bc_loss 1.8485e+04\n",
      "Epoch 24670, Training-Loss 3.0304e+04, Data-loss 1.8327e+03                  , pde-loss 2.1223e+03, initc-loss 1.4866e+04                    bc_loss 1.1483e+04\n",
      "Epoch 24680, Training-Loss 2.2163e+04, Data-loss 1.9394e+03                  , pde-loss 1.3974e+03, initc-loss 1.5119e+04                    bc_loss 3.7071e+03\n",
      "Epoch 24690, Training-Loss 2.1672e+04, Data-loss 1.4231e+03                  , pde-loss 1.2317e+03, initc-loss 1.4991e+04                    bc_loss 4.0265e+03\n",
      "Epoch 24700, Training-Loss 2.3983e+04, Data-loss 2.4285e+03                  , pde-loss 1.3835e+03, initc-loss 1.4227e+04                    bc_loss 5.9445e+03\n",
      "Epoch 24710, Training-Loss 2.0448e+04, Data-loss 1.1298e+03                  , pde-loss 7.3512e+02, initc-loss 1.4214e+04                    bc_loss 4.3694e+03\n",
      "Epoch 24720, Training-Loss 1.8382e+04, Data-loss 1.0232e+03                  , pde-loss 6.0976e+02, initc-loss 1.3106e+04                    bc_loss 3.6431e+03\n",
      "Epoch 24730, Training-Loss 1.6979e+04, Data-loss 1.1410e+03                  , pde-loss 9.5663e+02, initc-loss 1.2308e+04                    bc_loss 2.5738e+03\n",
      "Epoch 24740, Training-Loss 1.9845e+04, Data-loss 6.2405e+02                  , pde-loss 1.1743e+03, initc-loss 1.2808e+04                    bc_loss 5.2379e+03\n",
      "Epoch 24750, Training-Loss 3.2945e+04, Data-loss 7.1970e+02                  , pde-loss 7.4239e+02, initc-loss 1.2853e+04                    bc_loss 1.8630e+04\n",
      "Epoch 24760, Training-Loss 2.5503e+04, Data-loss 1.1137e+03                  , pde-loss 7.9519e+02, initc-loss 1.3783e+04                    bc_loss 9.8119e+03\n",
      "Epoch 24770, Training-Loss 2.4492e+04, Data-loss 1.8339e+03                  , pde-loss 1.4244e+03, initc-loss 1.4754e+04                    bc_loss 6.4799e+03\n",
      "Epoch 24780, Training-Loss 2.7065e+04, Data-loss 1.0918e+03                  , pde-loss 8.7218e+02, initc-loss 1.4386e+04                    bc_loss 1.0715e+04\n",
      "Epoch 24790, Training-Loss 2.9809e+04, Data-loss 1.1662e+03                  , pde-loss 1.3032e+03, initc-loss 1.4699e+04                    bc_loss 1.2642e+04\n",
      "Epoch 24800, Training-Loss 2.6904e+04, Data-loss 1.7664e+03                  , pde-loss 1.0305e+03, initc-loss 1.7028e+04                    bc_loss 7.0791e+03\n",
      "Epoch 24810, Training-Loss 1.9611e+04, Data-loss 1.3448e+03                  , pde-loss 9.3799e+02, initc-loss 1.3859e+04                    bc_loss 3.4690e+03\n",
      "Epoch 24820, Training-Loss 2.4437e+04, Data-loss 2.7751e+03                  , pde-loss 2.2667e+03, initc-loss 1.4218e+04                    bc_loss 5.1776e+03\n",
      "Epoch 24830, Training-Loss 2.0507e+04, Data-loss 2.0251e+03                  , pde-loss 2.0214e+03, initc-loss 1.2881e+04                    bc_loss 3.5795e+03\n",
      "Epoch 24840, Training-Loss 2.6874e+04, Data-loss 1.9091e+03                  , pde-loss 1.0615e+03, initc-loss 1.3454e+04                    bc_loss 1.0449e+04\n",
      "Epoch 24850, Training-Loss 1.9670e+04, Data-loss 1.0832e+03                  , pde-loss 6.2417e+02, initc-loss 1.3318e+04                    bc_loss 4.6447e+03\n",
      "Epoch 24860, Training-Loss 2.0511e+04, Data-loss 1.3814e+03                  , pde-loss 8.0210e+02, initc-loss 1.4652e+04                    bc_loss 3.6757e+03\n",
      "Epoch 24870, Training-Loss 1.7227e+04, Data-loss 6.7759e+02                  , pde-loss 6.0140e+02, initc-loss 1.3437e+04                    bc_loss 2.5108e+03\n",
      "Epoch 24880, Training-Loss 1.7644e+04, Data-loss 9.0998e+02                  , pde-loss 6.5894e+02, initc-loss 1.2787e+04                    bc_loss 3.2886e+03\n",
      "Epoch 24890, Training-Loss 1.9511e+04, Data-loss 9.6025e+02                  , pde-loss 1.0879e+03, initc-loss 1.2720e+04                    bc_loss 4.7431e+03\n",
      "Epoch 24900, Training-Loss 1.8080e+04, Data-loss 1.0109e+03                  , pde-loss 6.9300e+02, initc-loss 1.2435e+04                    bc_loss 3.9413e+03\n",
      "Epoch 24910, Training-Loss 2.8013e+04, Data-loss 1.1461e+03                  , pde-loss 9.1622e+02, initc-loss 1.3726e+04                    bc_loss 1.2225e+04\n",
      "Epoch 24920, Training-Loss 2.1083e+04, Data-loss 1.3672e+03                  , pde-loss 8.9717e+02, initc-loss 1.3302e+04                    bc_loss 5.5158e+03\n",
      "Epoch 24930, Training-Loss 1.8571e+04, Data-loss 1.3421e+03                  , pde-loss 8.3348e+02, initc-loss 1.2498e+04                    bc_loss 3.8980e+03\n",
      "Epoch 24940, Training-Loss 2.0732e+04, Data-loss 1.2481e+03                  , pde-loss 2.1936e+03, initc-loss 1.3831e+04                    bc_loss 3.4593e+03\n",
      "Epoch 24950, Training-Loss 2.0197e+04, Data-loss 9.5326e+02                  , pde-loss 1.1246e+03, initc-loss 1.2557e+04                    bc_loss 5.5622e+03\n",
      "Epoch 24960, Training-Loss 2.4350e+04, Data-loss 1.9506e+03                  , pde-loss 9.1302e+02, initc-loss 1.3662e+04                    bc_loss 7.8241e+03\n",
      "Epoch 24970, Training-Loss 1.8228e+04, Data-loss 9.4287e+02                  , pde-loss 1.2346e+03, initc-loss 1.2842e+04                    bc_loss 3.2084e+03\n",
      "Epoch 24980, Training-Loss 2.6902e+04, Data-loss 8.5631e+02                  , pde-loss 1.2130e+03, initc-loss 1.2633e+04                    bc_loss 1.2200e+04\n",
      "Epoch 24990, Training-Loss 3.1432e+04, Data-loss 1.6913e+03                  , pde-loss 1.2967e+03, initc-loss 1.3758e+04                    bc_loss 1.4686e+04\n",
      "Epoch 25000, Training-Loss 3.4432e+04, Data-loss 1.7429e+03                  , pde-loss 8.0010e+02, initc-loss 1.6115e+04                    bc_loss 1.5774e+04\n",
      "Epoch 25010, Training-Loss 3.0153e+04, Data-loss 1.4710e+03                  , pde-loss 1.2356e+03, initc-loss 1.4047e+04                    bc_loss 1.3399e+04\n",
      "Epoch 25020, Training-Loss 2.5286e+04, Data-loss 1.5999e+03                  , pde-loss 9.0895e+02, initc-loss 1.4293e+04                    bc_loss 8.4838e+03\n",
      "Epoch 25030, Training-Loss 2.2897e+04, Data-loss 1.3893e+03                  , pde-loss 1.1873e+03, initc-loss 1.3714e+04                    bc_loss 6.6059e+03\n",
      "Epoch 25040, Training-Loss 2.2581e+04, Data-loss 1.3620e+03                  , pde-loss 1.1022e+03, initc-loss 1.3960e+04                    bc_loss 6.1570e+03\n",
      "Epoch 25050, Training-Loss 2.1561e+04, Data-loss 1.6579e+03                  , pde-loss 9.6983e+02, initc-loss 1.2001e+04                    bc_loss 6.9322e+03\n",
      "Epoch 25060, Training-Loss 2.8209e+04, Data-loss 1.4454e+03                  , pde-loss 1.7379e+03, initc-loss 1.2764e+04                    bc_loss 1.2262e+04\n",
      "Epoch 25070, Training-Loss 4.3217e+04, Data-loss 3.6213e+03                  , pde-loss 1.5262e+03, initc-loss 1.4211e+04                    bc_loss 2.3858e+04\n",
      "Epoch 25080, Training-Loss 3.8464e+04, Data-loss 1.7027e+03                  , pde-loss 1.1609e+03, initc-loss 1.5889e+04                    bc_loss 1.9711e+04\n",
      "Epoch 25090, Training-Loss 3.3999e+04, Data-loss 2.7051e+03                  , pde-loss 1.3124e+03, initc-loss 1.6040e+04                    bc_loss 1.3942e+04\n",
      "Epoch 25100, Training-Loss 2.7509e+04, Data-loss 1.9774e+03                  , pde-loss 1.1750e+03, initc-loss 1.5550e+04                    bc_loss 8.8067e+03\n",
      "Epoch 25110, Training-Loss 2.3605e+04, Data-loss 1.3470e+03                  , pde-loss 8.8129e+02, initc-loss 1.5006e+04                    bc_loss 6.3705e+03\n",
      "Epoch 25120, Training-Loss 2.1350e+04, Data-loss 1.2402e+03                  , pde-loss 8.7986e+02, initc-loss 1.4918e+04                    bc_loss 4.3120e+03\n",
      "Epoch 25130, Training-Loss 1.9824e+04, Data-loss 1.2949e+03                  , pde-loss 1.2320e+03, initc-loss 1.3836e+04                    bc_loss 3.4613e+03\n",
      "Epoch 25140, Training-Loss 1.7829e+04, Data-loss 8.0088e+02                  , pde-loss 9.6683e+02, initc-loss 1.3013e+04                    bc_loss 3.0479e+03\n",
      "Epoch 25150, Training-Loss 1.7161e+04, Data-loss 1.2649e+03                  , pde-loss 9.7863e+02, initc-loss 1.2415e+04                    bc_loss 2.5033e+03\n",
      "Epoch 25160, Training-Loss 1.9633e+04, Data-loss 1.0250e+03                  , pde-loss 7.0235e+02, initc-loss 1.3640e+04                    bc_loss 4.2665e+03\n",
      "Epoch 25170, Training-Loss 2.1035e+04, Data-loss 1.2666e+03                  , pde-loss 1.1262e+03, initc-loss 1.3610e+04                    bc_loss 5.0327e+03\n",
      "Epoch 25180, Training-Loss 2.0565e+04, Data-loss 1.4044e+03                  , pde-loss 5.6516e+02, initc-loss 1.3036e+04                    bc_loss 5.5595e+03\n",
      "Epoch 25190, Training-Loss 4.8946e+04, Data-loss 8.9228e+02                  , pde-loss 1.1120e+03, initc-loss 1.2852e+04                    bc_loss 3.4089e+04\n",
      "Epoch 25200, Training-Loss 5.0249e+04, Data-loss 1.2636e+03                  , pde-loss 1.2125e+03, initc-loss 1.3852e+04                    bc_loss 3.3922e+04\n",
      "Epoch 25210, Training-Loss 3.8847e+04, Data-loss 2.8623e+03                  , pde-loss 9.8104e+02, initc-loss 1.8010e+04                    bc_loss 1.6994e+04\n",
      "Epoch 25220, Training-Loss 3.2440e+04, Data-loss 2.9178e+03                  , pde-loss 1.9169e+03, initc-loss 1.8573e+04                    bc_loss 9.0328e+03\n",
      "Epoch 25230, Training-Loss 2.9700e+04, Data-loss 3.0812e+03                  , pde-loss 2.1961e+03, initc-loss 1.7591e+04                    bc_loss 6.8325e+03\n",
      "Epoch 25240, Training-Loss 2.4512e+04, Data-loss 1.5198e+03                  , pde-loss 7.8635e+02, initc-loss 1.7362e+04                    bc_loss 4.8436e+03\n",
      "Epoch 25250, Training-Loss 2.5089e+04, Data-loss 2.4810e+03                  , pde-loss 1.8235e+03, initc-loss 1.6945e+04                    bc_loss 3.8390e+03\n",
      "Epoch 25260, Training-Loss 2.0439e+04, Data-loss 2.2542e+03                  , pde-loss 9.6284e+02, initc-loss 1.4909e+04                    bc_loss 2.3133e+03\n",
      "Epoch 25270, Training-Loss 1.8870e+04, Data-loss 1.0406e+03                  , pde-loss 9.9862e+02, initc-loss 1.3532e+04                    bc_loss 3.2987e+03\n",
      "Epoch 25280, Training-Loss 2.2309e+04, Data-loss 2.6409e+03                  , pde-loss 1.4485e+03, initc-loss 1.3795e+04                    bc_loss 4.4248e+03\n",
      "Epoch 25290, Training-Loss 1.8867e+04, Data-loss 1.3163e+03                  , pde-loss 9.8794e+02, initc-loss 1.3595e+04                    bc_loss 2.9679e+03\n",
      "Epoch 25300, Training-Loss 1.8687e+04, Data-loss 9.4937e+02                  , pde-loss 8.6841e+02, initc-loss 1.3205e+04                    bc_loss 3.6648e+03\n",
      "Epoch 25310, Training-Loss 1.7195e+04, Data-loss 1.0519e+03                  , pde-loss 7.2167e+02, initc-loss 1.2287e+04                    bc_loss 3.1347e+03\n",
      "Epoch 25320, Training-Loss 3.2083e+04, Data-loss 1.2065e+03                  , pde-loss 7.8872e+02, initc-loss 1.2527e+04                    bc_loss 1.7561e+04\n",
      "Epoch 25330, Training-Loss 2.8387e+04, Data-loss 2.5643e+03                  , pde-loss 1.6727e+03, initc-loss 1.5902e+04                    bc_loss 8.2481e+03\n",
      "Epoch 25340, Training-Loss 2.3261e+04, Data-loss 1.6937e+03                  , pde-loss 9.8382e+02, initc-loss 1.5932e+04                    bc_loss 4.6520e+03\n",
      "Epoch 25350, Training-Loss 2.5373e+04, Data-loss 2.0025e+03                  , pde-loss 1.1768e+03, initc-loss 1.4717e+04                    bc_loss 7.4769e+03\n",
      "Epoch 25360, Training-Loss 3.1003e+04, Data-loss 1.7495e+03                  , pde-loss 1.8409e+03, initc-loss 1.4105e+04                    bc_loss 1.3307e+04\n",
      "Epoch 25370, Training-Loss 2.3544e+04, Data-loss 1.3697e+03                  , pde-loss 1.2497e+03, initc-loss 1.4465e+04                    bc_loss 6.4588e+03\n",
      "Epoch 25380, Training-Loss 2.2438e+04, Data-loss 1.3011e+03                  , pde-loss 1.2705e+03, initc-loss 1.4951e+04                    bc_loss 4.9147e+03\n",
      "Epoch 25390, Training-Loss 3.3656e+04, Data-loss 1.5501e+03                  , pde-loss 8.3717e+02, initc-loss 1.4949e+04                    bc_loss 1.6320e+04\n",
      "Epoch 25400, Training-Loss 3.5203e+04, Data-loss 1.1452e+03                  , pde-loss 6.8852e+02, initc-loss 1.4372e+04                    bc_loss 1.8998e+04\n",
      "Epoch 25410, Training-Loss 3.2787e+04, Data-loss 2.3008e+03                  , pde-loss 8.1189e+02, initc-loss 1.6202e+04                    bc_loss 1.3472e+04\n",
      "Epoch 25420, Training-Loss 2.6512e+04, Data-loss 2.2725e+03                  , pde-loss 1.1480e+03, initc-loss 1.6401e+04                    bc_loss 6.6901e+03\n",
      "Epoch 25430, Training-Loss 2.5273e+04, Data-loss 2.0223e+03                  , pde-loss 1.3623e+03, initc-loss 1.5309e+04                    bc_loss 6.5790e+03\n",
      "Epoch 25440, Training-Loss 2.7527e+04, Data-loss 1.7343e+03                  , pde-loss 1.3704e+03, initc-loss 1.6241e+04                    bc_loss 8.1811e+03\n",
      "Epoch 25450, Training-Loss 2.1992e+04, Data-loss 1.2809e+03                  , pde-loss 1.4608e+03, initc-loss 1.4298e+04                    bc_loss 4.9514e+03\n",
      "Epoch 25460, Training-Loss 2.9901e+04, Data-loss 1.5097e+03                  , pde-loss 1.1437e+03, initc-loss 1.4320e+04                    bc_loss 1.2928e+04\n",
      "Epoch 25470, Training-Loss 2.7659e+04, Data-loss 1.7507e+03                  , pde-loss 1.4438e+03, initc-loss 1.5568e+04                    bc_loss 8.8973e+03\n",
      "Epoch 25480, Training-Loss 2.4809e+04, Data-loss 1.7607e+03                  , pde-loss 8.9285e+02, initc-loss 1.6538e+04                    bc_loss 5.6172e+03\n",
      "Epoch 25490, Training-Loss 2.4206e+04, Data-loss 1.5898e+03                  , pde-loss 1.4113e+03, initc-loss 1.4526e+04                    bc_loss 6.6784e+03\n",
      "Epoch 25500, Training-Loss 2.0786e+04, Data-loss 1.6759e+03                  , pde-loss 6.4011e+02, initc-loss 1.5312e+04                    bc_loss 3.1585e+03\n",
      "Epoch 25510, Training-Loss 1.9288e+04, Data-loss 9.5263e+02                  , pde-loss 1.2178e+03, initc-loss 1.3704e+04                    bc_loss 3.4132e+03\n",
      "Epoch 25520, Training-Loss 2.1559e+04, Data-loss 1.4746e+03                  , pde-loss 7.3646e+02, initc-loss 1.4426e+04                    bc_loss 4.9221e+03\n",
      "Epoch 25530, Training-Loss 2.3846e+04, Data-loss 1.6597e+03                  , pde-loss 8.3868e+02, initc-loss 1.4877e+04                    bc_loss 6.4706e+03\n",
      "Epoch 25540, Training-Loss 4.9832e+04, Data-loss 2.8111e+03                  , pde-loss 9.9452e+02, initc-loss 1.3075e+04                    bc_loss 3.2951e+04\n",
      "Epoch 25550, Training-Loss 2.6954e+05, Data-loss 3.3900e+03                  , pde-loss 2.0125e+03, initc-loss 1.6667e+04                    bc_loss 2.4747e+05\n",
      "Epoch 25560, Training-Loss 7.1966e+04, Data-loss 4.6350e+03                  , pde-loss 2.0343e+03, initc-loss 2.6238e+04                    bc_loss 3.9059e+04\n",
      "Epoch 25570, Training-Loss 5.2744e+04, Data-loss 4.6645e+03                  , pde-loss 2.0783e+03, initc-loss 2.7144e+04                    bc_loss 1.8858e+04\n",
      "Epoch 25580, Training-Loss 3.8562e+04, Data-loss 5.6113e+03                  , pde-loss 2.3305e+03, initc-loss 2.4672e+04                    bc_loss 5.9484e+03\n",
      "Epoch 25590, Training-Loss 3.5954e+04, Data-loss 4.3604e+03                  , pde-loss 1.2892e+03, initc-loss 2.4469e+04                    bc_loss 5.8355e+03\n",
      "Epoch 25600, Training-Loss 2.9934e+04, Data-loss 3.9007e+03                  , pde-loss 2.0492e+03, initc-loss 2.0910e+04                    bc_loss 3.0744e+03\n",
      "Epoch 25610, Training-Loss 2.7401e+04, Data-loss 3.8316e+03                  , pde-loss 1.1135e+03, initc-loss 2.0124e+04                    bc_loss 2.3325e+03\n",
      "Epoch 25620, Training-Loss 2.5005e+04, Data-loss 2.9257e+03                  , pde-loss 1.1223e+03, initc-loss 1.8565e+04                    bc_loss 2.3921e+03\n",
      "Epoch 25630, Training-Loss 2.2644e+04, Data-loss 2.2231e+03                  , pde-loss 1.3262e+03, initc-loss 1.6741e+04                    bc_loss 2.3539e+03\n",
      "Epoch 25640, Training-Loss 2.5212e+04, Data-loss 2.4642e+03                  , pde-loss 1.3440e+03, initc-loss 1.8944e+04                    bc_loss 2.4597e+03\n",
      "Epoch 25650, Training-Loss 2.2724e+04, Data-loss 1.8833e+03                  , pde-loss 1.3379e+03, initc-loss 1.7085e+04                    bc_loss 2.4179e+03\n",
      "Epoch 25660, Training-Loss 2.0955e+04, Data-loss 1.3446e+03                  , pde-loss 8.8788e+02, initc-loss 1.5305e+04                    bc_loss 3.4167e+03\n",
      "Epoch 25670, Training-Loss 2.2757e+04, Data-loss 1.8165e+03                  , pde-loss 1.0491e+03, initc-loss 1.7932e+04                    bc_loss 1.9591e+03\n",
      "Epoch 25680, Training-Loss 1.9739e+04, Data-loss 1.8568e+03                  , pde-loss 1.3848e+03, initc-loss 1.3762e+04                    bc_loss 2.7354e+03\n",
      "Epoch 25690, Training-Loss 2.2102e+04, Data-loss 2.8245e+03                  , pde-loss 2.1318e+03, initc-loss 1.4048e+04                    bc_loss 3.0978e+03\n",
      "Epoch 25700, Training-Loss 2.0866e+04, Data-loss 1.2559e+03                  , pde-loss 1.1914e+03, initc-loss 1.3926e+04                    bc_loss 4.4928e+03\n",
      "Epoch 25710, Training-Loss 5.5124e+04, Data-loss 2.4119e+03                  , pde-loss 1.5232e+03, initc-loss 1.4554e+04                    bc_loss 3.6635e+04\n",
      "Epoch 25720, Training-Loss 2.9610e+04, Data-loss 2.3357e+03                  , pde-loss 1.5988e+03, initc-loss 1.4914e+04                    bc_loss 1.0761e+04\n",
      "Epoch 25730, Training-Loss 2.7687e+04, Data-loss 2.2961e+03                  , pde-loss 1.7530e+03, initc-loss 1.6092e+04                    bc_loss 7.5450e+03\n",
      "Epoch 25740, Training-Loss 2.7898e+04, Data-loss 1.7790e+03                  , pde-loss 1.2744e+03, initc-loss 1.6302e+04                    bc_loss 8.5428e+03\n",
      "Epoch 25750, Training-Loss 2.4314e+04, Data-loss 1.9637e+03                  , pde-loss 1.1949e+03, initc-loss 1.4925e+04                    bc_loss 6.2295e+03\n",
      "Epoch 25760, Training-Loss 2.0270e+04, Data-loss 1.3899e+03                  , pde-loss 1.1880e+03, initc-loss 1.4899e+04                    bc_loss 2.7929e+03\n",
      "Epoch 25770, Training-Loss 1.9366e+04, Data-loss 1.0962e+03                  , pde-loss 1.0562e+03, initc-loss 1.5168e+04                    bc_loss 2.0463e+03\n",
      "Epoch 25780, Training-Loss 1.9162e+04, Data-loss 1.2789e+03                  , pde-loss 1.1472e+03, initc-loss 1.3261e+04                    bc_loss 3.4755e+03\n",
      "Epoch 25790, Training-Loss 1.7676e+04, Data-loss 9.8666e+02                  , pde-loss 1.1502e+03, initc-loss 1.2810e+04                    bc_loss 2.7289e+03\n",
      "Epoch 25800, Training-Loss 1.6355e+04, Data-loss 7.1525e+02                  , pde-loss 7.0697e+02, initc-loss 1.2652e+04                    bc_loss 2.2803e+03\n",
      "Epoch 25810, Training-Loss 2.1187e+04, Data-loss 1.5008e+03                  , pde-loss 1.6989e+03, initc-loss 1.3950e+04                    bc_loss 4.0372e+03\n",
      "Epoch 25820, Training-Loss 3.4975e+04, Data-loss 3.1409e+03                  , pde-loss 2.3348e+03, initc-loss 1.4341e+04                    bc_loss 1.5159e+04\n",
      "Epoch 25830, Training-Loss 2.2424e+04, Data-loss 2.0510e+03                  , pde-loss 1.0222e+03, initc-loss 1.3677e+04                    bc_loss 5.6745e+03\n",
      "Epoch 25840, Training-Loss 2.1724e+04, Data-loss 1.4224e+03                  , pde-loss 1.2935e+03, initc-loss 1.4422e+04                    bc_loss 4.5866e+03\n",
      "Epoch 25850, Training-Loss 2.6849e+04, Data-loss 1.1434e+03                  , pde-loss 1.0239e+03, initc-loss 1.3750e+04                    bc_loss 1.0932e+04\n",
      "Epoch 25860, Training-Loss 2.1476e+04, Data-loss 1.5040e+03                  , pde-loss 1.0845e+03, initc-loss 1.4509e+04                    bc_loss 4.3779e+03\n",
      "Epoch 25870, Training-Loss 2.1673e+04, Data-loss 1.1129e+03                  , pde-loss 1.1647e+03, initc-loss 1.3130e+04                    bc_loss 6.2658e+03\n",
      "Epoch 25880, Training-Loss 1.9116e+04, Data-loss 8.3992e+02                  , pde-loss 8.8325e+02, initc-loss 1.3443e+04                    bc_loss 3.9494e+03\n",
      "Epoch 25890, Training-Loss 1.9542e+04, Data-loss 1.2250e+03                  , pde-loss 9.9639e+02, initc-loss 1.3008e+04                    bc_loss 4.3118e+03\n",
      "Epoch 25900, Training-Loss 2.1956e+04, Data-loss 3.1872e+03                  , pde-loss 1.8485e+03, initc-loss 1.2667e+04                    bc_loss 4.2539e+03\n",
      "Epoch 25910, Training-Loss 4.3464e+04, Data-loss 1.5859e+03                  , pde-loss 1.1208e+03, initc-loss 1.3751e+04                    bc_loss 2.7007e+04\n",
      "Epoch 25920, Training-Loss 3.4293e+04, Data-loss 1.5860e+03                  , pde-loss 1.6770e+03, initc-loss 1.5354e+04                    bc_loss 1.5676e+04\n",
      "Epoch 25930, Training-Loss 3.5195e+04, Data-loss 1.6296e+03                  , pde-loss 2.1597e+03, initc-loss 1.4374e+04                    bc_loss 1.7032e+04\n",
      "Epoch 25940, Training-Loss 2.1529e+04, Data-loss 1.3111e+03                  , pde-loss 9.6849e+02, initc-loss 1.4534e+04                    bc_loss 4.7153e+03\n",
      "Epoch 25950, Training-Loss 2.3324e+04, Data-loss 1.6284e+03                  , pde-loss 1.8955e+03, initc-loss 1.4066e+04                    bc_loss 5.7333e+03\n",
      "Epoch 25960, Training-Loss 2.2136e+04, Data-loss 1.6168e+03                  , pde-loss 1.9196e+03, initc-loss 1.4891e+04                    bc_loss 3.7088e+03\n",
      "Epoch 25970, Training-Loss 2.0645e+04, Data-loss 1.1103e+03                  , pde-loss 8.2942e+02, initc-loss 1.2643e+04                    bc_loss 6.0626e+03\n",
      "Epoch 25980, Training-Loss 3.1898e+04, Data-loss 2.6507e+03                  , pde-loss 2.8311e+03, initc-loss 1.2020e+04                    bc_loss 1.4397e+04\n",
      "Epoch 25990, Training-Loss 2.4817e+04, Data-loss 1.5973e+03                  , pde-loss 1.7544e+03, initc-loss 1.3264e+04                    bc_loss 8.2018e+03\n",
      "Epoch 26000, Training-Loss 2.3865e+04, Data-loss 1.3482e+03                  , pde-loss 6.6410e+02, initc-loss 1.3096e+04                    bc_loss 8.7572e+03\n",
      "Epoch 26010, Training-Loss 2.2212e+04, Data-loss 1.6169e+03                  , pde-loss 9.8782e+02, initc-loss 1.4836e+04                    bc_loss 4.7716e+03\n",
      "Epoch 26020, Training-Loss 2.6328e+04, Data-loss 1.7458e+03                  , pde-loss 1.7326e+03, initc-loss 1.3392e+04                    bc_loss 9.4571e+03\n",
      "Epoch 26030, Training-Loss 2.4427e+04, Data-loss 1.6474e+03                  , pde-loss 1.3180e+03, initc-loss 1.4643e+04                    bc_loss 6.8182e+03\n",
      "Epoch 26040, Training-Loss 2.5569e+04, Data-loss 1.4219e+03                  , pde-loss 1.1547e+03, initc-loss 1.5004e+04                    bc_loss 7.9879e+03\n",
      "Epoch 26050, Training-Loss 1.9410e+04, Data-loss 6.9325e+02                  , pde-loss 1.1797e+03, initc-loss 1.3311e+04                    bc_loss 4.2259e+03\n",
      "Epoch 26060, Training-Loss 1.7330e+04, Data-loss 7.2043e+02                  , pde-loss 1.0480e+03, initc-loss 1.2486e+04                    bc_loss 3.0754e+03\n",
      "Epoch 26070, Training-Loss 1.8383e+04, Data-loss 5.5623e+02                  , pde-loss 1.0005e+03, initc-loss 1.2623e+04                    bc_loss 4.2031e+03\n",
      "Epoch 26080, Training-Loss 1.8128e+04, Data-loss 1.0307e+03                  , pde-loss 1.1756e+03, initc-loss 1.2863e+04                    bc_loss 3.0582e+03\n",
      "Epoch 26090, Training-Loss 1.7294e+04, Data-loss 1.3705e+03                  , pde-loss 1.1367e+03, initc-loss 1.3015e+04                    bc_loss 1.7714e+03\n",
      "Epoch 26100, Training-Loss 1.6273e+04, Data-loss 9.0938e+02                  , pde-loss 6.3263e+02, initc-loss 1.2942e+04                    bc_loss 1.7898e+03\n",
      "Epoch 26110, Training-Loss 1.7518e+04, Data-loss 7.5416e+02                  , pde-loss 9.7081e+02, initc-loss 1.1944e+04                    bc_loss 3.8490e+03\n",
      "Epoch 26120, Training-Loss 4.1270e+04, Data-loss 8.0608e+02                  , pde-loss 1.1864e+03, initc-loss 1.2660e+04                    bc_loss 2.6617e+04\n",
      "Epoch 26130, Training-Loss 3.1981e+04, Data-loss 1.7340e+03                  , pde-loss 5.5853e+02, initc-loss 1.3840e+04                    bc_loss 1.5849e+04\n",
      "Epoch 26140, Training-Loss 2.3190e+04, Data-loss 1.8751e+03                  , pde-loss 7.5516e+02, initc-loss 1.6690e+04                    bc_loss 3.8698e+03\n",
      "Epoch 26150, Training-Loss 2.3885e+04, Data-loss 2.0480e+03                  , pde-loss 1.1894e+03, initc-loss 1.6758e+04                    bc_loss 3.8899e+03\n",
      "Epoch 26160, Training-Loss 2.3201e+04, Data-loss 1.4152e+03                  , pde-loss 1.4517e+03, initc-loss 1.5033e+04                    bc_loss 5.3007e+03\n",
      "Epoch 26170, Training-Loss 1.8198e+04, Data-loss 1.1619e+03                  , pde-loss 8.5622e+02, initc-loss 1.3609e+04                    bc_loss 2.5710e+03\n",
      "Epoch 26180, Training-Loss 1.8276e+04, Data-loss 1.2992e+03                  , pde-loss 9.4008e+02, initc-loss 1.3935e+04                    bc_loss 2.1015e+03\n",
      "Epoch 26190, Training-Loss 1.7974e+04, Data-loss 1.0161e+03                  , pde-loss 1.4770e+03, initc-loss 1.3413e+04                    bc_loss 2.0682e+03\n",
      "Epoch 26200, Training-Loss 1.6517e+04, Data-loss 1.3549e+03                  , pde-loss 1.0757e+03, initc-loss 1.2055e+04                    bc_loss 2.0310e+03\n",
      "Epoch 26210, Training-Loss 1.5948e+04, Data-loss 7.8470e+02                  , pde-loss 6.6673e+02, initc-loss 1.1962e+04                    bc_loss 2.5350e+03\n",
      "Epoch 26220, Training-Loss 1.6684e+04, Data-loss 7.6416e+02                  , pde-loss 9.3355e+02, initc-loss 1.1432e+04                    bc_loss 3.5540e+03\n",
      "Epoch 26230, Training-Loss 2.2528e+04, Data-loss 8.6448e+02                  , pde-loss 1.0921e+03, initc-loss 1.2735e+04                    bc_loss 7.8373e+03\n",
      "Epoch 26240, Training-Loss 4.9901e+04, Data-loss 1.5037e+03                  , pde-loss 1.0827e+03, initc-loss 1.3088e+04                    bc_loss 3.4227e+04\n",
      "Epoch 26250, Training-Loss 3.6204e+04, Data-loss 2.1218e+03                  , pde-loss 6.1988e+02, initc-loss 1.4921e+04                    bc_loss 1.8541e+04\n",
      "Epoch 26260, Training-Loss 3.4062e+04, Data-loss 3.0454e+03                  , pde-loss 1.8145e+03, initc-loss 1.6550e+04                    bc_loss 1.2652e+04\n",
      "Epoch 26270, Training-Loss 3.5734e+04, Data-loss 4.2005e+03                  , pde-loss 2.0105e+03, initc-loss 1.7096e+04                    bc_loss 1.2426e+04\n",
      "Epoch 26280, Training-Loss 2.7894e+04, Data-loss 2.2117e+03                  , pde-loss 1.2333e+03, initc-loss 1.5225e+04                    bc_loss 9.2239e+03\n",
      "Epoch 26290, Training-Loss 2.3834e+04, Data-loss 1.9859e+03                  , pde-loss 7.6249e+02, initc-loss 1.5706e+04                    bc_loss 5.3798e+03\n",
      "Epoch 26300, Training-Loss 2.1103e+04, Data-loss 2.0308e+03                  , pde-loss 1.7225e+03, initc-loss 1.4289e+04                    bc_loss 3.0611e+03\n",
      "Epoch 26310, Training-Loss 1.7798e+04, Data-loss 7.0225e+02                  , pde-loss 9.3478e+02, initc-loss 1.3640e+04                    bc_loss 2.5215e+03\n",
      "Epoch 26320, Training-Loss 1.6755e+04, Data-loss 1.1179e+03                  , pde-loss 7.6395e+02, initc-loss 1.2937e+04                    bc_loss 1.9356e+03\n",
      "Epoch 26330, Training-Loss 1.7156e+04, Data-loss 7.7213e+02                  , pde-loss 9.1418e+02, initc-loss 1.3543e+04                    bc_loss 1.9274e+03\n",
      "Epoch 26340, Training-Loss 1.6143e+04, Data-loss 7.4224e+02                  , pde-loss 9.4720e+02, initc-loss 1.1724e+04                    bc_loss 2.7292e+03\n",
      "Epoch 26350, Training-Loss 1.8771e+04, Data-loss 9.9465e+02                  , pde-loss 7.2395e+02, initc-loss 1.3777e+04                    bc_loss 3.2754e+03\n",
      "Epoch 26360, Training-Loss 1.5714e+04, Data-loss 6.4496e+02                  , pde-loss 9.3091e+02, initc-loss 1.1168e+04                    bc_loss 2.9701e+03\n",
      "Epoch 26370, Training-Loss 1.8243e+04, Data-loss 8.9684e+02                  , pde-loss 1.3163e+03, initc-loss 1.2254e+04                    bc_loss 3.7752e+03\n",
      "Epoch 26380, Training-Loss 2.5865e+04, Data-loss 8.3487e+02                  , pde-loss 1.0264e+03, initc-loss 1.1152e+04                    bc_loss 1.2852e+04\n",
      "Epoch 26390, Training-Loss 3.5456e+04, Data-loss 1.0890e+03                  , pde-loss 1.6012e+03, initc-loss 1.2653e+04                    bc_loss 2.0113e+04\n",
      "Epoch 26400, Training-Loss 2.5062e+04, Data-loss 8.6576e+02                  , pde-loss 9.1163e+02, initc-loss 1.3572e+04                    bc_loss 9.7122e+03\n",
      "Epoch 26410, Training-Loss 2.1049e+04, Data-loss 1.1745e+03                  , pde-loss 7.0412e+02, initc-loss 1.3053e+04                    bc_loss 6.1168e+03\n",
      "Epoch 26420, Training-Loss 2.2716e+04, Data-loss 2.1706e+03                  , pde-loss 1.1735e+03, initc-loss 1.3232e+04                    bc_loss 6.1403e+03\n",
      "Epoch 26430, Training-Loss 2.1387e+04, Data-loss 9.6609e+02                  , pde-loss 1.5364e+03, initc-loss 1.2705e+04                    bc_loss 6.1802e+03\n",
      "Epoch 26440, Training-Loss 2.1753e+04, Data-loss 1.9050e+03                  , pde-loss 1.2364e+03, initc-loss 1.3176e+04                    bc_loss 5.4356e+03\n",
      "Epoch 26450, Training-Loss 1.8229e+04, Data-loss 1.0966e+03                  , pde-loss 8.5631e+02, initc-loss 1.2829e+04                    bc_loss 3.4476e+03\n",
      "Epoch 26460, Training-Loss 1.8004e+04, Data-loss 1.7058e+03                  , pde-loss 9.4839e+02, initc-loss 1.2542e+04                    bc_loss 2.8085e+03\n",
      "Epoch 26470, Training-Loss 1.7950e+04, Data-loss 1.1222e+03                  , pde-loss 7.1570e+02, initc-loss 1.2341e+04                    bc_loss 3.7709e+03\n",
      "Epoch 26480, Training-Loss 1.7207e+04, Data-loss 1.3795e+03                  , pde-loss 1.1192e+03, initc-loss 1.1424e+04                    bc_loss 3.2846e+03\n",
      "Epoch 26490, Training-Loss 1.6611e+04, Data-loss 1.0812e+03                  , pde-loss 7.8569e+02, initc-loss 1.1506e+04                    bc_loss 3.2383e+03\n",
      "Epoch 26500, Training-Loss 1.4706e+04, Data-loss 6.9963e+02                  , pde-loss 5.3492e+02, initc-loss 1.0953e+04                    bc_loss 2.5184e+03\n",
      "Epoch 26510, Training-Loss 2.1545e+04, Data-loss 1.4289e+03                  , pde-loss 2.3582e+03, initc-loss 1.3381e+04                    bc_loss 4.3766e+03\n",
      "Epoch 26520, Training-Loss 1.9929e+04, Data-loss 1.2140e+03                  , pde-loss 9.7389e+02, initc-loss 1.1040e+04                    bc_loss 6.7006e+03\n",
      "Epoch 26530, Training-Loss 2.4590e+04, Data-loss 8.2462e+02                  , pde-loss 8.1918e+02, initc-loss 1.1294e+04                    bc_loss 1.1652e+04\n",
      "Epoch 26540, Training-Loss 2.8558e+04, Data-loss 2.0297e+03                  , pde-loss 2.0155e+03, initc-loss 1.3102e+04                    bc_loss 1.1411e+04\n",
      "Epoch 26550, Training-Loss 2.2419e+04, Data-loss 1.9551e+03                  , pde-loss 2.0343e+03, initc-loss 1.3131e+04                    bc_loss 5.2984e+03\n",
      "Epoch 26560, Training-Loss 1.7899e+04, Data-loss 1.0181e+03                  , pde-loss 1.1795e+03, initc-loss 1.2902e+04                    bc_loss 2.7998e+03\n",
      "Epoch 26570, Training-Loss 2.1285e+04, Data-loss 1.0780e+03                  , pde-loss 9.8225e+02, initc-loss 1.2534e+04                    bc_loss 6.6900e+03\n",
      "Epoch 26580, Training-Loss 2.0801e+04, Data-loss 2.0669e+03                  , pde-loss 1.2748e+03, initc-loss 1.3635e+04                    bc_loss 3.8241e+03\n",
      "Epoch 26590, Training-Loss 1.7049e+04, Data-loss 8.8132e+02                  , pde-loss 6.2959e+02, initc-loss 1.2216e+04                    bc_loss 3.3225e+03\n",
      "Epoch 26600, Training-Loss 1.6514e+04, Data-loss 1.0943e+03                  , pde-loss 1.4898e+03, initc-loss 1.2011e+04                    bc_loss 1.9184e+03\n",
      "Epoch 26610, Training-Loss 1.5047e+04, Data-loss 6.5501e+02                  , pde-loss 7.0395e+02, initc-loss 1.1848e+04                    bc_loss 1.8404e+03\n",
      "Epoch 26620, Training-Loss 1.4202e+04, Data-loss 5.9533e+02                  , pde-loss 7.2571e+02, initc-loss 1.0833e+04                    bc_loss 2.0485e+03\n",
      "Epoch 26630, Training-Loss 1.4059e+04, Data-loss 1.0597e+03                  , pde-loss 7.5986e+02, initc-loss 1.0578e+04                    bc_loss 1.6620e+03\n",
      "Epoch 26640, Training-Loss 1.4317e+04, Data-loss 9.2741e+02                  , pde-loss 9.4920e+02, initc-loss 1.0711e+04                    bc_loss 1.7301e+03\n",
      "Epoch 26650, Training-Loss 2.3638e+04, Data-loss 2.0331e+03                  , pde-loss 1.6659e+03, initc-loss 1.1220e+04                    bc_loss 8.7184e+03\n",
      "Epoch 26660, Training-Loss 2.1909e+04, Data-loss 7.8439e+02                  , pde-loss 7.7037e+02, initc-loss 1.1849e+04                    bc_loss 8.5053e+03\n",
      "Epoch 26670, Training-Loss 3.4841e+04, Data-loss 1.6362e+03                  , pde-loss 1.2782e+03, initc-loss 1.5195e+04                    bc_loss 1.6732e+04\n",
      "Epoch 26680, Training-Loss 3.6840e+04, Data-loss 8.7957e+02                  , pde-loss 8.8963e+02, initc-loss 1.2787e+04                    bc_loss 2.2284e+04\n",
      "Epoch 26690, Training-Loss 3.2152e+04, Data-loss 2.3311e+03                  , pde-loss 1.0079e+03, initc-loss 1.4077e+04                    bc_loss 1.4737e+04\n",
      "Epoch 26700, Training-Loss 3.6624e+04, Data-loss 2.1132e+03                  , pde-loss 1.3509e+03, initc-loss 1.7290e+04                    bc_loss 1.5870e+04\n",
      "Epoch 26710, Training-Loss 2.8134e+04, Data-loss 2.4568e+03                  , pde-loss 1.0584e+03, initc-loss 1.5611e+04                    bc_loss 9.0077e+03\n",
      "Epoch 26720, Training-Loss 2.5188e+04, Data-loss 2.6093e+03                  , pde-loss 1.2190e+03, initc-loss 1.5793e+04                    bc_loss 5.5668e+03\n",
      "Epoch 26730, Training-Loss 2.0563e+04, Data-loss 1.5889e+03                  , pde-loss 7.5134e+02, initc-loss 1.4671e+04                    bc_loss 3.5522e+03\n",
      "Epoch 26740, Training-Loss 1.8181e+04, Data-loss 1.0621e+03                  , pde-loss 6.4509e+02, initc-loss 1.3652e+04                    bc_loss 2.8218e+03\n",
      "Epoch 26750, Training-Loss 1.9106e+04, Data-loss 2.2575e+03                  , pde-loss 1.4514e+03, initc-loss 1.2701e+04                    bc_loss 2.6962e+03\n",
      "Epoch 26760, Training-Loss 1.6416e+04, Data-loss 1.0829e+03                  , pde-loss 6.6713e+02, initc-loss 1.2296e+04                    bc_loss 2.3693e+03\n",
      "Epoch 26770, Training-Loss 1.7760e+04, Data-loss 8.7208e+02                  , pde-loss 7.9149e+02, initc-loss 1.1276e+04                    bc_loss 4.8207e+03\n",
      "Epoch 26780, Training-Loss 2.5414e+04, Data-loss 1.1842e+03                  , pde-loss 6.2598e+02, initc-loss 1.4688e+04                    bc_loss 8.9157e+03\n",
      "Epoch 26790, Training-Loss 2.2852e+04, Data-loss 9.7941e+02                  , pde-loss 9.7575e+02, initc-loss 1.3297e+04                    bc_loss 7.5992e+03\n",
      "Epoch 26800, Training-Loss 1.9001e+04, Data-loss 8.2705e+02                  , pde-loss 8.7912e+02, initc-loss 1.1950e+04                    bc_loss 5.3453e+03\n",
      "Epoch 26810, Training-Loss 2.5542e+04, Data-loss 1.2648e+03                  , pde-loss 1.2118e+03, initc-loss 1.2247e+04                    bc_loss 1.0818e+04\n",
      "Epoch 26820, Training-Loss 1.9266e+04, Data-loss 8.0624e+02                  , pde-loss 7.5446e+02, initc-loss 1.2542e+04                    bc_loss 5.1630e+03\n",
      "Epoch 26830, Training-Loss 3.0768e+04, Data-loss 8.1786e+02                  , pde-loss 9.3352e+02, initc-loss 1.2207e+04                    bc_loss 1.6809e+04\n",
      "Epoch 26840, Training-Loss 2.3769e+04, Data-loss 8.9090e+02                  , pde-loss 9.2715e+02, initc-loss 1.3125e+04                    bc_loss 8.8260e+03\n",
      "Epoch 26850, Training-Loss 1.8869e+04, Data-loss 1.2526e+03                  , pde-loss 5.5321e+02, initc-loss 1.2637e+04                    bc_loss 4.4264e+03\n",
      "Epoch 26860, Training-Loss 2.3305e+04, Data-loss 1.4574e+03                  , pde-loss 9.6227e+02, initc-loss 1.5381e+04                    bc_loss 5.5045e+03\n",
      "Epoch 26870, Training-Loss 2.0804e+04, Data-loss 2.0612e+03                  , pde-loss 8.6786e+02, initc-loss 1.3052e+04                    bc_loss 4.8234e+03\n",
      "Epoch 26880, Training-Loss 1.8244e+04, Data-loss 1.4300e+03                  , pde-loss 1.0185e+03, initc-loss 1.2336e+04                    bc_loss 3.4601e+03\n",
      "Epoch 26890, Training-Loss 1.7383e+04, Data-loss 7.8430e+02                  , pde-loss 1.1191e+03, initc-loss 1.2795e+04                    bc_loss 2.6849e+03\n",
      "Epoch 26900, Training-Loss 1.4518e+04, Data-loss 7.3073e+02                  , pde-loss 1.0342e+03, initc-loss 1.1254e+04                    bc_loss 1.4990e+03\n",
      "Epoch 26910, Training-Loss 1.4184e+04, Data-loss 9.3999e+02                  , pde-loss 6.2198e+02, initc-loss 1.1029e+04                    bc_loss 1.5927e+03\n",
      "Epoch 26920, Training-Loss 1.6714e+04, Data-loss 9.4639e+02                  , pde-loss 1.7937e+03, initc-loss 1.2228e+04                    bc_loss 1.7463e+03\n",
      "Epoch 26930, Training-Loss 1.4636e+04, Data-loss 3.7721e+02                  , pde-loss 8.0653e+02, initc-loss 1.0917e+04                    bc_loss 2.5354e+03\n",
      "Epoch 26940, Training-Loss 1.7971e+04, Data-loss 5.8353e+02                  , pde-loss 1.2426e+03, initc-loss 1.1483e+04                    bc_loss 4.6616e+03\n",
      "Epoch 26950, Training-Loss 2.5111e+04, Data-loss 1.2848e+03                  , pde-loss 1.0714e+03, initc-loss 1.1272e+04                    bc_loss 1.1483e+04\n",
      "Epoch 26960, Training-Loss 2.0705e+04, Data-loss 9.1083e+02                  , pde-loss 1.0958e+03, initc-loss 1.2139e+04                    bc_loss 6.5591e+03\n",
      "Epoch 26970, Training-Loss 1.9901e+04, Data-loss 1.1179e+03                  , pde-loss 6.5622e+02, initc-loss 1.3008e+04                    bc_loss 5.1187e+03\n",
      "Epoch 26980, Training-Loss 2.0385e+04, Data-loss 9.3485e+02                  , pde-loss 8.3687e+02, initc-loss 1.3523e+04                    bc_loss 5.0899e+03\n",
      "Epoch 26990, Training-Loss 2.1025e+04, Data-loss 1.8915e+03                  , pde-loss 1.3349e+03, initc-loss 1.2600e+04                    bc_loss 5.1982e+03\n",
      "Epoch 27000, Training-Loss 1.8555e+04, Data-loss 1.9135e+03                  , pde-loss 2.3352e+03, initc-loss 1.1460e+04                    bc_loss 2.8465e+03\n",
      "Epoch 27010, Training-Loss 1.5728e+04, Data-loss 5.5162e+02                  , pde-loss 7.1121e+02, initc-loss 1.1356e+04                    bc_loss 3.1087e+03\n",
      "Epoch 27020, Training-Loss 1.6053e+04, Data-loss 1.2284e+03                  , pde-loss 7.3904e+02, initc-loss 1.1039e+04                    bc_loss 3.0463e+03\n",
      "Epoch 27030, Training-Loss 1.7252e+04, Data-loss 5.6592e+02                  , pde-loss 5.9903e+02, initc-loss 1.1485e+04                    bc_loss 4.6026e+03\n",
      "Epoch 27040, Training-Loss 2.6540e+04, Data-loss 5.5949e+02                  , pde-loss 5.7951e+02, initc-loss 1.1058e+04                    bc_loss 1.4343e+04\n",
      "Epoch 27050, Training-Loss 3.7477e+04, Data-loss 9.1414e+02                  , pde-loss 4.4378e+02, initc-loss 1.1648e+04                    bc_loss 2.4471e+04\n",
      "Epoch 27060, Training-Loss 3.9712e+04, Data-loss 1.7526e+03                  , pde-loss 1.0031e+03, initc-loss 1.4394e+04                    bc_loss 2.2562e+04\n",
      "Epoch 27070, Training-Loss 2.8857e+04, Data-loss 1.1614e+03                  , pde-loss 9.7633e+02, initc-loss 1.5784e+04                    bc_loss 1.0936e+04\n",
      "Epoch 27080, Training-Loss 2.9817e+04, Data-loss 2.8461e+03                  , pde-loss 1.4349e+03, initc-loss 1.6005e+04                    bc_loss 9.5304e+03\n",
      "Epoch 27090, Training-Loss 2.4355e+04, Data-loss 1.8493e+03                  , pde-loss 7.5121e+02, initc-loss 1.6323e+04                    bc_loss 5.4320e+03\n",
      "Epoch 27100, Training-Loss 2.2134e+04, Data-loss 1.4110e+03                  , pde-loss 9.3158e+02, initc-loss 1.4283e+04                    bc_loss 5.5086e+03\n",
      "Epoch 27110, Training-Loss 1.8821e+04, Data-loss 1.0640e+03                  , pde-loss 8.6826e+02, initc-loss 1.3889e+04                    bc_loss 2.9996e+03\n",
      "Epoch 27120, Training-Loss 1.7766e+04, Data-loss 1.1139e+03                  , pde-loss 1.2118e+03, initc-loss 1.2788e+04                    bc_loss 2.6526e+03\n",
      "Epoch 27130, Training-Loss 2.2294e+04, Data-loss 1.8158e+03                  , pde-loss 1.1365e+03, initc-loss 1.5306e+04                    bc_loss 4.0355e+03\n",
      "Epoch 27140, Training-Loss 3.0824e+04, Data-loss 6.2507e+02                  , pde-loss 7.3667e+02, initc-loss 1.2827e+04                    bc_loss 1.6636e+04\n",
      "Epoch 27150, Training-Loss 5.6335e+04, Data-loss 1.1158e+03                  , pde-loss 1.0071e+03, initc-loss 1.6129e+04                    bc_loss 3.8082e+04\n",
      "Epoch 27160, Training-Loss 5.3135e+04, Data-loss 2.1322e+03                  , pde-loss 9.7054e+02, initc-loss 1.6268e+04                    bc_loss 3.3764e+04\n",
      "Epoch 27170, Training-Loss 3.1548e+04, Data-loss 3.8268e+03                  , pde-loss 1.9852e+03, initc-loss 1.5749e+04                    bc_loss 9.9877e+03\n",
      "Epoch 27180, Training-Loss 2.6976e+04, Data-loss 2.7532e+03                  , pde-loss 1.2893e+03, initc-loss 1.5738e+04                    bc_loss 7.1955e+03\n",
      "Epoch 27190, Training-Loss 2.5364e+04, Data-loss 2.0306e+03                  , pde-loss 2.3422e+03, initc-loss 1.6177e+04                    bc_loss 4.8136e+03\n",
      "Epoch 27200, Training-Loss 2.1541e+04, Data-loss 2.8119e+03                  , pde-loss 1.8170e+03, initc-loss 1.4192e+04                    bc_loss 2.7200e+03\n",
      "Epoch 27210, Training-Loss 1.8523e+04, Data-loss 1.5640e+03                  , pde-loss 7.4878e+02, initc-loss 1.3297e+04                    bc_loss 2.9124e+03\n",
      "Epoch 27220, Training-Loss 1.7807e+04, Data-loss 9.7256e+02                  , pde-loss 1.1306e+03, initc-loss 1.2828e+04                    bc_loss 2.8753e+03\n",
      "Epoch 27230, Training-Loss 1.8486e+04, Data-loss 1.1067e+03                  , pde-loss 1.1278e+03, initc-loss 1.2520e+04                    bc_loss 3.7314e+03\n",
      "Epoch 27240, Training-Loss 1.7852e+04, Data-loss 1.0468e+03                  , pde-loss 1.1529e+03, initc-loss 1.2713e+04                    bc_loss 2.9388e+03\n",
      "Epoch 27250, Training-Loss 1.8706e+04, Data-loss 1.0936e+03                  , pde-loss 1.4505e+03, initc-loss 1.3528e+04                    bc_loss 2.6334e+03\n",
      "Epoch 27260, Training-Loss 1.8421e+04, Data-loss 1.8808e+03                  , pde-loss 1.7112e+03, initc-loss 1.2198e+04                    bc_loss 2.6306e+03\n",
      "Epoch 27270, Training-Loss 2.0326e+04, Data-loss 9.6306e+02                  , pde-loss 1.0569e+03, initc-loss 1.1751e+04                    bc_loss 6.5543e+03\n",
      "Epoch 27280, Training-Loss 2.5119e+04, Data-loss 8.6574e+02                  , pde-loss 7.2605e+02, initc-loss 1.3665e+04                    bc_loss 9.8620e+03\n",
      "Epoch 27290, Training-Loss 2.8702e+04, Data-loss 1.1850e+03                  , pde-loss 1.1606e+03, initc-loss 1.3372e+04                    bc_loss 1.2984e+04\n",
      "Epoch 27300, Training-Loss 2.5631e+04, Data-loss 1.8151e+03                  , pde-loss 1.1051e+03, initc-loss 1.3941e+04                    bc_loss 8.7693e+03\n",
      "Epoch 27310, Training-Loss 2.4738e+04, Data-loss 1.9557e+03                  , pde-loss 1.3394e+03, initc-loss 1.4130e+04                    bc_loss 7.3133e+03\n",
      "Epoch 27320, Training-Loss 2.3006e+04, Data-loss 1.3546e+03                  , pde-loss 1.3506e+03, initc-loss 1.3340e+04                    bc_loss 6.9617e+03\n",
      "Epoch 27330, Training-Loss 2.3839e+04, Data-loss 3.3818e+03                  , pde-loss 1.5842e+03, initc-loss 1.3779e+04                    bc_loss 5.0931e+03\n",
      "Epoch 27340, Training-Loss 1.7902e+04, Data-loss 1.0991e+03                  , pde-loss 8.9584e+02, initc-loss 1.3976e+04                    bc_loss 1.9309e+03\n",
      "Epoch 27350, Training-Loss 1.8211e+04, Data-loss 8.4950e+02                  , pde-loss 1.1641e+03, initc-loss 1.1737e+04                    bc_loss 4.4606e+03\n",
      "Epoch 27360, Training-Loss 1.7418e+04, Data-loss 9.6120e+02                  , pde-loss 5.7917e+02, initc-loss 1.2356e+04                    bc_loss 3.5210e+03\n",
      "Epoch 27370, Training-Loss 1.9750e+04, Data-loss 6.6677e+02                  , pde-loss 6.6122e+02, initc-loss 1.2446e+04                    bc_loss 5.9752e+03\n",
      "Epoch 27380, Training-Loss 2.3303e+04, Data-loss 9.9050e+02                  , pde-loss 1.6522e+03, initc-loss 1.2289e+04                    bc_loss 8.3718e+03\n",
      "Epoch 27390, Training-Loss 2.2019e+04, Data-loss 1.1163e+03                  , pde-loss 6.8243e+02, initc-loss 1.2004e+04                    bc_loss 8.2168e+03\n",
      "Epoch 27400, Training-Loss 1.9072e+04, Data-loss 1.0727e+03                  , pde-loss 1.1469e+03, initc-loss 1.1855e+04                    bc_loss 4.9976e+03\n",
      "Epoch 27410, Training-Loss 2.5696e+04, Data-loss 1.5191e+03                  , pde-loss 1.4534e+03, initc-loss 1.2530e+04                    bc_loss 1.0194e+04\n",
      "Epoch 27420, Training-Loss 1.8439e+04, Data-loss 8.1591e+02                  , pde-loss 7.9711e+02, initc-loss 1.2682e+04                    bc_loss 4.1435e+03\n",
      "Epoch 27430, Training-Loss 2.4038e+04, Data-loss 1.6017e+03                  , pde-loss 9.4741e+02, initc-loss 1.3575e+04                    bc_loss 7.9142e+03\n",
      "Epoch 27440, Training-Loss 1.8214e+04, Data-loss 1.2620e+03                  , pde-loss 9.8698e+02, initc-loss 1.2241e+04                    bc_loss 3.7235e+03\n",
      "Epoch 27450, Training-Loss 1.5379e+04, Data-loss 1.1937e+03                  , pde-loss 6.7147e+02, initc-loss 1.0982e+04                    bc_loss 2.5322e+03\n",
      "Epoch 27460, Training-Loss 1.6164e+04, Data-loss 9.7081e+02                  , pde-loss 1.5730e+03, initc-loss 1.1286e+04                    bc_loss 2.3343e+03\n",
      "Epoch 27470, Training-Loss 1.7114e+04, Data-loss 1.2806e+03                  , pde-loss 8.7804e+02, initc-loss 1.1563e+04                    bc_loss 3.3920e+03\n",
      "Epoch 27480, Training-Loss 1.7305e+04, Data-loss 5.0310e+02                  , pde-loss 7.0706e+02, initc-loss 1.1408e+04                    bc_loss 4.6869e+03\n",
      "Epoch 27490, Training-Loss 1.5945e+04, Data-loss 8.2342e+02                  , pde-loss 9.0929e+02, initc-loss 1.0835e+04                    bc_loss 3.3777e+03\n",
      "Epoch 27500, Training-Loss 1.4452e+04, Data-loss 6.0137e+02                  , pde-loss 6.1591e+02, initc-loss 1.0938e+04                    bc_loss 2.2972e+03\n",
      "Epoch 27510, Training-Loss 1.7453e+04, Data-loss 7.5519e+02                  , pde-loss 1.3355e+03, initc-loss 1.1564e+04                    bc_loss 3.7985e+03\n",
      "Epoch 27520, Training-Loss 2.0354e+04, Data-loss 6.9614e+02                  , pde-loss 9.3642e+02, initc-loss 1.1514e+04                    bc_loss 7.2076e+03\n",
      "Epoch 27530, Training-Loss 1.9577e+04, Data-loss 1.0710e+03                  , pde-loss 8.9914e+02, initc-loss 1.1488e+04                    bc_loss 6.1182e+03\n",
      "Epoch 27540, Training-Loss 1.8379e+04, Data-loss 8.1407e+02                  , pde-loss 1.3581e+03, initc-loss 1.1792e+04                    bc_loss 4.4150e+03\n",
      "Epoch 27550, Training-Loss 1.9867e+04, Data-loss 9.1502e+02                  , pde-loss 8.1950e+02, initc-loss 1.1967e+04                    bc_loss 6.1655e+03\n",
      "Epoch 27560, Training-Loss 2.7662e+04, Data-loss 1.1377e+03                  , pde-loss 1.6052e+03, initc-loss 1.2289e+04                    bc_loss 1.2630e+04\n",
      "Epoch 27570, Training-Loss 2.9619e+04, Data-loss 1.2466e+03                  , pde-loss 1.1336e+03, initc-loss 1.3731e+04                    bc_loss 1.3507e+04\n",
      "Epoch 27580, Training-Loss 4.5698e+04, Data-loss 1.7532e+03                  , pde-loss 8.8658e+02, initc-loss 1.3082e+04                    bc_loss 2.9976e+04\n",
      "Epoch 27590, Training-Loss 4.1511e+04, Data-loss 1.5504e+03                  , pde-loss 1.0231e+03, initc-loss 1.5292e+04                    bc_loss 2.3646e+04\n",
      "Epoch 27600, Training-Loss 3.3292e+04, Data-loss 2.4265e+03                  , pde-loss 1.1971e+03, initc-loss 1.7197e+04                    bc_loss 1.2471e+04\n",
      "Epoch 27610, Training-Loss 2.3743e+04, Data-loss 1.6410e+03                  , pde-loss 8.7070e+02, initc-loss 1.4759e+04                    bc_loss 6.4726e+03\n",
      "Epoch 27620, Training-Loss 2.0005e+04, Data-loss 1.2020e+03                  , pde-loss 9.2891e+02, initc-loss 1.4689e+04                    bc_loss 3.1856e+03\n",
      "Epoch 27630, Training-Loss 2.3818e+04, Data-loss 9.1343e+02                  , pde-loss 1.0029e+03, initc-loss 1.5048e+04                    bc_loss 6.8542e+03\n",
      "Epoch 27640, Training-Loss 1.9436e+04, Data-loss 1.2252e+03                  , pde-loss 8.1566e+02, initc-loss 1.2995e+04                    bc_loss 4.4007e+03\n",
      "Epoch 27650, Training-Loss 1.9295e+04, Data-loss 1.8840e+03                  , pde-loss 1.0773e+03, initc-loss 1.2266e+04                    bc_loss 4.0675e+03\n",
      "Epoch 27660, Training-Loss 2.1045e+04, Data-loss 8.7031e+02                  , pde-loss 7.7192e+02, initc-loss 1.2820e+04                    bc_loss 6.5823e+03\n",
      "Epoch 27670, Training-Loss 2.8704e+04, Data-loss 3.2517e+03                  , pde-loss 2.5416e+03, initc-loss 1.2334e+04                    bc_loss 1.0577e+04\n",
      "Epoch 27680, Training-Loss 2.2550e+04, Data-loss 1.0048e+03                  , pde-loss 1.3050e+03, initc-loss 1.3062e+04                    bc_loss 7.1782e+03\n",
      "Epoch 27690, Training-Loss 2.6789e+04, Data-loss 2.3962e+03                  , pde-loss 1.1202e+03, initc-loss 1.3182e+04                    bc_loss 1.0091e+04\n",
      "Epoch 27700, Training-Loss 3.4792e+04, Data-loss 1.5484e+03                  , pde-loss 1.5362e+03, initc-loss 1.4235e+04                    bc_loss 1.7473e+04\n",
      "Epoch 27710, Training-Loss 3.6388e+04, Data-loss 1.5303e+03                  , pde-loss 8.3194e+02, initc-loss 1.5085e+04                    bc_loss 1.8941e+04\n",
      "Epoch 27720, Training-Loss 2.4524e+04, Data-loss 1.8341e+03                  , pde-loss 8.3466e+02, initc-loss 1.5353e+04                    bc_loss 6.5024e+03\n",
      "Epoch 27730, Training-Loss 2.0830e+04, Data-loss 1.1928e+03                  , pde-loss 1.0325e+03, initc-loss 1.3061e+04                    bc_loss 5.5433e+03\n",
      "Epoch 27740, Training-Loss 2.3428e+04, Data-loss 1.8872e+03                  , pde-loss 1.4393e+03, initc-loss 1.5543e+04                    bc_loss 4.5583e+03\n",
      "Epoch 27750, Training-Loss 2.2205e+04, Data-loss 1.2085e+03                  , pde-loss 1.1186e+03, initc-loss 1.2985e+04                    bc_loss 6.8925e+03\n",
      "Epoch 27760, Training-Loss 1.8365e+04, Data-loss 8.3436e+02                  , pde-loss 7.0986e+02, initc-loss 1.2969e+04                    bc_loss 3.8521e+03\n",
      "Epoch 27770, Training-Loss 2.3420e+04, Data-loss 9.9448e+02                  , pde-loss 1.1208e+03, initc-loss 1.2246e+04                    bc_loss 9.0580e+03\n",
      "Epoch 27780, Training-Loss 2.0265e+04, Data-loss 1.0187e+03                  , pde-loss 1.0721e+03, initc-loss 1.1958e+04                    bc_loss 6.2159e+03\n",
      "Epoch 27790, Training-Loss 2.5488e+04, Data-loss 1.2608e+03                  , pde-loss 1.3520e+03, initc-loss 1.2073e+04                    bc_loss 1.0802e+04\n",
      "Epoch 27800, Training-Loss 2.6552e+04, Data-loss 2.5927e+03                  , pde-loss 3.6915e+03, initc-loss 1.1627e+04                    bc_loss 8.6412e+03\n",
      "Epoch 27810, Training-Loss 2.0913e+04, Data-loss 1.7256e+03                  , pde-loss 1.5819e+03, initc-loss 1.2306e+04                    bc_loss 5.3001e+03\n",
      "Epoch 27820, Training-Loss 1.7350e+04, Data-loss 1.0367e+03                  , pde-loss 1.0388e+03, initc-loss 1.1988e+04                    bc_loss 3.2865e+03\n",
      "Epoch 27830, Training-Loss 1.6392e+04, Data-loss 8.6049e+02                  , pde-loss 7.2644e+02, initc-loss 1.2189e+04                    bc_loss 2.6165e+03\n",
      "Epoch 27840, Training-Loss 1.6421e+04, Data-loss 6.7080e+02                  , pde-loss 1.2337e+03, initc-loss 1.1462e+04                    bc_loss 3.0543e+03\n",
      "Epoch 27850, Training-Loss 1.8621e+04, Data-loss 6.1042e+02                  , pde-loss 5.2863e+02, initc-loss 1.0968e+04                    bc_loss 6.5138e+03\n",
      "Epoch 27860, Training-Loss 1.5735e+04, Data-loss 4.7694e+02                  , pde-loss 6.3801e+02, initc-loss 1.1038e+04                    bc_loss 3.5820e+03\n",
      "Epoch 27870, Training-Loss 1.6460e+04, Data-loss 7.0263e+02                  , pde-loss 1.0280e+03, initc-loss 1.2139e+04                    bc_loss 2.5895e+03\n",
      "Epoch 27880, Training-Loss 2.2259e+04, Data-loss 1.9635e+03                  , pde-loss 3.6070e+03, initc-loss 1.1038e+04                    bc_loss 5.6507e+03\n",
      "Epoch 27890, Training-Loss 1.8669e+04, Data-loss 6.1404e+02                  , pde-loss 7.8831e+02, initc-loss 1.2383e+04                    bc_loss 4.8834e+03\n",
      "Epoch 27900, Training-Loss 1.7722e+04, Data-loss 1.8687e+03                  , pde-loss 9.6169e+02, initc-loss 1.1359e+04                    bc_loss 3.5318e+03\n",
      "Epoch 27910, Training-Loss 1.8637e+04, Data-loss 5.3718e+02                  , pde-loss 9.7237e+02, initc-loss 1.0902e+04                    bc_loss 6.2257e+03\n",
      "Epoch 27920, Training-Loss 2.8965e+04, Data-loss 1.4265e+03                  , pde-loss 1.1711e+03, initc-loss 1.1274e+04                    bc_loss 1.5094e+04\n",
      "Epoch 27930, Training-Loss 2.4809e+04, Data-loss 1.2980e+03                  , pde-loss 9.1747e+02, initc-loss 1.3114e+04                    bc_loss 9.4799e+03\n",
      "Epoch 27940, Training-Loss 2.4006e+04, Data-loss 1.4108e+03                  , pde-loss 1.1232e+03, initc-loss 1.2418e+04                    bc_loss 9.0547e+03\n",
      "Epoch 27950, Training-Loss 2.2997e+04, Data-loss 1.4306e+03                  , pde-loss 9.7707e+02, initc-loss 1.2700e+04                    bc_loss 7.8896e+03\n",
      "Epoch 27960, Training-Loss 1.9501e+04, Data-loss 1.3072e+03                  , pde-loss 1.2948e+03, initc-loss 1.2948e+04                    bc_loss 3.9505e+03\n",
      "Epoch 27970, Training-Loss 1.7133e+04, Data-loss 8.2293e+02                  , pde-loss 6.5077e+02, initc-loss 1.2031e+04                    bc_loss 3.6283e+03\n",
      "Epoch 27980, Training-Loss 1.6257e+04, Data-loss 1.0096e+03                  , pde-loss 8.4179e+02, initc-loss 1.2094e+04                    bc_loss 2.3112e+03\n",
      "Epoch 27990, Training-Loss 1.5554e+04, Data-loss 1.5565e+03                  , pde-loss 6.8102e+02, initc-loss 1.0940e+04                    bc_loss 2.3766e+03\n",
      "Epoch 28000, Training-Loss 1.6829e+04, Data-loss 8.3721e+02                  , pde-loss 7.1872e+02, initc-loss 1.0250e+04                    bc_loss 5.0229e+03\n",
      "Epoch 28010, Training-Loss 1.8617e+04, Data-loss 8.3574e+02                  , pde-loss 1.4195e+03, initc-loss 1.0904e+04                    bc_loss 5.4577e+03\n",
      "Epoch 28020, Training-Loss 1.9440e+04, Data-loss 7.5622e+02                  , pde-loss 5.8088e+02, initc-loss 1.0990e+04                    bc_loss 7.1125e+03\n",
      "Epoch 28030, Training-Loss 1.5239e+04, Data-loss 7.2016e+02                  , pde-loss 7.5752e+02, initc-loss 1.0191e+04                    bc_loss 3.5703e+03\n",
      "Epoch 28040, Training-Loss 1.7765e+04, Data-loss 5.8211e+02                  , pde-loss 9.5475e+02, initc-loss 1.0964e+04                    bc_loss 5.2641e+03\n",
      "Epoch 28050, Training-Loss 1.8732e+04, Data-loss 1.0177e+03                  , pde-loss 8.4925e+02, initc-loss 1.0837e+04                    bc_loss 6.0281e+03\n",
      "Epoch 28060, Training-Loss 3.3388e+04, Data-loss 1.0708e+03                  , pde-loss 1.0613e+03, initc-loss 1.1405e+04                    bc_loss 1.9850e+04\n",
      "Epoch 28070, Training-Loss 4.8208e+04, Data-loss 8.9916e+02                  , pde-loss 9.4309e+02, initc-loss 1.4348e+04                    bc_loss 3.2017e+04\n",
      "Epoch 28080, Training-Loss 3.3885e+04, Data-loss 1.3548e+03                  , pde-loss 1.0726e+03, initc-loss 1.4915e+04                    bc_loss 1.6542e+04\n",
      "Epoch 28090, Training-Loss 3.4861e+04, Data-loss 1.5158e+03                  , pde-loss 9.6283e+02, initc-loss 1.4345e+04                    bc_loss 1.8037e+04\n",
      "Epoch 28100, Training-Loss 2.8479e+04, Data-loss 1.4726e+03                  , pde-loss 2.2627e+03, initc-loss 1.5884e+04                    bc_loss 8.8601e+03\n",
      "Epoch 28110, Training-Loss 2.2442e+04, Data-loss 1.9621e+03                  , pde-loss 1.1626e+03, initc-loss 1.3875e+04                    bc_loss 5.4430e+03\n",
      "Epoch 28120, Training-Loss 2.0820e+04, Data-loss 1.0328e+03                  , pde-loss 1.1952e+03, initc-loss 1.4001e+04                    bc_loss 4.5915e+03\n",
      "Epoch 28130, Training-Loss 1.9568e+04, Data-loss 1.4271e+03                  , pde-loss 8.1013e+02, initc-loss 1.4911e+04                    bc_loss 2.4199e+03\n",
      "Epoch 28140, Training-Loss 1.6403e+04, Data-loss 1.0871e+03                  , pde-loss 1.1272e+03, initc-loss 1.1869e+04                    bc_loss 2.3195e+03\n",
      "Epoch 28150, Training-Loss 1.7692e+04, Data-loss 1.0976e+03                  , pde-loss 5.3190e+02, initc-loss 1.2207e+04                    bc_loss 3.8554e+03\n",
      "Epoch 28160, Training-Loss 1.7098e+04, Data-loss 6.5438e+02                  , pde-loss 5.9327e+02, initc-loss 1.1912e+04                    bc_loss 3.9382e+03\n",
      "Epoch 28170, Training-Loss 2.0714e+04, Data-loss 9.8561e+02                  , pde-loss 9.5328e+02, initc-loss 1.1397e+04                    bc_loss 7.3775e+03\n",
      "Epoch 28180, Training-Loss 2.9497e+04, Data-loss 1.6081e+03                  , pde-loss 1.0207e+03, initc-loss 1.1813e+04                    bc_loss 1.5055e+04\n",
      "Epoch 28190, Training-Loss 2.7599e+04, Data-loss 1.6386e+03                  , pde-loss 8.5483e+02, initc-loss 1.3590e+04                    bc_loss 1.1516e+04\n",
      "Epoch 28200, Training-Loss 2.5758e+04, Data-loss 1.6490e+03                  , pde-loss 9.2053e+02, initc-loss 1.3354e+04                    bc_loss 9.8347e+03\n",
      "Epoch 28210, Training-Loss 2.2069e+04, Data-loss 1.8534e+03                  , pde-loss 1.0960e+03, initc-loss 1.3204e+04                    bc_loss 5.9159e+03\n",
      "Epoch 28220, Training-Loss 1.9874e+04, Data-loss 1.5095e+03                  , pde-loss 1.1351e+03, initc-loss 1.3741e+04                    bc_loss 3.4888e+03\n",
      "Epoch 28230, Training-Loss 1.7183e+04, Data-loss 9.2606e+02                  , pde-loss 8.8164e+02, initc-loss 1.2373e+04                    bc_loss 3.0015e+03\n",
      "Epoch 28240, Training-Loss 1.6368e+04, Data-loss 8.5495e+02                  , pde-loss 8.3098e+02, initc-loss 1.2639e+04                    bc_loss 2.0428e+03\n",
      "Epoch 28250, Training-Loss 1.5557e+04, Data-loss 9.7542e+02                  , pde-loss 4.8388e+02, initc-loss 1.1846e+04                    bc_loss 2.2521e+03\n",
      "Epoch 28260, Training-Loss 1.6303e+04, Data-loss 7.6904e+02                  , pde-loss 8.2226e+02, initc-loss 1.0730e+04                    bc_loss 3.9813e+03\n",
      "Epoch 28270, Training-Loss 1.8189e+04, Data-loss 6.4055e+02                  , pde-loss 7.9375e+02, initc-loss 1.1500e+04                    bc_loss 5.2550e+03\n",
      "Epoch 28280, Training-Loss 1.8516e+04, Data-loss 1.2348e+03                  , pde-loss 8.5907e+02, initc-loss 1.1791e+04                    bc_loss 4.6306e+03\n",
      "Epoch 28290, Training-Loss 1.7910e+04, Data-loss 1.1554e+03                  , pde-loss 1.4982e+03, initc-loss 1.1493e+04                    bc_loss 3.7634e+03\n",
      "Epoch 28300, Training-Loss 1.8081e+04, Data-loss 6.8829e+02                  , pde-loss 1.0450e+03, initc-loss 1.1486e+04                    bc_loss 4.8611e+03\n",
      "Epoch 28310, Training-Loss 1.8635e+04, Data-loss 1.8411e+03                  , pde-loss 2.8465e+03, initc-loss 1.1066e+04                    bc_loss 2.8806e+03\n",
      "Epoch 28320, Training-Loss 1.6617e+04, Data-loss 6.4074e+02                  , pde-loss 1.1376e+03, initc-loss 1.0892e+04                    bc_loss 3.9462e+03\n",
      "Epoch 28330, Training-Loss 1.7426e+04, Data-loss 1.3682e+03                  , pde-loss 1.0365e+03, initc-loss 1.1313e+04                    bc_loss 3.7083e+03\n",
      "Epoch 28340, Training-Loss 1.9674e+04, Data-loss 6.3312e+02                  , pde-loss 8.2300e+02, initc-loss 1.0785e+04                    bc_loss 7.4326e+03\n",
      "Epoch 28350, Training-Loss 2.5624e+04, Data-loss 1.1845e+03                  , pde-loss 1.4856e+03, initc-loss 1.1408e+04                    bc_loss 1.1546e+04\n",
      "Epoch 28360, Training-Loss 1.8767e+04, Data-loss 1.3212e+03                  , pde-loss 1.0147e+03, initc-loss 1.2441e+04                    bc_loss 3.9901e+03\n",
      "Epoch 28370, Training-Loss 1.6861e+04, Data-loss 6.8146e+02                  , pde-loss 1.1333e+03, initc-loss 1.2256e+04                    bc_loss 2.7905e+03\n",
      "Epoch 28380, Training-Loss 1.4272e+04, Data-loss 5.0054e+02                  , pde-loss 8.7861e+02, initc-loss 1.1079e+04                    bc_loss 1.8140e+03\n",
      "Epoch 28390, Training-Loss 1.8683e+04, Data-loss 6.2457e+02                  , pde-loss 1.0059e+03, initc-loss 1.0382e+04                    bc_loss 6.6704e+03\n",
      "Epoch 28400, Training-Loss 1.6656e+04, Data-loss 8.6213e+02                  , pde-loss 7.8689e+02, initc-loss 1.1357e+04                    bc_loss 3.6491e+03\n",
      "Epoch 28410, Training-Loss 1.6100e+04, Data-loss 5.0799e+02                  , pde-loss 9.4595e+02, initc-loss 1.2001e+04                    bc_loss 2.6451e+03\n",
      "Epoch 28420, Training-Loss 1.9660e+04, Data-loss 4.9433e+02                  , pde-loss 7.6375e+02, initc-loss 1.1283e+04                    bc_loss 7.1191e+03\n",
      "Epoch 28430, Training-Loss 2.2719e+04, Data-loss 8.7866e+02                  , pde-loss 6.5535e+02, initc-loss 1.1542e+04                    bc_loss 9.6432e+03\n",
      "Epoch 28440, Training-Loss 2.2871e+04, Data-loss 1.8366e+03                  , pde-loss 9.8689e+02, initc-loss 1.3311e+04                    bc_loss 6.7368e+03\n",
      "Epoch 28450, Training-Loss 1.7739e+04, Data-loss 5.7023e+02                  , pde-loss 6.3740e+02, initc-loss 1.1686e+04                    bc_loss 4.8446e+03\n",
      "Epoch 28460, Training-Loss 2.4514e+04, Data-loss 1.8681e+03                  , pde-loss 1.3630e+03, initc-loss 1.1764e+04                    bc_loss 9.5184e+03\n",
      "Epoch 28470, Training-Loss 2.6304e+04, Data-loss 2.0514e+03                  , pde-loss 1.8437e+03, initc-loss 1.1891e+04                    bc_loss 1.0517e+04\n",
      "Epoch 28480, Training-Loss 2.7804e+04, Data-loss 1.1156e+03                  , pde-loss 9.9855e+02, initc-loss 1.5969e+04                    bc_loss 9.7212e+03\n",
      "Epoch 28490, Training-Loss 1.9476e+04, Data-loss 1.4082e+03                  , pde-loss 1.0701e+03, initc-loss 1.2731e+04                    bc_loss 4.2665e+03\n",
      "Epoch 28500, Training-Loss 1.8281e+04, Data-loss 7.0669e+02                  , pde-loss 8.9541e+02, initc-loss 1.3130e+04                    bc_loss 3.5489e+03\n",
      "Epoch 28510, Training-Loss 1.7479e+04, Data-loss 8.0716e+02                  , pde-loss 1.6507e+03, initc-loss 1.2411e+04                    bc_loss 2.6101e+03\n",
      "Epoch 28520, Training-Loss 1.5433e+04, Data-loss 6.3584e+02                  , pde-loss 7.6120e+02, initc-loss 1.1176e+04                    bc_loss 2.8596e+03\n",
      "Epoch 28530, Training-Loss 1.5331e+04, Data-loss 9.0864e+02                  , pde-loss 1.0473e+03, initc-loss 1.1381e+04                    bc_loss 1.9937e+03\n",
      "Epoch 28540, Training-Loss 1.5772e+04, Data-loss 1.2404e+03                  , pde-loss 9.6555e+02, initc-loss 1.0502e+04                    bc_loss 3.0643e+03\n",
      "Epoch 28550, Training-Loss 1.7204e+04, Data-loss 6.5020e+02                  , pde-loss 8.9663e+02, initc-loss 1.0176e+04                    bc_loss 5.4819e+03\n",
      "Epoch 28560, Training-Loss 1.8776e+04, Data-loss 6.0561e+02                  , pde-loss 9.5034e+02, initc-loss 1.1401e+04                    bc_loss 5.8197e+03\n",
      "Epoch 28570, Training-Loss 1.9064e+04, Data-loss 1.0676e+03                  , pde-loss 6.4296e+02, initc-loss 1.1754e+04                    bc_loss 5.6002e+03\n",
      "Epoch 28580, Training-Loss 1.7744e+04, Data-loss 1.0741e+03                  , pde-loss 9.5600e+02, initc-loss 1.1806e+04                    bc_loss 3.9084e+03\n",
      "Epoch 28590, Training-Loss 1.5970e+04, Data-loss 1.1966e+03                  , pde-loss 9.8852e+02, initc-loss 1.0888e+04                    bc_loss 2.8966e+03\n",
      "Epoch 28600, Training-Loss 2.1926e+04, Data-loss 1.4983e+03                  , pde-loss 1.1971e+03, initc-loss 1.1714e+04                    bc_loss 7.5165e+03\n",
      "Epoch 28610, Training-Loss 2.8333e+04, Data-loss 7.2756e+02                  , pde-loss 1.2458e+03, initc-loss 1.2149e+04                    bc_loss 1.4210e+04\n",
      "Epoch 28620, Training-Loss 2.3545e+04, Data-loss 1.1487e+03                  , pde-loss 7.8560e+02, initc-loss 1.2735e+04                    bc_loss 8.8756e+03\n",
      "Epoch 28630, Training-Loss 2.0326e+04, Data-loss 1.2625e+03                  , pde-loss 9.8528e+02, initc-loss 1.3170e+04                    bc_loss 4.9080e+03\n",
      "Epoch 28640, Training-Loss 1.6613e+04, Data-loss 9.7544e+02                  , pde-loss 1.0284e+03, initc-loss 1.2039e+04                    bc_loss 2.5704e+03\n",
      "Epoch 28650, Training-Loss 1.5966e+04, Data-loss 9.6288e+02                  , pde-loss 7.8939e+02, initc-loss 1.1554e+04                    bc_loss 2.6602e+03\n",
      "Epoch 28660, Training-Loss 1.7262e+04, Data-loss 9.2417e+02                  , pde-loss 9.5721e+02, initc-loss 1.1819e+04                    bc_loss 3.5617e+03\n",
      "Epoch 28670, Training-Loss 1.6126e+04, Data-loss 6.9175e+02                  , pde-loss 7.4387e+02, initc-loss 1.0511e+04                    bc_loss 4.1795e+03\n",
      "Epoch 28680, Training-Loss 1.5452e+04, Data-loss 4.6619e+02                  , pde-loss 7.4559e+02, initc-loss 1.1188e+04                    bc_loss 3.0526e+03\n",
      "Epoch 28690, Training-Loss 1.5705e+04, Data-loss 7.0544e+02                  , pde-loss 1.7590e+03, initc-loss 1.0572e+04                    bc_loss 2.6681e+03\n",
      "Epoch 28700, Training-Loss 1.5607e+04, Data-loss 9.9267e+02                  , pde-loss 1.2156e+03, initc-loss 9.9835e+03                    bc_loss 3.4154e+03\n",
      "Epoch 28710, Training-Loss 1.6906e+04, Data-loss 9.0931e+02                  , pde-loss 6.2152e+02, initc-loss 9.5195e+03                    bc_loss 5.8556e+03\n",
      "Epoch 28720, Training-Loss 2.2214e+04, Data-loss 2.6518e+03                  , pde-loss 1.5952e+03, initc-loss 1.1027e+04                    bc_loss 6.9394e+03\n",
      "Epoch 28730, Training-Loss 2.8360e+04, Data-loss 7.4254e+02                  , pde-loss 1.0073e+03, initc-loss 1.2193e+04                    bc_loss 1.4418e+04\n",
      "Epoch 28740, Training-Loss 2.1135e+04, Data-loss 1.1425e+03                  , pde-loss 1.7236e+03, initc-loss 1.2206e+04                    bc_loss 6.0627e+03\n",
      "Epoch 28750, Training-Loss 1.6741e+04, Data-loss 9.7144e+02                  , pde-loss 8.8871e+02, initc-loss 1.1170e+04                    bc_loss 3.7111e+03\n",
      "Epoch 28760, Training-Loss 1.6334e+04, Data-loss 1.6013e+03                  , pde-loss 8.8607e+02, initc-loss 1.0931e+04                    bc_loss 2.9155e+03\n",
      "Epoch 28770, Training-Loss 1.6716e+04, Data-loss 4.5008e+02                  , pde-loss 1.0019e+03, initc-loss 1.1290e+04                    bc_loss 3.9740e+03\n",
      "Epoch 28780, Training-Loss 1.5308e+04, Data-loss 5.5751e+02                  , pde-loss 8.0969e+02, initc-loss 1.0354e+04                    bc_loss 3.5867e+03\n",
      "Epoch 28790, Training-Loss 2.0037e+04, Data-loss 9.2369e+02                  , pde-loss 1.3162e+03, initc-loss 1.0613e+04                    bc_loss 7.1844e+03\n",
      "Epoch 28800, Training-Loss 2.2851e+04, Data-loss 1.1876e+03                  , pde-loss 1.6247e+03, initc-loss 1.2043e+04                    bc_loss 7.9964e+03\n",
      "Epoch 28810, Training-Loss 2.2412e+04, Data-loss 1.3595e+03                  , pde-loss 7.3319e+02, initc-loss 1.1897e+04                    bc_loss 8.4219e+03\n",
      "Epoch 28820, Training-Loss 2.1796e+04, Data-loss 1.0413e+03                  , pde-loss 9.4848e+02, initc-loss 1.1914e+04                    bc_loss 7.8926e+03\n",
      "Epoch 28830, Training-Loss 1.7166e+04, Data-loss 6.3611e+02                  , pde-loss 7.7315e+02, initc-loss 1.1230e+04                    bc_loss 4.5275e+03\n",
      "Epoch 28840, Training-Loss 1.6177e+04, Data-loss 1.4106e+03                  , pde-loss 1.0257e+03, initc-loss 1.0532e+04                    bc_loss 3.2081e+03\n",
      "Epoch 28850, Training-Loss 1.5816e+04, Data-loss 6.8546e+02                  , pde-loss 1.3183e+03, initc-loss 1.0500e+04                    bc_loss 3.3123e+03\n",
      "Epoch 28860, Training-Loss 1.6542e+04, Data-loss 1.3985e+03                  , pde-loss 1.5271e+03, initc-loss 1.0552e+04                    bc_loss 3.0639e+03\n",
      "Epoch 28870, Training-Loss 1.7362e+04, Data-loss 8.6565e+02                  , pde-loss 6.1970e+02, initc-loss 1.0991e+04                    bc_loss 4.8852e+03\n",
      "Epoch 28880, Training-Loss 1.6028e+04, Data-loss 7.8435e+02                  , pde-loss 9.5679e+02, initc-loss 1.0695e+04                    bc_loss 3.5919e+03\n",
      "Epoch 28890, Training-Loss 4.1261e+04, Data-loss 9.4894e+02                  , pde-loss 7.8061e+02, initc-loss 1.0538e+04                    bc_loss 2.8993e+04\n",
      "Epoch 28900, Training-Loss 2.5416e+04, Data-loss 1.1859e+03                  , pde-loss 1.1688e+03, initc-loss 1.3242e+04                    bc_loss 9.8192e+03\n",
      "Epoch 28910, Training-Loss 2.5269e+04, Data-loss 2.3787e+03                  , pde-loss 1.5553e+03, initc-loss 1.2533e+04                    bc_loss 8.8017e+03\n",
      "Epoch 28920, Training-Loss 1.9762e+04, Data-loss 1.3548e+03                  , pde-loss 6.9380e+02, initc-loss 1.2967e+04                    bc_loss 4.7460e+03\n",
      "Epoch 28930, Training-Loss 1.8577e+04, Data-loss 6.0270e+02                  , pde-loss 1.1406e+03, initc-loss 1.2934e+04                    bc_loss 3.8999e+03\n",
      "Epoch 28940, Training-Loss 1.6360e+04, Data-loss 1.1126e+03                  , pde-loss 7.4856e+02, initc-loss 1.1797e+04                    bc_loss 2.7020e+03\n",
      "Epoch 28950, Training-Loss 1.6480e+04, Data-loss 1.1595e+03                  , pde-loss 1.3951e+03, initc-loss 1.1570e+04                    bc_loss 2.3553e+03\n",
      "Epoch 28960, Training-Loss 1.4209e+04, Data-loss 1.0455e+03                  , pde-loss 1.0496e+03, initc-loss 1.0169e+04                    bc_loss 1.9445e+03\n",
      "Epoch 28970, Training-Loss 1.8932e+04, Data-loss 7.5359e+02                  , pde-loss 9.8237e+02, initc-loss 1.0190e+04                    bc_loss 7.0059e+03\n",
      "Epoch 28980, Training-Loss 1.5481e+04, Data-loss 5.2288e+02                  , pde-loss 7.4525e+02, initc-loss 1.0302e+04                    bc_loss 3.9112e+03\n",
      "Epoch 28990, Training-Loss 2.1865e+04, Data-loss 6.7554e+02                  , pde-loss 7.2404e+02, initc-loss 1.2136e+04                    bc_loss 8.3291e+03\n",
      "Epoch 29000, Training-Loss 1.7741e+04, Data-loss 1.2039e+03                  , pde-loss 1.8615e+03, initc-loss 1.1202e+04                    bc_loss 3.4734e+03\n",
      "Epoch 29010, Training-Loss 1.5976e+04, Data-loss 7.8894e+02                  , pde-loss 7.1320e+02, initc-loss 1.1044e+04                    bc_loss 3.4300e+03\n",
      "Epoch 29020, Training-Loss 1.7279e+04, Data-loss 7.4158e+02                  , pde-loss 5.2147e+02, initc-loss 1.1124e+04                    bc_loss 4.8922e+03\n",
      "Epoch 29030, Training-Loss 1.8927e+04, Data-loss 9.7012e+02                  , pde-loss 9.1520e+02, initc-loss 1.1466e+04                    bc_loss 5.5758e+03\n",
      "Epoch 29040, Training-Loss 1.8231e+04, Data-loss 6.0498e+02                  , pde-loss 8.6475e+02, initc-loss 1.2002e+04                    bc_loss 4.7602e+03\n",
      "Epoch 29050, Training-Loss 1.9032e+04, Data-loss 6.7311e+02                  , pde-loss 7.6874e+02, initc-loss 1.3232e+04                    bc_loss 4.3573e+03\n",
      "Epoch 29060, Training-Loss 1.5978e+04, Data-loss 7.6492e+02                  , pde-loss 7.7530e+02, initc-loss 1.0810e+04                    bc_loss 3.6278e+03\n",
      "Epoch 29070, Training-Loss 1.6712e+04, Data-loss 1.0493e+03                  , pde-loss 7.6966e+02, initc-loss 1.0560e+04                    bc_loss 4.3332e+03\n",
      "Epoch 29080, Training-Loss 1.5411e+04, Data-loss 5.7986e+02                  , pde-loss 7.5464e+02, initc-loss 1.0520e+04                    bc_loss 3.5557e+03\n",
      "Epoch 29090, Training-Loss 1.6032e+04, Data-loss 5.3405e+02                  , pde-loss 5.5889e+02, initc-loss 1.1811e+04                    bc_loss 3.1282e+03\n",
      "Epoch 29100, Training-Loss 1.5471e+04, Data-loss 7.8564e+02                  , pde-loss 6.0975e+02, initc-loss 1.0842e+04                    bc_loss 3.2334e+03\n",
      "Epoch 29110, Training-Loss 2.1207e+04, Data-loss 1.0709e+03                  , pde-loss 8.9730e+02, initc-loss 1.0322e+04                    bc_loss 8.9167e+03\n",
      "Epoch 29120, Training-Loss 2.0068e+04, Data-loss 9.4799e+02                  , pde-loss 9.3180e+02, initc-loss 1.0402e+04                    bc_loss 7.7865e+03\n",
      "Epoch 29130, Training-Loss 1.8562e+04, Data-loss 9.0176e+02                  , pde-loss 1.2564e+03, initc-loss 1.0721e+04                    bc_loss 5.6823e+03\n",
      "Epoch 29140, Training-Loss 1.9010e+04, Data-loss 8.0605e+02                  , pde-loss 6.1637e+02, initc-loss 1.1975e+04                    bc_loss 5.6133e+03\n",
      "Epoch 29150, Training-Loss 2.4771e+04, Data-loss 1.5199e+03                  , pde-loss 9.5829e+02, initc-loss 1.1906e+04                    bc_loss 1.0387e+04\n",
      "Epoch 29160, Training-Loss 1.9375e+04, Data-loss 8.5465e+02                  , pde-loss 6.8801e+02, initc-loss 1.1993e+04                    bc_loss 5.8390e+03\n",
      "Epoch 29170, Training-Loss 1.8860e+04, Data-loss 1.7443e+03                  , pde-loss 1.6555e+03, initc-loss 1.1146e+04                    bc_loss 4.3134e+03\n",
      "Epoch 29180, Training-Loss 2.2456e+04, Data-loss 8.6944e+02                  , pde-loss 6.2118e+02, initc-loss 1.0726e+04                    bc_loss 1.0239e+04\n",
      "Epoch 29190, Training-Loss 1.7449e+04, Data-loss 7.2757e+02                  , pde-loss 8.7907e+02, initc-loss 1.0871e+04                    bc_loss 4.9709e+03\n",
      "Epoch 29200, Training-Loss 2.0271e+04, Data-loss 1.1438e+03                  , pde-loss 1.3095e+03, initc-loss 1.0960e+04                    bc_loss 6.8585e+03\n",
      "Epoch 29210, Training-Loss 2.1730e+04, Data-loss 8.4687e+02                  , pde-loss 9.0682e+02, initc-loss 1.0811e+04                    bc_loss 9.1651e+03\n",
      "Epoch 29220, Training-Loss 1.8835e+04, Data-loss 1.0731e+03                  , pde-loss 7.8455e+02, initc-loss 1.0859e+04                    bc_loss 6.1184e+03\n",
      "Epoch 29230, Training-Loss 1.7408e+04, Data-loss 8.5096e+02                  , pde-loss 1.1015e+03, initc-loss 1.2301e+04                    bc_loss 3.1540e+03\n",
      "Epoch 29240, Training-Loss 1.5348e+04, Data-loss 5.6969e+02                  , pde-loss 8.1766e+02, initc-loss 1.0931e+04                    bc_loss 3.0287e+03\n",
      "Epoch 29250, Training-Loss 1.4026e+04, Data-loss 9.8516e+02                  , pde-loss 4.7351e+02, initc-loss 1.0533e+04                    bc_loss 2.0347e+03\n",
      "Epoch 29260, Training-Loss 1.3925e+04, Data-loss 5.9554e+02                  , pde-loss 7.4955e+02, initc-loss 9.6804e+03                    bc_loss 2.8997e+03\n",
      "Epoch 29270, Training-Loss 1.4322e+04, Data-loss 7.5927e+02                  , pde-loss 6.5625e+02, initc-loss 9.7727e+03                    bc_loss 3.1334e+03\n",
      "Epoch 29280, Training-Loss 1.6532e+04, Data-loss 5.1081e+02                  , pde-loss 5.9280e+02, initc-loss 9.2700e+03                    bc_loss 6.1587e+03\n",
      "Epoch 29290, Training-Loss 1.6647e+04, Data-loss 1.1206e+03                  , pde-loss 7.1453e+02, initc-loss 1.0306e+04                    bc_loss 4.5060e+03\n",
      "Epoch 29300, Training-Loss 1.8991e+04, Data-loss 9.1534e+02                  , pde-loss 8.3390e+02, initc-loss 1.1748e+04                    bc_loss 5.4933e+03\n",
      "Epoch 29310, Training-Loss 2.1060e+04, Data-loss 5.7450e+02                  , pde-loss 7.1101e+02, initc-loss 1.1124e+04                    bc_loss 8.6502e+03\n",
      "Epoch 29320, Training-Loss 2.1198e+04, Data-loss 3.3981e+03                  , pde-loss 1.1530e+03, initc-loss 1.0607e+04                    bc_loss 6.0401e+03\n",
      "Epoch 29330, Training-Loss 1.5759e+04, Data-loss 7.9920e+02                  , pde-loss 6.8150e+02, initc-loss 1.0602e+04                    bc_loss 3.6771e+03\n",
      "Epoch 29340, Training-Loss 1.6153e+04, Data-loss 1.0191e+03                  , pde-loss 8.5980e+02, initc-loss 1.1307e+04                    bc_loss 2.9667e+03\n",
      "Epoch 29350, Training-Loss 1.5759e+04, Data-loss 1.0730e+03                  , pde-loss 1.2076e+03, initc-loss 1.0446e+04                    bc_loss 3.0326e+03\n",
      "Epoch 29360, Training-Loss 1.3271e+04, Data-loss 3.8327e+02                  , pde-loss 7.2441e+02, initc-loss 9.7176e+03                    bc_loss 2.4453e+03\n",
      "Epoch 29370, Training-Loss 1.4872e+04, Data-loss 7.3799e+02                  , pde-loss 8.5860e+02, initc-loss 9.6063e+03                    bc_loss 3.6692e+03\n",
      "Epoch 29380, Training-Loss 1.7999e+04, Data-loss 1.1409e+03                  , pde-loss 8.8257e+02, initc-loss 1.1269e+04                    bc_loss 4.7057e+03\n",
      "Epoch 29390, Training-Loss 2.6769e+04, Data-loss 1.9116e+03                  , pde-loss 7.3716e+02, initc-loss 1.1661e+04                    bc_loss 1.2459e+04\n",
      "Epoch 29400, Training-Loss 1.7614e+04, Data-loss 1.2728e+03                  , pde-loss 1.2715e+03, initc-loss 1.1518e+04                    bc_loss 3.5514e+03\n",
      "Epoch 29410, Training-Loss 2.1083e+04, Data-loss 1.2647e+03                  , pde-loss 1.2124e+03, initc-loss 1.1160e+04                    bc_loss 7.4460e+03\n",
      "Epoch 29420, Training-Loss 2.0466e+04, Data-loss 2.3132e+03                  , pde-loss 8.8931e+02, initc-loss 1.1809e+04                    bc_loss 5.4548e+03\n",
      "Epoch 29430, Training-Loss 1.6343e+04, Data-loss 8.3258e+02                  , pde-loss 6.1259e+02, initc-loss 1.1077e+04                    bc_loss 3.8206e+03\n",
      "Epoch 29440, Training-Loss 1.6052e+04, Data-loss 1.2191e+03                  , pde-loss 7.1889e+02, initc-loss 1.1617e+04                    bc_loss 2.4964e+03\n",
      "Epoch 29450, Training-Loss 1.4233e+04, Data-loss 6.6306e+02                  , pde-loss 5.9154e+02, initc-loss 1.0983e+04                    bc_loss 1.9959e+03\n",
      "Epoch 29460, Training-Loss 1.7966e+04, Data-loss 8.4401e+02                  , pde-loss 7.8565e+02, initc-loss 1.0812e+04                    bc_loss 5.5246e+03\n",
      "Epoch 29470, Training-Loss 1.7029e+04, Data-loss 8.0202e+02                  , pde-loss 1.4950e+03, initc-loss 9.9298e+03                    bc_loss 4.8026e+03\n",
      "Epoch 29480, Training-Loss 1.8812e+04, Data-loss 5.3721e+02                  , pde-loss 8.3332e+02, initc-loss 1.0806e+04                    bc_loss 6.6355e+03\n",
      "Epoch 29490, Training-Loss 1.8245e+04, Data-loss 8.3957e+02                  , pde-loss 6.4609e+02, initc-loss 1.0425e+04                    bc_loss 6.3341e+03\n",
      "Epoch 29500, Training-Loss 1.8152e+04, Data-loss 7.7358e+02                  , pde-loss 9.9293e+02, initc-loss 1.1454e+04                    bc_loss 4.9312e+03\n",
      "Epoch 29510, Training-Loss 1.6920e+04, Data-loss 9.9330e+02                  , pde-loss 6.4173e+02, initc-loss 1.1479e+04                    bc_loss 3.8063e+03\n",
      "Epoch 29520, Training-Loss 1.8488e+04, Data-loss 1.1281e+03                  , pde-loss 4.6614e+02, initc-loss 1.0658e+04                    bc_loss 6.2362e+03\n",
      "Epoch 29530, Training-Loss 1.9120e+04, Data-loss 9.0492e+02                  , pde-loss 5.6358e+02, initc-loss 1.2328e+04                    bc_loss 5.3243e+03\n",
      "Epoch 29540, Training-Loss 1.8583e+04, Data-loss 9.4493e+02                  , pde-loss 6.8822e+02, initc-loss 1.1503e+04                    bc_loss 5.4461e+03\n",
      "Epoch 29550, Training-Loss 1.7792e+04, Data-loss 8.6452e+02                  , pde-loss 5.1736e+02, initc-loss 1.1760e+04                    bc_loss 4.6496e+03\n",
      "Epoch 29560, Training-Loss 1.7804e+04, Data-loss 1.5816e+03                  , pde-loss 1.2578e+03, initc-loss 1.0737e+04                    bc_loss 4.2273e+03\n",
      "Epoch 29570, Training-Loss 1.5437e+04, Data-loss 1.0381e+03                  , pde-loss 6.9367e+02, initc-loss 1.0351e+04                    bc_loss 3.3550e+03\n",
      "Epoch 29580, Training-Loss 1.4499e+04, Data-loss 4.5613e+02                  , pde-loss 6.1144e+02, initc-loss 1.0419e+04                    bc_loss 3.0129e+03\n",
      "Epoch 29590, Training-Loss 1.4005e+04, Data-loss 1.0361e+03                  , pde-loss 5.2487e+02, initc-loss 9.3577e+03                    bc_loss 3.0866e+03\n",
      "Epoch 29600, Training-Loss 1.6706e+04, Data-loss 8.1060e+02                  , pde-loss 1.0870e+03, initc-loss 1.0159e+04                    bc_loss 4.6498e+03\n",
      "Epoch 29610, Training-Loss 2.0431e+04, Data-loss 5.8777e+02                  , pde-loss 1.0049e+03, initc-loss 9.9018e+03                    bc_loss 8.9368e+03\n",
      "Epoch 29620, Training-Loss 2.1962e+04, Data-loss 7.5215e+02                  , pde-loss 5.7169e+02, initc-loss 1.1672e+04                    bc_loss 8.9655e+03\n",
      "Epoch 29630, Training-Loss 2.1883e+04, Data-loss 1.1531e+03                  , pde-loss 5.2119e+02, initc-loss 1.1578e+04                    bc_loss 8.6307e+03\n",
      "Epoch 29640, Training-Loss 1.8658e+04, Data-loss 1.1674e+03                  , pde-loss 4.8397e+02, initc-loss 1.1382e+04                    bc_loss 5.6250e+03\n",
      "Epoch 29650, Training-Loss 1.9968e+04, Data-loss 1.7481e+03                  , pde-loss 8.0579e+02, initc-loss 1.1413e+04                    bc_loss 6.0005e+03\n",
      "Epoch 29660, Training-Loss 1.6445e+04, Data-loss 1.0622e+03                  , pde-loss 1.5082e+03, initc-loss 1.0685e+04                    bc_loss 3.1900e+03\n",
      "Epoch 29670, Training-Loss 1.3281e+04, Data-loss 3.6850e+02                  , pde-loss 5.6823e+02, initc-loss 9.9820e+03                    bc_loss 2.3622e+03\n",
      "Epoch 29680, Training-Loss 1.5150e+04, Data-loss 6.7344e+02                  , pde-loss 6.7592e+02, initc-loss 9.9688e+03                    bc_loss 3.8317e+03\n",
      "Epoch 29690, Training-Loss 2.0093e+04, Data-loss 7.7778e+02                  , pde-loss 5.9461e+02, initc-loss 1.0228e+04                    bc_loss 8.4925e+03\n",
      "Epoch 29700, Training-Loss 8.1244e+04, Data-loss 9.8185e+02                  , pde-loss 1.1995e+03, initc-loss 1.2677e+04                    bc_loss 6.6387e+04\n",
      "Epoch 29710, Training-Loss 6.9744e+04, Data-loss 4.3992e+03                  , pde-loss 3.3664e+03, initc-loss 1.8356e+04                    bc_loss 4.3623e+04\n",
      "Epoch 29720, Training-Loss 5.3842e+04, Data-loss 7.8943e+03                  , pde-loss 8.2059e+03, initc-loss 2.1692e+04                    bc_loss 1.6050e+04\n",
      "Epoch 29730, Training-Loss 4.6678e+04, Data-loss 5.9835e+03                  , pde-loss 3.6078e+03, initc-loss 2.4787e+04                    bc_loss 1.2299e+04\n",
      "Epoch 29740, Training-Loss 3.0996e+04, Data-loss 3.3953e+03                  , pde-loss 1.6783e+03, initc-loss 2.0002e+04                    bc_loss 5.9204e+03\n",
      "Epoch 29750, Training-Loss 2.8602e+04, Data-loss 2.9219e+03                  , pde-loss 1.5843e+03, initc-loss 1.9447e+04                    bc_loss 4.6488e+03\n",
      "Epoch 29760, Training-Loss 2.4818e+04, Data-loss 2.6888e+03                  , pde-loss 1.5069e+03, initc-loss 1.7195e+04                    bc_loss 3.4269e+03\n",
      "Epoch 29770, Training-Loss 2.1648e+04, Data-loss 2.0476e+03                  , pde-loss 1.0745e+03, initc-loss 1.5563e+04                    bc_loss 2.9630e+03\n",
      "Epoch 29780, Training-Loss 2.2677e+04, Data-loss 2.5253e+03                  , pde-loss 1.8557e+03, initc-loss 1.6116e+04                    bc_loss 2.1806e+03\n",
      "Epoch 29790, Training-Loss 2.1438e+04, Data-loss 2.2283e+03                  , pde-loss 1.9240e+03, initc-loss 1.4849e+04                    bc_loss 2.4361e+03\n",
      "Epoch 29800, Training-Loss 1.8029e+04, Data-loss 1.4354e+03                  , pde-loss 1.0052e+03, initc-loss 1.3453e+04                    bc_loss 2.1351e+03\n",
      "Epoch 29810, Training-Loss 1.7667e+04, Data-loss 2.1566e+03                  , pde-loss 7.0583e+02, initc-loss 1.2831e+04                    bc_loss 1.9735e+03\n",
      "Epoch 29820, Training-Loss 1.8742e+04, Data-loss 1.8940e+03                  , pde-loss 1.9946e+03, initc-loss 1.2966e+04                    bc_loss 1.8876e+03\n",
      "Epoch 29830, Training-Loss 1.5725e+04, Data-loss 8.1265e+02                  , pde-loss 9.2865e+02, initc-loss 1.1885e+04                    bc_loss 2.0990e+03\n",
      "Epoch 29840, Training-Loss 1.6280e+04, Data-loss 1.1016e+03                  , pde-loss 8.9205e+02, initc-loss 1.1843e+04                    bc_loss 2.4430e+03\n",
      "Epoch 29850, Training-Loss 2.0651e+04, Data-loss 1.3872e+03                  , pde-loss 2.2252e+03, initc-loss 1.0535e+04                    bc_loss 6.5037e+03\n",
      "Epoch 29860, Training-Loss 2.2364e+04, Data-loss 7.8364e+02                  , pde-loss 8.8434e+02, initc-loss 1.1589e+04                    bc_loss 9.1078e+03\n",
      "Epoch 29870, Training-Loss 2.3465e+04, Data-loss 1.5673e+03                  , pde-loss 1.5718e+03, initc-loss 1.2707e+04                    bc_loss 7.6182e+03\n",
      "Epoch 29880, Training-Loss 1.9282e+04, Data-loss 9.9884e+02                  , pde-loss 4.1245e+02, initc-loss 1.2389e+04                    bc_loss 5.4821e+03\n",
      "Epoch 29890, Training-Loss 1.9714e+04, Data-loss 1.5349e+03                  , pde-loss 2.1656e+03, initc-loss 1.1961e+04                    bc_loss 4.0529e+03\n",
      "Epoch 29900, Training-Loss 1.7270e+04, Data-loss 1.2427e+03                  , pde-loss 9.2385e+02, initc-loss 1.2256e+04                    bc_loss 2.8475e+03\n",
      "Epoch 29910, Training-Loss 1.7859e+04, Data-loss 1.0379e+03                  , pde-loss 1.2616e+03, initc-loss 1.2091e+04                    bc_loss 3.4687e+03\n",
      "Epoch 29920, Training-Loss 1.6572e+04, Data-loss 7.5399e+02                  , pde-loss 6.5814e+02, initc-loss 1.1126e+04                    bc_loss 4.0342e+03\n",
      "Epoch 29930, Training-Loss 1.4050e+04, Data-loss 5.8678e+02                  , pde-loss 1.0140e+03, initc-loss 1.0733e+04                    bc_loss 1.7170e+03\n",
      "Epoch 29940, Training-Loss 1.5980e+04, Data-loss 8.4656e+02                  , pde-loss 7.2414e+02, initc-loss 1.1243e+04                    bc_loss 3.1664e+03\n",
      "Epoch 29950, Training-Loss 1.6768e+04, Data-loss 1.6256e+03                  , pde-loss 9.6122e+02, initc-loss 9.8803e+03                    bc_loss 4.3011e+03\n",
      "Epoch 29960, Training-Loss 1.7850e+04, Data-loss 1.5212e+03                  , pde-loss 1.3092e+03, initc-loss 1.0727e+04                    bc_loss 4.2928e+03\n",
      "Epoch 29970, Training-Loss 1.9511e+04, Data-loss 5.0347e+02                  , pde-loss 9.6686e+02, initc-loss 1.1320e+04                    bc_loss 6.7205e+03\n",
      "Epoch 29980, Training-Loss 2.0827e+04, Data-loss 9.9709e+02                  , pde-loss 6.5588e+02, initc-loss 1.1206e+04                    bc_loss 7.9682e+03\n",
      "Epoch 29990, Training-Loss 2.1672e+04, Data-loss 1.1291e+03                  , pde-loss 5.9054e+02, initc-loss 1.1716e+04                    bc_loss 8.2370e+03\n",
      "Epoch 30000, Test-Loss 4.8798e+04, Test-Accuracy 2.5692e-01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses, val_losses = training_loop(epochs, model, loss_fn_data, optimizer,train_loader)  # Train the model\n",
    " \n",
    "test_losses = test_loop(epochs, model, loss_fn_data, optimizer, train_loader, test_loader)  # Test the model\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_nn = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).cpu().detach().numpy() # Get the predictions from the model\n",
    "\n",
    "temp_nn = temp_nn.reshape(num_steps+1, num_points) # Reshape the predictions to a 2D array\n",
    "time_ss= np.linspace(0, time_end, num_steps+1)\n",
    "plt.figure\n",
    "plt.plot(time_ss, temp_nn[:,num_points//2], label='Predicted Temperature')\n",
    "plt.plot(time_ss, temperature_history[:,num_points//2], label='Actual Temperature')\n",
    "plt.xlabel('Time(s)')\n",
    "plt.ylabel('Temperature (K)')\n",
    "plt.title('Predicted vs Actual Temperature at x = 7.5mm')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
