{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometry\n",
    "length = 15e-2              # Length of the rod\n",
    "\n",
    "# Material properties\n",
    "rho = 2760.0                      # Density of AL380 (kg/m^3)\n",
    "\n",
    "k = 109.0                        # W/m-K\n",
    "                       # W/m-K\n",
    "cp = 963.0                        # Specific heat of aluminum (J/kg-K)\n",
    "\n",
    "alpha = k / (rho * cp)            # Thermal diffusivity\n",
    "\n",
    "# print('alpha ia',alpha)\n",
    "#L_fusion = 3.9e3                 # J/kg\n",
    "L_fusion = 389.0e3               # J/kg\n",
    "\n",
    "# Spatial discretization\n",
    "\n",
    "num_points = 50                  # Number of spatial points\n",
    "dx = length / (num_points - 1)\n",
    "print('dx is',dx)\n",
    "                                   #dt = time_end/num_steps\n",
    "#num_steps = 200000               # Number of time steps\n",
    "                                  # num_steps = round(time_end/dt)\n",
    "                                                              \n",
    "# Time Discretization  \n",
    "# \n",
    "time_end = 10               # seconds                         \n",
    "#num_steps = 10000\n",
    "# dt = time_end/num_steps\n",
    "dt = abs(0.5 *(dx**2/alpha))\n",
    "print('dt is ',dt)\n",
    "num_steps = round(time_end/dt) +1\n",
    "print('num_steps is',num_steps)\n",
    "cfl = 0.5 *(dx**2/alpha)\n",
    "print('cfl is',cfl)\n",
    "#dt = time_end / num_steps\n",
    "time_steps = np.linspace(0, time_end, num_steps + 1)\n",
    "\n",
    "if dt <= cfl:\n",
    "    print('stability criteria satisfied')\n",
    "else:\n",
    "    print('stability criteria not satisfied')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Conditions\n",
    "T_L = 866.0                       #  K -Liquidus Temperature (593 c)\n",
    "T_S = 811.0                       # K- Solidus Temperature (538 C)\n",
    "\n",
    "\n",
    "# Initial temperature and phase fields\n",
    "init_temp = 870.0\n",
    "temperature = np.full(num_points, init_temp)\n",
    "phase = np.zeros(num_points)*1.0\n",
    "\n",
    "# Set boundary conditions\n",
    "temperature[-1] = 313.0 #(40 C)\n",
    "phase[-1] = 1.0\n",
    "\n",
    "temperature[0] = 313.0 #(40 C)\n",
    "phase[0] = 1.0\n",
    "\n",
    "# Store initial state in history\n",
    "temperature_history = [temperature.copy()]\n",
    "phi_history = [phase.copy()]\n",
    "\n",
    "#print(temperature_history,phi_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finite difference method\n",
    "\n",
    "for m in range(1, num_steps+1):                  # time loop\n",
    "    for n in range(1,num_points-1):              # space loop, adjusted range\n",
    "        #print(f\"Step {m}, point {n},Temperature: {temperature}, Phase: {phase}\")\n",
    "        temperature[n] = temperature[n] + ((alpha * dt )/ dx**2) * (temperature[n+1] - 2.0 * temperature[n] + temperature[n-1])\n",
    "        \n",
    "    \n",
    "    temperature_history.append(temperature.copy())\n",
    "    phi_history.append(phase.copy())\n",
    "    #Print for debugging\n",
    "    # print(f\"Step {m}, space{n},Temperature: {temperature}, Phase: {phase}\")\n",
    "\n",
    "\n",
    "#print(temperature_history)\n",
    "#print(phi_history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "temperature_history_a = np.array(temperature_history) \n",
    "phi_history_a = np.array(phi_history)\n",
    "\n",
    "time_steps = temperature_history_a.shape[0]\n",
    "spatial_poitns = temperature_history_a.shape[1]\n",
    "\n",
    "time = np.arange(time_steps)\n",
    "space = np.arange(spatial_poitns)\n",
    "\n",
    "T,X = np.meshgrid(time,space, indexing='ij')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot_surface(X,T,temperature_history_a, cmap='viridis')\n",
    "\n",
    "ax.set_xlabel('Space')\n",
    "ax.set_ylabel('Time')\n",
    "ax.set_zlabel('Temperature')\n",
    "ax.set_title('Temperature Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the neural network architecture\n",
    "class HeatPINN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size): # This is the constructor\n",
    "        super(HeatPINN, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, t):                               # This is the forward pass\n",
    "        input_features = torch.cat([x, t], dim=1)          # Concatenate the input features\n",
    "        m = self.base(input_features)                                 # Pass through the third layer\n",
    "        return m                    # Return the output of the network\n",
    "\n",
    "\n",
    "# features = torch.rand(1, 2)\n",
    "# model = HeatPINN(2, 20, 1)\n",
    "# output = model(features[:, 0:1], features[:, 1:2])\n",
    "# print(output)\n",
    "\n",
    "\n",
    "# Loss function for data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data for Aye Eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training data preparation\n",
    "x = torch.linspace(0, length, num_points).view(-1, 1).requires_grad_(True) # Spatial dimension of length l\n",
    "t = torch.linspace(0, time_end, num_steps+1).view(-1, 1).requires_grad_(True)# Temporal dimension of length T\n",
    "X, T = torch.meshgrid(x.squeeze(), t.squeeze(), indexing='ij') # Create a meshgrid of X and T\n",
    "\n",
    "X = X.reshape(-1, 1)  # Reshape X to a column vector\n",
    "T = T.reshape(-1, 1)   # Reshape T to a column vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "inputs = torch.cat([X, T], dim=1).to(device) # Concatenate the spatial and temporal inputs\n",
    "\n",
    "temp_t = torch.tensor(np.array(temperature_history)).to(device) # Convert the temperature history to a tensor\n",
    "# phase_t = torch.tensor(np.array(phi_history)).to(device)         # Convert the phase history to a tensor\n",
    "temp_inp = temp_t.reshape(-1,1) # Reshape the temperature tensor to a column vector\n",
    "# phase_inp = phase_t.reshape(-1,1) # Reshape the temperature tensor to a column vector\n",
    "\n",
    "\n",
    "#Data Splitting\n",
    "\n",
    "train_inputs, val_test_inputs, train_temp_inp, val_test_temp_inp = train_test_split(inputs, temp_inp, test_size=0.2, random_state=42)\n",
    "val_inputs, test_inputs, val_temp_inp, test_temp_inp = train_test_split(val_test_inputs, val_test_temp_inp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the custom data set for the training from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class  SpatiotemporalDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, inputs, temp_inp, transform = None, target_transform = None):\n",
    "#         self.inputs = inputs\n",
    "#         self.temp_inp = temp_inp\n",
    "        \n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return self.inputs[index], self.temp_inp[index]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.inputs)\n",
    "\n",
    "# # Create the dataset and dataloader   \n",
    "\n",
    "# train_dataset = SpatiotemporalDataset(train_inputs, train_temp_inp)\n",
    "\n",
    "# val_dataset = SpatiotemporalDataset(val_inputs, val_temp_inp)\n",
    "# test_dataset = SpatiotemporalDataset(test_inputs, test_temp_inp)\n",
    "\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=20, shuffle=False)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SpatiotemporalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, temp_inp, mean=None, std=None, transform=None, target_transform=None):\n",
    "        self.inputs = inputs\n",
    "        self.temp_inp = temp_inp\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        if mean is None or std is None:\n",
    "            self.mean = np.mean(inputs, axis=0)\n",
    "            self.std = np.std(inputs, axis=0)\n",
    "        else:\n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_data = (self.inputs[index] - self.mean) / self.std\n",
    "        temp_data = (self.temp_inp[index] - self.mean) / self.std\n",
    "        if self.transform:\n",
    "            input_data = self.transform(input_data)\n",
    "        if self.target_transform:\n",
    "            temp_data = self.target_transform(temp_data)\n",
    "        return torch.tensor(input_data, dtype=torch.float32), torch.tensor(temp_data, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate mean and std from the training data\n",
    "mean = train_inputs.mean(dim=0)\n",
    "std = train_inputs.std(dim=0)\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "train_dataset = SpatiotemporalDataset(train_inputs, train_temp_inp, mean=mean, std=std)\n",
    "val_dataset = SpatiotemporalDataset(val_inputs, val_temp_inp, mean=mean, std=std)\n",
    "test_dataset = SpatiotemporalDataset(test_inputs, test_temp_inp, mean=mean, std=std)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# # Example of iterating through the dataloader\n",
    "# for inputs, temp_inp in train_dataloader:\n",
    "#     print(inputs, temp_inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_loss(u,u_t,u_xx,alpha):\n",
    "    residual = u_t - alpha * u_xx\n",
    "    return nn.MSELoss()(residual,torch.zeros_like(residual))\n",
    "\n",
    "def boundary_loss(u_left,u_right,boundary_value):\n",
    "    return torch.mean((u_left - boundary_value)**2 + (u_right - boundary_value)**2)\n",
    "\n",
    "def initial_condition_loss(u_initial,initial_value):\n",
    "    return torch.mean((u_initial - initial_value)**2)\n",
    "\n",
    "\n",
    "def loss_fn_data(u_pred, u_true):\n",
    "    return nn.MSELoss()(u_pred, u_true)\n",
    "\n",
    "def l1_regularization(model, lambda_):\n",
    "    l1_reg = sum(param.abs().sum() for param in model.parameters())\n",
    "    return l1_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_size = 300\n",
    "learning_rate = 0.08\n",
    "epochs = 30000\n",
    "# alpha = 0.01  # Adjust this value based on your problem\n",
    "boundary_value = 313.0\n",
    "initial_value = init_temp\n",
    "# Initialize the model\n",
    "model = HeatPINN(input_size=2, hidden_size=hidden_size, output_size=1).to(device)\n",
    "lambda_l1 = 0.2\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(f\"Datatype:{type(train_losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, model, loss_fn_data, optimizer, train_dataloader, val_dataloader):\n",
    "    train_losses = []  # Initialize the list to store the training losses\n",
    "    val_losses = []    # Initialize the list to store the validation losses\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()                 # Set the model to training mode\n",
    "        train_loss = 0                # Initialize the training loss\n",
    "\n",
    "        for batch in train_dataloader:              # Loop through the training dataloader\n",
    "            inputs, temp_inp= batch                 # Get the inputs and the true values\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device) # Move the inputs and true values to the GPU\n",
    "            optimizer.zero_grad()                               # Zero the gradients\n",
    "            \n",
    "            # Forward pass\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1)).to(device) # Get the predictions\n",
    "            \n",
    "            # Loss calculation\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp.float())                                  # Calculate the data loss\n",
    "            l1_regularization_loss = l1_regularization(model, lambda_l1)                  # Calculate the L1 regularization loss\n",
    "            loss = data_loss + l1_regularization_loss                                      # Calculate the total loss\n",
    "            \n",
    "            # Backpropagation\n",
    "            loss.backward(retain_graph=True)                             # Backpropagate the gradients\n",
    "            \n",
    "            optimizer.step()                                                   # Update the weights\n",
    "            \n",
    "            train_loss += loss.item()     \n",
    "                                        # Add the loss to the training set loss\n",
    "        train_losses.append(train_loss)                               # Append the training loss to the list of training losses\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Training-Loss {train_loss}\")\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0                                                                     # Initialize the validation loss\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:                                                            # Loop through the validation dataloader\n",
    "                inputs, temp_inp= batch                                                        # Get the inputs and the true values\n",
    "                inputs, temp_inp= inputs.to(device), temp_inp.to(device)                                     # Move the inputs and true values to the GPU\n",
    "                u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))                        # Get the predictions\n",
    "                data_loss = loss_fn_data(u_pred, temp_inp.float())                                          # Calculate the data loss\n",
    "                loss = data_loss                                                                          # Calculate the total loss\n",
    "                val_loss += loss.item()                                                                     # Add the loss to the validation set loss\n",
    "            val_losses.append(val_loss)                                                                 # Append the validation loss to the list of validation losses\n",
    "                                                                        # Append the validation loss to the list of validation losses\n",
    "    return train_losses, val_losses                                                                    # Return the training and validation losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(epochs, model, loss_fn_data, optimizer, train_dataloader, test_dataloader):\n",
    "      \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():   \n",
    "        for batch in test_dataloader:\n",
    "            inputs, temp_inp= batch\n",
    "            inputs, temp_inp= inputs.to(device), temp_inp.to(device)\n",
    "            u_pred = model(inputs[:,0].unsqueeze(1), inputs[:,1].unsqueeze(1))\n",
    "            data_loss = loss_fn_data(u_pred, temp_inp.float())\n",
    "            loss = data_loss \n",
    "            test_loss += loss.item()\n",
    "        test_losses.append(test_loss)\n",
    "    if epochs % 10 == 0:\n",
    "        print(f\"Epoch {epochs}, Test-Loss {test_loss}\")    \n",
    "    return test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_losses, val_losses = training_loop(epochs, model, loss_fn_data, optimizer, train_dataloader, val_dataloader)  # Train the model\n",
    " \n",
    "test_losses = test_loop(epochs, model, loss_fn_data, optimizer, train_dataloader, test_dataloader)  # Test the model\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation Losses:{val_losses}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# # Load the model\n",
    "# model = HeatPINN(input_size=2, hidden_size=hidden_size, output_size=1).to(device)\n",
    "# model.load_state_dict(torch.load('model.pth'))\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss = test_loop(epochs, model, loss_fn_data, optimizer, train_dataloader, test_dataloader)\n",
    "# print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    " #plotting the loss\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0.0]],dtype=torch.float32).to(device)\n",
    "y = torch.tensor([[0.0]],dtype=torch.float32).to(device)\n",
    "\n",
    "y_o = model(x,y)\n",
    "print(y_o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-env)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
